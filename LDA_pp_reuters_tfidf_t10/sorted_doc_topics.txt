Corpus Type: tfidf
Topic Count: 10

test_14826        6: 0.716346760342798   1: 0.141413697284777   0: 0.089762600406294   5: 0.007512142320442   4: 0.007496317648533   8: 0.007494777518466   9: 0.007493890383417   7: 0.007493545316433   3: 0.007493239709685   2: 0.007493029069156 

test_14828        6: 0.821542506152213   4: 0.052774409784073   5: 0.015711452452432   0: 0.015710930521693   1: 0.015710857146676   7: 0.015710071472019   9: 0.015710045476131   8: 0.015709991646449   2: 0.015709986233819   3: 0.015709749114496 

test_14829        6: 0.440427719370760   0: 0.371639090605443   1: 0.089866062120686   8: 0.014014573442473   9: 0.014011927394139   5: 0.014009719363033   4: 0.014008499035040   2: 0.014007728395207   7: 0.014007682662596   3: 0.014006997610624 

test_14832        6: 0.562268786397846   0: 0.235978096512899   7: 0.080055259072116   1: 0.036730741637380   5: 0.014162374535258   9: 0.014161491134660   4: 0.014161048459958   8: 0.014160960661104   2: 0.014160838619760   3: 0.014160402969019 

test_14833        6: 0.525282797443708   7: 0.355511655945291   0: 0.014913272632266   1: 0.014900439515249   5: 0.014899854967106   9: 0.014899828170739   8: 0.014899172883534   2: 0.014897970072345   4: 0.014897591809723   3: 0.014897416560039 

test_14839        6: 0.874373389928445   9: 0.013962963182932   2: 0.013962421996144   1: 0.013957870054154   5: 0.013957719473596   0: 0.013957275418684   7: 0.013957192673814   8: 0.013957148911902   3: 0.013957102498478   4: 0.013956915861850 

test_14840        6: 0.679755143756431   2: 0.127797296505273   7: 0.077156143957237   9: 0.037972705082428   0: 0.022796347435973   8: 0.011793221400330   1: 0.010756433450271   3: 0.010673482428251   5: 0.010650992687411   4: 0.010648233296394 

test_14841        6: 0.448885062675495   5: 0.412002414714673   7: 0.017415952666558   0: 0.017386366073023   8: 0.017385883404825   1: 0.017385649730497   9: 0.017384955345149   4: 0.017384670408886   2: 0.017384568561898   3: 0.017384476418995 

test_14842        6: 0.805453566939744   3: 0.071456181235165   2: 0.015425471627170   5: 0.015381613084650   1: 0.015381143524617   0: 0.015381012309837   4: 0.015380729381161   9: 0.015380340518156   8: 0.015380050642065   7: 0.015379890737435 

test_14843        1: 0.550821626048092   6: 0.322216854690220   0: 0.052497229477589   9: 0.012196327634331   8: 0.010427753449493   5: 0.010369346340252   2: 0.010367822821920   3: 0.010367713556068   7: 0.010367670258475   4: 0.010367655723562 

test_14844        6: 0.589543629378704   1: 0.158039450189356   2: 0.121215630438006   3: 0.018758849096543   7: 0.018742602906459   5: 0.018740842509247   0: 0.018740564125948   8: 0.018739631001824   4: 0.018739530078440   9: 0.018739270275472 

test_14849        6: 0.452360204085570   0: 0.414125988744251   7: 0.040058337125176   1: 0.013370461149181   8: 0.013354584625596   9: 0.013347612346299   5: 0.013346709441130   4: 0.013345817838754   2: 0.013345198819198   3: 0.013345085824844 

test_14852        0: 0.619015526412698   6: 0.261269251516404   5: 0.014967368232711   4: 0.014967182170769   1: 0.014965702324742   8: 0.014963527280505   9: 0.014963077260332   7: 0.014962878604048   2: 0.014962864748629   3: 0.014962621449163 

test_14854        6: 0.748467321392368   5: 0.065061715322956   0: 0.059890516943395   1: 0.018083881652502   9: 0.018083227508436   4: 0.018083188264277   7: 0.018082757919002   8: 0.018082610018819   2: 0.018082500692983   3: 0.018082280285263 

test_14858        6: 0.667218766792603   0: 0.110346474251667   5: 0.068482598068977   3: 0.067603493540147   9: 0.022910069155727   1: 0.022491525269281   7: 0.010265964381866   8: 0.010234810920473   4: 0.010225746772394   2: 0.010220550846865 

test_14859        0: 0.832539891668308   6: 0.018664595245169   5: 0.018611368771667   1: 0.018603018825964   8: 0.018597389384285   9: 0.018597115013727   3: 0.018596873540655   4: 0.018596837396045   2: 0.018596488395618   7: 0.018596421758562 

test_14860        3: 0.480766175125208   5: 0.325020909201439   0: 0.058035925628642   2: 0.019588976591223   1: 0.019447162041626   6: 0.019441974121683   8: 0.019430885483923   9: 0.019424421787195   4: 0.019422424766679   7: 0.019421145252381 

test_14861        9: 0.858062035295678   8: 0.015774152314609   6: 0.015771913079461   0: 0.015771619659169   1: 0.015770999389424   5: 0.015770916664368   4: 0.015769929181998   7: 0.015769515336487   2: 0.015769490452321   3: 0.015769428626486 

test_14862        6: 0.570244516601544   0: 0.326659598589896   1: 0.012888276281801   5: 0.012887345503682   9: 0.012887041534122   8: 0.012886797484233   7: 0.012886745362235   4: 0.012886739759102   2: 0.012886524012209   3: 0.012886414871177 

test_14863        3: 0.377780688600574   6: 0.377031020065439   1: 0.120651594907826   0: 0.041815723628274   5: 0.019072859025610   9: 0.012757980657071   2: 0.012731896637312   8: 0.012724629818263   7: 0.012717376744678   4: 0.012716229914952 

test_14865        3: 0.452876802366460   6: 0.269322378444571   2: 0.102674638182908   0: 0.056785428609422   9: 0.019755714892007   1: 0.019738506501131   5: 0.019717324725640   7: 0.019710289850925   4: 0.019710183375126   8: 0.019708733051811 

test_14867        6: 0.837783798292587   5: 0.038151485686086   0: 0.015518369644989   1: 0.015507114349255   7: 0.015506869070984   4: 0.015506805863588   9: 0.015506514549682   8: 0.015506400255503   2: 0.015506354569202   3: 0.015506287718123 

test_14872        1: 0.500502967205456   6: 0.381770459716828   5: 0.014721271706874   4: 0.014720099479584   9: 0.014716451066005   0: 0.014716083040709   8: 0.014714808070307   3: 0.014713493584743   7: 0.014712309596639   2: 0.014712056532857 

test_14873        6: 0.665069067069162   3: 0.221384289830286   0: 0.014797343185281   4: 0.014452995887823   5: 0.014218987175319   7: 0.014102717040398   9: 0.014019142412246   1: 0.013997413949012   8: 0.013979743882445   2: 0.013978299568027 

test_14875        1: 0.798409921202736   6: 0.039856870245467   5: 0.038278657071520   7: 0.017666088718518   0: 0.017651219525132   4: 0.017632384104334   9: 0.017631666123499   3: 0.017625282000148   8: 0.017624561641372   2: 0.017623349367273 

test_14876        3: 0.323544357947292   5: 0.267976755163288   1: 0.267358765845235   4: 0.020162928687559   6: 0.020162475945274   0: 0.020160720333054   8: 0.020159499088568   9: 0.020158523516483   7: 0.020158073545295   2: 0.020157899927951 

test_14877        6: 0.801033121494811   1: 0.055153220439034   7: 0.017983048295193   5: 0.017976354660746   0: 0.017976246124599   2: 0.017976237209958   9: 0.017975517358750   8: 0.017975456296815   3: 0.017975443469104   4: 0.017975354650991 

test_14881        6: 0.820487532058943   1: 0.089155368224012   0: 0.011296251041002   5: 0.011294829050332   8: 0.011294533308757   9: 0.011294425521978   7: 0.011294297961517   4: 0.011294259327795   2: 0.011294251843107   3: 0.011294251662558 

test_14882        6: 0.589301044642940   7: 0.170603004422340   0: 0.127431163344726   9: 0.016101707848158   5: 0.016095732023240   4: 0.016093867955904   1: 0.016093662124120   8: 0.016093653431208   2: 0.016093174348444   3: 0.016092989858921 

test_14885        6: 0.867465553101205   0: 0.014726772494869   1: 0.014726557761023   9: 0.014726158554024   7: 0.014725982959644   8: 0.014725944104573   5: 0.014725941255051   4: 0.014725742331689   2: 0.014725733229210   3: 0.014725614208711 

test_14886        6: 0.658393413739970   0: 0.154678511445861   5: 0.023367250043469   1: 0.023366563524574   7: 0.023366456547339   9: 0.023365690626413   4: 0.023365579019521   8: 0.023365572131346   3: 0.023365538323493   2: 0.023365424598013 

test_14888        0: 0.518975518762652   4: 0.195608788851032   6: 0.141725208106439   5: 0.068893077178954   1: 0.012469517475592   3: 0.012469309146006   8: 0.012465316221770   9: 0.012464761392484   2: 0.012464409337711   7: 0.012464093527358 

test_14890        6: 0.601950173312663   0: 0.182949871193499   7: 0.113091878920472   1: 0.050908515706365   9: 0.012014935503007   5: 0.007833627944214   2: 0.007818882559346   8: 0.007811753986948   4: 0.007810302346492   3: 0.007810058526994 

test_14891        6: 0.709586797178245   5: 0.082669332014179   1: 0.071869395351263   0: 0.051107406361042   3: 0.048367016593513   9: 0.007421316259412   7: 0.007250801050709   2: 0.007243146766326   8: 0.007242584749321   4: 0.007242203675991 

test_14892        6: 0.852706883443668   7: 0.016371457748274   5: 0.016365702321300   8: 0.016365493579605   0: 0.016365439582059   1: 0.016365405679590   9: 0.016365075945830   2: 0.016364939855374   4: 0.016364897801521   3: 0.016364704042779 

test_14899        0: 0.411057024652406   3: 0.374852471447627   5: 0.026787557715707   6: 0.026768346345677   1: 0.026760873278052   2: 0.026755681591220   8: 0.026755286210031   4: 0.026754564127713   9: 0.026754189144968   7: 0.026754005486599 

test_14900        6: 0.529670694620479   4: 0.288517081372252   1: 0.052878976149029   2: 0.031787938772842   0: 0.016194106166685   3: 0.016191732798643   5: 0.016191590559391   9: 0.016189838360025   8: 0.016189064559654   7: 0.016188976641000 

test_14903        6: 0.543580378511506   5: 0.297963432430686   1: 0.019809076216515   9: 0.019808343245095   0: 0.019807901300210   4: 0.019807207676054   7: 0.019806203446080   8: 0.019806085541538   3: 0.019805778802970   2: 0.019805592829346 

test_14904        6: 0.526032352815857   1: 0.256680506726737   9: 0.129172895919769   0: 0.012588966785354   5: 0.012588953230764   4: 0.012587612013551   3: 0.012587348844720   7: 0.012587143701880   8: 0.012587137926701   2: 0.012587082034667 

test_14907        6: 0.557374351232233   2: 0.266372299597693   0: 0.047502374506729   1: 0.018496022906589   9: 0.018379428459601   5: 0.018377024104398   4: 0.018375314755477   3: 0.018374747167165   8: 0.018374402541615   7: 0.018374034728499 

test_14909        1: 0.470075403212777   6: 0.403023997310842   9: 0.015867622989666   0: 0.015865844968097   7: 0.015865155987029   5: 0.015861831039235   8: 0.015860501887095   2: 0.015860039284188   4: 0.015860006403601   3: 0.015859596917470 

test_14911        3: 0.318008702326159   1: 0.309978447975023   6: 0.240574388286480   0: 0.052938060612574   5: 0.013097537888400   4: 0.013085450651325   7: 0.013079983334444   2: 0.013079801362111   8: 0.013079181871821   9: 0.013078445691662 

test_14912        6: 0.821828014197918   1: 0.086647659118672   0: 0.011442113238132   5: 0.011440746860363   8: 0.011440445130416   9: 0.011440332446614   7: 0.011440205130281   4: 0.011440166561550   2: 0.011440159072702   3: 0.011440158243352 

test_14913        6: 0.732683800297194   8: 0.100267905774859   7: 0.053432397321402   1: 0.016234096088677   0: 0.016231944551408   5: 0.016230353123555   9: 0.016230270809670   2: 0.016229906416492   4: 0.016229667994123   3: 0.016229657622619 

test_14918        6: 0.712676648737027   9: 0.121977232375802   0: 0.020669978263956   5: 0.020669770905043   7: 0.020667935093899   8: 0.020667928903142   1: 0.020667679106038   2: 0.020667637240212   4: 0.020667623085696   3: 0.020667566289185 

test_14919        9: 0.707033484733021   6: 0.138197621153479   8: 0.019350591002279   3: 0.019346465756828   5: 0.019346445246286   0: 0.019345767950234   1: 0.019345556465006   4: 0.019344994980150   2: 0.019344588638147   7: 0.019344484074570 

test_14921        0: 0.688506882964586   6: 0.226169062055831   9: 0.012332226155696   1: 0.011928915782846   4: 0.011120843012597   7: 0.010535415587340   5: 0.009912387419241   3: 0.009833972083816   8: 0.009831883967027   2: 0.009828410971020 

test_14922        6: 0.518586774800149   8: 0.284887549251313   0: 0.084820948937658   1: 0.027916146906084   7: 0.013999792163666   5: 0.013959486910179   4: 0.013958005488162   9: 0.013957815172583   3: 0.013956753551369   2: 0.013956726818838 

test_14923        6: 0.796257295644715   0: 0.074689215722569   7: 0.016148994091378   8: 0.016133868874814   9: 0.016131607695892   1: 0.016128173761436   5: 0.016127853999367   4: 0.016127704716694   2: 0.016127700993372   3: 0.016127584499762 

test_14926        9: 0.458733536779087   6: 0.374951032696985   7: 0.042863541488626   5: 0.017648154453097   1: 0.017639338203642   4: 0.017636385771716   0: 0.017634656820142   8: 0.017631816449461   2: 0.017630985521754   3: 0.017630551815490 

test_14928        6: 0.453764430246825   0: 0.434712605037132   7: 0.013945708168886   5: 0.013945146851168   1: 0.013939632124387   9: 0.013939513507084   8: 0.013938636284540   4: 0.013938283127052   3: 0.013938107170850   2: 0.013937937482076 

test_14930        5: 0.359738624968208   6: 0.329036220246459   9: 0.137495622402642   0: 0.054049148887714   1: 0.019949714345318   2: 0.019947054014840   4: 0.019946489486268   3: 0.019946207637733   7: 0.019945730899761   8: 0.019945187111057 

test_14931        6: 0.643120415130881   7: 0.146898472571676   0: 0.142129804322592   1: 0.009710673368202   3: 0.009691641602606   8: 0.009691337058495   5: 0.009689983781144   9: 0.009689576395710   4: 0.009689104242500   2: 0.009688991526196 

test_14932        6: 0.718832788993562   2: 0.071858370390047   4: 0.067740275827238   5: 0.020232733249433   1: 0.020226127650014   0: 0.020224870072364   9: 0.020222181044997   7: 0.020221570615953   3: 0.020221337110914   8: 0.020219745045478 

test_14933        6: 0.488657218741897   4: 0.369897451311574   0: 0.037873899993861   1: 0.014837646587956   5: 0.014793052579342   3: 0.014789249095531   9: 0.014788061111345   7: 0.014787975401528   2: 0.014787936699872   8: 0.014787508477094 

test_14934        5: 0.777561122881342   3: 0.024715925342747   4: 0.024715737262655   0: 0.024715644267074   8: 0.024715330750889   1: 0.024715292303611   2: 0.024715292201596   6: 0.024715255556020   7: 0.024715220781591   9: 0.024715178652476 

test_14941        2: 0.552549849469689   6: 0.275593314538514   0: 0.048549461419248   8: 0.017863490089927   9: 0.017580052008225   5: 0.017577134180149   1: 0.017574424572167   4: 0.017572317044990   7: 0.017570569206413   3: 0.017569387470679 

test_14943        6: 0.720870453834080   8: 0.031026644843728   5: 0.031023048671592   1: 0.031021309332741   0: 0.031015252799975   4: 0.031014882055940   2: 0.031009305539389   3: 0.031007755476287   7: 0.031006092074848   9: 0.031005255371420 

test_14949        6: 0.850631037205496   4: 0.016601852295076   1: 0.016600495137216   5: 0.016599972049559   0: 0.016597244875039   2: 0.016594232928411   9: 0.016594019732768   8: 0.016593852800810   3: 0.016593706486851   7: 0.016593586488773 

test_14951        6: 0.450928829160045   5: 0.271466477384033   3: 0.164985007090688   7: 0.016107574617697   8: 0.016094209408375   4: 0.016089012073693   0: 0.016084902757044   1: 0.016081900976561   9: 0.016081644066208   2: 0.016080442465656 

test_14954        5: 0.780400580267212   4: 0.024403087568991   7: 0.024402380841633   1: 0.024402242437197   6: 0.024402053325280   0: 0.024398411461681   3: 0.024398109801983   8: 0.024397998604018   9: 0.024397601210646   2: 0.024397534481358 

test_14957        6: 0.868326718194142   9: 0.014637301567489   2: 0.014636253133854   5: 0.014629185992783   1: 0.014629051863493   7: 0.014628417063255   8: 0.014628358417301   0: 0.014628347252243   3: 0.014628317365700   4: 0.014628049149741 

test_14958        3: 0.436128236219710   5: 0.254038024255344   4: 0.038746098436506   8: 0.038727447154331   2: 0.038727436345175   7: 0.038726973690279   9: 0.038726620294016   0: 0.038726591145927   1: 0.038726340300723   6: 0.038726232157989 

test_14959        1: 0.530944732572947   6: 0.369118666571098   8: 0.012599374556675   3: 0.012480862721828   0: 0.012477502764761   5: 0.012476351117792   9: 0.012475849613106   7: 0.012475780854096   2: 0.012475470981693   4: 0.012475408246005 

test_14960        5: 0.508379389061700   3: 0.219696565716101   0: 0.115054268098292   4: 0.022414438967812   6: 0.022412675910896   8: 0.022408968688840   2: 0.022408498238844   9: 0.022408484443380   7: 0.022408409375525   1: 0.022408301498611 

test_14962        5: 0.356614121917015   3: 0.244698909119168   7: 0.194156196584229   4: 0.029225649070230   8: 0.029217867250398   9: 0.029217612567065   0: 0.029217548247070   2: 0.029217529280219   1: 0.029217311195062   6: 0.029217254769545 

test_14963        5: 0.583155935224289   2: 0.226414319536595   4: 0.023811406664315   8: 0.023802994685365   0: 0.023802689642860   6: 0.023802677446078   1: 0.023802590295631   3: 0.023802521764727   9: 0.023802496652643   7: 0.023802368087498 

test_14964        9: 0.799504754221859   8: 0.022301037803664   1: 0.022279746961990   6: 0.022278699223639   5: 0.022274095671396   0: 0.022273535124913   4: 0.022272453743362   7: 0.022272133509435   2: 0.022271912188383   3: 0.022271631551359 

test_14965        4: 0.369952943693300   8: 0.357462458350463   5: 0.034085657877743   1: 0.034074992212566   2: 0.034071175380066   3: 0.034071018522699   0: 0.034070935475169   7: 0.034070429948193   9: 0.034070311718532   6: 0.034070076821269 

test_14967        0: 0.428369518781958   5: 0.226339791581500   3: 0.155490955039300   7: 0.070248436194906   6: 0.019930121522480   4: 0.019924930887430   1: 0.019924891208978   9: 0.019924726868352   8: 0.019923679155884   2: 0.019922948759212 

test_14968        7: 0.389769460561691   5: 0.387259837127672   4: 0.027876271272570   8: 0.027872172821095   6: 0.027872044981014   9: 0.027871280835707   0: 0.027870488071519   1: 0.027869651532323   3: 0.027869420295137   2: 0.027869372501272 

test_14969        5: 0.818403344971465   6: 0.020178309712076   4: 0.020178288239414   1: 0.020177880912288   8: 0.020177804509288   0: 0.020177492893936   9: 0.020177097632761   3: 0.020176688292921   2: 0.020176578105361   7: 0.020176514730490 

test_14970        5: 0.568501517567965   6: 0.253704599224393   4: 0.022226747335102   0: 0.022224405677654   8: 0.022224344618474   1: 0.022224192157705   9: 0.022223848064012   2: 0.022223604265457   3: 0.022223389096256   7: 0.022223351992981 

test_14971        5: 0.435957658851733   8: 0.354952358927098   4: 0.026142786448414   3: 0.026135688923820   2: 0.026135519965206   9: 0.026135409018130   7: 0.026135319861951   1: 0.026135203003788   0: 0.026135154213407   6: 0.026134900786452 

test_14974        6: 0.537894045522758   7: 0.273853819897376   5: 0.023533753664669   8: 0.023532066316721   0: 0.023532026154538   9: 0.023531819827544   1: 0.023531007755355   2: 0.023530564922711   3: 0.023530538638800   4: 0.023530357299528 

test_14975        4: 0.476711509944743   6: 0.336736983301403   0: 0.044754804386910   5: 0.020476078581587   1: 0.020224925729980   8: 0.020222353305391   9: 0.020219147483144   7: 0.020218424572051   2: 0.020217975567994   3: 0.020217797126797 

test_14978        1: 0.486303694378477   2: 0.273539237473766   0: 0.119962397193379   5: 0.017177211624761   6: 0.017172553065245   9: 0.017171181824747   4: 0.017169727574229   7: 0.017168157292703   8: 0.017168036626883   3: 0.017167802945810 

test_14981        4: 0.408112192180988   2: 0.382463251617028   5: 0.026188307296852   8: 0.026179155448691   6: 0.026176479128078   3: 0.026176427093493   7: 0.026176177623085   0: 0.026176103286282   1: 0.026176040289805   9: 0.026175866035698 

test_14982        6: 0.838993300976706   1: 0.062338010194710   7: 0.012521795262565   5: 0.012310102086681   0: 0.012307568755532   2: 0.012306659348941   9: 0.012305982386083   4: 0.012305752526817   8: 0.012305672592558   3: 0.012305155869406 

test_14983        5: 0.631994921317840   1: 0.157498560587393   6: 0.078464901950119   4: 0.018867732395923   8: 0.018863112500505   9: 0.018862509000571   7: 0.018862087963551   2: 0.018862081787501   0: 0.018862048772807   3: 0.018862043723790 

test_14984        6: 0.614721347114085   5: 0.169731106850184   8: 0.070315536665200   7: 0.051018173082719   4: 0.029754699149090   1: 0.012934752521397   0: 0.012889920245743   3: 0.012881239969730   9: 0.012877628450727   2: 0.012875595951125 

test_14985        5: 0.665621000209650   6: 0.124457308347615   0: 0.026250864034843   1: 0.026242306972442   4: 0.026241014368020   2: 0.026239513179268   8: 0.026239198231207   3: 0.026236333244617   7: 0.026236331149858   9: 0.026236130262481 

test_14986        6: 0.531206222103167   0: 0.268415215821556   9: 0.025071369169319   1: 0.025044366097758   7: 0.025044303943876   2: 0.025043846645222   5: 0.025043738778127   4: 0.025043703193652   3: 0.025043634704409   8: 0.025043599542915 

test_14987        6: 0.651872819813048   0: 0.191169470920438   7: 0.075937427841124   5: 0.011597724953472   1: 0.011587330105989   8: 0.011572890353324   3: 0.011571618892539   9: 0.011564161869261   4: 0.011563303766554   2: 0.011563251484251 

test_14988        6: 0.881117205989635   1: 0.013209557654073   9: 0.013209493907217   5: 0.013209440510628   0: 0.013209390285713   8: 0.013209100429403   7: 0.013209063022680   4: 0.013208975767349   2: 0.013208961864084   3: 0.013208810569217 

test_14993        1: 0.690382549454970   6: 0.160981714725619   0: 0.040746711054373   5: 0.015457367606875   8: 0.015416685664925   9: 0.015408657461212   4: 0.015404956927397   3: 0.015400611860871   7: 0.015400500304913   2: 0.015400244938844 

test_14995        4: 0.393290621488964   0: 0.380844697370668   5: 0.028242342536284   8: 0.028232111411761   3: 0.028232049736902   2: 0.028231852394662   9: 0.028231653915567   7: 0.028231640179834   1: 0.028231631367483   6: 0.028231399597874 

test_14998        5: 0.527312075326620   1: 0.198570119921095   3: 0.130294140419736   4: 0.020549326362803   0: 0.020546748664594   7: 0.020545998643597   6: 0.020545484800696   2: 0.020545386718321   9: 0.020545372258751   8: 0.020545346883786 

test_15000        3: 0.470772021912147   5: 0.343762492310699   6: 0.023218782339772   0: 0.023182736156958   4: 0.023181792442648   1: 0.023176848578686   8: 0.023176627234127   9: 0.023176473534338   7: 0.023176331602357   2: 0.023175893888268 

test_15001        7: 0.506347710166524   6: 0.180906217111239   0: 0.124273859028218   4: 0.026933950256181   2: 0.026931754588950   1: 0.026931349383352   5: 0.026923863012554   8: 0.026920419537462   3: 0.026916083216869   9: 0.026914793698652 

test_15002        5: 0.527625261610972   3: 0.253746857940852   0: 0.027380397501747   6: 0.027341907593031   8: 0.027324687534391   1: 0.027320598582003   4: 0.027317032042799   7: 0.027316632901508   9: 0.027313980480857   2: 0.027312643811841 

test_15004        7: 0.506744585463001   1: 0.288802419288379   5: 0.025563750931042   6: 0.025559848417579   0: 0.025557195334180   2: 0.025556459101244   4: 0.025556094117926   9: 0.025554496034019   3: 0.025552927210623   8: 0.025552224102006 

test_15005        3: 0.347426548733083   6: 0.315366941645440   0: 0.161634388445711   1: 0.046417542964711   8: 0.043615881140823   4: 0.017119446769285   7: 0.017111866121984   5: 0.017109086946256   9: 0.017099503491036   2: 0.017098793741670 

test_15006        5: 0.735939463334440   4: 0.029342933935629   8: 0.029340142033675   9: 0.029339832123620   3: 0.029339670280085   6: 0.029339632042430   7: 0.029339611353568   0: 0.029339606594061   2: 0.029339582354947   1: 0.029339525947544 

test_15011        4: 0.453099145435814   3: 0.280386690550417   5: 0.033366514535176   1: 0.033310044673327   2: 0.033309284377844   6: 0.033306996348494   0: 0.033306932497159   9: 0.033305745108922   7: 0.033304388402771   8: 0.033304258070076 

test_15012        5: 0.410130465001877   6: 0.391422240790101   3: 0.024851508830788   4: 0.024808571059525   2: 0.024807668582328   9: 0.024800719489240   1: 0.024795112470944   0: 0.024794655273329   8: 0.024794555844390   7: 0.024794502657479 

test_15013        6: 0.562092022004369   0: 0.307036941150100   5: 0.036463125590257   8: 0.013516118533112   1: 0.013483429874855   3: 0.013482695073796   2: 0.013481515375503   7: 0.013481471339455   9: 0.013481463488120   4: 0.013481217570434 

test_15016        5: 0.689267015673317   4: 0.034528527610617   1: 0.034528513728898   6: 0.034526531853743   3: 0.034526017579103   8: 0.034524856419509   0: 0.034524720854434   2: 0.034524693964242   7: 0.034524571528124   9: 0.034524550788014 

test_15017        6: 0.849940503163439   1: 0.016674128047843   0: 0.016673516052702   9: 0.016673409609433   7: 0.016673215725284   5: 0.016673193019304   2: 0.016673090671315   8: 0.016673015413951   4: 0.016672996768821   3: 0.016672931527909 

test_15020        0: 0.679945340990152   6: 0.202463204805548   5: 0.014718665646938   3: 0.014699166316171   1: 0.014698366246948   4: 0.014697775216732   8: 0.014694714796272   9: 0.014694309240468   2: 0.014694229772432   7: 0.014694226968341 

test_15023        5: 0.740545007190088   4: 0.028831895619374   8: 0.028828063001294   2: 0.028827986212362   3: 0.028827936769371   7: 0.028827906864521   0: 0.028827879726867   9: 0.028827845424360   1: 0.028827794348022   6: 0.028827684843742 

test_15024        0: 0.793019330179501   6: 0.059723023455946   5: 0.018419578365219   4: 0.018415454823800   9: 0.018408984188798   1: 0.018406866796054   8: 0.018403682402575   7: 0.018401330662522   2: 0.018401008766873   3: 0.018400740358712 

test_15026        5: 0.829715732614159   8: 0.019009583634353   6: 0.018920737358163   0: 0.018909626039126   1: 0.018908293513870   9: 0.018908146535110   4: 0.018907759026100   2: 0.018906854166833   7: 0.018906731567855   3: 0.018906535544431 

test_15027        0: 0.517226470419374   5: 0.240362890853870   4: 0.030310055638542   6: 0.030302546498255   3: 0.030300115153871   2: 0.030299881179153   8: 0.030299795038383   1: 0.030299473760547   7: 0.030299400162895   9: 0.030299371295110 

test_15028        5: 0.817038619154400   9: 0.020331380196402   6: 0.020331117901907   8: 0.020330178659715   4: 0.020329460658990   1: 0.020328693971457   0: 0.020328557852841   7: 0.020327512924646   2: 0.020327305869473   3: 0.020327172810168 

test_15029        5: 0.590286987619119   2: 0.229917472879642   1: 0.022479080656157   6: 0.022475035746882   0: 0.022474705632660   7: 0.022474095091422   4: 0.022473600319163   9: 0.022473038973460   8: 0.022473026583646   3: 0.022472956497850 

test_15031        8: 0.468345343594762   6: 0.180512996402800   1: 0.152813928110850   0: 0.111983713169769   5: 0.014398962297417   9: 0.014392372264696   3: 0.014388790281218   4: 0.014388141307009   2: 0.014387939316270   7: 0.014387813255209 

test_15032        5: 0.739505172957363   3: 0.077477843868339   2: 0.022935036683484   1: 0.022872709726347   6: 0.022872134131083   9: 0.022871557725159   4: 0.022867578177421   0: 0.022866653378222   7: 0.022865746562965   8: 0.022865566789617 

test_15033        6: 0.688020815081640   0: 0.153709025870160   1: 0.057434712445525   8: 0.014407352672957   3: 0.014407176343745   9: 0.014405888622615   2: 0.014404202385770   5: 0.014403885737092   7: 0.014403672804651   4: 0.014403268035845 

test_15037        5: 0.769696272532502   6: 0.025674566089779   3: 0.025609230498339   1: 0.025579580462150   0: 0.025578920307755   9: 0.025572948293988   4: 0.025572287419648   2: 0.025572168671839   7: 0.025572100794217   8: 0.025571924929781 

test_15038        2: 0.767559476086863   8: 0.061946878402160   5: 0.021319259029837   6: 0.021319039093900   0: 0.021312496490961   7: 0.021309366018151   1: 0.021309300844259   4: 0.021309079919955   9: 0.021307922071404   3: 0.021307182042512 

test_15043        6: 0.504300096151192   7: 0.332792134877019   0: 0.086768079275832   8: 0.010879867109043   9: 0.010878321046818   5: 0.010877431188848   1: 0.010877227901205   4: 0.010876097181093   3: 0.010875755661672   2: 0.010874989607279 

test_15045        6: 0.472086224584277   8: 0.241886881809771   7: 0.129013021854753   0: 0.049961635985510   1: 0.017860414043414   5: 0.017841397105488   9: 0.017839664889655   3: 0.017837335256125   4: 0.017836847091306   2: 0.017836577379701 

test_15046        9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

test_15048        6: 0.622168098543015   9: 0.154624632166805   3: 0.099151665055863   1: 0.056482922546573   7: 0.011264899107194   0: 0.011263725447811   8: 0.011261204091382   2: 0.011260978058990   5: 0.011260969937825   4: 0.011260905044543 

test_15049        8: 0.606969697158143   6: 0.221120924502922   5: 0.069037791364788   3: 0.014753322623729   0: 0.014691751285613   9: 0.014687499159943   1: 0.014686432606402   7: 0.014684351954621   4: 0.014684244050582   2: 0.014683985293257 

test_15052        7: 0.519642555522691   1: 0.308804711288306   9: 0.021478946490948   4: 0.021465470417721   6: 0.021450703212644   5: 0.021444066029039   0: 0.021431767010843   8: 0.021430985783602   2: 0.021426037639940   3: 0.021424756604266 

test_15053        7: 0.427846807147362   5: 0.350855552741525   9: 0.027666327535494   4: 0.027665381115753   6: 0.027664846732117   8: 0.027664283448466   0: 0.027660464213231   1: 0.027660279783653   3: 0.027658075994383   2: 0.027657981288015 

test_15055        5: 0.648504280440432   1: 0.228277528525077   6: 0.015406145438775   7: 0.015405846682314   0: 0.015402509088934   8: 0.015401988565844   2: 0.015401380051099   9: 0.015401051270790   3: 0.015399810496595   4: 0.015399459440139 

test_15056        0: 0.541507964841415   5: 0.294387325588490   6: 0.020614863336524   9: 0.020538518409456   4: 0.020498174398499   7: 0.020490946978030   1: 0.020490702020033   8: 0.020490653215930   3: 0.020490458588401   2: 0.020490392623222 

test_15060        4: 0.525504871999751   0: 0.300109880895525   1: 0.039819413505026   6: 0.019228872929814   5: 0.019225992356649   8: 0.019224155624749   9: 0.019222773027188   2: 0.019221661971589   3: 0.019221194860762   7: 0.019221182828949 

test_15061        0: 0.496386891577062   5: 0.341216594320916   1: 0.020302386417185   4: 0.020300809410745   6: 0.020300243057832   2: 0.020299252088600   3: 0.020298912083300   9: 0.020298493775385   7: 0.020298333922160   8: 0.020298083346815 

test_15062        5: 0.445221034457858   3: 0.344520576898974   4: 0.026288524350370   8: 0.026281905537421   0: 0.026281774807822   9: 0.026281435647101   7: 0.026281249072841   6: 0.026281221027387   2: 0.026281170741858   1: 0.026281107458369 

test_15063        6: 0.489102640454291   2: 0.229470172670427   0: 0.169840872870285   9: 0.050259244798073   4: 0.013653910731570   5: 0.012243706471127   1: 0.010501861412035   7: 0.008381008795430   3: 0.008292508302360   8: 0.008254073494402 

test_15065        5: 0.804106459284647   9: 0.052473643292227   4: 0.017933053204948   8: 0.017927115507657   0: 0.017926946143250   3: 0.017926830712640   2: 0.017926646613472   1: 0.017926629863489   7: 0.017926520858551   6: 0.017926154519119 

test_15067        5: 0.608749592013078   7: 0.221242126748147   4: 0.021254273054256   1: 0.021251581476433   6: 0.021251115858284   0: 0.021251031120811   2: 0.021250185513827   9: 0.021250065262310   3: 0.021250022685775   8: 0.021250006267079 

test_15069        6: 0.440531104343030   5: 0.330927443677605   2: 0.028584607580442   0: 0.028579848033668   1: 0.028566261514479   9: 0.028562752916959   7: 0.028562703525722   8: 0.028562503405188   4: 0.028561582731146   3: 0.028561192271759 

test_15070        6: 0.443822684538728   4: 0.243788769025938   5: 0.039074633836669   8: 0.039046371096464   2: 0.039045364838932   0: 0.039044782011038   7: 0.039044600929992   3: 0.039044399004806   9: 0.039044235048840   1: 0.039044159668594 

test_15074        5: 0.717617036231908   1: 0.031388061552800   6: 0.031376873082598   4: 0.031376437766011   0: 0.031375364244282   3: 0.031373432704470   2: 0.031373343818440   9: 0.031373300094857   7: 0.031373146987118   8: 0.031373003517516 

test_15077        7: 0.419765339560981   5: 0.372553400137722   3: 0.025965251159392   4: 0.025960290623787   6: 0.025959403562524   1: 0.025959350968905   0: 0.025959310511644   2: 0.025959306624900   8: 0.025959261389779   9: 0.025959085460368 

test_15078        5: 0.619221059481456   4: 0.189800205230074   1: 0.023881256335605   6: 0.023873584191478   0: 0.023871612722962   8: 0.023871546611118   9: 0.023870932723025   3: 0.023870668873238   2: 0.023869682842420   7: 0.023869450988623 

test_15079        5: 0.418017462731797   6: 0.374697919266783   4: 0.025916600302799   8: 0.025910404154183   9: 0.025910000354634   2: 0.025909593641971   0: 0.025909582338830   7: 0.025909563620697   3: 0.025909484139237   1: 0.025909389449069 

test_15082        5: 0.472600971008137   2: 0.324930791173879   6: 0.025309751568684   8: 0.025309387310131   9: 0.025308926523254   0: 0.025308559291281   4: 0.025308154175546   3: 0.025308060810546   1: 0.025307981127521   7: 0.025307417011022 

test_15090        5: 0.838136364352239   4: 0.017987195746007   1: 0.017986065830497   0: 0.017985304925309   6: 0.017984731817337   7: 0.017984201861968   2: 0.017984085340133   9: 0.017984028533179   3: 0.017984024086666   8: 0.017983997506665 

test_15091        6: 0.359837784623624   5: 0.271052520367087   0: 0.227052597972726   1: 0.032891806441950   3: 0.025730641742319   2: 0.024867688304730   8: 0.014653265034417   9: 0.014640477113556   7: 0.014636944314743   4: 0.014636274084848 

test_15092        8: 0.704230641759553   7: 0.032867976835546   6: 0.032866658173870   5: 0.032865430650917   0: 0.032862382906320   1: 0.032862098999626   9: 0.032861790431604   3: 0.032861641870520   4: 0.032860934218338   2: 0.032860444153706 

test_15093        6: 0.723136094314986   5: 0.154357185627772   1: 0.015319921279103   4: 0.015316100709679   0: 0.015313285848930   9: 0.015312058976402   3: 0.015311562512312   8: 0.015311411332794   2: 0.015311293259144   7: 0.015311086138877 

test_15094        5: 0.714586662394262   0: 0.136469651913783   8: 0.018644923798196   4: 0.018619102965809   6: 0.018614836615107   9: 0.018613870803166   1: 0.018613646572557   2: 0.018612738853532   7: 0.018612365843205   3: 0.018612200240383 

test_15095        6: 0.679697137704586   1: 0.217804527628817   8: 0.012813905164232   9: 0.012813266144412   5: 0.012813263120668   0: 0.012812816325889   4: 0.012811675632776   7: 0.012811227602204   2: 0.012811130011726   3: 0.012811050664689 

test_15096        8: 0.832278242204287   6: 0.018640133845235   0: 0.018636385051800   1: 0.018636103324970   7: 0.018635867389992   9: 0.018635111824028   5: 0.018635108229193   2: 0.018634401112872   4: 0.018634392355034   3: 0.018634254662587 

test_15097        7: 0.526251694852409   6: 0.302512130767970   3: 0.055155011206807   0: 0.016620744520350   5: 0.016591652807133   1: 0.016574946414541   8: 0.016574515873227   4: 0.016573426774781   9: 0.016573074500685   2: 0.016572802282097 

test_15103        6: 0.388727232210755   5: 0.304750874189795   0: 0.133516150677258   8: 0.080828356313223   1: 0.030829261730460   3: 0.012341817409153   9: 0.012252024746431   7: 0.012251953687229   4: 0.012251803563021   2: 0.012250525472676 

test_15104        5: 0.510205078556031   0: 0.288431846141039   4: 0.025178379381468   6: 0.025170981934499   7: 0.025169919423895   8: 0.025169135558727   3: 0.025168794722088   9: 0.025168673165365   2: 0.025168666237928   1: 0.025168524878960 

test_15106        0: 0.479459754290780   6: 0.416201637904247   1: 0.013384510400869   5: 0.012994630863224   7: 0.012994116837671   9: 0.012993895330690   4: 0.012993639318161   8: 0.012993417940270   2: 0.012992310934163   3: 0.012992086179924 

test_15107        5: 0.565174341212951   0: 0.208108109899329   2: 0.110287512989926   8: 0.016641836085388   6: 0.016636485336557   1: 0.016635878275298   9: 0.016629879389718   7: 0.016629026239020   4: 0.016628644256371   3: 0.016628286315443 

test_15109        5: 0.337899491359254   7: 0.287658076086417   9: 0.189248555570593   4: 0.026461744000940   1: 0.026461657310963   8: 0.026455039276152   3: 0.026454113202435   2: 0.026453995246298   0: 0.026453779687367   6: 0.026453548259582 

test_15110        6: 0.548013870219873   0: 0.362654744863607   1: 0.011178119458499   5: 0.011166692694661   9: 0.011165170699123   3: 0.011164707560284   8: 0.011164686586272   4: 0.011164438802109   2: 0.011164001577167   7: 0.011163567538405 

test_15111        3: 0.603356431943326   6: 0.212706393812129   4: 0.023002703824107   2: 0.023001019330295   1: 0.022998397773644   0: 0.022993082488589   5: 0.022990838604586   8: 0.022985757014670   9: 0.022982992746358   7: 0.022982382462296 

test_15112        6: 0.659113715783201   7: 0.183504434649257   8: 0.047216041929277   1: 0.015744055877388   9: 0.015742944235810   0: 0.015741508033818   5: 0.015736613228082   3: 0.015734278063185   2: 0.015733222363565   4: 0.015733185836417 

test_15118        3: 0.459900930735534   5: 0.341393585025941   7: 0.024838798649227   4: 0.024838735725044   6: 0.024838500606213   1: 0.024838122553062   0: 0.024838049009846   2: 0.024837834211187   8: 0.024837799235369   9: 0.024837644248578 

test_15119        9: 0.512022186694811   1: 0.275658373781823   0: 0.026544842462126   5: 0.026541947455790   6: 0.026541511600922   4: 0.026539241694774   2: 0.026538811257309   7: 0.026537767607978   3: 0.026537679630954   8: 0.026537637813514 

test_15120        3: 0.498756062432335   5: 0.300417942745270   1: 0.025116714580508   0: 0.025112468028308   6: 0.025102213077303   8: 0.025100130133256   2: 0.025098933592433   7: 0.025098820915992   9: 0.025098363207954   4: 0.025098351286640 

test_15121        7: 0.486533259266208   6: 0.372042936284751   4: 0.026139651650958   3: 0.016631175776057   0: 0.016495263898800   5: 0.016436902061947   1: 0.016433157996623   9: 0.016431489708371   8: 0.016428154365063   2: 0.016428008991223 

test_15122        1: 0.454058235865204   2: 0.352570638226424   0: 0.035738034522990   9: 0.022807366711212   5: 0.022553161466783   6: 0.022506375085946   7: 0.022460018182510   4: 0.022445486780896   3: 0.022430453837581   8: 0.022430229320454 

test_15124        0: 0.497884856620124   4: 0.259782429238014   6: 0.030295386440860   5: 0.030294796768494   1: 0.030294099837080   3: 0.030290655738690   9: 0.030289938360718   2: 0.030289837073219   8: 0.030289013410796   7: 0.030288986512003 

test_15126        5: 0.479747882208859   8: 0.204769413454285   9: 0.142953407248765   4: 0.024651677090172   6: 0.024649260822368   3: 0.024645939957667   2: 0.024645776993539   7: 0.024645689431060   1: 0.024645480285417   0: 0.024645472507867 

test_15128        0: 0.609392230177573   4: 0.115391000622623   1: 0.112056675234333   5: 0.052288805216785   7: 0.018501071396216   6: 0.018479812772255   9: 0.018473373467714   2: 0.018472557277817   8: 0.018472247674726   3: 0.018472226159957 

test_15129        6: 0.513491652075957   7: 0.296492733938437   5: 0.023756495906662   1: 0.023754179141257   4: 0.023753292354415   0: 0.023752224009461   8: 0.023751500487471   3: 0.023750521979706   2: 0.023749116764558   9: 0.023748283342076 

test_15130        5: 0.808868249401973   4: 0.021240926039826   8: 0.021240102797624   6: 0.021236197442127   9: 0.021235834411139   0: 0.021235811280319   3: 0.021235778965615   2: 0.021235743360749   7: 0.021235726828931   1: 0.021235629471697 

test_15132        6: 0.514473592452657   7: 0.324609793106201   5: 0.020116717425503   0: 0.020115440087343   9: 0.020114565973526   4: 0.020114502407902   1: 0.020114480210306   8: 0.020113907862016   3: 0.020113533438682   2: 0.020113467035864 

test_15136        5: 0.435189545526059   4: 0.407316447599625   6: 0.019692711089384   0: 0.019690697784479   1: 0.019690037133014   3: 0.019685283855487   7: 0.019684398347125   9: 0.019683669700177   2: 0.019683628893129   8: 0.019683580071522 

test_15138        8: 0.528437936919083   1: 0.282083175646904   5: 0.023693191174366   6: 0.023689168908384   0: 0.023686522174371   2: 0.023682789412435   4: 0.023681998526857   7: 0.023681829526683   9: 0.023681770654554   3: 0.023681617056363 

test_15141        5: 0.807293996904452   9: 0.021416787253737   6: 0.021415643403240   8: 0.021414367768706   0: 0.021411127687749   4: 0.021411094419585   1: 0.021411011900573   7: 0.021409272798725   2: 0.021408390013568   3: 0.021408307849665 

test_15144        5: 0.402328085644158   1: 0.370793821234836   9: 0.028370671297240   4: 0.028365424520304   8: 0.028358122844408   3: 0.028357123075959   2: 0.028356907817049   7: 0.028356835591379   0: 0.028356523036779   6: 0.028356484937889 

test_15145        5: 0.606422188416034   8: 0.158139062849327   1: 0.118976738955235   9: 0.016643533990478   6: 0.016640912789525   3: 0.016640850902055   4: 0.016636961653482   0: 0.016633956078227   2: 0.016632948034985   7: 0.016632846330652 

test_15146        0: 0.425462809577266   3: 0.374706312191676   5: 0.049728403822287   7: 0.039774259450447   8: 0.018396334702963   6: 0.018392471834715   1: 0.018389657057955   2: 0.018384745970060   9: 0.018383135234924   4: 0.018381870157705 

test_15149        5: 0.506321728581636   6: 0.245085915701826   0: 0.154425138011225   1: 0.028276968190780   8: 0.011696885916882   3: 0.010930067890431   4: 0.010816648685028   7: 0.010816462873958   2: 0.010815233437808   9: 0.010814950710426 

test_15152        5: 0.761893431512587   4: 0.026461853627589   0: 0.026455989068260   8: 0.026455693271128   3: 0.026455599705314   2: 0.026455539234343   1: 0.026455510702602   7: 0.026455499682672   9: 0.026455498259555   6: 0.026455384935949 

test_15153        5: 0.739594318894327   4: 0.028940257526341   0: 0.028933673365119   8: 0.028933225970094   3: 0.028933126217828   7: 0.028933118534289   2: 0.028933089182711   6: 0.028933084903675   1: 0.028933072405762   9: 0.028933032999854 

test_15154        6: 0.472501121083385   1: 0.446863172981171   8: 0.015142925841373   9: 0.009548517424144   4: 0.009370494472127   7: 0.009332790681978   5: 0.009315020556856   0: 0.009310724601973   3: 0.009307639306171   2: 0.009307593050823 

test_15156        3: 0.510874917126471   6: 0.260020361645903   1: 0.110312396813744   9: 0.017014328843228   8: 0.016975927807566   0: 0.016965854273939   5: 0.016962493571449   4: 0.016958892348555   2: 0.016957580330253   7: 0.016957247238891 

test_15157        5: 0.516402216426474   3: 0.290783700068755   1: 0.024106402136183   6: 0.024105227555953   4: 0.024101309187242   9: 0.024100475837584   2: 0.024100312687592   0: 0.024100268775131   7: 0.024100071609582   8: 0.024100015715504 

test_15161        0: 0.472143096241128   6: 0.363393520803130   5: 0.020560655375532   1: 0.020560609322842   9: 0.020558282784792   2: 0.020557081815204   8: 0.020556764389826   3: 0.020556757130575   4: 0.020556731189002   7: 0.020556500947969 

test_15162        4: 0.444178236731298   6: 0.428917406489459   5: 0.015866474906876   8: 0.015864688928499   0: 0.015864190918640   9: 0.015863235288532   1: 0.015862471207242   7: 0.015861567319593   2: 0.015860916647144   3: 0.015860811562718 

test_15171        6: 0.670857951926101   0: 0.186766669888918   2: 0.035333665625895   9: 0.015302672652010   4: 0.015293871964605   1: 0.015291550206436   5: 0.015291520387536   8: 0.015287384645392   3: 0.015287381199066   7: 0.015287331504042 

test_15172        6: 0.520694399626230   5: 0.209530186356070   2: 0.033746224501232   4: 0.033730907428794   0: 0.033717310710746   3: 0.033716801223886   9: 0.033716284787674   8: 0.033716223011990   7: 0.033716195148873   1: 0.033715467204505 

test_15175        2: 0.571714813252295   5: 0.217740013702238   4: 0.026326932815359   8: 0.026318264638747   3: 0.026317181712509   0: 0.026316694369907   9: 0.026316688912569   1: 0.026316636089091   7: 0.026316586860999   6: 0.026316187646287 

test_15179        6: 0.616716849986784   7: 0.237196664142692   0: 0.018577427730236   2: 0.018242448742955   1: 0.018238495590511   9: 0.018206823482303   8: 0.018206618042552   5: 0.018205805155447   3: 0.018205368709516   4: 0.018203498417005 

test_15180        5: 0.431893700142155   3: 0.264172953537925   0: 0.135733351517425   4: 0.024033472880075   6: 0.024030936640039   8: 0.024027704397367   9: 0.024027090523794   2: 0.024027057709378   7: 0.024026909231725   1: 0.024026823420115 

test_15185        5: 0.649430109265153   4: 0.038956340771889   3: 0.038952569434941   2: 0.038951742130853   8: 0.038951726309526   7: 0.038951623574258   9: 0.038951529479124   0: 0.038951507295806   1: 0.038951447090351   6: 0.038951404648099 

test_15188        4: 0.556650931271167   2: 0.237724383014335   5: 0.025712295679582   8: 0.025702142245970   9: 0.025702054242808   3: 0.025701853119565   0: 0.025701793416122   1: 0.025701531121403   7: 0.025701524063083   6: 0.025701491825966 

test_15189        5: 0.619252563511431   0: 0.254806630485588   9: 0.015813708152233   4: 0.015734962265170   6: 0.015732220633173   3: 0.015732094748658   8: 0.015732064900435   1: 0.015731968904142   2: 0.015731910661210   7: 0.015731875737959 

test_15190        5: 0.675221412911250   2: 0.130728333654991   6: 0.069830952250944   4: 0.017746493058318   0: 0.017746235660273   1: 0.017745890532945   9: 0.017745397975951   8: 0.017745182653728   3: 0.017745055361322   7: 0.017745045940279 

test_15193        5: 0.489399227171546   4: 0.323930757499907   0: 0.027067990792951   1: 0.023564244223934   6: 0.022820455767461   8: 0.022669807714519   2: 0.022642012567197   7: 0.022638664606041   3: 0.022634013490371   9: 0.022632826166073 

test_15194        6: 0.413896574783653   5: 0.388437746450874   1: 0.093193508204251   3: 0.033548079279172   0: 0.012272304672899   4: 0.011920221099958   9: 0.011872872404263   7: 0.011624361679578   8: 0.011618607998973   2: 0.011615723426379 

test_15197        5: 0.785479725379607   3: 0.023836092634160   4: 0.023835972533833   1: 0.023835642537574   6: 0.023835604882657   0: 0.023835555193572   2: 0.023835385849589   8: 0.023835372797019   7: 0.023835345078652   9: 0.023835303113338 

test_15198        6: 0.476155998410192   2: 0.281534737024934   8: 0.076981723871252   0: 0.074208764218552   1: 0.015197182716145   3: 0.015185013849697   9: 0.015184901187086   7: 0.015184459786337   5: 0.015184108539545   4: 0.015183110396259 

test_15200        0: 0.603974867009467   6: 0.299308565307179   1: 0.012091999959479   5: 0.012089596989861   9: 0.012089546347799   2: 0.012089414872779   8: 0.012089239058392   7: 0.012089019738641   3: 0.012088884444060   4: 0.012088866272343 

test_15204        5: 0.344212825351612   3: 0.325058505400450   6: 0.179359932930116   1: 0.021629590684953   0: 0.021626886600552   4: 0.021622911294500   7: 0.021622443715247   2: 0.021622394612361   8: 0.021622349140573   9: 0.021622160269634 

test_15205        5: 0.812176503686194   4: 0.020876608448870   3: 0.020869339637573   1: 0.020868611269106   0: 0.020868320568353   6: 0.020868212460838   9: 0.020868116777175   8: 0.020868103071457   2: 0.020868102598309   7: 0.020868081482126 

test_15206        6: 0.598194445271077   1: 0.271324529288440   5: 0.026892648587461   8: 0.021916015070813   0: 0.013616322150610   4: 0.013611365007982   9: 0.013611325810800   3: 0.013611219372933   7: 0.013611097139539   2: 0.013611032300345 

test_15207        0: 0.432364082068656   5: 0.354264036534661   4: 0.026674546458576   6: 0.026672644886912   8: 0.026671383259063   1: 0.026671228512204   9: 0.026671078415186   3: 0.026670556104442   2: 0.026670307674201   7: 0.026670136086098 

test_15208        5: 0.785857101641170   4: 0.023794069300902   3: 0.023793994237674   1: 0.023793709018603   6: 0.023793633381313   0: 0.023793630879112   8: 0.023793517319816   2: 0.023793486133035   7: 0.023793444298966   9: 0.023793413789409 

test_15210        2: 0.433339700401329   1: 0.324915113917858   9: 0.086198519413751   5: 0.022242146354542   4: 0.022230703342404   6: 0.022229965210945   0: 0.022216386485679   7: 0.022209287547840   8: 0.022209183533631   3: 0.022208993792020 

test_15211        5: 0.836624211639641   4: 0.018154390751094   6: 0.018153308664142   8: 0.018153100303034   9: 0.018152824714939   0: 0.018152664792940   1: 0.018152493473053   3: 0.018152455401085   7: 0.018152306085838   2: 0.018152244174234 

test_15212        6: 0.767858578658722   4: 0.073455708532530   5: 0.067593866164629   8: 0.013014922562200   1: 0.013013677916163   0: 0.013013599851783   9: 0.013013085475493   7: 0.013012193380438   2: 0.013012191258071   3: 0.013012176199973 

test_15213        7: 0.473706852650806   6: 0.374269317594035   1: 0.042277206215491   3: 0.024967089278899   8: 0.017060884169417   0: 0.014005136114975   5: 0.013517171396924   4: 0.013428008410875   2: 0.013412543787945   9: 0.013355790380632 

test_15217        8: 0.544278593212420   1: 0.264172092868158   6: 0.024061836001338   3: 0.023959592553135   9: 0.023946249362723   0: 0.023937217559212   5: 0.023931554629049   7: 0.023905464642777   4: 0.023903871844119   2: 0.023903527327070 

test_15219        6: 0.686123313357448   1: 0.191470362070286   3: 0.029883994088607   5: 0.013233449981586   7: 0.013217700129440   0: 0.013217428400996   8: 0.013215602650552   4: 0.013212742008447   2: 0.013212707558538   9: 0.013212699754099 

test_15220        6: 0.506522858209616   3: 0.323080643316109   5: 0.047337956760610   0: 0.017608821152698   1: 0.017590613406545   7: 0.017574435291073   4: 0.017572732094055   9: 0.017571646916298   8: 0.017570321999072   2: 0.017569970853925 

test_15221        4: 0.783820880651705   5: 0.024026706303566   8: 0.024019543899566   9: 0.024019162438728   0: 0.024019031089047   6: 0.024018993861068   3: 0.024018947710620   2: 0.024018931460860   7: 0.024018909023902   1: 0.024018893560939 

test_15222        6: 0.767736910823764   5: 0.025900462301997   4: 0.025852238178959   8: 0.025793776259769   1: 0.025792381849951   0: 0.025788109383344   3: 0.025785321720163   2: 0.025784929682858   9: 0.025783077220766   7: 0.025782792578428 

test_15223        6: 0.543740736048549   0: 0.195262424222574   5: 0.160302411127862   2: 0.014407098087097   9: 0.014386050111158   1: 0.014383242983212   4: 0.014381426992008   3: 0.014379113368347   8: 0.014378809883397   7: 0.014378687175796 

test_15226        5: 0.614923428266235   0: 0.144318487555541   6: 0.120388110674204   1: 0.017202342190983   8: 0.017195260084814   2: 0.017194921307260   7: 0.017194500237133   9: 0.017194494766037   4: 0.017194323211320   3: 0.017194131706474 

test_15227        6: 0.857417241392184   8: 0.042694515235584   5: 0.012512151352293   4: 0.012487654326462   0: 0.012482221982745   1: 0.012482211845416   3: 0.012481473623133   9: 0.012481267127669   2: 0.012480871481633   7: 0.012480391632881 

test_15230        8: 0.455014132539268   6: 0.414756320043783   0: 0.033412724963767   7: 0.021189768053259   1: 0.012623567216383   9: 0.012605355084605   5: 0.012600243260493   3: 0.012599822397568   2: 0.012599141412556   4: 0.012598925028318 

test_15233        5: 0.709737976011338   3: 0.141018056161850   4: 0.018659311465421   0: 0.018655946684568   6: 0.018655396293999   9: 0.018654759261922   8: 0.018654741858684   1: 0.018654734923382   2: 0.018654562395604   7: 0.018654514943232 

test_15234        6: 0.855179995287406   9: 0.016092957662045   0: 0.016091903346554   1: 0.016091382063684   5: 0.016091035657672   3: 0.016090768592060   8: 0.016090679565395   7: 0.016090448544910   4: 0.016090422760891   2: 0.016090406519385 

test_15237        6: 0.664217898223097   8: 0.133064662198115   1: 0.058908923157829   0: 0.034637769196636   5: 0.034335234449240   3: 0.015096108880720   4: 0.014936214603947   2: 0.014934853582246   7: 0.014934176706915   9: 0.014934159001255 

test_15238        6: 0.588881288533240   2: 0.294609566766272   9: 0.022999398987709   3: 0.021900292042236   1: 0.011970063335144   0: 0.011946642038662   5: 0.011929028043708   4: 0.011921854908428   8: 0.011921409346053   7: 0.011920455998548 

test_15239        1: 0.376383806982359   6: 0.239382235950489   0: 0.164945835284115   5: 0.110588972237833   2: 0.031700195883239   7: 0.027450458927008   9: 0.012398805577894   3: 0.012394198125413   8: 0.012378204169947   4: 0.012377286861703 

test_15240        0: 0.867700549744069   6: 0.015068589216081   7: 0.014697493203922   5: 0.014653288932249   4: 0.014648015118173   1: 0.014647213360749   9: 0.014646702916439   8: 0.014646294070232   3: 0.014646127382083   2: 0.014645726056004 

test_15242        8: 0.403819858792571   0: 0.368695124890088   6: 0.028442667633236   9: 0.028437512894520   5: 0.028434748598572   1: 0.028434250021272   7: 0.028434166510246   2: 0.028433900631491   4: 0.028433885344669   3: 0.028433884683333 

test_15243        5: 0.701981236562900   0: 0.033116954968367   4: 0.033116008641750   1: 0.033114451719561   6: 0.033113513253835   2: 0.033112335847026   8: 0.033111679379938   3: 0.033111380040906   7: 0.033111274545958   9: 0.033111165039760 

test_15244        8: 0.494534030744218   6: 0.343136646210403   2: 0.055801431585024   0: 0.015232061012805   5: 0.015224092335040   3: 0.015217515416125   1: 0.015215958547240   9: 0.015214736108170   7: 0.015211860075122   4: 0.015211667965854 

test_15246        0: 0.494578362410644   6: 0.413058192082929   1: 0.011547824599292   5: 0.011545836456873   8: 0.011545820800699   9: 0.011545129790186   2: 0.011544986728679   4: 0.011544869028067   7: 0.011544511535156   3: 0.011544466567475 

test_15247        5: 0.798863866589076   0: 0.022360179558088   4: 0.022348370020248   6: 0.022347523887149   1: 0.022347023146888   8: 0.022346761054031   9: 0.022346710406740   3: 0.022346573878742   2: 0.022346561302544   7: 0.022346430156493 

test_15250        4: 0.637493895642468   6: 0.238789662698452   9: 0.015542445532628   2: 0.015503007723906   5: 0.015450751153147   1: 0.015445824047205   0: 0.015445177513232   8: 0.015444024785179   7: 0.015442896369400   3: 0.015442314534383 

test_15253        6: 0.672973524305478   3: 0.186920651959819   0: 0.042893174247053   1: 0.028638789861240   5: 0.011446673855281   7: 0.011428445341795   8: 0.011425368278740   9: 0.011425070979247   2: 0.011424165600160   4: 0.011424135571187 

test_15254        6: 0.402437599121302   8: 0.276206340248755   0: 0.216870502521876   1: 0.054745886147520   3: 0.008330528822759   4: 0.008326652013670   5: 0.008285579891222   7: 0.008270205146158   9: 0.008264666198382   2: 0.008262039888357 

test_15255        1: 0.349794670843616   7: 0.295963866859485   6: 0.244478924845723   9: 0.024047425930477   0: 0.014584134691277   5: 0.014270183935669   8: 0.014222269004333   3: 0.014212998130369   4: 0.014212844505216   2: 0.014212681253836 

test_15258        5: 0.422577663517382   0: 0.381565251417730   6: 0.024484537916888   3: 0.024482768883471   4: 0.024482421831266   1: 0.024481626970161   8: 0.024481571180233   2: 0.024481495231558   7: 0.024481354889601   9: 0.024481308161707 

test_15259        4: 0.564069765464319   0: 0.206544777666294   5: 0.028680987652878   3: 0.028672557385261   8: 0.028672451725019   2: 0.028672417754752   9: 0.028672334406359   7: 0.028672192462558   1: 0.028671573022841   6: 0.028670942459719 

test_15262        6: 0.755146379956280   1: 0.027208396859524   9: 0.027206821807158   0: 0.027205954951564   5: 0.027205878816960   8: 0.027205490609783   2: 0.027205436598493   7: 0.027205316440836   3: 0.027205254167243   4: 0.027205069792159 

test_15263        0: 0.757119237829006   6: 0.137736246182140   2: 0.019483722742436   9: 0.012875355830494   1: 0.012141714996492   5: 0.012133889326203   4: 0.012130337711605   8: 0.012126842922451   7: 0.012126475636204   3: 0.012126176822969 

test_15264        6: 0.390137094867573   7: 0.215319144620369   0: 0.135638160361742   3: 0.097744311229409   4: 0.089673890551034   5: 0.014459484678072   1: 0.014355303535133   2: 0.014241136249280   8: 0.014216251095538   9: 0.014215222811851 

test_15265        0: 0.532418718933875   5: 0.213071677706361   4: 0.031826929793968   8: 0.031812756186216   2: 0.031812158433055   1: 0.031811910524396   3: 0.031811651042401   6: 0.031811624746154   7: 0.031811398149811   9: 0.031811174483764 

test_15270        7: 0.338193366674867   5: 0.304536816333660   9: 0.187781483726958   8: 0.040013436825933   1: 0.034206917719836   6: 0.019083484657978   0: 0.019059043188137   4: 0.019043081638059   2: 0.019041735458283   3: 0.019040633776291 

test_15271        6: 0.664045843456782   0: 0.156278595134010   5: 0.051498851922633   8: 0.018319678601222   2: 0.018310276839637   1: 0.018310135399788   4: 0.018309389258199   7: 0.018309130947447   3: 0.018309081492494   9: 0.018309016947787 

test_15273        6: 0.677868508894306   7: 0.148377053437737   5: 0.021721851087561   0: 0.021721087408684   9: 0.021720588082732   1: 0.021719973063834   8: 0.021718329856764   4: 0.021717849902547   2: 0.021717453041416   3: 0.021717305224419 

test_15274        6: 0.390448792516887   5: 0.322976053638210   8: 0.174810311280173   0: 0.015975328104071   1: 0.015969829584631   7: 0.015967195791427   4: 0.015965414472868   9: 0.015962739864532   2: 0.015962283438305   3: 0.015962051308896 

test_15276        1: 0.439250275847094   5: 0.405075558785296   6: 0.019493169850198   0: 0.019473968976511   4: 0.019454368685152   3: 0.019452484925762   9: 0.019450145318824   8: 0.019450087464645   2: 0.019450034240348   7: 0.019449905906172 

test_15278        5: 0.399753073104707   6: 0.387767883928691   1: 0.026563408642048   0: 0.026561172223033   4: 0.026559654188660   2: 0.026559388641557   3: 0.026559079689219   7: 0.026558884084308   9: 0.026558735521261   8: 0.026558719976517 

test_15280        5: 0.584342054646555   2: 0.262451085757939   1: 0.019152813779491   6: 0.019151564326376   9: 0.019151022287059   0: 0.019151004457564   8: 0.019150319130725   4: 0.019150160156978   3: 0.019150009079733   7: 0.019149966377580 

test_15281        6: 0.535594506100962   5: 0.308261625516752   1: 0.050780482410469   9: 0.015155971188984   0: 0.015038121213711   4: 0.015036328097287   8: 0.015033955293307   2: 0.015033676204041   7: 0.015032733333624   3: 0.015032600640862 

test_15283        5: 0.456453814312095   0: 0.354674214242841   6: 0.023611377613476   3: 0.023609470317172   4: 0.023609160618724   1: 0.023608528039316   8: 0.023608472141972   2: 0.023608413407728   7: 0.023608295045626   9: 0.023608254261051 

test_15287        6: 0.856776996464312   5: 0.015914450605880   0: 0.015914006218245   8: 0.015913995235904   9: 0.015913529410148   7: 0.015913528961651   1: 0.015913525409534   4: 0.015913411529266   2: 0.015913341130153   3: 0.015913215034907 

test_15290        6: 0.458566231222469   5: 0.325774834349508   0: 0.105945844831997   1: 0.015680942777841   3: 0.015675951588351   4: 0.015671834088371   7: 0.015671546315898   9: 0.015671036228156   8: 0.015670955058277   2: 0.015670823539133 

test_15292        6: 0.412118694224998   7: 0.246194405654011   4: 0.229579374339554   0: 0.016038709108527   1: 0.016020808239092   5: 0.016019846737436   9: 0.016011501582527   2: 0.016006325671482   8: 0.016005719578641   3: 0.016004614863732 

test_15294        1: 0.813957290100845   6: 0.020683610308747   0: 0.020672659897231   5: 0.020671554267423   9: 0.020670490369764   8: 0.020669491547866   7: 0.020669259528998   4: 0.020669047715703   2: 0.020668513965882   3: 0.020668082297542 

test_15295        5: 0.482266036839747   6: 0.167210186109841   0: 0.157495573701531   4: 0.027584991173010   8: 0.027574185736831   2: 0.027574024812503   7: 0.027573917033771   3: 0.027573888193670   9: 0.027573732755035   1: 0.027573463644060 

test_15296        6: 0.833015825193528   4: 0.018570103248239   5: 0.018564681367665   1: 0.018559678074205   0: 0.018552702694833   8: 0.018547822133738   9: 0.018547577554397   2: 0.018547447601094   7: 0.018547169810171   3: 0.018546992322130 

test_15299        5: 0.495173250430643   0: 0.327919625055219   3: 0.022113972993912   4: 0.022113899835689   7: 0.022113593966634   8: 0.022113441912910   1: 0.022113292121740   6: 0.022113187939341   2: 0.022112938074048   9: 0.022112797669864 

test_15300        5: 0.494238939805292   4: 0.314751276460224   3: 0.023877676811054   6: 0.023876125926744   7: 0.023876098606046   1: 0.023876079849348   0: 0.023876035485322   2: 0.023875969147459   8: 0.023875951801705   9: 0.023875846106806 

test_15302        4: 0.748360365120119   1: 0.027977702122092   5: 0.027968594860268   0: 0.027963221240024   6: 0.027961225174409   2: 0.027954343256023   9: 0.027953829064545   7: 0.027953804326928   8: 0.027953683893443   3: 0.027953230942150 

test_15303        6: 0.707117607795987   5: 0.122129327020196   7: 0.037044227781055   0: 0.036916066636856   8: 0.016134790820247   9: 0.016132163584786   1: 0.016131909741653   2: 0.016131852677208   3: 0.016131194269676   4: 0.016130859672337 

test_15306        4: 0.555059646602782   6: 0.296018910521043   1: 0.031094014704094   0: 0.016844197785151   5: 0.016835455836258   3: 0.016829635575488   7: 0.016829583317355   9: 0.016829579626599   2: 0.016829574670911   8: 0.016829401360319 

test_15307        4: 0.599860078753749   9: 0.161105466282949   2: 0.078680945935766   5: 0.022915592017319   0: 0.022906934217615   6: 0.022906839053249   1: 0.022906331681034   8: 0.022906063669147   3: 0.022905919553029   7: 0.022905828836142 

test_15308        4: 0.487301127280252   1: 0.389067673940027   6: 0.031263332869875   0: 0.013213842653618   8: 0.013202414001098   5: 0.013193596369605   2: 0.013190312982756   3: 0.013189649879885   9: 0.013189114986235   7: 0.013188935036649 

test_15309        5: 0.419088879104435   7: 0.228930154986418   6: 0.220206650506482   1: 0.018828661010390   0: 0.018828075043175   4: 0.018826814843558   9: 0.018823783650127   8: 0.018822597161725   2: 0.018822344930847   3: 0.018822038762843 

test_15310        6: 0.570149062224734   9: 0.278688575585203   8: 0.044665630566506   1: 0.026173795315142   3: 0.013457350927662   7: 0.013376770488176   0: 0.013376088447479   5: 0.013371817970453   4: 0.013370579858345   2: 0.013370328616300 

test_15311        8: 0.499214394889567   6: 0.223335181865695   0: 0.140651187392538   4: 0.019548692880434   1: 0.019543378754455   5: 0.019543166001364   9: 0.019541277001620   3: 0.019541028396223   2: 0.019541021501643   7: 0.019540671316461 

test_15312        0: 0.848509445133273   5: 0.016837078075256   4: 0.016835653540919   6: 0.016835093186709   1: 0.016833178769295   7: 0.016831207081986   2: 0.016829769791641   9: 0.016829706381516   8: 0.016829607934717   3: 0.016829260104687 

test_15313        6: 0.549143175595099   1: 0.337128683794339   9: 0.014268525928802   0: 0.014222003268974   7: 0.014207308223932   2: 0.014207180974760   5: 0.014206488932334   8: 0.014206410399497   4: 0.014205177889884   3: 0.014205044992379 

test_15314        2: 0.501463061959551   6: 0.363813873382546   8: 0.027581685739451   0: 0.015928410906116   1: 0.015218014333866   5: 0.015215613764279   4: 0.015198969842259   3: 0.015194011349533   9: 0.015193212575111   7: 0.015193146147287 

test_15315        8: 0.424511050527617   5: 0.381358054115297   2: 0.024281597955441   4: 0.024272176530791   0: 0.024263076217302   6: 0.024263033848191   3: 0.024262872486918   1: 0.024262815482334   9: 0.024262741145958   7: 0.024262581690150 

test_15321        5: 0.774531634334515   6: 0.025053948564233   4: 0.025053106914143   8: 0.025052586268643   9: 0.025051979277096   1: 0.025051414201845   0: 0.025051402516212   7: 0.025051391847181   2: 0.025051351813104   3: 0.025051184263028 

test_15322        6: 0.884955542457038   9: 0.012783583384247   5: 0.012783442745185   2: 0.012782998244017   0: 0.012782997877586   1: 0.012782565028110   8: 0.012782307092461   3: 0.012782252088606   4: 0.012782247292345   7: 0.012782063790405 

test_15324        6: 0.459800187793037   8: 0.142224771856681   5: 0.132372508438349   0: 0.107799153598846   1: 0.082441954117600   2: 0.015074873509577   4: 0.015072216720301   9: 0.015072025436974   7: 0.015071543562361   3: 0.015070764966274 

test_15325        1: 0.356031872822096   6: 0.262802866672656   5: 0.260022531244219   2: 0.026747852426218   4: 0.023009769113166   9: 0.014289030852735   0: 0.014276255245925   8: 0.014273956027083   7: 0.014272997146375   3: 0.014272868449529 

test_15326        5: 0.594775119057132   8: 0.256559028696714   4: 0.018585276723674   6: 0.018584296246982   0: 0.018583010931672   7: 0.018582943609599   9: 0.018582704035150   1: 0.018582664180526   2: 0.018582578294164   3: 0.018582378224386 

test_15327        4: 0.513109124743607   7: 0.274751071052872   5: 0.026526150929941   2: 0.026522698582081   9: 0.026517603372428   8: 0.026515507788407   3: 0.026514615017671   0: 0.026514471350205   1: 0.026514378830540   6: 0.026514378332247 

test_15329        6: 0.536683728425970   7: 0.231547119380561   8: 0.115754840776746   0: 0.016629557329651   4: 0.016588197294362   5: 0.016563444159581   1: 0.016559682182831   9: 0.016559145753079   3: 0.016557251221380   2: 0.016557033475839 

test_15335        1: 0.845490047393548   9: 0.017406106443725   5: 0.017148211282253   4: 0.017143007512645   0: 0.017140796705621   6: 0.017137004409576   3: 0.017133871345854   8: 0.017133848092928   2: 0.017133555908397   7: 0.017133550905453 

test_15336        5: 0.461996318858242   3: 0.293870645472033   4: 0.030524050480948   8: 0.030516876335355   9: 0.030515855791987   2: 0.030515482864077   7: 0.030515450601037   1: 0.030515122362077   6: 0.030515111203286   0: 0.030515086030960 

test_15337        3: 0.497897965312735   2: 0.183692848478336   6: 0.179920304685743   5: 0.019790431665084   0: 0.019789620278391   4: 0.019784971351712   1: 0.019783438701147   7: 0.019780890714692   8: 0.019780826181016   9: 0.019778702631143 

test_15339        2: 0.396912274646742   7: 0.365794608204186   5: 0.029666051084841   6: 0.029665339598551   9: 0.029662140844960   1: 0.029660950549255   0: 0.029660806302901   4: 0.029659807189327   8: 0.029659260522139   3: 0.029658761057098 

test_15341        6: 0.847516411766416   5: 0.016943952076507   0: 0.016943089825800   8: 0.016942753545223   4: 0.016942637744030   1: 0.016942584021663   9: 0.016942482186269   2: 0.016942140903848   7: 0.016942106797451   3: 0.016941841132791 

test_15344        6: 0.431140480376914   7: 0.426606304758643   2: 0.017788294128008   9: 0.017783954794784   5: 0.017783248507837   4: 0.017780390782527   0: 0.017780322586525   1: 0.017779757531548   8: 0.017779392455687   3: 0.017777854077527 

test_15345        1: 0.817065816224105   5: 0.020522100322110   9: 0.020404374315963   4: 0.020312827248289   0: 0.020299200590559   8: 0.020297354208098   6: 0.020281606126565   2: 0.020272517879386   7: 0.020272202199106   3: 0.020272000885818 

test_15348        5: 0.608971742570275   2: 0.218920397039738   6: 0.021516111697337   4: 0.021515016075171   1: 0.021513563681217   8: 0.021513372413784   9: 0.021512927238710   0: 0.021512755849002   7: 0.021512185289213   3: 0.021511928145553 

test_15349        6: 0.329680357049789   4: 0.297819751725056   1: 0.259031703574875   0: 0.017121645040204   9: 0.016412106256933   5: 0.016118563167494   2: 0.015968320576967   8: 0.015956961910399   7: 0.015945583272925   3: 0.015945007425357 

test_15351        6: 0.626725042118070   7: 0.228938671534480   2: 0.018048455756121   9: 0.018044752174325   5: 0.018042936835611   8: 0.018040795032055   4: 0.018040710391164   0: 0.018040101572806   1: 0.018039869682177   3: 0.018038664903189 

test_15352        6: 0.661489806461944   0: 0.246490743045159   2: 0.018593312568864   9: 0.015234370047502   1: 0.013783690968867   4: 0.008882816924593   5: 0.008882704765351   7: 0.008881133210584   8: 0.008880892559851   3: 0.008880529447286 

test_15354        5: 0.501888776396656   8: 0.320655365170526   2: 0.022194182498765   4: 0.022186947520363   0: 0.022179282300666   6: 0.022179210402324   9: 0.022179146300932   3: 0.022179083998872   1: 0.022179046261818   7: 0.022178959149078 

test_15356        5: 0.469246572359835   6: 0.264742801496968   2: 0.106236606764574   4: 0.022826616319850   8: 0.022825294652216   0: 0.022824966551671   9: 0.022824946042995   1: 0.022824279657034   7: 0.022824068511288   3: 0.022823847643569 

test_15357        6: 0.508009269865910   8: 0.359825483600869   1: 0.016532119511512   5: 0.016520780324941   7: 0.016520037735820   0: 0.016519468766726   9: 0.016518408660590   3: 0.016518280237831   4: 0.016518136328694   2: 0.016518014967109 

test_15359        5: 0.807692739911790   6: 0.021368254535739   4: 0.021367985829428   2: 0.021367899576525   8: 0.021367327095473   1: 0.021367309435677   0: 0.021367281761570   7: 0.021367251109806   9: 0.021367198872853   3: 0.021366751871139 

test_15363        6: 0.319793352007050   8: 0.281413652536159   1: 0.221999219813262   4: 0.101841582709331   7: 0.012760340209636   0: 0.012485195976477   2: 0.012476062837870   9: 0.012415886015650   5: 0.012408778866992   3: 0.012405929027574 

test_15364        6: 0.463860171291394   0: 0.458960977180658   5: 0.009648160765789   9: 0.009648005497610   1: 0.009647871558884   8: 0.009647315816042   7: 0.009647102915104   3: 0.009646803692552   4: 0.009646797585110   2: 0.009646793696857 

test_15365        7: 0.425886878450303   6: 0.359967283362348   0: 0.089082486267144   2: 0.017875747710904   8: 0.017868479863315   5: 0.017865304340013   9: 0.017864744407876   1: 0.017863603553905   4: 0.017862853265635   3: 0.017862618778558 

test_15366        6: 0.863491160623081   5: 0.015227752523179   4: 0.015207978613966   0: 0.015179620742851   1: 0.015172624425308   9: 0.015147510379182   7: 0.015145735437142   2: 0.015144157809560   3: 0.015143246851147   8: 0.015140212594583 

test_15367        6: 0.739930142822333   0: 0.126724217363107   5: 0.037189735428798   7: 0.013918184967172   9: 0.013798737164049   8: 0.013792850399391   3: 0.013679377960491   1: 0.013657898885225   2: 0.013654637990032   4: 0.013654217019402 

test_15368        6: 0.269120787533274   9: 0.213839304357865   0: 0.210094399227676   2: 0.190258778853931   8: 0.019458456071229   4: 0.019446980783494   7: 0.019446657808626   5: 0.019446495990198   1: 0.019446008583365   3: 0.019442130790342 

test_15372        6: 0.496887559678986   2: 0.218380049164740   1: 0.122713678782808   0: 0.067212548858075   5: 0.050663578511588   3: 0.008982823137995   8: 0.008833469719289   7: 0.008775619888452   4: 0.008775339391493   9: 0.008775332866574 

test_15375        6: 0.769508011150171   3: 0.087943090947718   0: 0.046500799932922   1: 0.033495476994093   2: 0.016284163131261   8: 0.009285250651299   5: 0.009247151638414   4: 0.009246555762017   7: 0.009244805553142   9: 0.009244694238963 

test_15378        6: 0.785046475725930   3: 0.063883265553540   1: 0.018887597797176   9: 0.018885449043694   8: 0.018884245836057   0: 0.018883690993125   7: 0.018882647686452   5: 0.018882452341024   2: 0.018882174302491   4: 0.018882000720510 

test_15379        8: 0.743211258171599   5: 0.028548743337624   3: 0.028539768865515   1: 0.028538856657618   9: 0.028534436410459   4: 0.028532199275233   0: 0.028531116383265   6: 0.028521713188290   7: 0.028521239925742   2: 0.028520667784655 

test_15380        5: 0.492582414422785   8: 0.368402264909599   6: 0.017395688472795   3: 0.017392015334403   9: 0.017375994239766   1: 0.017372976565434   0: 0.017371863488536   4: 0.017369699207612   7: 0.017368608091388   2: 0.017368475267681 

test_15383        8: 0.709517813666518   6: 0.032304746483089   9: 0.032295066691700   2: 0.032287977674079   4: 0.032274319365700   5: 0.032270086595468   3: 0.032265051246750   1: 0.032263052050155   7: 0.032261483637737   0: 0.032260402588804 

test_15384        0: 0.534653109120940   6: 0.382215799654261   5: 0.010392626166212   9: 0.010392271285192   8: 0.010391971368671   1: 0.010391239321240   3: 0.010390849131059   7: 0.010390796614324   4: 0.010390766732537   2: 0.010390570605565 

test_15386        6: 0.867409750239836   5: 0.014732921998486   0: 0.014732837296620   9: 0.014732405204289   1: 0.014732317104816   3: 0.014732068666441   7: 0.014731958809077   8: 0.014731955061475   4: 0.014731902399286   2: 0.014731883219674 

test_15387        3: 0.457494838729382   5: 0.377033133796262   1: 0.020840683756921   7: 0.020735850794632   9: 0.020669544539093   6: 0.020652452177829   8: 0.020649513571840   4: 0.020642078815456   0: 0.020640988418609   2: 0.020640915399977 

test_15388        8: 0.487864074898726   6: 0.372170615062097   0: 0.017498386527049   7: 0.017496098470592   9: 0.017495444055996   5: 0.017495425326306   1: 0.017495126415438   4: 0.017495078281497   2: 0.017494954263626   3: 0.017494796698673 

test_15389        6: 0.561720229123563   8: 0.279658548658827   3: 0.028740042882126   9: 0.028522187950125   0: 0.025642067398938   1: 0.015203580372847   5: 0.015132681938281   4: 0.015129503151148   2: 0.015126277854265   7: 0.015124880669879 

test_15391        5: 0.539638971717093   6: 0.251020335786476   1: 0.026202482937141   9: 0.026168009543058   8: 0.026162311282557   4: 0.026162130253594   7: 0.026161964693968   0: 0.026161384046321   2: 0.026161262991006   3: 0.026161146748786 

test_15394        6: 0.801775078325896   0: 0.076045111321006   1: 0.015280435856392   9: 0.015273094596222   5: 0.015272400872662   7: 0.015271597343021   2: 0.015271318413460   8: 0.015271118682463   4: 0.015269934099331   3: 0.015269910489546 

test_15396        0: 0.617686543662721   6: 0.259960552112942   8: 0.015296279556488   9: 0.015295784790036   5: 0.015295188832494   4: 0.015294281162078   1: 0.015293823528924   3: 0.015293807853109   2: 0.015292355801143   7: 0.015291382700065 

test_15397        1: 0.795923337144379   5: 0.022698295473736   4: 0.022683034092166   6: 0.022674839298135   0: 0.022674406060055   8: 0.022671744014997   3: 0.022669421934986   9: 0.022669235254038   2: 0.022667849671270   7: 0.022667837056238 

test_15400        6: 0.881111668741096   0: 0.013212063541755   1: 0.013210411028079   9: 0.013209589343914   5: 0.013209501431392   8: 0.013209438465636   7: 0.013209378345530   3: 0.013209373340182   2: 0.013209319729394   4: 0.013209256033022 

test_15404        0: 0.442120479358618   4: 0.396668326723411   6: 0.020163003796205   1: 0.020157416521367   5: 0.020150127094660   9: 0.020149256717140   3: 0.020148316475925   8: 0.020148178323752   2: 0.020147447666566   7: 0.020147447322355 

test_15406        6: 0.788846220254245   5: 0.023611852763643   4: 0.023472504770462   9: 0.023453111970775   3: 0.023442033593164   1: 0.023438927640787   0: 0.023436323484511   2: 0.023434749931917   8: 0.023433641886793   7: 0.023430633703702 

test_15409        5: 0.352832726830164   6: 0.349403355801793   0: 0.199574705714315   9: 0.014035108747507   7: 0.014034292693118   1: 0.014027517801580   2: 0.014024047617885   8: 0.014023131112275   4: 0.014022713406706   3: 0.014022400274658 

test_15410        6: 0.863540073932070   8: 0.015163389318849   0: 0.015162652881271   9: 0.015162357124648   5: 0.015162315373994   1: 0.015162268672440   7: 0.015161990214890   2: 0.015161674429173   4: 0.015161653660980   3: 0.015161624391685 

test_15411        6: 0.636233453836820   8: 0.193606071666269   2: 0.021279391487244   0: 0.021279073206893   1: 0.021274389820858   7: 0.021269797133279   5: 0.021267772985883   9: 0.021263644785809   4: 0.021263492896561   3: 0.021262912180383 

test_15413        0: 0.550389456442395   5: 0.209089990678771   6: 0.146602529777595   1: 0.013421334807745   2: 0.013417591531936   4: 0.013416456159672   9: 0.013415764651026   8: 0.013415723926079   3: 0.013415582402979   7: 0.013415569621802 

test_15415        6: 0.736489591199062   8: 0.111620215227102   2: 0.019002385019438   0: 0.019000286804723   7: 0.018988346898643   5: 0.018983179888055   1: 0.018979568516080   9: 0.018979400764286   4: 0.018978864185014   3: 0.018978161497600 

test_15416        6: 0.500489746873900   4: 0.317856689502366   5: 0.051350182770991   1: 0.030374171851779   7: 0.028824618275902   9: 0.014261276080671   3: 0.014213433970930   0: 0.014211982896629   8: 0.014209074416603   2: 0.014208823360228 

test_15417        6: 0.898117546229783   5: 0.018284302773132   7: 0.010955037201968   3: 0.010491425301680   1: 0.010385417854483   0: 0.010355552248757   4: 0.010354063488194   2: 0.010352524902983   9: 0.010352073866038   8: 0.010352056132981 

test_15420        5: 0.709827653776848   6: 0.118273122898084   9: 0.021488368060358   1: 0.021488094023549   0: 0.021487765845336   2: 0.021487649770639   8: 0.021487386793074   7: 0.021487129157029   3: 0.021486493429760   4: 0.021486336245322 

test_15421        9: 0.550532092732511   6: 0.268238968918353   0: 0.050607212125403   5: 0.018829272588926   1: 0.018670533203789   3: 0.018628857950302   7: 0.018624477778459   8: 0.018624372348140   2: 0.018622354039766   4: 0.018621858314351 

test_15424        6: 0.525341689013399   7: 0.345905847224846   1: 0.016132685888267   9: 0.016092120524345   0: 0.016091612187083   5: 0.016087729471449   2: 0.016087417759741   8: 0.016087408277191   4: 0.016086788409018   3: 0.016086701244661 

test_15425        2: 0.484098312093211   6: 0.325741717491930   1: 0.023795183470414   0: 0.023783181731838   5: 0.023767428313286   9: 0.023765016971086   8: 0.023764235531904   3: 0.023763617565976   4: 0.023761967677456   7: 0.023759339152899 

test_15427        3: 0.444697376735927   5: 0.332473244950552   8: 0.073501156726530   1: 0.021352939113881   0: 0.021344999527322   9: 0.021337238068852   6: 0.021326082500612   4: 0.021325858305850   7: 0.021320759679330   2: 0.021320344391144 

test_15428        6: 0.736491504988894   5: 0.029286419048272   9: 0.029280630026682   4: 0.029280202303792   8: 0.029277841738502   0: 0.029277383187040   7: 0.029277346148589   1: 0.029276593117428   2: 0.029276213748595   3: 0.029275865692206 

test_15429        9: 0.508647754773430   5: 0.286975045320518   0: 0.025582640056385   6: 0.025571538257052   4: 0.025539719647825   1: 0.025537943486139   8: 0.025536662670919   2: 0.025536318757080   7: 0.025536255226923   3: 0.025536121803727 

test_15430        6: 0.795146150112784   5: 0.022764811040353   9: 0.022763666272617   7: 0.022762239357565   4: 0.022761758739245   8: 0.022761067491091   0: 0.022760603637628   1: 0.022760133208291   2: 0.022759887239529   3: 0.022759682900896 

test_15431        6: 0.689401816636446   9: 0.129354784938315   0: 0.069763065292708   1: 0.015937624624674   8: 0.015924487750577   7: 0.015924118307922   5: 0.015923980791716   3: 0.015923650322673   4: 0.015923245635309   2: 0.015923225699659 

test_15432        6: 0.680524812276579   5: 0.172303078013082   3: 0.018422027803392   0: 0.018396297383827   1: 0.018394969845399   8: 0.018393258533975   7: 0.018391586703876   9: 0.018391441149426   2: 0.018391278159623   4: 0.018391250130822 

test_15436        8: 0.785055665446411   9: 0.023893546871997   6: 0.023885539570618   5: 0.023882684480484   0: 0.023881548991091   1: 0.023881262985509   4: 0.023880663597348   7: 0.023879751426156   3: 0.023879735866542   2: 0.023879600763843 

test_15438        6: 0.610897082660636   5: 0.252372234233368   9: 0.017103715386596   0: 0.017091200998038   1: 0.017090532096398   4: 0.017090113052982   3: 0.017088879538631   8: 0.017088813671743   7: 0.017088804027560   2: 0.017088624334049 

test_15441        9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

test_15442        6: 0.515084134262504   1: 0.407070079104915   0: 0.019400007367344   2: 0.008359458359617   7: 0.008357472806407   9: 0.008347541383767   4: 0.008346153980824   5: 0.008345742450971   3: 0.008344721402568   8: 0.008344688881084 

test_15444        6: 0.518342110152778   0: 0.390961345248558   8: 0.011339277152401   5: 0.011337751920946   9: 0.011337710092301   1: 0.011337012977718   3: 0.011336462622622   7: 0.011336381375328   2: 0.011336112326565   4: 0.011335836130784 

test_15446        6: 0.613412659719698   9: 0.193741631735354   7: 0.069739968488600   0: 0.017615854566873   5: 0.017596745122455   2: 0.017590369046636   3: 0.017584559766364   1: 0.017573550286840   4: 0.017572606004858   8: 0.017572055262321 

test_15447        6: 0.450792180923622   9: 0.239563374914225   1: 0.171128778316507   0: 0.069448335307724   8: 0.011513297501276   7: 0.011511674293485   5: 0.011511393001367   4: 0.011510380509843   3: 0.011510301834402   2: 0.011510283397549 

test_15448        6: 0.650637343971349   1: 0.201650657611859   8: 0.018467912870862   5: 0.018467687797639   0: 0.018466423628973   9: 0.018463664292803   7: 0.018461722272134   4: 0.018461533195749   2: 0.018461529618707   3: 0.018461524739925 

test_15449        1: 0.459527978511459   6: 0.410363062919614   0: 0.016281156481090   8: 0.016262757600818   9: 0.016261385721222   3: 0.016260935913826   7: 0.016260842033100   5: 0.016260700607667   4: 0.016260619776589   2: 0.016260560434614 

test_15450        6: 0.740065048889772   0: 0.115955751569912   1: 0.077621688966220   5: 0.009502881038254   8: 0.009493271857596   4: 0.009474390692372   3: 0.009473984040233   9: 0.009471047248552   7: 0.009471012434124   2: 0.009470923262965 

test_15451        6: 0.771568329691210   5: 0.110781505873376   9: 0.014715148932007   0: 0.014712416596248   4: 0.014706564921020   1: 0.014704638427949   8: 0.014703179398041   7: 0.014702944452316   2: 0.014702662611871   3: 0.014702609095961 

test_15452        6: 0.769509186178417   3: 0.087945893465187   0: 0.046495940350766   1: 0.033496545755382   2: 0.016283974997749   8: 0.009285252132829   5: 0.009247151608951   4: 0.009246555689963   7: 0.009244805580915   9: 0.009244694239841 

test_15453        6: 0.760127369344529   3: 0.129450175739452   0: 0.025367459361133   1: 0.018615505981657   9: 0.011079436560520   8: 0.011077441470537   7: 0.011075184128537   5: 0.011070754167571   2: 0.011068505423126   4: 0.011068167822937 

test_15454        6: 0.655124198791752   0: 0.265229798877583   5: 0.010140915334851   9: 0.010057101852786   1: 0.009935813223925   3: 0.009903732618598   8: 0.009902704355250   2: 0.009902434820821   7: 0.009902329079218   4: 0.009900971045216 

test_15455        6: 0.881111704936072   0: 0.013212028557860   1: 0.013210409856944   9: 0.013209589334046   5: 0.013209501423625   8: 0.013209438459299   7: 0.013209378340524   3: 0.013209373335284   2: 0.013209319725673   4: 0.013209256030673 

test_15457        5: 0.487085587270129   2: 0.315306266305796   3: 0.024701901596831   4: 0.024701412871238   6: 0.024701136695728   0: 0.024700917416426   1: 0.024700866008611   8: 0.024700831649592   7: 0.024700604997838   9: 0.024700475187810 

test_15459        0: 0.543767983511665   5: 0.290496972105966   4: 0.020721933223626   6: 0.020719286148489   1: 0.020717181046469   9: 0.020715538603510   8: 0.020715474049098   3: 0.020715437788078   2: 0.020715370102414   7: 0.020714823420684 

test_15460        6: 0.458914624452626   1: 0.451592304798873   0: 0.024184282205388   2: 0.009337839453718   7: 0.009337613074124   9: 0.009328545189395   4: 0.009327074406002   3: 0.009326255810004   8: 0.009326023781240   5: 0.009325436828629 

test_15462        6: 0.601153977947537   2: 0.202250345448719   0: 0.075259242554284   1: 0.017334319806707   8: 0.017334207370329   7: 0.017333755085978   9: 0.017333723460986   5: 0.017333598119526   3: 0.017333448952284   4: 0.017333381253651 

test_15464        6: 0.487818488770488   1: 0.312777531567032   0: 0.025201575263552   5: 0.024893086589524   2: 0.024889305257464   4: 0.024885867804915   8: 0.024883894658788   7: 0.024883529631572   3: 0.024883387064824   9: 0.024883333391842 

test_15467        6: 0.846432321816779   5: 0.017078496681179   4: 0.017064036784668   0: 0.017061807969738   1: 0.017061576384109   2: 0.017061354611148   8: 0.017060515590529   9: 0.017060445453103   3: 0.017059782343664   7: 0.017059662365083 

test_15468        6: 0.475107601607769   2: 0.350075929753745   5: 0.021859357184177   1: 0.021857154119553   4: 0.021853798546013   0: 0.021852739572349   9: 0.021849002159840   3: 0.021848821869479   8: 0.021848187258349   7: 0.021847407928726 

test_15471        1: 0.305998455167043   6: 0.285793543565342   5: 0.213802693472184   8: 0.089926368469197   0: 0.017417889383241   9: 0.017413682312203   4: 0.017412601459658   2: 0.017411853292060   7: 0.017411544479591   3: 0.017411368399481 

test_15472        6: 0.874897407198242   4: 0.013904307418916   5: 0.013903279831128   0: 0.013899794198997   9: 0.013899469254805   1: 0.013899446157858   8: 0.013899393119631   7: 0.013899057466697   2: 0.013898966692333   3: 0.013898878661392 

test_15476        5: 0.818865795597830   6: 0.020130152497940   4: 0.020126671775687   0: 0.020125874178123   1: 0.020125627448292   7: 0.020125331643194   9: 0.020125313573626   8: 0.020125174082320   2: 0.020125078506477   3: 0.020124980696512 

test_15477        4: 0.511550503013712   1: 0.300395042796951   5: 0.023516576586357   6: 0.023506275894696   8: 0.023505772770625   0: 0.023505466823251   2: 0.023505143194355   7: 0.023505121786361   3: 0.023505074123178   9: 0.023505023010512 

test_15478        0: 0.838840180559642   6: 0.017913656780375   9: 0.017913625589660   8: 0.017906926435473   5: 0.017906770970517   1: 0.017905587464477   4: 0.017904114238640   7: 0.017903838415601   3: 0.017903497559222   2: 0.017901801986393 

test_15479        5: 0.632974833456912   8: 0.216940000855765   7: 0.018781731552905   0: 0.018781532389611   6: 0.018761951650139   1: 0.018760843331988   9: 0.018750877819236   4: 0.018749827803558   3: 0.018749633298724   2: 0.018748767841163 

test_15481        1: 0.343791497420798   6: 0.314728351218160   5: 0.123318265811687   8: 0.113086829208965   0: 0.017517686469248   4: 0.017512433520697   9: 0.017512243538299   2: 0.017511194027355   7: 0.017510800088236   3: 0.017510698696556 

test_15482        4: 0.779244624568095   5: 0.024533212426219   8: 0.024528709544339   9: 0.024527766589532   3: 0.024527734596735   0: 0.024527682372289   2: 0.024527641321944   7: 0.024527571320394   1: 0.024527563151700   6: 0.024527494108754 

test_15483        6: 0.671966587570351   5: 0.178871550275833   3: 0.018670740254953   0: 0.018644953160675   1: 0.018643814944976   8: 0.018641925465475   7: 0.018640320756823   9: 0.018640135061456   2: 0.018639998459694   4: 0.018639974049765 

test_15484        6: 0.387311208466445   8: 0.337189457261692   0: 0.162277128394278   5: 0.016177708114919   3: 0.016175932852534   1: 0.016175597039680   4: 0.016174215977793   2: 0.016173124410704   9: 0.016172854184547   7: 0.016172773297408 

test_15485        6: 0.571865387603159   7: 0.289991577204047   5: 0.017284652149011   3: 0.017267292093152   1: 0.017266300227337   8: 0.017265887400908   4: 0.017265246744045   0: 0.017265054253062   9: 0.017264715843788   2: 0.017263886481491 

test_15487        5: 0.728587105839780   1: 0.030166855472843   0: 0.030161984472456   6: 0.030160432138761   7: 0.030155260996129   4: 0.030155256459142   8: 0.030154620211042   9: 0.030154414788860   2: 0.030152577087244   3: 0.030151492533743 

test_15489        5: 0.845021142490768   6: 0.017222143917954   9: 0.017220445268760   4: 0.017220056216003   8: 0.017219908032929   0: 0.017219825104770   1: 0.017219629269802   7: 0.017219204030507   2: 0.017218894903317   3: 0.017218750765190 

test_15494        5: 0.652372499255730   6: 0.194342181509356   1: 0.019162391142428   0: 0.019162078277829   8: 0.019161835262660   4: 0.019160274879531   3: 0.019159914262211   7: 0.019159819938873   9: 0.019159612366489   2: 0.019159393104893 

test_15495        5: 0.678756714810070   1: 0.120807574037861   4: 0.025057211031895   6: 0.025056134075882   3: 0.025054266416469   0: 0.025053906877957   8: 0.025053661492000   2: 0.025053547190216   9: 0.025053496354275   7: 0.025053487713375 

test_15496        5: 0.817698278217665   6: 0.020256464280697   9: 0.020256322994263   4: 0.020256064940646   0: 0.020255646790051   1: 0.020255611786051   7: 0.020255486183051   3: 0.020255480575628   8: 0.020255360403714   2: 0.020255283828232 

test_15500        6: 0.355729873329310   5: 0.329409614679207   7: 0.203071115014208   3: 0.015982876098837   8: 0.015970197470455   0: 0.015967922348144   9: 0.015967327840858   2: 0.015967225032764   1: 0.015967015248726   4: 0.015966832937491 

test_15501        5: 0.575712468592733   1: 0.236867086127222   8: 0.058376762547255   2: 0.018448071264074   0: 0.018442431545270   6: 0.018440942597865   3: 0.018428445649921   9: 0.018428337458248   7: 0.018427776460285   4: 0.018427677757128 

test_15503        6: 0.865721941830245   1: 0.014920723665567   0: 0.014920355161300   5: 0.014919772541196   9: 0.014919769200168   8: 0.014919544266406   7: 0.014919495897975   3: 0.014919490679935   2: 0.014919486556274   4: 0.014919420200934 

test_15504        6: 0.401146085629620   1: 0.367061149735742   0: 0.059903299084032   8: 0.052041537403290   5: 0.020016553878351   7: 0.019979734664974   3: 0.019964685611891   9: 0.019962987751344   2: 0.019962204841663   4: 0.019961761399092 

test_15510        9: 0.728857055052533   8: 0.100216170970847   6: 0.021379071590886   0: 0.021365834064994   5: 0.021364851449771   4: 0.021363699732564   7: 0.021363511477133   1: 0.021363485971699   3: 0.021363168581920   2: 0.021363151107653 

test_15511        1: 0.712140184963709   6: 0.177584455594679   7: 0.022874850959212   5: 0.012493720683799   4: 0.012492493462963   0: 0.012485525684608   8: 0.012482922527478   9: 0.012482096340674   2: 0.012481982050922   3: 0.012481767731955 

test_15515        5: 0.710089845808578   2: 0.122405678449633   6: 0.020940712198787   8: 0.020939900220264   4: 0.020939255950067   0: 0.020937548752873   9: 0.020937246173410   1: 0.020936870268211   7: 0.020936484591474   3: 0.020936457586702 

test_15520        6: 0.614834732947568   9: 0.190917625597149   1: 0.088013873583696   5: 0.015187179517026   4: 0.015180135345788   0: 0.015178036899751   7: 0.015175274240478   2: 0.015171533713660   3: 0.015170882493642   8: 0.015170725661241 

test_15521        4: 0.798765860795698   8: 0.022366334403894   6: 0.022366048834654   5: 0.022362793197166   9: 0.022361064751970   1: 0.022360793797238   0: 0.022360020055176   7: 0.022352927699233   2: 0.022352536075470   3: 0.022351620389500 

test_15522        6: 0.732471826130606   0: 0.029750719327436   8: 0.029731210638345   1: 0.029729126007553   5: 0.029720984690980   3: 0.029720251647546   7: 0.029719734590105   9: 0.029718722426562   2: 0.029718719433358   4: 0.029718705107510 

test_15523        9: 0.726494115564988   6: 0.120072473122680   8: 0.019197883005799   1: 0.019184508725945   0: 0.019176652357890   5: 0.019176362560491   4: 0.019175015174581   7: 0.019174431667900   2: 0.019174389537230   3: 0.019174168282496 

test_15527        6: 0.684381051276354   7: 0.156660785397614   0: 0.019870953968243   1: 0.019870885619937   8: 0.019869797455729   9: 0.019869784629486   5: 0.019869766960017   4: 0.019869069085586   2: 0.019868960256580   3: 0.019868945350453 

test_15528        5: 0.788245197792865   0: 0.023543086771325   1: 0.023534351922259   6: 0.023529738312610   3: 0.023525564865551   7: 0.023525392367792   2: 0.023524363948751   8: 0.023524273726258   9: 0.023524049905931   4: 0.023523980386658 

test_15531        6: 0.520312214060119   2: 0.375066805979003   8: 0.025281828023127   1: 0.011451377343788   0: 0.011383321028607   7: 0.011315258334967   9: 0.011307768808558   5: 0.011302669513424   4: 0.011299835988159   3: 0.011278920920247 

test_15532        0: 0.795045759100092   6: 0.022779762181462   8: 0.022772714832099   5: 0.022772714362649   1: 0.022772441424836   9: 0.022771929593903   7: 0.022771604050197   4: 0.022771252167416   2: 0.022771102635530   3: 0.022770719651816 

test_15535        8: 0.408351447350987   5: 0.293638244562966   4: 0.037263209050219   3: 0.037255713649976   2: 0.037249308924165   1: 0.037248979499310   0: 0.037248797784385   7: 0.037248440173373   9: 0.037248184172299   6: 0.037247674832320 

test_15536        0: 0.579746840990964   6: 0.187446234675730   4: 0.118055246482727   7: 0.016419819207645   8: 0.016391940608146   5: 0.016390740320290   3: 0.016389041196484   9: 0.016387509314067   2: 0.016386347388217   1: 0.016386279815731 

test_15539        6: 0.697559027579718   0: 0.184673747588444   3: 0.027513358677309   4: 0.021835047789828   7: 0.011409154052163   8: 0.011404395902831   1: 0.011402225665389   5: 0.011401420437198   9: 0.011400920045083   2: 0.011400702262038 

test_15540        6: 0.817063668884053   4: 0.020347774788077   8: 0.020336444493748   5: 0.020336052605348   3: 0.020320764214063   0: 0.020319438524597   2: 0.020319097919166   9: 0.020318935094550   1: 0.020318929097852   7: 0.020318894378545 

test_15542        0: 0.774909773694898   5: 0.025049800811552   7: 0.025005852648780   2: 0.025005437406212   3: 0.025005383431731   9: 0.025005171858449   8: 0.025004952212991   1: 0.025004852323139   4: 0.025004789677857   6: 0.025003985934390 

test_15543        7: 0.444136157972832   6: 0.415342167920115   1: 0.029957823633913   0: 0.015839642369881   5: 0.015790938279122   9: 0.015787906508867   8: 0.015787858538531   3: 0.015786980009784   4: 0.015785362184691   2: 0.015785162582263 

test_15544        0: 0.766668961006504   1: 0.025932829904458   5: 0.025925346274385   6: 0.025925327062120   4: 0.025925313913117   2: 0.025924813132277   9: 0.025924642000223   8: 0.025924625629877   3: 0.025924180068205   7: 0.025923961008834 

test_15545        0: 0.583551094190153   6: 0.258390359416919   9: 0.019787455662685   1: 0.019754383211584   7: 0.019753719789204   5: 0.019753579998818   3: 0.019752581607537   2: 0.019752524554221   8: 0.019752317615298   4: 0.019751983953581 

test_15547        0: 0.498990002208117   5: 0.347709406409649   1: 0.019165940465037   6: 0.019165887704147   4: 0.019162145255829   7: 0.019161968898779   8: 0.019161613676250   3: 0.019161380118715   9: 0.019161100528366   2: 0.019160554735110 

test_15548        3: 0.399976122126240   5: 0.378763921483104   8: 0.027670141410762   4: 0.027663079354441   2: 0.027654653019118   0: 0.027654587893857   1: 0.027654510192299   9: 0.027654444739542   7: 0.027654407841812   6: 0.027654131938825 

test_15549        6: 0.912365779035744   0: 0.033045155284712   3: 0.006827627060364   5: 0.006825073943116   1: 0.006824436832603   4: 0.006823284042650   7: 0.006822382607750   8: 0.006822150810852   2: 0.006822103619733   9: 0.006822006762476 

test_15550        6: 0.654295530889642   7: 0.098316692760966   0: 0.092728289905283   3: 0.052999574311568   5: 0.016947917369214   1: 0.016944364576356   8: 0.016943786504980   9: 0.016942852727776   4: 0.016940515962459   2: 0.016940474991757 

test_15551        6: 0.744642835535782   0: 0.139343478385691   1: 0.048139395934010   8: 0.009908284452682   3: 0.009670177991956   4: 0.009660111836124   9: 0.009659117549399   5: 0.009658914601353   2: 0.009658903943198   7: 0.009658779769805 

test_15552        6: 0.619641313918681   5: 0.182691858474719   0: 0.097095332219617   1: 0.025776889891901   3: 0.012513031654875   7: 0.012456878967382   9: 0.012456616658992   8: 0.012456246433578   2: 0.012455939218646   4: 0.012455892561610 

test_15553        5: 0.685671849351912   3: 0.098380640241479   7: 0.027008855525181   6: 0.026996958648943   1: 0.026990661319806   2: 0.026990632691246   0: 0.026990258932821   8: 0.026990124348388   9: 0.026990095712409   4: 0.026989923227816 

test_15556        6: 0.508958153742237   9: 0.201734737255563   0: 0.158823850583988   1: 0.049964952899850   8: 0.035952016629855   7: 0.011447550827254   5: 0.008371337962879   2: 0.008336641218576   3: 0.008227651152120   4: 0.008183107727679 

test_15558        5: 0.444770283639596   0: 0.411908128132650   4: 0.017917412343243   6: 0.017917411935843   1: 0.017915676562982   9: 0.017915089020051   8: 0.017914343052999   3: 0.017913928810778   7: 0.017913899533524   2: 0.017913826968334 

test_15559        5: 0.786909821597398   6: 0.023683865316052   4: 0.023676648211839   7: 0.023676240542768   0: 0.023676201483969   9: 0.023676030928867   1: 0.023675635323821   8: 0.023675391126103   2: 0.023675110689265   3: 0.023675054779917 

test_15560        9: 0.763599362595399   5: 0.026272704088669   6: 0.026272371997572   8: 0.026270396970759   0: 0.026267770256588   1: 0.026265402753516   4: 0.026264283168855   2: 0.026263687156303   7: 0.026262699160928   3: 0.026261321851412 

test_15561        3: 0.577911495395555   5: 0.231103576459783   1: 0.023881394852202   6: 0.023879091112398   0: 0.023877152283748   8: 0.023870237571309   4: 0.023869785029932   2: 0.023869401843913   9: 0.023869033198544   7: 0.023868832252615 

test_15562        6: 0.800983976789628   0: 0.074445689166212   1: 0.015578571238516   3: 0.015577524864955   8: 0.015571474026337   5: 0.015569559669071   4: 0.015568643424745   7: 0.015568339109145   9: 0.015568134803193   2: 0.015568086908198 

test_15563        5: 0.680219622084819   6: 0.154684617607192   7: 0.020667793108323   0: 0.020637240513970   1: 0.020634536794976   2: 0.020633468656859   9: 0.020632289366925   3: 0.020631626014795   8: 0.020629476985906   4: 0.020629328866234 

test_15565        0: 0.760315181393616   1: 0.097723141406350   6: 0.018076507838123   3: 0.017825075099014   7: 0.017712259049578   2: 0.017681144635480   5: 0.017676427083437   4: 0.017670948055013   8: 0.017659922697515   9: 0.017659392741874 

test_15566        7: 0.422969928869694   5: 0.323567173186760   4: 0.031691553583346   0: 0.031682813010258   3: 0.031681810448304   8: 0.031681611833891   2: 0.031681566412674   1: 0.031681256944860   9: 0.031681231140647   6: 0.031681054569566 

test_15567        0: 0.496501096497093   6: 0.411756313050733   7: 0.011473929147497   5: 0.011467791246570   8: 0.011467601259513   4: 0.011466840817241   1: 0.011466734256587   9: 0.011466722490373   2: 0.011466572079877   3: 0.011466399154517 

test_15568        5: 0.475892136383145   6: 0.327537652771856   0: 0.024573604305361   1: 0.024573459241931   8: 0.024573240788790   9: 0.024570525822385   2: 0.024570258046436   7: 0.024570166296110   3: 0.024569521435008   4: 0.024569434908977 

test_15569        2: 0.284604285633975   1: 0.258155231018271   5: 0.199387079794385   6: 0.183699931267618   0: 0.012362537297417   7: 0.012358319413084   4: 0.012358200871426   3: 0.012358188302870   9: 0.012358151854753   8: 0.012358074546202 

test_15570        4: 0.751204486413468   7: 0.027676662947383   5: 0.027647981988253   6: 0.027639858877420   0: 0.027639630012415   9: 0.027639004876023   8: 0.027638960272222   1: 0.027637842792959   2: 0.027637799732627   3: 0.027637772087229 

test_15571        1: 0.470890539413840   3: 0.375160917562104   0: 0.031549554740151   5: 0.018039153131961   2: 0.017613534292160   6: 0.017359912662687   4: 0.017347287882342   9: 0.017346943412931   8: 0.017346563741677   7: 0.017345593160148 

test_15572        6: 0.689377396929506   0: 0.132617494563582   5: 0.022252580831482   2: 0.022252279256936   1: 0.022250520614411   7: 0.022250503333929   8: 0.022250291536493   4: 0.022249995250880   9: 0.022249635347065   3: 0.022249302335716 

test_15573        6: 0.848616525214821   5: 0.016823277255177   4: 0.016821014834246   8: 0.016820866381157   0: 0.016820439032613   9: 0.016819966702101   1: 0.016819902445814   7: 0.016819695071789   2: 0.016819257293349   3: 0.016819055768933 

test_15574        6: 0.699870845313664   3: 0.084997867785128   7: 0.071034200447406   5: 0.045083390009854   0: 0.016504836600414   9: 0.016502073987598   4: 0.016501802583413   8: 0.016501694832606   2: 0.016501655268205   1: 0.016501633171713 

test_15575        9: 0.571017770801587   6: 0.271423792092641   5: 0.019701302136082   4: 0.019696828658050   1: 0.019696457310441   0: 0.019695408856507   2: 0.019692948123803   3: 0.019692720230700   7: 0.019691483099345   8: 0.019691288690843 

test_15578        9: 0.785119121206748   6: 0.023939425446919   5: 0.023877980342925   4: 0.023871767646779   1: 0.023869555819487   8: 0.023869422200318   2: 0.023865449212041   0: 0.023864445580153   7: 0.023861894142804   3: 0.023860938401827 

test_15579        9: 0.798079285386887   5: 0.022441218938582   8: 0.022440001142881   6: 0.022438402837808   0: 0.022435225315032   4: 0.022434901930277   7: 0.022433207603858   1: 0.022433077201323   2: 0.022432858601759   3: 0.022431821041594 

test_15580        9: 0.315637981382584   7: 0.266838174732263   6: 0.175770261197689   0: 0.137501795382120   3: 0.017379181971908   8: 0.017377997195164   1: 0.017373922809911   5: 0.017373623163798   4: 0.017373560967133   2: 0.017373501197430 

test_15581        0: 0.721683249630809   6: 0.149628067554108   1: 0.022377329328673   5: 0.015195705124144   4: 0.015188644539700   8: 0.015186080457491   3: 0.015185573575093   9: 0.015185245399746   2: 0.015185162431616   7: 0.015184941958618 

test_15582        6: 0.503367916599260   7: 0.343121033706015   0: 0.019228960455566   5: 0.019187437056603   1: 0.019184016770931   8: 0.019183189340520   3: 0.019182883198194   2: 0.019181627838087   4: 0.019181507832605   9: 0.019181427202218 

test_15583        0: 0.709372560447482   5: 0.032307036818360   6: 0.032298760624384   8: 0.032289632940079   7: 0.032289277850752   9: 0.032289270125076   4: 0.032288675002483   1: 0.032288635198963   3: 0.032288437429675   2: 0.032287713562746 

test_15584        6: 0.533199445214822   8: 0.291035989333943   7: 0.040611636895524   5: 0.038426762692699   1: 0.016121958809641   0: 0.016121926495151   2: 0.016121337813596   9: 0.016120519852237   4: 0.016120267986633   3: 0.016120154905752 

test_15585        1: 0.645257694458783   5: 0.179620495038307   8: 0.044962169132693   0: 0.018595499199882   6: 0.018595277793226   9: 0.018594134465218   3: 0.018593714900056   4: 0.018593711728344   2: 0.018593682817938   7: 0.018593620465553 

test_15590        4: 0.650732670238481   0: 0.169793598410968   5: 0.022441638081232   6: 0.022436483370913   8: 0.022433106707981   7: 0.022432831786318   9: 0.022432798592233   1: 0.022432624761144   2: 0.022432263690645   3: 0.022431984360085 

test_15591        4: 0.551668524404037   6: 0.239859668598949   0: 0.046875929537300   5: 0.023144470573759   1: 0.023083743308098   2: 0.023075790829108   9: 0.023074384854833   8: 0.023073115907989   3: 0.023072927880056   7: 0.023071444105871 

test_15593        5: 0.469951599212166   1: 0.387076576839424   2: 0.017916055496664   6: 0.017866328969302   0: 0.017865979534480   4: 0.017865299648666   9: 0.017864769938189   3: 0.017864569783966   8: 0.017864465121189   7: 0.017864355455954 

test_15594        5: 0.544167197152997   8: 0.261746929214453   4: 0.024265872106804   2: 0.024263083610456   9: 0.024259722693395   3: 0.024259569847033   7: 0.024259511857358   6: 0.024259411338823   0: 0.024259390793738   1: 0.024259311384943 

test_15595        7: 0.621577430480251   6: 0.153273731355346   1: 0.069134851810420   5: 0.022291512784842   0: 0.022290624932558   4: 0.022289849164729   8: 0.022285859986057   3: 0.022285642615572   2: 0.022285410038722   9: 0.022285086831503 

test_15596        6: 0.444703091786974   2: 0.386876941425942   0: 0.021117110835795   5: 0.021055678767876   1: 0.021048952116890   4: 0.021044685689297   9: 0.021038645266873   7: 0.021038521510849   3: 0.021038382233586   8: 0.021037990365918 

test_15597        5: 0.563068911342500   1: 0.290597146617287   8: 0.018293910081698   0: 0.018292138500487   6: 0.018291662705640   4: 0.018291528703324   3: 0.018291221226034   9: 0.018291199010651   2: 0.018291152197646   7: 0.018291129614734 

test_15598        5: 0.321273826342179   0: 0.280422712277443   7: 0.243826092830066   6: 0.022074578555110   4: 0.022070265104432   9: 0.022070005299146   1: 0.022066512641260   8: 0.022065608648504   2: 0.022065483075573   3: 0.022064915226287 

test_15600        1: 0.779577776815926   2: 0.059277799227349   6: 0.020149388046248   5: 0.020147218505311   9: 0.020146581595641   0: 0.020141908788288   7: 0.020140998906293   4: 0.020140141678222   8: 0.020139252099937   3: 0.020138934336784 

test_15601        5: 0.679421577347640   1: 0.149533170195407   6: 0.021382878590498   4: 0.021381992502699   0: 0.021381405166703   2: 0.021380080231250   7: 0.021379855142786   3: 0.021379769023029   8: 0.021379670932266   9: 0.021379600867722 

test_15602        6: 0.819645290579144   5: 0.050499463322955   8: 0.035132634627482   0: 0.013537328857550   1: 0.013532583532912   4: 0.013531060262307   9: 0.013530622440722   2: 0.013530611894507   7: 0.013530259222280   3: 0.013530145260141 

test_15603        6: 0.741834974886040   9: 0.028687565338058   0: 0.028685837282299   8: 0.028685162278648   1: 0.028685058193310   5: 0.028684714856587   3: 0.028684341361587   2: 0.028684305301893   7: 0.028684098982494   4: 0.028683941519084 

test_15605        0: 0.800206908989943   5: 0.022670843895326   6: 0.022240439566224   1: 0.022133518824202   8: 0.022128352376702   4: 0.022125344606375   9: 0.022123859719511   7: 0.022123822585659   2: 0.022123786604499   3: 0.022123122831559 

test_15607        2: 0.527262117327715   6: 0.323276991751044   8: 0.018688944899963   5: 0.018684101036025   9: 0.018683941906647   1: 0.018682545597290   0: 0.018682330614620   7: 0.018680001447681   4: 0.018679852869270   3: 0.018679172549746 

test_15610        9: 0.763599044112126   5: 0.026272705580939   6: 0.026272685443592   8: 0.026270398152153   0: 0.026267771081758   1: 0.026265403282444   4: 0.026264283569425   2: 0.026263687485476   7: 0.026262699377333   3: 0.026261321914754 

test_15613        6: 0.384533297012790   5: 0.370989215486014   4: 0.030567236843516   2: 0.030561971053584   9: 0.030560205763301   0: 0.030558274496137   1: 0.030557996476822   3: 0.030557476827529   7: 0.030557188890478   8: 0.030557137149830 

test_15615        8: 0.564195140848722   6: 0.240510634253869   9: 0.061568558982553   3: 0.044543787042264   0: 0.014866322505859   5: 0.014865765569614   1: 0.014864549754222   7: 0.014862021413950   2: 0.014861622681130   4: 0.014861596947817 

test_15616        2: 0.532802118474088   0: 0.314360515512034   1: 0.019118374197914   5: 0.019111085352372   6: 0.019105409102965   4: 0.019101679591381   8: 0.019100704718820   7: 0.019100517532518   3: 0.019099892159371   9: 0.019099703358537 

test_15617        6: 0.766460871946922   0: 0.111784618226463   5: 0.046936258454931   1: 0.010696161613440   3: 0.010692370259780   2: 0.010686352525221   8: 0.010686318632882   9: 0.010685890253570   7: 0.010685774566908   4: 0.010685383519883 

test_15618        6: 0.813212139281945   8: 0.020759246862407   1: 0.020754313069711   7: 0.020753966356419   0: 0.020753957404586   9: 0.020753693338979   5: 0.020753214111252   2: 0.020753208231968   4: 0.020753168684000   3: 0.020753092658731 

test_15620        6: 0.445681926516881   8: 0.389600315360868   0: 0.079086683259711   1: 0.012594827339680   7: 0.012379296624018   3: 0.012358949386920   5: 0.012075621497947   9: 0.012074678380040   2: 0.012074067381393   4: 0.012073634252541 

test_15621        6: 0.578329812153705   3: 0.207719269909394   1: 0.100736399676575   0: 0.016174945342658   5: 0.016174222720236   8: 0.016173837840496   9: 0.016173269568751   7: 0.016172846523595   4: 0.016172727417274   2: 0.016172668847317 

test_15623        4: 0.556374189018346   6: 0.256911795520244   1: 0.023341276611369   0: 0.023340440013173   9: 0.023340056517505   5: 0.023339974516211   8: 0.023339053775381   2: 0.023338711168036   7: 0.023337457878951   3: 0.023337044980784 

test_15624        6: 0.648901540547175   0: 0.128218806163925   7: 0.109533777429734   1: 0.034187485139791   9: 0.013195787595254   8: 0.013194644066967   5: 0.013193409070139   3: 0.013191776057679   2: 0.013191725831621   4: 0.013191048097716 

test_15625        6: 0.612622229750190   8: 0.178670420321189   0: 0.109738308783273   1: 0.038120168762108   3: 0.016179045518966   9: 0.008934255131634   5: 0.008934142680161   7: 0.008933951422525   2: 0.008933818280680   4: 0.008933659349275 

test_15626        5: 0.739910130007603   6: 0.028901754256640   1: 0.028900469934498   4: 0.028900367569983   7: 0.028898772597867   8: 0.028897780670611   9: 0.028897732060338   0: 0.028897683276978   2: 0.028897666353214   3: 0.028897643272268 

test_15629        0: 0.814769424036916   6: 0.020586792025081   1: 0.020583157626618   5: 0.020582740796872   4: 0.020580400016372   7: 0.020579930303419   2: 0.020579534509108   3: 0.020579457367420   9: 0.020579339047980   8: 0.020579224270212 

test_15632        5: 0.590675458130793   9: 0.238115341376922   4: 0.021403525203142   3: 0.021401200240665   8: 0.021401138058890   1: 0.021400820390562   0: 0.021400703337114   2: 0.021400686327519   7: 0.021400585967624   6: 0.021400540966768 

test_15634        5: 0.701192314424023   2: 0.033202822694620   3: 0.033201685806009   1: 0.033200916035936   6: 0.033200768389753   4: 0.033200593665845   0: 0.033200544230079   9: 0.033200316569593   7: 0.033200198298710   8: 0.033199839885432 

test_15636        6: 0.560139220093435   0: 0.228636208863422   1: 0.065440335375971   3: 0.020833349033788   7: 0.020832398680330   9: 0.020827871560665   8: 0.020823035515981   5: 0.020823031007481   2: 0.020822277816687   4: 0.020822272052240 

test_15637        5: 0.788410824179892   3: 0.023510195129707   7: 0.023510105707257   0: 0.023510057173135   2: 0.023509961501103   6: 0.023509930762604   8: 0.023509871839451   4: 0.023509801136609   1: 0.023509651207816   9: 0.023509601362426 

test_15639        6: 0.334052444809516   4: 0.285844915177520   0: 0.181914753493787   1: 0.124284506976759   2: 0.017043322047419   9: 0.012470821689846   5: 0.011098012223057   3: 0.011097296202976   8: 0.011097167557429   7: 0.011096759821690 

test_15640        3: 0.403824957967237   5: 0.396564704539173   4: 0.024956720778714   1: 0.024952582577152   8: 0.024950919136910   9: 0.024950330458218   2: 0.024950198939326   7: 0.024950071682525   0: 0.024949829095320   6: 0.024949684825424 

test_15641        5: 0.283450793881006   6: 0.276548755134284   7: 0.230976579063078   9: 0.059630963808547   1: 0.040759218345592   0: 0.037117295555339   4: 0.017885365259146   3: 0.017880193294933   8: 0.017876520037048   2: 0.017874315621028 

test_15642        4: 0.412275005729512   6: 0.314386280654504   0: 0.130116855190299   5: 0.041028137024574   2: 0.017047712199186   9: 0.017031145657308   8: 0.017029215379631   1: 0.017028733982616   7: 0.017028693662795   3: 0.017028220519574 

test_15643        6: 0.750895086508335   2: 0.096042829893833   1: 0.051151959523360   0: 0.014562862056555   8: 0.014559210227739   5: 0.014557814910555   7: 0.014557722404370   9: 0.014557621657684   4: 0.014557533989250   3: 0.014557358828319 

test_15646        0: 0.754396788507119   6: 0.027299175215132   1: 0.027289033210935   5: 0.027288982636335   9: 0.027288911142220   7: 0.027288589560660   8: 0.027287687517893   2: 0.027287235736959   4: 0.027287097466617   3: 0.027286499006131 

test_15648        6: 0.758176308182308   7: 0.026869610712048   1: 0.026869379264848   8: 0.026869374653107   0: 0.026869348791586   9: 0.026869260550722   3: 0.026869187030612   2: 0.026869183607226   5: 0.026869182512676   4: 0.026869164694866 

test_15649        6: 0.770772731861209   7: 0.025469960886159   8: 0.025469754227639   0: 0.025469715306416   1: 0.025469710980935   9: 0.025469665545613   2: 0.025469620769517   3: 0.025469617321514   5: 0.025469616961564   4: 0.025469606139434 

test_15651        4: 0.747433139305224   5: 0.028077755946552   0: 0.028062028729686   6: 0.028061780454506   8: 0.028061196993383   1: 0.028061132115958   9: 0.028061080583386   2: 0.028060671077836   7: 0.028060644480512   3: 0.028060570312956 

test_15653        6: 0.667438212146928   1: 0.161830027010392   5: 0.056213297579332   8: 0.029854414035918   0: 0.014123218686324   9: 0.014108333646727   4: 0.014108237318868   7: 0.014108146184027   2: 0.014108136834071   3: 0.014107976557413 

test_15655        5: 0.829286659528187   6: 0.018969423740613   0: 0.018968722361075   1: 0.018968687142757   8: 0.018968134911622   4: 0.018968118348940   9: 0.018967717931213   3: 0.018967634483883   2: 0.018967466959414   7: 0.018967434592295 

test_15656        6: 0.532978240741262   0: 0.263764463163460   5: 0.119349078353004   1: 0.011998799144428   8: 0.011985548114956   9: 0.011984974142536   7: 0.011984942005044   2: 0.011984705085314   3: 0.011984702134820   4: 0.011984547115176 

test_15664        7: 0.545226578047770   1: 0.241028549876580   0: 0.063556553907267   8: 0.021464732027775   6: 0.021456266881292   5: 0.021455087952779   4: 0.021453929709602   3: 0.021453400880217   2: 0.021452588009647   9: 0.021452312707071 

test_15666        6: 0.620741464365576   9: 0.202860470844635   0: 0.056066040266073   1: 0.017225776061491   3: 0.017185545080289   8: 0.017185320013735   5: 0.017184628235895   4: 0.017183896741455   2: 0.017183722134468   7: 0.017183136256383 

test_15667        5: 0.752587015705339   4: 0.098907937712280   8: 0.018576191301692   3: 0.018573554836367   0: 0.018563007004350   1: 0.018559603057674   6: 0.018558578234471   7: 0.018558166234613   9: 0.018558078744252   2: 0.018557867168964 

test_15668        5: 0.424144789730100   8: 0.395854142080586   1: 0.022506311334119   0: 0.022504295745429   4: 0.022503424864999   6: 0.022498385925294   3: 0.022497370232996   7: 0.022497243569366   9: 0.022497147256421   2: 0.022496889260688 

test_15669        5: 0.660137847459914   6: 0.135630082693999   4: 0.025533067592649   1: 0.025531026606182   8: 0.025528872472029   3: 0.025528482435156   0: 0.025527980658065   9: 0.025527688573185   2: 0.025527483801128   7: 0.025527467707695 

test_15672        1: 0.431746601499413   4: 0.389030765558019   6: 0.022409404357682   0: 0.022404077662068   5: 0.022403716970542   9: 0.022403010233813   8: 0.022401590739688   7: 0.022401181171025   2: 0.022400068098253   3: 0.022399583709497 

test_15674        5: 0.357719346093330   4: 0.306542567040084   0: 0.221862206434046   1: 0.024019641402111   6: 0.014980013956546   7: 0.014979251835690   3: 0.014974591073537   2: 0.014974400490253   9: 0.014974007115569   8: 0.014973974558835 

test_15675        6: 0.717512021058652   7: 0.078593946213583   8: 0.046682233893798   0: 0.045285542536184   1: 0.018679832301345   5: 0.018656264288261   9: 0.018651550743740   2: 0.018646424046750   3: 0.018646239634708   4: 0.018645945282980 

test_15676        6: 0.840854995033321   1: 0.017698710423534   8: 0.017684347993360   7: 0.017680937289499   9: 0.017680730521888   2: 0.017680545040543   3: 0.017680425301366   0: 0.017680295307583   4: 0.017679918540698   5: 0.017679094548208 

test_15677        6: 0.760344958811172   8: 0.026666196466595   1: 0.026628082144514   0: 0.026627309575780   7: 0.026623536275268   5: 0.026622923441648   2: 0.026622425429760   9: 0.026622280289559   4: 0.026621165964262   3: 0.026621121601443 

test_15679        5: 0.680264031585283   4: 0.114015367590504   0: 0.025717318272192   6: 0.025716014690461   8: 0.025714687140130   3: 0.025714575221571   1: 0.025714562135011   2: 0.025714527005518   7: 0.025714518943731   9: 0.025714397415600 

test_15680        4: 0.784708258746774   5: 0.023929565139345   6: 0.023927713709441   8: 0.023922451480095   9: 0.023921428395876   0: 0.023919210352643   7: 0.023918411389466   1: 0.023918214776375   2: 0.023917700845046   3: 0.023917045164939 

test_15682        1: 0.659589892305691   0: 0.112504424446145   5: 0.084483747107962   9: 0.020500113717364   4: 0.020488203286994   6: 0.020487499068538   8: 0.020486667546609   2: 0.020486662079438   7: 0.020486565097023   3: 0.020486225344236 

test_15686        6: 0.891211669049924   1: 0.012089006076085   5: 0.012088270148974   0: 0.012087929571449   8: 0.012087838939792   9: 0.012087214749478   7: 0.012087153341222   4: 0.012087095136947   2: 0.012086963944973   3: 0.012086859041156 

test_15688        5: 0.480344175145144   6: 0.322048827175807   3: 0.024701461847204   4: 0.024701361629329   2: 0.024701353824709   1: 0.024700924909026   0: 0.024700750082357   7: 0.024700429447910   9: 0.024700390876470   8: 0.024700325062045 

test_15689        6: 0.711784363913866   0: 0.137662066439050   1: 0.045256691653366   7: 0.015050266948756   8: 0.015045466318151   5: 0.015040693803532   9: 0.015040653888783   2: 0.015040030690681   4: 0.015039883544223   3: 0.015039882799591 

test_15691        4: 0.346812503232498   5: 0.256477529521120   6: 0.214356681731968   7: 0.073414794551416   0: 0.018161640289596   1: 0.018160837610684   9: 0.018154812830976   8: 0.018154152609658   2: 0.018153620910465   3: 0.018153426711620 

test_15692        4: 0.481036500856206   5: 0.363509713623624   9: 0.019434391634572   1: 0.019433100532775   7: 0.019432434284389   6: 0.019432031217441   8: 0.019431379288095   0: 0.019430813530959   3: 0.019430496148896   2: 0.019429138883044 

test_15694        6: 0.540126533775680   3: 0.303210447440897   0: 0.035199810699483   1: 0.017439352202156   8: 0.017361252034766   5: 0.017333023190698   9: 0.017332782143884   7: 0.017332456910206   4: 0.017332252072045   2: 0.017332089530184 

test_15695        5: 0.631446443878177   9: 0.167797104385573   2: 0.025105319935552   6: 0.025100768192492   4: 0.025093924422385   8: 0.025092608752006   1: 0.025091544187440   0: 0.025091027547190   7: 0.025090639376659   3: 0.025090619322526 

test_15696        6: 0.349446713799060   4: 0.335608187432933   8: 0.127523993845224   1: 0.070833744691165   0: 0.027432670782266   9: 0.026315380761972   3: 0.015967234160131   7: 0.015649572002206   2: 0.015629728017960   5: 0.015592774507082 

test_15698        6: 0.322918942011794   7: 0.267391422923518   5: 0.238836401308665   1: 0.037970428811440   2: 0.022201309559081   0: 0.022184984076731   3: 0.022128454206010   4: 0.022123476998914   9: 0.022122356078554   8: 0.022122224025293 

test_15702        5: 0.445674082009200   9: 0.345188951274336   3: 0.026142795408263   2: 0.026142794346874   4: 0.026142392760528   1: 0.026142014713773   6: 0.026141970040372   0: 0.026141876342202   7: 0.026141692931899   8: 0.026141430172552 

test_15703        2: 0.582927264047654   6: 0.262080567837220   8: 0.048135579362377   5: 0.015291766218143   4: 0.015288520732037   0: 0.015266100471357   1: 0.015263727413201   7: 0.015249848929776   9: 0.015248810052238   3: 0.015247814935997 

test_15704        5: 0.744873688710154   9: 0.078462678148880   6: 0.055193385180600   8: 0.017363381739473   1: 0.017360278747951   7: 0.017356597831211   2: 0.017353452576251   4: 0.017348297747596   3: 0.017344155799994   0: 0.017344083517890 

test_15707        5: 0.787955904014761   4: 0.023561179131782   6: 0.023560923085894   3: 0.023560659005730   1: 0.023560479977999   0: 0.023560402591414   2: 0.023560217374701   7: 0.023560100753627   8: 0.023560086535658   9: 0.023560047528434 

test_15708        5: 0.457120210050354   1: 0.301003030085100   4: 0.030235662762352   3: 0.030235469647186   0: 0.030235013051462   8: 0.030234279830703   6: 0.030234151493674   2: 0.030234109562687   7: 0.030234091922836   9: 0.030233981593647 

test_15709        5: 0.527362436739043   7: 0.280411221901085   1: 0.024031981812808   4: 0.024030118029995   6: 0.024028618290706   3: 0.024027552084741   0: 0.024027268789189   9: 0.024027013027138   8: 0.024027005408922   2: 0.024026783916373 

test_15710        8: 0.841547041366929   5: 0.017680092159084   6: 0.017634239288373   4: 0.017602405770534   9: 0.017596923136094   0: 0.017589766550818   7: 0.017587776469394   3: 0.017587487349258   1: 0.017587217116425   2: 0.017587050793091 

test_15713        4: 0.520989749552879   1: 0.270108759826971   6: 0.053953911410758   0: 0.022185404617276   5: 0.022131991001840   9: 0.022129278944907   7: 0.022127708395100   3: 0.022126031686888   2: 0.022124317126241   8: 0.022122847437140 

test_15715        4: 0.550208594513220   7: 0.232064031421401   8: 0.027224367673172   5: 0.027224072627237   6: 0.027214292445598   0: 0.027214066747563   2: 0.027213027570523   1: 0.027212966903778   9: 0.027212627494313   3: 0.027211952603196 

test_15717        5: 0.821485228873604   6: 0.019880631344562   0: 0.019847306925520   1: 0.019831558817354   9: 0.019829782469866   8: 0.019826093619605   4: 0.019825068409334   2: 0.019824915513570   3: 0.019824740583092   7: 0.019824673443493 

test_15719        5: 0.398134585984537   3: 0.380801816120739   1: 0.027657022774443   4: 0.027635676362224   8: 0.027629063719970   6: 0.027628783171758   9: 0.027628633071518   0: 0.027628252019483   7: 0.027628227690426   2: 0.027627939084900 

test_15720        6: 0.858897150118613   5: 0.015680924328077   0: 0.015678656438727   1: 0.015678460108514   4: 0.015677812377778   3: 0.015677528603345   8: 0.015677521161889   7: 0.015677361785785   9: 0.015677359425541   2: 0.015677225651731 

test_15721        7: 0.400063625642600   6: 0.396342800869847   1: 0.025452953081839   4: 0.025450169929217   8: 0.025449875435595   0: 0.025449451959791   5: 0.025449176633514   3: 0.025448022966470   2: 0.025447404061243   9: 0.025446519419883 

test_15723        5: 0.770995064326842   6: 0.025447276289866   8: 0.025446018579251   4: 0.025445740756837   9: 0.025444965327800   0: 0.025444684854201   1: 0.025444367441482   2: 0.025444030681733   7: 0.025443937113787   3: 0.025443914628200 

test_15725        6: 0.669056932586426   8: 0.148063071431303   1: 0.072929467702570   0: 0.015734828411989   5: 0.015708596842224   9: 0.015705917071288   4: 0.015703671920209   7: 0.015699845223204   3: 0.015698839083669   2: 0.015698829727118 

test_15726        6: 0.515636175139228   7: 0.232090720810445   2: 0.076091238128439   1: 0.074960821655810   5: 0.016878717085982   0: 0.016872181795787   8: 0.016868610118934   9: 0.016868215365937   4: 0.016866728162427   3: 0.016866591737011 

test_15727        2: 0.427626934112261   6: 0.361832788186561   0: 0.067159209523677   7: 0.020488642449832   8: 0.020485592340611   5: 0.020482536591093   1: 0.020481620699814   4: 0.020481057562468   9: 0.020480839334978   3: 0.020480779198704 

test_15728        2: 0.532055647055394   6: 0.289715961191675   7: 0.022284391343436   0: 0.022284358551320   8: 0.022278060492394   1: 0.022277826536458   9: 0.022276674761300   5: 0.022276471545316   4: 0.022275445667049   3: 0.022275162855658 

test_15729        5: 0.628416940101864   4: 0.230480576772009   6: 0.017640263925497   0: 0.017638699053826   9: 0.017637921919463   1: 0.017637876967706   8: 0.017637789898557   2: 0.017636690058583   3: 0.017636668581263   7: 0.017636572721234 

test_15732        5: 0.455847977511659   0: 0.356826431259723   4: 0.023418711214903   1: 0.023416615764989   8: 0.023416278668029   9: 0.023415393223200   6: 0.023415355919474   3: 0.023414819098402   2: 0.023414261670501   7: 0.023414155669120 

test_15733        5: 0.698495047064755   2: 0.135968678585684   6: 0.020714622656869   9: 0.020694731206293   0: 0.020693207802772   1: 0.020693090170424   8: 0.020687105854437   7: 0.020686727160251   4: 0.020684657921609   3: 0.020682131576906 

test_15736        0: 0.522507322024638   5: 0.317964533000497   9: 0.026808193411535   6: 0.019757182289623   1: 0.018829435925585   2: 0.018826988460122   3: 0.018826929867820   8: 0.018826822095847   7: 0.018826393401541   4: 0.018826199522793 

test_15737        6: 0.724488040167820   8: 0.142194809391970   0: 0.016714078634826   9: 0.016664216913351   1: 0.016658301309595   5: 0.016657720421791   4: 0.016656331063697   7: 0.016656025599504   3: 0.016655304339442   2: 0.016655172158003 

test_15739        9: 0.619686764677609   0: 0.232414272764717   1: 0.018500985831800   6: 0.018493098281411   5: 0.018490079029271   4: 0.018484363071300   3: 0.018483939978487   2: 0.018482654838900   8: 0.018482030668565   7: 0.018481810857939 

test_15742        7: 0.439699815769403   0: 0.248150229444921   6: 0.223716608374717   8: 0.024530630163373   1: 0.014482303381477   5: 0.009932163453299   4: 0.009886535139251   2: 0.009879785068282   9: 0.009878489903724   3: 0.009843439301553 

test_15749        6: 0.528590392077710   4: 0.258171135655867   5: 0.026659932336121   8: 0.026655309812081   0: 0.026654717598609   1: 0.026654645903705   9: 0.026654087845525   2: 0.026653622458273   3: 0.026653169744866   7: 0.026652986567243 

test_15751        6: 0.643154335177466   4: 0.129537373309592   7: 0.075386906017184   9: 0.021707932954532   5: 0.021705498242414   0: 0.021702280653146   1: 0.021702038458346   3: 0.021701313364028   8: 0.021701168769884   2: 0.021701153053407 

test_15753        5: 0.494412083949057   9: 0.325379068162760   6: 0.022528459569965   4: 0.022527632610061   1: 0.022526455249719   8: 0.022526275592584   0: 0.022525670133216   7: 0.022525195988608   2: 0.022524740298203   3: 0.022524418445828 

test_15757        5: 0.789974504609523   6: 0.023346447208671   8: 0.023335584211511   9: 0.023335505127152   0: 0.023335399803037   4: 0.023335382920572   1: 0.023335052445712   7: 0.023334331528265   3: 0.023333908506728   2: 0.023333883638829 

test_15759        5: 0.428694707828941   0: 0.363018522863031   2: 0.026037493882317   4: 0.026036271344114   3: 0.026036049101688   9: 0.026035926560792   1: 0.026035635737066   6: 0.026035549055837   7: 0.026035053211387   8: 0.026034790414827 

test_15762        5: 0.514338779051773   6: 0.267443353239700   8: 0.104217259551408   1: 0.016289189581857   9: 0.016288568414235   4: 0.016288321565176   0: 0.016285677239083   7: 0.016283231795444   2: 0.016283130562107   3: 0.016282488999217 

test_15767        5: 0.503933248053289   6: 0.246303715600302   9: 0.115037763646494   8: 0.019252316954181   2: 0.019248800342911   0: 0.019247550684516   7: 0.019247068230549   1: 0.019244086169273   3: 0.019243776363234   4: 0.019241673955251 

test_15768        6: 0.823600037681269   5: 0.019716651837384   0: 0.019591256332258   8: 0.019589141805473   7: 0.019587662420889   4: 0.019585992159418   1: 0.019582920967837   9: 0.019582858877068   2: 0.019581839109966   3: 0.019581638808438 

test_15769        5: 0.579718272998947   8: 0.206648704247283   4: 0.026710319708790   6: 0.026705999130004   9: 0.026704064375658   0: 0.026703932454467   7: 0.026702997061101   2: 0.026702063585485   1: 0.026702012077254   3: 0.026701634361012 

test_15772        5: 0.427271257367396   2: 0.226989017048520   9: 0.201054080028082   6: 0.020672173128592   8: 0.020670311590356   1: 0.020669370909904   4: 0.020669248010835   0: 0.020669185944116   7: 0.020667894146767   3: 0.020667461825433 

test_15777        5: 0.604039116183757   9: 0.182846307312816   4: 0.026647199684236   0: 0.026644324252209   1: 0.026639491143077   7: 0.026637203516173   8: 0.026636822074448   6: 0.026636782482192   2: 0.026636392958002   3: 0.026636360393089 

test_15778        5: 0.803230975424867   1: 0.021871012762988   0: 0.021866516794031   6: 0.021863679893399   4: 0.021863200513257   2: 0.021861199842125   9: 0.021861149377372   3: 0.021860940690309   7: 0.021860755250053   8: 0.021860569451599 

test_15780        5: 0.459658162852025   3: 0.195420052184114   0: 0.180342650129611   1: 0.023513649601284   4: 0.023511470099899   2: 0.023511021984886   8: 0.023510838282278   6: 0.023510810935772   7: 0.023510710955453   9: 0.023510632974679 

test_15782        5: 0.732036458349948   1: 0.111415656423587   6: 0.019572320726052   0: 0.019570432370723   9: 0.019569034190974   8: 0.019568472905073   4: 0.019568226498515   7: 0.019566855671994   3: 0.019566361217238   2: 0.019566181645896 

test_15785        0: 0.803793246079511   5: 0.021803973446308   4: 0.021803118252378   1: 0.021802312993451   6: 0.021801218732357   3: 0.021799600202204   9: 0.021799313662188   2: 0.021799240573920   7: 0.021799149476208   8: 0.021798826581474 

test_15790        0: 0.380972266999269   5: 0.354951878461290   4: 0.033023115872269   1: 0.033008583838696   8: 0.033007758763385   2: 0.033007473957798   3: 0.033007467229057   9: 0.033007176354516   7: 0.033007167663329   6: 0.033007110860389 

test_15793        6: 0.761977929457266   1: 0.092884388132700   0: 0.018144749625126   5: 0.018144051275046   9: 0.018142148247488   8: 0.018141957290286   7: 0.018141810700962   4: 0.018141304142134   2: 0.018140921808705   3: 0.018140739320287 

test_15797        4: 0.774892181902968   5: 0.025019760657528   8: 0.025011897029642   6: 0.025011420368881   1: 0.025011232081514   9: 0.025011113591417   0: 0.025010843246942   3: 0.025010559625701   7: 0.025010506136018   2: 0.025010485359389 

test_15798        6: 0.464288694593947   9: 0.367180931566558   0: 0.079858978815334   8: 0.012685711361589   7: 0.012671632495393   1: 0.012664530341377   5: 0.012663352102481   4: 0.012663012641546   2: 0.012661582434338   3: 0.012661573647437 

test_15800        4: 0.496441160467809   5: 0.357571929882469   6: 0.018251190946835   9: 0.018249104001984   1: 0.018249061612983   8: 0.018248703634605   0: 0.018248205149331   2: 0.018246975150080   7: 0.018246962533519   3: 0.018246706620385 

test_15801        7: 0.504858505934514   0: 0.309641696998085   9: 0.056739884311164   5: 0.018402574930961   4: 0.018398928251141   6: 0.018395725572691   1: 0.018391891336811   2: 0.018390966681707   8: 0.018390100178943   3: 0.018389725803982 

test_15803        6: 0.827740980552723   5: 0.019162594763799   3: 0.019139239632578   4: 0.019137925410287   7: 0.019137158128399   0: 0.019137057860490   9: 0.019136541263142   1: 0.019136521384838   8: 0.019136088908783   2: 0.019135892094960 

test_15804        6: 0.857873034990374   5: 0.015792274692498   1: 0.015792070240815   0: 0.015792038863106   8: 0.015791944889624   9: 0.015791905885916   7: 0.015791867353578   4: 0.015791638571469   2: 0.015791624115850   3: 0.015791600396769 

test_15805        9: 0.728819852364176   6: 0.030144098873882   0: 0.030134363986888   8: 0.030133627863716   1: 0.030131553819905   5: 0.030129183355919   7: 0.030127413911609   3: 0.030126922279177   2: 0.030126915997198   4: 0.030126067547530 

test_15807        5: 0.814999840568302   6: 0.020557519487317   4: 0.020556165650191   2: 0.020556015181771   1: 0.020555911612436   0: 0.020555197298633   8: 0.020554993143246   3: 0.020554907094310   9: 0.020554782484317   7: 0.020554667479478 

test_15808        0: 0.484439218671732   5: 0.328058029488092   1: 0.023440777516027   6: 0.023438968279476   3: 0.023438607830481   2: 0.023437218394058   4: 0.023437107750370   8: 0.023436800680835   9: 0.023436650904569   7: 0.023436620484358 

test_15810        0: 0.323657837656425   1: 0.297019724391978   6: 0.248839884320334   2: 0.033360993782498   9: 0.016364826331954   3: 0.016307635913180   5: 0.016118420613699   4: 0.016110403946962   7: 0.016110174159007   8: 0.016110098883963 

test_15811        6: 0.829109360519939   5: 0.019022935377477   3: 0.018985589184396   4: 0.018984301445743   7: 0.018983586835005   0: 0.018983516486648   1: 0.018983060439975   9: 0.018982918316309   8: 0.018982468802956   2: 0.018982262591554 

test_15816        6: 0.702103956920828   8: 0.139198538725657   5: 0.019846954907941   0: 0.019845403683265   9: 0.019838087313149   7: 0.019837516179248   4: 0.019833072594729   1: 0.019832913297562   2: 0.019831974088860   3: 0.019831582288762 

test_15817        6: 0.641323922949176   0: 0.129863749866533   1: 0.111300499512284   8: 0.031328438532145   3: 0.014379509558889   5: 0.014371903071467   7: 0.014360637099742   2: 0.014357277846366   9: 0.014357046997792   4: 0.014357014565608 

test_15819        5: 0.420689101558594   7: 0.359876188897058   8: 0.027433548983841   4: 0.027432821743934   1: 0.027429300821747   0: 0.027429296405917   3: 0.027428277725037   9: 0.027427351045338   2: 0.027427104709199   6: 0.027427008109336 

test_15821        5: 0.824362877843088   4: 0.019518321094313   1: 0.019516960086151   6: 0.019515711636171   0: 0.019514978543722   9: 0.019514363632042   8: 0.019514328946250   2: 0.019514202701110   7: 0.019514149148349   3: 0.019514106368805 

test_15822        5: 0.618607505616848   2: 0.171859999271553   6: 0.026195372167833   8: 0.026192403142800   4: 0.026192186653929   9: 0.026191620662573   1: 0.026190684710601   0: 0.026190649687733   7: 0.026190054127447   3: 0.026189523958683 

test_15823        5: 0.773932040272182   3: 0.025121681784547   4: 0.025120691664586   1: 0.025118769926096   0: 0.025117886194902   6: 0.025117875789446   2: 0.025117791120309   9: 0.025117788212700   8: 0.025117774815552   7: 0.025117700219681 

test_15829        2: 0.552718703026916   5: 0.193761948655921   6: 0.121315361050024   8: 0.018892811721422   9: 0.018891167679874   0: 0.018886485634434   1: 0.018885585708985   4: 0.018883107584940   3: 0.018882460451352   7: 0.018882368486132 

test_15831        7: 0.781169393302365   0: 0.024347521703511   5: 0.024321701022381   2: 0.024319629136655   6: 0.024310451020502   4: 0.024309876944657   1: 0.024308746324253   3: 0.024304407800998   8: 0.024304160635794   9: 0.024304112108884 

test_15832        5: 0.594637541817777   3: 0.196352147116639   6: 0.026129220427956   8: 0.026128543655490   9: 0.026127375297341   4: 0.026126759569580   0: 0.026125555524433   1: 0.026125335381763   2: 0.026123784125224   7: 0.026123737083798 

test_15833        4: 0.402627483920737   5: 0.386342473349761   6: 0.026383398562004   8: 0.026380515593613   9: 0.026379513440141   0: 0.026377856632650   1: 0.026377533348082   7: 0.026377423938967   2: 0.026377157612865   3: 0.026376643601180 

test_15834        5: 0.821573230425248   4: 0.019827740696846   1: 0.019826375697848   9: 0.019825164743273   2: 0.019825072962432   6: 0.019824964990762   0: 0.019824726645997   8: 0.019824276329535   7: 0.019824248098821   3: 0.019824199409239 

test_15836        6: 0.525827618152795   2: 0.306641236529286   1: 0.044335219498924   8: 0.017605383421562   0: 0.017603388534020   3: 0.017599357269592   5: 0.017599045912216   7: 0.017596435341171   4: 0.017596213639097   9: 0.017596101701337 

test_15838        6: 0.611892341796024   7: 0.162246393947847   1: 0.124286852152486   3: 0.014582494530348   0: 0.014521870888765   8: 0.014502616505137   5: 0.014494976029265   4: 0.014491177581857   9: 0.014490767876743   2: 0.014490508691529 

test_15840        6: 0.483982879909433   0: 0.443675517881502   4: 0.009074758292373   9: 0.009057709907665   7: 0.009040050814886   5: 0.009035297520034   2: 0.009034468223319   1: 0.009033453779451   3: 0.009033207499605   8: 0.009032656171730 

test_15841        5: 0.439406591339300   6: 0.229327556926747   4: 0.180069967971057   3: 0.042284794338032   1: 0.033196055376856   8: 0.015190848277635   7: 0.015159815154666   9: 0.015143305896883   0: 0.015111596077146   2: 0.015109468641679 

test_15842        6: 0.769249174439241   5: 0.025642398314234   8: 0.025639612504363   4: 0.025639193440906   0: 0.025639158262266   7: 0.025638895910597   9: 0.025638855944686   1: 0.025637597905039   2: 0.025637562389002   3: 0.025637550889667 

test_15844        6: 0.764852391760602   5: 0.026132123138950   4: 0.026129926497677   8: 0.026127853637847   9: 0.026126967942586   7: 0.026126674777614   0: 0.026126530525937   2: 0.026125902844575   3: 0.026125858340394   1: 0.026125770533818 

test_15845        0: 0.467025108050897   6: 0.312209097357930   5: 0.027604998193108   4: 0.027597608824989   8: 0.027596616086760   7: 0.027594337356237   9: 0.027593480053109   1: 0.027593467438059   2: 0.027592819782264   3: 0.027592466856646 

test_15846        8: 0.711118767574180   5: 0.032142427425095   6: 0.032112620693572   9: 0.032102076396718   1: 0.032095209652847   0: 0.032091149756617   7: 0.032085966069581   3: 0.032084050753362   4: 0.032083870662599   2: 0.032083861015428 

test_15847        9: 0.462120866013013   8: 0.328966455641096   6: 0.026135961633331   5: 0.026126126737105   0: 0.026113744806936   1: 0.026110597114982   7: 0.026108439701652   3: 0.026105995610950   4: 0.026105951335688   2: 0.026105861405247 

test_15851        5: 0.702362819827888   8: 0.142009730321605   4: 0.019459666734890   2: 0.019455775411512   0: 0.019452127027767   9: 0.019452034869321   1: 0.019452014543026   3: 0.019451964695526   6: 0.019451934768951   7: 0.019451931799515 

test_15852        5: 0.710039567119241   6: 0.032236955075289   4: 0.032220931512044   0: 0.032215162090070   1: 0.032215014796062   8: 0.032214960042142   3: 0.032214905255332   2: 0.032214496508881   9: 0.032214008975381   7: 0.032213998625557 

test_15853        6: 0.449414248404386   5: 0.371518696183332   8: 0.030186894895464   0: 0.021889172985624   7: 0.021842678613487   1: 0.021092571880723   9: 0.021017688668820   4: 0.021012825590080   2: 0.021012687471319   3: 0.021012535306766 

test_15854        8: 0.529299938159039   5: 0.259332210363816   6: 0.026459340534882   1: 0.026438627545386   0: 0.026424952749225   7: 0.026413389119494   9: 0.026410946916571   4: 0.026409091239934   3: 0.026405779078797   2: 0.026405724292855 

test_15855        8: 0.340000792258286   5: 0.276161522440419   6: 0.210044089696624   9: 0.059480297495098   0: 0.019058254464574   1: 0.019054442986896   2: 0.019053977752963   7: 0.019050405970585   4: 0.019048165817666   3: 0.019048051116891 

test_15856        6: 0.849540731985333   5: 0.016719293682933   0: 0.016718302888795   1: 0.016717986048085   9: 0.016717831584496   8: 0.016717790879825   4: 0.016717408485434   7: 0.016717212930796   2: 0.016716823782246   3: 0.016716617732057 

test_15858        6: 0.538466671128719   8: 0.269228079078803   0: 0.024044906167522   5: 0.024041650469310   7: 0.024040013844649   9: 0.024036552557820   1: 0.024035823454084   2: 0.024035619379403   4: 0.024035463345343   3: 0.024035220574348 

test_15859        6: 0.550662979768681   8: 0.236665165671649   9: 0.051213989982117   0: 0.023149451324607   1: 0.023070668167888   2: 0.023053056906239   7: 0.023048907569047   5: 0.023048356797208   3: 0.023043927657931   4: 0.023043496154633 

test_15860        6: 0.812079403486987   5: 0.020884381982806   8: 0.020881722594102   3: 0.020880271602225   0: 0.020879442394195   7: 0.020879209182542   1: 0.020879158238090   4: 0.020878967620333   9: 0.020878752917138   2: 0.020878689981581 

test_15861        5: 0.624492667940282   1: 0.254581693986779   6: 0.015125290554861   0: 0.015116170795572   2: 0.015114328461350   7: 0.015114078185606   9: 0.015114069191709   4: 0.015113979550473   8: 0.015113909334937   3: 0.015113811998432 

test_15863        6: 0.800332456268018   5: 0.022189253219068   4: 0.022186142312722   8: 0.022185451807574   9: 0.022185380883855   7: 0.022184768995866   0: 0.022184537694591   3: 0.022184108944543   1: 0.022183955023641   2: 0.022183944850122 

test_15864        0: 0.475701677802376   6: 0.372341130782312   5: 0.019022340879238   8: 0.019000880317104   1: 0.018992750827299   2: 0.018991211890883   4: 0.018988166632283   7: 0.018987335206564   3: 0.018987255898130   9: 0.018987249763811 

test_15865        6: 0.796964312871660   5: 0.022562464781525   8: 0.022560771125966   9: 0.022560688550361   4: 0.022559987148191   0: 0.022558863126288   7: 0.022558746482675   3: 0.022558122112794   1: 0.022558034477945   2: 0.022558009322595 

test_15866        6: 0.747031640629291   8: 0.078559174300066   7: 0.021808633004795   5: 0.021804714345288   9: 0.021800610315394   4: 0.021800341635377   0: 0.021799232945372   3: 0.021798658574891   2: 0.021798514847374   1: 0.021798479402152 

test_15867        5: 0.538170597533927   3: 0.208134170063467   6: 0.031772325241893   0: 0.031711294900537   2: 0.031704655764379   1: 0.031703048571134   9: 0.031702271956844   8: 0.031700904729156   4: 0.031700654005803   7: 0.031700077232859 

test_15868        6: 0.795321692014105   5: 0.022745207135055   9: 0.022743730163725   4: 0.022742667851769   8: 0.022742154746921   7: 0.022741411133478   0: 0.022741379794228   3: 0.022740647874542   2: 0.022740588720739   1: 0.022740520565438 

test_15869        6: 0.787007353161102   5: 0.023669614201933   4: 0.023666661980178   8: 0.023666131027783   9: 0.023665781248744   7: 0.023665495689603   0: 0.023665391572421   3: 0.023664592578003   2: 0.023664516751643   1: 0.023664461788590 

test_15870        6: 0.798962131504693   5: 0.022342648112970   4: 0.022338093992557   9: 0.022337753007631   8: 0.022337664461316   7: 0.022337023214332   0: 0.022336412691182   1: 0.022336280651274   3: 0.022336053179401   2: 0.022335939184645 

test_15871        8: 0.668243067306532   6: 0.144343885500047   0: 0.024802476628458   5: 0.024235587050011   7: 0.023505592776796   2: 0.023317598988649   1: 0.023115942353658   3: 0.023084950210619   9: 0.022698162080815   4: 0.022652737104415 

test_15872        6: 0.611827529255380   7: 0.162281923045859   1: 0.124320069347416   3: 0.014578602066620   0: 0.014521844866303   8: 0.014502605919236   5: 0.014494973703547   4: 0.014491176992334   9: 0.014490767099133   2: 0.014490507704171 

test_15874        6: 0.801402585563651   5: 0.022069867732365   9: 0.022067176157672   4: 0.022067079764380   8: 0.022066500179955   7: 0.022065862077815   0: 0.022065753345172   3: 0.022065101519527   1: 0.022065057475589   2: 0.022065016183875 

test_15875        6: 0.416979737013664   7: 0.329825332682836   8: 0.130991210734511   0: 0.055122579674253   1: 0.011965076298061   5: 0.011232954123582   9: 0.011055870148868   4: 0.010945142205513   2: 0.010943482313239   3: 0.010938614805473 

test_15876        6: 0.764288020490307   5: 0.026213403460735   4: 0.026201894997158   9: 0.026186489276929   8: 0.026186292213925   0: 0.026185121538105   3: 0.026185095855250   7: 0.026184841326875   2: 0.026184648702370   1: 0.026184192138347 

test_15877        6: 0.764035238625109   9: 0.057481342280791   5: 0.022331942974381   4: 0.022311403134476   1: 0.022310538001307   8: 0.022308657681550   7: 0.022305687473080   0: 0.022305500063108   3: 0.022304876705296   2: 0.022304813060901 

test_15878        5: 0.832776029674592   6: 0.018593670855598   0: 0.018580713020207   1: 0.018580017440405   7: 0.018578634002098   2: 0.018578247201457   9: 0.018578222379629   4: 0.018578189312111   3: 0.018578159453620   8: 0.018578116660283 

test_15879        5: 0.721090139606420   0: 0.030994643988896   6: 0.030992934838186   9: 0.030992164861903   1: 0.030989870364875   4: 0.030988859960017   7: 0.030988115521959   8: 0.030987879395305   2: 0.030987862010419   3: 0.030987529452020 

test_15881        5: 0.656252140268598   4: 0.165875508489333   1: 0.022236676262855   0: 0.022234151298944   9: 0.022233947887584   8: 0.022233652326734   6: 0.022233624266206   3: 0.022233521450086   2: 0.022233437605836   7: 0.022233340143825 

test_15885        5: 0.790465295165853   6: 0.023284902480019   0: 0.023283582184610   2: 0.023283191391463   1: 0.023282392318072   4: 0.023281118964184   8: 0.023280282150444   3: 0.023279873629016   9: 0.023279707492755   7: 0.023279654223585 

test_15886        5: 0.544342082669278   4: 0.280522669982315   6: 0.021895789217663   1: 0.021893201689422   8: 0.021892038916507   0: 0.021891952386007   9: 0.021890631745507   3: 0.021890601689161   2: 0.021890545404403   7: 0.021890486299737 

test_15888        5: 0.645369257477680   3: 0.179221056411236   0: 0.021940888284095   6: 0.021938030723930   4: 0.021924006374735   1: 0.021923351173133   7: 0.021921292089454   8: 0.021920906779718   2: 0.021920763588285   9: 0.021920447097733 

test_15889        5: 0.747965636660660   4: 0.028006296073565   3: 0.028003620117908   2: 0.028003599744276   8: 0.028003581727355   1: 0.028003520154975   7: 0.028003498908823   0: 0.028003490793406   9: 0.028003443587765   6: 0.028003312231267 

test_15890        6: 0.664669666626952   0: 0.111517051158867   8: 0.101812424831207   9: 0.017432178923690   5: 0.017431254241906   7: 0.017428986763773   4: 0.017427637422702   3: 0.017427051456113   1: 0.017426931743409   2: 0.017426816831382 

test_15892        5: 0.453722118666868   2: 0.352283347713804   1: 0.024256577982982   6: 0.024254144583228   0: 0.024251689022802   8: 0.024250757170228   4: 0.024246968863219   9: 0.024245848549438   7: 0.024244519037432   3: 0.024244028410000 

test_15893        6: 0.732955280176528   8: 0.138909789289787   0: 0.016043636362618   1: 0.016019255587166   4: 0.016014972045448   5: 0.016013998200523   7: 0.016010960522848   9: 0.016010896008757   2: 0.016010634976534   3: 0.016010576829791 

test_15894        0: 0.474483647672285   3: 0.226752400070099   6: 0.188935724680893   8: 0.015734494711580   1: 0.015689305803898   5: 0.015683996591270   4: 0.015682208595225   2: 0.015679943242419   9: 0.015679471046560   7: 0.015678807585770 

test_15895        6: 0.749759775752685   1: 0.027805363189066   0: 0.027805227488154   7: 0.027805157855631   5: 0.027804378178886   8: 0.027804330620420   2: 0.027804149251395   9: 0.027804044477325   4: 0.027803909732191   3: 0.027803663454247 

test_15896        5: 0.792812213592347   0: 0.023041522503543   4: 0.023020526427925   8: 0.023018952349467   3: 0.023018872850893   2: 0.023018153629141   7: 0.023017874320597   1: 0.023017689162074   9: 0.023017687902677   6: 0.023016507261336 

test_15897        8: 0.457350989357930   5: 0.349039932261492   3: 0.024202093670099   6: 0.024202039690722   0: 0.024201407283751   4: 0.024201281486232   1: 0.024200833433763   2: 0.024200631036595   9: 0.024200441406586   7: 0.024200350372830 

test_15898        8: 0.373122912977186   5: 0.279284470670728   0: 0.198937023086245   6: 0.021243283392788   1: 0.021237609387517   7: 0.021237536261910   4: 0.021234912659570   3: 0.021234509973375   9: 0.021234214672954   2: 0.021233526917726 

test_15899        5: 0.811776676520835   7: 0.020927680308750   4: 0.020914832493715   6: 0.020912997339819   1: 0.020912439223589   3: 0.020911173076275   0: 0.020911164274851   8: 0.020911159488385   9: 0.020910956053305   2: 0.020910921220477 

test_15900        1: 0.339372338229375   8: 0.277836063043802   7: 0.224485306048400   4: 0.022633462455373   6: 0.022618401920972   0: 0.022612999189721   5: 0.022612278210289   3: 0.022610050185946   2: 0.022609903969321   9: 0.022609196746801 

test_15901        5: 0.463409347403761   9: 0.246796850282377   3: 0.134548677183660   0: 0.022280542672203   1: 0.022223188668761   6: 0.022179765520388   2: 0.022141015338666   8: 0.022140880776470   7: 0.022140770384455   4: 0.022138961769258 

test_15902        5: 0.795997202831399   6: 0.022668022483091   3: 0.022667214121938   2: 0.022667131714486   4: 0.022666904196007   0: 0.022666855558765   1: 0.022666788948230   7: 0.022666694807918   8: 0.022666620626204   9: 0.022666564711962 

test_15903        6: 0.706667028560362   5: 0.085359881527365   8: 0.025997417293006   0: 0.025997348987732   7: 0.025997048960371   1: 0.025996896530509   3: 0.025996635015687   2: 0.025996020533232   9: 0.025995943803592   4: 0.025995778788146 

test_15904        6: 0.753377875286509   0: 0.027415051438034   7: 0.027402448814940   1: 0.027401746525282   8: 0.027400980287784   5: 0.027400741932921   9: 0.027400426954700   2: 0.027400390109268   4: 0.027400291288760   3: 0.027400047361800 

test_15906        6: 0.564138639843960   5: 0.286543806631196   4: 0.044627007529716   0: 0.016059659909773   7: 0.015767156530668   8: 0.014866615328486   2: 0.014565285542975   1: 0.014526414784494   9: 0.014454803860101   3: 0.014450610038631 

test_15908        5: 0.454812392540686   6: 0.370029098931147   1: 0.021899387725091   4: 0.021896402537025   0: 0.021895747950599   9: 0.021893651799267   2: 0.021893470255326   7: 0.021893435185786   8: 0.021893384933288   3: 0.021893028141785 

test_15909        5: 0.734080125045074   7: 0.121021038479832   6: 0.018115840708560   4: 0.018114028920820   1: 0.018112559244714   9: 0.018112335495492   2: 0.018111749653696   0: 0.018111612543315   8: 0.018110832768543   3: 0.018109877139953 

test_15910        6: 0.436332588237607   4: 0.373617586316652   7: 0.024826473208643   9: 0.023613562620307   2: 0.023612876418112   0: 0.023606851772209   5: 0.023600928644341   8: 0.023599127821857   1: 0.023595577748713   3: 0.023594427211560 

test_15911        6: 0.842624903894304   0: 0.017488087731833   5: 0.017487622083989   4: 0.017486222797562   8: 0.017485838146142   7: 0.017485807756978   1: 0.017485646965867   9: 0.017485371765627   3: 0.017485252050638   2: 0.017485246807060 

test_15912        1: 0.589388605399083   5: 0.254706976242687   0: 0.055433808607350   8: 0.014359817826304   6: 0.014359670950037   4: 0.014350819520713   9: 0.014350456257601   2: 0.014350137431978   7: 0.014350068821359   3: 0.014349638942888 

test_15913        6: 0.816972626223365   5: 0.020356752228690   4: 0.020346321520245   1: 0.020333292233721   0: 0.020332384174342   8: 0.020332150524350   9: 0.020331781248275   7: 0.020331735699942   2: 0.020331527948956   3: 0.020331428198113 

test_15914        6: 0.519132031327494   2: 0.176165478281655   4: 0.154410633350558   7: 0.024926971618812   9: 0.020907629973843   0: 0.020900356457775   5: 0.020892955909934   8: 0.020891435793410   1: 0.020886435326725   3: 0.020886071959795 

test_15916        6: 0.729771198048882   0: 0.142790282532485   5: 0.015933845612875   1: 0.015930583297709   9: 0.015929974239823   8: 0.015929428462529   7: 0.015929004478802   4: 0.015928715987688   2: 0.015928541481743   3: 0.015928425857464 

test_15917        6: 0.457753147484248   8: 0.282068127577349   3: 0.113323593951515   9: 0.038480014387730   5: 0.018181791289721   0: 0.018086794914341   4: 0.018065660266929   2: 0.018050004714395   1: 0.018026643464144   7: 0.017964221949629 

test_15918        9: 0.443551205397742   6: 0.376627401289724   1: 0.053897091910194   0: 0.017998846321698   5: 0.017991275158215   2: 0.017991235390757   4: 0.017990328290938   8: 0.017986451050976   3: 0.017983886217166   7: 0.017982278972590 

test_15920        5: 0.645413388475408   9: 0.184791119292300   1: 0.021279622529144   6: 0.021229722563987   0: 0.021222766922642   3: 0.021221220961026   7: 0.021212737773718   2: 0.021210095670904   4: 0.021209899846628   8: 0.021209425964242 

test_15921        6: 0.631612311042359   4: 0.207326208230275   2: 0.020144625988358   5: 0.020135193344363   8: 0.020133632427143   9: 0.020130764437753   0: 0.020129759347562   1: 0.020129512270557   7: 0.020129476837265   3: 0.020128516074365 

test_15922        6: 0.533277264132173   4: 0.299691159903266   2: 0.020900272121426   5: 0.020878286821840   8: 0.020878213430272   9: 0.020876725698612   7: 0.020875074834732   0: 0.020874641786399   1: 0.020874488843567   3: 0.020873872427713 

test_15923        6: 0.503957003379269   4: 0.333921820647417   2: 0.020287452679924   5: 0.020264228311010   8: 0.020263786986014   9: 0.020263065916898   7: 0.020261258491175   0: 0.020260863676807   1: 0.020260598871955   3: 0.020259921039531 

test_15924        6: 0.624225711960256   5: 0.175372831672642   9: 0.025053464067328   4: 0.025051929647157   2: 0.025051067783518   1: 0.025050130347853   0: 0.025050008157700   8: 0.025048855421155   7: 0.025048106061375   3: 0.025047894881017 

test_15925        6: 0.599354986430264   1: 0.204862849588343   3: 0.037300856758987   2: 0.022724856906431   4: 0.022641943287519   5: 0.022638892323981   8: 0.022631204333668   9: 0.022617523394620   0: 0.022615749224795   7: 0.022611137751392 

test_15927        6: 0.664622980056492   0: 0.186282351836665   5: 0.018639378414200   1: 0.018636991972566   2: 0.018636990702613   4: 0.018636428536497   7: 0.018636291348320   8: 0.018636284719201   3: 0.018636220730706   9: 0.018636081682741 

test_15928        6: 0.434159003878239   4: 0.312663840097239   7: 0.102852195089118   2: 0.021486878628413   5: 0.021475495609327   8: 0.021473935940216   9: 0.021473379194803   0: 0.021472754416424   1: 0.021471519100352   3: 0.021470998045870 

test_15929        9: 0.318608923601069   6: 0.216502908910658   5: 0.174343516173247   8: 0.147622774917126   0: 0.056373748500835   7: 0.017441369098396   1: 0.017280340119305   2: 0.017278027779528   4: 0.017274482927301   3: 0.017273907972535 

test_15930        5: 0.554213962213388   9: 0.207132702084595   0: 0.083751993830228   1: 0.022140888574269   6: 0.022138138816320   8: 0.022126388592988   3: 0.022124970050181   4: 0.022123680789678   7: 0.022123639008250   2: 0.022123636040104 

test_15932        1: 0.605565877979263   6: 0.224801797695244   0: 0.046662152875438   8: 0.025128490271114   7: 0.024949124898202   2: 0.014668081691244   9: 0.014575406811398   4: 0.014555401266650   3: 0.014547618004531   5: 0.014546048506916 

test_15933        5: 0.781897679538326   4: 0.024234867149816   3: 0.024233914100623   1: 0.024233845832260   0: 0.024233567951016   6: 0.024233437780880   2: 0.024233260178207   8: 0.024233177104620   9: 0.024233128529973   7: 0.024233121834278 

test_15934        5: 0.502841620627110   3: 0.299031298295221   4: 0.024767681404089   2: 0.024765917985625   1: 0.024765858138132   6: 0.024765780334285   7: 0.024765545288518   0: 0.024765537995615   8: 0.024765436380395   9: 0.024765323551010 

test_15937        5: 0.356884130246654   4: 0.260440073017162   3: 0.180172958995716   0: 0.028933092856301   8: 0.028930442347124   2: 0.028928088241924   6: 0.028927934401126   1: 0.028927846659528   7: 0.028927840156709   9: 0.028927593077755 

test_15939        6: 0.582279782021841   1: 0.196433715667444   0: 0.064750782713463   2: 0.039652403244114   9: 0.033453916411107   7: 0.028644919675613   4: 0.013766507664034   5: 0.013716971149640   3: 0.013654038136158   8: 0.013646963316585 

test_15942        0: 0.723938824438045   6: 0.030691113779137   8: 0.030675961250091   7: 0.030672432996103   1: 0.030670916155440   2: 0.030670397889045   9: 0.030670375153473   3: 0.030670273073128   5: 0.030670038531992   4: 0.030669666733546 

test_15944        5: 0.475129936051204   3: 0.346025496093151   4: 0.022363156830189   0: 0.022356380648117   9: 0.022354866117388   8: 0.022354489619951   6: 0.022354254638697   7: 0.022354242970468   2: 0.022353669018610   1: 0.022353508012226 

test_15949        6: 0.531532296824458   8: 0.336057511702473   0: 0.016700910608971   3: 0.016618638432229   5: 0.016517020675233   1: 0.016516934785857   4: 0.016515141030289   7: 0.016513935780755   9: 0.016513896433333   2: 0.016513713726402 

test_15950        5: 0.524157449938245   6: 0.331805518713904   8: 0.018006739831808   1: 0.018005712379197   0: 0.018005658711262   9: 0.018004518640422   7: 0.018003982695791   4: 0.018003900662481   2: 0.018003550644584   3: 0.018002967782307 

test_15951        8: 0.445489296708285   6: 0.398694265243370   5: 0.019483641481268   1: 0.019477403514174   0: 0.019477056430923   4: 0.019476409614615   9: 0.019475936235387   7: 0.019475498127792   2: 0.019475381511108   3: 0.019475111133077 

test_15952        8: 0.602073775007319   6: 0.264081069784193   1: 0.016740414422071   0: 0.016734554659453   7: 0.016732193714430   9: 0.016730166720085   5: 0.016729397791766   2: 0.016726201347660   4: 0.016726137326504   3: 0.016726089226519 

test_15953        8: 0.597589521917743   6: 0.259517094971939   0: 0.030034566083515   4: 0.016126247211057   5: 0.016124038318912   2: 0.016123631266433   1: 0.016122224383444   9: 0.016121385807543   7: 0.016121007623669   3: 0.016120282415747 

test_15956        1: 0.584732741237330   6: 0.290358251673289   2: 0.015619355613557   0: 0.015614608219386   8: 0.015614257045171   9: 0.015613552632822   5: 0.015613005442574   4: 0.015612381123018   3: 0.015610938303471   7: 0.015610908709382 

test_15959        5: 0.807098661855391   3: 0.021437670705889   1: 0.021433703944370   6: 0.021433568142735   0: 0.021433380316120   4: 0.021433293745171   2: 0.021432515619544   9: 0.021432466589885   8: 0.021432411467848   7: 0.021432327613048 

test_15960        5: 0.533412690703359   6: 0.262788525620180   9: 0.063479600008568   1: 0.020049632151810   2: 0.020047347230295   0: 0.020046957369773   8: 0.020046106722313   7: 0.020044786084756   4: 0.020042516922505   3: 0.020041837186441 

test_15961        0: 0.469258391936452   6: 0.265419222720941   1: 0.143785732757850   5: 0.017366309017154   4: 0.017364759155564   9: 0.017361852380259   2: 0.017361084715928   8: 0.017360984524138   3: 0.017360964000713   7: 0.017360698791001 

test_15963        6: 0.762165411628907   1: 0.026506562603901   4: 0.026423921677336   9: 0.026421605189240   5: 0.026418096323715   0: 0.026416837588229   8: 0.026412636926420   3: 0.026412402999776   2: 0.026411872306003   7: 0.026410652756473 

test_15964        6: 0.210448387354584   0: 0.210170467580250   2: 0.196637161034971   7: 0.176631317784710   1: 0.134550134718959   3: 0.014336342476673   9: 0.014334314959149   5: 0.014298205584943   8: 0.014296992609851   4: 0.014296675895909 

test_15967        1: 0.451702113544072   5: 0.275345237631055   6: 0.177947074257689   8: 0.013575601592367   0: 0.013573842604619   4: 0.013572761850444   9: 0.013571290718588   2: 0.013570727438188   7: 0.013570726404492   3: 0.013570623958484 

test_15968        1: 0.830469650099026   6: 0.018841578296918   0: 0.018838737031879   5: 0.018836438914214   4: 0.018835870127280   2: 0.018835761248047   8: 0.018835623111266   7: 0.018835512848861   9: 0.018835438786699   3: 0.018835389535811 

test_15969        5: 0.463553209719644   4: 0.360883267391923   6: 0.021948831901087   8: 0.021946766707358   9: 0.021946002900476   1: 0.021944968558732   0: 0.021944901864832   7: 0.021944200588599   2: 0.021943968061338   3: 0.021943882306010 

test_15970        0: 0.804916360632546   6: 0.021687873193903   9: 0.021685949783474   1: 0.021679392326893   4: 0.021677371767470   5: 0.021674944663449   8: 0.021673317097418   3: 0.021668495513450   7: 0.021668152041789   2: 0.021668142979608 

test_15973        5: 0.481367461029219   6: 0.392421055190235   0: 0.015785211140083   4: 0.015777104642467   8: 0.015775909710166   2: 0.015775327480682   7: 0.015775065101570   1: 0.015774636833565   9: 0.015774383888852   3: 0.015773844983161 

test_15975        6: 0.635941117859671   7: 0.266720357423535   5: 0.012175101259571   1: 0.012170527036731   9: 0.012170158067309   0: 0.012167180600794   4: 0.012165588428925   3: 0.012163774380931   8: 0.012163566035876   2: 0.012162628906657 

test_15976        8: 0.768220296515915   6: 0.025758002272760   5: 0.025755193680900   9: 0.025754943207449   7: 0.025752899387389   0: 0.025752852204999   1: 0.025751778183038   4: 0.025751707058439   2: 0.025751271443392   3: 0.025751056045719 

test_15977        8: 0.749448429831044   5: 0.027872357029709   6: 0.027837605702624   3: 0.027837428033941   4: 0.027834512941123   9: 0.027834414248469   0: 0.027834305087492   7: 0.027834020697214   1: 0.027833795310041   2: 0.027833131118345 

test_15978        8: 0.632459183500424   5: 0.151311064329134   6: 0.027033628847066   4: 0.027031670817011   0: 0.027028019403111   9: 0.027027760401114   3: 0.027027676819733   1: 0.027027532359621   7: 0.027027139733464   2: 0.027026323789322 

test_15979        4: 0.411905891440270   6: 0.277702068784417   5: 0.196574659315511   0: 0.016280233814349   2: 0.016257265741338   1: 0.016257228732725   9: 0.016255946039463   3: 0.016255735360893   7: 0.016255493777912   8: 0.016255476993123 

test_15980        5: 0.388334936236327   6: 0.363215775735169   4: 0.031061135290150   8: 0.031056697908496   9: 0.031055392622262   1: 0.031055352927866   2: 0.031055323452904   0: 0.031055156527458   3: 0.031055143154887   7: 0.031055086144482 

test_15981        5: 0.519336644186268   0: 0.242719404595675   4: 0.029748656955321   1: 0.029743710224174   8: 0.029742338271244   3: 0.029742006339021   2: 0.029741943950479   9: 0.029741838221402   7: 0.029741761586504   6: 0.029741695669914 

test_15984        4: 0.471244224289422   0: 0.294633104689429   5: 0.029272935220942   1: 0.029265834878856   6: 0.029265017261882   8: 0.029264118430757   7: 0.029263776887862   3: 0.029263739478734   2: 0.029263650178705   9: 0.029263598683410 

test_15985        5: 0.610660908990665   2: 0.222252381004114   4: 0.020889032090166   6: 0.020887992946042   0: 0.020886129949290   1: 0.020884889963073   7: 0.020884753634482   3: 0.020884689176129   8: 0.020884633229879   9: 0.020884589016159 

test_15987        8: 0.455623468334548   6: 0.443686747591817   0: 0.012594429130935   5: 0.012588620485831   1: 0.012586308679717   4: 0.012584855068991   9: 0.012584705680509   3: 0.012583814318255   7: 0.012583630854536   2: 0.012583419854860 

test_15988        1: 0.580499806384480   6: 0.170350918832197   0: 0.076197111809976   8: 0.060298025277205   7: 0.034180595043187   2: 0.015870684408487   9: 0.015685666272232   4: 0.015652630234956   5: 0.015634159848818   3: 0.015630401888461 

test_15989        8: 0.548567692338263   7: 0.274384851807124   6: 0.022144822966594   9: 0.022142964847036   5: 0.022129511280018   0: 0.022127919877901   1: 0.022127113452781   4: 0.022125603284185   2: 0.022124984887135   3: 0.022124535258962 

test_15993        8: 0.448974039693879   0: 0.407456593613278   1: 0.018151258463159   6: 0.017920012850990   9: 0.017917763821753   5: 0.017917717480160   4: 0.017916221246408   2: 0.017915569535689   7: 0.017915478988199   3: 0.017915344306485 

test_15995        6: 0.792398672023642   5: 0.023140200417502   9: 0.023061763786492   4: 0.023060015993666   1: 0.023059112126389   0: 0.023058135925889   8: 0.023056328863865   2: 0.023055535688883   3: 0.023055264924298   7: 0.023054970249374 

test_15996        6: 0.586107861913086   5: 0.249308940119714   1: 0.020578485745215   8: 0.020576818240920   0: 0.020573379150593   9: 0.020573002161701   4: 0.020571996289218   7: 0.020570131244137   2: 0.020569918227963   3: 0.020569466907453 

test_15997        5: 0.790876348771637   1: 0.023246358578363   6: 0.023243937189270   0: 0.023237229831409   9: 0.023235656300947   8: 0.023234520355539   4: 0.023231932959423   7: 0.023231757990955   2: 0.023231397447940   3: 0.023230860574517 

test_15999        6: 0.840358742779899   5: 0.017779652644862   3: 0.017736393359333   4: 0.017733971887854   7: 0.017732849609129   8: 0.017732645906913   0: 0.017732186168394   9: 0.017731345705134   1: 0.017731290226169   2: 0.017730921712314 

test_16002        5: 0.744501731178777   1: 0.028405986309739   0: 0.028399931240696   6: 0.028390904488008   7: 0.028385136014044   4: 0.028384938876989   9: 0.028384138770522   2: 0.028383644993689   8: 0.028382520220209   3: 0.028381067907327 

test_16003        5: 0.454673530465872   4: 0.361566349004551   3: 0.022971523516705   6: 0.022970261480129   0: 0.022969839413307   1: 0.022969787010335   8: 0.022969739412421   9: 0.022969716118567   7: 0.022969710458941   2: 0.022969543119172 

test_16004        0: 0.758565302596453   1: 0.026832649890975   6: 0.026830216736295   8: 0.026826804908870   9: 0.026825746082353   5: 0.026825380275919   2: 0.026823689820439   7: 0.026823576314890   3: 0.026823342432577   4: 0.026823290941229 

test_16005        9: 0.457092895777573   6: 0.406005464904117   2: 0.041586490291172   0: 0.017519543850076   8: 0.013026605609526   5: 0.012965100734713   4: 0.012958939834600   7: 0.012949313940274   1: 0.012948238172629   3: 0.012947406885320 

test_16006        1: 0.461355965706437   6: 0.457451106541207   2: 0.010185201630112   0: 0.010147834944805   9: 0.010147665472519   5: 0.010142677800023   8: 0.010142578529663   7: 0.010142542023561   4: 0.010142240388994   3: 0.010142186962680 

test_16007        0: 0.780432327134106   2: 0.085673006604887   6: 0.016747803117252   9: 0.016745267293309   5: 0.016736394397387   1: 0.016734517013842   4: 0.016733324705689   8: 0.016733139988582   7: 0.016732353127141   3: 0.016731866617805 

test_16009        6: 0.920495544269283   7: 0.009192451614071   0: 0.008793137680352   1: 0.008790586584358   3: 0.008790191235757   4: 0.008789717880561   5: 0.008788706711917   9: 0.008786699316082   8: 0.008786521945206   2: 0.008786442762413 

test_16012        6: 0.784481514540237   5: 0.023948854268231   1: 0.023947063057317   7: 0.023947003959324   0: 0.023946645222070   8: 0.023946093814164   9: 0.023946045008974   3: 0.023945709158758   2: 0.023945611630113   4: 0.023945459340811 

test_16013        5: 0.805232608140598   6: 0.021646919918625   0: 0.021641943875414   8: 0.021641821588155   4: 0.021641616366266   9: 0.021640270258111   1: 0.021639853901061   7: 0.021638424193189   2: 0.021638402996946   3: 0.021638138761633 

test_16014        9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

test_16015        2: 0.393445518928354   5: 0.374223427778601   4: 0.029045644839913   3: 0.029041003359081   8: 0.029040883973057   0: 0.029040857402605   7: 0.029040746408415   9: 0.029040673865503   1: 0.029040664354460   6: 0.029040579090012 

test_16016        5: 0.433830030750124   0: 0.394930270810568   4: 0.021410843968475   6: 0.021405428896949   8: 0.021404810539548   9: 0.021404054864621   1: 0.021403860716233   3: 0.021403659815439   2: 0.021403520883745   7: 0.021403518754299 

test_16021        1: 0.504466167776192   2: 0.330009394920419   5: 0.020696479895423   6: 0.020693272197830   0: 0.020692778115840   4: 0.020689147586594   8: 0.020689126954730   9: 0.020688225431116   7: 0.020687764512870   3: 0.020687642608986 

test_16022        5: 0.809901890075592   7: 0.021129950747094   4: 0.021125908254871   6: 0.021121270954637   1: 0.021120908847284   3: 0.021120109129033   8: 0.021120056186381   0: 0.021120036660698   2: 0.021119946525755   9: 0.021119922618656 

test_16023        6: 0.479072045966747   5: 0.246108569695973   3: 0.174094162001652   1: 0.025214105803069   0: 0.012599702263010   8: 0.012589586817338   2: 0.012584786650460   4: 0.012579495433536   7: 0.012579349783454   9: 0.012578195584761 

test_16026        1: 0.820764718066271   5: 0.019918661665776   6: 0.019916292469284   8: 0.019915718699261   0: 0.019915536914877   4: 0.019914056977504   9: 0.019913855005807   2: 0.019913783758086   7: 0.019913725278567   3: 0.019913651164566 

test_16029        1: 0.454285813417787   2: 0.388540999082885   0: 0.048066865826629   3: 0.015677881559506   8: 0.015595508115063   5: 0.015570621310703   6: 0.015569701941017   4: 0.015564836281377   9: 0.015563971152196   7: 0.015563801312837 

test_16030        5: 0.675693827603158   0: 0.157341648868211   4: 0.020876496832666   1: 0.020871567684012   2: 0.020869623061620   3: 0.020869459404898   7: 0.020869395765200   8: 0.020869377576607   9: 0.020869307057191   6: 0.020869296146438 

test_16033        0: 0.698412993456246   5: 0.033515770551820   1: 0.033514709404462   6: 0.033512824975301   2: 0.033508171423336   7: 0.033507515757724   4: 0.033507175317198   8: 0.033507174276729   9: 0.033506862858499   3: 0.033506801978684 

test_16037        0: 0.786326376680299   5: 0.023745532162192   1: 0.023745426182683   6: 0.023743521556035   2: 0.023740271864005   4: 0.023740083878217   7: 0.023739866982509   8: 0.023739853571977   9: 0.023739692105628   3: 0.023739375016456 

test_16040        9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

test_16041        4: 0.721805918340328   5: 0.030959817233466   1: 0.030942539730028   0: 0.030910946942279   2: 0.030902404350763   6: 0.030901139482967   3: 0.030894823091456   8: 0.030894465512386   9: 0.030894024085971   7: 0.030893921230357 

test_16045        4: 0.606103289505438   9: 0.188260665251993   5: 0.025714751474285   0: 0.025708058046269   1: 0.025703665866625   6: 0.025703354804412   8: 0.025702128001558   3: 0.025701457135757   2: 0.025701359508362   7: 0.025701270405301 

test_16052        6: 0.831659629474139   5: 0.018709560907589   4: 0.018705483067713   9: 0.018704267683720   8: 0.018704033858316   0: 0.018703895517357   7: 0.018703631581672   1: 0.018703258944423   3: 0.018703148828360   2: 0.018703090136710 

test_16053        8: 0.412230539633864   6: 0.390840325342647   0: 0.129302144203937   1: 0.009682511282544   7: 0.009665659788659   5: 0.009657950639360   4: 0.009655512327907   9: 0.009655417700214   3: 0.009654994608399   2: 0.009654944472470 

test_16055        6: 0.408420914393997   5: 0.406869160918555   4: 0.023095534299015   7: 0.023094057746020   2: 0.023087511959455   9: 0.023087144240326   8: 0.023086573713751   3: 0.023086495749588   1: 0.023086387363730   0: 0.023086219615564 

test_16063        6: 0.763592139476292   7: 0.087203207908052   8: 0.018654884659856   0: 0.018652372474803   9: 0.018651887206847   5: 0.018650607979017   1: 0.018649438478338   4: 0.018648769640529   2: 0.018648408744857   3: 0.018648283431408 

test_16066        6: 0.492440496025469   7: 0.275015134746500   1: 0.029074226073255   8: 0.029070911947572   0: 0.029069507542724   9: 0.029067528615812   5: 0.029065977933624   4: 0.029065526081124   2: 0.029065410801478   3: 0.029065280232442 

test_16067        6: 0.762342778787943   5: 0.026419610621352   1: 0.026415265829461   0: 0.026404678309239   3: 0.026404490016357   8: 0.026403911159170   7: 0.026403084567000   9: 0.026402647144233   4: 0.026401803316778   2: 0.026401730248468 

test_16068        6: 0.667647086978905   1: 0.182322453008920   0: 0.044440638259552   9: 0.015090162278076   3: 0.015088193141240   8: 0.015084145830448   5: 0.015082825684730   7: 0.015081829249055   2: 0.015081653657971   4: 0.015081011911102 

test_16069        1: 0.819335649481292   6: 0.020108094151719   7: 0.020071732015071   9: 0.020071395648019   0: 0.020071300128447   8: 0.020071203749514   3: 0.020067989822848   5: 0.020067854478875   2: 0.020067679911912   4: 0.020067100612301 

test_16071        7: 0.633495671467788   6: 0.224832650236541   9: 0.029061743203218   5: 0.016095570343186   4: 0.016087498318113   8: 0.016086896739395   0: 0.016085795522528   1: 0.016085304326997   2: 0.016084494573144   3: 0.016084375269089 

test_16072        6: 0.519440699146631   0: 0.258877687501898   7: 0.147363177558322   3: 0.021577995994013   1: 0.015604336161127   4: 0.007503141977434   5: 0.007423185015200   8: 0.007408352761968   9: 0.007401878625084   2: 0.007399545258323 

test_16074        6: 0.427639443248959   8: 0.201075739576895   2: 0.196701633296577   5: 0.061903309002089   0: 0.018841507445329   1: 0.018840375054267   9: 0.018750939478235   3: 0.018749850200718   4: 0.018748828880329   7: 0.018748373816601 

test_16075        6: 0.660424172904360   1: 0.244005817091309   0: 0.020177051041265   3: 0.010772113647728   5: 0.010771051284563   9: 0.010770359801557   8: 0.010770346117677   7: 0.010769834206135   2: 0.010769693654863   4: 0.010769560250543 

test_16076        6: 0.888315770795558   1: 0.012410433003733   5: 0.012409837492212   0: 0.012409532187086   9: 0.012409472643392   3: 0.012409223290405   4: 0.012409075493318   8: 0.012408933182460   7: 0.012408864806073   2: 0.012408857105763 

test_16077        6: 0.442149772543038   5: 0.390401814233960   8: 0.051548597153906   9: 0.029166937206370   3: 0.014591865971188   1: 0.014539676629057   4: 0.014415013191063   0: 0.014398757198491   7: 0.014394050126336   2: 0.014393515746590 

test_16079        6: 0.650325862042463   7: 0.187168108024998   1: 0.020328506675884   9: 0.020322274823983   0: 0.020321154247301   5: 0.020316634105510   8: 0.020305557268597   4: 0.020304411153228   3: 0.020303992408037   2: 0.020303499249999 

test_16080        6: 0.622888055292075   5: 0.194930772724617   8: 0.048405923058455   7: 0.019192277636436   3: 0.019109826322844   0: 0.019106151642503   2: 0.019093285380541   9: 0.019091792372171   4: 0.019091122347841   1: 0.019090793222516 

test_16083        0: 0.848739470701782   1: 0.017010813370765   6: 0.016847460517399   8: 0.016773741489689   5: 0.016773128612272   9: 0.016772882905791   7: 0.016770932627335   2: 0.016770614522061   3: 0.016770542247735   4: 0.016770413005173 

test_16086        5: 0.333493316905282   2: 0.288483109332165   6: 0.187170442224951   0: 0.083087550631828   3: 0.017970415038231   1: 0.017964742566218   9: 0.017959826833127   4: 0.017958736240602   7: 0.017955937478662   8: 0.017955922748935 

test_16088        6: 0.696872448858611   5: 0.145385561998123   1: 0.065302199458424   9: 0.013233835784232   0: 0.013201345105163   7: 0.013201248106483   3: 0.013201119515744   8: 0.013200893241953   2: 0.013200723064619   4: 0.013200624866649 

test_16091        3: 0.603531772746613   6: 0.240864615797578   0: 0.019533563258935   1: 0.019451265547555   5: 0.019440801474500   4: 0.019436624254594   8: 0.019435750379285   2: 0.019435499695475   9: 0.019435414657163   7: 0.019434692188301 

test_16093        1: 0.429610213536950   6: 0.383718489107740   8: 0.060130931196113   3: 0.044364717740997   0: 0.025061704732409   7: 0.011437690551274   9: 0.011425647744288   5: 0.011419293605003   2: 0.011417154202777   4: 0.011414157582449 

test_16094        6: 0.906208644815967   4: 0.010459260536831   1: 0.010427634459922   5: 0.010415862433202   0: 0.010415288748679   9: 0.010414771517490   3: 0.010414693070357   8: 0.010414657358534   2: 0.010414643128846   7: 0.010414543930172 

test_16095        6: 0.695731868614611   0: 0.160044119049037   2: 0.072802686127505   5: 0.010220228906988   1: 0.010204044409308   7: 0.010200033255694   8: 0.010199550786044   9: 0.010199218514690   4: 0.010199200604058   3: 0.010199049732066 

test_16096        6: 0.633895230856883   7: 0.211644926416904   0: 0.019309549483077   1: 0.019308203235946   8: 0.019308161338074   9: 0.019307537257964   4: 0.019307494692877   5: 0.019306982318185   2: 0.019306012599660   3: 0.019305901800431 

test_16097        6: 0.645082045852012   7: 0.217882094147110   0: 0.046507312522449   1: 0.013947095921761   8: 0.013193104369034   5: 0.012750058317106   4: 0.012665918202707   9: 0.012657819218997   2: 0.012657692183520   3: 0.012656859265305 

test_16098        6: 0.393077833904150   7: 0.350961400198801   9: 0.093289960171495   3: 0.023241624117062   5: 0.023240827165373   0: 0.023238773899173   8: 0.023238226656438   4: 0.023237920144430   1: 0.023237153776931   2: 0.023236279966148 

test_16099        6: 0.835026734526855   0: 0.064663333117555   4: 0.012547401974747   5: 0.012542446530590   9: 0.012536876594309   8: 0.012536846405313   7: 0.012536732634555   2: 0.012536645138686   1: 0.012536551251144   3: 0.012536431826245 

test_16100        6: 0.377076274550560   7: 0.301358047916264   9: 0.168647579703589   1: 0.021848213767201   3: 0.021848077295657   5: 0.021846850585092   8: 0.021844022676598   0: 0.021844014543040   4: 0.021843727630777   2: 0.021843191331220 

test_16103        6: 0.554002870811535   0: 0.187164833910064   1: 0.186645566383385   5: 0.010334845819338   4: 0.010317023442928   9: 0.010307124517160   7: 0.010307061397924   8: 0.010307012459700   2: 0.010306868460361   3: 0.010306792797606 

test_16106        1: 0.755813131587727   6: 0.027138450275811   8: 0.027134214406729   0: 0.027132631188859   9: 0.027131988608562   7: 0.027131034623760   5: 0.027130130946436   3: 0.027129489037920   2: 0.027129465678948   4: 0.027129463645248 

test_16107        6: 0.538151548648031   4: 0.180562644900637   3: 0.162867921463630   0: 0.016964057859462   1: 0.016942417528277   7: 0.016915978996779   5: 0.016900609141666   8: 0.016898502338964   9: 0.016898296395620   2: 0.016898022726935 

test_16108        6: 0.776728054081778   5: 0.075431172572441   0: 0.069217634124976   1: 0.011247983786238   9: 0.011241965757852   8: 0.011229684266166   4: 0.011225942661233   3: 0.011225894484399   2: 0.011225858178983   7: 0.011225810085934 

test_16110        2: 0.597078648099667   6: 0.224900460653364   7: 0.022287419626490   0: 0.022273023627705   1: 0.022253255592815   5: 0.022245670927259   9: 0.022242250160829   8: 0.022239912347818   4: 0.022239882491233   3: 0.022239476472820 

test_16111        6: 0.485646458678996   1: 0.383205264018891   8: 0.016394935616864   0: 0.016394841619352   9: 0.016393654158034   5: 0.016393492939623   7: 0.016393050685271   3: 0.016392817002512   2: 0.016392743263878   4: 0.016392742016580 

test_16112        1: 0.760423249154872   6: 0.131046256687684   0: 0.013715312562570   5: 0.013550206591968   8: 0.013549019988759   4: 0.013543958414396   2: 0.013543549336511   9: 0.013543014445522   7: 0.013542746560839   3: 0.013542686256880 

test_16115        7: 0.798668157333151   2: 0.022392444693593   6: 0.022375369075407   1: 0.022375309951296   0: 0.022370583147688   5: 0.022369603590326   8: 0.022364108683258   4: 0.022362581986213   9: 0.022361403573136   3: 0.022360437965932 

test_16117        6: 0.842452708773907   1: 0.017509916367825   5: 0.017509007416729   0: 0.017506477032257   4: 0.017504692063281   8: 0.017503838944332   9: 0.017503521583326   2: 0.017503420873751   7: 0.017503249747914   3: 0.017503167196679 

test_16118        6: 0.636443902617995   3: 0.166661073280228   0: 0.115363785624697   5: 0.011651003829070   1: 0.011649091979101   7: 0.011648938760262   9: 0.011647194373807   8: 0.011645703108411   4: 0.011644894939771   2: 0.011644411486660 

test_16119        6: 0.708641687263137   5: 0.186883475791291   1: 0.013161673204938   0: 0.013093028459274   8: 0.013037021322763   4: 0.013036981409366   9: 0.013036643559487   2: 0.013036611136172   3: 0.013036555727297   7: 0.013036322126274 

test_16120        8: 0.450533540005846   6: 0.384661087870643   1: 0.020621101156291   5: 0.020618698132250   0: 0.020614437594406   2: 0.020598351161532   7: 0.020591912628079   9: 0.020588408446433   4: 0.020586280728419   3: 0.020586182276101 

test_16122        6: 0.506821842975730   3: 0.272341520648016   5: 0.063442157396587   9: 0.022634438282356   1: 0.022462574370740   0: 0.022460113709199   4: 0.022459539645329   7: 0.022459344877806   8: 0.022459236861145   2: 0.022459231233094 

test_16123        0: 0.523781819651885   6: 0.330879884045721   7: 0.027662092116058   1: 0.016811471527490   5: 0.016811419085866   9: 0.016811008223420   4: 0.016810786432508   8: 0.016810561045045   2: 0.016810516405464   3: 0.016810441466541 

test_16125        6: 0.667587054386306   9: 0.113098285901311   4: 0.096810284196964   1: 0.017514284249389   0: 0.017513309460039   5: 0.017502614510464   8: 0.017495614880527   7: 0.017493598546162   3: 0.017492588442563   2: 0.017492365426274 

test_16126        6: 0.575386870225913   8: 0.259968869560247   3: 0.038328023946538   7: 0.035050688141526   1: 0.015223362356421   5: 0.015215010368130   2: 0.015212426318134   0: 0.015209459181050   4: 0.015202890387079   9: 0.015202399514961 

test_16130        0: 0.509347556245121   4: 0.200785098369858   6: 0.192839310576211   1: 0.014673166049676   5: 0.013793738529513   2: 0.013723886077983   7: 0.013723884900429   9: 0.013718455757897   8: 0.013701052377675   3: 0.013693851115637 

test_16133        9: 0.857811563191731   6: 0.015800451565361   8: 0.015799237149162   5: 0.015799227888944   0: 0.015798768341782   4: 0.015798486661836   1: 0.015798338686115   2: 0.015798027758897   7: 0.015797964562907   3: 0.015797934193266 

test_16134        6: 0.684354141263187   3: 0.142888135869889   7: 0.021652606908052   8: 0.021590405405248   5: 0.021586928789184   9: 0.021586331547511   0: 0.021586029389793   4: 0.021585386722807   1: 0.021585290557903   2: 0.021584743546427 

test_16136        1: 0.770072630480496   6: 0.068869153012175   3: 0.020138684173694   5: 0.020135209021744   0: 0.020133669163025   8: 0.020130528824511   4: 0.020130384587554   9: 0.020130258433998   7: 0.020129833845913   2: 0.020129648456890 

test_16139        6: 0.657799179096453   1: 0.184299295846017   3: 0.066349398229080   0: 0.029795763312881   9: 0.013276924336185   5: 0.012780555253269   7: 0.008996204455817   2: 0.008905772657415   8: 0.008904957572970   4: 0.008891949239912 

test_16140        1: 0.510911591161072   6: 0.351627592112020   2: 0.031181268028507   0: 0.029602745685432   5: 0.012781566561138   9: 0.012780971075130   4: 0.012779957388391   8: 0.012779003221792   3: 0.012778958522233   7: 0.012776346244284 

test_16141        5: 0.460896391428614   3: 0.371374056429406   9: 0.046049967166998   6: 0.017434553038060   4: 0.017392830077769   0: 0.017381969092511   8: 0.017370025801639   1: 0.017369173745227   2: 0.017365592408534   7: 0.017365440811243 

test_16142        6: 0.683471260191427   7: 0.176206053811992   5: 0.017541006905261   2: 0.017540715519653   0: 0.017540694782854   4: 0.017540400639816   9: 0.017540221949260   1: 0.017540030890992   8: 0.017539872864445   3: 0.017539742444300 

test_16143        6: 0.804905806049979   5: 0.021677499587032   0: 0.021677390387468   1: 0.021677368110676   9: 0.021677305508402   8: 0.021677266181975   7: 0.021676912569609   3: 0.021676894582220   2: 0.021676892539787   4: 0.021676664482851 

test_16144        6: 0.620628373600413   2: 0.162687367313272   0: 0.107643971363809   7: 0.028872745056045   1: 0.014244305829307   8: 0.013234211213605   9: 0.013173052399861   3: 0.013172916378675   5: 0.013172024853580   4: 0.013171031991431 

test_16145        1: 0.555623768713764   3: 0.188944925878169   5: 0.104957075247582   6: 0.021501459945336   0: 0.021501140130740   9: 0.021496797274234   8: 0.021494702479044   7: 0.021493577722389   4: 0.021493448236350   2: 0.021493104372392 

test_16146        6: 0.544249702967473   9: 0.309379584071997   0: 0.055972296076453   8: 0.012972741986636   3: 0.012922218029156   2: 0.012907124256124   5: 0.012902790838022   1: 0.012902609733044   7: 0.012895707538091   4: 0.012895224503002 

test_16147        6: 0.651639077884876   1: 0.150632660084667   7: 0.084634034195909   5: 0.025677213268497   3: 0.014630967351910   9: 0.014563652774543   0: 0.014556280309975   2: 0.014555953509331   8: 0.014555244047398   4: 0.014554916572894 

test_16148        6: 0.531387816524647   9: 0.269630484262194   7: 0.053875250255317   0: 0.020733494806012   5: 0.020731520725262   1: 0.020728963532266   4: 0.020728674515698   8: 0.020728397174629   2: 0.020727849971023   3: 0.020727548232952 

test_16149        1: 0.384396314577095   6: 0.328942508185765   0: 0.101158719370282   3: 0.067669133707829   2: 0.038619405008889   5: 0.015854383364913   8: 0.015843003899847   4: 0.015838920141589   9: 0.015838845197958   7: 0.015838766545833 

test_16150        6: 0.707890707730828   1: 0.144306905739867   8: 0.018483386022349   0: 0.018475691895649   5: 0.018474974005607   9: 0.018474665419461   2: 0.018474211313295   3: 0.018473275395104   7: 0.018473233347880   4: 0.018472949129959 

test_16152        6: 0.440546852279554   8: 0.343944340971280   7: 0.086711002712846   1: 0.018418694375561   0: 0.018403149887890   4: 0.018399885726444   2: 0.018398222884447   5: 0.018396590417361   3: 0.018390813366418   9: 0.018390447378199 

test_16155        2: 0.493141916449532   6: 0.369579023597031   3: 0.017306401444452   9: 0.017168068253275   0: 0.017163100760677   1: 0.017135495778288   5: 0.017133906699577   4: 0.017124850214002   8: 0.017123717085716   7: 0.017123519717450 

test_16158        6: 0.720832843913032   0: 0.165040097463997   1: 0.025478995913977   7: 0.020771299976917   3: 0.011554859580317   8: 0.011527146184638   9: 0.011369573741748   5: 0.011182948369860   4: 0.011124535721199   2: 0.011117699134315 

test_16159        3: 0.511999661955863   0: 0.336113284335492   6: 0.019597760473291   5: 0.018930617998544   1: 0.018913569626391   8: 0.018910795444148   9: 0.018900566575645   4: 0.018879496761916   7: 0.018878709206304   2: 0.018875537622406 

test_16161        6: 0.722154311727630   1: 0.114871933390493   7: 0.061599997869927   0: 0.014497271944643   8: 0.014484528887271   5: 0.014478799699645   9: 0.014478749011406   4: 0.014478166055398   2: 0.014478158066101   3: 0.014478083347487 

test_16162        6: 0.775321282647945   4: 0.065434371425611   1: 0.035223044682298   0: 0.032729594283139   7: 0.015223738891078   5: 0.015215471933367   9: 0.015214765242298   8: 0.015213644372014   3: 0.015212086791247   2: 0.015211999731004 

test_16163        1: 0.358549500112615   5: 0.165206181147650   4: 0.150644535414480   6: 0.145399053274287   0: 0.123128916240995   8: 0.012632884819311   9: 0.011111587179043   7: 0.011109486546075   2: 0.011109269645610   3: 0.011108585619934 

test_16164        6: 0.780046272543242   8: 0.096266554214874   7: 0.015472146461755   9: 0.015460591940269   5: 0.015459934038424   3: 0.015459574907339   0: 0.015459565614382   1: 0.015458561263427   2: 0.015458441660654   4: 0.015458357355633 

test_16166        2: 0.438841777302512   6: 0.365996274110215   7: 0.074955681928120   0: 0.022538620814732   5: 0.016343817884425   1: 0.016294925023304   3: 0.016265921236931   9: 0.016254962846590   8: 0.016254452503711   4: 0.016253566349461 

test_16170        6: 0.702599788339845   5: 0.101113004351408   7: 0.083580792989565   1: 0.016103325710022   0: 0.016102179744579   4: 0.016100846115629   9: 0.016100256574143   3: 0.016099982851319   2: 0.016099918257815   8: 0.016099905065675 

test_16171        6: 0.829111771344295   0: 0.061644209206840   7: 0.021415212533697   5: 0.018712716786634   3: 0.011704466879527   2: 0.011488999467881   1: 0.011483281908798   4: 0.011480321875338   9: 0.011479719032423   8: 0.011479300964566 

test_16172        9: 0.725791952938923   5: 0.030477379545520   4: 0.030477057154202   6: 0.030471518191515   8: 0.030465894607130   0: 0.030464191258879   3: 0.030463981031263   1: 0.030462850694515   7: 0.030462721594480   2: 0.030462452983574 

test_16173        3: 0.632129792967823   0: 0.129538173090659   6: 0.122980432354935   4: 0.016483175276106   5: 0.016480296461761   2: 0.016479901307963   1: 0.016478144165032   9: 0.016477660111903   8: 0.016477163947661   7: 0.016475260316157 

test_16175        6: 0.509204254791958   5: 0.298251434678506   9: 0.083330006469728   3: 0.015605237964772   4: 0.015602830462826   1: 0.015602059099061   8: 0.015601817417084   0: 0.015601427550420   2: 0.015600528829799   7: 0.015600402735846 

test_16176        4: 0.312210750178440   1: 0.303401368671872   6: 0.278521568733074   9: 0.020728492981264   0: 0.014195960285844   2: 0.014191092843487   5: 0.014188927044522   7: 0.014187875466023   8: 0.014187587666179   3: 0.014186376129295 

test_16177        6: 0.616023072172571   9: 0.271303254908628   8: 0.014126226223482   0: 0.014125477866762   1: 0.014114278845585   5: 0.014073746894662   7: 0.014058587166645   4: 0.014058556431698   3: 0.014058445315195   2: 0.014058354174772 

test_16179        6: 0.499710674998891   8: 0.329862056250529   9: 0.064454848913571   0: 0.015160534645460   4: 0.015155844220320   5: 0.015144484212654   7: 0.015139245024733   1: 0.015124686342323   2: 0.015124536567301   3: 0.015123088824219 

test_16180        6: 0.600843807372307   7: 0.236716221668511   0: 0.020307296708419   1: 0.020306118888245   8: 0.020306089320119   9: 0.020305105575277   4: 0.020304779834320   5: 0.020304347500144   2: 0.020303176934816   3: 0.020303056197841 

test_16185        6: 0.613414720818077   0: 0.236801989859420   5: 0.018726568206968   1: 0.018725209221608   8: 0.018722632113310   7: 0.018722392490067   2: 0.018722171712307   9: 0.018721608089123   4: 0.018721491312069   3: 0.018721216177050 

test_16188        9: 0.675273469897106   6: 0.158916256892269   8: 0.020732471395176   5: 0.020726227377389   3: 0.020726045763722   0: 0.020725866388030   1: 0.020725742909628   4: 0.020724990887878   7: 0.020724493909702   2: 0.020724434579100 

test_16189        6: 0.488142695219106   1: 0.380709019713862   8: 0.016394937812509   0: 0.016394837730864   9: 0.016393650037143   5: 0.016393500022181   7: 0.016393049641084   3: 0.016392820164415   2: 0.016392744931618   4: 0.016392744727219 

test_16190        6: 0.656229124752531   1: 0.150561828661812   0: 0.076318750813532   7: 0.059874133467455   9: 0.015078580398143   3: 0.008397919863092   4: 0.008396878922207   5: 0.008382524653384   8: 0.008380292300639   2: 0.008379966167205 

test_16193        7: 0.789637190871859   6: 0.023387195802737   5: 0.023376506105643   1: 0.023375793842242   0: 0.023371671686747   8: 0.023371134327551   9: 0.023370867343873   3: 0.023370504791717   4: 0.023369702683604   2: 0.023369432544026 

test_16194        6: 0.800701037807968   1: 0.022148540407502   5: 0.022146839709621   4: 0.022144647184224   7: 0.022143804830060   0: 0.022143795519467   3: 0.022143688569409   9: 0.022143017141394   8: 0.022142770519481   2: 0.022141858310875 

test_16195        6: 0.867071827505089   0: 0.023518323313465   7: 0.023193275147181   2: 0.012879825565512   1: 0.012231560914457   5: 0.012221702496384   8: 0.012221674251290   9: 0.012221103076511   4: 0.012220449135436   3: 0.012220258594675 

test_16196        6: 0.858800267192534   8: 0.027923183633329   0: 0.014175044592215   1: 0.014159038304726   5: 0.014158397215327   3: 0.014157523537275   9: 0.014157430896158   4: 0.014156446082374   2: 0.014156355933444   7: 0.014156312612619 

test_16197        6: 0.774430846858976   9: 0.065478367596860   4: 0.020031930042306   2: 0.020026450379608   1: 0.020020971709951   5: 0.020004994628852   0: 0.020003250110849   7: 0.020001521968782   8: 0.020001166292492   3: 0.020000500411323 

test_16200        6: 0.609798719482904   1: 0.185233072349444   0: 0.130672513405118   3: 0.027878801869586   5: 0.007755018883537   8: 0.007734802122260   7: 0.007731888646410   9: 0.007731866098623   2: 0.007731671876316   4: 0.007731645265802 

test_16201        6: 0.865078478833972   4: 0.015025621436752   8: 0.014987768926068   0: 0.014987663678355   9: 0.014987368124895   7: 0.014986832047510   2: 0.014986747781374   3: 0.014986706866604   1: 0.014986568160108   5: 0.014986244144362 

test_16202        5: 0.408812711885220   7: 0.371409989696715   0: 0.027480500612363   4: 0.027477972167757   6: 0.027471346438272   8: 0.027470562107181   1: 0.027469435702407   9: 0.027469423772293   2: 0.027469142041857   3: 0.027468915575936 

test_16203        6: 0.577153188241011   1: 0.266145143043220   5: 0.019592438134992   0: 0.019591130369682   3: 0.019587411027568   4: 0.019587363834221   9: 0.019586057736284   7: 0.019585936685337   2: 0.019585810008042   8: 0.019585520919642 

test_16206        5: 0.541109748587856   2: 0.268880081807836   6: 0.023791669929209   0: 0.023759939025046   9: 0.023745287890012   4: 0.023745180156799   1: 0.023744790696260   7: 0.023742010874008   8: 0.023741040200655   3: 0.023740250832317 

test_16207        5: 0.396612851119137   6: 0.329172061655628   3: 0.162163308765609   9: 0.016009285017311   4: 0.016008805936627   0: 0.016007385172888   1: 0.016007310910249   8: 0.016007171151150   2: 0.016005950023731   7: 0.016005870247670 

test_16210        6: 0.803295113365136   5: 0.021864073604710   0: 0.021859274442662   1: 0.021858420562319   4: 0.021857206169812   2: 0.021853899955487   3: 0.021853745087217   8: 0.021852989200266   9: 0.021852864943832   7: 0.021852412668558 

test_16211        0: 0.814455054285044   9: 0.029103665503835   1: 0.028415344699508   5: 0.018866996036475   6: 0.018735463989511   7: 0.018110767736460   2: 0.018090410146149   4: 0.018079949659856   3: 0.018071248680495   8: 0.018071099262667 

test_16212        6: 0.458655476700411   8: 0.389652300397327   9: 0.019054840834149   5: 0.018951741302620   1: 0.018949610594544   4: 0.018948212270158   2: 0.018947438096507   0: 0.018947150177658   3: 0.018946872192508   7: 0.018946357434117 

test_16213        6: 0.517450634643320   0: 0.227749468357632   8: 0.142676041331311   1: 0.016065315284624   5: 0.016011558644887   4: 0.016010668150356   9: 0.016009807322955   7: 0.016009291405835   3: 0.016008885985481   2: 0.016008328873599 

test_16214        6: 0.774479403086187   0: 0.082553126788766   1: 0.066254254693945   4: 0.011047651233497   7: 0.010954416639585   9: 0.010943684957205   5: 0.010942845306166   2: 0.010942791726583   8: 0.010941326890503   3: 0.010940498677562 

test_16215        0: 0.509305408158824   4: 0.200788598627068   6: 0.192858060748536   1: 0.014693192203434   5: 0.013793652495355   2: 0.013723887092616   7: 0.013723887050171   9: 0.013718411763336   8: 0.013701051499371   3: 0.013693850361292 

test_16216        0: 0.727104508231644   1: 0.179516366733497   6: 0.011679141089154   5: 0.011678491495068   9: 0.011672220719004   4: 0.011671175162194   3: 0.011669944481864   2: 0.011669773750533   7: 0.011669254119255   8: 0.011669124217788 

test_16219        5: 0.422227156606348   7: 0.336003912096000   4: 0.064115234954115   8: 0.057516521971689   1: 0.020038197290427   2: 0.020032753391317   9: 0.020031847263841   0: 0.020016499046937   6: 0.020010598788531   3: 0.020007278590794 

test_16221        5: 0.784355764913740   4: 0.023964024749863   7: 0.023962601935014   6: 0.023960464796117   8: 0.023960174869240   9: 0.023959844239110   0: 0.023959733982223   1: 0.023959198091791   2: 0.023959100649993   3: 0.023959091772909 

test_16223        6: 0.719977252933807   5: 0.031121268481489   1: 0.031117445728932   0: 0.031114761440251   4: 0.031114720296632   7: 0.031112101544279   9: 0.031111157732055   8: 0.031110980758241   2: 0.031110818355884   3: 0.031109492728430 

test_16225        6: 0.430944175901081   0: 0.427809146699163   1: 0.030150761863158   3: 0.015883300698202   8: 0.015871110482228   5: 0.015868985923619   9: 0.015868650827863   2: 0.015868082079612   4: 0.015867897476141   7: 0.015867888048934 

test_16226        6: 0.910730016329895   8: 0.013515213390026   5: 0.009805249281090   1: 0.009594253730483   3: 0.009489021340823   4: 0.009432563567657   0: 0.009415313475359   2: 0.009410023939530   7: 0.009308244038651   9: 0.009300100906486 

test_16228        1: 0.324650803523031   5: 0.268528562230107   6: 0.199356584969052   4: 0.029646409964998   0: 0.029643422814086   8: 0.029635704875128   2: 0.029634971994476   7: 0.029634601430709   3: 0.029634594020236   9: 0.029634344178177 

test_16230        5: 0.460672437649669   0: 0.356251377341217   4: 0.022889795389634   1: 0.022888974829196   6: 0.022883726344741   8: 0.022883061236182   7: 0.022882959390937   9: 0.022882893542199   2: 0.022882408067505   3: 0.022882366208720 

test_16232        1: 0.441473913704604   3: 0.377119914353519   5: 0.022758799738121   6: 0.022675666544121   0: 0.022672503995917   7: 0.022668907538722   4: 0.022658568030634   8: 0.022657612578054   2: 0.022657443251832   9: 0.022656670264475 

test_16233        9: 0.474959524944628   1: 0.328078338722574   2: 0.065338298573859   0: 0.018825173423531   6: 0.018813783346833   5: 0.018809782447122   7: 0.018795957136782   4: 0.018795180512366   8: 0.018792134962577   3: 0.018791825929729 

test_16234        8: 0.511691088072822   5: 0.303269461804017   6: 0.023144097826252   4: 0.023131402856655   0: 0.023127991224607   9: 0.023127908138823   2: 0.023127689335643   1: 0.023127265706648   7: 0.023126549863587   3: 0.023126545170946 

test_16236        4: 0.397158954546976   6: 0.252273344528767   0: 0.208880102653455   8: 0.020721834155789   1: 0.020162900593044   9: 0.020161946503386   2: 0.020161153174230   5: 0.020160703559949   7: 0.020160104294731   3: 0.020158955989672 

test_16238        6: 0.377097423978264   4: 0.279141401500657   1: 0.244390392204982   8: 0.019857517586723   7: 0.019275309239904   2: 0.012143824838590   5: 0.012029883993264   0: 0.012025923002139   3: 0.012021758033981   9: 0.012016565621496 

test_16241        6: 0.561674632387392   1: 0.340607209450496   0: 0.012278084559620   5: 0.012237532198661   3: 0.012201576248140   4: 0.012200371125797   7: 0.012200217841479   8: 0.012200176654964   9: 0.012200160605109   2: 0.012200038928342 

test_16243        0: 0.699017073006095   5: 0.033450540839719   4: 0.033445151031586   9: 0.033443677342039   1: 0.033443348663325   8: 0.033441473589758   6: 0.033440685822157   2: 0.033439705627681   7: 0.033439381721385   3: 0.033438962356254 

test_16244        4: 0.636911959704191   8: 0.190633600102327   5: 0.021575614135434   0: 0.021572989302336   1: 0.021556996282541   6: 0.021551027131417   3: 0.021549771669323   9: 0.021549709863447   2: 0.021549238510122   7: 0.021549093298861 

test_16246        5: 0.704187229586646   9: 0.116872843763600   0: 0.022381667109149   6: 0.022381043077157   8: 0.022372101074582   3: 0.022364641732795   4: 0.022360842793736   1: 0.022360500312823   7: 0.022359742632071   2: 0.022359387917441 

test_16247        6: 0.809610240161318   0: 0.021171341987366   5: 0.021158201852135   1: 0.021153563426809   4: 0.021152360434876   9: 0.021151437918330   7: 0.021151412207448   3: 0.021150715445201   2: 0.021150702153398   8: 0.021150024413119 

test_16248        6: 0.593663798124264   8: 0.272129726264687   0: 0.017601965133294   9: 0.016805171418384   7: 0.016693482830168   5: 0.016622059548778   1: 0.016621698462074   4: 0.016621602201845   3: 0.016620449445271   2: 0.016620046571234 

test_16250        6: 0.613152685178117   9: 0.228085650129766   1: 0.037124579510827   5: 0.017391772535899   8: 0.017375069965592   2: 0.017374861890239   0: 0.017374572493178   4: 0.017373886544307   7: 0.017373806472796   3: 0.017373115279279 

test_16251        9: 0.558345116841280   6: 0.291181062765443   8: 0.018822088554590   1: 0.018809654455669   0: 0.018808606494273   5: 0.018807973889019   7: 0.018806972355899   4: 0.018806478600480   3: 0.018806053935656   2: 0.018805992107691 

test_16252        2: 0.247866062487287   6: 0.245908890764592   5: 0.187993863585727   1: 0.181712390125909   3: 0.063723006681486   0: 0.014761216275861   4: 0.014540647814926   8: 0.014504006836513   7: 0.014495337382627   9: 0.014494578045072 

test_16255        0: 0.795045909834667   6: 0.022779612032402   8: 0.022772714708491   5: 0.022772714238906   1: 0.022772441317296   9: 0.022771929514851   7: 0.022771603988814   4: 0.022771252125083   2: 0.022771102601296   3: 0.022770719638194 

test_16256        6: 0.689500882026059   1: 0.209231131402218   0: 0.012660103217269   5: 0.012658856268408   3: 0.012658740570043   8: 0.012658411094162   9: 0.012658033997096   4: 0.012657968484290   7: 0.012657947436635   2: 0.012657925503821 

test_16257        6: 0.750100081203548   1: 0.148062816949260   5: 0.023011679158940   4: 0.011324626308791   8: 0.011252063646253   0: 0.011250701226395   9: 0.011249779781695   7: 0.011249479639262   3: 0.011249421202487   2: 0.011249350883368 

test_16258        9: 0.397899898352127   0: 0.356348876878269   6: 0.110064474014456   7: 0.019394065501489   5: 0.019386170812232   1: 0.019385559482033   4: 0.019384347859645   2: 0.019379438049006   8: 0.019378714854587   3: 0.019378454196156 

test_16260        5: 0.670033577265050   4: 0.036667256122232   8: 0.036662629310462   3: 0.036662622163337   2: 0.036662550420924   1: 0.036662484013596   0: 0.036662412346797   7: 0.036662256083682   9: 0.036662179825803   6: 0.036662032448117 

test_16262        5: 0.671943845827254   2: 0.176623766307265   6: 0.018973076247831   1: 0.018925900450908   0: 0.018925102114223   9: 0.018921955073530   4: 0.018921768612256   7: 0.018921728916771   3: 0.018921490013735   8: 0.018921366436227 

test_16263        5: 0.758433924206136   4: 0.026843449064132   6: 0.026842597828287   8: 0.026840984683782   0: 0.026840142738372   1: 0.026840114835518   9: 0.026839825137443   7: 0.026839811048624   3: 0.026839650715358   2: 0.026839499742348 

test_16264        6: 0.463528466860194   5: 0.236299594300009   9: 0.194987375852315   0: 0.026760131375348   1: 0.013089797939390   8: 0.013067404520625   4: 0.013067272905304   7: 0.013067015580252   2: 0.013066512428917   3: 0.013066428237647 

test_16265        6: 0.832091570547737   8: 0.018658131183477   5: 0.018656843287148   9: 0.018656422116405   7: 0.018656373503385   0: 0.018656299256792   1: 0.018656270198032   2: 0.018656109442088   3: 0.018656072975566   4: 0.018655907489371 

test_16266        5: 0.503145079078825   2: 0.179640176674594   0: 0.164660529256624   1: 0.021799007077820   4: 0.021797783415970   8: 0.021791658855712   3: 0.021791544196197   6: 0.021791481881511   9: 0.021791452572069   7: 0.021791286990679 

test_16268        6: 0.467495605304430   0: 0.453604273495247   1: 0.009886912362769   4: 0.009863318423920   7: 0.009859577235148   9: 0.009858600271709   8: 0.009858243719783   5: 0.009857889807014   2: 0.009857803095384   3: 0.009857776284595 

test_16269        5: 0.723078832277141   4: 0.030772883345481   8: 0.030768968489918   6: 0.030768737120824   9: 0.030768634908541   3: 0.030768444126348   2: 0.030768416395368   0: 0.030768399458797   7: 0.030768345876396   1: 0.030768338001186 

test_16270        6: 0.759489981604012   2: 0.099546679690224   5: 0.017621356039831   9: 0.017620854561961   0: 0.017620668145733   8: 0.017620589750131   1: 0.017620449611090   7: 0.017620199823871   4: 0.017619782888334   3: 0.017619437884811 

test_16271        6: 0.496835479431823   5: 0.336026740324113   3: 0.065457501748663   9: 0.015353974544745   8: 0.014439409303033   0: 0.014412436542564   7: 0.014390501136274   1: 0.014381938550640   2: 0.014351250682993   4: 0.014350767735151 

test_16274        9: 0.763598076453773   6: 0.026273639066651   5: 0.026272709652452   8: 0.026270401414389   0: 0.026267773390829   1: 0.026265404781669   4: 0.026264284712760   2: 0.026263688428060   7: 0.026262700000676   3: 0.026261322098742 

test_16275        5: 0.829341722053208   4: 0.018963786880322   6: 0.018962733247728   0: 0.018962153236999   1: 0.018961830039374   8: 0.018961671507557   9: 0.018961659716847   7: 0.018961492539007   3: 0.018961490926307   2: 0.018961459852652 

test_16277        1: 0.464799567521228   5: 0.243683303082640   7: 0.146241597232883   0: 0.054128731156449   6: 0.015239129516485   9: 0.015187028206952   8: 0.015182360603677   4: 0.015179734067021   2: 0.015179561244256   3: 0.015178987368409 

test_16278        0: 0.773067533831304   5: 0.130830355874474   7: 0.012024306954038   1: 0.012016389732110   6: 0.012015994647974   4: 0.012009687557531   9: 0.012009360251092   8: 0.012008961835767   2: 0.012008820264108   3: 0.012008589051601 

test_16279        6: 0.546651590897151   8: 0.283046990284854   5: 0.021291988582584   7: 0.021288718887816   1: 0.021287967808940   0: 0.021287271064547   3: 0.021286998524321   9: 0.021286292304819   4: 0.021286229125557   2: 0.021285952519412 

test_16281        6: 0.495707719390433   9: 0.288064574445303   1: 0.027030306437187   0: 0.027029818500583   5: 0.027028646761954   7: 0.027028593260861   8: 0.027028196045368   3: 0.027027577787095   2: 0.027027369574251   4: 0.027027197796964 

test_16282        6: 0.502451421339627   0: 0.365135461169822   9: 0.016553034813154   5: 0.016552551667069   8: 0.016552340610118   1: 0.016551773976574   7: 0.016551107029144   4: 0.016550977450951   2: 0.016550687252639   3: 0.016550644690902 

test_16283        5: 0.405393550796072   8: 0.367650235065621   1: 0.084804353375817   4: 0.020322433098994   6: 0.020312799931494   0: 0.020304392427765   7: 0.020303342546824   2: 0.020303304983116   9: 0.020302941527111   3: 0.020302646247187 

test_16284        5: 0.832932891848228   4: 0.018566095115093   6: 0.018562898516276   1: 0.018562703531027   8: 0.018562675653185   9: 0.018562629413910   0: 0.018562599123367   2: 0.018562510602456   7: 0.018562501054415   3: 0.018562495142043 

test_16285        9: 0.805109880961006   6: 0.021659206462559   8: 0.021656635628073   5: 0.021655168062638   0: 0.021654414080582   1: 0.021654259482805   2: 0.021653401098076   4: 0.021652572916638   7: 0.021652377190930   3: 0.021652084116694 

test_16286        4: 0.497898361284425   6: 0.342369400887427   9: 0.048010277695079   0: 0.015987192437219   1: 0.015965794950608   5: 0.015957877762744   7: 0.015955359671764   2: 0.015953842866762   8: 0.015951829516721   3: 0.015950062927250 

test_16287        0: 0.625802511328908   3: 0.189843054491545   7: 0.023080927397868   1: 0.023041689244799   2: 0.023041460241193   8: 0.023039941450410   6: 0.023039773010067   5: 0.023039024973333   4: 0.023035865652848   9: 0.023035752209030 

test_16288        9: 0.426591065819300   5: 0.367389784591415   8: 0.025886508195279   3: 0.025749695314917   4: 0.025738362833654   0: 0.025735735536368   6: 0.025731637457252   1: 0.025727485024831   2: 0.025724997237763   7: 0.025724727989222 

test_16289        5: 0.679908643623096   6: 0.154995591007105   7: 0.020667811898679   0: 0.020637237778880   1: 0.020634526758309   2: 0.020633467691873   9: 0.020632288692600   3: 0.020631626891550   8: 0.020629476569558   4: 0.020629329088349 

test_16291        8: 0.475214615196400   5: 0.255990750938953   4: 0.033610070836751   6: 0.033598622056109   0: 0.033598387431954   9: 0.033598292270105   1: 0.033598031851222   2: 0.033597541940978   3: 0.033597005480165   7: 0.033596681997364 

test_16294        5: 0.410699277549656   8: 0.387576147660507   6: 0.025218975709917   4: 0.025218003882353   9: 0.025215945182794   0: 0.025214978296356   1: 0.025214722488147   7: 0.025214174678049   2: 0.025214160251578   3: 0.025213614300643 

test_16297        5: 0.605027322981796   2: 0.204787705237796   4: 0.023775691798877   7: 0.023773027013106   0: 0.023773005607220   1: 0.023772942567005   9: 0.023772660166774   6: 0.023772637771624   3: 0.023772575212150   8: 0.023772431643651 

test_16298        9: 0.731136825082688   6: 0.029886713298734   8: 0.029875013423301   7: 0.029874796928781   0: 0.029874461153133   1: 0.029871638667556   2: 0.029870299112084   5: 0.029870284295648   3: 0.029870248531822   4: 0.029869719506253 

test_16299        1: 0.436253680790310   5: 0.334495685482960   9: 0.028681536681921   4: 0.028661441313343   8: 0.028651767000264   3: 0.028651429480083   2: 0.028651250029057   0: 0.028651218234716   7: 0.028651021700060   6: 0.028650969287286 

test_16300        4: 0.407484826655898   5: 0.404674440342536   1: 0.023481859290951   0: 0.023481323140022   3: 0.023481037180941   6: 0.023480978629316   2: 0.023479057436162   9: 0.023478992063816   8: 0.023478779237537   7: 0.023478706022823 

test_16301        9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

test_16302        5: 0.563779335808792   8: 0.214229958722808   1: 0.027753315422430   6: 0.027752915444146   3: 0.027752334308642   0: 0.027750107877086   9: 0.027746023233517   4: 0.027745828096283   2: 0.027745115719388   7: 0.027745065366908 

test_16303        5: 0.722398257232811   2: 0.030852004479417   1: 0.030847564966202   4: 0.030845137360788   6: 0.030844738741667   8: 0.030844306289988   0: 0.030843504033226   7: 0.030841958032398   3: 0.030841347227604   9: 0.030841181635899 

test_16304        6: 0.408326450401131   2: 0.326830824547409   4: 0.101666111599327   1: 0.023317654129928   5: 0.023317436727203   0: 0.023310852185846   9: 0.023309466400318   3: 0.023309046811847   8: 0.023306382906829   7: 0.023305774290161 

test_16307        1: 0.812480477990929   8: 0.021122227349342   6: 0.020831539018609   7: 0.020800646795421   5: 0.020797731082785   0: 0.020796998518676   4: 0.020794496905349   9: 0.020792683591683   2: 0.020791711688791   3: 0.020791487058414 

test_16310        6: 0.563613908766011   9: 0.305527227760725   5: 0.016360479722078   0: 0.016358284078451   4: 0.016358091452531   1: 0.016357092600238   8: 0.016356567729787   2: 0.016356259800538   7: 0.016356239685952   3: 0.016355848403689 

test_16311        8: 0.460599271546687   5: 0.362697418938213   6: 0.022101428377288   1: 0.022096913845445   0: 0.022092257138556   9: 0.022084543245497   7: 0.022083619485876   3: 0.022083613364545   4: 0.022081639609391   2: 0.022079294448502 

test_16312        6: 0.364547495607720   8: 0.294543524162315   5: 0.190757213949036   0: 0.048596183983342   2: 0.016974329946836   4: 0.016918812523796   1: 0.016916231603154   9: 0.016915919684868   7: 0.016915354032293   3: 0.016914934506641 

test_16314        6: 0.772335127412903   5: 0.047650015690259   4: 0.022554450385690   2: 0.022511349357836   3: 0.022496895020558   8: 0.022491892350935   7: 0.022490375389150   0: 0.022490263338317   9: 0.022489871086098   1: 0.022489759968254 

test_16315        5: 0.704755481542523   1: 0.093229487731331   8: 0.065576027466117   6: 0.019505786507839   0: 0.019491420763097   2: 0.019489667561602   9: 0.019488985423587   4: 0.019488634064192   7: 0.019487424500092   3: 0.019487084439620 

test_16316        6: 0.829592045345003   0: 0.018937141781336   5: 0.018936074612583   1: 0.018933955503746   4: 0.018933689656226   3: 0.018933580798295   8: 0.018933455649524   2: 0.018933403005112   9: 0.018933349600133   7: 0.018933304048043 

test_16317        4: 0.581068603467493   2: 0.208196829975396   5: 0.026349512552377   0: 0.026343952187979   7: 0.026340561002268   6: 0.026340371395117   1: 0.026340266249353   9: 0.026340036508807   3: 0.026340006616382   8: 0.026339860044830 

test_16318        5: 0.429683510416477   6: 0.360952016956896   0: 0.099925175190297   1: 0.015663897925388   3: 0.015649664586307   7: 0.015625193331272   9: 0.015625188006361   8: 0.015625159775191   4: 0.015625121441376   2: 0.015625072370434 

test_16319        5: 0.611411656482777   0: 0.198066786033841   4: 0.023818630850881   6: 0.023816025084689   8: 0.023815783647903   9: 0.023814951332242   1: 0.023814314165652   2: 0.023814040511556   3: 0.023813989453556   7: 0.023813822436901 

test_16320        8: 0.405789468233107   6: 0.304703782303725   0: 0.143816481460928   7: 0.040136718679134   1: 0.017594500738159   5: 0.017593925147419   4: 0.017591693375947   3: 0.017591260090626   2: 0.017591119591402   9: 0.017591050379552 

test_16324        5: 0.819945234473831   6: 0.020007407261058   4: 0.020007396960571   8: 0.020006201424522   9: 0.020006043731710   7: 0.020005767539317   0: 0.020005616756596   1: 0.020005551289562   2: 0.020005435948132   3: 0.020005344614701 

test_16327        6: 0.696097842343859   3: 0.102974716649914   8: 0.069062039898184   5: 0.018838979636325   0: 0.018838844763779   1: 0.018838299806365   7: 0.018837720259739   4: 0.018837234909166   2: 0.018837170937586   9: 0.018837150795081 

test_16331        8: 0.607180379851784   2: 0.150331954213094   6: 0.123180059786110   9: 0.017045350878965   0: 0.017045230058295   1: 0.017044614263010   5: 0.017044008049452   7: 0.017042942594934   4: 0.017042795668732   3: 0.017042664635624 

test_16332        3: 0.426582181360179   1: 0.246056817119985   6: 0.186643996277285   8: 0.063272918679671   9: 0.015906958767495   0: 0.012362586785919   7: 0.012301646347942   2: 0.012297305816610   5: 0.012289742381981   4: 0.012285846462932 

test_16336        5: 0.529895759589074   6: 0.308745226259678   0: 0.020178476846651   1: 0.020170268092186   4: 0.020169107038959   9: 0.020168744995189   8: 0.020168318660998   2: 0.020168212177032   7: 0.020168087669541   3: 0.020167798670693 

test_16337        5: 0.691913777141308   6: 0.106385312001309   4: 0.025218075716457   0: 0.025213897486933   7: 0.025213826098242   9: 0.025211321870854   8: 0.025211239179239   1: 0.025211121995204   3: 0.025210727805420   2: 0.025210700705033 

test_16339        6: 0.514865622171898   5: 0.344335454684098   1: 0.017601429538107   9: 0.017601289971588   4: 0.017600650157190   0: 0.017600462293149   3: 0.017599627111845   8: 0.017598736328165   2: 0.017598399057318   7: 0.017598328686641 

test_16342        5: 0.745513677539197   6: 0.112342553114343   8: 0.017790909887149   4: 0.017767151557552   1: 0.017766351663111   3: 0.017764207325021   2: 0.017763848641305   7: 0.017763801288517   9: 0.017763758890622   0: 0.017763740093184 

test_16343        0: 0.659914604543113   1: 0.212033775526540   4: 0.016014339065550   5: 0.016012944311314   6: 0.016007792718374   8: 0.016003741197687   9: 0.016003630437001   7: 0.016003263392074   3: 0.016003000989151   2: 0.016002907819194 

test_16346        4: 0.753659840595078   8: 0.088033085151984   5: 0.019794023724498   9: 0.019789249647444   6: 0.019788283759344   0: 0.019787423141858   2: 0.019787066389727   3: 0.019787043423379   7: 0.019787007000623   1: 0.019786977166065 

test_16347        5: 0.826687297567150   0: 0.019285163335326   4: 0.019272990574844   8: 0.019254217491174   6: 0.019251429855285   7: 0.019250246733341   3: 0.019249942162938   2: 0.019249835756932   9: 0.019249579204951   1: 0.019249297318060 

test_16348        5: 0.793835189024424   4: 0.022913343904973   8: 0.022906778549294   6: 0.022906617230817   7: 0.022906436203384   9: 0.022906425232741   0: 0.022906356289968   3: 0.022906347886682   2: 0.022906278195346   1: 0.022906227482372 

test_16350        4: 0.646812833925813   5: 0.154939486093574   8: 0.024790197814990   6: 0.024780911503523   0: 0.024780182899598   1: 0.024780029816136   3: 0.024779234035818   9: 0.024779154315369   7: 0.024778987039328   2: 0.024778982555850 

test_16354        6: 0.336619973125094   8: 0.267150257128584   1: 0.223856938970964   7: 0.084286488368919   2: 0.023359643453478   0: 0.013396173664870   5: 0.012847693520328   4: 0.012828265269066   3: 0.012827546475246   9: 0.012827020023452 

test_16357        6: 0.906208230011387   4: 0.010459677826918   1: 0.010427631929025   5: 0.010415862450562   0: 0.010415288758712   9: 0.010414771522755   3: 0.010414693072626   8: 0.010414657362517   2: 0.010414643132620   7: 0.010414543932880 

test_16359        6: 0.426224769773702   1: 0.284209558143297   0: 0.197420095692995   7: 0.013198731744489   5: 0.013161196818307   8: 0.013157383418460   2: 0.013157185161997   9: 0.013157183921486   4: 0.013156955889776   3: 0.013156939435492 

test_16360        5: 0.703565546311176   0: 0.149059060353145   9: 0.018435874563473   4: 0.018422481275077   6: 0.018420127557506   1: 0.018419557077160   8: 0.018419417016717   7: 0.018419409348885   2: 0.018419279327120   3: 0.018419247169741 

test_16362        7: 0.812466063898006   6: 0.020850945872421   5: 0.020841170850639   1: 0.020837174146427   8: 0.020835554512927   0: 0.020834682592874   2: 0.020834654829053   4: 0.020833401035664   3: 0.020833358626440   9: 0.020832993635550 

test_16363        5: 0.501468990647836   4: 0.326467947732671   6: 0.021510184762904   8: 0.021508712865357   0: 0.021508027197380   9: 0.021508002060147   1: 0.021507656266803   2: 0.021507071138884   7: 0.021506746707830   3: 0.021506660620187 

test_16365        5: 0.727923242642086   9: 0.115322773313826   6: 0.019595843991665   4: 0.019595680373179   8: 0.019595310899471   0: 0.019594794971011   1: 0.019594419968090   2: 0.019592666439999   7: 0.019592655841981   3: 0.019592611558691 

test_16366        6: 0.884811839356424   3: 0.012802121761802   1: 0.012798898662275   8: 0.012798327323479   0: 0.012798305898411   7: 0.012798246716724   2: 0.012798146379146   9: 0.012798102324310   5: 0.012798044471774   4: 0.012797967105656 

test_16367        6: 0.488541332217097   5: 0.259322369401303   0: 0.083653651613370   8: 0.066018240310443   2: 0.035542151703821   4: 0.020304253886465   1: 0.011738300312625   9: 0.011627100305943   7: 0.011626346582583   3: 0.011626253666351 

test_16369        5: 0.451834771712477   6: 0.367263317179195   0: 0.049079331372588   4: 0.018833873312339   1: 0.018832805687546   9: 0.018831637842984   7: 0.018831382934611   8: 0.018831318010873   3: 0.018830863394360   2: 0.018830698553027 

test_16370        6: 0.582917361916472   1: 0.265681938220312   0: 0.030100191706015   9: 0.017370466722747   4: 0.017335797815784   5: 0.017331509350478   7: 0.017316951138299   3: 0.017316524979401   2: 0.017314689078035   8: 0.017314569072456 

test_16371        5: 0.618628899175250   9: 0.229950470266872   4: 0.018935991205620   6: 0.018928846617574   1: 0.018928302149610   0: 0.018927087001039   7: 0.018925366228465   8: 0.018925293748074   2: 0.018924882385617   3: 0.018924861221880 

test_16372        5: 0.724060812361650   6: 0.030665812328716   4: 0.030662260219957   1: 0.030660569726533   8: 0.030660411655638   0: 0.030659475708678   3: 0.030658484265961   2: 0.030657540536608   7: 0.030657424065260   9: 0.030657209131000 

test_16374        5: 0.433177349599901   1: 0.385775217196740   6: 0.022635353188025   4: 0.022632373067403   9: 0.022631253848621   8: 0.022630378625056   7: 0.022630371722390   0: 0.022630282845389   3: 0.022628723047385   2: 0.022628696859090 

test_16376        5: 0.457901538642628   7: 0.335138505280394   4: 0.025876182216991   1: 0.025869933763689   8: 0.025869729273317   9: 0.025869052033016   3: 0.025868940565038   2: 0.025868843257313   0: 0.025868650233549   6: 0.025868624734066 

test_16377        5: 0.665701418299024   1: 0.171986458534630   6: 0.020299995905331   4: 0.020290845921302   9: 0.020287035735272   7: 0.020287005062668   8: 0.020286923902096   3: 0.020286869814154   2: 0.020286785784832   0: 0.020286661040691 

test_16379        5: 0.597661620580947   6: 0.252554965839161   1: 0.018727199540331   0: 0.018725462789151   9: 0.018722814311727   2: 0.018721750995336   4: 0.018721726371055   7: 0.018721631726562   8: 0.018721544199052   3: 0.018721283646678 

test_16380        5: 0.791573018397838   4: 0.023162689165407   6: 0.023160620526536   0: 0.023158801809675   8: 0.023158452562127   9: 0.023157688965565   1: 0.023157608074393   7: 0.023157507590879   3: 0.023156854475759   2: 0.023156758431823 

test_16383        8: 0.715388407290149   6: 0.114404694070222   2: 0.046102427031751   0: 0.017735992299793   9: 0.017731365638216   1: 0.017728887798164   5: 0.017727651522604   7: 0.017727141555410   4: 0.017726857369081   3: 0.017726575424609 

test_16385        0: 0.483952414132787   5: 0.297977226330966   4: 0.027266607142327   8: 0.027258007220346   3: 0.027257941408970   2: 0.027257801769455   9: 0.027257650097411   7: 0.027257649016374   1: 0.027257441990971   6: 0.027257260890394 

test_16386        5: 0.587379806740376   9: 0.189712474334964   4: 0.027867813851861   8: 0.027866136718020   1: 0.027865681692400   0: 0.027861812720805   6: 0.027861661713903   3: 0.027861641618864   2: 0.027861555912211   7: 0.027861414696597 

test_16388        5: 0.593500689480532   6: 0.198031834370118   0: 0.026069083272920   8: 0.026061055634878   4: 0.026060512180418   1: 0.026057896631071   9: 0.026054956598637   2: 0.026054897800685   3: 0.026054647015167   7: 0.026054427015576 

test_16390        0: 0.521225246497595   5: 0.292410150298854   4: 0.023305294260680   1: 0.023294919463723   3: 0.023294653159494   6: 0.023294560511497   2: 0.023294442274326   7: 0.023293656637968   9: 0.023293538586768   8: 0.023293538309096 

test_16392        5: 0.604116026631334   4: 0.220519015370345   6: 0.021923692846590   0: 0.021921019640159   8: 0.021921013110927   1: 0.021920708915259   3: 0.021919900871981   9: 0.021919697558239   7: 0.021919639458730   2: 0.021919285596436 

test_16393        5: 0.666369411703167   0: 0.157980273394565   6: 0.021963777045507   8: 0.021962343275873   9: 0.021959990480422   7: 0.021954947319712   1: 0.021954237409010   4: 0.021952735247919   3: 0.021951412377833   2: 0.021950871745991 

test_16394        5: 0.688975096219027   0: 0.127206030652082   8: 0.022979428091869   6: 0.022978272995219   1: 0.022977317067804   4: 0.022977147671199   3: 0.022976835027277   2: 0.022976669341239   9: 0.022976647855317   7: 0.022976555078968 

test_16395        1: 0.568722642349903   2: 0.298093196581172   6: 0.016652131163439   5: 0.016650996151235   0: 0.016648861628001   4: 0.016647164500569   8: 0.016646774005553   9: 0.016646672166688   7: 0.016646182772905   3: 0.016645378680534 

test_16396        5: 0.660399266619508   0: 0.168569887991304   6: 0.021383334755534   8: 0.021381736334748   1: 0.021380839987149   4: 0.021377162717580   3: 0.021377034647234   9: 0.021377032854168   7: 0.021376946981822   2: 0.021376757110954 

test_16398        0: 0.492416429600955   4: 0.348022466830826   1: 0.019949429367636   6: 0.019948399190431   9: 0.019947562678728   5: 0.019944486881095   8: 0.019943465229371   2: 0.019943400048362   7: 0.019942509599297   3: 0.019941850573299 

test_16399        6: 0.363125163250835   5: 0.236913822837133   8: 0.212967755604964   0: 0.096515856624150   4: 0.015096811053869   9: 0.015077230105962   1: 0.015076192250543   7: 0.015076146260524   3: 0.015075765840908   2: 0.015075256171111 

test_16400        5: 0.574198736243650   0: 0.214947223320535   4: 0.026368664956905   7: 0.026356434630156   8: 0.026355082547588   3: 0.026354869669739   2: 0.026354812246079   9: 0.026354774553892   6: 0.026354718740370   1: 0.026354683091084 

test_16401        5: 0.652339243159845   8: 0.159728776139424   6: 0.023495118250293   3: 0.023491721860829   0: 0.023491475256185   1: 0.023491310916573   4: 0.023491087530329   9: 0.023490500028971   2: 0.023490424217183   7: 0.023490342640367 

test_16402        6: 0.461867015476765   2: 0.386767881439200   4: 0.018991782636628   7: 0.018919880920071   5: 0.018914820723684   9: 0.018911529644953   1: 0.018908905898514   0: 0.018907427097950   8: 0.018905538259946   3: 0.018905217902289 

test_16403        6: 0.450573983849834   4: 0.313840881531914   0: 0.109699395133297   9: 0.017992704437449   5: 0.017987595581240   1: 0.017983632212358   8: 0.017980670872127   2: 0.017980602838879   3: 0.017980336993299   7: 0.017980196549605 

test_16404        5: 0.793795423344336   2: 0.055664018284767   1: 0.018821712280413   0: 0.018820787162451   6: 0.018819044026990   4: 0.018817354368096   9: 0.018816350765387   8: 0.018815546916786   3: 0.018815050530723   7: 0.018814712320051 

test_16405        5: 0.457017726943223   1: 0.373014725678693   6: 0.021249148258146   4: 0.021247048262547   9: 0.021246364388497   7: 0.021245521806809   8: 0.021245519802795   0: 0.021245321666549   2: 0.021244437444932   3: 0.021244185747808 

test_16406        1: 0.740397034926191   0: 0.028851162629903   5: 0.028845405567360   6: 0.028844682156625   9: 0.028843828532513   4: 0.028843781409427   2: 0.028843715493121   3: 0.028843480304348   8: 0.028843462584593   7: 0.028843446395918 

test_16407        6: 0.419896270239181   4: 0.240982607152841   1: 0.185338334973857   2: 0.022052472386856   0: 0.022043420231118   7: 0.021971075752097   5: 0.021940434005963   8: 0.021935731322863   9: 0.021922273139177   3: 0.021917380796047 

test_16409        0: 0.847362737335808   6: 0.016995405762518   2: 0.016986826608053   5: 0.016963864733107   1: 0.016953562838275   4: 0.016949218296946   9: 0.016947744267047   3: 0.016947250266335   8: 0.016946809843806   7: 0.016946580048106 

test_16410        5: 0.534576442868750   3: 0.290243448156019   4: 0.021903072874913   6: 0.021899682022516   7: 0.021897110477362   1: 0.021896595670023   0: 0.021896286784674   8: 0.021896136764715   9: 0.021895654690486   2: 0.021895569690541 

test_16415        6: 0.829302387469371   5: 0.018968048958169   0: 0.018967146909205   9: 0.018967146267664   8: 0.018966470625864   7: 0.018966140253115   1: 0.018966081475986   2: 0.018965703885141   3: 0.018965462684086   4: 0.018965411471398 

test_16417        5: 0.501230066918355   3: 0.223606065956595   4: 0.127822160859186   6: 0.021051107278062   9: 0.021048873820234   0: 0.021048722636283   1: 0.021048585678956   7: 0.021048582519540   8: 0.021047967826628   2: 0.021047866506161 

test_16418        5: 0.678387305546430   4: 0.035739214535164   3: 0.035734418285448   2: 0.035734387972320   8: 0.035734353384726   1: 0.035734275835568   0: 0.035734201690437   7: 0.035734039454873   9: 0.035733994483296   6: 0.035733808811738 

test_16419        2: 0.596423528138362   0: 0.092700946513651   1: 0.088344774895284   6: 0.031831908632790   5: 0.031814664902368   7: 0.031791784053125   4: 0.031775512981154   8: 0.031773812292522   9: 0.031772356994558   3: 0.031770710596186 

test_16420        5: 0.620868866012451   9: 0.190591122237115   1: 0.023573163927257   6: 0.023571705438331   0: 0.023568700637219   4: 0.023566006937369   2: 0.023565633384282   8: 0.023565452150650   3: 0.023564796165571   7: 0.023564553109755 

test_16421        5: 0.663126075606365   2: 0.186989063671134   1: 0.018743217178048   0: 0.018736843232496   6: 0.018736822462304   4: 0.018735120607466   7: 0.018733620029347   8: 0.018733400918298   9: 0.018733297387806   3: 0.018732538906736 

test_16422        4: 0.796385421040311   6: 0.022632445315488   5: 0.022632243383131   9: 0.022626596838736   1: 0.022623539460864   0: 0.022621719471868   7: 0.022619820281886   8: 0.022619775497092   2: 0.022619453297640   3: 0.022618985412986 

test_16424        5: 0.747632408716994   4: 0.028043281236945   8: 0.028042630072730   6: 0.028040779166468   9: 0.028040499644123   0: 0.028040140964125   2: 0.028040095969667   3: 0.028040079661893   7: 0.028040053928653   1: 0.028040030638403 

test_16426        5: 0.628766985463814   9: 0.144000710393798   3: 0.028411186443013   8: 0.028407164081279   2: 0.028406749537297   6: 0.028405821085996   0: 0.028403410360832   1: 0.028401561721049   4: 0.028399218441495   7: 0.028397192471428 

test_16427        6: 0.548310661082967   0: 0.333062944919243   1: 0.014838693757579   5: 0.014828796417774   3: 0.014827488378207   8: 0.014826560265272   9: 0.014826511304830   4: 0.014826248043485   2: 0.014826242617224   7: 0.014825853213419 

test_16428        5: 0.747486825704536   4: 0.028058931771838   2: 0.028057777056081   9: 0.028057582957795   3: 0.028056598300701   8: 0.028056535396820   0: 0.028056527710375   1: 0.028056498163591   7: 0.028056424136562   6: 0.028056298801703 

test_16429        6: 0.551471028378463   3: 0.287386609343006   5: 0.020144780226476   0: 0.020143623032262   2: 0.020143146174536   8: 0.020142961853608   1: 0.020142875622640   9: 0.020142242751990   4: 0.020141764056088   7: 0.020140968560930 

test_16430        6: 0.363618209529696   3: 0.237417643992056   0: 0.180451119767029   9: 0.111071066888494   1: 0.049664412410076   5: 0.011556717120131   4: 0.011555625129442   2: 0.011555379808348   7: 0.011554935486379   8: 0.011554889868349 

test_16432        4: 0.672680561803359   0: 0.082500183344267   5: 0.075875462972269   8: 0.024174101630647   3: 0.024128546549638   9: 0.024128481910269   6: 0.024128214327450   2: 0.024128177762443   1: 0.024128176635165   7: 0.024128093064492 

test_16433        6: 0.481478595594051   3: 0.268875891494899   7: 0.088918441265088   5: 0.022963565051407   1: 0.022962624294466   8: 0.022962269817409   0: 0.022961572612841   4: 0.022959465161808   2: 0.022959010964391   9: 0.022958563743640 

test_16434        8: 0.346668028596330   6: 0.302768867865309   5: 0.255956920427561   1: 0.013553071662129   0: 0.013520501264586   3: 0.013511552256555   7: 0.013511447505010   4: 0.013504741173845   9: 0.013503334245943   2: 0.013501535002734 

test_16437        5: 0.803112237080101   1: 0.021881934057065   6: 0.021877629869330   4: 0.021877617014803   9: 0.021875395947877   3: 0.021875306470244   8: 0.021875159915958   0: 0.021875104200611   2: 0.021874936323678   7: 0.021874679120332 

test_16438        9: 0.652546650178995   6: 0.217367656714689   8: 0.016502321094084   3: 0.016263920510091   2: 0.016222322060274   5: 0.016221513327161   1: 0.016221038305782   4: 0.016219377417533   0: 0.016218050533975   7: 0.016217149857415 

test_16440        5: 0.703556388925138   1: 0.032947247876445   6: 0.032941825568088   4: 0.032938623881257   0: 0.032938139509070   2: 0.032936724060418   8: 0.032935699156653   3: 0.032935687486409   9: 0.032934875985697   7: 0.032934787550825 

test_16441        5: 0.666434166340441   6: 0.140461583872610   4: 0.024146301367844   9: 0.024138193706893   8: 0.024137502732032   0: 0.024136516846668   3: 0.024136516731330   2: 0.024136510408870   1: 0.024136368248363   7: 0.024136339744950 

test_16442        6: 0.657374616857164   1: 0.200407724015289   0: 0.037660514431002   7: 0.014988400762502   5: 0.014941667873464   4: 0.014928281479199   9: 0.014927921579061   8: 0.014924359899557   2: 0.014923328704316   3: 0.014923184398446 

test_16443        1: 0.847223094087858   6: 0.017029332928382   9: 0.016998681065938   5: 0.016973578929048   4: 0.016970446882705   0: 0.016963153912879   7: 0.016961360192089   8: 0.016960755748140   2: 0.016959947347306   3: 0.016959648905655 

test_16444        2: 0.468447509195663   6: 0.205435547735527   1: 0.183584408855673   8: 0.020417651217463   5: 0.020371462798688   0: 0.020357318085955   4: 0.020353696512380   7: 0.020344832066491   9: 0.020344526306536   3: 0.020343047225624 

test_16448        5: 0.434552246705793   2: 0.310250935685718   1: 0.031907043324469   4: 0.031902530784556   0: 0.031902209046527   9: 0.031900787662096   7: 0.031896437620408   3: 0.031896341131282   8: 0.031896036039785   6: 0.031895431999367 

test_16449        9: 0.457712791043199   0: 0.216918722157515   6: 0.199622370572265   1: 0.017969595195755   5: 0.017965782303168   4: 0.017964136821037   2: 0.017962753906868   8: 0.017961351119630   3: 0.017961323832903   7: 0.017961173047660 

test_16450        7: 0.774905906581492   6: 0.025131628886752   1: 0.025061745052267   0: 0.025018741045355   4: 0.025007549585184   8: 0.024979037895569   5: 0.024978808067203   9: 0.024976148929217   2: 0.024970857578367   3: 0.024969576378596 

test_16454        5: 0.729002414647439   1: 0.129958269470672   6: 0.017635767016997   0: 0.017633397987152   4: 0.017630352411396   8: 0.017628558272926   7: 0.017628407172805   9: 0.017627884723978   3: 0.017627533324849   2: 0.017627414971787 

test_16457        0: 0.795410801629460   5: 0.022744503197934   1: 0.022737017763766   6: 0.022735148896526   7: 0.022729770233916   2: 0.022729150902528   8: 0.022729131506822   3: 0.022728903997455   4: 0.022728786523719   9: 0.022726785347875 

test_16458        5: 0.516098660494508   0: 0.292280201520760   4: 0.023955915896770   6: 0.023954914306859   1: 0.023953267649905   7: 0.023952593116353   8: 0.023951582654643   3: 0.023951066157968   2: 0.023950925812135   9: 0.023950872390099 

test_16459        0: 0.834555008859230   5: 0.018386224386803   1: 0.018385471912283   6: 0.018383364412271   4: 0.018382981948547   8: 0.018381762831886   2: 0.018381747329073   9: 0.018381250872281   7: 0.018381148601987   3: 0.018381038845639 

test_16460        7: 0.512278903578669   5: 0.248702823133583   0: 0.045005852379083   6: 0.027951683700289   8: 0.027699555053533   1: 0.027682458275632   4: 0.027670987499840   2: 0.027670287994525   9: 0.027668768095852   3: 0.027668680288993 

test_16461        3: 0.389975755664287   5: 0.381181836300082   8: 0.028609864080034   4: 0.028609613190419   2: 0.028604012792646   1: 0.028603894114359   0: 0.028603851188097   9: 0.028603824418678   7: 0.028603773916023   6: 0.028603574335376 

test_16463        5: 0.456864136318322   8: 0.354649545789724   6: 0.023609055405698   0: 0.023556370631151   2: 0.023555202836122   1: 0.023553665369190   3: 0.023553537386550   9: 0.023553519091285   7: 0.023552512269817   4: 0.023552454902142 

test_16465        3: 0.565403142531314   1: 0.237311134442890   5: 0.024763426115908   4: 0.024702908106936   0: 0.024657572677597   7: 0.024642113454520   6: 0.024638650126147   9: 0.024628662716480   8: 0.024626449420033   2: 0.024625940408177 

test_16468        5: 0.797222840825725   4: 0.022531266688100   6: 0.022531229568976   8: 0.022531135311327   3: 0.022530815861539   0: 0.022530764989014   1: 0.022530650581479   9: 0.022530499023020   2: 0.022530399903030   7: 0.022530397247789 

test_16469        5: 0.800193888785869   0: 0.022201816869185   4: 0.022200992289512   6: 0.022200957524885   8: 0.022200928268774   3: 0.022200541745735   1: 0.022200406127784   9: 0.022200223501968   2: 0.022200123916642   7: 0.022200120969646 

test_16470        5: 0.732937868244824   4: 0.093986785298190   6: 0.021634989609128   8: 0.021634883028841   3: 0.021634514430100   0: 0.021634450230499   1: 0.021634317856912   9: 0.021634141550368   2: 0.021634026505809   7: 0.021634023245328 

test_16471        5: 0.802261727686954   6: 0.021972737926501   0: 0.021971424793693   4: 0.021971108744728   8: 0.021970994194965   3: 0.021970654754756   1: 0.021970487734076   9: 0.021970398334591   2: 0.021970234228415   7: 0.021970231601321 

test_16472        5: 0.560721245137215   9: 0.255990893569686   6: 0.022911503907690   8: 0.022911462270952   4: 0.022911291614255   3: 0.022911020639141   0: 0.022910940517283   1: 0.022910778550151   2: 0.022910434822864   7: 0.022910428970763 

test_16473        5: 0.803137689006327   4: 0.021875342110206   6: 0.021874137513709   8: 0.021873709712471   3: 0.021873385455741   0: 0.021873333846166   9: 0.021873246155834   1: 0.021873217953033   2: 0.021872978103926   7: 0.021872960142586 

test_16475        4: 0.357466229086925   0: 0.279810586676325   6: 0.197543563214772   7: 0.052725776735768   2: 0.030904599053492   5: 0.016319865732449   1: 0.016310319404739   9: 0.016309036078573   8: 0.016305306491615   3: 0.016304717525342 

test_16476        5: 0.722764642973432   4: 0.115765544927986   6: 0.020185537136786   1: 0.020185140574138   0: 0.020183581399574   8: 0.020183206588390   2: 0.020183200864441   3: 0.020183140509717   7: 0.020183046963765   9: 0.020182958061772 

test_16478        5: 0.737426358914214   0: 0.087269902109788   4: 0.021918809309226   8: 0.021914819777742   6: 0.021912538390616   9: 0.021911557989216   3: 0.021911549590667   2: 0.021911539537255   1: 0.021911477417012   7: 0.021911446964264 

test_16479        6: 0.403996360843104   0: 0.220131514448103   3: 0.208504704649395   9: 0.049092226457425   7: 0.019718042226284   4: 0.019717800987121   5: 0.019711762234379   1: 0.019711649786692   2: 0.019708117983049   8: 0.019707820384449 

test_16480        5: 0.702324590173568   6: 0.112746245572261   4: 0.023122413936196   1: 0.023115989797598   8: 0.023115551278554   0: 0.023115270793268   3: 0.023115229350705   9: 0.023114976438265   7: 0.023114871358557   2: 0.023114861301028 

test_16481        5: 0.818686556418386   0: 0.032658842863032   6: 0.032248382702995   1: 0.026663103060119   8: 0.014959959177386   9: 0.014957807340374   7: 0.014956628223545   2: 0.014956549564999   4: 0.014956459476413   3: 0.014955711172751 

test_16483        2: 0.480730656386314   0: 0.340543710461166   4: 0.031519673788482   1: 0.027359882459708   8: 0.026422651997842   6: 0.026282632048811   9: 0.016847995772787   5: 0.016785657713046   3: 0.016756014264045   7: 0.016751125107798 

test_16486        5: 0.779264506504389   9: 0.024558053055048   8: 0.024527753931938   6: 0.024523939394193   1: 0.024521888688631   4: 0.024521628855075   0: 0.024521168611947   2: 0.024520512549945   7: 0.024520322480265   3: 0.024520225928568 

test_16487        5: 0.682232644578210   2: 0.135124767383482   7: 0.022833175609144   6: 0.022832633452818   0: 0.022830636503570   8: 0.022829739025130   4: 0.022829663163585   1: 0.022829407042016   9: 0.022829239306207   3: 0.022828093935838 

test_16488        5: 0.557072219978913   6: 0.278043286895782   0: 0.036950286892948   1: 0.018278936080177   8: 0.018276540311026   2: 0.018276072924638   7: 0.018275970548801   4: 0.018275594657618   9: 0.018275546040137   3: 0.018275545669961 

test_16490        5: 0.488588842850153   8: 0.181524264885967   9: 0.128814356743081   4: 0.078836755798801   6: 0.020382156155974   0: 0.020379488596816   1: 0.020378356417276   7: 0.020366989842218   3: 0.020364844265199   2: 0.020363944444515 

test_16492        5: 0.698130922888635   0: 0.162983684422178   6: 0.017366905785021   4: 0.017363774099527   7: 0.017359384538278   8: 0.017359343719129   9: 0.017359306269982   1: 0.017359246690090   3: 0.017358717422682   2: 0.017358714164477 

test_16493        7: 0.564183144595623   6: 0.239280166174700   8: 0.024684862082243   4: 0.024629806054606   1: 0.024607031724566   0: 0.024526300208905   5: 0.024526267301651   3: 0.024521165438943   2: 0.024521014993614   9: 0.024520241425149 

test_16495        5: 0.594433875415007   6: 0.266459697016724   0: 0.017404770753418   1: 0.017390952630432   9: 0.017386596326311   8: 0.017385048424553   4: 0.017385013773501   2: 0.017384880817060   7: 0.017384809815480   3: 0.017384355027514 

test_16496        5: 0.537824137042912   6: 0.218269881828489   0: 0.097616313575047   1: 0.051103414255464   8: 0.015874208732386   2: 0.015866470814019   4: 0.015862302890758   7: 0.015861610706397   3: 0.015861568405843   9: 0.015860091748685 

test_16499        6: 0.463971179930308   9: 0.398108522092516   5: 0.017244175391214   0: 0.017241547439590   1: 0.017240542642020   2: 0.017239595964153   4: 0.017239127156395   8: 0.017239014440095   7: 0.017238177007836   3: 0.017238117935873 

test_16502        5: 0.675311480303167   6: 0.159302922722998   7: 0.020679664824308   4: 0.020674642516758   1: 0.020674078666210   0: 0.020673624579342   8: 0.020671347750396   9: 0.020671011866970   2: 0.020670692071590   3: 0.020670534698261 

test_16505        6: 0.657612734389794   1: 0.200159323406753   0: 0.037670719508367   7: 0.014988385585672   5: 0.014941729791000   4: 0.014928297755249   9: 0.014927932939270   8: 0.014924360455453   2: 0.014923330219829   3: 0.014923185948614 

test_16510        5: 0.582530059656790   0: 0.270611595814961   3: 0.018451466983145   1: 0.018357261033846   6: 0.018347626469321   9: 0.018343361536651   7: 0.018341036761570   8: 0.018339914458481   2: 0.018339254166626   4: 0.018338423118609 

test_16512        6: 0.512959294901322   5: 0.307590806905848   0: 0.022433646433140   1: 0.022433440785966   4: 0.022431426416255   7: 0.022431206655259   2: 0.022430826576779   9: 0.022429916072050   8: 0.022429886817669   3: 0.022429548435713 

test_16513        6: 0.311258604859713   9: 0.275954924366906   4: 0.170281251312923   0: 0.165682434139699   8: 0.013002817668382   5: 0.012913257121197   1: 0.012741657915765   2: 0.012724334962879   3: 0.012720985257672   7: 0.012719732394866 

test_16518        5: 0.496485906101924   7: 0.308943859039702   3: 0.024322331663078   4: 0.024321610181326   6: 0.024321584700655   0: 0.024321343697533   1: 0.024321245778540   8: 0.024320907004993   2: 0.024320672440822   9: 0.024320539391427 

test_16519        5: 0.621591352966091   6: 0.232061071349192   1: 0.018297678380151   0: 0.018295897693534   9: 0.018293274037245   2: 0.018292316432884   4: 0.018292233572523   7: 0.018292184647695   8: 0.018292113222835   3: 0.018291877697849 

test_16521        8: 0.447366637809242   5: 0.365289732173201   3: 0.041397879045911   6: 0.020868002403128   0: 0.020867838150020   1: 0.020846406052687   4: 0.020844152794814   2: 0.020841884577447   9: 0.020839352907917   7: 0.020838114085632 

test_16522        5: 0.753607439044076   4: 0.027378903557741   0: 0.027377389061731   8: 0.027377244773111   1: 0.027376977205432   9: 0.027376552670813   6: 0.027376460491128   3: 0.027376373882127   2: 0.027376359434372   7: 0.027376299879471 

test_16523        6: 0.627002528029151   1: 0.216179341624384   0: 0.019638317915879   5: 0.019602136697360   2: 0.019597165450308   8: 0.019596898190215   4: 0.019596807459368   9: 0.019595659044235   3: 0.019595647519700   7: 0.019595498069399 

test_16525        6: 0.440405484846464   8: 0.414800103231946   5: 0.018102751242223   0: 0.018100301010579   4: 0.018099463419819   7: 0.018099280157386   9: 0.018098806798749   1: 0.018098378987535   3: 0.018097791495628   2: 0.018097638809670 

test_16527        5: 0.432124203737426   6: 0.403109687320454   4: 0.020598181577471   0: 0.020598157968664   1: 0.020596210242146   8: 0.020595570184927   9: 0.020595152579258   7: 0.020594777043069   2: 0.020594139911832   3: 0.020593919434753 

test_16530        5: 0.708842960180148   0: 0.032353750196533   6: 0.032351894278247   4: 0.032351799068492   1: 0.032350997749260   8: 0.032350166819923   2: 0.032349740273997   7: 0.032349603923188   3: 0.032349568786042   9: 0.032349518724170 

test_16531        8: 0.439100112000386   0: 0.230052777276355   9: 0.159725197613556   3: 0.056523311222669   7: 0.019247424748767   6: 0.019076187287509   1: 0.019073613796797   5: 0.019070260915906   4: 0.019066755926396   2: 0.019064359211657 

test_16533        5: 0.840562470653397   9: 0.017717855903440   6: 0.017717185917620   1: 0.017717140118002   0: 0.017715798579580   4: 0.017715465940069   2: 0.017713612326135   8: 0.017713561121189   7: 0.017713470388533   3: 0.017713439052035 

test_16538        5: 0.565563242107932   8: 0.239401227624434   6: 0.024384147188752   0: 0.024380444396972   4: 0.024380392236772   1: 0.024380306198352   7: 0.024378838977442   9: 0.024377479068236   2: 0.024376977437806   3: 0.024376944763301 

test_16539        5: 0.657699801304905   0: 0.038050101320802   4: 0.038035512836499   8: 0.038031029886394   2: 0.038030749242145   6: 0.038030634280074   3: 0.038030587681495   7: 0.038030545004201   1: 0.038030527187243   9: 0.038030511256242 

test_16545        5: 0.772720534083997   6: 0.025255165418438   0: 0.025254779455495   4: 0.025254316119653   8: 0.025253825577815   9: 0.025253199673164   1: 0.025252228259473   7: 0.025252154484741   2: 0.025252038544434   3: 0.025251758382791 

test_16546        5: 0.636221427436599   1: 0.116871664888222   4: 0.108689710574146   6: 0.019747254693887   8: 0.019745740005516   9: 0.019745209810804   0: 0.019744990861455   7: 0.019744825070554   2: 0.019744652011833   3: 0.019744524646983 

test_16549        5: 0.523077773066178   3: 0.287987442005039   6: 0.023620082476959   0: 0.023617017055060   1: 0.023616985490461   7: 0.023616983333681   2: 0.023616023115648   4: 0.023615999217831   8: 0.023615909355885   9: 0.023615784883257 

test_16551        5: 0.798751200664623   4: 0.022364673267287   6: 0.022360774458708   8: 0.022360719380478   0: 0.022360547527336   1: 0.022360511560187   9: 0.022360467282942   3: 0.022360421307554   7: 0.022360354003747   2: 0.022360330547137 

test_16554        8: 0.425466285190978   5: 0.290144021209748   4: 0.035559548494209   3: 0.035547614811073   2: 0.035547448419126   1: 0.035547155710398   0: 0.035547083451177   7: 0.035547020970084   9: 0.035546926158221   6: 0.035546895584987 

test_16555        7: 0.325943892952063   4: 0.244454594679542   6: 0.189562354505783   0: 0.131849735860035   5: 0.018033638251138   1: 0.018033178972747   9: 0.018030865916975   3: 0.018030666313264   2: 0.018030655352717   8: 0.018030417195735 

test_16561        5: 0.772963442855743   4: 0.025233164765721   0: 0.025225742918231   8: 0.025225664768357   6: 0.025225605022727   7: 0.025225420773328   3: 0.025225343600367   9: 0.025225232477703   2: 0.025225194175149   1: 0.025225188642673 

test_16563        9: 0.353192859257618   8: 0.278052687626662   0: 0.205395367781775   3: 0.048984208965775   7: 0.019240549220655   6: 0.019054432883327   1: 0.019029506981316   4: 0.019022756304079   5: 0.019021299974218   2: 0.019006331004575 

test_16564        6: 0.882775716108744   8: 0.013036411626108   0: 0.013024068241832   5: 0.013023979019029   1: 0.013023953603978   9: 0.013023442618915   4: 0.013023130709255   3: 0.013023121714589   7: 0.013023107735103   2: 0.013023068622447 

test_16565        6: 0.495975429913660   0: 0.420806598373741   1: 0.010622183606667   9: 0.010402564169363   7: 0.010390183889838   8: 0.010364934463233   5: 0.010359718347953   2: 0.010359632423246   4: 0.010359427499513   3: 0.010359327312787 

test_16568        5: 0.674140500311066   8: 0.167020396985279   1: 0.019858721310947   0: 0.019855048990715   4: 0.019854792844146   6: 0.019854449156270   3: 0.019854186989030   2: 0.019854054795536   7: 0.019853961526255   9: 0.019853887090756 

test_16569        5: 0.597461757393326   3: 0.137023853588867   8: 0.081779163363325   4: 0.077337593004434   6: 0.017782001767394   0: 0.017768843713510   7: 0.017739714966349   1: 0.017702932835443   9: 0.017702137216436   2: 0.017702002150916 

test_16570        6: 0.437652996310432   2: 0.390989109656131   1: 0.021647283280892   0: 0.021532746064294   3: 0.021416634707851   5: 0.021357194990491   4: 0.021351396422298   7: 0.021350976523401   9: 0.021350976492188   8: 0.021350685552022 

test_16574        6: 0.810777527539515   5: 0.021040432475712   4: 0.021032446933587   0: 0.021023055171770   9: 0.021022067094969   1: 0.021021361063940   8: 0.021021210312806   7: 0.021020745426971   3: 0.021020685348991   2: 0.021020468631740 

test_16577        6: 0.413208749354633   4: 0.250045078916326   2: 0.215707222547842   8: 0.032312178265244   1: 0.015609357179114   0: 0.014802016628175   7: 0.014689433762994   3: 0.014543968329442   5: 0.014541272717938   9: 0.014540722298291 

test_16581        6: 0.293421851982365   9: 0.249192399054181   8: 0.239452574031795   1: 0.063907757003889   5: 0.045203601901714   0: 0.044380531276536   2: 0.016114621539801   3: 0.016110407511660   4: 0.016108605843309   7: 0.016107649854749 

test_16583        9: 0.437926982955394   1: 0.380704080136479   5: 0.022688993500149   4: 0.022675008987740   0: 0.022669329328512   6: 0.022668930113540   2: 0.022668429848001   8: 0.022666602052211   3: 0.022666075373199   7: 0.022665567704776 

test_16584        5: 0.765048693066413   4: 0.026108571313152   8: 0.026106383425086   6: 0.026105971457082   9: 0.026105937660971   0: 0.026105381774980   1: 0.026104918172594   3: 0.026104756530985   7: 0.026104719949598   2: 0.026104666649138 

test_16585        4: 0.456383760917648   5: 0.388101013194771   8: 0.019537279801198   6: 0.019447917692726   0: 0.019437448334951   2: 0.019418956092007   9: 0.019418864322993   1: 0.019418731723756   7: 0.019418339417718   3: 0.019417688502232 

test_16587        4: 0.709279205099107   1: 0.129136703240970   5: 0.020204884652253   6: 0.020198149627511   9: 0.020197615328015   0: 0.020197578696797   8: 0.020197166754415   2: 0.020196304147998   7: 0.020196208963297   3: 0.020196183489639 

test_16588        0: 0.871665104569688   4: 0.014300274606096   6: 0.014269048896784   1: 0.014268525315815   8: 0.014253033879142   9: 0.014251710341511   5: 0.014249671585781   7: 0.014248351187927   3: 0.014247248965065   2: 0.014247030652190 

test_16589        6: 0.566291445519532   4: 0.300135325137816   9: 0.021140271647698   0: 0.016270948587837   1: 0.016032350725510   5: 0.016028935367450   7: 0.016026841590210   8: 0.016025102545967   2: 0.016024712492160   3: 0.016024066385820 

test_16590        0: 0.559805498647265   5: 0.313602988811317   4: 0.015826915393394   6: 0.015825247309680   8: 0.015824113357099   1: 0.015824047632131   9: 0.015822963669471   2: 0.015822804172640   7: 0.015822723545921   3: 0.015822697461083 

test_16591        5: 0.805087183964263   0: 0.021670662482254   6: 0.021665713885226   1: 0.021659425501120   9: 0.021654031106985   2: 0.021653255872326   3: 0.021653012435895   4: 0.021652327815358   8: 0.021652310781756   7: 0.021652076154817 

test_16592        5: 0.596077407577896   3: 0.199974697438251   6: 0.025499756991722   7: 0.025499387652624   1: 0.025498167029592   4: 0.025494965158324   0: 0.025491566121943   2: 0.025488179345565   8: 0.025488000576407   9: 0.025487872107677 

test_16593        6: 0.415667996158530   9: 0.368244519258118   0: 0.086992487950007   2: 0.018447774853430   1: 0.018444001993713   3: 0.018443785750856   5: 0.018441082054886   8: 0.018440796019746   4: 0.018438960490211   7: 0.018438595470503 

test_16597        2: 0.574479382749361   6: 0.270061727745177   5: 0.019440192708298   0: 0.019439300587067   4: 0.019437753491163   1: 0.019433971191825   7: 0.019427669587338   9: 0.019426934085531   3: 0.019426790730557   8: 0.019426277123684 

test_16598        5: 0.785885807406962   6: 0.023795166493352   7: 0.023793961259396   4: 0.023793254030819   1: 0.023793171098601   0: 0.023789562682340   3: 0.023787929590368   2: 0.023787164987622   8: 0.023787074461642   9: 0.023786907988897 

test_16599        5: 0.443876663898480   9: 0.318113354887915   4: 0.029755715053566   8: 0.029755302618505   6: 0.029752879467960   0: 0.029750395003544   1: 0.029749651337606   2: 0.029748785682261   3: 0.029748754371383   7: 0.029748497678780 

test_16600        1: 0.491628593583371   6: 0.389788953443467   8: 0.020655668733208   0: 0.014029001160417   5: 0.013990920518641   7: 0.013985380970096   9: 0.013985218399449   4: 0.013984547519607   2: 0.013976427858541   3: 0.013975287813204 

test_16601        6: 0.580113772010272   0: 0.272554125609755   5: 0.018419548438188   4: 0.018417274981997   8: 0.018416591372393   1: 0.018416523037095   3: 0.018415693822712   9: 0.018415681101549   7: 0.018415476027911   2: 0.018415313598128 

test_16602        4: 0.832741791597665   6: 0.047098840288376   0: 0.015028981256601   1: 0.015025499478037   5: 0.015020826101292   7: 0.015019996588757   3: 0.015016950924102   9: 0.015016166264300   8: 0.015016149764847   2: 0.015014797736023 

test_16604        6: 0.507007535101605   4: 0.340269054162108   9: 0.028870983800477   0: 0.018010094446191   1: 0.017649017583791   5: 0.017641303115987   7: 0.017640541948604   8: 0.017637614783069   2: 0.017637276093739   3: 0.017636578964429 

test_16606        4: 0.699332612184077   5: 0.033413878277042   3: 0.033406919115941   1: 0.033406876928189   2: 0.033406840991012   0: 0.033406811046119   8: 0.033406775619737   9: 0.033406507192071   7: 0.033406497743034   6: 0.033406280902777 

test_16607        6: 0.701291692931629   9: 0.090629236744296   0: 0.060830250909416   1: 0.047582404355690   7: 0.037052492688044   5: 0.012532816185929   8: 0.012521215379631   2: 0.012520099613192   3: 0.012519969539495   4: 0.012519821652678 

test_16608        5: 0.799415642560250   4: 0.022288440159402   6: 0.022288348799422   1: 0.022286929955892   7: 0.022286918409674   0: 0.022286907586818   9: 0.022286765252183   3: 0.022286741168806   8: 0.022286658243928   2: 0.022286647863625 

test_16610        2: 0.697318807990264   5: 0.033652924983895   4: 0.033640435961626   8: 0.033638761308880   6: 0.033638323585250   9: 0.033633219889899   0: 0.033627265102269   1: 0.033619464927888   7: 0.033615908711735   3: 0.033614887538294 

test_16611        6: 0.720718529259127   5: 0.105510749143869   1: 0.048060215288983   0: 0.038120144735651   4: 0.014603127187265   8: 0.014597918073451   9: 0.014597458414065   3: 0.014597424052520   2: 0.014597252812350   7: 0.014597181032718 

test_16615        5: 0.572874897672434   4: 0.196636928456426   9: 0.091775541641420   0: 0.019856361219832   6: 0.019811257177278   8: 0.019810448256519   1: 0.019809899282176   7: 0.019808381338991   3: 0.019808145751382   2: 0.019808139203541 

test_16619        5: 0.609102812746382   6: 0.157463367774609   0: 0.115950535788895   9: 0.016789157052500   2: 0.016788515120307   8: 0.016784189099554   3: 0.016784023795622   4: 0.016780193863531   1: 0.016779109204135   7: 0.016778095554463 

test_16621        6: 0.572315917321855   1: 0.228675770890909   4: 0.074705801602034   5: 0.017761943896071   0: 0.017759503446412   3: 0.017759155684493   9: 0.017756158818870   2: 0.017755671497910   8: 0.017755383543592   7: 0.017754693297853 

test_16622        6: 0.456013454173375   5: 0.386194629635278   9: 0.019824973809550   3: 0.019712988980539   1: 0.019709763625000   0: 0.019709363999416   2: 0.019709055635944   4: 0.019708841035954   7: 0.019708707990369   8: 0.019708221114574 

test_16623        5: 0.548530153569688   9: 0.240592520851579   8: 0.026363498204932   4: 0.026362893489629   6: 0.026361154884197   0: 0.026358872075860   1: 0.026358269618015   3: 0.026357634815825   2: 0.026357579161992   7: 0.026357423328283 

test_16624        6: 0.505793073777479   7: 0.271395618664680   1: 0.027852709294933   0: 0.027852301875680   8: 0.027851713490713   5: 0.027851299703594   9: 0.027850993906977   2: 0.027850943457832   4: 0.027850841728726   3: 0.027850504099386 

test_16625        5: 0.339187000358202   4: 0.308564240799418   8: 0.179023621255579   3: 0.024746667960399   9: 0.024746605021979   2: 0.024746526031359   7: 0.024746511253934   6: 0.024746449589024   0: 0.024746204469170   1: 0.024746173260935 

test_16626        9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

test_16627        6: 0.425055853503838   5: 0.368160968864957   9: 0.025850455233720   0: 0.025849426890114   1: 0.025847818011928   3: 0.025847599814879   8: 0.025847336911432   7: 0.025847011342458   2: 0.025846791000359   4: 0.025846738426314 

test_16628        5: 0.657679353603430   7: 0.206861798593062   6: 0.016934032524437   4: 0.016933857622693   0: 0.016933184200803   1: 0.016932942955660   8: 0.016931284472456   9: 0.016931261962882   2: 0.016931171742655   3: 0.016931112321921 

test_16630        6: 0.441942507217110   0: 0.343681813934191   1: 0.097522259828920   2: 0.021464380748679   8: 0.021454060957810   5: 0.014795054574369   9: 0.014792083296108   4: 0.014782834624894   7: 0.014782743309349   3: 0.014782261508569 

test_16633        5: 0.744892817681024   4: 0.028348048888272   6: 0.028346343005340   1: 0.028345198979686   0: 0.028345070084103   8: 0.028344740651224   9: 0.028344588403314   3: 0.028344438126393   7: 0.028344378480851   2: 0.028344375699794 

test_16635        5: 0.546159147320076   3: 0.285604600126256   6: 0.021032031501697   4: 0.021031537222640   0: 0.021029592720226   9: 0.021029243414330   7: 0.021028842225183   8: 0.021028730327715   1: 0.021028328451666   2: 0.021027946690209 

test_16636        6: 0.428265773856127   1: 0.312590947661942   3: 0.171340458653179   7: 0.026458530484932   0: 0.010530766481999   5: 0.010189897363720   2: 0.010159664549754   4: 0.010158958304390   9: 0.010152564094267   8: 0.010152438549690 

test_16638        5: 0.784153662094721   6: 0.023986986514603   1: 0.023984657146635   0: 0.023983695233850   9: 0.023982820819480   8: 0.023981986650929   4: 0.023981577135123   7: 0.023981559714632   3: 0.023981534899672   2: 0.023981519790355 

test_16641        5: 0.656255430787040   3: 0.167646717321190   6: 0.022013808671573   4: 0.022013100936577   8: 0.022012936375196   9: 0.022012357286087   1: 0.022011738343489   0: 0.022011612939187   7: 0.022011440251344   2: 0.022010857088316 

test_16642        5: 0.844061516668227   0: 0.017349433361313   6: 0.017325912880557   4: 0.017324647366183   8: 0.017324642690116   9: 0.017323529498237   1: 0.017323204748469   7: 0.017322510647095   2: 0.017322363782670   3: 0.017322238357132 

test_16644        0: 0.537095215420739   5: 0.322154853017870   8: 0.036418541122944   9: 0.014915172402399   6: 0.014905813959023   1: 0.014903244880505   4: 0.014903026878363   7: 0.014901517800544   2: 0.014901464139348   3: 0.014901150378265 

test_16645        5: 0.503750130630370   9: 0.317217625538498   0: 0.022386698173359   4: 0.022382720565329   1: 0.022379248865994   2: 0.022378130634043   6: 0.022377246309143   7: 0.022376691069151   8: 0.022375836933142   3: 0.022375671280971 

test_16646        6: 0.564778319201459   4: 0.263526380225449   0: 0.045547796715669   7: 0.018025367511806   1: 0.018023019672854   2: 0.018022032295198   5: 0.018021681091043   9: 0.018018678259908   8: 0.018018466781035   3: 0.018018258245579 

test_16648        1: 0.458703072027374   5: 0.337685807015667   6: 0.025463087358663   0: 0.025455470273790   8: 0.025450011262994   4: 0.025449408027690   9: 0.025449117233325   2: 0.025448314782434   7: 0.025448027678551   3: 0.025447684339512 

test_16649        6: 0.670910559972049   9: 0.114164005301628   0: 0.073105007236866   1: 0.047831080228020   7: 0.033566120487175   5: 0.012092249699773   8: 0.012083398645436   2: 0.012082643619279   3: 0.012082588355506   4: 0.012082346454267 

test_16650        6: 0.787313843062167   5: 0.052906242636003   0: 0.019980989574883   2: 0.019975512979764   1: 0.019973968187163   8: 0.019972630040902   4: 0.019972441238253   9: 0.019971301567196   3: 0.019967143714582   7: 0.019965926999087 

test_16651        6: 0.587377260450872   9: 0.210289007809514   8: 0.087703218671245   5: 0.016599098097587   7: 0.016349879255703   1: 0.016340485874693   2: 0.016335734607303   0: 0.016335685951474   3: 0.016335034090315   4: 0.016334595191296 

test_16652        6: 0.394819989429518   2: 0.394633459303160   1: 0.026331405147650   5: 0.026325356217956   4: 0.026323952316047   0: 0.026318762431423   9: 0.026314460876861   8: 0.026313573717491   3: 0.026309667092499   7: 0.026309373467394 

test_16653        5: 0.763364966594014   3: 0.026293319288240   4: 0.026293153722767   6: 0.026292841990924   1: 0.026292789024848   0: 0.026292725159710   8: 0.026292613260598   2: 0.026292556202688   9: 0.026292522270322   7: 0.026292512485890 

test_16654        5: 0.802605909990646   4: 0.021935037799676   8: 0.021934959734119   6: 0.021934060686486   9: 0.021932885593510   0: 0.021932495488425   1: 0.021931652144425   7: 0.021931076360314   2: 0.021931009390086   3: 0.021930912812313 

test_16655        4: 0.809347954755497   5: 0.021193169268905   6: 0.021183164163641   0: 0.021182623224945   8: 0.021182388747564   1: 0.021182355936255   3: 0.021182252205833   7: 0.021182101544130   2: 0.021182026047439   9: 0.021181964105791 

test_16656        1: 0.496338371183973   4: 0.275166016224452   0: 0.107459337370087   6: 0.017305259674466   9: 0.017292556972244   5: 0.017290398570090   8: 0.017288607436184   7: 0.017286823728084   2: 0.017286777264514   3: 0.017285851575906 

test_16658        6: 0.874893027323088   8: 0.024269744110196   0: 0.012610563732053   1: 0.012607413369425   2: 0.012604626091243   5: 0.012604476437327   9: 0.012604087084349   7: 0.012602315510991   4: 0.012602061069084   3: 0.012601685272245 

test_16662        5: 0.395533962900805   7: 0.347560890047264   4: 0.032118123953260   6: 0.032114621990766   8: 0.032114036038197   1: 0.032112085606000   9: 0.032111928811719   2: 0.032111642800115   0: 0.032111443179646   3: 0.032111264672228 

test_16663        4: 0.778122554311925   6: 0.024664693540492   0: 0.024654466651345   1: 0.024653952869868   5: 0.024653654451799   2: 0.024650937989804   9: 0.024650670740279   3: 0.024649861924229   8: 0.024649711591265   7: 0.024649495928995 

test_16664        5: 0.764675772901942   6: 0.026154333446790   8: 0.026148550166063   4: 0.026147770587714   9: 0.026147482740037   0: 0.026146075526679   1: 0.026145379742427   7: 0.026145304623314   2: 0.026144784878641   3: 0.026144545386394 

test_16665        5: 0.754177279097770   6: 0.027329234759891   4: 0.027321526739138   2: 0.027313176831822   9: 0.027312106483833   1: 0.027309715940892   7: 0.027309329207146   3: 0.027309301938926   8: 0.027309294890990   0: 0.027309034109592 

test_16667        0: 0.810977507288655   4: 0.021056221457046   5: 0.021011887123571   6: 0.021010406955205   3: 0.021008262526498   1: 0.020992114675251   9: 0.020986804249821   8: 0.020985808396299   7: 0.020985713809240   2: 0.020985273518415 

test_16668        5: 0.471489689724523   4: 0.360470134876291   6: 0.021008273134933   8: 0.021005773905082   1: 0.021005436757286   0: 0.021005052310696   9: 0.021004836915386   7: 0.021003636097788   2: 0.021003606821156   3: 0.021003559456859 

test_16670        5: 0.637678003846899   8: 0.180029222797642   6: 0.022789031006126   4: 0.022787634963608   9: 0.022786842187291   0: 0.022786397630721   1: 0.022786251557862   7: 0.022785756067884   2: 0.022785550748797   3: 0.022785309193169 

test_16672        5: 0.474593680448667   8: 0.294189260370082   4: 0.090640271216862   6: 0.020086173012320   0: 0.020083956122327   1: 0.020082263110178   9: 0.020082244489443   7: 0.020080841930652   3: 0.020080789868479   2: 0.020080519430990 

test_16675        0: 0.701549232913207   1: 0.033163998756448   5: 0.033163329245026   3: 0.033161221990521   4: 0.033160959014835   6: 0.033160906966048   2: 0.033160373314802   7: 0.033160017446185   8: 0.033160011631315   9: 0.033159948721612 

test_16676        1: 0.512638784821878   3: 0.268932788780387   5: 0.027308524264057   6: 0.027304807023512   2: 0.027304725541692   0: 0.027304567595387   4: 0.027301897933868   7: 0.027301405537624   9: 0.027301300924366   8: 0.027301197577229 

test_16677        5: 0.676928605403339   0: 0.182171987035534   1: 0.033752419922127   6: 0.015319761953337   7: 0.015305688851853   9: 0.015304941019255   2: 0.015304507484563   8: 0.015304331380134   4: 0.015304193244049   3: 0.015303563705811 

test_16678        5: 0.429746253286840   1: 0.357298716747933   4: 0.026621329737487   3: 0.026620047589366   2: 0.026619046216924   0: 0.026618983531187   6: 0.026618964169882   7: 0.026618929731757   8: 0.026618895385428   9: 0.026618833603197 

test_16679        5: 0.483077569734285   2: 0.317832793449657   4: 0.024887534063821   1: 0.024886927249321   3: 0.024886479751673   0: 0.024886173393928   6: 0.024886015268057   9: 0.024885569020904   7: 0.024885538676522   8: 0.024885399391832 

test_16680        6: 0.428576313960812   2: 0.194070626630823   4: 0.191190298909287   0: 0.101482044348347   1: 0.022577764482868   9: 0.012724518744140   7: 0.012433917136959   5: 0.012318789266113   3: 0.012314767347747   8: 0.012310959172907 

test_16681        6: 0.549030488469670   8: 0.126883996879992   0: 0.113350483904286   2: 0.108873997423438   7: 0.016979875072086   5: 0.016977367683520   1: 0.016977219039445   9: 0.016976890630560   4: 0.016975480689924   3: 0.016974200207078 

test_16684        1: 0.831769196508784   5: 0.040020136423071   2: 0.016220414476312   6: 0.016065195043174   9: 0.016016490766418   0: 0.015989784462723   7: 0.015980478859166   4: 0.015980304623836   8: 0.015979214318324   3: 0.015978784518191 

test_16685        1: 0.713485625268838   8: 0.150354977271484   6: 0.017025260038235   5: 0.017023458622591   0: 0.017020036640820   3: 0.017018603509864   9: 0.017018560064319   4: 0.017018027755653   7: 0.017017768386194   2: 0.017017682442002 

test_16687        5: 0.431349599947915   0: 0.348803217632080   1: 0.027483962878360   4: 0.027483285615221   8: 0.027480791005241   6: 0.027480334590377   3: 0.027479942735428   9: 0.027479673114575   2: 0.027479662177503   7: 0.027479530303299 

test_16688        8: 0.516607965566502   1: 0.291468297694589   6: 0.058358868881559   4: 0.019102516350138   5: 0.019093401685652   7: 0.019083298542192   0: 0.019076591557889   9: 0.019070325630594   2: 0.019069503057863   3: 0.019069231033021 

test_16695        6: 0.470220218115923   1: 0.326311212695599   5: 0.070106066546159   2: 0.019055282619981   0: 0.019051940699807   4: 0.019051938250965   9: 0.019051325767261   8: 0.019050762145701   3: 0.019050675339451   7: 0.019050577819152 

test_16698        5: 0.493994284114907   7: 0.168384690211065   1: 0.152439513547404   6: 0.026457862056154   4: 0.026455663619326   8: 0.026455539632324   9: 0.026454541175849   0: 0.026453097695660   2: 0.026452612332405   3: 0.026452195614906 

test_16700        1: 0.571825823753911   6: 0.293824831915354   0: 0.016820282678164   9: 0.016808239962585   8: 0.016791241930949   5: 0.016787518198864   4: 0.016785794619375   2: 0.016785548941757   3: 0.016785456893832   7: 0.016785261105208 

test_16705        5: 0.565255960918601   8: 0.224944684635575   4: 0.026230197495556   9: 0.026224439842976   1: 0.026224425900653   3: 0.026224228205466   6: 0.026224112178116   0: 0.026224075516892   2: 0.026224010132663   7: 0.026223865173503 

test_16706        8: 0.413938148387484   6: 0.249289306294447   5: 0.200383984403268   0: 0.019507267163860   7: 0.019491012959114   4: 0.019486871899678   1: 0.019485185354610   9: 0.019473779075642   2: 0.019472963962331   3: 0.019471480499566 

test_16707        1: 0.833258991274268   8: 0.018529370458130   0: 0.018526934117611   6: 0.018526676924536   5: 0.018526639861707   4: 0.018526440460072   9: 0.018526317177064   2: 0.018526270441100   3: 0.018526213818334   7: 0.018526145467178 

test_16708        5: 0.745481580875545   1: 0.028300832819850   6: 0.028282745491825   8: 0.028279263271945   0: 0.028278585271265   4: 0.028278264317681   9: 0.028277411795955   2: 0.028274128219311   3: 0.028273668007044   7: 0.028273519929577 

test_16710        0: 0.749344363180137   2: 0.098057615903975   6: 0.019086440144351   1: 0.019076124746754   5: 0.019073397401062   9: 0.019073050257638   3: 0.019072722964130   8: 0.019072574700985   4: 0.019072041640949   7: 0.019071669060018 

test_16711        4: 0.432102792235246   6: 0.378293224721917   9: 0.058436502648774   5: 0.018743309647474   0: 0.018741591074366   1: 0.018739427078313   8: 0.018737853788922   7: 0.018735316505523   2: 0.018735301681110   3: 0.018734680618356 

test_16714        1: 0.481548486832915   3: 0.297651977904694   5: 0.027606392545938   0: 0.027600870766459   2: 0.027599642369336   6: 0.027599482591700   4: 0.027598851347598   7: 0.027598173290758   9: 0.027598095188750   8: 0.027598027161853 

test_16715        9: 0.539167215658358   4: 0.241050193542142   5: 0.027486124194658   6: 0.027473178451448   1: 0.027472844486069   3: 0.027470491739629   0: 0.027470479490855   8: 0.027470115146856   2: 0.027469823691214   7: 0.027469533598769 

test_16717        5: 0.611281686080425   3: 0.220457689370853   1: 0.021035736485721   0: 0.021033776922603   4: 0.021033223525465   6: 0.021031991546920   2: 0.021031553305497   8: 0.021031461136793   7: 0.021031456820266   9: 0.021031424805457 

test_16718        5: 0.584678045927218   6: 0.138664703867550   7: 0.106817644955474   3: 0.024271459230647   4: 0.024268861595767   1: 0.024262714048338   0: 0.024261666967647   9: 0.024258433757010   2: 0.024258409301410   8: 0.024258060348939 

test_16719        4: 0.567351728895989   8: 0.227402822780057   5: 0.025663440401925   3: 0.025654865277104   6: 0.025654650752822   1: 0.025654571781682   0: 0.025654554731095   7: 0.025654540178361   9: 0.025654423073210   2: 0.025654402127756 

test_16723        1: 0.584332692905432   6: 0.292957271484574   9: 0.028985223147236   0: 0.013414558048042   2: 0.013390863714733   7: 0.013387934953937   5: 0.013385297497280   4: 0.013383047163956   3: 0.013381728236049   8: 0.013381382848761 

test_16725        5: 0.762977854506975   6: 0.026339090933205   8: 0.026336818661431   4: 0.026336778745268   9: 0.026336049619747   0: 0.026335177639474   1: 0.026334837381997   2: 0.026334685183972   7: 0.026334612766147   3: 0.026334094561783 

test_16726        5: 0.419753942394268   0: 0.369275149462878   3: 0.026372321638474   4: 0.026371804539688   1: 0.026371466098915   6: 0.026371422834173   8: 0.026371264894374   2: 0.026371069030687   7: 0.026370820517911   9: 0.026370738588632 

test_16727        1: 0.448308772838477   6: 0.310275656711992   4: 0.132055068335255   0: 0.023906745040657   5: 0.016027042979845   9: 0.013938666702112   2: 0.013927041439172   8: 0.013854958782660   7: 0.013853087799294   3: 0.013852959370537 

test_16734        8: 0.596706802539034   1: 0.233788152604065   0: 0.040937918716703   6: 0.018401307900969   3: 0.018385222818960   5: 0.018361905516663   4: 0.018360109496520   9: 0.018353258213596   2: 0.018352990103324   7: 0.018352332090166 

test_16735        5: 0.732140716703326   4: 0.029765118263431   3: 0.029761934531165   8: 0.029761888205069   2: 0.029761866634588   9: 0.029761792704690   0: 0.029761758947632   1: 0.029761727882686   7: 0.029761716944745   6: 0.029761479182668 

test_16737        5: 0.754152946182387   1: 0.044345671783795   6: 0.025454043927027   9: 0.025398522469719   3: 0.025124882564522   0: 0.025110197919756   8: 0.025105009826871   4: 0.025103932855581   2: 0.025102713830986   7: 0.025102078639355 

test_16739        6: 0.443062029214343   5: 0.273627632678300   7: 0.107088030251068   4: 0.060116384393595   3: 0.033309522566279   9: 0.032202303616445   8: 0.012743534141484   1: 0.012624029737923   0: 0.012613598145462   2: 0.012612935255102 

test_16740        6: 0.862556116228626   5: 0.015315960119348   0: 0.015267095148345   3: 0.015266222574849   1: 0.015266110492066   9: 0.015266049517347   4: 0.015265859556972   8: 0.015265628756385   7: 0.015265558024860   2: 0.015265399581202 

test_16743        6: 0.588074325699161   7: 0.193412768684281   1: 0.027326185288293   0: 0.027314331938097   8: 0.027314025211232   9: 0.027312564568607   5: 0.027311590222592   3: 0.027311454774251   2: 0.027311426322189   4: 0.027311327291296 

test_16744        6: 0.595139061876193   1: 0.187434735898172   7: 0.076666131499748   0: 0.020116705316524   8: 0.020109714538698   9: 0.020107462207403   5: 0.020106928181600   2: 0.020106558309253   3: 0.020106353684707   4: 0.020106348487702 

test_16745        6: 0.863289755519614   0: 0.015190851232412   5: 0.015190752035148   1: 0.015190270626860   9: 0.015189909214966   4: 0.015189877687344   8: 0.015189807695094   7: 0.015189754049729   3: 0.015189512770977   2: 0.015189509167858 

test_16746        6: 0.764891423064165   5: 0.026125682200674   9: 0.026123832387705   7: 0.026123284323316   0: 0.026123272951560   1: 0.026123258444998   8: 0.026123043167752   2: 0.026122360769775   3: 0.026122016645246   4: 0.026121826044809 

test_16747        5: 0.493609381525142   6: 0.277747214007140   1: 0.140219325448868   4: 0.012638242369756   0: 0.012633500991919   2: 0.012630693670681   8: 0.012630643689128   9: 0.012630597174282   7: 0.012630205526961   3: 0.012630195596123 

test_16749        3: 0.344933042623751   6: 0.324991143586059   8: 0.184274510264799   1: 0.047192547709274   7: 0.016479823168132   0: 0.016472573858863   5: 0.016417476838811   9: 0.016416974697285   2: 0.016411052882492   4: 0.016410854370534 

test_16750        6: 0.650792347927935   9: 0.123678613420708   0: 0.100304816827346   5: 0.017897421729450   8: 0.017888998932071   1: 0.017887732120888   7: 0.017887667094413   3: 0.017887568658652   2: 0.017887538956205   4: 0.017887294332333 

test_16751        6: 0.757741114374764   9: 0.078671758988505   5: 0.020457125742589   1: 0.020448791533821   4: 0.020448246845444   8: 0.020447225894320   0: 0.020446969939266   7: 0.020446342255300   3: 0.020446280490129   2: 0.020446143935862 

test_16752        6: 0.857255865081131   5: 0.015861436657982   0: 0.015860902362858   8: 0.015860804255551   1: 0.015860734499023   9: 0.015860219837309   4: 0.015860188798151   7: 0.015860125203196   3: 0.015859871153248   2: 0.015859852151552 

test_16753        6: 0.707026776152261   7: 0.121565344730947   4: 0.048779851621948   0: 0.017529920173244   1: 0.017523745758244   9: 0.017516969490416   5: 0.017515938664482   8: 0.017515397453838   2: 0.017513071681453   3: 0.017512984273167 

test_16754        6: 0.748580136285365   1: 0.027938803312036   8: 0.027938344390780   7: 0.027936570962275   0: 0.027936189941048   9: 0.027934951427774   5: 0.027933948977415   3: 0.027933740229538   2: 0.027933688669844   4: 0.027933625803923 

test_16755        8: 0.401529772685561   6: 0.384345007073290   3: 0.090691254719655   7: 0.017635806044682   9: 0.017634890048880   0: 0.017634650075776   5: 0.017633982835362   1: 0.017632275361341   2: 0.017631213874621   4: 0.017631147280833 

test_16759        6: 0.569427344319753   0: 0.226896005532855   1: 0.134356026212005   7: 0.009903603835628   5: 0.009903196736109   9: 0.009902989065872   3: 0.009902806560946   8: 0.009902778038033   4: 0.009902650843506   2: 0.009902598855296 

test_16761        6: 0.528173197712998   1: 0.238700926276604   7: 0.108063525150995   0: 0.017869381962278   8: 0.017869153245539   5: 0.017866913755633   9: 0.017866202976148   3: 0.017863612303500   2: 0.017863555050115   4: 0.017863531566188 

test_16762        6: 0.850732357469260   1: 0.016587582465114   2: 0.016585858658888   0: 0.016585205096362   5: 0.016585142568261   9: 0.016585037028206   7: 0.016584939401539   8: 0.016584698612251   4: 0.016584666220207   3: 0.016584512479912 

test_16763        6: 0.632415310425133   5: 0.264714924517924   7: 0.012864222490531   8: 0.012861704023594   4: 0.012858651395317   0: 0.012858063804232   1: 0.012857152568092   9: 0.012856844044669   3: 0.012856774259663   2: 0.012856352470846 

test_16765        6: 0.493431809854318   9: 0.291504217322090   0: 0.100857418445529   8: 0.027724563273792   5: 0.014464526542973   4: 0.014405739146837   1: 0.014403396691904   7: 0.014403026490375   3: 0.014402683947590   2: 0.014402618284592 

test_16766        6: 0.590377160511373   9: 0.199773675864067   0: 0.113625565980515   7: 0.013748377757854   1: 0.013747566967939   5: 0.013746307499561   8: 0.013746044015223   2: 0.013746036980125   4: 0.013744636612848   3: 0.013744627810494 

test_16767        6: 0.570867343079557   9: 0.294345764634469   0: 0.016852598931342   8: 0.016849971002806   5: 0.016848621133696   1: 0.016848304546050   7: 0.016847470258006   4: 0.016846938817256   2: 0.016846643617208   3: 0.016846343979611 

test_16770        6: 0.616053319940259   5: 0.211985262820479   1: 0.053523889902707   0: 0.016922914139281   3: 0.016920977810597   8: 0.016919431837883   9: 0.016918860903302   4: 0.016918519574522   7: 0.016918414206433   2: 0.016918408864537 

test_16772        6: 0.660817534894387   9: 0.162101926526746   5: 0.042289602850960   0: 0.040681450266630   8: 0.015685267032536   1: 0.015684949710182   3: 0.015684947286645   2: 0.015684841114609   7: 0.015684795682847   4: 0.015684684634457 

test_16774        6: 0.607500973824514   5: 0.255017622216441   0: 0.043854488153465   1: 0.013383748092726   3: 0.013374807268251   9: 0.013374175795125   8: 0.013374010465759   7: 0.013373603534339   2: 0.013373319587442   4: 0.013373251061938 

test_16775        6: 0.628555540192483   7: 0.179244696696002   1: 0.095601763597983   8: 0.013801516893151   3: 0.013801018844725   5: 0.013800528262075   0: 0.013799570696860   4: 0.013799305711168   9: 0.013798914604663   2: 0.013797144500890 

test_16776        4: 0.284440493621180   6: 0.274931425945473   7: 0.256520305787332   1: 0.075047609475783   0: 0.018236136012757   5: 0.018189659107362   3: 0.018176861720213   2: 0.018170945705726   9: 0.018154809527188   8: 0.018131753096985 

test_16777        6: 0.590271778661794   0: 0.327967955764492   1: 0.025057160376719   8: 0.008115807748769   4: 0.008104351178258   5: 0.008098144451990   7: 0.008096290614132   2: 0.008096226901171   9: 0.008096179876674   3: 0.008096104426001 

test_16779        6: 0.517506714740588   8: 0.358568362615039   9: 0.015492088066482   0: 0.015491828447982   7: 0.015491487408019   1: 0.015491308382252   5: 0.015490972290948   4: 0.015489337502010   2: 0.015488969380447   3: 0.015488931166232 

test_16783        6: 0.782443930217788   1: 0.054245399745360   9: 0.038241270018098   3: 0.035698573506272   0: 0.014907790707829   5: 0.014895282534165   4: 0.014892785591016   8: 0.014891914986225   7: 0.014891604802987   2: 0.014891447890259 

test_16784        6: 0.645431980629586   5: 0.196006199014885   0: 0.080705027057726   1: 0.012646667079096   9: 0.010876400607953   8: 0.010869076006004   7: 0.010867275977882   3: 0.010865861502523   2: 0.010865855799142   4: 0.010865656325204 

test_16787        6: 0.573903536793431   5: 0.215778341352847   0: 0.118066488165328   1: 0.013181853879875   3: 0.013179036064689   9: 0.013178649697134   8: 0.013178565950377   7: 0.013177868102492   2: 0.013177858741029   4: 0.013177801252797 

test_16788        0: 0.484813905435199   6: 0.424550323028616   1: 0.011332164035381   8: 0.011330185094226   5: 0.011329434803341   7: 0.011329129341774   9: 0.011328862093182   4: 0.011328769168645   3: 0.011328644837140   2: 0.011328582162495 

test_16790        6: 0.632408989828249   5: 0.264721247949707   7: 0.012864221238362   8: 0.012861703218156   4: 0.012858651054210   0: 0.012858063645119   1: 0.012857152548025   9: 0.012856843964565   3: 0.012856774143437   2: 0.012856352410169 

test_16792        5: 0.449757034967717   0: 0.418444193768844   6: 0.016475932436918   1: 0.016475667639769   8: 0.016474813400385   7: 0.016474653893225   2: 0.016474558328072   4: 0.016474482238899   3: 0.016474352605871   9: 0.016474310720299 

test_16794        6: 0.755352974376359   1: 0.098663225546126   4: 0.066778315450300   0: 0.022028197214760   8: 0.009782047762512   9: 0.009485694830110   5: 0.009481299402695   7: 0.009476460260017   3: 0.009475993798696   2: 0.009475791358426 

test_16795        5: 0.697557901364227   3: 0.135454416306882   0: 0.020875964329471   6: 0.020875363093291   4: 0.020875010489135   8: 0.020872478969065   1: 0.020872332136997   2: 0.020872269693427   7: 0.020872137572181   9: 0.020872126045325 

test_16796        0: 0.625641157949166   8: 0.213066038742181   6: 0.020170849249340   5: 0.020166720621743   1: 0.020162924455020   3: 0.020161405552143   4: 0.020158498719978   2: 0.020157977257528   9: 0.020157728976742   7: 0.020156698476158 

test_16797        5: 0.677532071087630   7: 0.137280646909900   4: 0.023152385649362   8: 0.023149358719410   6: 0.023148897854937   9: 0.023147908585031   0: 0.023147761681602   1: 0.023147132677472   2: 0.023146939717214   3: 0.023146897117440 

test_16798        5: 0.808253776957986   4: 0.021313717400631   6: 0.021304687996936   1: 0.021304659591990   0: 0.021304581653840   7: 0.021304058232661   8: 0.021303726410640   3: 0.021303636518257   9: 0.021303607861402   2: 0.021303547375657 

test_16799        5: 0.520719911005786   0: 0.296426224657573   4: 0.022859269955099   1: 0.022856862167031   6: 0.022856544561585   7: 0.022856390596060   2: 0.022856328391722   8: 0.022856178315688   3: 0.022856166288161   9: 0.022856124061297 

test_16800        7: 0.444400388748075   5: 0.316428003507127   4: 0.029903392689241   6: 0.029896725377550   0: 0.029895840464209   2: 0.029895439104037   1: 0.029895276414143   9: 0.029895036856363   3: 0.029895029629503   8: 0.029894867209751 

test_16801        5: 0.630829454643519   8: 0.173053283473406   4: 0.024518973506135   1: 0.024514456662523   0: 0.024514295364334   6: 0.024514201626066   3: 0.024513909767181   2: 0.024513858608645   9: 0.024513793222512   7: 0.024513773125680 

test_16802        4: 0.759272237338817   5: 0.026761740009550   6: 0.026753977021670   0: 0.026748183820496   1: 0.026746045154645   2: 0.026744202785680   8: 0.026743791151965   7: 0.026743613878792   3: 0.026743330773519   9: 0.026742878064866 

test_16803        5: 0.785430646586758   6: 0.023844791691988   8: 0.023844133927128   9: 0.023841622912230   1: 0.023841124800191   4: 0.023840969096411   0: 0.023840416633034   7: 0.023839510028762   2: 0.023838571708109   3: 0.023838212615390 

test_16804        5: 0.686894205387406   8: 0.132460716840236   6: 0.052047651641286   4: 0.018376816340386   2: 0.018370710269961   1: 0.018370094249989   0: 0.018370058645028   9: 0.018370013114477   3: 0.018369908452674   7: 0.018369825058558 

test_16806        5: 0.618598418800870   4: 0.128915067043431   9: 0.096904116421608   8: 0.022232701411401   0: 0.022225174883250   3: 0.022225160307790   6: 0.022224966374609   1: 0.022224936697262   2: 0.022224820875311   7: 0.022224637184468 

test_16807        4: 0.548432981756625   0: 0.243259389359554   9: 0.026050540825278   5: 0.026043953991240   6: 0.026042041306267   7: 0.026035590088126   8: 0.026034508029479   2: 0.026033846726057   1: 0.026033614309043   3: 0.026033533608330 

test_16808        5: 0.655942930681630   7: 0.136016791007642   4: 0.026012620271164   0: 0.026004186070955   8: 0.026004091306496   3: 0.026004001489006   6: 0.026003912514031   2: 0.026003864445803   1: 0.026003835542608   9: 0.026003766670665 

test_16809        4: 0.744742692243673   5: 0.028372023407835   7: 0.028362245752245   8: 0.028360640104242   3: 0.028360497305105   9: 0.028360439868974   0: 0.028360437236310   2: 0.028360371933096   1: 0.028360342692680   6: 0.028360309455840 

test_16810        5: 0.535017717191929   7: 0.263628882047724   4: 0.025174811782667   6: 0.025172266807765   8: 0.025168420614060   9: 0.025167912791297   0: 0.025167651406671   1: 0.025167560686223   3: 0.025167527051678   2: 0.025167249619986 

test_16811        0: 0.755923001408746   9: 0.096819085299438   6: 0.018408839940114   5: 0.018408522453864   1: 0.018408152901750   4: 0.018406980850844   8: 0.018406960624836   7: 0.018406250595530   2: 0.018406207336483   3: 0.018405998588396 

test_16812        5: 0.678033118532942   2: 0.155235014943087   4: 0.020847133801113   3: 0.020840799192148   8: 0.020840794062453   0: 0.020840737212900   9: 0.020840656122796   6: 0.020840623793496   7: 0.020840620376083   1: 0.020840501962981 

test_16813        5: 0.436499739044554   0: 0.295604248471706   8: 0.108728145459163   6: 0.022741117752599   4: 0.022739665760318   7: 0.022739040921947   1: 0.022737412013105   9: 0.022737303840725   3: 0.022736695924630   2: 0.022736630811253 

test_16814        4: 0.699287203987729   5: 0.033422405724227   3: 0.033411517802883   0: 0.033411468598685   8: 0.033411368458928   2: 0.033411346453236   9: 0.033411275627359   1: 0.033411230637895   7: 0.033411126689299   6: 0.033411056019760 

test_16815        4: 0.771074583162764   5: 0.025442318792400   6: 0.025435902293143   0: 0.025435638833267   8: 0.025435430574151   3: 0.025435282868016   2: 0.025435269499905   9: 0.025435236788229   1: 0.025435204594734   7: 0.025435132593391 

test_16816        2: 0.477137954433898   5: 0.271663572654389   4: 0.031411342745884   3: 0.031398756700100   8: 0.031398650736495   7: 0.031398130898894   9: 0.031398035624316   0: 0.031397986302162   1: 0.031397898924121   6: 0.031397670979741 

test_16817        5: 0.728071590492549   9: 0.110074134512738   4: 0.020235578360855   1: 0.020231714083764   0: 0.020231392344782   2: 0.020231317879761   3: 0.020231225051633   8: 0.020231115441808   7: 0.020231030109283   6: 0.020230901722827 

test_16818        5: 0.803904720457544   6: 0.021791826593227   7: 0.021790994961789   1: 0.021789464307021   4: 0.021788880235574   0: 0.021787223036236   9: 0.021787115467950   3: 0.021786751522687   8: 0.021786546451797   2: 0.021786476966175 

test_16819        5: 0.806799412282391   0: 0.021474021496121   6: 0.021471019406166   4: 0.021468860529457   2: 0.021464707588037   3: 0.021464606817012   1: 0.021464575637083   8: 0.021464342950838   9: 0.021464247224558   7: 0.021464206068337 

test_16824        0: 0.817377621996664   5: 0.020301921020843   4: 0.020293493024708   6: 0.020292839808192   1: 0.020290442873733   9: 0.020289689670760   8: 0.020289040977653   7: 0.020288523714783   2: 0.020288254508842   3: 0.020288172403822 

test_16825        4: 0.712736793549574   1: 0.111882595886160   0: 0.021957263251286   5: 0.021922732408191   8: 0.021919767048665   6: 0.021916527939569   7: 0.021916367420309   9: 0.021916171599174   3: 0.021915891999212   2: 0.021915888897860 

test_16826        0: 0.439196041349798   1: 0.423017027584478   4: 0.017229220261142   5: 0.017226256266881   6: 0.017225014620184   8: 0.017224270752140   9: 0.017220895572430   7: 0.017220858343060   2: 0.017220261544604   3: 0.017220153705283 

test_16833        6: 0.410043413008491   2: 0.180446957819536   4: 0.163909587452208   1: 0.086253151195580   0: 0.067107677114316   7: 0.031598181283820   9: 0.019734339303867   5: 0.013642871005853   8: 0.013633165385058   3: 0.013630656431271 

test_16834        5: 0.764298234829544   3: 0.026189699878212   4: 0.026189349386519   8: 0.026189088528149   0: 0.026188986138409   6: 0.026188984467493   2: 0.026188955902359   7: 0.026188930750571   1: 0.026188910500118   9: 0.026188859618625 

test_16835        5: 0.446275085981677   2: 0.364893519714572   6: 0.023605793808347   3: 0.023604610273426   0: 0.023603880394819   4: 0.023603855496747   1: 0.023603817294467   8: 0.023603239938062   7: 0.023603118891921   9: 0.023603078205963 

test_16836        4: 0.392757191210624   5: 0.390898787679601   3: 0.027044834204817   2: 0.027042835867515   0: 0.027042834721306   1: 0.027042821410730   6: 0.027042712906287   7: 0.027042695072697   8: 0.027042667054252   9: 0.027042619872171 

test_16837        5: 0.437535335684339   8: 0.345371225162707   3: 0.027138301044522   4: 0.027137428427790   2: 0.027136341062360   0: 0.027136331166965   6: 0.027136317490500   1: 0.027136275718499   7: 0.027136259410772   9: 0.027136184831545 

test_16838        3: 0.430232378093773   5: 0.354937744751190   4: 0.026854800440789   2: 0.026853648484480   6: 0.026853638132884   0: 0.026853630250694   7: 0.026853580277378   1: 0.026853575605382   8: 0.026853510775084   9: 0.026853493188348 

test_16839        0: 0.472033996945553   5: 0.341578936359095   2: 0.023313408270156   3: 0.023297147683994   1: 0.023297118883718   4: 0.023296791606704   6: 0.023296163532695   9: 0.023295544228647   8: 0.023295449577921   7: 0.023295442911517 

test_16843        6: 0.663100950246929   1: 0.189297649217425   5: 0.018456323717671   4: 0.018453031231673   7: 0.018450147793008   0: 0.018449241805169   9: 0.018448969723258   8: 0.018448125237135   2: 0.018447783820489   3: 0.018447777207243 

test_16848        5: 0.690155627461599   0: 0.149925458303661   4: 0.019994224807944   6: 0.019989855101418   8: 0.019989574562550   1: 0.019989141642897   9: 0.019989062554931   3: 0.019989051645954   2: 0.019989014919740   7: 0.019988988999305 

test_16850        5: 0.525754176942393   7: 0.280217011212835   6: 0.024267234713697   4: 0.024254398880130   1: 0.024252272520062   9: 0.024251989444050   8: 0.024251893101921   0: 0.024251677155323   2: 0.024249685244692   3: 0.024249660784896 

test_16851        6: 0.886880648775569   0: 0.012574269059950   1: 0.012570369900909   5: 0.012570079347676   4: 0.012567819836998   8: 0.012567560846913   2: 0.012567382835178   9: 0.012567335277678   7: 0.012567331215148   3: 0.012567202903981 

test_16852        6: 0.661296881158976   0: 0.122026403423662   2: 0.113263292840091   9: 0.026869301893665   1: 0.019250911217247   7: 0.011462412323997   8: 0.011459188060083   5: 0.011457629659383   4: 0.011457088627980   3: 0.011456890794915 

test_16853        6: 0.722440699835052   9: 0.165150900367229   1: 0.031561918642367   0: 0.011551002698174   4: 0.011550954232045   8: 0.011550004217919   5: 0.011549166110269   3: 0.011548784536450   7: 0.011548385177674   2: 0.011548184182821 

test_16854        6: 0.830085743623717   9: 0.018880120973099   5: 0.018879910206344   0: 0.018879565768280   7: 0.018879490219669   8: 0.018879274612982   1: 0.018879237568345   2: 0.018878945475760   4: 0.018878860703108   3: 0.018878850848696 

test_16856        6: 0.792222218041048   0: 0.069927534662184   7: 0.044684619197587   1: 0.022116548123907   8: 0.012439114823978   3: 0.011727856540574   9: 0.011720916185047   2: 0.011720452881432   5: 0.011720385885667   4: 0.011720353658576 

test_16858        5: 0.476000918740976   7: 0.345163770775280   0: 0.022367178097772   4: 0.022354565330731   6: 0.022353072277822   3: 0.022352608166925   8: 0.022352063105794   2: 0.022352018243142   9: 0.022351914182725   1: 0.022351891078833 

test_16865        5: 0.795795636289344   4: 0.022692992271773   2: 0.022691421048193   8: 0.022688908253969   6: 0.022688897164801   9: 0.022688617281379   1: 0.022688393314975   7: 0.022688390200626   0: 0.022688376437271   3: 0.022688367737669 

test_16868        8: 0.341924396896599   6: 0.261929096138011   0: 0.203716328920278   5: 0.086988920842511   1: 0.026853648180510   9: 0.015719335409167   7: 0.015717314016968   4: 0.015716995394253   3: 0.015716985735988   2: 0.015716978465717 

test_16871        6: 0.609245746761305   1: 0.279914916209780   8: 0.021934769369205   0: 0.012719882240364   5: 0.012700103048307   9: 0.012697831488116   4: 0.012696849336595   7: 0.012696848302961   3: 0.012696788699839   2: 0.012696264543529 

test_16872        1: 0.835486283460020   5: 0.018286030341531   6: 0.018282504427090   8: 0.018279253078363   0: 0.018278615710338   9: 0.018277907851889   4: 0.018277538680652   7: 0.018277415613632   2: 0.018277370711547   3: 0.018277080124940 

test_16873        5: 0.481778315616959   6: 0.288254866142323   7: 0.055104107526259   1: 0.024990738441922   0: 0.024981390853785   2: 0.024978806771737   8: 0.024978196380779   9: 0.024978078707465   4: 0.024977808220645   3: 0.024977691338126 

test_16874        1: 0.828442055780254   0: 0.019166851145605   2: 0.019072551761781   5: 0.019053151349161   6: 0.019045352132150   8: 0.019044597458934   9: 0.019044178314365   4: 0.019043924628216   7: 0.019043673007540   3: 0.019043664421993 

test_16875        6: 0.417666899588463   7: 0.258437710588602   5: 0.224348828397191   1: 0.014231600234767   0: 0.014225061849374   4: 0.014222413989988   2: 0.014218814743573   9: 0.014216688524792   3: 0.014216021807695   8: 0.014215960275554 

test_16884        5: 0.766521668199493   3: 0.025942887529755   4: 0.025942338309728   8: 0.025941961336344   0: 0.025941921857278   6: 0.025941892116863   2: 0.025941867372385   7: 0.025941844908694   1: 0.025941820730492   9: 0.025941797638968 

test_16885        5: 0.824660432356204   6: 0.019493284093248   9: 0.019491720984717   2: 0.019489397363165   7: 0.019480406228191   3: 0.019479983277288   0: 0.019477820692106   1: 0.019477291451226   8: 0.019474875325302   4: 0.019474788228553 

test_16886        5: 0.775145606487377   3: 0.025005111445899   4: 0.024986328084050   8: 0.024980636893583   2: 0.024980487394931   0: 0.024980460748376   9: 0.024980444762950   7: 0.024980412662733   6: 0.024980370491305   1: 0.024980141028797 

test_16888        4: 0.787562330239541   0: 0.063672772712578   1: 0.018607821697414   5: 0.018601005591568   6: 0.018594327916435   3: 0.018592490129066   8: 0.018592381999183   2: 0.018592318822721   9: 0.018592301822458   7: 0.018592249069038 

test_16890        5: 0.470377609016771   3: 0.334217257301408   4: 0.024428652402698   2: 0.024425282160470   0: 0.024425276971966   8: 0.024425276310371   9: 0.024425218178193   7: 0.024425169421479   6: 0.024425129648741   1: 0.024425128587901 

test_16893        5: 0.730812391357646   8: 0.072510925893527   4: 0.047091437460929   9: 0.046502442918822   6: 0.017239134869958   1: 0.017171157795359   0: 0.017170524750359   7: 0.017167529362035   2: 0.017167370957636   3: 0.017167084633729 

test_16897        6: 0.633115047241897   3: 0.250508615154760   0: 0.014626218483101   1: 0.014567845809592   5: 0.014555650131810   7: 0.014531482417353   4: 0.014528540512605   9: 0.014523901880219   8: 0.014521520086754   2: 0.014521178281909 

test_16903        6: 0.670420154566250   0: 0.145256975179465   9: 0.061970321143929   7: 0.017489559601336   2: 0.017482766708327   8: 0.017477030941906   1: 0.017476663944937   5: 0.017476344153923   3: 0.017475222796090   4: 0.017474960963837 

test_16908        5: 0.581548464951895   6: 0.251523035379035   8: 0.020882256430288   0: 0.020867145735111   9: 0.020864204825955   1: 0.020863836317890   7: 0.020863651706957   4: 0.020863083339216   2: 0.020862786788878   3: 0.020861534524775 

test_16909        8: 0.401902360427804   5: 0.347017930408695   6: 0.122113538832593   1: 0.018450255880196   0: 0.018424625454622   4: 0.018420566079282   9: 0.018419003337701   2: 0.018417310905513   3: 0.018417304376132   7: 0.018417104297463 

test_16910        5: 0.818062907186751   4: 0.020219074380108   1: 0.020216198838292   0: 0.020215364835095   6: 0.020215123341422   8: 0.020214612739582   9: 0.020214376355562   3: 0.020214221102580   7: 0.020214071693673   2: 0.020214049526934 

test_16911        4: 0.573515513794259   8: 0.199536400323525   6: 0.028398294059798   5: 0.028369092028748   3: 0.028364316666996   2: 0.028364170620852   7: 0.028363969512141   9: 0.028363478721175   1: 0.028362397337010   0: 0.028362366935494 

test_16912        4: 0.507978562720707   8: 0.255921017104192   5: 0.029521272827671   3: 0.029511556086617   0: 0.029511455421830   2: 0.029511420523593   1: 0.029511401543838   9: 0.029511135527295   7: 0.029511109078448   6: 0.029511069165809 

test_16913        5: 0.693814021779689   1: 0.136211428498490   4: 0.021248599188841   6: 0.021248574657018   8: 0.021247676061236   9: 0.021246574104460   0: 0.021246482584321   2: 0.021245640962157   7: 0.021245636689089   3: 0.021245365474699 

test_16916        5: 0.801342068108615   6: 0.022075499676529   2: 0.022075231599321   4: 0.022074944369494   9: 0.022072596002669   1: 0.022072396467016   0: 0.022072149046236   3: 0.022071924500112   8: 0.022071671449712   7: 0.022071518780297 

test_16917        9: 0.637158981564137   1: 0.197840238651127   5: 0.020630796793775   4: 0.020626250702582   6: 0.020626167090975   0: 0.020626078807158   2: 0.020623394817201   8: 0.020622940051647   7: 0.020622704165867   3: 0.020622447355532 

test_16918        4: 0.422448885780099   2: 0.326705026558914   5: 0.031363956992624   6: 0.031356853713410   9: 0.031356117158015   0: 0.031354446764444   1: 0.031354188087902   7: 0.031353541513649   8: 0.031353533608425   3: 0.031353449822518 

test_16921        5: 0.745262534562031   4: 0.028307463925079   6: 0.028305163844710   9: 0.028304217364923   0: 0.028304173264091   8: 0.028303580335477   1: 0.028303367906519   3: 0.028303230351166   2: 0.028303156031016   7: 0.028303112414987 

test_16922        2: 0.442870568331857   6: 0.256503405966387   3: 0.089387108714345   5: 0.030184419902754   1: 0.030179023843783   0: 0.030177682935428   9: 0.030177420144636   4: 0.030176541036242   8: 0.030174745340313   7: 0.030169083784255 

test_16923        1: 0.773336728184948   9: 0.025188781133009   5: 0.025186587991287   6: 0.025185167338777   0: 0.025184946883597   4: 0.025184517037487   8: 0.025183996372870   2: 0.025183265324661   7: 0.025183095991043   3: 0.025182913742321 

test_16925        1: 0.427802324764054   7: 0.406411973711134   9: 0.038828962279579   6: 0.018535632248131   4: 0.018423123947113   0: 0.018016132677484   3: 0.018005923892324   5: 0.017994877263485   2: 0.017990608732658   8: 0.017990440484036 

test_16926        6: 0.882381128397592   0: 0.039191580799010   4: 0.013660500716016   5: 0.009266833596738   9: 0.009256319634622   1: 0.009252590765813   7: 0.009248957368129   8: 0.009247547045566   2: 0.009247300824200   3: 0.009247240852315 

test_16929        6: 0.624552889637739   0: 0.257654470010036   1: 0.014727787231937   5: 0.014724204559015   7: 0.014723671182663   8: 0.014723589768085   9: 0.014723468986005   4: 0.014723433664356   2: 0.014723290362743   3: 0.014723194597422 

test_16932        6: 0.668311830409877   5: 0.211985206420323   1: 0.014967988150216   0: 0.014965731630034   4: 0.014962215599274   8: 0.014962008763349   3: 0.014961298807524   9: 0.014961277566940   2: 0.014961255538806   7: 0.014961187113657 

test_17031        5: 0.685817547638989   3: 0.139039818627937   6: 0.021928440355410   9: 0.021905971174670   4: 0.021889041703439   0: 0.021888985818560   7: 0.021885438411524   1: 0.021881811887619   8: 0.021881491212482   2: 0.021881453169369 

test_17032        4: 0.788474603647110   5: 0.023514051628756   8: 0.023501835351898   6: 0.023501802978453   7: 0.023501390314124   2: 0.023501378459382   3: 0.023501282105406   0: 0.023501267038776   1: 0.023501217275432   9: 0.023501171200662 

test_17034        4: 0.827302422205868   8: 0.019221997759655   6: 0.019194946592880   5: 0.019191557711881   0: 0.019184284801782   9: 0.019183198041643   1: 0.019181959262345   7: 0.019180186579653   2: 0.019180100147140   3: 0.019179346897153 

test_17035        4: 0.718580953762297   0: 0.101625656723462   7: 0.022511133003511   5: 0.022477708454906   3: 0.022468450522026   2: 0.022467467385449   8: 0.022467353251148   9: 0.022467304167304   1: 0.022467030537675   6: 0.022466942192222 

test_17036        8: 0.394371258900275   6: 0.363640774440929   0: 0.148924148944561   1: 0.033295034313656   5: 0.009966308177404   9: 0.009962035738378   7: 0.009960747836835   2: 0.009960093430851   4: 0.009959961832585   3: 0.009959636384526 

test_17037        5: 0.562642854677355   3: 0.221028761722724   0: 0.086537631470134   1: 0.018556868566326   6: 0.018546737076488   4: 0.018541855309869   8: 0.018536454200862   9: 0.018536413331971   2: 0.018536406451635   7: 0.018536017192636 

test_17038        6: 0.890670891670167   0: 0.012152017595214   1: 0.012149383363268   5: 0.012147530563780   2: 0.012146957318581   9: 0.012146689332390   7: 0.012146653083161   3: 0.012146631492213   8: 0.012146626272248   4: 0.012146619308978 

test_17039        1: 0.752149721567152   6: 0.140821870531457   8: 0.013489213242522   5: 0.013363926148386   0: 0.013363574787303   3: 0.013362790464513   2: 0.013362521360184   9: 0.013362329331375   4: 0.013362071753347   7: 0.013361980813761 

test_17041        6: 0.720632335830432   0: 0.101124782186998   7: 0.055588295751393   1: 0.017529380269733   5: 0.017523006120425   8: 0.017521511189009   9: 0.017520726034307   3: 0.017520294262056   2: 0.017519889205944   4: 0.017519779149703 

test_17042        6: 0.630413636065567   9: 0.195033287019108   1: 0.055703972026377   5: 0.016984752854301   4: 0.016981971673959   0: 0.016981069633776   8: 0.016980891386607   7: 0.016974363859746   2: 0.016973074665928   3: 0.016972980814632 

test_17044        1: 0.736961374271750   6: 0.029237144687031   0: 0.029227091235405   7: 0.029225686926406   9: 0.029225479954961   8: 0.029225074676928   5: 0.029224755320307   2: 0.029224545943000   4: 0.029224427423074   3: 0.029224419561137 

test_17045        6: 0.758135140014882   0: 0.026874987176194   5: 0.026874760615770   8: 0.026874749134480   4: 0.026874406480715   7: 0.026874206253360   1: 0.026873469996050   2: 0.026872870403439   9: 0.026872793867740   3: 0.026872616057368 

test_17046        6: 0.745831478368968   9: 0.028249163209130   1: 0.028243430315464   4: 0.028243327011507   5: 0.028242957243040   0: 0.028240610626218   2: 0.028239724368356   7: 0.028237726673747   3: 0.028235938244341   8: 0.028235643939228 

test_17047        6: 0.776127150257180   3: 0.093116317540080   0: 0.050612103945277   9: 0.011456881663291   2: 0.011451854412489   1: 0.011450079936273   5: 0.011450047529791   7: 0.011445622937597   4: 0.011445090055721   8: 0.011444851722299 

test_17048        6: 0.533308082915659   9: 0.243180709542255   1: 0.073094290593885   4: 0.049695154903483   0: 0.016797061206621   5: 0.016788750101697   3: 0.016784621069100   7: 0.016784002339394   2: 0.016783902278289   8: 0.016783425049616 

test_17051        6: 0.561671407418584   1: 0.296439462162748   0: 0.041358215074497   5: 0.014363263263919   9: 0.014361852199276   8: 0.014361762658371   7: 0.014361321435983   3: 0.014360998847836   4: 0.014360918436056   2: 0.014360798502730 

test_17052        6: 0.665528254606227   9: 0.171271515389248   5: 0.020410891991544   1: 0.020402869840209   0: 0.020401311060989   8: 0.020398382318212   2: 0.020397732001680   4: 0.020396637675757   3: 0.020396370147542   7: 0.020396034968593 

test_17053        3: 0.473968867283082   1: 0.354971693339928   4: 0.044794677026096   6: 0.018051080888726   5: 0.018038079891083   0: 0.018037461581268   8: 0.018034878157129   9: 0.018034624791754   7: 0.018034484327645   2: 0.018034152713288 

test_17054        6: 0.502663817848809   4: 0.229511688514486   5: 0.113828698938299   8: 0.050365179733874   1: 0.042612366425948   3: 0.012213507072387   0: 0.012206621234021   2: 0.012199956777421   9: 0.012199795590590   7: 0.012198367864162 

test_17436        6: 0.524745903262026   0: 0.343852958784204   1: 0.016461516668973   3: 0.016422445359688   8: 0.016422301536161   9: 0.016419047892175   7: 0.016419003828601   5: 0.016418984773794   2: 0.016418948887469   4: 0.016418889006909 

test_17440        5: 0.415420573966477   6: 0.359605499287619   1: 0.028123884185389   9: 0.028123296284232   4: 0.028122522252499   8: 0.028121878654825   0: 0.028121666689435   3: 0.028120433792602   7: 0.028120296473376   2: 0.028119948413545 

test_17441        6: 0.495082577814993   3: 0.239886966576425   9: 0.113570365274425   1: 0.040845502044613   0: 0.018492202911841   5: 0.018428738786080   2: 0.018425519105604   7: 0.018423432170358   8: 0.018422486885988   4: 0.018422208429671 

test_17442        6: 0.810845483248913   5: 0.021020642318961   0: 0.021017508572037   9: 0.021017230931173   4: 0.021016801593182   8: 0.021016734229694   1: 0.021016574422205   7: 0.021016538463330   3: 0.021016287285909   2: 0.021016198934597 

test_17443        6: 0.661714658979877   5: 0.160480869794834   0: 0.086897093156733   8: 0.012991487622075   1: 0.012991144501874   7: 0.012985277887282   9: 0.012985029403066   3: 0.012984964455076   2: 0.012984864053465   4: 0.012984610145719 

test_17445        0: 0.748859727034333   8: 0.027921993963081   1: 0.027910679271447   6: 0.027908857450162   9: 0.027903087281347   3: 0.027900572804310   5: 0.027899709954767   2: 0.027898833878752   7: 0.027898311075429   4: 0.027898227286373 

test_17446        6: 0.395897089176427   9: 0.288093109040598   3: 0.187620452284647   5: 0.018345481311397   2: 0.018342610754906   1: 0.018341429558500   0: 0.018340567165967   7: 0.018340285919606   4: 0.018339667920817   8: 0.018339306867133 

test_17448        6: 0.737685150647861   1: 0.142813748317539   0: 0.014946403491535   9: 0.014940986904591   8: 0.014937282791924   7: 0.014935447128670   3: 0.014935439411114   2: 0.014935316440035   5: 0.014935259425990   4: 0.014934965440742 

test_17449        6: 0.703696647338495   5: 0.081656796577319   0: 0.074099558354406   8: 0.066977236080818   4: 0.012397982392254   7: 0.012260858932103   9: 0.012258964763984   3: 0.012217834558546   1: 0.012217474058851   2: 0.012216646943224 

test_17452        6: 0.601004795584687   1: 0.318478356595944   0: 0.010096534740099   5: 0.010060353814447   9: 0.010060226677207   8: 0.010060133096999   7: 0.010060038147688   2: 0.010059897398308   4: 0.010059834242540   3: 0.010059829702079 

test_17455        1: 0.836955676487925   6: 0.018127234496639   7: 0.018119971956057   0: 0.018116000257396   3: 0.018113931083575   9: 0.018113859687743   5: 0.018113722116577   8: 0.018113399753269   4: 0.018113233488784   2: 0.018112970672036 

test_17457        7: 0.429164455838591   6: 0.380182392918942   9: 0.066194792993651   0: 0.045107000772924   1: 0.013259078957980   5: 0.013230740973842   2: 0.013219698323261   4: 0.013215196247687   8: 0.013214031262441   3: 0.013212611710680 

test_17462        6: 0.538447386725776   0: 0.341889776381639   3: 0.014960076284235   8: 0.014958380212477   9: 0.014958240828826   1: 0.014958046631457   5: 0.014957127246993   7: 0.014957041954983   4: 0.014956965197610   2: 0.014956958536002 

test_17463        9: 0.438151719450948   6: 0.265664204753421   3: 0.160758137870141   0: 0.019367441394268   5: 0.019354100251640   1: 0.019354087413245   2: 0.019342485696470   7: 0.019340448309684   4: 0.019333754976960   8: 0.019333619883222 

test_17470        6: 0.605149439364745   0: 0.139685187015362   7: 0.106186416640870   8: 0.057950412166619   9: 0.029013005511461   1: 0.012437775651664   3: 0.012401691719402   5: 0.012392472571677   2: 0.012392145704686   4: 0.012391453653514 

test_17472        9: 0.659164040973848   6: 0.181607055784530   4: 0.019990197656647   3: 0.019940688410668   0: 0.019910191655656   5: 0.019889645910465   7: 0.019876983908452   1: 0.019874223272602   8: 0.019873495022198   2: 0.019873477404933 

test_17473        6: 0.536984380835954   3: 0.294492391323244   4: 0.021066294184563   9: 0.021065717319395   8: 0.021065586406739   0: 0.021065418751087   5: 0.021065330999340   2: 0.021065259664286   1: 0.021065089808011   7: 0.021064530707381 

test_17477        6: 0.892166654156331   5: 0.018692997286142   9: 0.011951335846639   0: 0.011148670086537   1: 0.011051262546254   2: 0.011006445120982   7: 0.010996829656506   4: 0.010995320561300   8: 0.010995316649215   3: 0.010995168090094 

test_17478        6: 0.648529862801798   2: 0.195559384543425   1: 0.066292602920957   0: 0.020171080213136   5: 0.011575365068883   7: 0.011574536230816   8: 0.011574502081134   3: 0.011574334006999   9: 0.011574273477215   4: 0.011574058655639 

test_17479        0: 0.793023003714583   6: 0.032321798204229   1: 0.021909205224746   5: 0.021826878045312   2: 0.021822098077226   9: 0.021820032242027   4: 0.021819904405187   8: 0.021819119595741   3: 0.021819055580405   7: 0.021818904910545 

test_17480        6: 0.490725898779991   3: 0.296495420033615   0: 0.125619885115292   8: 0.012564649870994   5: 0.012436525063285   1: 0.012433347235187   9: 0.012431544714720   2: 0.012431002885721   4: 0.012430902026217   7: 0.012430824274978 

test_17481        6: 0.702663276310859   4: 0.033045361602176   0: 0.033042568773433   1: 0.033038367939632   7: 0.033036461351353   9: 0.033035394058088   2: 0.033034854781197   5: 0.033034813843714   8: 0.033034492692557   3: 0.033034408646992 

test_17484        1: 0.736039865448686   5: 0.029336998491003   4: 0.029330277008454   6: 0.029329099114234   8: 0.029327962601818   9: 0.029327926994393   0: 0.029327904212317   2: 0.029326953579404   3: 0.029326557311805   7: 0.029326455237887 

test_17486        6: 0.509247568992048   3: 0.356025020959777   0: 0.047733659493738   8: 0.012550115367401   5: 0.012412741003063   1: 0.012409800081192   9: 0.012406320245472   2: 0.012405006983100   4: 0.012404926406577   7: 0.012404840467634 

test_17487        0: 0.424078180540000   7: 0.291027758249617   4: 0.035621770127055   5: 0.035621494321780   1: 0.035612497391453   2: 0.035608471076412   8: 0.035607876642720   6: 0.035607592305837   9: 0.035607249807612   3: 0.035607109537515 

test_17488        1: 0.437095056544165   9: 0.364763471071908   5: 0.083708818536760   0: 0.016698117342622   3: 0.016364837804159   8: 0.016354388529747   6: 0.016258154613865   2: 0.016254499720628   4: 0.016251755598536   7: 0.016250900237608 

test_17489        8: 0.403239072121168   5: 0.365629917149641   4: 0.028896291814000   0: 0.028891656651588   3: 0.028891159582756   2: 0.028890451853731   6: 0.028890429432721   9: 0.028890404596823   1: 0.028890355811195   7: 0.028890260986377 

test_17491        1: 0.839318569865161   5: 0.017887648675898   7: 0.017856020518396   6: 0.017852741680115   9: 0.017849778751695   0: 0.017848604160748   4: 0.017847435269787   2: 0.017847144504097   8: 0.017846400411997   3: 0.017845656162106 

test_17492        7: 0.701701851706781   6: 0.160434807706597   1: 0.017388255899175   9: 0.017340075960904   0: 0.017196362809379   8: 0.017194441217884   3: 0.017191512022977   2: 0.017186186323757   5: 0.017186105947957   4: 0.017180400404589 

test_17493        5: 0.384992875497034   3: 0.357584722839917   1: 0.032184620767592   0: 0.032180430075874   4: 0.032178863265222   2: 0.032176118598741   6: 0.032176040981071   8: 0.032175810510481   9: 0.032175387353393   7: 0.032175130110673 

test_17494        6: 0.442049680144164   5: 0.403510644852605   2: 0.052957389824609   8: 0.014534325910362   3: 0.014501708453075   7: 0.014497079000847   0: 0.014490414431527   9: 0.014488433883264   1: 0.014485500153844   4: 0.014484823345704 

test_17499        6: 0.617305968729754   1: 0.167768192771477   8: 0.111347751211355   0: 0.026298714258914   5: 0.012881160081720   7: 0.012880060267011   2: 0.012880028369045   9: 0.012879720713566   4: 0.012879310184660   3: 0.012879093412496 

test_17501        6: 0.492761588524206   4: 0.276745120889486   0: 0.028818575191117   1: 0.028816024935561   5: 0.028813203071404   8: 0.028809722265675   7: 0.028809341404642   2: 0.028809158502318   9: 0.028808830614320   3: 0.028808434601269 

test_17502        6: 0.608089583388497   0: 0.238593935730787   1: 0.039335451415351   5: 0.016327115301390   9: 0.016278050268873   2: 0.016277544866597   4: 0.016276043186289   8: 0.016274286595211   7: 0.016274037334566   3: 0.016273951912439 

test_17503        6: 0.618354441785885   0: 0.269051115093583   7: 0.020546516645022   5: 0.013150609054802   8: 0.013150144430965   9: 0.013150104602795   4: 0.013150098204348   1: 0.013149119943768   3: 0.013148963331372   2: 0.013148886907460 

test_17506        0: 0.461655564449518   4: 0.222828518007523   6: 0.216081084358495   1: 0.014322587415243   9: 0.014209075177363   7: 0.014192651712955   5: 0.014180857545616   8: 0.014177060513779   2: 0.014176365489257   3: 0.014176235330252 

test_17507        5: 0.412511905014682   3: 0.217431630707718   1: 0.213740525381567   0: 0.038051465583078   6: 0.019740537106639   7: 0.019705390446567   8: 0.019705319494036   2: 0.019704661035678   4: 0.019704504707632   9: 0.019704060522403 

test_17509        6: 0.876164568728044   0: 0.034615666992925   7: 0.011155536471823   1: 0.011154053004089   8: 0.011152767582708   3: 0.011151960859033   9: 0.011151688606945   5: 0.011151538479922   4: 0.011151185537879   2: 0.011151033736633 

test_17511        6: 0.749876690324163   0: 0.100307594502357   4: 0.048902877684756   5: 0.014530913454236   7: 0.014398596883155   8: 0.014397861895921   1: 0.014396880711393   9: 0.014396466673083   3: 0.014396079537525   2: 0.014396038333410 

test_17513        0: 0.830460992675276   6: 0.018904603800468   4: 0.018835550539815   5: 0.018834176435866   1: 0.018834136946880   8: 0.018830341492658   2: 0.018827356471081   9: 0.018824815390137   7: 0.018824134327809   3: 0.018823891920009 

test_17516        2: 0.530032313246632   6: 0.328075791579278   0: 0.017776787856542   5: 0.017742436985186   9: 0.017736319594684   1: 0.017729598720177   8: 0.017727492059593   7: 0.017726980340034   4: 0.017726577339863   3: 0.017725702278010 

test_17518        4: 0.476228316200923   1: 0.333419197454056   6: 0.023897398107887   5: 0.023787696731917   3: 0.023782837651060   2: 0.023780851140600   0: 0.023778633759311   9: 0.023775416020767   8: 0.023775318056337   7: 0.023774334877143 

test_17519        1: 0.506447583055910   6: 0.261796828000002   9: 0.147472577950849   5: 0.012077787337346   0: 0.012060451656572   2: 0.012032695010880   7: 0.012029153107484   4: 0.012027787969697   8: 0.012027752071504   3: 0.012027383839755 

test_17521        6: 0.866608023924203   0: 0.030142415538938   5: 0.012917175748390   4: 0.012909023485359   7: 0.012904528214788   8: 0.012904054102583   1: 0.012903894082839   9: 0.012903714614270   2: 0.012903653381485   3: 0.012903516907144 

test_17523        9: 0.789708314779974   8: 0.023370016890138   6: 0.023367947660383   5: 0.023366235322766   0: 0.023365111431816   1: 0.023365008066593   4: 0.023364685111175   7: 0.023364441327835   3: 0.023364136612866   2: 0.023364102796455 

test_17529        7: 0.498902114176402   0: 0.348827015725538   6: 0.019156747239421   5: 0.019020692939166   1: 0.019019765275104   4: 0.019015974260389   2: 0.019014823619626   9: 0.019014742759619   8: 0.019014740629890   3: 0.019013383374847 

test_17534        0: 0.670570049766146   7: 0.036611676802273   5: 0.036610373223546   4: 0.036605859620079   8: 0.036601048950314   1: 0.036600936506891   9: 0.036600324993057   2: 0.036600085547119   6: 0.036599961932262   3: 0.036599682658313 

test_17538        8: 0.425352203768096   5: 0.263338284758322   6: 0.132441476710028   0: 0.052837938079030   1: 0.021011993206707   3: 0.021007322781593   4: 0.021003214044846   9: 0.021003108231041   2: 0.021003094359531   7: 0.021001364060806 

test_17540        4: 0.566936275886344   6: 0.256288791419476   5: 0.056718332692736   9: 0.017162044981469   1: 0.017153862505147   8: 0.017153634215321   0: 0.017149130598577   3: 0.017147479799685   2: 0.017145420451258   7: 0.017145027449988 

test_17543        5: 0.790467997795908   4: 0.023284759887665   0: 0.023281516246755   8: 0.023281137459047   9: 0.023280910379102   1: 0.023280909469513   3: 0.023280808155831   6: 0.023280689663419   2: 0.023280668167912   7: 0.023280602774848 

test_17544        5: 0.728037121898391   6: 0.030224348889125   2: 0.030222678954622   9: 0.030220682730315   4: 0.030220169870750   1: 0.030215861280556   0: 0.030215236753321   7: 0.030215158937191   3: 0.030214702660584   8: 0.030214038025144 

test_17545        5: 0.549666823844531   1: 0.232993941232648   6: 0.027171948997328   4: 0.027169812665912   9: 0.027167676037299   0: 0.027166451188081   3: 0.027166032751340   8: 0.027165920934418   2: 0.027165720948772   7: 0.027165671399669 

test_17547        5: 0.517847876420052   1: 0.266511501273050   4: 0.026959583452952   6: 0.026958754575860   2: 0.026958082505853   9: 0.026956372456388   0: 0.026952393350659   7: 0.026952126679626   3: 0.026951849278049   8: 0.026951460007510 

test_17551        1: 0.454044274513028   4: 0.264780323255178   0: 0.163828071771762   9: 0.030071207824856   6: 0.014706099295421   5: 0.014521460006463   7: 0.014514311247365   2: 0.014512398919681   8: 0.014511111689405   3: 0.014510741476840 

test_17554        5: 0.612729102466572   0: 0.195091491866653   2: 0.024023524303186   3: 0.024022809394245   6: 0.024022684366485   4: 0.024022564512605   1: 0.024022384887711   9: 0.024022332703530   7: 0.024021620978412   8: 0.024021484520601 

test_17556        5: 0.648831106936704   8: 0.153498055893158   4: 0.024714713608956   1: 0.024708421070585   6: 0.024708169500969   0: 0.024708059589767   7: 0.024708017026026   3: 0.024707878214434   2: 0.024707819097220   9: 0.024707759062182 

test_17558        5: 0.501526228324989   0: 0.324106175463395   4: 0.021799805764074   6: 0.021795979795152   7: 0.021795732519034   8: 0.021795348028209   9: 0.021795332365791   1: 0.021795239080203   2: 0.021795104392922   3: 0.021795054266231 

test_17559        8: 0.412121487421740   5: 0.384673775318202   0: 0.058845073097081   1: 0.020635973652316   6: 0.020626747685123   9: 0.020622901162257   2: 0.020620283729657   4: 0.020618659363272   7: 0.020617829250009   3: 0.020617269320343 

test_17562        6: 0.580353211480682   0: 0.192068308138278   4: 0.072341917014206   3: 0.048080587895316   5: 0.017862909842099   9: 0.017861849412852   1: 0.017858970950176   8: 0.017858046182175   7: 0.017857103905103   2: 0.017857095179112 

test_17563        0: 0.536821692462267   2: 0.295539667034912   1: 0.037156037559406   3: 0.018687446152251   6: 0.018646622121219   7: 0.018634417369614   5: 0.018630133581420   8: 0.018628782903527   4: 0.018628027811042   9: 0.018627173004342 

test_17567        0: 0.740717237259779   1: 0.028817785446018   5: 0.028810587869223   9: 0.028810477289734   6: 0.028810379364198   7: 0.028807486023646   4: 0.028806724060412   2: 0.028806545557400   8: 0.028806468562654   3: 0.028806308566937 

test_17568        6: 0.663790714965957   4: 0.194889610958068   8: 0.035024881666090   7: 0.015212166149597   5: 0.015201054564100   1: 0.015176960631307   0: 0.015176788689311   3: 0.015176034188924   2: 0.015175949547672   9: 0.015175838638975 

test_17569        9: 0.785221453356410   6: 0.042793953914608   1: 0.021609730002093   2: 0.021503637413127   5: 0.021487895577676   0: 0.021482078210226   4: 0.021479719865346   3: 0.021474470277152   8: 0.021474129014736   7: 0.021472932368625 

test_17573        0: 0.402629391564843   1: 0.303948982128372   5: 0.197403026349808   8: 0.014189778075645   2: 0.013686223028358   6: 0.013631313803068   4: 0.013629690330411   9: 0.013627401990408   7: 0.013627216359221   3: 0.013626976369865 

test_17574        0: 0.450904007307043   1: 0.273075541037926   6: 0.113316139185972   5: 0.077728630249591   7: 0.022098468645922   9: 0.012755277354360   4: 0.012553289303771   3: 0.012524132790679   8: 0.012523474461003   2: 0.012521039663733 

test_17576        9: 0.532703434290992   1: 0.322758535209723   0: 0.018083179506340   5: 0.018069355379667   6: 0.018066279900741   4: 0.018064557812968   8: 0.018064170666002   2: 0.018063867072176   7: 0.018063356441658   3: 0.018063263719733 

test_17577        8: 0.575402719714070   6: 0.249046778116897   1: 0.062481404381853   0: 0.016160090520401   5: 0.016159612179844   9: 0.016150515506530   2: 0.016150375197715   4: 0.016149852111715   7: 0.016149481734259   3: 0.016149170536717 

test_17579        0: 0.451667207277897   1: 0.270710720223038   5: 0.161938854291201   6: 0.016532217439018   7: 0.016530815350619   9: 0.016525094623794   4: 0.016524890891295   2: 0.016523823518456   8: 0.016523410636265   3: 0.016522965748417 

test_17580        1: 0.588606085357358   4: 0.228560292711512   6: 0.040401923243880   9: 0.020423826776713   2: 0.020337011006106   0: 0.020336988711753   8: 0.020335587584846   5: 0.020334146718263   3: 0.020332071229672   7: 0.020332066659897 

test_17584        9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

test_17585        7: 0.552890358906914   6: 0.217949009689902   0: 0.133428691158375   3: 0.013727661108513   1: 0.013690033171051   8: 0.013666019673454   5: 0.013665641958685   9: 0.013664791398445   2: 0.013660509970229   4: 0.013657282964432 

test_17589        5: 0.758260248031671   6: 0.027027942029138   8: 0.026904663388736   2: 0.026887311973823   9: 0.026861236701352   0: 0.026844835879179   1: 0.026816798689997   4: 0.026799234121782   7: 0.026799076730417   3: 0.026798652453905 

test_17593        6: 0.598029786978890   4: 0.202258241317875   0: 0.066102079596158   1: 0.028287028181414   9: 0.027884812262090   7: 0.015633463077016   8: 0.015458569116586   5: 0.015451705454041   2: 0.015447906753549   3: 0.015446407262382 

test_17595        3: 0.512850159561470   5: 0.345072240487668   6: 0.017791633335297   0: 0.017764240478913   1: 0.017762603570550   2: 0.017754267691072   9: 0.017752798346493   8: 0.017751211570528   4: 0.017750697830329   7: 0.017750147127680 

test_17596        3: 0.481914003806657   1: 0.345718265942673   5: 0.021732159160564   0: 0.021580310342178   6: 0.021576160580565   4: 0.021500013566181   8: 0.021498482497797   2: 0.021493802628429   9: 0.021493632699799   7: 0.021493168775157 

test_17597        8: 0.437384129728794   6: 0.220780273005719   5: 0.185212874885858   0: 0.022391082801376   1: 0.022385838732401   4: 0.022371259730097   2: 0.022368926958048   9: 0.022368806167285   7: 0.022368691434159   3: 0.022368116556263 

test_17601        5: 0.562886808773690   6: 0.223833446432756   0: 0.093825785508847   2: 0.017068758408787   1: 0.017067113266469   9: 0.017065699811408   4: 0.017063284976667   3: 0.017063068610402   8: 0.017063059757922   7: 0.017062974453052 

test_17607        5: 0.758279160354558   6: 0.026868524040546   4: 0.026865462011023   0: 0.026857358216337   1: 0.026857139793759   8: 0.026855701635763   3: 0.026854735101714   2: 0.026853977992557   7: 0.026853976870590   9: 0.026853963983153 

test_17612        1: 0.872799138230378   5: 0.014150383519864   6: 0.014138152617096   7: 0.014136297816875   2: 0.014132323924288   0: 0.014132060744702   9: 0.014129624271621   4: 0.014127829024000   8: 0.014127650735475   3: 0.014126539115703 

test_17616        5: 0.504122388201650   1: 0.274631480348213   4: 0.027662486161732   8: 0.027657557852413   6: 0.027655344056326   9: 0.027654597122284   0: 0.027654469844540   3: 0.027654014320476   7: 0.027653858628875   2: 0.027653803463491 

test_17617        4: 0.481867091379433   1: 0.163407880810953   0: 0.154924883870893   8: 0.028547922237803   5: 0.028547034596848   7: 0.028541218222057   3: 0.028541206660775   2: 0.028541068813430   9: 0.028540877054452   6: 0.028540816353356 

test_17618        1: 0.366027125954012   6: 0.341071193748504   2: 0.190844819730075   9: 0.014600084044889   0: 0.014576796315172   5: 0.014576462606979   8: 0.014576057157505   3: 0.014575905117988   7: 0.014575807912996   4: 0.014575747411880 

test_17619        6: 0.829072717003370   5: 0.019160833838981   4: 0.018982874565176   1: 0.018975310520577   3: 0.018972504485942   0: 0.018969939985104   2: 0.018968030117589   9: 0.018967939594437   8: 0.018965245819843   7: 0.018964604068981 

test_17620        6: 0.563859303302815   0: 0.355945055841503   1: 0.010407827052456   8: 0.010111130780413   9: 0.009948291097021   5: 0.009946254125696   4: 0.009945724665114   7: 0.009945532115386   2: 0.009945522964574   3: 0.009945358055023 

test_17622        6: 0.852227098850668   5: 0.016432063370896   3: 0.016418578351472   9: 0.016418151878067   1: 0.016418109691759   0: 0.016417961521140   4: 0.016417518701856   2: 0.016417012050928   7: 0.016416782707967   8: 0.016416722875247 

test_17625        5: 0.539422564416979   0: 0.309603576951302   6: 0.018877959617547   8: 0.018877784255451   1: 0.018873697110358   9: 0.018871515491630   4: 0.018869835880733   2: 0.018868004512552   7: 0.018867621518157   3: 0.018867440245292 

test_17630        5: 0.820787384971531   6: 0.019914145591973   4: 0.019913171240502   8: 0.019912629252052   2: 0.019912619169353   7: 0.019912484526139   0: 0.019912091174904   9: 0.019912045663330   1: 0.019911881688362   3: 0.019911546721856 

test_17632        6: 0.851902418923375   9: 0.016593148985483   5: 0.016447078529132   3: 0.016438023590955   1: 0.016437170139061   0: 0.016436971596045   4: 0.016436699017458   2: 0.016436401095101   7: 0.016436128766814   8: 0.016435959356576 

test_17633        6: 0.497613189955111   7: 0.319379132574425   9: 0.022904753291487   3: 0.022893270963036   5: 0.022872293632855   0: 0.022869236908040   4: 0.022868430972278   8: 0.022866900302703   1: 0.022866873730657   2: 0.022865917669408 

test_17640        1: 0.707056566700349   5: 0.135909837995765   6: 0.019730344433955   0: 0.019639009314000   8: 0.019615923504955   3: 0.019610581509015   9: 0.019610463266715   2: 0.019609550574744   4: 0.019608949559561   7: 0.019608773140941 

test_17643        0: 0.592756617817778   5: 0.251347440121358   6: 0.019491306033043   1: 0.019490924187948   7: 0.019486110455872   4: 0.019485844624033   3: 0.019485601635275   8: 0.019485567381616   9: 0.019485357084480   2: 0.019485230658597 

test_17644        0: 0.818489793881127   5: 0.066465325975883   6: 0.014388861675495   1: 0.014380416827212   9: 0.014379534755166   4: 0.014379432067351   7: 0.014379307875314   2: 0.014379159932508   8: 0.014379154888750   3: 0.014379012121193 

test_17651        1: 0.588013041203891   4: 0.246442198899212   5: 0.020701644372621   0: 0.020696857390691   6: 0.020694024101818   2: 0.020690802792731   8: 0.020690710667008   7: 0.020690387992830   9: 0.020690258559563   3: 0.020690074019637 

test_17652        6: 0.417687640666454   2: 0.269655463363012   4: 0.164668378537660   5: 0.021158632757619   1: 0.021148099110320   0: 0.021143621543915   9: 0.021135159401344   3: 0.021134746707907   8: 0.021134265031430   7: 0.021133992880340 

test_17654        1: 0.565558867708317   6: 0.327082089485710   3: 0.021627802797971   0: 0.012307951240505   5: 0.012269258764952   7: 0.012237173910370   4: 0.012230721260062   8: 0.012228890055209   9: 0.012228722242854   2: 0.012228522534051 

test_17655        5: 0.492515686365682   7: 0.291658791136973   4: 0.026983104989356   6: 0.026979078267352   1: 0.026978717345255   0: 0.026977226356744   3: 0.026977133156823   8: 0.026976874795280   2: 0.026976709234681   9: 0.026976678351852 

test_17658        7: 0.503610000966485   6: 0.325415095235976   8: 0.036783235147925   1: 0.019207050628593   0: 0.019171765298282   5: 0.019166025168190   9: 0.019165040760749   4: 0.019162144544896   2: 0.019160313461413   3: 0.019159328787490 

test_17659        7: 0.511178690164378   6: 0.232287247389807   4: 0.074330964541851   1: 0.026059332887013   9: 0.026033671099530   5: 0.026028801035808   0: 0.026024769294430   3: 0.026020003579421   2: 0.026019990276805   8: 0.026016529730958 

test_17660        5: 0.794612600152969   4: 0.022823151099164   6: 0.022821138574790   9: 0.022820760710502   0: 0.022820560590359   7: 0.022820533661263   1: 0.022820507975323   8: 0.022820383406167   2: 0.022820216023202   3: 0.022820147806261 

test_17661        5: 0.437458961866493   9: 0.335851307615848   4: 0.028347526070748   8: 0.028334952700555   0: 0.028334765122422   1: 0.028334660967192   3: 0.028334546632937   6: 0.028334460986117   7: 0.028334431504588   2: 0.028334386533100 

test_17662        6: 0.536616477669201   0: 0.302514376074830   3: 0.020152421024737   5: 0.020103820403021   7: 0.020103656640894   8: 0.020103294617227   1: 0.020102342390953   9: 0.020101209288225   2: 0.020101207094135   4: 0.020101194796777 

test_17664        6: 0.543219906821125   4: 0.287600171396599   7: 0.021154191586581   1: 0.021147479134524   8: 0.021146997521529   0: 0.021146976180686   5: 0.021146738333417   9: 0.021146307899108   3: 0.021145695411378   2: 0.021145535715052 

test_17666        6: 0.466514098907711   4: 0.331778402339756   3: 0.050684390722454   5: 0.021583504914763   0: 0.021580062559581   1: 0.021573657927962   8: 0.021571717935129   2: 0.021571599523539   9: 0.021571462282558   7: 0.021571102886546 

test_17669        7: 0.390873685329862   6: 0.241941634860895   0: 0.220827981206989   4: 0.020914117269627   2: 0.020908864035736   9: 0.020908716208242   5: 0.020908133823559   8: 0.020906441917709   1: 0.020906107325079   3: 0.020904318022303 

test_17670        6: 0.654597174284999   9: 0.173701090630764   0: 0.050409128548288   1: 0.030397714156630   3: 0.022159963385388   7: 0.013769183944162   4: 0.013758504336440   2: 0.013736378271100   5: 0.013736073007198   8: 0.013734789435031 

test_17671        1: 0.558142438292500   5: 0.241564143623328   2: 0.025090641571627   4: 0.025081134544485   6: 0.025022282923415   0: 0.025021977463427   3: 0.025019514236789   7: 0.025019454961104   9: 0.025019265326990   8: 0.025019147056336 

test_17672        5: 0.672595509927396   1: 0.176409476339285   4: 0.018894531834130   0: 0.018874281630470   8: 0.018871156585769   9: 0.018871079935458   2: 0.018871033976566   3: 0.018871031188900   7: 0.018870984742620   6: 0.018870913839406 

test_17673        1: 0.763356614149280   7: 0.026302209699163   5: 0.026298926746210   4: 0.026294960528027   0: 0.026292114014607   6: 0.026291779116306   9: 0.026291746995252   3: 0.026291172420184   8: 0.026290481670138   2: 0.026289994660831 

test_17674        6: 0.794650378584304   5: 0.100558912728437   0: 0.013746420490975   1: 0.013139005067616   3: 0.013014650130944   9: 0.012992546029737   2: 0.012977295820946   8: 0.012974846251597   7: 0.012974305423279   4: 0.012971639472165 

test_17677        6: 0.553425443624709   5: 0.286545019633726   4: 0.020136620976934   1: 0.019993118704723   3: 0.019987533978146   0: 0.019984075379119   8: 0.019982396655273   7: 0.019982247034150   2: 0.019982014111665   9: 0.019981529901556 

test_17682        4: 0.519837009445497   6: 0.325677964659904   5: 0.019315986831647   0: 0.019313957862569   1: 0.019311758999686   9: 0.019309612898614   2: 0.019309212633942   7: 0.019308511312658   3: 0.019308047571265   8: 0.019307937784219 

test_17683        7: 0.716184119874861   1: 0.031543603253918   0: 0.031543301397033   6: 0.031538910764309   5: 0.031536661154740   4: 0.031531906676200   2: 0.031531228425510   3: 0.031530924360553   9: 0.031530179191289   8: 0.031529164901586 

test_17685        5: 0.502601397570476   6: 0.315308412379413   4: 0.022767587720678   8: 0.022760640096591   3: 0.022760522245018   0: 0.022760340397230   9: 0.022760336507915   2: 0.022760291606807   1: 0.022760272763504   7: 0.022760198712369 

test_17686        9: 0.477489613321979   6: 0.390527410752386   1: 0.027554827730041   0: 0.014953750084037   8: 0.014941461959934   7: 0.014913012462580   4: 0.014907531580722   5: 0.014905742139167   2: 0.014903627901086   3: 0.014903022068066 

test_17687        6: 0.840852949659739   5: 0.017693378637972   0: 0.017686644848593   1: 0.017684644737695   3: 0.017682592723248   4: 0.017681255843703   2: 0.017680398932771   8: 0.017680099652475   9: 0.017679266101118   7: 0.017678768862688 

test_17688        4: 0.707560082161581   0: 0.140176892183647   6: 0.019040759089808   1: 0.019034928919821   5: 0.019033689721149   8: 0.019033233156225   9: 0.019031638786373   3: 0.019030200750610   2: 0.019029333041512   7: 0.019029242189273 

test_17694        0: 0.853344446720967   8: 0.016358191513166   4: 0.016340540172861   7: 0.016298917039275   5: 0.016280810430628   1: 0.016276770884439   6: 0.016276693456087   9: 0.016274787461501   2: 0.016274680491108   3: 0.016274161829969 

test_17698        0: 0.724578359015708   5: 0.030607890663491   6: 0.030605108732300   2: 0.030604446643246   1: 0.030603207399554   9: 0.030601333284808   7: 0.030600569575547   8: 0.030600158188284   3: 0.030599610814389   4: 0.030599315682673 

test_17700        5: 0.341238366001090   6: 0.239582528253938   0: 0.137855156057854   1: 0.101512254673908   3: 0.094303673649121   9: 0.034113727161942   2: 0.020467675939936   4: 0.010312316852996   8: 0.010309446196782   7: 0.010304855212433 

test_17701        0: 0.610791614164532   1: 0.199582494872427   4: 0.085017579654441   6: 0.015059013047969   3: 0.014995173987440   7: 0.014936620426959   5: 0.014904915821628   8: 0.014904472370812   9: 0.014904058427735   2: 0.014904057226057 

test_17702        0: 0.724577840364037   5: 0.030608402641263   6: 0.030605110670554   2: 0.030604448325182   1: 0.030603208677051   9: 0.030601333981547   7: 0.030600570039979   8: 0.030600158531055   3: 0.030599610993722   4: 0.030599315775610 

test_17703        5: 0.635574074392691   8: 0.112219848196595   6: 0.094555831033563   3: 0.045963717433503   1: 0.035975656633242   0: 0.015196021618303   4: 0.015131583551158   7: 0.015129169779566   9: 0.015127481967564   2: 0.015126615393815 

test_17706        2: 0.488382394142308   5: 0.208288524171538   7: 0.124061687440791   4: 0.056341232529340   6: 0.020505990085177   1: 0.020495586389080   0: 0.020494859461241   8: 0.020478834366671   9: 0.020476545102122   3: 0.020474346311733 

test_17707        6: 0.634728393461506   0: 0.235489978145447   5: 0.044326723257068   3: 0.012279431846483   9: 0.012206060557037   8: 0.012203624206528   1: 0.012202208253227   4: 0.012188436170736   2: 0.012187606052978   7: 0.012187538048988 

test_17710        0: 0.809643768292722   1: 0.021161564606782   5: 0.021158321619057   2: 0.021153106997175   6: 0.021148617091913   3: 0.021147589215092   4: 0.021147457766302   7: 0.021146621533746   8: 0.021146520982152   9: 0.021146431895059 

test_17712        5: 0.436733414591123   0: 0.390649852502522   8: 0.021580520765661   4: 0.021580425171456   6: 0.021578532523725   9: 0.021576725992760   7: 0.021575827543358   1: 0.021575262463610   2: 0.021574756165351   3: 0.021574682280434 

test_17714        1: 0.512372389635675   6: 0.386380283503036   3: 0.019674344830953   0: 0.011783990835802   8: 0.011650645119172   7: 0.011632813828381   5: 0.011628005866494   4: 0.011626894320476   9: 0.011625487703132   2: 0.011625144356880 

test_17716        5: 0.600759100359454   1: 0.264198144113114   6: 0.017091749408599   8: 0.016868864530135   0: 0.016860168009204   4: 0.016857090989315   3: 0.016844858312743   9: 0.016840457143023   7: 0.016839810077861   2: 0.016839757056553 

test_17719        5: 0.322937563356373   6: 0.304646940034338   7: 0.191773977045425   8: 0.062923374290225   1: 0.019624033899945   4: 0.019622879297251   0: 0.019622518555261   9: 0.019617704522643   2: 0.019615556807188   3: 0.019615452191351 

test_17722        8: 0.595970909312023   1: 0.183389718145915   6: 0.027596100488113   7: 0.027579340571390   0: 0.027578538210746   9: 0.027577237602572   5: 0.027577234856653   2: 0.027577036507970   3: 0.027576980732655   4: 0.027576903571963 

test_17723        0: 0.825991998823554   1: 0.019342786510977   5: 0.019339187038853   6: 0.019335968730005   2: 0.019334522031339   4: 0.019331910363559   9: 0.019331791899629   8: 0.019330888390978   7: 0.019330569911100   3: 0.019330376300006 

test_17727        0: 0.739988326049932   5: 0.028906939742193   6: 0.028897693276637   1: 0.028893433826914   4: 0.028887940764821   3: 0.028887514532650   2: 0.028885456518977   7: 0.028884699058995   9: 0.028884393667248   8: 0.028883602561633 

test_17728        5: 0.734963468784135   0: 0.069161866136556   4: 0.024494792563052   1: 0.024490422153658   7: 0.024488157238602   9: 0.024486539765440   6: 0.024481692022723   3: 0.024479196938480   8: 0.024477317215953   2: 0.024476547181401 

test_17731        6: 0.521598437009915   1: 0.403724663496864   5: 0.009511924931734   0: 0.009444077905927   9: 0.009405209890510   8: 0.009313038023880   7: 0.009293672812720   3: 0.009236681038817   2: 0.009236216925130   4: 0.009236077964504 

test_17733        6: 0.773774570403218   8: 0.025144304839880   5: 0.025138390506311   1: 0.025137126997027   0: 0.025135827343900   7: 0.025134285442563   3: 0.025133950030342   9: 0.025133893447433   2: 0.025133879108463   4: 0.025133771880863 

test_17738        7: 0.501068289437927   5: 0.268701679274187   1: 0.028788890295512   0: 0.028781998636163   6: 0.028781463156002   9: 0.028777767012226   8: 0.028776681384234   4: 0.028775494739654   2: 0.028775088037920   3: 0.028772648026177 

test_17742        6: 0.751652296998981   1: 0.027634104829455   3: 0.027592316664187   0: 0.027591407651146   7: 0.027588575601702   9: 0.027588408928378   8: 0.027588382222167   5: 0.027588351318183   2: 0.027588119274205   4: 0.027588036511596 

test_17743        1: 0.819334914730168   0: 0.020146122517438   6: 0.020135472868565   4: 0.020088783752595   5: 0.020063257611986   9: 0.020055731600234   3: 0.020048906703035   2: 0.020043235163434   8: 0.020042258847084   7: 0.020041316205462 

test_17746        7: 0.610702459806817   4: 0.165700878876354   5: 0.028134995934923   1: 0.027935628880698   0: 0.027931818488417   6: 0.027927224547308   2: 0.027917952852121   9: 0.027917514525047   3: 0.027915956328904   8: 0.027915569759412 

test_17748        6: 0.673858774001723   9: 0.178775685185441   5: 0.044288371586036   1: 0.014733901762220   0: 0.014725488483224   8: 0.014723908686398   3: 0.014723774191857   2: 0.014723416990250   7: 0.014723349419695   4: 0.014723329693156 

test_17749        3: 0.539893251821227   0: 0.263514279878031   5: 0.024579345010801   6: 0.024577610520410   1: 0.024574844456404   8: 0.024572623324028   7: 0.024572380785097   9: 0.024572136161211   2: 0.024571905006105   4: 0.024571623036686 

test_17750        6: 0.897578072581561   1: 0.029130196543006   8: 0.009433013095210   5: 0.009409625166382   3: 0.009105232808125   0: 0.009074027515099   4: 0.009068276844315   9: 0.009067500436422   7: 0.009067036855369   2: 0.009067018154512 

test_17751        5: 0.781346280149238   0: 0.024308042698599   1: 0.024306836128004   4: 0.024295277739968   6: 0.024291059452776   3: 0.024290642871147   8: 0.024290585296150   2: 0.024290511912281   7: 0.024290392024195   9: 0.024290371727642 

test_17752        5: 0.824104572289769   1: 0.019575049272060   6: 0.019549696863492   0: 0.019545583378992   2: 0.019538260120726   8: 0.019537919907099   4: 0.019537684972460   7: 0.019537497320685   9: 0.019537103409692   3: 0.019536632465026 

test_17753        5: 0.538517200061346   2: 0.236937103738217   4: 0.028074733783900   8: 0.028067620656330   3: 0.028067534431914   6: 0.028067284979805   7: 0.028067255189151   9: 0.028067173550390   0: 0.028067106508947   1: 0.028066987100000 

test_17755        6: 0.744558305102927   9: 0.084895884449797   1: 0.047827657334525   5: 0.017533377951004   8: 0.017532717356716   0: 0.017531948580353   4: 0.017531262320488   7: 0.017529716765430   2: 0.017529613372383   3: 0.017529516766377 

test_17757        6: 0.500702192082345   5: 0.285597569174058   2: 0.026715541458347   4: 0.026713977818507   0: 0.026713208978688   9: 0.026713133112111   1: 0.026712765612979   7: 0.026711417365018   3: 0.026710205266413   8: 0.026709989131536 

test_17758        6: 0.712559786394184   5: 0.123059700881664   0: 0.020551694631990   9: 0.020550219353379   4: 0.020547120882470   1: 0.020546962498420   8: 0.020546636052962   3: 0.020546145206652   2: 0.020545903391040   7: 0.020545830707238 

test_17759        6: 0.855964349121628   5: 0.016004610030855   4: 0.016004292899276   1: 0.016004273543800   2: 0.016004238788051   0: 0.016003968705300   9: 0.016003758969166   3: 0.016003631458640   7: 0.016003465461114   8: 0.016003411022170 

test_17760        0: 0.352990796263435   1: 0.273063672477930   5: 0.175989869524075   6: 0.129728683240690   2: 0.011374159517355   4: 0.011371707108784   9: 0.011371213771739   7: 0.011370363711672   8: 0.011370089495090   3: 0.011369444889230 

test_17762        0: 0.701028267518042   4: 0.033226176202189   1: 0.033222738868740   5: 0.033220091288284   6: 0.033218797826621   2: 0.033217813128847   9: 0.033217525004360   3: 0.033216629518027   7: 0.033216213986519   8: 0.033215746658371 

test_17763        9: 0.419511892475071   5: 0.263197052228413   1: 0.192647331491977   0: 0.028858613332923   6: 0.015968283837875   4: 0.015963865028514   7: 0.015963351352361   3: 0.015963259037221   2: 0.015963225101298   8: 0.015963126114346 

test_17766        6: 0.829907790932333   1: 0.018906218891671   5: 0.018906034654296   0: 0.018900228285572   4: 0.018899911127091   2: 0.018899606102766   3: 0.018895281963214   7: 0.018895018527090   9: 0.018894989395066   8: 0.018894920120901 

test_17767        6: 0.752870734299711   7: 0.027460123263825   1: 0.027459900326951   0: 0.027459299520224   5: 0.027458604375039   9: 0.027458388095366   2: 0.027458368015642   4: 0.027458275392932   8: 0.027458270350478   3: 0.027458036359832 

test_17769        6: 0.791416548025567   5: 0.023176523221145   7: 0.023176292608502   1: 0.023176184489004   0: 0.023176113976289   4: 0.023175867759793   9: 0.023175828043082   8: 0.023175731362845   2: 0.023175532954035   3: 0.023175377559737 

test_17770        5: 0.820171056784928   6: 0.045449362312632   1: 0.016869714893166   0: 0.016798438281838   8: 0.016792637093688   2: 0.016784007514054   7: 0.016783960190473   9: 0.016783877801780   4: 0.016783862429653   3: 0.016783082697790 

test_17771        6: 0.355200181837787   5: 0.214108974336781   1: 0.138949075729047   0: 0.133153357093130   2: 0.100112923216994   9: 0.012275155152614   7: 0.011867139664227   4: 0.011444446601510   3: 0.011444414369769   8: 0.011444331998143 

test_17773        5: 0.469002174972505   7: 0.352258124258647   1: 0.022366188281228   6: 0.022363081662835   9: 0.022340885921046   0: 0.022338809966735   4: 0.022337857182084   3: 0.022331813517974   8: 0.022330910482253   2: 0.022330153754693 

test_17775        0: 0.519649188505547   4: 0.268693927615946   1: 0.057642730575516   5: 0.050501616601231   7: 0.017323346451745   6: 0.017244161672507   2: 0.017238839508403   3: 0.017235956060884   9: 0.017235426848560   8: 0.017234806159660 

test_17776        0: 0.535482595526936   1: 0.195943246315641   7: 0.167401110525136   6: 0.014548827438746   9: 0.014446377763333   2: 0.014437131407233   5: 0.014436549106683   4: 0.014435026975527   8: 0.014434862632666   3: 0.014434272308099 

test_17777        1: 0.575468341712635   8: 0.273697396195985   5: 0.018858452814572   6: 0.018858068777972   0: 0.018854415219220   9: 0.018853031142672   4: 0.018852985316193   2: 0.018852747029475   7: 0.018852523303120   3: 0.018852038488156 

test_17780        6: 0.472861347535994   8: 0.302667094168251   1: 0.084118770920862   0: 0.068010849715913   5: 0.012058982614742   9: 0.012057171455838   3: 0.012057030096625   7: 0.012056384573812   2: 0.012056214741816   4: 0.012056154176147 

test_17782        1: 0.866528264810889   0: 0.015083421120866   5: 0.014911598564096   4: 0.014882542485334   9: 0.014781275902032   3: 0.014763346277062   6: 0.014763177740631   8: 0.014762418648449   2: 0.014762057405253   7: 0.014761897045389 

test_17783        6: 0.486681208299169   3: 0.253055679942030   0: 0.168574383904210   8: 0.013229645441694   5: 0.013080934217270   1: 0.013077198625230   4: 0.013075643668839   9: 0.013075550762045   2: 0.013074934088351   7: 0.013074821051161 

test_17784        1: 0.506519872773646   4: 0.341479954345825   6: 0.019005567853846   5: 0.019002592362991   0: 0.019002260925642   2: 0.019001552255053   9: 0.018998137524897   8: 0.018997159573043   7: 0.018996545831671   3: 0.018996356553386 

test_17785        6: 0.693922124050607   1: 0.148498263587857   5: 0.019708499060372   2: 0.019697812464593   4: 0.019697483003204   0: 0.019697425692919   9: 0.019694797426251   8: 0.019694766078989   3: 0.019694608323827   7: 0.019694220311380 

test_17787        8: 0.480464767581151   1: 0.252253712221841   0: 0.076811827074376   5: 0.027215042583685   6: 0.027213923842938   4: 0.027209234864547   9: 0.027208847080085   2: 0.027208670375182   3: 0.027207381021437   7: 0.027206593354758 

test_17788        4: 0.691105318782702   3: 0.114489446810355   5: 0.024314739130413   6: 0.024299876632340   8: 0.024298847547294   0: 0.024298836700302   1: 0.024298498683077   7: 0.024298380347028   2: 0.024298140863849   9: 0.024297914502641 

test_17791        4: 0.584767036695453   3: 0.123843655329819   6: 0.086267967473199   1: 0.081115172468460   0: 0.020676651351978   7: 0.020670029070585   5: 0.020669608248636   2: 0.020664041672678   8: 0.020663356034777   9: 0.020662481654416 

test_17792        4: 0.438442232122877   2: 0.213424332515467   0: 0.159869546587818   9: 0.026901062867963   1: 0.026900670419095   5: 0.026900065342673   6: 0.026895328315061   7: 0.026889574623254   3: 0.026889096846037   8: 0.026888090359755 

test_17795        5: 0.814696338436981   4: 0.020594796721011   1: 0.020588878022736   0: 0.020588743119867   6: 0.020588700426545   9: 0.020588681419963   8: 0.020588589827592   2: 0.020588477009432   3: 0.020588451583703   7: 0.020588343432171 

test_17798        6: 0.622795404211841   1: 0.144231078867186   4: 0.029143870496975   5: 0.029131062383129   0: 0.029125221863159   2: 0.029117705337693   3: 0.029114698293704   7: 0.029114366076861   8: 0.029113840697737   9: 0.029112751771714 

test_17802        5: 0.559379003628882   3: 0.226937397187385   4: 0.026715600956899   6: 0.026711104725319   0: 0.026709650969983   8: 0.026709647631090   1: 0.026709621622372   9: 0.026709362264521   7: 0.026709312675129   2: 0.026709298338420 

test_17805        6: 0.488143895454033   3: 0.251344735936548   0: 0.169095551783384   8: 0.013190182383573   5: 0.013041945849041   1: 0.013038363384344   4: 0.013036713194326   9: 0.013036651640410   2: 0.013036031019157   7: 0.013035929355184 

test_17808        5: 0.428261698689104   7: 0.342745552711286   9: 0.088541872312792   6: 0.020076528024304   0: 0.020069173785750   1: 0.020062505410255   4: 0.020062210493833   2: 0.020060421778524   8: 0.020060152792185   3: 0.020059884001968 

test_17809        2: 0.486220904345928   6: 0.209242084770108   0: 0.186964007317215   1: 0.016802610012533   5: 0.016800089203333   4: 0.016798552306858   8: 0.016794773575183   9: 0.016793543005612   7: 0.016791914800073   3: 0.016791520663157 

test_17810        2: 0.512470395156353   6: 0.316787992530780   0: 0.021353150425576   1: 0.021352628252928   5: 0.021343178431177   4: 0.021339938848657   9: 0.021338469722465   7: 0.021338439892819   8: 0.021338175097635   3: 0.021337631641610 

test_17811        5: 0.778257571611245   6: 0.024661509333341   4: 0.024643552021442   0: 0.024635693108546   7: 0.024634526829427   1: 0.024634253454687   8: 0.024633679896430   3: 0.024633293261764   9: 0.024633095618096   2: 0.024632824865023 

test_17812        6: 0.355319203868119   7: 0.344107207129718   0: 0.180229941301938   1: 0.044475455899186   4: 0.012725539023464   5: 0.012631773474533   9: 0.012627941069780   8: 0.012627803700701   2: 0.012627802669891   3: 0.012627331862672 

test_17813        0: 0.537802660077559   6: 0.327527221131086   4: 0.026117027367685   9: 0.015508575868611   5: 0.015508520790428   2: 0.015508169253039   1: 0.015508042738034   8: 0.015506861438791   7: 0.015506610190560   3: 0.015506311144207 

test_17816        2: 0.452384983301349   6: 0.338603822677345   9: 0.078401896016128   1: 0.052291914583140   8: 0.013056127767673   0: 0.013054934959924   5: 0.013053789236619   4: 0.013051061181890   7: 0.013050821066453   3: 0.013050649209479 

test_17822        0: 0.476857409703063   5: 0.334596072553805   1: 0.023571258499614   6: 0.023569614995665   9: 0.023569293489472   4: 0.023568289210371   7: 0.023567310324244   8: 0.023567123351504   2: 0.023566933733176   3: 0.023566694139085 

test_17823        6: 0.870938559728421   7: 0.014342841679520   1: 0.014341327315389   2: 0.014340905210340   0: 0.014339812545582   5: 0.014339622836091   8: 0.014339548629092   4: 0.014339234845773   3: 0.014339078122443   9: 0.014339069087349 

test_17825        5: 0.630581142099379   2: 0.194308389629221   0: 0.021890543055873   1: 0.021890490578981   6: 0.021890074950880   9: 0.021889737416482   4: 0.021888505699088   3: 0.021887672501727   7: 0.021886756390657   8: 0.021886687677713 

test_17827        1: 0.655316214596932   6: 0.182533773849998   0: 0.020275259208753   5: 0.020269847571569   3: 0.020268434014384   9: 0.020267529336063   4: 0.020267480371277   2: 0.020267314640847   8: 0.020267147405043   7: 0.020266999005135 

test_17829        6: 0.476580478266563   5: 0.369681619200991   1: 0.019241894887514   0: 0.019219560366492   3: 0.019215766350253   9: 0.019212451571728   4: 0.019212188295292   8: 0.019212075989479   2: 0.019212042473373   7: 0.019211922598315 

test_17834        5: 0.495133278132943   7: 0.193322461982343   6: 0.136495837871687   4: 0.025010616054843   0: 0.025006989320701   3: 0.025006722560180   1: 0.025006374005367   8: 0.025006110422729   2: 0.025005947263489   9: 0.025005662385718 

test_17835        5: 0.384435930403055   1: 0.318210331205492   9: 0.165355345184389   6: 0.018860990159319   0: 0.018859081688077   3: 0.018857189882449   2: 0.018856162530929   4: 0.018855472722589   8: 0.018855425943788   7: 0.018854070279914 

test_17837        1: 0.446371544342868   5: 0.336395453569628   0: 0.077601508168187   3: 0.039885397676756   6: 0.016680424697072   2: 0.016635573041613   4: 0.016614260380453   9: 0.016605614728989   8: 0.016605353164251   7: 0.016604870230185 

test_17839        6: 0.696827685024611   4: 0.154905126560877   0: 0.052295871511900   9: 0.016650349644377   1: 0.015784889489283   5: 0.013093518747438   7: 0.012622450194155   8: 0.012609945915836   3: 0.012605995780468   2: 0.012604167131054 

test_17847        1: 0.403100706667402   6: 0.338887690244776   4: 0.100046180718123   5: 0.022570632275892   0: 0.022567984795767   3: 0.022565772351185   8: 0.022565667678731   9: 0.022565643792350   2: 0.022565041325564   7: 0.022564680150211 

test_17848        5: 0.762177415825755   6: 0.026576930265758   8: 0.026421183279082   0: 0.026417116711108   7: 0.026412994437945   4: 0.026404749435928   3: 0.026398678803695   1: 0.026397220058252   2: 0.026397030092314   9: 0.026396681090162 

test_17849        0: 0.570353774517768   5: 0.225674169777658   6: 0.112745100020169   9: 0.013281860883554   4: 0.013007086597778   1: 0.012989597027140   2: 0.012989569256857   8: 0.012986952012977   7: 0.012986015107177   3: 0.012985874798922 

test_17853        1: 0.573941539961202   7: 0.231983998440318   5: 0.024265545406230   4: 0.024260787078731   6: 0.024259371735648   0: 0.024258953832500   9: 0.024258160401668   2: 0.024257568572487   8: 0.024257249352262   3: 0.024256825218955 

test_17857        1: 0.419722919886226   5: 0.225651736332184   2: 0.210623925887920   6: 0.020577446208172   0: 0.020572684179291   4: 0.020571298193194   8: 0.020570232685679   3: 0.020570150413775   9: 0.020569829306728   7: 0.020569776906831 

test_17860        4: 0.462816546650502   1: 0.351636951308286   6: 0.023207860755339   5: 0.023199375641829   0: 0.023198598290848   3: 0.023188534984033   2: 0.023188325930295   8: 0.023188145463014   9: 0.023187872948327   7: 0.023187788027527 

test_17863        1: 0.353622194338187   2: 0.215845260637480   6: 0.180943662148099   5: 0.168968100311889   0: 0.013773791370943   3: 0.013416937900400   9: 0.013414712669724   7: 0.013346917871387   4: 0.013334282429483   8: 0.013334140322409 

test_17864        5: 0.394407735882612   6: 0.377041981653243   9: 0.100167569095716   1: 0.018344964547266   7: 0.018343828191430   2: 0.018343306136726   0: 0.018339680819452   3: 0.018337108878851   8: 0.018337074221863   4: 0.018336750572841 

test_17866        1: 0.800939282064063   6: 0.022327701476745   5: 0.022096076599212   0: 0.022094466815214   9: 0.022093769559424   8: 0.022090818006266   7: 0.022089947091935   2: 0.022089638839406   4: 0.022089438784496   3: 0.022088860763240 

test_17867        0: 0.745814801256653   1: 0.028251079287660   5: 0.028248994460530   6: 0.028245628737733   4: 0.028241982594963   8: 0.028241711025981   2: 0.028239575549100   9: 0.028238866311631   7: 0.028238692403302   3: 0.028238668372447 

test_17870        6: 0.791169826607351   0: 0.079678149351692   4: 0.041219939680345   8: 0.012569158105430   2: 0.012562191578819   1: 0.012560653561152   5: 0.012560314811096   9: 0.012560195773399   7: 0.012559861963082   3: 0.012559708567635 

test_17871        6: 0.538304855977185   0: 0.389951477811492   1: 0.016210376579097   5: 0.007934314960067   7: 0.007933661785622   9: 0.007933364832791   8: 0.007933245223063   4: 0.007933001623170   2: 0.007932924389583   3: 0.007932776817930 

test_17872        6: 0.388271574568247   1: 0.313861687577036   4: 0.182124992773122   5: 0.016538311531415   7: 0.016536384955995   3: 0.016535223178269   0: 0.016534812021153   9: 0.016533636081340   8: 0.016532080409074   2: 0.016531296904349 

test_17873        0: 0.677113716312753   5: 0.211543872926766   1: 0.013953192483106   6: 0.013936702033585   9: 0.013909323913630   3: 0.013908950289221   8: 0.013908890240982   2: 0.013908788533897   7: 0.013908334943432   4: 0.013908228322627 

test_17874        6: 0.802816149793469   0: 0.071836999248607   4: 0.039094824777322   2: 0.012326650166090   8: 0.012326063085663   3: 0.012325025765718   1: 0.012319425073695   9: 0.012318509652890   7: 0.012318262793423   5: 0.012318089643125 

test_17875        6: 0.832591139122306   5: 0.018604132429267   2: 0.018603516310570   9: 0.018600792134885   7: 0.018600278981063   1: 0.018600257527828   4: 0.018600190875044   8: 0.018600178700406   0: 0.018600167619868   3: 0.018599346298762 

test_17876        0: 0.600529110962225   6: 0.257968875989015   1: 0.025589197258662   5: 0.016753523847901   3: 0.016540185055964   4: 0.016526937863472   9: 0.016523900749483   7: 0.016523590994416   2: 0.016522659190031   8: 0.016522018088831 

test_17877        6: 0.668500327647935   7: 0.184430964735741   0: 0.065587858600481   1: 0.011652757121421   8: 0.011642572538584   9: 0.011639174650814   5: 0.011637202040533   2: 0.011636567294802   4: 0.011636406199398   3: 0.011636169170291 

test_17878        9: 0.818500775089285   6: 0.020971061914932   5: 0.020100721479663   3: 0.020088259023000   7: 0.020072193704915   0: 0.020058073999342   2: 0.020057284134338   4: 0.020050962503505   1: 0.020050845720276   8: 0.020049822430744 

test_17880        6: 0.787552810230844   9: 0.023613070721491   0: 0.023606725961380   2: 0.023605274310154   3: 0.023604644462851   8: 0.023604108645111   5: 0.023603975241805   1: 0.023603604717078   7: 0.023602899998613   4: 0.023602885710672 

test_17881        1: 0.574336392469031   0: 0.197276132142557   6: 0.028557635209243   8: 0.028551422289312   9: 0.028547374349396   5: 0.028546870983584   3: 0.028546509452411   7: 0.028546462694578   2: 0.028545924147631   4: 0.028545276262258 

test_17883        6: 0.738236593473285   0: 0.141990832308045   1: 0.032389641589370   8: 0.021779038466246   7: 0.015167105338052   3: 0.013608048691739   5: 0.009216823732177   9: 0.009215192817718   4: 0.009198746980717   2: 0.009197976602651 

test_17886        6: 0.542441649612807   1: 0.203446298504606   0: 0.173203444526722   5: 0.017877808107164   2: 0.010506455355969   8: 0.010505521938178   9: 0.010505206212635   4: 0.010504741622890   7: 0.010504604229121   3: 0.010504269889908 

test_17887        5: 0.609004165679461   7: 0.162203907718028   6: 0.028618642600570   1: 0.028610449272459   9: 0.028598650820204   0: 0.028594042350911   8: 0.028593881502263   4: 0.028593290735097   2: 0.028591692215260   3: 0.028591277105746 

test_17888        6: 0.875735251284536   3: 0.026830839470178   1: 0.012180962030485   0: 0.012179315990601   8: 0.012179148927275   5: 0.012179125726866   9: 0.012178938347814   2: 0.012178815711376   4: 0.012178810727900   7: 0.012178791782969 

test_17892        6: 0.495809621871554   3: 0.315700529081519   8: 0.048692596501499   1: 0.038350098799089   7: 0.016939033389801   0: 0.016931806713741   9: 0.016902675196112   5: 0.016893189461185   2: 0.016891203858927   4: 0.016889245126572 

test_17894        6: 0.484326405095123   0: 0.398188282949370   7: 0.014699671372379   1: 0.014688896193085   2: 0.014684479764727   5: 0.014683227710041   8: 0.014682529383067   9: 0.014682298573877   3: 0.014682177243246   4: 0.014682031715085 

test_17896        0: 0.503709046990895   6: 0.422972306300761   1: 0.009404376231202   9: 0.009131587747881   5: 0.009131500175600   8: 0.009130654171176   4: 0.009130463106796   7: 0.009130068171952   2: 0.009130006711531   3: 0.009129990392206 

test_17897        6: 0.824822223993420   0: 0.043275603771368   1: 0.016506935777014   5: 0.016501482613523   7: 0.016486983584160   4: 0.016483298130682   9: 0.016482077596131   3: 0.016480736916083   8: 0.016480493529414   2: 0.016480164088206 

test_17899        0: 0.835540199210878   6: 0.018278378353016   8: 0.018276858962645   5: 0.018274088451575   9: 0.018273276437272   1: 0.018272986402948   7: 0.018271306849053   3: 0.018271117488586   4: 0.018271003938152   2: 0.018270783905876 

test_17900        5: 0.395685527452451   9: 0.182094762388676   2: 0.170695526492712   3: 0.127639894574192   0: 0.020654200068071   1: 0.020651474817539   8: 0.020646898528898   4: 0.020644877505623   6: 0.020644328699380   7: 0.020642509472458 

test_17901        5: 0.340901094227478   9: 0.288090699946135   3: 0.141050477580769   6: 0.110382685440591   8: 0.019945584503599   1: 0.019929308994965   0: 0.019929096889272   4: 0.019925895316324   7: 0.019922606493469   2: 0.019922550607398 

test_17906        6: 0.839522706830786   0: 0.068943626227883   1: 0.021904583675429   8: 0.009957472764457   5: 0.009945939698608   9: 0.009945269002030   7: 0.009945203246673   4: 0.009945103887271   2: 0.009945050438620   3: 0.009945044228244 

test_17907        3: 0.436975467224776   6: 0.423290415020726   1: 0.031728645273308   5: 0.015486449310395   0: 0.015439877337156   9: 0.015423653842785   8: 0.015418642775981   4: 0.015418474087369   7: 0.015409206720813   2: 0.015409168406691 

test_17911        0: 0.645046855799329   6: 0.229511594173475   1: 0.015684042002608   5: 0.015682712318031   8: 0.015679824397959   9: 0.015679303090819   7: 0.015679162884809   2: 0.015679120182348   4: 0.015678893370162   3: 0.015678491780460 

test_17913        6: 0.647438322864159   5: 0.149587373484720   2: 0.100755693696265   8: 0.014620742342266   3: 0.014605387622168   9: 0.014602830216377   0: 0.014598332506872   1: 0.014598083066033   7: 0.014596896352566   4: 0.014596337848574 

test_17915        6: 0.468030448141332   0: 0.251684207317146   7: 0.200949339223235   3: 0.019308634545197   8: 0.012778928837989   5: 0.009555494214316   1: 0.009491497816993   9: 0.009400629039531   2: 0.009400416319046   4: 0.009400404545216 

test_17916        6: 0.455948716362395   7: 0.336842069182320   5: 0.025916745372356   4: 0.025909965108497   9: 0.025898975742907   0: 0.025898340735438   8: 0.025896823578988   1: 0.025896436057191   2: 0.025896206340367   3: 0.025895721519543 

test_17922        3: 0.360353635172754   5: 0.339831274208042   1: 0.177679131682023   6: 0.017456051938533   9: 0.017450051570390   0: 0.017447864718802   4: 0.017446367296932   8: 0.017445646259346   2: 0.017445148902758   7: 0.017444828250419 

test_17923        6: 0.701466243025379   9: 0.149183250217740   5: 0.059991326379026   0: 0.034398766624512   3: 0.009295976702908   4: 0.009241241589449   1: 0.009141879936711   8: 0.009107179968720   7: 0.009091452854716   2: 0.009082682700838 

test_17924        6: 0.827827060517444   8: 0.019132632529999   9: 0.019132384573948   5: 0.019130958941324   0: 0.019130181892550   1: 0.019129540671121   7: 0.019129416184322   2: 0.019129312412248   3: 0.019129259042829   4: 0.019129253234214 

test_17925        3: 0.427937897199189   6: 0.406748674913847   1: 0.053150663572282   0: 0.046068787737749   8: 0.011112017736862   7: 0.010996859651834   5: 0.010996833141070   9: 0.010996194618778   4: 0.010996059988023   2: 0.010996011440365 

test_17926        6: 0.825616830480155   9: 0.019387328691066   5: 0.019375048785429   8: 0.019374906045765   0: 0.019374548176604   7: 0.019374500198285   2: 0.019374459015554   3: 0.019374446394639   4: 0.019373970141972   1: 0.019373962070532 

test_17927        6: 0.392992882501215   1: 0.345041823096166   9: 0.135718048408927   4: 0.032036507948335   2: 0.015714522199418   0: 0.015708656078906   5: 0.015698152628059   3: 0.015697539498803   7: 0.015696472793170   8: 0.015695394847001 

test_17929        6: 0.652190150971078   1: 0.240463028099175   4: 0.013431165148060   2: 0.013420814453375   0: 0.013416360516413   5: 0.013416020464719   8: 0.013415746112331   9: 0.013415744150824   7: 0.013415595121161   3: 0.013415374962862 

test_17930        6: 0.880631811255394   1: 0.028740423204910   2: 0.011352759227109   5: 0.011350819035783   8: 0.011348326124921   9: 0.011322558896728   0: 0.011321676162654   4: 0.011311746456314   7: 0.011310568174093   3: 0.011309311462094 

test_17932        6: 0.746879043767400   5: 0.028133609448156   9: 0.028128683175533   8: 0.028127066067752   0: 0.028122565755393   3: 0.028122219263784   4: 0.028122199897133   7: 0.028121651860858   1: 0.028121649024613   2: 0.028121311739378 

test_17933        6: 0.865900319490115   5: 0.014910035944195   4: 0.014901221445521   8: 0.014899784006726   9: 0.014899012039396   0: 0.014898954856783   1: 0.014897856601836   3: 0.014897749369629   7: 0.014897536849045   2: 0.014897529396754 

test_17939        6: 0.611309803890815   1: 0.178734196692847   9: 0.026249395011564   8: 0.026247129856637   0: 0.026245360125473   5: 0.026243097866829   2: 0.026243048130956   7: 0.026242846635900   3: 0.026242637106137   4: 0.026242484682841 

test_17943        6: 0.677129983712683   1: 0.182085995755655   9: 0.017599911432479   5: 0.017598436822015   8: 0.017598426640210   0: 0.017598311634607   2: 0.017598027644252   7: 0.017597249307716   3: 0.017596864300790   4: 0.017596792749592 

test_17948        6: 0.695132614775951   5: 0.137404573358709   1: 0.075993014776662   9: 0.013082428566132   4: 0.013072606224995   8: 0.013071892364276   0: 0.013061559840691   2: 0.013060882132233   7: 0.013060322814334   3: 0.013060105146017 

test_17950        4: 0.569197484019203   6: 0.239377066431545   0: 0.051878538950319   5: 0.036753506005333   7: 0.027429156596870   1: 0.015161890292769   9: 0.015087255745155   2: 0.015051312182112   8: 0.015033682942925   3: 0.015030106833768 

test_17952        6: 0.562445741759404   7: 0.265782690775063   1: 0.052871780573466   8: 0.047487918524974   9: 0.011919402819677   0: 0.011906808491165   5: 0.011897993300408   3: 0.011896938401425   2: 0.011895838091944   4: 0.011894887262475 

test_17955        2: 0.381532218999874   6: 0.349546885555947   1: 0.085208802250650   8: 0.074396120751259   7: 0.018242990071627   0: 0.018229668134983   9: 0.018213059749876   5: 0.018210405140958   3: 0.018210010105431   4: 0.018209839239396 

test_17956        0: 0.770822669139933   6: 0.065559599888456   7: 0.020466821485135   1: 0.020459827586247   4: 0.020454490413526   5: 0.020451863541321   9: 0.020451698844087   8: 0.020446884400048   2: 0.020445448333893   3: 0.020440696367354 

test_17957        0: 0.767362402706937   5: 0.025853905624641   6: 0.025852766914141   1: 0.025850877546496   4: 0.025847674118070   3: 0.025846918201627   9: 0.025846581211191   7: 0.025846343777003   2: 0.025846317462613   8: 0.025846212437280 

test_17958        6: 0.527189409916872   3: 0.309690224362102   0: 0.037373408467020   2: 0.017987227100315   8: 0.017968312114018   5: 0.017964350091142   1: 0.017961534750999   4: 0.017955539331761   9: 0.017955476162347   7: 0.017954517703424 

test_17960        1: 0.828773929842921   7: 0.019031674222252   6: 0.019028402758984   4: 0.019028266177439   0: 0.019026501890801   5: 0.019025359063117   3: 0.019022208979394   9: 0.019021475828016   2: 0.019021188957042   8: 0.019020992280034 

test_17962        6: 0.530553227445831   8: 0.341610395912160   9: 0.025111889437697   3: 0.023265449221813   0: 0.013294376616625   1: 0.013249706222500   7: 0.013231564343970   5: 0.013228709905988   2: 0.013227405785241   4: 0.013227275108175 

test_17963        6: 0.673210655520144   1: 0.223144387832192   4: 0.012965862383404   2: 0.012958686616653   0: 0.012954006636263   5: 0.012953652130760   9: 0.012953327483171   8: 0.012953252181087   7: 0.012953179570018   3: 0.012952989646307 

test_17964        5: 0.418971161047267   6: 0.275904320009136   3: 0.164585508463777   1: 0.046014401633330   9: 0.015758590759018   8: 0.015755863040503   4: 0.015754166517591   0: 0.015753421042189   2: 0.015751311162783   7: 0.015751256324407 

test_17965        5: 0.846793166088593   8: 0.037127257625392   9: 0.014519452903346   6: 0.014512085737552   0: 0.014509816786018   4: 0.014508386768482   1: 0.014508385832676   7: 0.014507436151301   2: 0.014507075525208   3: 0.014506936581432 

test_17966        6: 0.650971805823641   8: 0.152285952467548   0: 0.124633292886439   2: 0.023286766317177   9: 0.008491207150895   7: 0.008460643973287   5: 0.008159207717887   1: 0.007904294621845   4: 0.007903814607472   3: 0.007903014433808 

test_17967        5: 0.663233710890784   8: 0.133030798012258   4: 0.025475058971954   0: 0.025466015705500   3: 0.025465863600094   6: 0.025465861792748   9: 0.025465760138297   2: 0.025465689486603   1: 0.025465661187789   7: 0.025465580213972 

test_17968        6: 0.465475477477446   3: 0.375834827439954   0: 0.038325952572788   2: 0.017211802469630   8: 0.017197530457024   5: 0.017195837222815   1: 0.017194658450970   4: 0.017188620189346   9: 0.017188118085167   7: 0.017187175634860 

test_17970        6: 0.635208981378922   5: 0.166224059215452   0: 0.139432466694112   3: 0.008493845099339   2: 0.008489553401547   7: 0.008455861639901   1: 0.008444694131171   9: 0.008417611455088   8: 0.008416639392759   4: 0.008416287591709 

test_17972        5: 0.758646766671360   4: 0.026819968454221   6: 0.026819420735561   1: 0.026816845297472   0: 0.026816449438621   3: 0.026816188658685   8: 0.026816149645974   7: 0.026816133270391   2: 0.026816120355134   9: 0.026815957472580 

test_17973        5: 0.604114443667263   0: 0.244399043177817   9: 0.018956663351665   2: 0.018940819004495   1: 0.018934124377928   6: 0.018933899286940   4: 0.018930893165631   8: 0.018930188076986   7: 0.018930042118459   3: 0.018929883772816 

test_17975        4: 0.484057832579529   0: 0.250969802324130   5: 0.033131586837116   3: 0.033120454370865   2: 0.033120309166317   8: 0.033120307354193   7: 0.033120100904761   9: 0.033120067863576   1: 0.033119975598673   6: 0.033119563000838 

test_17978        2: 0.661934246476555   1: 0.185907605387701   6: 0.019026189763928   5: 0.019022606359670   0: 0.019020503710306   8: 0.019019032585446   4: 0.019018516855704   7: 0.019018334219262   3: 0.019016625874142   9: 0.019016338767285 

test_17979        8: 0.502154974768056   6: 0.326620887296962   7: 0.074445777983612   4: 0.020662680960813   0: 0.012728216722329   9: 0.012680077821067   2: 0.012678714246230   5: 0.012676338026094   3: 0.012676260089086   1: 0.012676072085752 

test_17980        6: 0.771008498958718   0: 0.132575565482726   5: 0.035296951732321   1: 0.011222991828627   8: 0.008325057500819   3: 0.008323109966550   9: 0.008312383021953   4: 0.008312338157892   2: 0.008311677050955   7: 0.008311426299439 

test_17981        5: 0.391566026550966   7: 0.348400584042262   8: 0.112181151350472   1: 0.021244905389970   6: 0.021147886253647   0: 0.021100673228473   2: 0.021096537201103   4: 0.021091766456024   9: 0.021085430435151   3: 0.021085039091931 

test_17984        6: 0.458507729981160   3: 0.236388926176388   7: 0.166395889597849   5: 0.019837701495217   1: 0.019828258260955   0: 0.019819845148340   9: 0.019806537597725   4: 0.019805699718121   2: 0.019804725213465   8: 0.019804686810778 

test_17986        6: 0.753668449916578   0: 0.122442074537974   1: 0.016111615203566   5: 0.015855881937931   3: 0.015375122786932   8: 0.015345512138626   4: 0.015301989431414   7: 0.015301910960232   9: 0.015299932947609   2: 0.015297510139136 

test_17988        5: 0.700939311779123   8: 0.139484757758735   4: 0.019955109374436   6: 0.019946185019212   2: 0.019946127058075   0: 0.019945948872256   1: 0.019945824817531   3: 0.019945596423047   7: 0.019945571360388   9: 0.019945567537195 

test_17993        3: 0.308925842007364   5: 0.299979761116168   6: 0.254701324151509   0: 0.020194286685465   1: 0.019429767850998   2: 0.019369585058947   4: 0.019359109989206   8: 0.019350815907472   9: 0.019345457070283   7: 0.019344050162588 

test_18001        6: 0.639263663791296   1: 0.226384160774035   5: 0.016809169426602   0: 0.016793695378971   9: 0.016791683924397   7: 0.016791579960615   3: 0.016791562609284   8: 0.016791554694906   4: 0.016791510299918   2: 0.016791419139976 

test_18009        6: 0.743297169353222   3: 0.134889430896897   0: 0.048192947374590   1: 0.010520879248373   2: 0.010518710637770   9: 0.010516727676440   5: 0.010516396528139   8: 0.010516254809260   4: 0.010515764452323   7: 0.010515719022986 

test_18010        3: 0.261228301906308   6: 0.256708781917525   0: 0.241942241799315   1: 0.034312427078706   2: 0.034302261696853   9: 0.034302017889522   5: 0.034301722650201   7: 0.034301535969510   8: 0.034300413793786   4: 0.034300295298273 

test_18011        6: 0.526360006807385   7: 0.247937576681236   9: 0.028214521649651   0: 0.028214043078996   8: 0.028213431933331   1: 0.028212551375783   3: 0.028212486804924   5: 0.028212099356649   2: 0.028211761969322   4: 0.028211520342724 

test_18012        6: 0.427711288341846   3: 0.226132928659616   0: 0.182568776184826   1: 0.023371254821918   8: 0.023370921228272   5: 0.023369732849884   9: 0.023369255964864   2: 0.023369207658664   7: 0.023368480758888   4: 0.023368153531222 

test_18013        6: 0.457871391769905   1: 0.323815874866699   0: 0.027306070837838   5: 0.027290383423497   2: 0.027287283415434   8: 0.027287074315871   4: 0.027285685851068   7: 0.027285492858687   3: 0.027285384270652   9: 0.027285358390350 

test_18014        6: 0.788411909074722   8: 0.023513186356681   1: 0.023511349864079   5: 0.023510745736917   0: 0.023510023263722   9: 0.023509529214005   2: 0.023508653368443   7: 0.023508607098053   4: 0.023508125576890   3: 0.023507870446489 

test_18017        6: 0.312854273712285   9: 0.307255836412724   1: 0.230717269685679   0: 0.039446968572079   5: 0.018296239191348   4: 0.018292301649360   2: 0.018284807052011   8: 0.018284336564177   7: 0.018284052730148   3: 0.018283914430190 

test_18024        6: 0.645844663011278   7: 0.246072608906396   1: 0.013521511275668   0: 0.013510067774582   5: 0.013509291645211   8: 0.013508757061935   9: 0.013508592229050   4: 0.013508270761227   3: 0.013508127722497   2: 0.013508109612156 

test_18028        3: 0.428461837962711   5: 0.413263414322570   4: 0.019785284274667   6: 0.019784475040058   1: 0.019784446135254   7: 0.019784294071491   0: 0.019784262901934   9: 0.019784057076976   2: 0.019784008904894   8: 0.019783919309443 

test_18029        5: 0.390789980076785   3: 0.307386909776083   6: 0.157295761225267   0: 0.021032503620831   1: 0.020964563658556   4: 0.020958752509161   2: 0.020427503391041   8: 0.020387094791709   7: 0.020378477808397   9: 0.020378453142170 

test_18034        0: 0.552597308787209   6: 0.332215026566336   3: 0.022484032874835   8: 0.013273338784085   7: 0.013248709390894   9: 0.013240403661733   5: 0.013236190634180   1: 0.013235654494808   4: 0.013234715164796   2: 0.013234619641125 

test_18035        6: 0.675821909741556   7: 0.141861864551045   1: 0.056670274346436   0: 0.035711302875168   8: 0.014993606699401   2: 0.014990389624949   5: 0.014990385027185   3: 0.014986955497998   9: 0.014986917103082   4: 0.014986394533181 

test_18036        6: 0.843328515919467   5: 0.031454674596633   1: 0.015666349957927   2: 0.015657805677408   4: 0.015654424551515   0: 0.015651419326280   3: 0.015648615013287   7: 0.015646251330779   9: 0.015646193004309   8: 0.015645750622396 

test_18037        0: 0.719024555305626   5: 0.102584029278106   6: 0.022300894693886   8: 0.022300549453370   1: 0.022299621955441   4: 0.022298613385376   3: 0.022298188097381   9: 0.022298130700731   2: 0.022297792673539   7: 0.022297624456544 

test_18038        5: 0.438082423075767   8: 0.348737518259754   1: 0.026650400141311   0: 0.026649814570890   6: 0.026648449779988   4: 0.026647407698858   2: 0.026646902966197   9: 0.026645761211942   7: 0.026645684742095   3: 0.026645637553197 

test_18040        5: 0.758349235614433   9: 0.071606074065837   6: 0.042484281456092   3: 0.018231867422742   1: 0.018228446336830   0: 0.018221620975592   2: 0.018219799219333   8: 0.018219794950574   4: 0.018219541351424   7: 0.018219338607143 

test_18048        5: 0.795491527934678   4: 0.022725166403632   6: 0.022723685041443   1: 0.022723320661961   0: 0.022723244049975   8: 0.022722735624253   9: 0.022722696082026   7: 0.022722552358941   3: 0.022722546367781   2: 0.022722525475311 

test_18050        6: 0.734151656478088   9: 0.114117833497187   0: 0.054324286509398   1: 0.022563075612643   5: 0.012480145263024   3: 0.012479143126904   8: 0.012473673702976   7: 0.012470116556896   4: 0.012470074266667   2: 0.012469994986217 

test_18051        8: 0.508616276477572   6: 0.251354552702769   7: 0.073342898742185   9: 0.060237747764733   0: 0.017749439737485   1: 0.017742638587279   4: 0.017740676315826   5: 0.017739619809401   2: 0.017738167202555   3: 0.017737982660193 

test_18052        5: 0.629352348133335   3: 0.187191781458284   6: 0.022937855094224   4: 0.022933422242678   1: 0.022932983350690   8: 0.022931892711366   0: 0.022930538537330   9: 0.022930142158537   7: 0.022929543757153   2: 0.022929492556403 

test_18061        6: 0.704639656032398   0: 0.132127563001806   5: 0.020412704185117   4: 0.020403926572840   9: 0.020403531721718   8: 0.020402950684050   3: 0.020402715158309   7: 0.020402550275290   1: 0.020402409831669   2: 0.020401992536804 

test_18062        5: 0.796480799092990   6: 0.022621037411583   8: 0.022616773310513   0: 0.022614515348448   4: 0.022613904566759   1: 0.022611975386932   3: 0.022610429414484   2: 0.022610275280760   7: 0.022610180169793   9: 0.022610110017738 

test_18065        5: 0.554795310383448   7: 0.236603318224990   1: 0.026082413605670   4: 0.026078231770163   0: 0.026074158339272   6: 0.026073513912182   3: 0.026073302718545   9: 0.026073271299170   2: 0.026073269757171   8: 0.026073209989389 

test_18066        9: 0.493143479711884   6: 0.369350068390754   0: 0.031335760763602   4: 0.015170097809637   5: 0.015169405085835   1: 0.015169154371914   8: 0.015168091577460   2: 0.015165328904334   7: 0.015164828575664   3: 0.015163784808917 

test_18068        5: 0.542518073015076   3: 0.231576284897756   4: 0.028242599276527   6: 0.028240913231736   0: 0.028237271439605   8: 0.028237059497253   2: 0.028237047637910   9: 0.028236965157290   7: 0.028236895002309   1: 0.028236890844538 

test_18071        1: 0.349557447796300   2: 0.206827048273854   6: 0.192834395344071   5: 0.122453261858900   0: 0.058133458261597   8: 0.014107327456095   4: 0.014033451202269   9: 0.014018634308740   3: 0.014018121421581   7: 0.014016854076594 

test_18075        0: 0.473514173279726   1: 0.222071831675415   2: 0.193901927984820   5: 0.020609594414226   6: 0.015887222408511   7: 0.015078021563538   9: 0.014792528188115   8: 0.014790461669603   4: 0.014688824610360   3: 0.014665414205687 

test_18079        1: 0.833039825942628   6: 0.018624271811120   0: 0.018557224213847   5: 0.018555193706793   7: 0.018544329715511   8: 0.018540857372884   4: 0.018537135883192   2: 0.018533800767944   9: 0.018533729467414   3: 0.018533631118667 

test_18080        0: 0.839883213620454   5: 0.017796251087797   6: 0.017793616245520   1: 0.017792946513247   4: 0.017790320581623   9: 0.017789117952937   8: 0.017788992611802   7: 0.017788735131285   2: 0.017788423321388   3: 0.017788382933948 

test_18085        6: 0.881140453037310   0: 0.013207734760758   2: 0.013206886596080   9: 0.013206642674953   1: 0.013206566711278   7: 0.013206428296049   5: 0.013206361020014   4: 0.013206346391854   8: 0.013206306314394   3: 0.013206274197310 

test_18086        6: 0.897899625582312   0: 0.033181939601065   8: 0.008633103929021   1: 0.008622325380041   7: 0.008611648059394   9: 0.008610825214709   5: 0.008610542562318   2: 0.008610248466950   4: 0.008609880586968   3: 0.008609860617221 

test_18093        6: 0.328538565451548   0: 0.293735969147330   7: 0.178131411912422   9: 0.097083074416960   5: 0.017089379185255   4: 0.017085617851524   1: 0.017084728219817   8: 0.017084028746392   3: 0.017083938722347   2: 0.017083286346406 

test_18095        6: 0.589810339438311   0: 0.320455460851508   1: 0.011218749288968   9: 0.011217042453859   5: 0.011216520191298   7: 0.011216448755501   8: 0.011216421046434   2: 0.011216409278488   4: 0.011216350758811   3: 0.011216257936822 

test_18096        5: 0.808368923604688   0: 0.021319336393209   1: 0.021309011201460   3: 0.021288394745338   7: 0.021287283373288   4: 0.021286622564492   6: 0.021286579068895   9: 0.021285251436987   8: 0.021285154317153   2: 0.021283443294490 

test_18099        6: 0.337395877951523   5: 0.308136301514672   0: 0.215383933317695   8: 0.073680464834612   1: 0.010934479374207   3: 0.010901114074331   7: 0.010898531122388   9: 0.010893243207621   4: 0.010889053816035   2: 0.010887000786916 

test_18101        4: 0.357363892628362   6: 0.227327586335200   1: 0.160129787670966   9: 0.140126757284437   0: 0.019178770597396   5: 0.019177647704489   8: 0.019175911855822   2: 0.019173602638645   3: 0.019173308289290   7: 0.019172734995393 

test_18104        6: 0.795123231125477   1: 0.075758092203233   0: 0.035558959181297   8: 0.022882251788181   5: 0.011781078282169   7: 0.011779349952773   9: 0.011779338399411   4: 0.011779299607477   3: 0.011779253114125   2: 0.011779146345858 

test_18106        9: 0.754487455302869   3: 0.027298241416721   6: 0.027285185206260   0: 0.027280344990020   5: 0.027277432864274   1: 0.027276377907314   2: 0.027274678067890   8: 0.027274451811395   7: 0.027273241444742   4: 0.027272590988514 

test_18108        9: 0.449844575179772   6: 0.409754608426276   0: 0.039625103875586   4: 0.014400863850315   1: 0.014399261653524   5: 0.014397076412614   8: 0.014396480338637   7: 0.014394452386464   2: 0.014394285719893   3: 0.014393292156919 

test_18109        6: 0.648943545256683   3: 0.229986365591840   0: 0.015152650553588   5: 0.015138819990831   1: 0.015134165355529   4: 0.015132196508362   9: 0.015129446773025   8: 0.015129260274093   2: 0.015126801722968   7: 0.015126747973082 

test_18111        2: 0.563251957200081   6: 0.191102138341647   0: 0.077625309447520   7: 0.049185948811356   5: 0.019808305862083   1: 0.019806194134085   4: 0.019806125271324   8: 0.019804919857602   9: 0.019804907656560   3: 0.019804193417742 

test_18120        5: 0.628686168816571   8: 0.208612844525138   4: 0.020340899036850   6: 0.020337896533688   0: 0.020337391165045   1: 0.020337113904502   9: 0.020336986154561   3: 0.020336968616857   7: 0.020336887532830   2: 0.020336843713958 

test_18128        6: 0.696884772538565   8: 0.109596365341999   7: 0.065296992352129   2: 0.038327323980936   0: 0.014990657861396   1: 0.014986322388723   5: 0.014983514262141   3: 0.014978125535990   4: 0.014978001875291   9: 0.014977923862830 

test_18135        1: 0.664458938936643   7: 0.120370893045401   6: 0.096742539454770   8: 0.016987098432327   5: 0.016908678485771   0: 0.016907869302730   3: 0.016906327683422   4: 0.016906206043356   9: 0.016905832004245   2: 0.016905616611335 

test_18136        6: 0.555353097023239   5: 0.200994633660829   0: 0.149494409236169   1: 0.013463837723469   4: 0.013451862011217   7: 0.013448601346459   3: 0.013448522259617   8: 0.013448499388421   9: 0.013448440606032   2: 0.013448096744549 

test_18138        0: 0.543661929172457   6: 0.345351041250685   9: 0.025096690247828   4: 0.015151498139200   1: 0.012733323783690   5: 0.011606881123127   8: 0.011600171950363   2: 0.011599877541155   3: 0.011599359167006   7: 0.011599227624490 

test_18142        6: 0.505712939820101   0: 0.320126635306925   2: 0.089235766005121   3: 0.012140296704676   1: 0.012131606177422   8: 0.012131577805739   9: 0.012130909567385   5: 0.012130839182652   7: 0.012129763305851   4: 0.012129666124129 

test_18145        8: 0.286904596518142   6: 0.243579434219536   7: 0.135293192973910   1: 0.124366389125323   2: 0.074624626355003   3: 0.073552024311259   4: 0.015425845536945   5: 0.015420892371924   0: 0.015417960269204   9: 0.015415038318756 

test_18146        6: 0.658263527167427   0: 0.162283194570270   2: 0.089250396958529   9: 0.012890789561708   7: 0.012886100168419   5: 0.012885947048512   3: 0.012885770276508   1: 0.012885666656895   8: 0.012884664629811   4: 0.012883942961921 

test_18148        6: 0.639157871548482   0: 0.234405283126795   9: 0.032138711335318   3: 0.032107656996072   1: 0.010543255568425   5: 0.010347351510706   8: 0.010325163196131   4: 0.010325004331421   7: 0.010324873660952   2: 0.010324828725697 

test_18149        9: 0.455358896784711   6: 0.266954051485545   5: 0.111713148846392   3: 0.090738736708349   1: 0.012618220244725   0: 0.012610402913952   2: 0.012508833760985   4: 0.012507238971748   8: 0.012496541782528   7: 0.012493928501064 

test_18150        6: 0.699446576509661   9: 0.137215674584554   1: 0.058789682697030   2: 0.027242517939037   0: 0.013045617283299   5: 0.012854961827271   7: 0.012851572076744   4: 0.012851188469622   8: 0.012851111040402   3: 0.012851097572381 

test_18152        5: 0.532330631351726   1: 0.216497205392626   9: 0.088895013867590   4: 0.023184609111775   6: 0.023182944865451   0: 0.023182015658255   2: 0.023181989553368   8: 0.023181959358156   3: 0.023181871297872   7: 0.023181759543183 

test_18155        5: 0.650422984427985   3: 0.161753391367379   4: 0.023485339808301   1: 0.023477317697762   0: 0.023476943850077   6: 0.023476932942103   8: 0.023476900934117   2: 0.023476781612782   9: 0.023476703984156   7: 0.023476703375338 

test_18157        4: 0.811739203564907   0: 0.020981078445251   5: 0.020942127596769   1: 0.020932518532241   6: 0.020909718642764   9: 0.020900603799710   2: 0.020900378942891   3: 0.020899045877993   7: 0.020897670249169   8: 0.020897654348306 

test_18158        5: 0.747168222048317   4: 0.028095445821628   2: 0.028092328682552   3: 0.028092123042085   6: 0.028092111738079   8: 0.028092031394994   7: 0.028091996482213   0: 0.028091957698408   1: 0.028091897542848   9: 0.028091885548875 

test_18160        6: 0.613443585697901   0: 0.166594769348860   3: 0.104892080217534   1: 0.016444561896456   5: 0.016441982359150   4: 0.016438762555739   8: 0.016436297943515   9: 0.016436124941933   7: 0.016436008715879   2: 0.016435826323034 

test_18166        4: 0.508027710997704   7: 0.282892167067642   5: 0.026145713032529   8: 0.026133850875944   6: 0.026133776339087   0: 0.026133538729913   3: 0.026133420982790   2: 0.026133378560077   9: 0.026133272259498   1: 0.026133171154814 

test_18176        6: 0.431622319539017   8: 0.384528064707744   9: 0.078433600681005   7: 0.023789186581179   0: 0.013730627197350   1: 0.013627976919483   2: 0.013574957732808   5: 0.013565479866924   3: 0.013564059243801   4: 0.013563727530690 

test_18177        6: 0.570841964772330   5: 0.197096241381961   8: 0.112511249744377   0: 0.033916993759663   1: 0.020433292846809   4: 0.013042742121892   7: 0.013042401342788   3: 0.013039504084952   9: 0.013038450745412   2: 0.013037159199816 

test_18180        5: 0.617492331467925   6: 0.192570133618318   1: 0.023749164110824   4: 0.023745213385366   9: 0.023741090526244   0: 0.023740993196538   2: 0.023740552853973   3: 0.023740241059059   7: 0.023740183327112   8: 0.023740096454641 

test_18182        1: 0.851904886381691   8: 0.016465384163070   6: 0.016458926481716   0: 0.016456994058612   5: 0.016453629809084   4: 0.016452645093755   9: 0.016452198775060   2: 0.016452109747477   7: 0.016451755566168   3: 0.016451469923367 

test_18185        0: 0.757010339802949   6: 0.137672944121674   3: 0.013212459087747   9: 0.013158383333220   1: 0.013158318387479   5: 0.013158182135889   8: 0.013157938157165   4: 0.013157762178804   2: 0.013157071740233   7: 0.013156601054840 

test_18186        6: 0.460219724266412   1: 0.332673465805280   5: 0.122303691812736   0: 0.012116312222577   9: 0.012115997843943   8: 0.012114868735594   3: 0.012114390936913   2: 0.012114293118432   4: 0.012113685788672   7: 0.012113569469441 

test_18187        5: 0.486231510469527   9: 0.365689127871744   0: 0.018544012024446   6: 0.018543112977392   1: 0.018512279594177   4: 0.018497198935608   3: 0.018496364196152   8: 0.018495622660573   2: 0.018495599825875   7: 0.018495171444507 

test_18188        0: 0.823329815071928   5: 0.019633554234273   1: 0.019632468472325   6: 0.019630098892020   4: 0.019629875107184   8: 0.019629191470592   9: 0.019629055181858   2: 0.019628687840405   3: 0.019628637677092   7: 0.019628616052325 

test_18191        4: 0.466252719611450   6: 0.283140183550277   7: 0.067876478045999   2: 0.045694622372346   1: 0.034431913401238   9: 0.020656150438997   5: 0.020498040818908   3: 0.020488056116814   0: 0.020480991938510   8: 0.020480843705460 

test_18205        6: 0.610116953986347   5: 0.230570600163185   1: 0.019921916149485   0: 0.019915740792823   8: 0.019914292711826   2: 0.019912571024738   4: 0.019912565344565   9: 0.019911886144737   3: 0.019911742124770   7: 0.019911731557527 

test_18210        1: 0.659754218174184   8: 0.202799616847532   5: 0.017299892928612   6: 0.017216668939355   0: 0.017182373266046   4: 0.017150134133331   7: 0.017149777814198   2: 0.017149230843041   9: 0.017149133396578   3: 0.017148953657123 

test_18213        6: 0.651217664588475   1: 0.243856809321235   0: 0.013132395743552   5: 0.013125199116986   4: 0.013118974615604   3: 0.013111731013201   8: 0.013109531845347   7: 0.013109344751991   2: 0.013109340159789   9: 0.013109008843819 

test_18217        5: 0.478540714981533   6: 0.392223837323938   7: 0.026049764827495   2: 0.025365163389910   0: 0.012987847776979   1: 0.012973052724333   4: 0.012968819751981   9: 0.012964933694264   8: 0.012963656678831   3: 0.012962208850736 

test_18221        6: 0.773704091130277   8: 0.025153118331753   5: 0.025145923693343   1: 0.025145724966099   0: 0.025143806309315   7: 0.025141810448371   3: 0.025141455880280   9: 0.025141401827787   2: 0.025141387303992   4: 0.025141280108783 

test_18222        6: 0.600108671712239   8: 0.285792518859161   9: 0.014852243385992   3: 0.014411041029689   0: 0.014203650611206   1: 0.014167104420801   7: 0.014129148187143   5: 0.014113482035779   4: 0.014111207613225   2: 0.014110932144763 

test_18223        6: 0.850528639403764   1: 0.016614154863242   5: 0.016612279886185   0: 0.016608924706187   4: 0.016606981661286   2: 0.016606322911100   8: 0.016606314638404   9: 0.016605523360928   3: 0.016605471991995   7: 0.016605386576909 

test_18225        0: 0.797477963239666   5: 0.022521750698934   7: 0.022513123007637   6: 0.022511038278677   9: 0.022497899378225   1: 0.022496724329526   2: 0.022495786868654   3: 0.022495584756131   8: 0.022495430047142   4: 0.022494699395406 

test_18228        9: 0.656856833612325   6: 0.193417995145225   1: 0.040743720501197   3: 0.024402452078596   5: 0.014199290196248   0: 0.014077510440543   4: 0.014077098260852   2: 0.014075143060928   8: 0.014075020900909   7: 0.014074935803178 

test_18229        1: 0.855700372510185   5: 0.016044306464801   0: 0.016035783302259   6: 0.016033220264211   3: 0.016032092203407   9: 0.016031017871449   8: 0.016030986203249   2: 0.016030982408378   4: 0.016030744939805   7: 0.016030493832257 

test_18231        6: 0.523375163592881   1: 0.379759256314351   0: 0.013397431553520   5: 0.012097033951329   9: 0.012027237004916   3: 0.011872791625095   8: 0.011869019839677   7: 0.011867456536097   4: 0.011867366175615   2: 0.011867243406519 

test_18232        1: 0.757478066010268   6: 0.026955136535827   8: 0.026951250487021   5: 0.026947155269307   0: 0.026946729082018   2: 0.026945209481710   4: 0.026944600680674   9: 0.026944193858785   7: 0.026943916885924   3: 0.026943741708466 

test_18234        3: 0.379888292323120   5: 0.282540729139590   6: 0.173896788647006   7: 0.023420312141337   9: 0.023390919588859   2: 0.023380383727688   1: 0.023372701259779   0: 0.023370787138846   4: 0.023370386191212   8: 0.023368699842562 

test_18236        6: 0.560591461413656   1: 0.273078844592895   8: 0.020793064090742   5: 0.020792936492537   0: 0.020791411958340   2: 0.020790876561309   9: 0.020790696449086   4: 0.020790518544141   3: 0.020790145803444   7: 0.020790044093851 

test_18238        1: 0.459025102342468   9: 0.341060657537763   6: 0.046568508955752   0: 0.021943895859513   7: 0.021910784641764   5: 0.021902602808139   4: 0.021898104137476   8: 0.021897078334371   2: 0.021896818433282   3: 0.021896446949472 

test_18239        2: 0.527493641626718   5: 0.253215147319631   8: 0.027435826094149   4: 0.027424362027278   1: 0.027410627178043   6: 0.027408151783712   0: 0.027406207121566   9: 0.027405295038356   7: 0.027400711134992   3: 0.027400030675554 

test_18242        5: 0.645127316155572   3: 0.166680711986499   4: 0.023529485906758   0: 0.023523494313399   6: 0.023523461696511   1: 0.023523370734054   8: 0.023523156654845   7: 0.023523135689813   2: 0.023522995178450   9: 0.023522871684099 

test_18243        5: 0.639108548763387   8: 0.171599524118735   1: 0.023672120791766   4: 0.023663987021319   6: 0.023659667521011   9: 0.023659582289115   0: 0.023659235048607   3: 0.023659151383268   2: 0.023659139356343   7: 0.023659043706448 

test_18249        6: 0.437945352423738   5: 0.341966975493631   0: 0.027523014580807   4: 0.027515864503556   8: 0.027508543689674   3: 0.027508207969619   7: 0.027508098259069   2: 0.027508065680374   9: 0.027507973914154   1: 0.027507903485379 

test_18252        6: 0.473229175420893   2: 0.227238355638338   5: 0.150967961040497   0: 0.044887964368869   8: 0.028698691385714   1: 0.023557291000577   7: 0.012921352981243   4: 0.012841376677443   9: 0.012832912582540   3: 0.012824918903885 

test_18253        5: 0.499671507388096   6: 0.356829782329643   1: 0.017950834139010   8: 0.017944580429266   0: 0.017937747175134   2: 0.017934122920600   9: 0.017933596416936   4: 0.017933464395623   7: 0.017932277745130   3: 0.017932087060561 

test_18254        1: 0.628622046111132   6: 0.230085966841401   5: 0.017665191965387   2: 0.017663282491499   0: 0.017661828180780   4: 0.017660824540060   7: 0.017660475462331   9: 0.017660363511062   8: 0.017660142050987   3: 0.017659878845361 

test_18257        1: 0.554845661884656   6: 0.314557146433151   7: 0.027713388417233   0: 0.014698963919078   2: 0.014698520571486   5: 0.014697754187845   8: 0.014697594761410   9: 0.014697155486602   3: 0.014697049199971   4: 0.014696765138567 

test_18258        5: 0.605023466001527   0: 0.226714642249027   4: 0.021037933363226   6: 0.021032980676821   1: 0.021032108509527   7: 0.021031859230693   9: 0.021031791896170   3: 0.021031754507596   8: 0.021031741153019   2: 0.021031722412393 

test_18263        6: 0.791027905310706   0: 0.073935000026568   1: 0.016897094859356   7: 0.016877461019370   3: 0.016877417564137   2: 0.016877308609281   5: 0.016877223448853   8: 0.016877042485583   9: 0.016876864875733   4: 0.016876681800411 

test_18271        6: 0.685126967005733   0: 0.098377328422229   1: 0.092975305281186   8: 0.047378537530176   9: 0.022537683427531   3: 0.010731057975384   5: 0.010718975514111   2: 0.010718075603913   7: 0.010718058530824   4: 0.010718010708912 

test_18275        6: 0.766090992154798   3: 0.110439141888746   1: 0.015440699715802   8: 0.015438205846525   0: 0.015437810832469   5: 0.015431450432278   9: 0.015430934402226   7: 0.015430516794641   2: 0.015430150628621   4: 0.015430097303894 

test_18276        6: 0.830513445594234   5: 0.018833805006194   0: 0.018833260117400   1: 0.018831910663707   4: 0.018831482409326   2: 0.018831353232652   3: 0.018831239429356   8: 0.018831226166135   9: 0.018831139857527   7: 0.018831137523470 

test_18277        6: 0.849475525484493   5: 0.017046396550311   7: 0.016698780869286   1: 0.016684549556453   8: 0.016683640529015   2: 0.016682727579961   0: 0.016682539561321   4: 0.016682458932334   9: 0.016681864991567   3: 0.016681515945259 

test_18280        6: 0.441640731957050   0: 0.254390016555152   5: 0.204324142353659   1: 0.027639930788900   9: 0.012073010053242   7: 0.012004445830434   8: 0.011982435695938   3: 0.011982173406134   2: 0.011981692533181   4: 0.011981420826310 

test_18281        6: 0.591412547423805   8: 0.244831683126899   1: 0.020561131544001   5: 0.020473640692729   0: 0.020456462268222   4: 0.020455410161478   9: 0.020452486497027   2: 0.020452400622400   7: 0.020452210849754   3: 0.020452026813684 

test_18283        5: 0.506297061296620   2: 0.282444685527597   4: 0.026413043145347   6: 0.026408875421225   1: 0.026407031816279   9: 0.026406640631685   0: 0.026406230719666   3: 0.026405543471235   8: 0.026405515676375   7: 0.026405372293971 

test_18294        5: 0.724635343616983   4: 0.030602159312035   3: 0.030595649674973   8: 0.030595476708321   2: 0.030595389651739   7: 0.030595261086440   9: 0.030595258264361   0: 0.030595178705536   1: 0.030595169418533   6: 0.030595113561079 

test_18296        6: 0.757644663678941   4: 0.085864071721328   5: 0.019567787086408   8: 0.019566518647305   0: 0.019560824339733   7: 0.019560451073907   1: 0.019559315183892   9: 0.019559078495162   3: 0.019558963921463   2: 0.019558325851860 

test_18297        6: 0.570013968798381   9: 0.250809337564924   0: 0.075728788526017   7: 0.014787746754612   2: 0.014781962288013   5: 0.014776279756102   1: 0.014775732753777   8: 0.014775632336521   4: 0.014775286286291   3: 0.014775264935362 

test_18300        5: 0.670690579474150   1: 0.196778850327114   6: 0.016575299265524   8: 0.016568337379310   2: 0.016567287565840   0: 0.016566713998332   9: 0.016565562125700   7: 0.016562640151380   4: 0.016562616449917   3: 0.016562113262733 

test_18302        6: 0.901600133152920   7: 0.010934929508433   0: 0.010934899842712   1: 0.010934202955713   5: 0.010933658064353   4: 0.010933585211517   8: 0.010932275921513   9: 0.010932164645049   2: 0.010932081499632   3: 0.010932069198159 

test_18303        5: 0.745696420458671   4: 0.028258037797778   6: 0.028256981033105   0: 0.028256098984945   1: 0.028255919942374   8: 0.028255464553749   7: 0.028255284800265   2: 0.028255281218196   9: 0.028255257041728   3: 0.028255254169190 

test_18306        0: 0.500869239524224   6: 0.380334310492654   8: 0.014849928272504   1: 0.014849825204133   7: 0.014849811948516   5: 0.014849615652054   9: 0.014849470631417   2: 0.014849404541486   3: 0.014849198284251   4: 0.014849195448761 

test_18307        4: 0.366884893108075   6: 0.254709544746789   0: 0.193795950503808   5: 0.026384288733166   8: 0.026372012593681   1: 0.026370905478849   3: 0.026370744321775   7: 0.026370722772594   2: 0.026370574489818   9: 0.026370363251444 

test_18308        4: 0.521053287109390   1: 0.225626365286157   5: 0.031674623261073   8: 0.031664033331658   3: 0.031663884548987   2: 0.031663717302893   9: 0.031663620126622   7: 0.031663599677262   0: 0.031663568150633   6: 0.031663301205327 

test_18309        5: 0.643864299865830   8: 0.162233695704724   1: 0.024249469127833   4: 0.024240343573456   6: 0.024235782176659   9: 0.024235570052451   0: 0.024235298909316   3: 0.024235237763381   2: 0.024235174773455   7: 0.024235128052896 

test_18311        2: 0.741084796195981   5: 0.028776426837713   4: 0.028769971439273   9: 0.028768209031566   1: 0.028767131038875   6: 0.028767000612652   8: 0.028766955002385   7: 0.028766891832308   0: 0.028766566783515   3: 0.028766051225733 

test_18313        1: 0.824801235894624   6: 0.019707936820187   5: 0.019439904388348   0: 0.019438434443533   9: 0.019437572564771   8: 0.019435722581785   2: 0.019435185010241   7: 0.019435038370411   4: 0.019434704183441   3: 0.019434265742659 

test_18317        5: 0.448439063344126   6: 0.323770472227565   0: 0.135965757601225   2: 0.017291375056871   1: 0.015063823485614   9: 0.012047153465969   3: 0.011889442108309   7: 0.011850777142809   4: 0.011841134637600   8: 0.011841000929913 

test_18321        6: 0.643260199724576   5: 0.214275494097631   8: 0.017809957711608   0: 0.017809667653288   1: 0.017808168736088   4: 0.017807940731853   9: 0.017807538682276   2: 0.017807178945031   7: 0.017807093304673   3: 0.017806760412977 

test_18323        6: 0.658154532067398   3: 0.103352975921086   8: 0.064147315349234   0: 0.045200380803290   5: 0.040884278985167   4: 0.017673460118841   7: 0.017648464079701   1: 0.017648262466275   2: 0.017645190182174   9: 0.017645140026834 

test_18325        6: 0.370968515641271   4: 0.236798727254723   2: 0.230580666567478   0: 0.047133826562913   1: 0.027745792723850   3: 0.017360487340149   5: 0.017354632224895   7: 0.017353093811799   9: 0.017352318968701   8: 0.017351938904219 

test_18326        5: 0.764855102023138   7: 0.026137311376746   4: 0.026129260289739   8: 0.026126266661138   6: 0.026125609822705   0: 0.026125475084641   9: 0.026125276076839   3: 0.026125249585406   1: 0.026125231129206   2: 0.026125217950442 

test_18328        6: 0.703850678159278   3: 0.131752535480358   1: 0.068759932028403   0: 0.029778457114369   8: 0.011030323585006   9: 0.010972291502313   5: 0.010964494236941   7: 0.010963904063873   2: 0.010963713462021   4: 0.010963670367437 

test_18329        6: 0.775491241929417   4: 0.085213631273899   1: 0.052017963458397   0: 0.012489951953093   8: 0.012473787831908   3: 0.012465333182147   7: 0.012462198780634   5: 0.012462127847227   9: 0.012462121912390   2: 0.012461641830887 

test_18332        6: 0.383250022786023   3: 0.332585892144146   8: 0.139669026292678   0: 0.060663866450736   5: 0.013976350737841   4: 0.013974667868935   1: 0.013974435211404   9: 0.013968941472405   2: 0.013968680928716   7: 0.013968116107116 

test_18334        1: 0.646493622710605   5: 0.179491862468873   6: 0.056330240268933   0: 0.016818564140163   3: 0.016816086355631   2: 0.016810003162532   7: 0.016809985241698   4: 0.016809921445368   9: 0.016809866556589   8: 0.016809847649608 

test_18336        7: 0.782325161022721   5: 0.024230373159108   6: 0.024219178289204   0: 0.024206064878084   1: 0.024202740785921   4: 0.024177503556492   9: 0.024167065058236   2: 0.024160044115543   3: 0.024158164947783   8: 0.024153704186909 

test_18337        6: 0.511347600593758   3: 0.371348642683428   8: 0.015007819951496   0: 0.014640769345406   1: 0.014615334893343   4: 0.014614907281148   5: 0.014608462688777   7: 0.014605893515043   9: 0.014605461355813   2: 0.014605107691789 

test_18339        5: 0.476619587088211   6: 0.242139225957276   2: 0.134963114433994   9: 0.050015549413775   7: 0.016050764946566   0: 0.016048604436587   1: 0.016046100539758   4: 0.016039056371367   8: 0.016039038438418   3: 0.016038958374048 

test_18340        6: 0.704752986691281   1: 0.108095156245197   5: 0.092651856602923   7: 0.013511437915966   9: 0.013504537339783   3: 0.013500277968183   2: 0.013496104084019   8: 0.013496070694507   0: 0.013496037553262   4: 0.013495534904879 

test_18342        4: 0.430728348440050   5: 0.396194577995315   1: 0.021639568117148   0: 0.021638947634825   6: 0.021637869447330   3: 0.021632954980596   2: 0.021632260533073   9: 0.021632009857862   8: 0.021631764690872   7: 0.021631698302931 

test_18345        6: 0.479929115300531   7: 0.252289025623990   0: 0.112536606309734   3: 0.067403954552068   8: 0.014713070037198   4: 0.014684452213481   5: 0.014611448820909   2: 0.014610898891908   1: 0.014610841255004   9: 0.014610586995177 

test_18347        6: 0.489681105316626   7: 0.377747192704863   5: 0.016578346502436   0: 0.016573206962737   9: 0.016572208375802   4: 0.016571411670058   8: 0.016569689259256   1: 0.016569036745344   3: 0.016568993528976   2: 0.016568808933903 

test_18348        6: 0.510664533515522   1: 0.224455712998405   0: 0.154628428703376   8: 0.015776001180258   3: 0.015747534505835   9: 0.015746416097139   5: 0.015746088989655   7: 0.015745244329286   4: 0.015745086265677   2: 0.015744953414848 

test_18351        6: 0.552164861622118   5: 0.224133230276096   7: 0.096403944749530   4: 0.018197833290470   1: 0.018184175675437   3: 0.018183723524769   2: 0.018183699179433   9: 0.018183080915141   0: 0.018182962713574   8: 0.018182488053432 

test_18352        6: 0.575449864598519   0: 0.243012188268680   9: 0.057391459802544   5: 0.028619609737582   4: 0.028078162514129   8: 0.013491330527779   1: 0.013490411793968   7: 0.013489178551902   3: 0.013488916275573   2: 0.013488877929323 

test_18354        5: 0.616256774003510   8: 0.188378611491106   4: 0.024425686365921   6: 0.024420332524937   2: 0.024420172129229   0: 0.024419971014285   1: 0.024419842300719   3: 0.024419636143673   9: 0.024419490374267   7: 0.024419483652353 

test_18355        5: 0.445340679698111   6: 0.417539314375904   0: 0.017148477852616   4: 0.017140697616647   8: 0.017139136543232   1: 0.017138881986309   9: 0.017138862857144   7: 0.017138156905289   2: 0.017138001252515   3: 0.017137790912233 

test_18356        6: 0.563208849266401   8: 0.319573106970561   3: 0.014727449919024   4: 0.014703029858954   0: 0.014669469742150   5: 0.014630674753971   9: 0.014627259194304   1: 0.014620424027240   7: 0.014620058738588   2: 0.014619677528807 

test_18357        6: 0.548697842038666   3: 0.250809476101699   1: 0.071132877781061   0: 0.043201507931182   8: 0.033125741326058   5: 0.010616184956340   9: 0.010608751032468   4: 0.010603820847704   7: 0.010601942840358   2: 0.010601855144464 

test_18360        6: 0.558585710511525   0: 0.164831064869464   1: 0.129846167230479   5: 0.089195821137266   3: 0.009595711860617   2: 0.009590395827193   9: 0.009589577599819   8: 0.009588647290018   7: 0.009588598419567   4: 0.009588305254051 

test_18362        6: 0.577698327173415   9: 0.250120799047423   3: 0.021586565451877   0: 0.021517950023616   5: 0.021516268607503   1: 0.021512858812579   8: 0.021512210986915   4: 0.021512181072309   2: 0.021511844875352   7: 0.021510993949012 

test_18363        6: 0.770401783697816   1: 0.025514441368103   8: 0.025513256799981   7: 0.025511640571282   0: 0.025511582382269   9: 0.025510296793717   5: 0.025510053666389   4: 0.025509109451247   2: 0.025508930793845   3: 0.025508904475351 

test_18366        6: 0.837950993737002   5: 0.018009266870630   9: 0.018005619706377   0: 0.018005459512311   4: 0.018005437712307   1: 0.018005433137000   8: 0.018004557376259   7: 0.018004515800606   3: 0.018004393491547   2: 0.018004322655960 

test_18367        3: 0.372348648679480   9: 0.280699368338495   6: 0.209683811117858   0: 0.019637712647351   5: 0.019613489669702   1: 0.019612952193573   4: 0.019608416909166   7: 0.019601375204988   2: 0.019599069064828   8: 0.019595156174558 

test_18370        6: 0.734379885060701   0: 0.112113760052806   8: 0.019192681373601   1: 0.019190934202321   9: 0.019188238493982   2: 0.019187717492963   7: 0.019187146538092   5: 0.019187052709466   3: 0.019186305157755   4: 0.019186278918314 

test_18465        6: 0.816821565396945   3: 0.020354082511764   0: 0.020353733761913   1: 0.020353625998386   9: 0.020353247546570   7: 0.020353198063037   2: 0.020353096131611   8: 0.020353045333195   5: 0.020352584870671   4: 0.020351820385909 

test_18466        6: 0.826687105028138   4: 0.019268975572236   5: 0.019262529215924   0: 0.019255588581127   1: 0.019254782442098   8: 0.019254373135111   9: 0.019254321466529   7: 0.019254298891626   2: 0.019254181702231   3: 0.019253843964980 

test_18467        6: 0.432543575613248   2: 0.383986663259736   0: 0.048317230128758   1: 0.019594845388312   5: 0.019287471022801   7: 0.019262187036631   4: 0.019255245668554   8: 0.019251648634828   3: 0.019251146816492   9: 0.019249986430641 

test_18470        6: 0.571181516623269   2: 0.183295592645210   1: 0.076312034991457   3: 0.050137885010067   5: 0.019856620047678   4: 0.019854314005342   8: 0.019841100427690   0: 0.019840622097854   7: 0.019840355368174   9: 0.019839958783259 

test_18472        6: 0.581373136961586   0: 0.192847835449409   2: 0.098165567170796   1: 0.059773454483379   5: 0.011313121129174   8: 0.011306303050597   9: 0.011305476086137   4: 0.011305253529353   7: 0.011305009533825   3: 0.011304842605743 

test_18476        8: 0.466220066478623   6: 0.324183487470535   0: 0.026203789177004   1: 0.026203589203006   9: 0.026200157253750   5: 0.026198319091064   4: 0.026198013559459   2: 0.026197558804957   3: 0.026197523925249   7: 0.026197495036353 

test_18479        6: 0.449504006256474   0: 0.432329201440511   3: 0.014776721957689   8: 0.014772137024176   5: 0.014771369206465   1: 0.014771108770935   9: 0.014770306655143   4: 0.014768918204613   2: 0.014768453378998   7: 0.014767777104997 

test_18480        9: 0.655816568413366   6: 0.184285049873810   2: 0.020019950609435   1: 0.019987157052194   5: 0.019986681835079   0: 0.019982454499452   3: 0.019981604117446   7: 0.019980737583172   8: 0.019979908971033   4: 0.019979887045014 

test_18481        5: 0.543449541472768   8: 0.270942029928142   6: 0.023226527392444   1: 0.023221038890269   9: 0.023199069371539   7: 0.023197165919560   4: 0.023191879805376   0: 0.023191575672759   3: 0.023190598381666   2: 0.023190573165477 

test_18482        6: 0.657247003001595   8: 0.209111611377739   0: 0.040111545760511   7: 0.013371627043580   5: 0.013363389955845   9: 0.013362426518921   1: 0.013359555485062   4: 0.013357967593788   2: 0.013357504396815   3: 0.013357368866144 

test_18483        5: 0.418091163007701   1: 0.172148875332570   7: 0.159006904869191   3: 0.135148462115091   6: 0.019276637764027   9: 0.019269085339752   4: 0.019266731436928   8: 0.019266649311419   0: 0.019263788361225   2: 0.019261702462097 

test_18487        9: 0.830088853445345   6: 0.018888350249266   5: 0.018886025451947   0: 0.018878659794761   8: 0.018878200087348   7: 0.018876576739673   3: 0.018876164560867   1: 0.018875952005246   2: 0.018875617403371   4: 0.018875600262175 

test_18488        6: 0.534587730772047   1: 0.316013222926389   8: 0.018686054908428   5: 0.018683927499890   0: 0.018673814210335   9: 0.018672038534698   2: 0.018671806952819   3: 0.018670651036250   7: 0.018670489398898   4: 0.018670263760245 

test_18489        6: 0.834432561640991   1: 0.018397693034106   0: 0.018397027380425   5: 0.018396811333914   8: 0.018396485927450   9: 0.018395928191696   4: 0.018395922286030   2: 0.018395907596019   7: 0.018395890459824   3: 0.018395772149545 

test_18490        6: 0.531339038001556   0: 0.365257145831187   5: 0.012926380682510   1: 0.012925870530165   9: 0.012925684666069   4: 0.012925418326144   8: 0.012925341758242   7: 0.012925159981507   2: 0.012925032272372   3: 0.012924927950248 

test_18493        6: 0.642170421513614   8: 0.180773859492835   2: 0.045680103071257   4: 0.042223225737570   0: 0.014864716726602   1: 0.014862710494069   5: 0.014857632826087   9: 0.014856187123351   7: 0.014855774269445   3: 0.014855368745169 

test_18495        5: 0.613607165650271   6: 0.154472712559941   8: 0.085873325239835   9: 0.020866393021783   1: 0.020865830486307   0: 0.020864950434598   4: 0.020862968411197   3: 0.020862726269750   7: 0.020862204969949   2: 0.020861722956370 

test_18496        6: 0.578447325990286   2: 0.259086797150455   5: 0.020317327055973   9: 0.020307948357781   0: 0.020307455055349   8: 0.020306882399957   4: 0.020306825396730   3: 0.020306658079085   7: 0.020306523687632   1: 0.020306256826752 

test_18497        5: 0.528880813405111   3: 0.318836610261251   9: 0.019038194038158   8: 0.019036210259792   6: 0.019035504891654   4: 0.019035434500789   1: 0.019035174214976   0: 0.019034704686942   2: 0.019033783817868   7: 0.019033569923459 

test_18504        1: 0.551278365500366   6: 0.306306460344137   0: 0.023319995505932   5: 0.017019025506056   8: 0.017013512084539   4: 0.017013202973270   7: 0.017013023400490   9: 0.017012597595545   2: 0.017012084738414   3: 0.017011732351251 

test_18509        6: 0.754587952269471   9: 0.100092409587029   5: 0.018173477003437   1: 0.018164981862124   4: 0.018164671102599   0: 0.018163682392385   3: 0.018163572822371   8: 0.018163411922644   7: 0.018163051130041   2: 0.018162789907899 

test_18514        6: 0.650429919104045   5: 0.213343977594202   9: 0.017030953552497   3: 0.017030518855775   4: 0.017028933756741   1: 0.017028691370759   8: 0.017028106330047   0: 0.017028050827909   2: 0.017025619738900   7: 0.017025228869126 

test_18519        6: 0.661014843443810   8: 0.139820334592273   0: 0.082662725980005   5: 0.019356141184771   1: 0.016389589361506   9: 0.016152936852718   4: 0.016151460197796   3: 0.016150876698197   2: 0.016150620673314   7: 0.016150471015610 

test_18520        0: 0.473878801042934   6: 0.389910331815752   9: 0.017028071216957   8: 0.017027819052729   7: 0.017027532478747   5: 0.017026125011911   1: 0.017025839703982   2: 0.017025553432489   4: 0.017025014194647   3: 0.017024912049852 

test_18521        6: 0.651533172370491   1: 0.128617731338247   0: 0.107826456515823   9: 0.016006845898081   2: 0.016004662282634   5: 0.016003089585411   7: 0.016002113838312   3: 0.016002086639914   8: 0.016001971354853   4: 0.016001870176234 

test_18523        6: 0.566889006618153   1: 0.099063053054774   0: 0.098307738085261   3: 0.073813878846320   5: 0.060003675697503   8: 0.046046059417880   2: 0.013970021263911   9: 0.013969131503960   7: 0.013969107352018   4: 0.013968328160221 

test_18524        6: 0.733579497404718   5: 0.029611591089068   1: 0.029605075683765   8: 0.029603668591781   9: 0.029601794747699   7: 0.029601201765810   0: 0.029600298114124   3: 0.029600004815382   2: 0.029598567453207   4: 0.029598300334446 

test_18527        6: 0.738177641468040   5: 0.071193038721431   1: 0.054682496630461   0: 0.031735741972326   9: 0.017375922597213   8: 0.017367901063856   4: 0.017367255596976   7: 0.017366967517539   3: 0.017366695075834   2: 0.017366339356324 

test_18530        6: 0.645791137575082   3: 0.262415814908662   1: 0.017132540738773   9: 0.010704963871634   5: 0.010701569067085   0: 0.010671001960509   8: 0.010657143544508   4: 0.010650769602026   7: 0.010637853496148   2: 0.010637205235574 

test_18531        6: 0.434856965150818   5: 0.239429821231402   8: 0.223864191604584   1: 0.025521131467963   7: 0.016958680091753   0: 0.011883158304625   2: 0.011872367839576   9: 0.011871472736797   3: 0.011871120132192   4: 0.011871091440289 

test_18533        9: 0.480235955793741   7: 0.290230816365717   5: 0.028764984575406   6: 0.028689954070861   3: 0.028689330942905   0: 0.028679501157286   4: 0.028678135868711   8: 0.028677604579176   1: 0.028677545908710   2: 0.028676170737487 

test_18534        9: 0.757976519397532   5: 0.026911351598191   6: 0.026896698685911   0: 0.026892174238745   4: 0.026889156553484   8: 0.026888321482176   7: 0.026886988114294   3: 0.026886934545610   1: 0.026886662030487   2: 0.026885193353570 

test_18536        6: 0.758289829839390   5: 0.026864478270329   9: 0.026858961579746   3: 0.026856939321782   0: 0.026855982708624   8: 0.026855483332502   1: 0.026855312224952   7: 0.026854703964415   2: 0.026854233707483   4: 0.026854075050777 

test_18537        6: 0.760575945220510   9: 0.026613642961196   8: 0.026604043484683   5: 0.026603743453416   7: 0.026602531500098   0: 0.026600511129443   1: 0.026600193282907   2: 0.026599834801935   3: 0.026599824737697   4: 0.026599729428116 

test_18538        6: 0.465345140146147   3: 0.304121427668228   9: 0.028826774088197   8: 0.028823489289893   5: 0.028820373532533   1: 0.028813337030837   0: 0.028813183516598   7: 0.028812447866015   2: 0.028811992571844   4: 0.028811834289708 

test_18539        7: 0.459702932623952   6: 0.419703098022881   5: 0.015077909795424   8: 0.015075232805801   2: 0.015074776840163   9: 0.015074189779992   0: 0.015073266383379   1: 0.015072988575537   4: 0.015072833229627   3: 0.015072771943243 

test_18540        6: 0.695608555188812   0: 0.123789159560714   2: 0.058059693885971   7: 0.037174040681781   5: 0.014231075235649   9: 0.014229142966669   1: 0.014228355806321   3: 0.014226911345968   8: 0.014226733627239   4: 0.014226331700877 

test_18544        6: 0.819236531453595   1: 0.020085615526377   0: 0.020085605859040   7: 0.020085299790948   8: 0.020084953576764   9: 0.020084680758423   4: 0.020084422229924   5: 0.020084373859579   2: 0.020084335329068   3: 0.020084181616282 

test_18549        6: 0.816821220062040   3: 0.020354139377785   0: 0.020353870851797   1: 0.020353783773277   9: 0.020353237183826   7: 0.020353198384867   2: 0.020353097848109   8: 0.020353046373933   5: 0.020352585634456   4: 0.020351820509910 

test_18554        6: 0.838302071712741   1: 0.038878198697094   8: 0.015353325678786   5: 0.015352805584049   0: 0.015352785295846   9: 0.015352321187178   2: 0.015352151943618   4: 0.015352147287712   3: 0.015352122929022   7: 0.015352069683955 

test_18557        6: 0.686420793847862   1: 0.146679831137738   0: 0.048485809921670   5: 0.016969813866851   8: 0.016911255006876   7: 0.016908039737581   9: 0.016906318413465   4: 0.016906170060692   2: 0.016906128612592   3: 0.016905839394672 

test_18563        5: 0.514926645080682   7: 0.257375234783182   6: 0.106057116951468   3: 0.017432538415826   1: 0.017377133490105   0: 0.017372489270118   8: 0.017365597994596   4: 0.017365347365376   9: 0.017364022211957   2: 0.017363874436689 

test_18564        6: 0.534669135843827   1: 0.315931801811257   8: 0.018686068292006   5: 0.018683930722521   0: 0.018673814435511   9: 0.018672038075184   2: 0.018671806731481   3: 0.018670650995009   7: 0.018670489378422   4: 0.018670263714782 

test_18565        6: 0.626610876302109   8: 0.228926858087760   0: 0.047970890329020   3: 0.013811007512911   1: 0.013793024390595   4: 0.013788761878560   5: 0.013775993099174   9: 0.013775912417943   2: 0.013773353368211   7: 0.013773322613716 

test_18566        6: 0.412339193794033   7: 0.236489788689230   5: 0.185477829532721   1: 0.023677879663462   0: 0.023673400600894   4: 0.023668714323938   9: 0.023668635567099   2: 0.023668506050625   8: 0.023668304931049   3: 0.023667746846949 

test_18567        6: 0.526094937947820   2: 0.355773440803670   5: 0.022263489805659   0: 0.013725336152796   1: 0.013719008930709   7: 0.013685836307223   8: 0.013685305525422   9: 0.013684304401731   4: 0.013684215466328   3: 0.013684124658641 

test_18569        3: 0.738479135579673   5: 0.029152318142962   0: 0.029071425694466   6: 0.029067760292229   1: 0.029054963966016   9: 0.029035302412299   4: 0.029035188159183   2: 0.029035006601889   7: 0.029034645436354   8: 0.029034253714930 

test_18570        3: 0.425701215829296   0: 0.405868677503942   6: 0.021152210039588   1: 0.021067235685529   5: 0.021046705628999   9: 0.021035434786015   8: 0.021033735164825   4: 0.021031975418707   7: 0.021031525928595   2: 0.021031284014505 

test_18571        6: 0.624567317693906   7: 0.217113586106267   1: 0.069090771449101   8: 0.022006383140740   3: 0.011209196818756   5: 0.011206095988685   9: 0.011205575320007   4: 0.011201844275503   0: 0.011200489312262   2: 0.011198739894773 

test_18575        9: 0.414407214570599   1: 0.306527078261142   0: 0.143943471443092   8: 0.030975940562819   6: 0.017677666938695   5: 0.017436076074179   4: 0.017265390240164   7: 0.017258701250542   3: 0.017254314618187   2: 0.017254146040580 

test_18576        6: 0.289673028348045   5: 0.287622411527393   1: 0.215547234590008   9: 0.119725305132464   0: 0.014630117250278   2: 0.014560803417477   4: 0.014560567889748   7: 0.014560369282362   3: 0.014560201433686   8: 0.014559961128540 

test_18577        1: 0.623395744965714   6: 0.242927363347271   2: 0.016734540507904   5: 0.016714605750609   4: 0.016712014726018   0: 0.016708437604092   8: 0.016702306775171   9: 0.016702025855475   3: 0.016701609177254   7: 0.016701351290491 

test_18585        1: 0.734396623248368   9: 0.057630034120476   5: 0.026039739267164   6: 0.026006670397704   2: 0.025992843363388   4: 0.025988763398021   0: 0.025988241543173   7: 0.025985793297277   8: 0.025985789710019   3: 0.025985501654411 

test_18590        8: 0.566286302673646   1: 0.254617306393270   0: 0.022451716401306   6: 0.022385493452109   5: 0.022379657547208   4: 0.022377444418697   2: 0.022376161317868   7: 0.022375793216408   9: 0.022375521908368   3: 0.022374602671120 

test_18591        5: 0.585425253940505   6: 0.240231926034542   7: 0.075130530342597   8: 0.014189911892599   1: 0.014184142229402   4: 0.014169919172184   0: 0.014167392966466   9: 0.014167086432750   3: 0.014166943896625   2: 0.014166893092330 

test_18592        1: 0.309775186801575   6: 0.244446151962814   9: 0.173294599781228   0: 0.170466585485232   8: 0.017012517354092   2: 0.017003412635671   5: 0.017003149453906   7: 0.016999685698608   3: 0.016999483441513   4: 0.016999227385360 

test_18595        5: 0.468705222090845   6: 0.325353534211144   2: 0.050232621356551   8: 0.045263991056922   1: 0.018456278186649   0: 0.018432664729210   7: 0.018407277609475   9: 0.018387420902773   3: 0.018380519648777   4: 0.018380470207655 

test_18599        6: 0.634079351279110   0: 0.219637587532194   7: 0.043316878886105   3: 0.014711327931512   5: 0.014710397440278   1: 0.014709801156602   8: 0.014709350573671   2: 0.014708592346760   4: 0.014708408302093   9: 0.014708304551675 

test_18600        0: 0.441213757162806   5: 0.426804128114589   6: 0.016510691547675   1: 0.016499936807733   9: 0.016495749260458   4: 0.016495622288010   3: 0.016495343168714   8: 0.016495048166178   2: 0.016494954236468   7: 0.016494769247370 

test_18602        5: 0.774995991882970   4: 0.025007251951116   8: 0.024999793147457   3: 0.024999630831417   0: 0.024999621976304   2: 0.024999616107852   9: 0.024999570804056   7: 0.024999514106544   1: 0.024999509626618   6: 0.024999499565667 

test_18604        6: 0.553274658415550   1: 0.355825172323920   7: 0.015387599889836   5: 0.010793046127655   9: 0.010788466367970   0: 0.010786855485683   8: 0.010786206048586   3: 0.010786116264026   2: 0.010786006863637   4: 0.010785872213138 

test_18605        1: 0.569502527784127   5: 0.263895208749855   6: 0.020835627211300   4: 0.020825820549714   0: 0.020825373149853   3: 0.020823355291809   7: 0.020823115123477   2: 0.020823102371057   9: 0.020822997556117   8: 0.020822872212692 

test_18606        5: 0.586188343639471   8: 0.210282104121642   4: 0.025449626147419   3: 0.025440191137055   2: 0.025440014649621   0: 0.025440011888846   7: 0.025439970771223   9: 0.025439966753781   6: 0.025439890704959   1: 0.025439880185985 

test_18609        6: 0.904261799018856   4: 0.010661941850623   8: 0.010635865259759   0: 0.010634671786853   2: 0.010634397656520   7: 0.010634393133439   1: 0.010634345031195   9: 0.010634271649228   5: 0.010634267126237   3: 0.010634047487292 

test_18610        5: 0.517775982430965   9: 0.336264892385137   6: 0.018253407533665   0: 0.018247387144322   4: 0.018244555475541   8: 0.018244216852487   2: 0.018243103057475   1: 0.018242244241688   3: 0.018242152652539   7: 0.018242058226180 

test_18614        6: 0.781677354668001   1: 0.060392054810796   3: 0.047033442665576   0: 0.032319572721569   5: 0.027109491110866   7: 0.010305854915382   4: 0.010294979582133   8: 0.010289550007297   9: 0.010289307143895   2: 0.010288392374485 

test_18616        6: 0.578322281370423   7: 0.283254024601021   5: 0.017320839653246   3: 0.017302465052456   1: 0.017301260982182   8: 0.017300758786772   4: 0.017300232686620   0: 0.017300012249449   9: 0.017299466731573   2: 0.017298657886259 

test_18621        6: 0.535362724196296   1: 0.385990925215504   3: 0.010136535374982   4: 0.009989725941735   9: 0.009779257765770   0: 0.009775949264062   5: 0.009743305233224   8: 0.009741562664282   2: 0.009740560355892   7: 0.009739453988252 

test_18625        6: 0.750664134495004   0: 0.150416309990867   1: 0.024149701527086   9: 0.010693289530780   7: 0.010690740842498   5: 0.010678810617041   8: 0.010676963802015   2: 0.010676792843326   3: 0.010676660404865   4: 0.010676595946518 

test_18627        4: 0.597891754141784   8: 0.192964033035067   5: 0.026153197772235   1: 0.026146106386426   0: 0.026145612533743   6: 0.026142593408831   2: 0.026140762198792   3: 0.026138833421682   9: 0.026138700746802   7: 0.026138406354638 

test_18638        6: 0.495891776498996   8: 0.281515201570248   7: 0.065692558309644   5: 0.040065061884678   2: 0.019523074292401   0: 0.019465994899014   1: 0.019465111489385   9: 0.019463220754004   4: 0.019459679237629   3: 0.019458321064000 

test_18642        6: 0.903687857383894   4: 0.010725858521270   8: 0.010699238840601   0: 0.010698535859757   1: 0.010698188802913   5: 0.010698171806101   7: 0.010698153622587   2: 0.010698148952823   9: 0.010698057139821   3: 0.010697789070232 

test_18643        1: 0.478504220018694   0: 0.275228072297076   6: 0.030787632209603   5: 0.030787087689568   4: 0.030783834052830   2: 0.030782346245349   7: 0.030781930515589   8: 0.030781879748938   9: 0.030781805868937   3: 0.030781191353417 

test_18644        5: 0.713911453948960   6: 0.031797959715598   1: 0.031790388237773   0: 0.031789041411356   4: 0.031786059274430   2: 0.031785708641812   8: 0.031785022178081   3: 0.031784968257082   7: 0.031784742969135   9: 0.031784655365773 

test_18646        5: 0.675361529785265   1: 0.146666825068705   4: 0.022249439859388   6: 0.022248485060312   2: 0.022245942707599   0: 0.022245818726909   9: 0.022245783755697   8: 0.022245681456682   7: 0.022245368977988   3: 0.022245124601456 

test_18648        4: 0.768031547095553   5: 0.025782039102225   6: 0.025774241155110   0: 0.025773494763486   2: 0.025773364287021   8: 0.025773339153785   1: 0.025773196649505   3: 0.025772941532027   9: 0.025772936173845   7: 0.025772900087444 

test_18651        6: 0.756031104043893   2: 0.074775775063154   0: 0.043832045352166   3: 0.030964687275586   5: 0.015741882905580   9: 0.015739020204689   4: 0.015733381824395   1: 0.015729425020727   7: 0.015726376980626   8: 0.015726301329183 

test_18654        5: 0.419015108509633   7: 0.414611514250249   1: 0.020803984224242   8: 0.020802959750685   6: 0.020800426626771   9: 0.020797817473556   0: 0.020796929232712   2: 0.020791730270597   4: 0.020790222989163   3: 0.020789306672392 

test_18655        2: 0.526472523245381   9: 0.249138276397040   6: 0.028058860647410   1: 0.028052129906119   5: 0.028047936745217   7: 0.028047753314943   8: 0.028046753757321   3: 0.028045955688440   0: 0.028045825291013   4: 0.028043985007117 

test_18658        5: 0.667418629582691   1: 0.168002125149880   0: 0.020604130112483   6: 0.020589209749609   7: 0.020569972487149   2: 0.020564119966416   9: 0.020563422337177   8: 0.020563198306461   4: 0.020562789958090   3: 0.020562402350044 

test_18660        1: 0.764456770946428   0: 0.026368678152309   6: 0.026212059732771   5: 0.026148230419262   4: 0.026146706704304   2: 0.026136990162817   9: 0.026135556247501   8: 0.026132654232365   7: 0.026131196342669   3: 0.026131157059575 

test_18663        6: 0.341438438602477   8: 0.295899260534696   1: 0.233342805867560   3: 0.018503046047108   7: 0.018497784293593   5: 0.018467236956292   0: 0.018465314484092   4: 0.018462195117905   2: 0.018461968274152   9: 0.018461949822125 

test_18664        6: 0.724645747011750   5: 0.030604616676364   0: 0.030597823664960   9: 0.030594294515581   4: 0.030593759204021   1: 0.030593521698588   8: 0.030593424693499   3: 0.030592647368941   7: 0.030592184185388   2: 0.030591980980908 

test_18665        6: 0.782671418424825   1: 0.071965664536712   5: 0.033534572956324   0: 0.015986636012154   9: 0.015976683962279   8: 0.015973329325548   4: 0.015973292831914   7: 0.015973122385243   3: 0.015972837967201   2: 0.015972441597800 

test_18667        6: 0.704219184693276   7: 0.179519171663605   1: 0.014573641088979   0: 0.014529966727347   5: 0.014529212036853   4: 0.014527480941584   9: 0.014525888343632   8: 0.014525277982092   3: 0.014525247121356   2: 0.014524929401276 

test_18668        0: 0.747958643606331   6: 0.028018661841960   8: 0.028011838525585   1: 0.028004067355061   9: 0.028002921718525   4: 0.028001873493838   5: 0.028000890873755   7: 0.028000862635183   2: 0.028000382405185   3: 0.027999857544579 

test_18670        0: 0.354501307578563   6: 0.240215598733589   5: 0.209640877381325   8: 0.027986889537537   4: 0.027952680657221   7: 0.027941609780265   1: 0.027941414562542   9: 0.027940221675433   3: 0.027939711416406   2: 0.027939688677119 

test_18672        6: 0.660886102728451   0: 0.199964785409542   1: 0.057363547800092   8: 0.019909734589753   4: 0.015989709833471   9: 0.012974335091981   5: 0.008233981008504   7: 0.008228631314578   2: 0.008224712719236   3: 0.008224459504391 

test_18674        0: 0.437204603635073   6: 0.432374946370244   8: 0.016305161549444   1: 0.016303324216374   5: 0.016303029885625   4: 0.016302621178859   9: 0.016302329595973   7: 0.016301573765498   2: 0.016301325788169   3: 0.016301084014741 

test_18676        6: 0.632848406662079   8: 0.136361850801156   0: 0.105013040664469   5: 0.017969127261761   1: 0.017968428167753   3: 0.017968356835781   4: 0.017967920297738   7: 0.017967733767099   9: 0.017967656689726   2: 0.017967478852438 

test_18678        2: 0.613228537294438   1: 0.173634005052500   7: 0.026650266821636   6: 0.026644794356717   5: 0.026641530740521   9: 0.026640642701875   3: 0.026640382682753   8: 0.026640266347567   4: 0.026639824164663   0: 0.026639749837330 

test_18680        2: 0.767307642844118   6: 0.025873544483890   1: 0.025857071115462   8: 0.025854683830230   0: 0.025853890301177   7: 0.025852768387907   5: 0.025852002822135   9: 0.025850655920265   4: 0.025849243994109   3: 0.025848496300706 

test_18682        6: 0.859787249392469   1: 0.015582057742950   5: 0.015580943102049   0: 0.015579958803172   4: 0.015578883857185   2: 0.015578442105195   3: 0.015578224537840   7: 0.015578182220912   9: 0.015578045666587   8: 0.015578012571641 

test_18686        6: 0.528385054708065   0: 0.239736822396252   7: 0.113641214528831   5: 0.016897780635032   1: 0.016893367869973   8: 0.016890234158879   9: 0.016889477577660   4: 0.016889290356248   2: 0.016888822747887   3: 0.016887935021172 

test_18688        7: 0.345556358570421   6: 0.334154546596029   0: 0.233762403464636   1: 0.012464093448881   5: 0.012384071048419   2: 0.012371347625399   4: 0.012327695901608   9: 0.012326887993648   8: 0.012326641550219   3: 0.012325953800742 

test_18689        2: 0.450743072897531   5: 0.398203243035643   6: 0.018892577132341   1: 0.018889762065270   9: 0.018888176044350   0: 0.018879503508062   3: 0.018877094160390   8: 0.018876802481562   7: 0.018875728800171   4: 0.018874039874680 

test_18692        2: 0.593247135789560   6: 0.214291063769981   5: 0.024070833521663   4: 0.024059611667277   1: 0.024056074227269   8: 0.024056008039852   0: 0.024055045767911   7: 0.024054879537269   9: 0.024054803831334   3: 0.024054543847884 

test_18698        2: 0.552357114068177   1: 0.269448890515208   5: 0.022277788870395   6: 0.022275904952598   4: 0.022274810919473   7: 0.022274612395030   9: 0.022274122649207   8: 0.022272516021727   3: 0.022272380252585   0: 0.022271859355600 

test_18699        5: 0.554710462012548   8: 0.254147200576795   4: 0.023899507902044   3: 0.023892044906006   2: 0.023891942444128   9: 0.023891846732283   7: 0.023891814181137   1: 0.023891759092802   0: 0.023891757997910   6: 0.023891664154348 

test_18700        6: 0.606481875112563   2: 0.255238591191027   8: 0.042491951445345   0: 0.021878899949081   1: 0.012369826065205   5: 0.012320463635708   9: 0.012304977517673   4: 0.012304620117833   7: 0.012304403279865   3: 0.012304391685698 

test_18701        2: 0.658102985483431   0: 0.152812633671615   6: 0.023644655470685   5: 0.023638230734769   1: 0.023635567314553   4: 0.023634787414189   8: 0.023634207345420   7: 0.023633230939154   9: 0.023632306250346   3: 0.023631395375839 

test_18703        5: 0.572175630383944   2: 0.232951615257624   4: 0.024366130151865   6: 0.024359315049952   9: 0.024359070755924   8: 0.024357765734743   1: 0.024357733649341   3: 0.024357683128412   7: 0.024357576744614   0: 0.024357479143582 

test_18704        2: 0.547358303020248   7: 0.228031993069654   6: 0.028088471114428   1: 0.028082357955415   8: 0.028075398625896   5: 0.028074415931670   0: 0.028074025725151   9: 0.028072695799794   4: 0.028071879164283   3: 0.028070459593461 

test_18705        2: 0.733845737859106   5: 0.029574352903040   6: 0.029573473055729   1: 0.029572911046470   4: 0.029572848841713   9: 0.029572742911998   0: 0.029572300851705   7: 0.029572053139765   3: 0.029571950243238   8: 0.029571629147236 

test_18706        2: 0.762343056268323   6: 0.026419437456292   5: 0.026408827127821   1: 0.026407102358860   8: 0.026405899183786   4: 0.026404857911112   7: 0.026403998308192   0: 0.026403977540399   9: 0.026402109650798   3: 0.026400734194418 

test_18707        2: 0.751351774154181   5: 0.027634124287269   4: 0.027630972500219   6: 0.027626881638349   9: 0.027626360619418   1: 0.027626289572794   3: 0.027626063410916   7: 0.027625876383287   8: 0.027625848268114   0: 0.027625809165453 

test_18708        5: 0.785305050692065   4: 0.023858252318409   0: 0.023858186476954   1: 0.023856528180767   6: 0.023855388534618   2: 0.023855345781612   3: 0.023853024349402   8: 0.023852841418461   9: 0.023852721283034   7: 0.023852660964677 

test_18713        4: 0.597225941057626   2: 0.182712114595277   5: 0.027514846786192   6: 0.027507535623410   0: 0.027506999565689   1: 0.027506736891798   8: 0.027506594476562   9: 0.027506481270094   3: 0.027506481069623   7: 0.027506268663729 

test_18718        4: 0.802602683335281   8: 0.021969376193596   6: 0.021951884363712   9: 0.021949646145298   5: 0.021940804469069   0: 0.021923639563446   7: 0.021920716004599   1: 0.021919390510619   2: 0.021912789926575   3: 0.021909069487805 

test_18719        4: 0.723250454315673   3: 0.099593720322322   5: 0.022150748957540   8: 0.022143954962962   0: 0.022143633427851   2: 0.022143561736752   1: 0.022143556552432   9: 0.022143512341788   6: 0.022143456292195   7: 0.022143401090484 

test_18721        5: 0.695843455602126   8: 0.145014214876937   7: 0.019963864338244   4: 0.019926813314068   0: 0.019881868428353   6: 0.019876376896352   2: 0.019874424739950   1: 0.019873974159468   9: 0.019872826721367   3: 0.019872180923135 

test_18724        6: 0.423173219929263   8: 0.375116679319204   9: 0.056464649019761   0: 0.053714027459359   1: 0.015279061060160   7: 0.015252333639681   5: 0.015250745914648   4: 0.015249963600814   2: 0.015249827253091   3: 0.015249492804020 

test_18728        2: 0.834137601771602   5: 0.018435339823407   6: 0.018430116650115   1: 0.018429108120222   0: 0.018428747428949   4: 0.018428659041253   3: 0.018428025797522   9: 0.018427686270858   8: 0.018427418613553   7: 0.018427296482520 

test_18730        6: 0.712776187285324   2: 0.119378056021882   3: 0.048985619814433   0: 0.017018829804779   1: 0.016977703823054   5: 0.016976971232990   4: 0.016973881814614   9: 0.016971390082560   7: 0.016971068401872   8: 0.016970291718493 

test_18732        6: 0.402956590542804   5: 0.388617522122793   4: 0.026060031146418   8: 0.026052536951622   3: 0.026052430489840   2: 0.026052316747839   7: 0.026052215963973   9: 0.026052164422795   0: 0.026052113362690   1: 0.026052078249225 

test_18736        2: 0.738011597809130   6: 0.122179370797890   0: 0.017518901909475   1: 0.017476345357090   5: 0.017473812805507   4: 0.017468508185629   9: 0.017468304838086   7: 0.017467795828614   3: 0.017467746362504   8: 0.017467616106075 

test_18738        2: 0.807077440092266   6: 0.050951086912399   5: 0.017750834810937   0: 0.017747695622736   1: 0.017746764540387   4: 0.017745656313733   8: 0.017745366874042   3: 0.017745174506075   7: 0.017744999401754   9: 0.017744980925671 

test_18739        2: 0.789687529903955   7: 0.070935989849652   6: 0.017444739569196   1: 0.017444617960207   5: 0.017420847494655   0: 0.017420076858529   9: 0.017418419954146   4: 0.017410845510580   8: 0.017408470292994   3: 0.017408462606088 

test_18743        2: 0.543118321323700   1: 0.214383529656973   5: 0.030325237141545   4: 0.030318140319270   6: 0.030309596149115   3: 0.030309381037502   7: 0.030309072000787   8: 0.030308962258430   9: 0.030308953099034   0: 0.030308807013644 

test_18744        6: 0.706654233895824   7: 0.161208122443044   1: 0.059716532149444   0: 0.011293257757643   5: 0.010189547564431   3: 0.010187907317101   8: 0.010187622738993   4: 0.010187604035879   9: 0.010187594288534   2: 0.010187577809107 

test_18746        6: 0.616082130384499   2: 0.254232232656057   5: 0.016214726700097   4: 0.016211583606032   8: 0.016210926939489   1: 0.016210774706328   0: 0.016209786816850   9: 0.016209749511078   7: 0.016209119801354   3: 0.016208968878216 

test_18747        2: 0.733577799212175   5: 0.029604181466983   6: 0.029603534321562   4: 0.029602881156241   9: 0.029602585210132   1: 0.029602217511523   7: 0.029601876158023   0: 0.029601872914391   8: 0.029601672427485   3: 0.029601379621485 

test_18748        6: 0.799239057317577   2: 0.022329370981597   9: 0.022310667957488   5: 0.022303822929095   7: 0.022303447797352   3: 0.022303296826443   8: 0.022303264272838   0: 0.022302478718420   4: 0.022302373313157   1: 0.022302219886033 

test_18749        6: 0.742785323654721   5: 0.092709853122597   1: 0.020571311182703   9: 0.020569420111869   0: 0.020563717534162   4: 0.020562667740368   8: 0.020560222835791   3: 0.020559531077890   7: 0.020559309953743   2: 0.020558642786155 

test_18750        8: 0.750805907823359   5: 0.027695113949559   6: 0.027689433713016   0: 0.027688380999555   4: 0.027687361247178   1: 0.027687085186671   9: 0.027686964986351   3: 0.027686868602507   2: 0.027686523838436   7: 0.027686359653368 

test_18751        8: 0.484157160640948   1: 0.370017451868640   0: 0.018255155312243   6: 0.018250601291285   5: 0.018229566019125   4: 0.018218258779127   3: 0.018218161818762   2: 0.018218046191710   9: 0.018217955729658   7: 0.018217642348502 

test_18752        9: 0.472163361852872   6: 0.247528591912737   1: 0.125727908062879   5: 0.072228208680929   2: 0.013728317191780   0: 0.013727501621196   3: 0.013724509578406   4: 0.013724280783325   7: 0.013723810484321   8: 0.013723509831554 

test_18753        6: 0.797847320960199   9: 0.022467726137697   5: 0.022462689905155   0: 0.022460768133459   8: 0.022460455822168   1: 0.022460425401228   7: 0.022460388593330   2: 0.022460197453750   3: 0.022460032891874   4: 0.022459994701141 

test_18754        2: 0.525723570743034   7: 0.308312521564058   5: 0.020760463963964   6: 0.020747729912048   4: 0.020746109657229   1: 0.020744439748512   0: 0.020742649970697   8: 0.020740953045065   3: 0.020740801615043   9: 0.020740759780349 

test_18763        8: 0.826554532996984   6: 0.019278552266274   1: 0.019272886317439   0: 0.019272283125245   5: 0.019271217865250   9: 0.019270565397356   7: 0.019270158099036   2: 0.019270067769851   4: 0.019269977803136   3: 0.019269758359430 

test_18765        2: 0.670687105747239   9: 0.187981336872385   5: 0.017674223657465   6: 0.017673681169324   0: 0.017665688086223   1: 0.017664348753366   4: 0.017663929532265   3: 0.017663805684796   8: 0.017663439029324   7: 0.017662441467612 

test_18768        6: 0.299835110275402   9: 0.274373574103654   1: 0.236747043138313   5: 0.086614356613806   3: 0.017074949729361   0: 0.017072724707464   2: 0.017071974549629   4: 0.017071461579110   8: 0.017069527908720   7: 0.017069277394542 

test_18769        5: 0.720587441976821   8: 0.088408634034362   6: 0.059245041515946   9: 0.018831315997287   4: 0.018827697994287   0: 0.018820457168357   7: 0.018820321955565   2: 0.018819821613549   1: 0.018819640452031   3: 0.018819627291796 

test_18773        2: 0.582712025749599   1: 0.247958583798779   6: 0.021194640018205   5: 0.021166767884346   4: 0.021162539346271   0: 0.021161373080918   9: 0.021161341703266   7: 0.021161326400750   3: 0.021160704337631   8: 0.021160697680234 

test_18774        6: 0.518795086555000   9: 0.141692099925709   1: 0.139258887605916   8: 0.114275557642742   5: 0.014558944143606   0: 0.014291032594150   7: 0.014288269243617   3: 0.014283993864681   4: 0.014278219039878   2: 0.014277909384702 

test_18778        1: 0.544040332918500   0: 0.272561620345721   3: 0.036304946032162   5: 0.021017966041297   6: 0.021013943681135   4: 0.021013680609397   9: 0.021012390041046   2: 0.021011797924535   8: 0.021011741802564   7: 0.021011580603643 

test_18779        9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

test_18781        6: 0.861116182856127   7: 0.032835334055491   9: 0.013415280442022   3: 0.013357711114772   1: 0.013290720654582   0: 0.013252135215354   8: 0.013190782193895   5: 0.013181941704316   4: 0.013179993721354   2: 0.013179918042089 

test_18782        5: 0.827378322076068   6: 0.019227000181993   0: 0.019199281329633   2: 0.019174291793417   9: 0.019174049224072   8: 0.019173577854825   1: 0.019173516632654   7: 0.019166954123490   3: 0.019166658618719   4: 0.019166348165128 

test_18783        1: 0.699359301190423   5: 0.110339500946431   4: 0.052062678911810   0: 0.019752972893333   6: 0.019752754918650   3: 0.019749442632916   8: 0.019746471925004   7: 0.019745840012860   9: 0.019745662072653   2: 0.019745374495920 

test_18789        2: 0.725874794916078   6: 0.030460772987482   9: 0.030458862044080   5: 0.030458432156125   1: 0.030458357447275   7: 0.030458045018161   0: 0.030457892472502   3: 0.030457681897195   4: 0.030457675609339   8: 0.030457485451762 

test_18795        2: 0.638106505648123   6: 0.214163821630228   5: 0.018469618870252   1: 0.018466253667886   0: 0.018466181158051   4: 0.018466180557534   9: 0.018465568930528   3: 0.018465342297244   8: 0.018465288404177   7: 0.018465238835976 

test_18798        6: 0.822238869182677   8: 0.037179742877320   4: 0.017773053251980   9: 0.017570039295348   5: 0.017543942196479   2: 0.017539775792184   1: 0.017539281651652   0: 0.017538746417196   7: 0.017538434487690   3: 0.017538114847474 

test_18807        6: 0.618265265059035   2: 0.202431327353374   5: 0.022415239618466   1: 0.022413335113869   0: 0.022413008055719   7: 0.022412883242266   4: 0.022412358736486   3: 0.022412302331266   9: 0.022412193140150   8: 0.022412087349369 

test_18810        2: 0.495836494627335   0: 0.207014378227417   5: 0.159358861864617   6: 0.019689920474123   1: 0.019684554849982   4: 0.019684306378620   9: 0.019683401280418   7: 0.019682851070928   3: 0.019682710702400   8: 0.019682520524157 

test_18811        9: 0.566109336059083   6: 0.237651442740753   5: 0.030608901267380   0: 0.023689054550314   1: 0.023686241136143   7: 0.023669167380004   2: 0.023655418685040   4: 0.023654402210838   3: 0.023638795809537   8: 0.023637240160909 

test_18816        5: 0.776326198556086   1: 0.024896591435923   4: 0.024849899664322   3: 0.024846883755053   8: 0.024846824885189   6: 0.024846765495337   0: 0.024846737363476   9: 0.024846722813617   2: 0.024846715416850   7: 0.024846660614147 

test_18824        2: 0.420805758659798   6: 0.358605182086914   1: 0.027576038061361   9: 0.027574670242839   5: 0.027574445546843   0: 0.027573984034079   7: 0.027572742611540   4: 0.027572553473259   8: 0.027572415883213   3: 0.027572209400154 

test_18828        4: 0.818078144496185   5: 0.020220164802034   6: 0.020213956837097   9: 0.020212657582178   0: 0.020212648956503   1: 0.020212516937864   8: 0.020212511439296   7: 0.020212475077972   3: 0.020212468679959   2: 0.020212455190912 

test_18830        5: 0.538513839891367   4: 0.250626154717136   6: 0.068214831036402   8: 0.020378357503936   0: 0.020378202707474   9: 0.020377777527099   3: 0.020377760609020   1: 0.020377715825321   2: 0.020377686928565   7: 0.020377673253681 

test_18832        5: 0.743032825426877   4: 0.028559361148266   6: 0.028551722308282   0: 0.028551067911165   8: 0.028550988829494   3: 0.028550907017170   2: 0.028550855275984   7: 0.028550825320984   9: 0.028550739169117   1: 0.028550707592661 

test_18835        6: 0.907262094015954   2: 0.010383917606508   0: 0.010299661575575   1: 0.010296324442181   9: 0.010293778544879   5: 0.010293713759765   3: 0.010292738717149   8: 0.010292648061209   4: 0.010292617322695   7: 0.010292505954084 

test_18840        2: 0.699899848792784   6: 0.136009362995531   5: 0.042350223930834   4: 0.017430340132265   0: 0.017392046919625   7: 0.017391902670324   9: 0.017383226168120   1: 0.017381664935360   8: 0.017380691942720   3: 0.017380691512438 

test_18842        1: 0.694123326195263   6: 0.146100144952216   5: 0.019977753731793   0: 0.019972329490944   4: 0.019971773745727   2: 0.019971254046552   9: 0.019971042208112   3: 0.019970908251969   7: 0.019970823024442   8: 0.019970644352983 

test_18849        0: 0.477623681352743   6: 0.436314883321116   9: 0.016256466173286   4: 0.010030857065615   1: 0.009996190937189   5: 0.009968499763274   2: 0.009954754478125   8: 0.009953018148868   7: 0.009951981026305   3: 0.009949667733479 

test_18851        6: 0.494100947142647   8: 0.340388291257508   7: 0.039612305091725   3: 0.017997289506042   1: 0.017996107220241   2: 0.017982236436916   4: 0.017982102673508   5: 0.017981273916948   0: 0.017980075982414   9: 0.017979370772050 

test_18852        3: 0.654933378351063   6: 0.202201723053557   7: 0.017906322034157   1: 0.017882867353960   0: 0.017868857679873   5: 0.017854286438125   2: 0.017842005363579   4: 0.017837852917398   9: 0.017837060558405   8: 0.017835646249881 

test_18856        1: 0.725985787974170   2: 0.030448242375568   6: 0.030447398568054   0: 0.030446503149061   4: 0.030446196742552   8: 0.030445934541621   5: 0.030445216956763   9: 0.030444967357266   7: 0.030444936859821   3: 0.030444815475125 

test_18857        4: 0.297108943222609   6: 0.283312496779311   2: 0.277230131220616   0: 0.020447423204047   5: 0.020337578144245   9: 0.020331929233688   3: 0.020314400034422   1: 0.020306186155079   7: 0.020305980892550   8: 0.020304931113432 

test_18858        6: 0.672775339902261   3: 0.120228362978076   2: 0.066673373509893   9: 0.041176557038396   7: 0.039419135071562   0: 0.011977492685697   5: 0.011970603700090   1: 0.011966600748724   8: 0.011911991011354   4: 0.011900543353946 

test_18859        4: 0.597962859531757   6: 0.173151255451420   9: 0.093394430615616   1: 0.019364567215186   0: 0.019359009868729   5: 0.019356565602867   8: 0.019353545777393   3: 0.019352914789073   2: 0.019352646013601   7: 0.019352205134359 

test_18860        6: 0.855174496932937   5: 0.016095933608894   1: 0.016091840253733   3: 0.016091698701988   8: 0.016091485085836   0: 0.016091299263776   7: 0.016090877934836   4: 0.016090865654038   9: 0.016090756306450   2: 0.016090746257512 

test_18861        3: 0.422596839731691   1: 0.254535568566823   6: 0.165916870394625   0: 0.036705058204070   8: 0.020055873236534   5: 0.020044198093895   4: 0.020037108159376   2: 0.020036734022852   9: 0.020036279324658   7: 0.020035470265476 

test_18863        1: 0.609358773546048   4: 0.149830073360368   2: 0.090944204900461   7: 0.021413748490530   6: 0.021413220851712   0: 0.021413127462009   8: 0.021408836403505   5: 0.021407133687925   9: 0.021405673205158   3: 0.021405208092284 

test_18865        6: 0.485375460718602   8: 0.348853038891953   7: 0.040133438030928   3: 0.017962509051775   1: 0.017957834536617   2: 0.017944739529460   4: 0.017944623427271   5: 0.017943824721632   0: 0.017942603772006   9: 0.017941927319756 

test_18867        1: 0.553377040519677   6: 0.353768992384459   0: 0.011652205538117   5: 0.011602068835485   7: 0.011601702235094   4: 0.011601519099090   8: 0.011600777369966   9: 0.011598617868818   2: 0.011598540499091   3: 0.011598535650205 

test_18870        5: 0.408310863598053   3: 0.334222896380939   4: 0.032191372086761   8: 0.032182397143149   0: 0.032182279363050   2: 0.032182238186969   9: 0.032182166575726   1: 0.032181995181696   7: 0.032181962009212   6: 0.032181829474443 

test_18872        9: 0.462365557889224   5: 0.228113580811924   6: 0.192156403690838   0: 0.016771994679342   1: 0.016766756447471   3: 0.016766592377176   4: 0.016766521149226   7: 0.016765551336190   8: 0.016763577957441   2: 0.016763463661167 

test_18873        6: 0.885381365281712   5: 0.012741171112896   0: 0.012735467860750   1: 0.012735322098539   2: 0.012735149218740   7: 0.012734751207859   8: 0.012734344949832   9: 0.012734301145272   3: 0.012734140213337   4: 0.012733986911062 

test_18875        4: 0.535770793665151   5: 0.312666095660818   6: 0.018954184872668   1: 0.018944832071999   8: 0.018944829277596   0: 0.018944789107857   9: 0.018944755790955   7: 0.018943327267821   2: 0.018943309289098   3: 0.018943082996037 

test_18882        5: 0.735781349596051   6: 0.111205330512255   0: 0.043055831480472   7: 0.015709818859294   1: 0.015708608580042   2: 0.015708218676941   3: 0.015707920731029   8: 0.015707874258958   4: 0.015707526802202   9: 0.015707520502757 

test_18888        5: 0.478868140733045   6: 0.378257910944482   1: 0.041158103536053   8: 0.014836533985964   0: 0.014485629189869   9: 0.014483858363706   7: 0.014477818367273   2: 0.014477738712524   3: 0.014477539879305   4: 0.014476726287779 

test_18895        1: 0.780375331432039   7: 0.065567894040014   6: 0.019272253099856   0: 0.019258126750968   5: 0.019258004235999   9: 0.019255772611591   2: 0.019254669838630   4: 0.019253149829607   3: 0.019252482946358   8: 0.019252315214939 

test_18896        5: 0.438769031635257   3: 0.318057036986052   0: 0.086556734726282   1: 0.022406330736235   6: 0.022393132680601   9: 0.022371160386402   2: 0.022362653490780   4: 0.022361983405593   8: 0.022361032360212   7: 0.022360903592587 

test_18898        6: 0.802045269715860   5: 0.021999484561642   0: 0.021997689135572   1: 0.021996953451308   2: 0.021994881502829   4: 0.021994821505557   3: 0.021993542343891   9: 0.021993106018903   8: 0.021992210711729   7: 0.021992041052710 

test_18899        6: 0.848691390183057   8: 0.016818220521659   5: 0.016813146605003   0: 0.016812480234411   7: 0.016811511347528   1: 0.016811217211243   4: 0.016810562507288   3: 0.016810545289323   9: 0.016810520086994   2: 0.016810406013493 

test_18902        6: 0.608380129172517   3: 0.250949816569562   9: 0.041242811846377   2: 0.014226804571477   5: 0.014204227622766   0: 0.014201836600087   8: 0.014199788265643   7: 0.014199222595181   1: 0.014197736777418   4: 0.014197625978974 

test_18904        6: 0.801604228666168   8: 0.038672814126467   7: 0.020202590944520   0: 0.020010701271045   9: 0.019974932184595   5: 0.019909059644796   4: 0.019907322459577   1: 0.019906821217282   2: 0.019905967916491   3: 0.019905561569057 

test_18906        6: 0.793462285810075   4: 0.053967527021288   2: 0.019397537970441   1: 0.019048756519066   0: 0.019029889441778   5: 0.019024456653081   3: 0.019019287182812   7: 0.019017950614211   8: 0.019016373657411   9: 0.019015935129838 

test_18908        6: 0.830654129930975   7: 0.018824140692422   1: 0.018816069823790   0: 0.018815550434025   8: 0.018815248826844   9: 0.018815189692039   4: 0.018815145832471   2: 0.018815137099960   3: 0.018815050207408   5: 0.018814337460064 

test_18910        0: 0.619672932862323   3: 0.170988552410518   6: 0.076167145974837   5: 0.019028782996504   1: 0.019027314182186   4: 0.019024582307345   9: 0.019024140234263   8: 0.019022577574580   2: 0.019022267620304   7: 0.019021703837140 

test_18911        6: 0.675387052345433   3: 0.140534193580982   0: 0.091033678147273   1: 0.019147354767967   7: 0.012365285029699   5: 0.012308351045214   9: 0.012306658748915   4: 0.012306542724713   8: 0.012305759473035   2: 0.012305124136769 

test_18917        6: 0.413898406311811   9: 0.272601658997374   0: 0.177974307573960   1: 0.040924717248332   4: 0.035566136143608   3: 0.015375459597605   5: 0.010960212907270   2: 0.010903302247092   8: 0.010898997156414   7: 0.010896801816533 

test_18920        0: 0.379661385910722   9: 0.307514711155312   8: 0.189555777789750   5: 0.017627376878784   6: 0.017621779876563   1: 0.017617148514703   4: 0.017601222352390   3: 0.017600855119069   7: 0.017600775842198   2: 0.017598966560508 

test_18921        5: 0.784161763544405   3: 0.024131930456527   0: 0.023994349376844   6: 0.023965860078982   1: 0.023960920097155   8: 0.023958802729312   9: 0.023957274504895   4: 0.023957071956354   2: 0.023956283377349   7: 0.023955743878177 

test_18922        9: 0.608600401734972   5: 0.244180182696119   6: 0.018499091760044   2: 0.018413530438815   0: 0.018406469896170   1: 0.018386177814739   7: 0.018385790543724   8: 0.018384024903629   4: 0.018373084467965   3: 0.018371245743823 

test_18924        1: 0.521691888328339   6: 0.383209857030836   7: 0.018989070874567   0: 0.011242996211154   8: 0.010823390237282   5: 0.010818202465934   3: 0.010806390731787   9: 0.010806166909177   2: 0.010806063767028   4: 0.010805973443895 

test_18930        9: 0.506698638712739   0: 0.347728629783251   6: 0.018243064960194   8: 0.018219941928044   5: 0.018197073191795   1: 0.018191385986422   7: 0.018181213907365   4: 0.018180941974699   3: 0.018180318123983   2: 0.018178791431508 

test_18932        6: 0.400211673188149   4: 0.242143018466120   1: 0.156231463681746   9: 0.058158479195343   3: 0.057376860244686   2: 0.017189969649498   5: 0.017175114282217   8: 0.017174813633059   0: 0.017170415840369   7: 0.017168191818814 

test_18938        0: 0.496197442955898   1: 0.363839294914038   4: 0.043921033014701   3: 0.020419753297346   7: 0.013027024262780   6: 0.012830132509579   5: 0.012452321629911   8: 0.012438833784976   2: 0.012438684454891   9: 0.012435479175881 

test_18943        0: 0.756630300029588   6: 0.027065753251229   7: 0.027042894762106   1: 0.027040450467843   8: 0.027037740114727   5: 0.027036739072920   2: 0.027036559650405   3: 0.027036537287477   9: 0.027036529864073   4: 0.027036495499632 

test_18944        4: 0.498015564170425   6: 0.272295822099395   9: 0.101679672658399   5: 0.018296503150821   1: 0.018289466737602   0: 0.018288523953877   2: 0.018284290478212   8: 0.018283771235785   3: 0.018283603599900   7: 0.018282781915584 

test_18945        0: 0.427455554301201   6: 0.390645251529112   9: 0.044292664810275   1: 0.036940714819763   2: 0.016785591480597   7: 0.016783157461371   5: 0.016776548397246   3: 0.016775106789191   8: 0.016772834280272   4: 0.016772576130972 

test_18946        8: 0.772525754960519   5: 0.025282560967380   6: 0.025282433524869   9: 0.025276647572101   4: 0.025273978642412   1: 0.025273681944020   0: 0.025272775382238   7: 0.025272687844034   2: 0.025270530481256   3: 0.025268948681172 

test_18951        1: 0.836681885720316   6: 0.018150574261949   5: 0.018149298093290   0: 0.018146224890982   4: 0.018146158797724   2: 0.018146019738693   9: 0.018145310889388   3: 0.018144970480721   8: 0.018144935978404   7: 0.018144621148534 

test_18952        5: 0.779555214298474   7: 0.024515419576503   0: 0.024502277299910   6: 0.024497126857512   1: 0.024493383956211   2: 0.024491699123718   9: 0.024486746533896   8: 0.024486120699557   3: 0.024486044895585   4: 0.024485966758634 

test_18953        5: 0.417164666256937   1: 0.341714395547144   4: 0.030150083003835   0: 0.030139470648116   3: 0.030138819130916   6: 0.030138738997727   8: 0.030138702874617   2: 0.030138527961560   9: 0.030138304727146   7: 0.030138290852002 

test_18954        6: 0.822121819056054   5: 0.019765510272467   0: 0.019765041316648   1: 0.019764884176708   8: 0.019764441550220   9: 0.019764286842695   7: 0.019764177064127   4: 0.019763584450199   2: 0.019763211487600   3: 0.019763043783281 

test_18955        5: 0.494586740760987   2: 0.234242318665036   1: 0.104104256132519   4: 0.048085715730641   6: 0.019841518763059   0: 0.019836519781777   7: 0.019825963517697   3: 0.019825773554336   8: 0.019825694925887   9: 0.019825498168062 

test_18959        4: 0.724776975546214   1: 0.030626900016085   0: 0.030600529526068   6: 0.030582829149148   2: 0.030578777814387   9: 0.030568048662064   5: 0.030567979825033   7: 0.030566340264673   8: 0.030565908064057   3: 0.030565711132271 

test_18962        5: 0.829502902102465   1: 0.018959774161565   6: 0.018946293357233   0: 0.018945745656337   9: 0.018941748381981   2: 0.018941441606408   4: 0.018940813815628   7: 0.018940475473239   3: 0.018940474832452   8: 0.018940330612692 

test_18963        1: 0.617349190816018   5: 0.222311023941109   6: 0.020052449854346   0: 0.020042876453693   4: 0.020041427123054   9: 0.020041137533031   2: 0.020040828246453   3: 0.020040490373373   8: 0.020040329261417   7: 0.020040246397507 

test_18973        6: 0.870309797160834   1: 0.022051274640404   4: 0.018968695155800   0: 0.018680986012643   5: 0.011666013953284   7: 0.011665328993624   8: 0.011664703459151   9: 0.011664614531748   2: 0.011664304142571   3: 0.011664281949942 

test_18975        4: 0.306766036578740   6: 0.278805412701180   2: 0.271097916592503   1: 0.032073716390640   0: 0.018593899723315   9: 0.018540374564206   5: 0.018532543338247   3: 0.018531330232114   8: 0.018529515893364   7: 0.018529253985691 

test_18985        6: 0.750932369931205   0: 0.158887640988229   8: 0.011281166515531   5: 0.011271902239780   9: 0.011271561954711   1: 0.011271515382168   4: 0.011271195424894   7: 0.011270925553221   2: 0.011270922689448   3: 0.011270799320813 

test_18986        1: 0.395600320832224   6: 0.235961561887712   9: 0.214164666896808   5: 0.022043165260514   2: 0.022041006784456   0: 0.022039862969257   8: 0.022038270296017   4: 0.022037613202964   7: 0.022036937975974   3: 0.022036593894074 

test_18987        6: 0.507667300643760   0: 0.377501527672611   7: 0.014372103747346   8: 0.014356371921494   9: 0.014351698920994   5: 0.014351591572576   1: 0.014350161184782   4: 0.014349993390182   3: 0.014349669726030   2: 0.014349581220226 

test_18988        2: 0.531505525906809   1: 0.237775904615470   5: 0.068836685681940   0: 0.023129922843510   6: 0.023129098806508   4: 0.023126072305332   3: 0.023124494975152   8: 0.023124473046464   9: 0.023124124059381   7: 0.023123697759433 

test_18990        6: 0.749924891206557   1: 0.138450509893859   7: 0.023787067428134   0: 0.012560057564292   9: 0.012551805489662   8: 0.012546903062182   5: 0.012545059568618   3: 0.012544628387264   2: 0.012544556557775   4: 0.012544520841659 

test_18991        6: 0.708514604235340   0: 0.194255446196958   9: 0.012156500213046   1: 0.012154779286689   5: 0.012153925260800   4: 0.012153387922977   8: 0.012153120627070   7: 0.012152794245089   2: 0.012152724287770   3: 0.012152717724261 

test_18992        6: 0.502536928611875   0: 0.410783165586011   9: 0.010838125783780   3: 0.010838037049676   1: 0.010835362926319   5: 0.010834038467124   8: 0.010833822767563   2: 0.010833578003028   7: 0.010833471670429   4: 0.010833469134195 

test_18993        6: 0.633614262657517   0: 0.144523106635652   7: 0.138357005612576   8: 0.011941244440900   9: 0.011931748676485   1: 0.011929627679322   5: 0.011926141535176   4: 0.011925650561651   2: 0.011925641202878   3: 0.011925570997844 

test_18994        6: 0.784451138826115   0: 0.102559328527235   1: 0.024785665328345   8: 0.012632631399774   9: 0.012596014043919   5: 0.012595633648190   7: 0.012595296999088   2: 0.012594956654465   4: 0.012594778154910   3: 0.012594556417959 

test_18995        6: 0.862731052263419   8: 0.025267799316377   0: 0.014004730978287   7: 0.014000952952144   9: 0.013999510018801   5: 0.013999455604843   1: 0.013999435218683   3: 0.013999069181072   4: 0.013999034799672   2: 0.013998959666701 

test_18996        6: 0.802153143228437   0: 0.099573686184131   1: 0.028537870769145   7: 0.009980502758254   8: 0.009970419939786   9: 0.009959563096348   5: 0.009956984987199   4: 0.009956165177644   3: 0.009955832399845   2: 0.009955831459211 

test_18997        5: 0.531447175283382   3: 0.250320760268083   0: 0.027335281793909   6: 0.027291421857389   8: 0.027274379467928   1: 0.027270069167079   4: 0.027269379225674   7: 0.027266249099406   9: 0.027263134311835   2: 0.027262149525316 

test_19000        6: 0.617829570409032   0: 0.293653265199330   9: 0.028731794109834   7: 0.008570521259610   1: 0.008544474458793   8: 0.008534536658057   3: 0.008534403059513   5: 0.008534083348068   4: 0.008533678001067   2: 0.008533673496697 

test_19004        0: 0.741093904458858   6: 0.028778019019155   5: 0.028767359003026   2: 0.028766657186321   9: 0.028766619604128   1: 0.028765864310864   7: 0.028765818280002   8: 0.028765384103884   4: 0.028765193092989   3: 0.028765180940774 

test_19005        6: 0.832915112881453   7: 0.050378902575257   0: 0.028561782286082   9: 0.012596657631900   1: 0.012592009102174   5: 0.012591411989790   8: 0.012591142162840   4: 0.012591044005802   2: 0.012590976237872   3: 0.012590961126830 

test_19006        8: 0.474917171897722   6: 0.311365087317001   4: 0.064864976204669   0: 0.042051573906864   1: 0.017961945757453   3: 0.017826314170547   7: 0.017808723089591   5: 0.017739124694616   2: 0.017734616581935   9: 0.017730466379603 

test_19009        6: 0.487475292009561   5: 0.367430912266767   4: 0.018139868089060   1: 0.018138135990323   0: 0.018136928671653   9: 0.018136066843001   8: 0.018135757519524   7: 0.018135741091770   2: 0.018135722403312   3: 0.018135575115029 

test_19017        6: 0.884306495109243   5: 0.012855762264664   0: 0.012855336382367   1: 0.012855105519775   9: 0.012855014872032   4: 0.012854634244649   8: 0.012854594528421   2: 0.012854419830636   7: 0.012854402741622   3: 0.012854234506592 

test_19020        6: 0.745967478741041   5: 0.028230574383517   0: 0.028226920727745   1: 0.028226712827152   8: 0.028225671442756   2: 0.028225254124755   3: 0.028224892888729   9: 0.028224733231270   4: 0.028223912364563   7: 0.028223849268471 

test_19021        6: 0.746237497189480   5: 0.028198690687852   1: 0.028197250289294   0: 0.028196993282326   4: 0.028196409642259   8: 0.028195261431442   2: 0.028194672873031   7: 0.028194602401299   9: 0.028194418130102   3: 0.028194204072915 

test_19022        6: 0.790821485677705   8: 0.054084729762487   1: 0.019429806280900   5: 0.019382696518958   2: 0.019381388353481   0: 0.019381344452376   4: 0.019380055965289   9: 0.019379855486610   3: 0.019379480840606   7: 0.019379156661589 

test_19023        6: 0.830677925696407   1: 0.018815494104959   5: 0.018814086770323   0: 0.018814065348604   8: 0.018813319633842   7: 0.018813309830999   4: 0.018813087814286   9: 0.018812946389385   2: 0.018812922861341   3: 0.018812841549854 

test_19028        6: 0.420644956338735   0: 0.346378050891571   8: 0.165575041018955   1: 0.010600267167322   3: 0.009480500239849   5: 0.009465003308704   9: 0.009464907865924   7: 0.009464178543195   4: 0.009463688359256   2: 0.009463406266489 

test_19029        5: 0.861757072613804   4: 0.015362454081262   6: 0.015362156017384   1: 0.015361299448472   0: 0.015360043086035   7: 0.015359644134454   9: 0.015359599949515   8: 0.015359457511630   3: 0.015359138165512   2: 0.015359134991933 

test_19033        0: 0.505981977225905   6: 0.373584406033191   9: 0.026081807147177   7: 0.013494151684704   5: 0.013477307385342   1: 0.013476612669062   8: 0.013476052423749   3: 0.013475973189002   2: 0.013475907354364   4: 0.013475804887504 

test_19037        6: 0.542629015875777   9: 0.345525675872689   3: 0.013988750329648   0: 0.013987473565302   1: 0.013981025012687   5: 0.013979972545864   4: 0.013979110758417   7: 0.013976995296651   8: 0.013976132021337   2: 0.013975848721627 

test_19040        6: 0.905117617666257   0: 0.010543535782590   8: 0.010542817489730   1: 0.010542734604453   5: 0.010542570235187   9: 0.010542425815556   7: 0.010542187616419   4: 0.010542062293419   2: 0.010542055464236   3: 0.010541993032153 

test_19041        6: 0.632016758752132   3: 0.158044262189748   9: 0.110845556920492   1: 0.014183388817563   0: 0.014160559811938   5: 0.014152340510527   8: 0.014149912566049   4: 0.014149126263260   7: 0.014149056472360   2: 0.014149037695931 

test_19042        5: 0.609996680099917   6: 0.254219468644445   9: 0.017101338990797   4: 0.016987691130173   1: 0.016952287694331   0: 0.016951986670221   8: 0.016948363855195   7: 0.016947717907568   2: 0.016947296178780   3: 0.016947168828572 

test_19044        6: 0.833550072666511   5: 0.018497400030902   9: 0.018494502621671   8: 0.018494373533530   0: 0.018494191836603   4: 0.018494099287410   7: 0.018494095963252   1: 0.018493975100025   2: 0.018493664200659   3: 0.018493624759437 

test_19045        5: 0.754708976959544   1: 0.027275316624105   6: 0.027269154834440   9: 0.027253025097918   2: 0.027252147559156   7: 0.027250290976809   8: 0.027248391109294   0: 0.027248092807070   4: 0.027247732968183   3: 0.027246871063480 

test_19048        0: 0.395897736995335   4: 0.343390439146143   1: 0.032600871449744   5: 0.032600118018140   6: 0.032586535482419   2: 0.032585253285925   7: 0.032584830773873   8: 0.032584799129256   9: 0.032584787386859   3: 0.032584628332307 

test_19050        0: 0.852547759838839   5: 0.027743285787143   1: 0.014995531986929   6: 0.014985059135402   4: 0.014959215018922   9: 0.014955323082891   8: 0.014954661080784   3: 0.014953273894883   7: 0.014952972968854   2: 0.014952917205353 

test_19053        5: 0.805618075300762   6: 0.021621467086071   9: 0.021617755694683   1: 0.021597040141172   4: 0.021593140921403   7: 0.021591627587278   8: 0.021591296298978   3: 0.021589996348229   2: 0.021589979564842   0: 0.021589621056583 

test_19055        6: 0.464394320054556   8: 0.387255382600563   9: 0.036800735013530   5: 0.015943509223663   0: 0.015940328848205   1: 0.015940100463381   3: 0.015933818655406   7: 0.015930947160767   4: 0.015930441534220   2: 0.015930416445709 

test_19057        6: 0.674437889516499   5: 0.154621448139563   8: 0.046547104862955   0: 0.017774915464991   1: 0.017771261777664   2: 0.017769827063020   7: 0.017769711626513   9: 0.017769419933094   4: 0.017769234643475   3: 0.017769186972225 

test_19059        6: 0.746189718972100   3: 0.069164566224305   0: 0.061287159905508   8: 0.017631253849541   9: 0.017622416296923   1: 0.017621548488533   5: 0.017621414717550   2: 0.017620914038728   7: 0.017620855262763   4: 0.017620152244049 

test_19061        6: 0.515462593721476   0: 0.343742524511643   3: 0.030060270989629   1: 0.028199084200454   5: 0.013756814719371   9: 0.013756112257838   7: 0.013755769479358   8: 0.013755750266588   4: 0.013755550226040   2: 0.013755529627602 

test_19062        6: 0.625447171828888   0: 0.151550232795007   8: 0.110873822181206   3: 0.016023963461561   5: 0.016018547728613   9: 0.016017820778892   7: 0.016017702553961   1: 0.016017153891845   4: 0.016016904923858   2: 0.016016679856171 

test_19065        6: 0.549563676193745   7: 0.172345211837705   3: 0.164068482014223   0: 0.032413970254352   5: 0.013659377851237   9: 0.013646139284335   8: 0.013582528262155   1: 0.013576640301711   2: 0.013572210692464   4: 0.013571763308073 

test_19069        6: 0.523999682075900   7: 0.211908500196354   1: 0.101908504089332   0: 0.045620409513054   2: 0.041363783929522   5: 0.015063847403995   8: 0.015042737374923   9: 0.015031372136413   3: 0.015030667295624   4: 0.015030495984885 

test_19073        1: 0.539848648731617   6: 0.322492525521313   2: 0.017256072812030   5: 0.017205028801056   0: 0.017201264917908   4: 0.017200844696030   7: 0.017199609960699   9: 0.017199066603428   8: 0.017198900293740   3: 0.017198037662179 

test_19075        6: 0.692032613054539   5: 0.175634632192069   0: 0.046027671945260   9: 0.012332515549429   1: 0.012329172333364   8: 0.012329046016155   4: 0.012328795837730   7: 0.012328732996652   2: 0.012328430722766   3: 0.012328389352036 

test_19077        6: 0.724249192410741   7: 0.085681417472886   8: 0.067691195293530   5: 0.017486974677621   3: 0.017485917970121   9: 0.017482326952269   0: 0.017481281117376   1: 0.017480765567538   4: 0.017480500483268   2: 0.017480428054649 

test_19079        6: 0.731862697038412   9: 0.029794764283669   0: 0.029793334203520   1: 0.029793245629929   7: 0.029793069748067   8: 0.029793019526572   5: 0.029792813226098   2: 0.029792573839379   3: 0.029792432346013   4: 0.029792050158341 

test_19081        6: 0.776303443202886   5: 0.024859909754079   9: 0.024856332959478   0: 0.024854878489964   3: 0.024854552741247   1: 0.024854512947462   8: 0.024854500203409   7: 0.024854372262604   2: 0.024853939977514   4: 0.024853557461357 

test_19082        6: 0.796263576171914   2: 0.058268969092666   0: 0.018289160668550   1: 0.018257614904174   5: 0.018155369132711   8: 0.018153933641930   9: 0.018153475422858   7: 0.018152940131171   3: 0.018152795032366   4: 0.018152165801661 

test_19083        9: 0.453340417224921   6: 0.412792944028906   0: 0.031116039160528   1: 0.014735401277286   7: 0.014727140166102   5: 0.014682310291232   3: 0.014653294566925   2: 0.014652202213871   8: 0.014650696456799   4: 0.014649554613430 

test_19087        0: 0.863032478731799   1: 0.031088166270351   9: 0.013257609673499   6: 0.013239939158237   8: 0.013237468137189   5: 0.013231521253126   4: 0.013228785215219   3: 0.013228638642305   2: 0.013227739994997   7: 0.013227652923278 

test_19088        6: 0.537370426517455   7: 0.210063958385908   2: 0.120343408214283   5: 0.018889917494998   0: 0.018889476241385   1: 0.018889083613934   8: 0.018889064660804   4: 0.018888524589756   9: 0.018888494121149   3: 0.018887646160329 

test_19092        6: 0.865986956048388   5: 0.014891046424826   0: 0.014890414938216   1: 0.014890410553500   9: 0.014890308840205   8: 0.014890264651239   2: 0.014890256742821   3: 0.014890215626272   7: 0.014890172832822   4: 0.014889953341711 

test_19097        6: 0.601188503981691   3: 0.267406696095575   1: 0.016439737681649   5: 0.016428101031580   0: 0.016426025258639   8: 0.016422526534472   7: 0.016422448795565   4: 0.016422003442312   2: 0.016421999203496   9: 0.016421957975022 

test_19101        6: 0.467341862112568   5: 0.255399702285964   0: 0.108533376675316   3: 0.064793653118819   7: 0.029996088939812   9: 0.014790671462199   1: 0.014788774875314   8: 0.014785618652617   4: 0.014785153397315   2: 0.014785098480076 

test_19110        6: 0.594954054911479   9: 0.307937390873155   1: 0.012420989800318   0: 0.012141270452488   3: 0.012091438941483   2: 0.012091390006427   5: 0.012091319745608   8: 0.012090798066532   7: 0.012090759509754   4: 0.012090587692757 

test_19113        0: 0.820821917702365   9: 0.019958758836711   8: 0.019912258031117   1: 0.019907803231976   6: 0.019905625299609   5: 0.019904097496597   4: 0.019899004483778   2: 0.019897147204536   3: 0.019896699719367   7: 0.019896687993945 

test_19118        8: 0.392910806931284   3: 0.351053877304256   1: 0.032018170274719   0: 0.032010263209753   5: 0.032008966980005   6: 0.032008151026797   4: 0.032001561970133   2: 0.031997590736303   9: 0.031996130556398   7: 0.031994481010352 

test_19121        6: 0.755877960122149   9: 0.027130617562984   8: 0.027129166462734   0: 0.027125019523448   7: 0.027123692931936   1: 0.027123673039342   4: 0.027122637062051   2: 0.027122540505750   5: 0.027122434517279   3: 0.027122258272325 

test_19122        6: 0.560944453643582   2: 0.284971796978651   5: 0.019313386419890   7: 0.019286774502705   8: 0.019249823333797   9: 0.019249670669362   3: 0.019246878662532   0: 0.019246366346269   1: 0.019246191557348   4: 0.019244657885864 

test_19127        1: 0.512572416355566   3: 0.293537289759572   6: 0.072831604748295   8: 0.017309978638253   5: 0.017300139747903   0: 0.017294507119230   7: 0.017290045088869   4: 0.017289025505138   9: 0.017288479199653   2: 0.017286513837520 

test_19128        6: 0.642240033229678   0: 0.257460374380077   1: 0.012559386272047   9: 0.012538780679530   5: 0.012534104847833   2: 0.012533731511069   3: 0.012533534715094   4: 0.012533512435557   8: 0.012533311545453   7: 0.012533230383662 

test_19136        8: 0.325516029973505   0: 0.297203832856427   1: 0.257279408033258   6: 0.017189369481115   5: 0.017162104785568   9: 0.017152814940900   4: 0.017127925717266   2: 0.017124971342592   7: 0.017123051388550   3: 0.017120491480818 

test_19137        8: 0.417932957290621   6: 0.392851469466771   5: 0.023663676535802   1: 0.023657862346406   0: 0.023654967525527   4: 0.023653522363975   2: 0.023647080423491   7: 0.023647057854342   9: 0.023645995497306   3: 0.023645410695760 

test_19142        4: 0.688680271226158   9: 0.113418095089379   5: 0.024748891055104   6: 0.024736530594071   3: 0.024736525830329   8: 0.024736438251420   1: 0.024736093361828   0: 0.024736021124042   2: 0.024735580163679   7: 0.024735553303990 

test_19152        0: 0.603758223757592   6: 0.208075984601991   4: 0.023591866608710   8: 0.023528722867633   5: 0.023514768757786   2: 0.023509879864764   9: 0.023508602510099   1: 0.023506343650063   3: 0.023502821769556   7: 0.023502785611807 

test_19155        9: 0.423924584928867   5: 0.368014417183479   6: 0.086817750032692   1: 0.017360979257387   0: 0.017320618119088   3: 0.017315349750232   7: 0.017312260230619   8: 0.017311550958696   4: 0.017311518146819   2: 0.017310971392121 

test_19159        4: 0.636543527799491   6: 0.165722733891087   7: 0.048154186998912   0: 0.021377202321175   1: 0.021374333192551   9: 0.021373313341972   5: 0.021371191373278   2: 0.021361426079477   8: 0.021361173174798   3: 0.021360911827259 

test_19163        6: 0.697022520916830   9: 0.177764752818454   0: 0.015656339688654   4: 0.015655585331428   8: 0.015652037133292   1: 0.015651695974845   5: 0.015649509367766   2: 0.015649243302921   3: 0.015649173071810   7: 0.015649142394001 

test_19165        6: 0.644996462945251   0: 0.195297426760989   8: 0.073949313261279   1: 0.012251887738599   9: 0.012251119836437   5: 0.012250837278156   7: 0.012250837066705   3: 0.012250737709714   2: 0.012250697322339   4: 0.012250680080529 

test_19167        6: 0.668561433985737   5: 0.189313752279661   1: 0.061624341809658   9: 0.011524027877844   0: 0.011508644688964   8: 0.011494139736081   7: 0.011493557784697   3: 0.011493390230587   2: 0.011493355856206   4: 0.011493355750565 

test_19169        6: 0.873909102693652   8: 0.014011232920013   0: 0.014010810826425   1: 0.014010553220566   7: 0.014010094089425   9: 0.014009767951551   2: 0.014009670710133   5: 0.014009642261746   4: 0.014009616581858   3: 0.014009508744631 

test_19170        5: 0.782666086222493   4: 0.024152188011757   6: 0.024148152967130   0: 0.024148106632866   1: 0.024147905283428   8: 0.024147849843778   3: 0.024147523649937   7: 0.024147490655402   2: 0.024147373788012   9: 0.024147322945195 

test_19171        5: 0.782666163277412   4: 0.024152111315129   6: 0.024148152898861   0: 0.024148106567112   1: 0.024147905228545   8: 0.024147849791898   3: 0.024147523615488   7: 0.024147490622690   2: 0.024147373761506   9: 0.024147322921359 

test_19174        5: 0.441890016890575   2: 0.359085773052902   4: 0.024881000575345   6: 0.024878866429915   9: 0.024877823788446   8: 0.024877817861124   7: 0.024877398471663   1: 0.024877246495934   0: 0.024877224696239   3: 0.024876831737857 

test_19178        5: 0.564818690017622   1: 0.275108753024677   4: 0.020014403290131   8: 0.020008925548616   0: 0.020008674475873   6: 0.020008479768621   7: 0.020008109562566   3: 0.020008008653702   9: 0.020008007753800   2: 0.020007947904394 

test_19180        5: 0.814532980902511   0: 0.020616295099070   6: 0.020614032885970   1: 0.020610320129030   8: 0.020605926802754   9: 0.020604912299141   4: 0.020604192496748   7: 0.020604059575688   2: 0.020603802163974   3: 0.020603477645115 

test_19181        1: 0.784110167626298   0: 0.085008331600342   3: 0.016368801079958   8: 0.016365311596847   6: 0.016360956795349   5: 0.016360003651955   4: 0.016357113378329   7: 0.016357028118105   9: 0.016356317342223   2: 0.016355968810594 

test_19182        2: 0.583469429170481   1: 0.209662139414571   6: 0.025865663485373   9: 0.025859032719240   5: 0.025858702279316   7: 0.025857636407006   8: 0.025857378698724   3: 0.025857358661953   0: 0.025856829307955   4: 0.025855829855382 

test_19191        6: 0.514061374430500   1: 0.354578172315853   0: 0.034891092601350   8: 0.021560301611090   5: 0.013051474981261   4: 0.012568830555870   9: 0.012468486826574   2: 0.012278647687453   7: 0.012271368655772   3: 0.012270250334277 

test_19193        2: 0.324320749202612   6: 0.299866830422671   1: 0.189571977657815   3: 0.067161929200367   5: 0.019852275407980   4: 0.019846042595798   9: 0.019845814538962   0: 0.019844804628293   8: 0.019844793396731   7: 0.019844782948770 

test_19198        6: 0.693431020010538   3: 0.144566783395675   5: 0.020254758821968   8: 0.020251338603417   0: 0.020250990536543   9: 0.020249965797157   1: 0.020249663827938   4: 0.020248909474935   7: 0.020248579563213   2: 0.020247989968618 

test_19199        6: 0.446345352016353   1: 0.416824113534403   8: 0.029404689587831   3: 0.015389756807854   0: 0.015339774349343   9: 0.015339575361994   7: 0.015339492487463   5: 0.015339193430355   2: 0.015339119122111   4: 0.015338933302293 

test_19201        8: 0.513377502609382   6: 0.316952380051858   7: 0.042761502013612   9: 0.037765859291525   0: 0.014867359360818   1: 0.014856963870085   5: 0.014856555876077   4: 0.014854286041824   2: 0.014853864185519   3: 0.014853726699301 

test_19202        3: 0.420194529524671   6: 0.349509166528172   5: 0.028793034819509   1: 0.028791381396012   0: 0.028791036445341   4: 0.028785967775428   2: 0.028784174676384   9: 0.028784012752383   8: 0.028783803155761   7: 0.028782892926338 

test_19208        3: 0.585623190018081   6: 0.264252187790174   8: 0.018821958124817   0: 0.018792731049984   1: 0.018774072349349   4: 0.018753485332061   9: 0.018753349085013   5: 0.018752687226921   7: 0.018738847537504   2: 0.018737491486095 

test_19213        6: 0.616585518790545   7: 0.216812874420572   5: 0.020826944021898   0: 0.020825851469084   1: 0.020825230265405   4: 0.020825204743062   8: 0.020824878156227   9: 0.020824831358899   2: 0.020824353736077   3: 0.020824313038230 

test_19223        7: 0.443301606830160   6: 0.226053280655610   1: 0.188280145230546   4: 0.030981614200073   9: 0.026857996315719   2: 0.016921290476727   0: 0.016904807355180   5: 0.016902344360356   8: 0.016899010970509   3: 0.016897903605120 

test_19229        8: 0.481324609373836   7: 0.253067085315959   5: 0.033205818397268   0: 0.033201445232502   6: 0.033201089780014   1: 0.033201031543367   9: 0.033200586186428   3: 0.033200352531040   4: 0.033199339210836   2: 0.033198642428750 

test_19237        8: 0.648380635238040   7: 0.198820760018462   6: 0.019115173641844   0: 0.019109622733942   1: 0.019105982605451   5: 0.019097485886042   9: 0.019093698913047   2: 0.019092404130916   3: 0.019092239589332   4: 0.019091997242924 

test_19238        6: 0.867050454985197   8: 0.014781888192217   1: 0.014773521072613   2: 0.014770985641998   0: 0.014770775879708   7: 0.014770660270076   9: 0.014770594225008   3: 0.014770488767234   5: 0.014770402972721   4: 0.014770227993229 

test_19240        0: 0.720597505242533   1: 0.031058140510070   6: 0.031049505548888   5: 0.031045571784411   2: 0.031042489389620   4: 0.031041872174925   7: 0.031041424884055   8: 0.031041267202454   9: 0.031041203992243   3: 0.031041019270800 

test_19241        0: 0.590333693048103   1: 0.224967046326856   8: 0.049919694757896   6: 0.044951025057378   9: 0.019062850431554   5: 0.014157408473544   7: 0.014152831093223   4: 0.014152488787299   3: 0.014151577801181   2: 0.014151384222966 

test_19254        5: 0.697091743434267   6: 0.125466649046520   9: 0.022190673023672   8: 0.022181748610761   4: 0.022181547161956   0: 0.022178122681153   1: 0.022177536662266   3: 0.022177346710624   2: 0.022177328787185   7: 0.022177303881595 

test_19255        1: 0.510052008351547   6: 0.247758632563051   0: 0.126960658213791   3: 0.028697962845283   5: 0.014423712162458   9: 0.014422529076674   8: 0.014421467282421   2: 0.014421062827387   7: 0.014421057101627   4: 0.014420909575759 

test_19256        0: 0.821734218825260   7: 0.019812199573250   5: 0.019812183216486   4: 0.019811194445699   1: 0.019807336923986   6: 0.019806663113910   3: 0.019804645378994   8: 0.019804304517645   2: 0.019803651544325   9: 0.019803602460445 

test_19258        6: 0.395530038331715   5: 0.352338568167768   3: 0.088294293378426   1: 0.023410413930385   0: 0.023407241729062   4: 0.023405620503867   2: 0.023403953044180   7: 0.023403326068528   8: 0.023403288931548   9: 0.023403255914520 

test_19262        6: 0.446899203141514   0: 0.438832817635877   5: 0.014321200646416   2: 0.014294779576384   1: 0.014279420855169   7: 0.014275055081723   9: 0.014275035296207   3: 0.014274482829942   8: 0.014274046279778   4: 0.014273958656990 

test_19263        5: 0.314447997685514   6: 0.270107700354260   0: 0.193232426279603   1: 0.125356785344928   9: 0.016143389051831   2: 0.016143014310722   8: 0.016142594987671   7: 0.016142225570605   3: 0.016141980757462   4: 0.016141885657405 

test_19267        5: 0.708907906505136   6: 0.098035306184548   4: 0.024139822219863   8: 0.024131460637704   0: 0.024131058390673   2: 0.024130988170301   1: 0.024130912230216   3: 0.024130882109041   9: 0.024130843879202   7: 0.024130819673317 

test_19269        0: 0.477316587719233   6: 0.379035862023831   1: 0.017957373360877   5: 0.017956441423390   9: 0.017955794102523   4: 0.017955777145354   8: 0.017955684628768   7: 0.017955588659035   2: 0.017955482227261   3: 0.017955408709727 

test_19270        1: 0.487162127145093   8: 0.280833031217362   0: 0.072913647076961   9: 0.022830787773815   5: 0.022719249266152   6: 0.022710667785396   3: 0.022708479495142   4: 0.022708168065269   2: 0.022707287127204   7: 0.022706555047607 

test_19271        5: 0.731130674577148   6: 0.103253999201018   0: 0.020704944361889   1: 0.020703665712696   2: 0.020701610799501   4: 0.020701573910774   8: 0.020701003385067   7: 0.020700897430115   9: 0.020700883804765   3: 0.020700746817026 

test_19272        6: 0.339650122521580   0: 0.202867288719419   3: 0.164371796448982   5: 0.143503887129103   1: 0.043107764079135   8: 0.040152550742024   2: 0.016591755879535   9: 0.016586545213614   4: 0.016584533337197   7: 0.016583755929411 

test_19273        6: 0.468079025163914   4: 0.362430901457908   1: 0.065902081662290   9: 0.025752193224800   7: 0.012983038403118   0: 0.012976052810506   5: 0.012975924224527   8: 0.012967874362573   3: 0.012966811796120   2: 0.012966096894244 

test_19275        0: 0.591974857058831   6: 0.292499590403029   7: 0.014449874267859   1: 0.014439947330446   8: 0.014439738568042   4: 0.014439383043524   9: 0.014439260495978   5: 0.014439234534007   2: 0.014439075205435   3: 0.014439039092848 

test_19277        6: 0.476534688452251   7: 0.253915516147615   3: 0.109755851394545   5: 0.022847577800661   1: 0.022826063016187   8: 0.022825159554727   2: 0.022824223463928   0: 0.022824030348566   9: 0.022823652619409   4: 0.022823237202111 

test_19280        1: 0.833277996124082   5: 0.018539048114240   6: 0.018527788110451   7: 0.018526306641727   0: 0.018525123520207   2: 0.018524867620390   4: 0.018520396945372   3: 0.018519850988777   9: 0.018519431479582   8: 0.018519190455172 

test_19281        5: 0.515428191121703   8: 0.242480552796659   1: 0.030271115652298   0: 0.030263919003674   6: 0.030263506419767   4: 0.030262532860957   9: 0.030258225819959   3: 0.030257646247184   2: 0.030257485250312   7: 0.030256824827487 

test_19283        0: 0.704991792363871   1: 0.106529057218583   6: 0.071719773103209   2: 0.016685929418363   5: 0.016681534865271   4: 0.016679885007594   9: 0.016678121384822   7: 0.016678023830417   8: 0.016677986160359   3: 0.016677896647511 

test_19284        8: 0.767262956369750   6: 0.025869998174745   9: 0.025863177037197   7: 0.025859773451042   5: 0.025859172053378   1: 0.025858802667809   0: 0.025856849084364   2: 0.025856568751337   4: 0.025856516105727   3: 0.025856186304650 

test_19285        6: 0.700163251086986   9: 0.141264256171935   0: 0.073111318355289   1: 0.031973137938234   7: 0.009736704873319   3: 0.008911647653789   5: 0.008712760863464   2: 0.008709155455236   4: 0.008708988476272   8: 0.008708779125476 

test_19286        4: 0.421189170129762   6: 0.386759564053774   1: 0.062965984983342   7: 0.018702228004104   8: 0.018470194738831   0: 0.018462711184838   9: 0.018436820930724   5: 0.018339090223978   2: 0.018337164651860   3: 0.018337071098787 

test_19290        0: 0.843904133706349   9: 0.017354183308461   6: 0.017350085174918   8: 0.017346600502531   1: 0.017342564182917   7: 0.017342131068722   5: 0.017340839853175   4: 0.017340376250190   3: 0.017340239712370   2: 0.017338846240368 

test_19291        2: 0.395665345146443   6: 0.311312227530966   0: 0.181832282481554   5: 0.015887133278969   4: 0.015885883106432   1: 0.015884214039864   9: 0.015883578106363   8: 0.015883480847044   7: 0.015883354290973   3: 0.015882501171391 

test_19293        6: 0.833473547381467   1: 0.018639405948611   8: 0.018506354012481   5: 0.018485074471057   0: 0.018483726340034   9: 0.018483095827621   7: 0.018482295253790   4: 0.018482253697481   3: 0.018482177301574   2: 0.018482069765886 

test_19294        6: 0.870336351565581   5: 0.014411943697364   4: 0.014408336835992   8: 0.014408328561963   9: 0.014407924729051   1: 0.014406547370587   0: 0.014406241873553   7: 0.014405096793177   2: 0.014404739885238   3: 0.014404488687494 

test_19295        6: 0.856321178044219   5: 0.037037906203624   4: 0.013331030727779   7: 0.013330851648978   0: 0.013330489421874   1: 0.013330008433483   8: 0.013329963057292   9: 0.013329730276695   3: 0.013329473856103   2: 0.013329368329953 

test_19297        1: 0.810464209232145   5: 0.021066351808490   6: 0.021064258221594   0: 0.021062575064399   4: 0.021060387309094   7: 0.021056954749704   2: 0.021056658697271   9: 0.021056565922796   8: 0.021056136712966   3: 0.021055902281541 

test_19304        5: 0.667388741176788   2: 0.131546000529906   4: 0.025142080483741   8: 0.025132350304374   1: 0.025132011355357   9: 0.025131963062562   0: 0.025131919597682   6: 0.025131706210711   3: 0.025131685710678   7: 0.025131541568200 

test_19307        0: 0.816048611947828   5: 0.020446791940477   6: 0.020444716421031   8: 0.020439682184453   4: 0.020438492712363   1: 0.020438263921485   2: 0.020436637568750   9: 0.020436586708646   7: 0.020435136501229   3: 0.020435080093738 

test_19308        5: 0.485940806295095   8: 0.301487149670060   0: 0.026576670276999   4: 0.026574360348117   1: 0.026570316761694   2: 0.026570227353468   6: 0.026570199916215   3: 0.026570198031052   7: 0.026570081064505   9: 0.026569990282794 

test_19312        6: 0.415054262835710   5: 0.293913849182308   8: 0.140843383082378   1: 0.021460086788508   0: 0.021456075850557   2: 0.021455530853292   4: 0.021454888963198   7: 0.021454290517023   9: 0.021454039061052   3: 0.021453592865974 

test_19318        6: 0.546358343047493   3: 0.182571451334083   1: 0.160008437134472   8: 0.026494747121403   7: 0.018481834995390   0: 0.013501346307835   5: 0.013146430652366   9: 0.013145905410995   2: 0.013145874060329   4: 0.013145629935634 

test_19322        6: 0.623901007740390   0: 0.227584833062188   7: 0.018565636696993   5: 0.018565371792495   1: 0.018564502183929   8: 0.018564219555567   4: 0.018563651270101   9: 0.018563630076343   2: 0.018563585695640   3: 0.018563561926353 

test_19325        1: 0.714690426596331   8: 0.160203111518964   0: 0.015645444026651   5: 0.015645297060963   6: 0.015638510900068   4: 0.015636606931671   9: 0.015635295732310   3: 0.015635182868563   2: 0.015635163168500   7: 0.015634961195979 

test_19327        2: 0.418064642544759   6: 0.355075881779042   1: 0.028365275912139   0: 0.028361596422827   5: 0.028357632329002   9: 0.028355798732418   4: 0.028354959111069   7: 0.028354934413502   8: 0.028354816882940   3: 0.028354461872302 

test_19329        0: 0.569663622904725   9: 0.242057443797773   5: 0.023541003874586   6: 0.023537979870087   7: 0.023535769374668   2: 0.023534826470265   1: 0.023533452589032   8: 0.023532243656932   4: 0.023532043533765   3: 0.023531613928167 

test_19331        3: 0.464399980125169   6: 0.361750861568234   0: 0.021736161841986   1: 0.021734961714911   5: 0.021734568866188   4: 0.021730078005164   2: 0.021729190714175   9: 0.021728116829280   7: 0.021728099234458   8: 0.021727981100435 

test_19334        6: 0.469927190688652   2: 0.387774216294749   8: 0.017869339640543   0: 0.017791517856302   5: 0.017775631262472   1: 0.017774815304162   9: 0.017773701364105   7: 0.017772995787074   4: 0.017771910854044   3: 0.017768680947897 

test_19341        2: 0.500925554731132   1: 0.351747822908660   0: 0.018443683914496   6: 0.018438613628914   3: 0.018412641971954   5: 0.018409183175051   9: 0.018407890135172   7: 0.018405111601189   4: 0.018404767872638   8: 0.018404730060795 

test_19343        4: 0.505116687375199   1: 0.343539274100709   6: 0.018927921110082   0: 0.018924720583416   5: 0.018922391481585   9: 0.018915371886971   8: 0.018915034409522   7: 0.018913104977541   2: 0.018912799917958   3: 0.018912694157016 

test_19344        6: 0.787927860831125   5: 0.052600073447400   0: 0.019941213086490   1: 0.019937693479129   8: 0.019934961337836   9: 0.019933425148229   4: 0.019932613866893   2: 0.019931396075259   3: 0.019930639411099   7: 0.019930123316540 

test_19351        1: 0.498929706916659   0: 0.370718245965409   6: 0.016298201945486   5: 0.016295397425655   9: 0.016293772535797   8: 0.016293572026378   4: 0.016293240590335   7: 0.016292669887444   2: 0.016292606821734   3: 0.016292585885102 

test_19352        1: 0.500822433736759   4: 0.264674608912120   2: 0.029327203388185   0: 0.029314185469085   6: 0.029313775188642   5: 0.029311550365079   9: 0.029309423353720   7: 0.029309133430005   3: 0.029308905681385   8: 0.029308780475019 

test_19356        0: 0.482753625983781   1: 0.249631406305252   6: 0.033456662643342   9: 0.033451934024583   8: 0.033451306227882   5: 0.033451301849486   7: 0.033451133923116   2: 0.033451058710222   3: 0.033450826380778   4: 0.033450743951558 

test_19357        4: 0.801720821480855   6: 0.022051115494711   5: 0.022046151332556   0: 0.022026183136957   8: 0.022026056905316   3: 0.022026030708443   9: 0.022025968392901   2: 0.022025960777746   1: 0.022025857774682   7: 0.022025853995834 

test_19358        6: 0.773906623621420   8: 0.025127267755926   5: 0.025123937787381   1: 0.025123134690700   0: 0.025121546360952   7: 0.025119940742785   3: 0.025119521454869   9: 0.025119391133540   2: 0.025119373402492   4: 0.025119263049936 

test_19359        6: 0.448283926759914   3: 0.305933881354255   4: 0.084872828250067   0: 0.022991124286399   1: 0.022991004637361   5: 0.022988306824480   9: 0.022987982473583   2: 0.022984951019537   8: 0.022983073929415   7: 0.022982920464989 

test_19360        2: 0.521672295941412   1: 0.321584323901064   0: 0.019656400719522   4: 0.019603392650194   5: 0.019593449405291   6: 0.019584287195824   9: 0.019580625030307   8: 0.019575107086904   7: 0.019575092250494   3: 0.019575025818988 

test_19364        6: 0.544315238075062   1: 0.303269034280542   0: 0.019076461646717   5: 0.019049652714173   2: 0.019048378930098   8: 0.019048364512502   4: 0.019048291561230   7: 0.019048268497228   9: 0.019048245394322   3: 0.019048064388125 

test_19365        4: 0.737941722746678   5: 0.029134181836333   3: 0.029116204642285   1: 0.029116045273573   6: 0.029115966125083   8: 0.029115791290872   9: 0.029115655530378   0: 0.029115397549470   7: 0.029114584807908   2: 0.029114450197420 

test_19367        6: 0.887128754335972   7: 0.019855885141332   9: 0.016873907717521   0: 0.011036583420128   4: 0.010921388666557   5: 0.010888270757070   3: 0.010866451918373   8: 0.010816595561734   1: 0.010810338920942   2: 0.010801823560370 

test_19368        5: 0.680749221933207   6: 0.147397987271931   9: 0.021490328881590   1: 0.021488175417247   0: 0.021482597370581   8: 0.021479056196681   2: 0.021478857458919   7: 0.021478276981145   4: 0.021477984615374   3: 0.021477513873325 

test_19369        5: 0.665154832110489   0: 0.142903599075740   4: 0.023997007268506   3: 0.023994027927411   6: 0.023991881666687   8: 0.023991812227212   2: 0.023991733761367   7: 0.023991729009035   1: 0.023991707833956   9: 0.023991669119597 

test_19371        6: 0.449060813536367   4: 0.311767773225594   7: 0.102602514441624   1: 0.035362413403405   0: 0.017087435618065   2: 0.016833183866038   5: 0.016831217214552   8: 0.016818558637765   9: 0.016818393865426   3: 0.016817696191164 

test_19373        6: 0.527430688436576   7: 0.360087845366146   5: 0.014106167516261   1: 0.014080800891192   0: 0.014054599567703   8: 0.014051528791564   9: 0.014047500606109   3: 0.014047267428214   2: 0.014046882829456   4: 0.014046718566778 

test_19374        5: 0.651803823441829   2: 0.148293202019057   1: 0.025089449894237   4: 0.024980116091107   6: 0.024974912177843   8: 0.024971964776563   3: 0.024971711167999   0: 0.024971686107497   9: 0.024971616995269   7: 0.024971517328598 

test_19375        5: 0.698585903254091   0: 0.124889372095903   4: 0.022074023975376   1: 0.022064644237338   6: 0.022064452355452   8: 0.022064377898720   9: 0.022064348652334   2: 0.022064345339298   3: 0.022064317992461   7: 0.022064214199026 

test_19377        6: 0.644426729595601   0: 0.262517591926408   8: 0.011634698696577   1: 0.011633370985332   5: 0.011631621107738   9: 0.011631531058342   7: 0.011631148905938   4: 0.011631148563777   3: 0.011631094041222   2: 0.011631065119065 

test_19378        0: 0.837779695189014   6: 0.047211335601692   1: 0.014379288119512   9: 0.014377906001747   7: 0.014377045176382   5: 0.014376928017186   8: 0.014375353120204   4: 0.014374484951834   2: 0.014374034291124   3: 0.014373929531305 

test_19379        7: 0.389709081702380   5: 0.388080168453439   0: 0.072907641262776   6: 0.021348767240181   1: 0.021342922704152   4: 0.021325323782202   9: 0.021324730356003   2: 0.021320761078153   8: 0.021320422060592   3: 0.021320181360122 

test_19380        0: 0.788416801297188   3: 0.045561869875418   5: 0.020781484114696   4: 0.020763541844293   6: 0.020757578209832   1: 0.020752137369375   9: 0.020749437838413   7: 0.020745311097319   8: 0.020737541018457   2: 0.020734297335009 

test_19381        6: 0.539614458796350   9: 0.309514041537295   0: 0.018874703351939   1: 0.018868241337545   5: 0.018863548646644   4: 0.018854849902564   7: 0.018854281414093   2: 0.018852611189460   8: 0.018852039951380   3: 0.018851223872729 

test_19383        2: 0.508801430400856   1: 0.321439170062937   7: 0.021385148914044   0: 0.021199160762462   5: 0.021198813418161   6: 0.021198141994331   4: 0.021196184296654   9: 0.021194499611461   8: 0.021193952900292   3: 0.021193497638801 

test_19386        6: 0.417806212744666   2: 0.385128005893152   0: 0.041931711935418   1: 0.022288174181545   7: 0.022151368266745   9: 0.022143697828034   5: 0.022142187508648   8: 0.022137741609513   4: 0.022135649379806   3: 0.022135250652473 

test_19387        6: 0.575469360599955   8: 0.273581188447192   1: 0.062739554694450   3: 0.012608698865524   0: 0.012603266208621   9: 0.012599780954585   7: 0.012599677372477   5: 0.012599527702925   2: 0.012599522390548   4: 0.012599422763722 

test_19388        6: 0.567566383184962   1: 0.238228888453427   3: 0.065204522120202   5: 0.018431039100137   0: 0.018430330907023   4: 0.018429298805407   8: 0.018427889480718   9: 0.018427442448928   2: 0.018427120643848   7: 0.018427084855347 

test_19397        6: 0.426494754609208   7: 0.237745748388065   1: 0.186144548108664   9: 0.068930125912148   0: 0.013448830580240   5: 0.013448201302745   4: 0.013447397624744   8: 0.013447097237141   2: 0.013446843513366   3: 0.013446452723678 

test_19403        6: 0.564741849769255   3: 0.290734348406312   1: 0.058361348155286   7: 0.019522203360792   8: 0.011351878997372   0: 0.011074646435681   9: 0.011058140696334   5: 0.011052488018471   2: 0.011051739695587   4: 0.011051356464911 

test_19406        0: 0.725389111525805   7: 0.030514402674442   6: 0.030513421178237   5: 0.030513372571984   1: 0.030512893338320   2: 0.030512799841092   4: 0.030511265666691   8: 0.030511031621901   9: 0.030510880551573   3: 0.030510821029955 

test_19409        4: 0.505378866160862   6: 0.339322551083986   5: 0.043281862372551   9: 0.016150843655108   3: 0.016137260431372   0: 0.016024498608754   2: 0.015985364775966   8: 0.015912131575093   1: 0.015904220989594   7: 0.015902400346712 

test_19410        5: 0.582630380431565   1: 0.202687840877891   4: 0.026844405503137   0: 0.026834209164540   8: 0.026833999469974   6: 0.026833888526008   3: 0.026833868626443   2: 0.026833844298274   9: 0.026833790360942   7: 0.026833772741226 

test_19411        0: 0.697846151720428   1: 0.194188418877136   2: 0.013662391111219   6: 0.013575590876417   8: 0.013455876889486   5: 0.013454992665582   7: 0.013454534091629   9: 0.013454156471491   4: 0.013454104969637   3: 0.013453782326976 

test_19412        5: 0.472161527079873   6: 0.314289127491174   9: 0.060140954307740   1: 0.046578252858569   0: 0.017816381274786   8: 0.017804216800838   4: 0.017802990615393   2: 0.017802282870410   7: 0.017802169630607   3: 0.017802097070608 

test_19416        8: 0.761268521200777   5: 0.026540888714940   6: 0.026530392253978   0: 0.026524563058278   1: 0.026523964634674   4: 0.026523655585572   9: 0.026522397676312   3: 0.026522253846184   7: 0.026522232795308   2: 0.026521130233977 

test_19418        5: 0.649447055246147   6: 0.183313938294327   8: 0.020932360482508   0: 0.020904469547215   9: 0.020901706538063   7: 0.020901211377356   1: 0.020900987223108   4: 0.020899944000550   2: 0.020899897681020   3: 0.020898429609708 

test_19419        2: 0.315543756562947   1: 0.294152706481694   5: 0.152227709510367   6: 0.145943872625266   4: 0.015378910541052   0: 0.015353061169562   3: 0.015351206477597   8: 0.015350698350119   9: 0.015349315356700   7: 0.015348762924697 

test_19420        4: 0.471246257552693   1: 0.238328150440720   0: 0.127509860778421   6: 0.023281955519951   2: 0.023275952993513   5: 0.023273075523492   9: 0.023272500975055   8: 0.023270884934218   3: 0.023270736317748   7: 0.023270624964190 

test_19422        5: 0.568008764645615   3: 0.227401509398496   4: 0.025578493204835   6: 0.025573772759987   0: 0.025573330670460   1: 0.025573104233595   8: 0.025572931944789   9: 0.025572808396746   2: 0.025572654175623   7: 0.025572630569854 

test_19424        5: 0.603060054689571   4: 0.214378237057634   7: 0.022831365463635   0: 0.022820073731312   6: 0.022819756475637   8: 0.022818607808778   2: 0.022818151898917   9: 0.022818005804327   1: 0.022818004121419   3: 0.022817742948770 

test_19426        6: 0.787400084799010   4: 0.055604636033539   0: 0.019637695332234   8: 0.019624568976066   1: 0.019623496605970   2: 0.019623182600049   5: 0.019623150340084   9: 0.019621943623454   3: 0.019620683031180   7: 0.019620558658414 

test_19427        5: 0.607459043769565   1: 0.191753782071641   4: 0.025103958787401   8: 0.025097741425802   3: 0.025097710501893   0: 0.025097651501243   2: 0.025097581949407   6: 0.025097541239800   9: 0.025097538568540   7: 0.025097450184707 

test_19428        1: 0.759617150840487   5: 0.120123176763130   6: 0.015035048038071   0: 0.015033276653651   4: 0.015033095927334   9: 0.015032117938067   2: 0.015031595737517   8: 0.015031588679752   7: 0.015031517378462   3: 0.015031432043528 

test_19431        1: 0.497284942452638   6: 0.268363050675241   0: 0.099395135860362   2: 0.032753725709374   3: 0.017041704853630   7: 0.017033153054275   5: 0.017032902072329   8: 0.017031988417144   9: 0.017031921277020   4: 0.017031475627987 

test_19432        1: 0.632448742310406   6: 0.270961061740216   0: 0.046203848604348   7: 0.007898373721072   8: 0.007252108097390   5: 0.007057566701411   3: 0.007046365193424   9: 0.007044192067641   4: 0.007044033960723   2: 0.007043707603369 

test_19433        6: 0.868812497649722   1: 0.025702936121101   9: 0.013187810228421   5: 0.013185927204343   8: 0.013185649621647   0: 0.013185525582047   4: 0.013185274811346   3: 0.013184910842467   2: 0.013184758742081   7: 0.013184709196826 

test_19435        1: 0.844042204618030   5: 0.017330894414795   6: 0.017329971203952   0: 0.017329014086324   4: 0.017328780492919   2: 0.017328208853393   9: 0.017327945440790   8: 0.017327757478603   7: 0.017327615909511   3: 0.017327607501683 

test_19440        4: 0.625029482779809   8: 0.168347274454053   5: 0.025837479599323   6: 0.025826903095286   2: 0.025826598803769   3: 0.025826578815142   7: 0.025826556080336   0: 0.025826496064401   1: 0.025826395987444   9: 0.025826234320436 

test_19441        1: 0.715726505724953   6: 0.116693725371889   3: 0.020951226343299   0: 0.020948582295512   5: 0.020948002980477   4: 0.020947079456007   8: 0.020946396046215   9: 0.020946288883856   2: 0.020946193620609   7: 0.020945999277183 

test_19444        6: 0.529810970430561   1: 0.225994546194191   0: 0.150771792113980   9: 0.013375368449164   5: 0.013341428142238   8: 0.013341404080830   2: 0.013341202390637   7: 0.013341173836163   3: 0.013341121888899   4: 0.013340992473337 

test_19447        8: 0.448675387683527   6: 0.367777610588790   2: 0.050568397881917   5: 0.019001744531576   4: 0.019001070370877   1: 0.019001006213998   0: 0.018996590143636   3: 0.018994739721374   7: 0.018991824238942   9: 0.018991628625363 

test_19448        1: 0.554461335360953   4: 0.294629904430056   6: 0.018874333653859   5: 0.018871102474817   0: 0.018870092986873   8: 0.018860064679438   9: 0.018859174767584   3: 0.018858240207234   2: 0.018858144527288   7: 0.018857606911899 

test_19450        5: 0.461771355878408   3: 0.182604311526749   4: 0.116017397246517   1: 0.106401824767936   0: 0.022202643435154   8: 0.022201421428198   6: 0.022200936830347   9: 0.022200672183010   7: 0.022199819463519   2: 0.022199617240162 

test_19451        5: 0.788856303576848   8: 0.058239714653343   4: 0.019128728284644   1: 0.019123535936085   0: 0.019111311492831   9: 0.019110949480812   6: 0.019110826689804   7: 0.019106473081821   2: 0.019106384183934   3: 0.019105772619876 

test_19453        0: 0.764013313863869   5: 0.026229463979745   6: 0.026225439534245   1: 0.026221199791805   9: 0.026218623302233   4: 0.026218606404983   8: 0.026218446206476   2: 0.026218365507610   3: 0.026218363045691   7: 0.026218178363342 

test_19458        6: 0.479169884902890   8: 0.310393140867130   7: 0.026309618814547   5: 0.026304700210797   9: 0.026304390746103   0: 0.026304043217399   4: 0.026303952063058   3: 0.026303639706392   1: 0.026303323807006   2: 0.026303305664679 

test_19459        5: 0.744762168341708   4: 0.028366441528797   1: 0.028359167518883   6: 0.028359164752379   0: 0.028359053439486   8: 0.028358938834158   3: 0.028358924393889   9: 0.028358776906460   2: 0.028358729806084   7: 0.028358634478155 

test_19461        0: 0.427768797643279   9: 0.352325742467022   5: 0.027499170039301   1: 0.027497796654439   6: 0.027494786275185   4: 0.027483886127779   3: 0.027483882959652   8: 0.027482212491349   2: 0.027482131425686   7: 0.027481593916307 

test_19462        5: 0.750149652801441   1: 0.079577022530987   6: 0.021314786450236   0: 0.021292003696603   8: 0.021280094644280   9: 0.021278108290541   4: 0.021277528846022   7: 0.021277255322752   2: 0.021277252710046   3: 0.021276294707092 

test_19463        2: 0.726176684080497   6: 0.030451775203895   1: 0.030450716201230   8: 0.030436732357490   0: 0.030425825547258   5: 0.030414380894356   9: 0.030412266633094   7: 0.030410994891611   4: 0.030410318391071   3: 0.030410305799498 

test_19464        0: 0.826780249328698   1: 0.019249729727384   6: 0.019249226322163   5: 0.019247314691968   9: 0.019246195660384   7: 0.019246012203702   4: 0.019245471365761   8: 0.019245438649354   2: 0.019245424290448   3: 0.019244937760138 

test_19466        4: 0.718546584727720   6: 0.031509916578177   9: 0.031349752268293   8: 0.031258507951091   0: 0.031253341287674   7: 0.031252449289121   5: 0.031220562661422   1: 0.031212259894063   2: 0.031199943544143   3: 0.031196681798295 

test_19470        9: 0.416200491340317   6: 0.306252777256389   1: 0.063199113307664   0: 0.060889977542623   5: 0.025610432401613   7: 0.025571328383071   4: 0.025570680967882   3: 0.025569418731249   2: 0.025568011621111   8: 0.025567768448081 

test_19471        6: 0.440203553460439   4: 0.162014033234213   1: 0.129784697348313   2: 0.086827106025903   8: 0.072753255381844   9: 0.032107796694268   7: 0.021707527043981   5: 0.020985615075255   0: 0.020204874514092   3: 0.013411541221692 

test_19473        1: 0.728288655310900   5: 0.097590903326199   6: 0.022542229266775   8: 0.021710104347917   0: 0.021682459392604   4: 0.021673215305015   3: 0.021637892660492   9: 0.021624901128195   7: 0.021624896788360   2: 0.021624742473541 

test_19474        4: 0.589671998626118   0: 0.164024010817246   5: 0.030807218729486   3: 0.030786941892977   6: 0.030785193869268   2: 0.030785028248921   7: 0.030785008917722   1: 0.030784947815756   8: 0.030784860160238   9: 0.030784790922269 

test_19475        5: 0.594345947329464   3: 0.205001407317949   4: 0.025089682357358   1: 0.025081544637347   0: 0.025080586060242   6: 0.025080361047072   8: 0.025080313230322   2: 0.025080076134538   7: 0.025080058889067   9: 0.025080022996642 

test_19477        6: 0.493149389363717   3: 0.344657451119333   8: 0.047239840677434   4: 0.016427809808327   0: 0.016424939337095   1: 0.016422005380773   5: 0.016420691287272   9: 0.016419416030895   7: 0.016419339209199   2: 0.016419117785955 

test_19478        6: 0.461040669144891   0: 0.427698866967984   9: 0.041723331213322   5: 0.015772775631862   8: 0.012160136199211   4: 0.010676588109812   1: 0.007748073617709   3: 0.007730045610526   2: 0.007724764795689   7: 0.007724748708995 

test_19480        6: 0.778562960808566   0: 0.057414299762343   7: 0.047347090443458   1: 0.016693009769830   2: 0.016665935819245   5: 0.016665909961980   8: 0.016663473793513   9: 0.016662701246069   4: 0.016662509352646   3: 0.016662109042350 

test_19482        2: 0.340509548513538   5: 0.288765657648509   6: 0.219967455968725   1: 0.021564382091108   0: 0.021539585904179   3: 0.021533489684024   4: 0.021533011617788   8: 0.021529511670413   9: 0.021528991385977   7: 0.021528365515740 

test_19483        0: 0.447575839327778   6: 0.377798234252934   1: 0.111089329689433   9: 0.009753389210494   2: 0.009197331939554   7: 0.008922773748481   8: 0.008917096301822   5: 0.008915593101600   4: 0.008915247782452   3: 0.008915164645452 

test_19487        6: 0.475073326048331   3: 0.312486186534195   0: 0.026567030653930   9: 0.026559896678868   5: 0.026554034910412   2: 0.026553954493101   8: 0.026552291971141   1: 0.026551689493788   4: 0.026551145350467   7: 0.026550443865767 

test_19489        6: 0.755811535005693   1: 0.112516080668926   4: 0.024990905227757   9: 0.023163363741470   7: 0.014031248522633   8: 0.013907642274448   0: 0.013897067391770   5: 0.013894253109819   2: 0.013893961330592   3: 0.013893942726892 

test_19491        6: 0.677927509514305   3: 0.155297827050033   4: 0.052772509753038   0: 0.032230576209112   1: 0.013785848116597   5: 0.013654145827309   7: 0.013591083648454   8: 0.013580336905576   2: 0.013580140180053   9: 0.013580022795523 

test_19492        6: 0.505240254843654   2: 0.353348522831080   0: 0.031348202210527   3: 0.015732002288694   9: 0.015728520029561   1: 0.015722776345860   5: 0.015722501025721   7: 0.015719496139102   4: 0.015718914933051   8: 0.015718809352752 

test_19497        6: 0.694109248541387   9: 0.101286744963499   7: 0.073975211065680   0: 0.045654026524460   1: 0.037122918799865   2: 0.009571926073274   5: 0.009571042459111   8: 0.009569750180114   4: 0.009569643178106   3: 0.009569488214504 

test_19499        6: 0.785400653812417   0: 0.068714566685972   9: 0.047971950822355   1: 0.030481717884321   7: 0.021152175539865   2: 0.009280533812221   8: 0.009250856615007   3: 0.009249600939484   5: 0.009249131382716   4: 0.009248812505642 

test_19500        6: 0.836054808167650   8: 0.018218956591907   5: 0.018217026870352   1: 0.018216734917808   0: 0.018216112173890   9: 0.018215804452010   4: 0.018215328474246   7: 0.018215103076056   3: 0.018215066999760   2: 0.018215058276319 

test_19501        8: 0.595555320761048   5: 0.190818470957850   1: 0.026714214091040   2: 0.026713172376653   0: 0.026710651088033   6: 0.026705896022749   9: 0.026697688070671   4: 0.026695839266017   3: 0.026694385361896   7: 0.026694362004043 

test_19505        1: 0.483206607930064   6: 0.335338299307915   0: 0.064329840733103   8: 0.039286404605023   2: 0.017816202649146   7: 0.017117533000613   9: 0.010771785402325   3: 0.010765250881866   4: 0.010684042546065   5: 0.010684032943881 

test_19506        6: 0.787284169365007   1: 0.069619525812547   0: 0.035633528815932   3: 0.015452151719397   9: 0.015337748935427   7: 0.015337290855941   4: 0.015334047539967   2: 0.015334013942262   5: 0.015333908192204   8: 0.015333614821317 

test_19507        2: 0.317858740984943   1: 0.225032527350249   6: 0.221539372074779   5: 0.129104883811441   8: 0.027845715919936   0: 0.015894196411181   7: 0.015685343558818   9: 0.015680665409753   3: 0.015679946685552   4: 0.015678607793348 

test_19509        6: 0.793588493175324   1: 0.100627670967834   3: 0.017352252759206   0: 0.016724622376637   7: 0.012846034409362   5: 0.011819508523123   9: 0.011788375114508   2: 0.011752476785415   8: 0.011751566114148   4: 0.011748999774444 

test_19510        9: 0.403710654763966   1: 0.231067099046596   5: 0.155125508278639   6: 0.122095135550979   8: 0.014686634896903   4: 0.014678634735559   0: 0.014666880353810   2: 0.014658475560074   3: 0.014655879142625   7: 0.014655097670849 

test_19511        6: 0.609951407157889   0: 0.168118414346735   8: 0.114240635863411   9: 0.023466491965318   7: 0.022889066936704   1: 0.012267904502444   5: 0.012267305168757   4: 0.012266644547901   2: 0.012266132732795   3: 0.012265996778045 

test_19512        6: 0.762141556316076   8: 0.079503750990889   9: 0.044585401638929   0: 0.016255469060405   5: 0.016253535133374   1: 0.016253480050148   7: 0.016252170004864   4: 0.016251784124254   2: 0.016251479301849   3: 0.016251373379214 

test_19513        6: 0.757042488402517   5: 0.027000880388201   4: 0.026996808590295   0: 0.026995583196034   9: 0.026994646485636   8: 0.026994266749339   1: 0.026994250715164   3: 0.026994024906607   7: 0.026993780901683   2: 0.026993269664524 

test_19515        5: 0.573532465827675   8: 0.217551645666280   6: 0.026143974984015   9: 0.026136985505390   1: 0.026121145238066   0: 0.026106177036133   7: 0.026104727066617   4: 0.026102072620628   3: 0.026100487510400   2: 0.026100318544795 

test_19529        6: 0.449377147788796   8: 0.376066288130471   0: 0.021821831655374   5: 0.021820251073443   9: 0.021820158988101   1: 0.021820047059521   7: 0.021819641123482   3: 0.021818474103715   4: 0.021818166057676   2: 0.021817994019422 

test_19534        6: 0.731538500982681   1: 0.149647921838308   0: 0.037549642118094   8: 0.011610782790236   7: 0.011610771564171   5: 0.011610251000209   9: 0.011608787184343   2: 0.011607894391382   4: 0.011607818790869   3: 0.011607629339708 

test_19537        6: 0.670186628794197   3: 0.130874719580303   0: 0.024869331001736   1: 0.024868955516063   9: 0.024868708536189   8: 0.024867650571320   7: 0.024866301459204   2: 0.024866038092268   5: 0.024865920118259   4: 0.024865746330459 

test_19539        6: 0.642680874260540   8: 0.154874928333822   1: 0.060296007176941   9: 0.039609475390517   3: 0.024505148726561   5: 0.021451158493718   0: 0.019704072602660   7: 0.012293034607285   4: 0.012292953314702   2: 0.012292347093255 

test_19540        6: 0.428024706379130   0: 0.390101091958502   9: 0.096189774811186   1: 0.012595475457967   2: 0.012196380339037   5: 0.012182490889865   8: 0.012178944176619   4: 0.012177297843806   7: 0.012176935504421   3: 0.012176902639467 

test_19541        6: 0.695528131795684   3: 0.177830377073437   9: 0.026736438350348   0: 0.014279949223939   8: 0.014275528536266   1: 0.014275015823431   5: 0.014271120014202   7: 0.014267923188578   4: 0.014267825552592   2: 0.014267690441523 

test_19545        6: 0.747130827953308   9: 0.028098238181631   0: 0.028097757941222   8: 0.028096963561905   1: 0.028096572017021   7: 0.028096457162890   3: 0.028096057909276   5: 0.028095946817168   2: 0.028095860703431   4: 0.028095317752148 

test_19546        6: 0.703969331468207   7: 0.080690498699751   0: 0.071795056416917   5: 0.047638890837777   2: 0.024323247539322   1: 0.020853300262539   9: 0.013057856315725   8: 0.012559774129203   4: 0.012556162140224   3: 0.012555882190335 

test_19547        6: 0.421335198125743   3: 0.228740128418409   8: 0.153842526452800   0: 0.028016015978444   9: 0.028013916092447   7: 0.028011377329548   1: 0.028010976010834   5: 0.028010391334774   2: 0.028010156944541   4: 0.028009313312461 

test_19549        6: 0.655060124496538   0: 0.212827997378983   8: 0.016515847615307   5: 0.016514998972103   4: 0.016514572544837   9: 0.016513695900372   1: 0.016513485189206   7: 0.016513255036484   2: 0.016513036790007   3: 0.016512986076164 

test_19551        6: 0.821273645912007   1: 0.073788257416726   5: 0.024035696449124   0: 0.011657816271408   7: 0.011543187206824   2: 0.011540564032537   8: 0.011540240317812   3: 0.011540221352597   9: 0.011540190004152   4: 0.011540181036813 

test_19555        6: 0.616093483839257   3: 0.169191677640760   0: 0.101153447700053   1: 0.023401707045719   2: 0.015132857030583   5: 0.015028486310604   8: 0.015006729464759   9: 0.014997543859453   7: 0.014997502804917   4: 0.014996564303896 

test_19556        6: 0.668320341276625   1: 0.220699044719984   3: 0.026429183100274   0: 0.015434498741374   2: 0.011683910982822   7: 0.011527530803216   8: 0.011513389137994   9: 0.011474771991337   5: 0.011460827925496   4: 0.011456501320877 

test_19557        6: 0.516389770429317   7: 0.192134303703509   0: 0.186986997734158   5: 0.027174096015032   1: 0.012896424695246   9: 0.012886142504712   8: 0.012883435548745   4: 0.012882999366771   3: 0.012882956530012   2: 0.012882873472497 

test_19559        6: 0.682150166536953   0: 0.185636888298697   1: 0.029418776502072   3: 0.026220058745724   5: 0.016614597568977   2: 0.011992485457013   9: 0.011991961487238   4: 0.011991916530179   8: 0.011991692423734   7: 0.011991456449413 

test_19560        6: 0.684421200631764   1: 0.194597109598023   3: 0.015230684477233   5: 0.015108803357610   0: 0.015107619041229   9: 0.015107118391264   8: 0.015107060172488   4: 0.015106985077994   2: 0.015106723867565   7: 0.015106695384830 

test_19561        5: 0.525913230849250   0: 0.191393639825093   7: 0.141740258386817   6: 0.020148958834518   8: 0.020136896788744   3: 0.020134590049791   1: 0.020133959526835   4: 0.020133384360405   2: 0.020132591006605   9: 0.020132490371941 

test_19562        5: 0.546713747425403   6: 0.286165411557478   1: 0.020892156340225   0: 0.020891354600383   9: 0.020890680726909   4: 0.020890422305795   8: 0.020889544614663   7: 0.020889361809198   2: 0.020888744781148   3: 0.020888575838798 

test_19568        6: 0.751326867825350   5: 0.027637419375904   0: 0.027634247457748   9: 0.027630752702509   7: 0.027628929239295   3: 0.027628881141125   1: 0.027628603920061   8: 0.027628441000642   4: 0.027627978736054   2: 0.027627878601311 

test_19569        6: 0.736541332187947   5: 0.029281059816079   0: 0.029277533080571   9: 0.029273417168857   3: 0.029271785676559   7: 0.029271506717216   1: 0.029271361947779   8: 0.029271180523429   2: 0.029270419601508   4: 0.029270403280053 

test_19570        6: 0.807294272927749   1: 0.081738605294614   0: 0.022640386050399   5: 0.013081262526118   7: 0.012562319188574   8: 0.012537488758933   9: 0.012537024451114   3: 0.012536250625302   2: 0.012536235327773   4: 0.012536154849423 

test_19571        5: 0.373518762731750   8: 0.362557785237058   7: 0.114203246817829   6: 0.021400780229602   9: 0.021392772972010   1: 0.021391582413720   3: 0.021384230149674   4: 0.021384124060435   2: 0.021383479804229   0: 0.021383235583692 

test_19572        4: 0.343052988099473   6: 0.295597270075979   7: 0.198041491145373   1: 0.023333880165248   5: 0.023332444437105   0: 0.023332052096658   2: 0.023329350111037   3: 0.023327119508456   9: 0.023327019327335   8: 0.023326385033336 

test_19625        6: 0.650884204666530   1: 0.191477682184406   9: 0.019722151548438   0: 0.019715196026266   5: 0.019705652270842   3: 0.019699774882462   7: 0.019699172423709   8: 0.019699132717096   4: 0.019698569795768   2: 0.019698463484484 

test_19630        7: 0.355199534610446   3: 0.279097371833567   6: 0.233680165283954   1: 0.018868435649950   5: 0.018862694658852   0: 0.018861391545871   9: 0.018859867117632   2: 0.018857015021490   8: 0.018856808577636   4: 0.018856715700604 

test_19631        5: 0.380102933355927   0: 0.376904552782034   6: 0.030382634309529   1: 0.030382053460115   3: 0.030373249899392   9: 0.030372879347204   7: 0.030370634569713   2: 0.030370401030136   4: 0.030370336898813   8: 0.030370324347137 

test_19635        3: 0.407757653393397   0: 0.221426686986859   5: 0.170312833411100   7: 0.060696925203953   1: 0.023319703219464   6: 0.023308791115151   9: 0.023296149074248   4: 0.023294258431998   2: 0.023293591619573   8: 0.023293407544258 

test_19639        5: 0.779971662684682   4: 0.024450873572488   6: 0.024448216526077   3: 0.024447981037819   1: 0.024447170794398   0: 0.024446952066852   8: 0.024446928994041   9: 0.024446774469971   7: 0.024446729116057   2: 0.024446710737615 

test_19642        5: 0.786003640478735   4: 0.023780235841338   8: 0.023777148946591   6: 0.023777118920031   3: 0.023777057279806   7: 0.023776981605758   9: 0.023776978546210   0: 0.023776975131379   2: 0.023776962427096   1: 0.023776900823057 

test_19644        5: 0.763197840526708   7: 0.069388044615704   4: 0.020933619217813   6: 0.020926016558686   0: 0.020925929377153   8: 0.020925737006142   1: 0.020925727147465   2: 0.020925714012275   9: 0.020925686254213   3: 0.020925685283838 

test_19645        6: 0.775298910094026   1: 0.052835058039629   5: 0.021524049969800   2: 0.021488501937716   0: 0.021485763576732   4: 0.021477119053876   9: 0.021472959683046   7: 0.021472927246061   3: 0.021472378895463   8: 0.021472331503652 

test_19647        3: 0.532597154106986   5: 0.271111788411263   6: 0.024577521335756   0: 0.024536091342696   4: 0.024534351654280   1: 0.024529605950355   8: 0.024528508273895   7: 0.024528488075306   9: 0.024528419027148   2: 0.024528071822315 

test_19648        4: 0.777706917944654   5: 0.024705789397903   8: 0.024698699413931   0: 0.024698665971761   6: 0.024698415956287   2: 0.024698388234699   3: 0.024698318290989   9: 0.024698284755117   1: 0.024698277002771   7: 0.024698243031888 

test_19649        5: 0.577130853485208   1: 0.262255715564951   6: 0.020196658193726   0: 0.020075343469297   8: 0.020060064529097   9: 0.020056558040873   7: 0.020056298090601   2: 0.020056276161456   4: 0.020056255402733   3: 0.020055977062058 

test_19650        5: 0.369774243120476   8: 0.324973978362515   4: 0.156473306239348   1: 0.021266968946443   0: 0.021259900134792   6: 0.021253599443468   2: 0.021252321505933   9: 0.021252214234505   3: 0.021246906673721   7: 0.021246561338799 

test_19651        5: 0.768266733953287   4: 0.025755062906581   0: 0.025749561269909   1: 0.025748273008130   8: 0.025746955247161   6: 0.025746763028277   2: 0.025746700480537   7: 0.025746663551639   3: 0.025746656974120   9: 0.025746629580359 

test_19653        6: 0.802931675835998   9: 0.054764466622112   0: 0.017854524075176   5: 0.017780740625893   1: 0.017778339441119   3: 0.017778223398380   8: 0.017778191761056   7: 0.017778179675447   2: 0.017777926808552   4: 0.017777731756266 

test_19654        0: 0.775377754884097   6: 0.053247702644785   1: 0.021498467489584   3: 0.021414888448031   5: 0.021412666146266   2: 0.021409883711665   9: 0.021409778661754   8: 0.021409777082936   4: 0.021409576020344   7: 0.021409504910538 

test_19655        5: 0.787043477757495   1: 0.023665451590999   0: 0.023665225587650   4: 0.023664300813620   2: 0.023661393391267   6: 0.023660451401389   8: 0.023660261949477   3: 0.023659856615929   7: 0.023659803482205   9: 0.023659777409969 

test_19657        3: 0.443115503299618   5: 0.347202570462577   4: 0.026218835270733   0: 0.026209551827295   8: 0.026209151526124   6: 0.026209115386329   2: 0.026208893406729   9: 0.026208848224519   7: 0.026208778857865   1: 0.026208751738211 

test_19658        6: 0.708172159658301   7: 0.109471517134442   0: 0.071816907493934   1: 0.015795376089233   5: 0.015791639827088   3: 0.015790640104433   8: 0.015790580760510   9: 0.015790526623471   2: 0.015790372071736   4: 0.015790280236853 

test_19663        2: 0.532780844876856   6: 0.176512056547504   1: 0.140954322589409   8: 0.053875192604448   4: 0.015992540495369   5: 0.015983444375370   0: 0.015979644849208   3: 0.015975647960747   9: 0.015975468427332   7: 0.015970837273757 

test_19664        9: 0.429177331372044   6: 0.323824656283793   8: 0.121829486614240   0: 0.018005255112775   2: 0.017875915537251   5: 0.017858528821910   4: 0.017858282535357   1: 0.017858158417127   7: 0.017856916819419   3: 0.017855468486085 

test_19666        2: 0.480282915018895   1: 0.332985722750634   0: 0.023347257077516   5: 0.023346016329743   6: 0.023342649429625   4: 0.023340239213543   7: 0.023339613828010   3: 0.023339235851669   8: 0.023338384916952   9: 0.023337965583413 

test_19667        5: 0.800951769497553   4: 0.022118588180146   6: 0.022116426937367   0: 0.022116402969146   1: 0.022116393310897   3: 0.022116186547990   7: 0.022116120325301   2: 0.022116088539675   8: 0.022116030233132   9: 0.022115993458791 

test_19668        6: 0.571970463962462   0: 0.137333150071789   7: 0.124842317072458   3: 0.054548372731164   9: 0.036488109935034   5: 0.014964295499775   1: 0.014964091890468   8: 0.014963689363761   4: 0.014962809980806   2: 0.014962699492284 

test_19672        6: 0.545373544517243   4: 0.171275827258652   0: 0.171001133318713   5: 0.042357076779868   1: 0.016048981770422   3: 0.010956474334768   9: 0.010750506235575   8: 0.010745916013088   7: 0.010745552882104   2: 0.010744986889570 

test_19674        5: 0.803563791393115   4: 0.021831631174422   6: 0.021826082749836   0: 0.021825721939893   1: 0.021825691812092   8: 0.021825483092472   3: 0.021825423040234   9: 0.021825414379870   2: 0.021825393391556   7: 0.021825367026511 

test_19675        0: 0.647788444070039   6: 0.145518383448199   4: 0.025844485541222   1: 0.025842564510263   5: 0.025837600652723   2: 0.025834519162097   9: 0.025833640469128   8: 0.025833579262265   3: 0.025833423409194   7: 0.025833359474869 

test_19679        5: 0.522561286888009   1: 0.230281832152423   2: 0.070270222114277   9: 0.063301534617663   6: 0.025081683455909   0: 0.018192385019964   7: 0.017579751673218   8: 0.017577922767475   4: 0.017577270167771   3: 0.017576111143291 

test_19680        5: 0.755914401070328   8: 0.081386412834302   4: 0.020339516793350   6: 0.020337625199220   7: 0.020337343368220   9: 0.020337160130747   0: 0.020336942493942   3: 0.020336902386767   1: 0.020336879045381   2: 0.020336816677744 

test_19681        0: 0.411829106897024   5: 0.315207744932788   2: 0.138280180409379   4: 0.019266511874564   6: 0.019252902844182   1: 0.019250459424758   8: 0.019229102101283   7: 0.019228734307181   3: 0.019227690755074   9: 0.019227566453768 

test_19683        0: 0.435853846862899   6: 0.416362038692455   1: 0.030558488318070   5: 0.022751427728418   3: 0.015749000580265   4: 0.015748652295338   2: 0.015744887525527   9: 0.015743945024422   8: 0.015743938924811   7: 0.015743774047796 

test_19684        6: 0.801920877091864   0: 0.066965767876538   1: 0.053459251548099   8: 0.020209131229516   3: 0.009586606496808   9: 0.009572605560933   7: 0.009572346050397   5: 0.009571205352970   4: 0.009571177700265   2: 0.009571031092611 

test_19689        8: 0.704140140575600   6: 0.032878986171764   5: 0.032875942171284   0: 0.032873035540019   1: 0.032872764015200   9: 0.032872466325873   3: 0.032872323915452   4: 0.032871641142336   7: 0.032871522049694   2: 0.032871178092779 

test_19690        7: 0.427877204603177   1: 0.397667947313400   5: 0.021815500216867   0: 0.021812279214203   6: 0.021808902078644   9: 0.021808322834186   4: 0.021803038353910   3: 0.021803011601522   2: 0.021802399411520   8: 0.021801394372571 

test_19692        0: 0.518852140000646   6: 0.263952081938135   5: 0.027155994274790   7: 0.027150636573575   2: 0.027150384497994   1: 0.027148353362865   3: 0.027147690284038   4: 0.027147650887910   9: 0.027147624690296   8: 0.027147443489750 

test_19693        8: 0.836776234306962   6: 0.018144607394379   0: 0.018137600335468   1: 0.018136475544203   5: 0.018135725866664   9: 0.018135595690764   7: 0.018133952014503   2: 0.018133478386944   4: 0.018133179324101   3: 0.018133151136012 

test_19697        5: 0.720009354754592   8: 0.083116258588928   1: 0.044674842774952   6: 0.021793143239543   0: 0.021766913269415   9: 0.021744631249104   7: 0.021725798106168   4: 0.021723846225681   2: 0.021723072518159   3: 0.021722139273458 

test_19699        9: 0.405495920978937   5: 0.347203750233270   2: 0.070636339997952   3: 0.057924725972074   1: 0.019999571482951   6: 0.019813353281976   0: 0.019742149401857   8: 0.019737754869090   4: 0.019724136208532   7: 0.019722297573362 

test_19702        4: 0.423859874790265   6: 0.232023093506660   5: 0.225266675434383   0: 0.016981811887375   1: 0.016981662637582   8: 0.016978435074168   2: 0.016977569920389   9: 0.016977479474572   7: 0.016976708167470   3: 0.016976689107137 

test_19703        9: 0.567752951937960   5: 0.144073617310034   6: 0.133806276498964   2: 0.022082712030493   1: 0.022053670373778   0: 0.022050400352855   4: 0.022047062042187   7: 0.022045025207960   8: 0.022044689511534   3: 0.022043594734235 

test_19704        5: 0.530460194367513   9: 0.253271902646297   7: 0.027044574275990   4: 0.027036036813094   1: 0.027035802827835   8: 0.027030506682320   3: 0.027030359626277   2: 0.027030315285696   6: 0.027030165544636   0: 0.027030141930341 

test_19706        1: 0.734978779896282   6: 0.029448282807258   0: 0.029448066628562   5: 0.029447500485992   9: 0.029446624722209   4: 0.029446484400908   2: 0.029446222950618   8: 0.029446192257855   7: 0.029445981857625   3: 0.029445863992691 

test_19710        8: 0.451133368682321   5: 0.318279243105128   4: 0.028830678753968   6: 0.028823491629360   0: 0.028822339070032   3: 0.028822299621194   7: 0.028822296724673   2: 0.028822159191379   9: 0.028822114197093   1: 0.028822009024851 

test_19711        5: 0.507609228925920   4: 0.193391178051828   6: 0.154557875652696   1: 0.020637886799769   0: 0.020636584074244   9: 0.020634218990981   2: 0.020633522975422   8: 0.020633412390574   3: 0.020633195472367   7: 0.020632896666199 

test_19712        5: 0.610517958679184   0: 0.189113929575280   4: 0.025053154563833   1: 0.025045708546137   6: 0.025045392976222   8: 0.025044995311649   9: 0.025044807530082   3: 0.025044698212896   2: 0.025044677743574   7: 0.025044676861143 

test_19713        1: 0.743244969314157   0: 0.133619948827557   5: 0.015782225938113   4: 0.015340382699307   2: 0.015338091772455   6: 0.015338017496206   8: 0.015334408957111   9: 0.015334134830450   3: 0.015334007791417   7: 0.015333812373226 

test_19719        5: 0.817383296553894   1: 0.020294435525582   6: 0.020293171528562   0: 0.020291729578808   2: 0.020290156888137   8: 0.020289838369590   4: 0.020289584857469   9: 0.020289404921926   3: 0.020289206795126   7: 0.020289174980906 

test_19721        6: 0.535124697951835   0: 0.315268592757761   7: 0.031858049600036   8: 0.029939766252763   5: 0.020979611486578   9: 0.013430953517210   1: 0.013350182999695   2: 0.013349515757975   3: 0.013349353963475   4: 0.013349275712672 

test_19723        5: 0.451229847445614   3: 0.365278892354175   4: 0.022941340376389   6: 0.022937293850597   0: 0.022936867306224   7: 0.022935376136558   1: 0.022935327544396   9: 0.022935203349060   8: 0.022935021571981   2: 0.022934830065006 

test_19726        5: 0.272851253757094   4: 0.238219920863252   9: 0.200003236247158   8: 0.119601800881553   0: 0.028225055678594   1: 0.028223429765569   6: 0.028222617947046   7: 0.028220564821954   2: 0.028216773173637   3: 0.028215346864141 

test_19727        5: 0.728400600251007   9: 0.115467245246455   6: 0.019569660638337   1: 0.019532490959698   0: 0.019527822378085   3: 0.019513308284233   8: 0.019497958109130   2: 0.019497601753373   4: 0.019497541571155   7: 0.019495770808528 

test_19731        0: 0.733203696848809   1: 0.072682823074373   6: 0.024301838962867   3: 0.024261236100119   5: 0.024259569185948   8: 0.024258660601111   9: 0.024258205030070   4: 0.024258195254996   2: 0.024258036881282   7: 0.024257738060425 

test_19732        5: 0.731845445165340   8: 0.081718281924150   0: 0.023311762310090   6: 0.023308370410183   1: 0.023307425562528   9: 0.023303590300727   7: 0.023303353574340   4: 0.023301281269002   2: 0.023300465729242   3: 0.023300023754398 

test_19734        6: 0.382702382396681   4: 0.254535202465451   9: 0.135332598858618   1: 0.090617176330282   0: 0.044956256401781   7: 0.032144428736897   5: 0.014931733624541   8: 0.014930743017847   2: 0.014925010636766   3: 0.014924467531137 

test_19737        1: 0.463471596789613   8: 0.351282571167711   5: 0.023162975978343   6: 0.023157994847355   0: 0.023156814169547   9: 0.023155549780103   4: 0.023154081484322   3: 0.023153149519422   2: 0.023152844572593   7: 0.023152421690993 

test_19742        5: 0.549085703168439   0: 0.283321551830707   4: 0.020954457859521   6: 0.020950510235978   1: 0.020948090739244   9: 0.020948015639914   8: 0.020947995694806   2: 0.020947924534269   3: 0.020947908284253   7: 0.020947842012869 

test_19744        7: 0.503788684995092   0: 0.297335792848059   5: 0.076819732895208   9: 0.017448125667149   1: 0.017443902453408   2: 0.017441499119643   6: 0.017436919042781   3: 0.017428738969548   4: 0.017428648884615   8: 0.017427955124498 

test_19745        5: 0.553794883126877   0: 0.220055432974773   4: 0.028273311676545   6: 0.028269625684099   3: 0.028267980670358   8: 0.028267935888287   2: 0.028267807721795   7: 0.028267706914140   9: 0.028267695741679   1: 0.028267619601449 

test_19748        1: 0.502938593693524   3: 0.291282597317625   5: 0.025750043632149   0: 0.025726741534442   6: 0.025722076177344   4: 0.025717002702297   8: 0.025716509447707   2: 0.025715845690220   9: 0.025715377877245   7: 0.025715211927446 

test_19751        1: 0.450087042106918   2: 0.271416356188369   6: 0.149992026663460   9: 0.024149343216552   0: 0.023803123083668   3: 0.016210375136379   4: 0.016099790931897   8: 0.016085208947099   7: 0.016080519784083   5: 0.016076213941574 

test_19756        6: 0.633953731845948   3: 0.121682676147891   9: 0.115417373676659   8: 0.037477708792705   0: 0.015262130533793   7: 0.015243429488799   1: 0.015242017196699   2: 0.015240549017224   5: 0.015240348931834   4: 0.015240034368448 

test_19758        3: 0.579416864370950   5: 0.244615599517445   0: 0.022021965772051   4: 0.022001602826688   1: 0.021996961877373   6: 0.021992355810032   2: 0.021989991432647   9: 0.021988723111151   8: 0.021988451063987   7: 0.021987484217675 

test_19760        1: 0.538224927120087   3: 0.201606466569368   6: 0.138461223066290   5: 0.039574445918253   0: 0.016441379523599   8: 0.013300081321552   7: 0.013198322721774   4: 0.013077902697620   9: 0.013070618086285   2: 0.013044632975173 

test_19761        5: 0.822045212400618   6: 0.019843745142009   0: 0.019771121878657   1: 0.019764268588092   8: 0.019763779947771   9: 0.019763345217896   4: 0.019763093535277   7: 0.019762248292466   3: 0.019761911909919   2: 0.019761273087295 

test_19762        1: 0.873391494245337   0: 0.014072138457905   6: 0.014071952438540   7: 0.014067912361921   4: 0.014067457198280   5: 0.014066968251846   2: 0.014066536469428   9: 0.014065273678330   8: 0.014065208193712   3: 0.014065058704702 

test_19763        0: 0.758849603042990   1: 0.084154355181576   6: 0.019637546295931   5: 0.019629234877476   4: 0.019622455827628   9: 0.019621641446722   8: 0.019621630800888   3: 0.019621332612843   2: 0.019621119093028   7: 0.019621080820918 

test_19764        6: 0.724520777409230   5: 0.117282915127623   9: 0.044476244237566   0: 0.016254714789486   7: 0.016250540947264   4: 0.016243811559535   1: 0.016243372623839   8: 0.016242784708488   2: 0.016242474693213   3: 0.016242363903756 

test_19766        8: 0.478056541205832   1: 0.360854127877485   6: 0.020149821208208   5: 0.020139117256143   0: 0.020138119492770   2: 0.020132862163413   4: 0.020132846238551   9: 0.020132509321844   3: 0.020132206026362   7: 0.020131849209391 

test_19767        1: 0.353848955840047   5: 0.296269790017372   4: 0.171436821967550   9: 0.058600867211528   8: 0.033040664519188   6: 0.031784562291405   0: 0.013759420172690   2: 0.013755672686527   7: 0.013751745418159   3: 0.013751499875535 

test_19769        6: 0.428097593597259   4: 0.367252706181362   0: 0.051484291005874   7: 0.021901964601759   1: 0.021883361957233   9: 0.021878563271033   5: 0.021877342234924   3: 0.021875056400538   2: 0.021874599843291   8: 0.021874520906727 

test_19773        8: 0.627593504834896   6: 0.200874719422163   7: 0.038135795960584   1: 0.019196274582263   0: 0.019044174245803   5: 0.019033861788153   4: 0.019031988470435   2: 0.019030674467572   3: 0.019030258430164   9: 0.019028747797967 

test_19775        0: 0.490589583428877   6: 0.300970823021415   2: 0.084449232104262   5: 0.029087077076187   7: 0.015819308679595   1: 0.015818883941067   8: 0.015817365916149   4: 0.015816916452671   9: 0.015816741576578   3: 0.015814067803199 

test_19780        1: 0.778064348009809   5: 0.024712068940126   7: 0.024686907420329   9: 0.024662524353616   6: 0.024661206182653   8: 0.024645042197954   0: 0.024644109000181   4: 0.024642840443932   2: 0.024640688289274   3: 0.024640265162125 

test_19781        1: 0.469766010630903   6: 0.339737941969311   5: 0.064683036134737   0: 0.030993851727436   7: 0.016433509569560   2: 0.015698817182071   9: 0.015676817073200   8: 0.015671543687630   3: 0.015669299624142   4: 0.015669172401010 

test_19784        5: 0.530226978931014   1: 0.281244569004052   4: 0.023570198330038   6: 0.023567386812625   0: 0.023566057485752   7: 0.023565242828247   8: 0.023565150785395   2: 0.023564971043269   3: 0.023564739558719   9: 0.023564705220891 

test_19786        5: 0.295615558319589   7: 0.290401086459415   6: 0.203209376310509   0: 0.067602277093378   3: 0.053167618794519   1: 0.018009600765741   8: 0.017999946849479   2: 0.017998381079111   9: 0.017998265666104   4: 0.017997888662156 

test_19787        5: 0.793657526410601   0: 0.061190948240293   4: 0.018147396307593   6: 0.018143825113110   1: 0.018143542370949   8: 0.018143457230637   9: 0.018143365503521   7: 0.018143317910416   3: 0.018143311628213   2: 0.018143309284665 

test_19788        5: 0.789698754326185   6: 0.023368192496530   4: 0.023367534788605   1: 0.023367244635091   0: 0.023367067443875   8: 0.023366419506036   2: 0.023366357969039   9: 0.023366339146807   7: 0.023366054715989   3: 0.023366034971842 

test_19790        5: 0.598988847994323   8: 0.206800112332324   4: 0.024283045551286   6: 0.024275789261281   1: 0.024275748728790   0: 0.024275637866689   9: 0.024275542865020   3: 0.024275135647543   2: 0.024275080489942   7: 0.024275059262802 

test_19796        1: 0.780291064675269   6: 0.024416013111703   5: 0.024413952703530   0: 0.024412507095922   9: 0.024411483631826   4: 0.024411246668946   8: 0.024411207076376   2: 0.024411183135928   7: 0.024410878804452   3: 0.024410463096047 

test_19799        1: 0.707751078960408   6: 0.109467167673140   0: 0.064998922092525   4: 0.016829838388006   5: 0.016828612225466   9: 0.016825352168440   8: 0.016824964051378   3: 0.016824784865513   2: 0.016824686482095   7: 0.016824593093029 

test_19802        4: 0.431279547019174   6: 0.389082847826774   2: 0.042499287912634   7: 0.020149940746162   5: 0.019553281554434   0: 0.019526168775236   3: 0.019502705192420   8: 0.019483979037804   9: 0.019475687085922   1: 0.019446554849441 

test_19803        4: 0.766464853007696   5: 0.025955710223781   0: 0.025947721165736   3: 0.025947534014064   8: 0.025947493569515   2: 0.025947395086548   6: 0.025947341435531   7: 0.025947331238643   9: 0.025947312650313   1: 0.025947307608172 

test_19807        6: 0.838358521673480   0: 0.029446490155977   1: 0.027794911226328   7: 0.014951622736607   5: 0.014913086611399   2: 0.014907726825058   9: 0.014907133367782   4: 0.014906968137886   8: 0.014906842309572   3: 0.014906696955912 

test_19808        4: 0.431239050887049   6: 0.389123010588816   2: 0.042499331175593   7: 0.020149465797973   5: 0.019553960881769   0: 0.019526205441085   3: 0.019502702760423   8: 0.019484001799187   9: 0.019475706757428   1: 0.019446563910677 

test_19810        9: 0.442051061078554   1: 0.409023894222162   2: 0.019070302817700   5: 0.018871550313702   6: 0.018681846649367   7: 0.018534940986339   0: 0.018445801097749   3: 0.018445122581342   4: 0.018440546444170   8: 0.018434933808915 

test_19812        4: 0.755163630863071   5: 0.027208956884330   6: 0.027204401842447   1: 0.027203647895245   9: 0.027203442333703   3: 0.027203234196349   0: 0.027203217481479   2: 0.027203214658732   8: 0.027203130705059   7: 0.027203123139584 

test_19815        5: 0.803745010214843   3: 0.054303365697322   7: 0.017750250328737   1: 0.017746530481983   6: 0.017744702597776   4: 0.017744601426486   0: 0.017744282866755   9: 0.017741559987877   8: 0.017740115099821   2: 0.017739581298401 

test_19821        8: 0.595949810898910   1: 0.183403227202709   6: 0.027603677836815   7: 0.027579346113374   0: 0.027578541921303   9: 0.027577238471149   5: 0.027577235731324   2: 0.027577036992764   3: 0.027576981078389   4: 0.027576903753263 

test_19823        2: 0.657390413587359   0: 0.142298188335520   5: 0.025071895760908   3: 0.025042441130495   1: 0.025041099056926   6: 0.025039835617487   8: 0.025033192300907   4: 0.025029983933856   7: 0.025026876529781   9: 0.025026073746761 

test_19826        4: 0.414209371501842   5: 0.276274905815490   8: 0.070088613363753   7: 0.063311757532744   6: 0.053664653644328   0: 0.024530833719317   2: 0.024501252857315   1: 0.024479487252741   9: 0.024478102921453   3: 0.024461021391016 

test_19828        6: 0.612950401283471   1: 0.197122377128535   0: 0.075855062124803   4: 0.030287353441075   9: 0.024859070903806   5: 0.015306525484116   3: 0.014378278989347   8: 0.009929923103286   7: 0.009662322219197   2: 0.009648685322364 

test_19830        2: 0.532120340553384   5: 0.257119134072516   9: 0.049343604162431   6: 0.023069493310664   1: 0.023067023023567   0: 0.023060234973617   8: 0.023058387555489   3: 0.023056838922126   4: 0.023052748700495   7: 0.023052194725711 

test_19831        5: 0.682835625085575   6: 0.159943147248815   1: 0.035292555928989   2: 0.017451570162366   8: 0.017413972549419   0: 0.017413970258207   9: 0.017413420522592   4: 0.017413014267452   3: 0.017411415452908   7: 0.017411308523676 

test_19832        6: 0.334089939099251   1: 0.247980380796170   2: 0.228505701092573   0: 0.126877027979180   9: 0.010438998906533   3: 0.010431637089752   7: 0.010430871893733   5: 0.010427678131181   8: 0.010413144058127   4: 0.010404620953500 

test_19833        1: 0.667573787417705   0: 0.119185222110468   4: 0.098564588313227   5: 0.016388343596646   6: 0.016385188158453   8: 0.016381596339403   9: 0.016380754793878   2: 0.016380434395936   7: 0.016380307589447   3: 0.016379777284837 

test_19835        6: 0.540075273454584   3: 0.182019034694092   8: 0.118270986033628   4: 0.057645697208543   0: 0.017063651445499   1: 0.017049919953376   9: 0.016998519710939   5: 0.016980803256018   7: 0.016950867664708   2: 0.016945246578612 

test_19837        5: 0.519640057654906   7: 0.205870287328355   0: 0.147018244726174   1: 0.018247695312249   6: 0.018213471377455   9: 0.018202766603333   4: 0.018202627836794   8: 0.018201984869232   2: 0.018201635661125   3: 0.018201228630378 

test_19839        2: 0.551296653847618   1: 0.243083346902567   9: 0.070213133803674   0: 0.019410110313676   6: 0.019358793280202   5: 0.019328741944423   4: 0.019328706505116   7: 0.019326943801330   3: 0.019326896959798   8: 0.019326672641596 

test_19844        6: 0.728603405948833   1: 0.091006654427365   4: 0.079021763116162   2: 0.014573605884110   0: 0.014570412393162   7: 0.014484903997827   5: 0.014444259022267   8: 0.014443439464415   9: 0.014428648888804   3: 0.014422906857055 

test_19850        5: 0.642304485523286   0: 0.160837613737357   6: 0.024625128941297   4: 0.024612719925958   8: 0.024603641150098   3: 0.024603461102621   2: 0.024603331016448   9: 0.024603274993007   7: 0.024603246967983   1: 0.024603096641945 

test_19854        5: 0.634870904411298   4: 0.193492215268885   1: 0.021454751640819   8: 0.021454692181219   6: 0.021454686827841   0: 0.021454666335017   9: 0.021454663026764   3: 0.021454570526099   2: 0.021454474538879   7: 0.021454375243178 

test_19856        7: 0.492592467659069   5: 0.291442788324162   1: 0.026998174328687   0: 0.026998143329921   3: 0.026995751020240   2: 0.026995348932498   4: 0.026995292665520   6: 0.026995114047250   9: 0.026994229383313   8: 0.026992690309340 

test_19860        4: 0.791667715827017   1: 0.023162197192026   0: 0.023150257402321   3: 0.023148049730195   5: 0.023147864050922   6: 0.023147424965972   9: 0.023146450995929   2: 0.023144124579638   7: 0.023142970869333   8: 0.023142944386647 

test_19862        4: 0.817040657812533   6: 0.020351775215391   8: 0.020350143317906   9: 0.020344106276190   5: 0.020332923655849   0: 0.020323747089868   1: 0.020317327277349   7: 0.020317058859935   2: 0.020312177717130   3: 0.020310082777849 

test_19864        2: 0.390247332904900   8: 0.302561866697866   1: 0.165121245738266   4: 0.020312686536543   5: 0.020308340485567   6: 0.020296537675893   0: 0.020292913134434   7: 0.020291014120855   3: 0.020284275305838   9: 0.020283787399838 

test_19865        5: 0.789662298995263   4: 0.023375576801998   6: 0.023370946826160   0: 0.023370502764801   1: 0.023370352211830   8: 0.023370208838921   3: 0.023370120483436   7: 0.023370102921850   2: 0.023369963658013   9: 0.023369926497728 

test_19866        2: 0.576527271372253   6: 0.176240736756188   5: 0.112676246932867   0: 0.019242315009027   1: 0.019236519839573   4: 0.019216141729841   8: 0.019215645259092   9: 0.019215359279846   3: 0.019215322058762   7: 0.019214441762551 

test_19867        6: 0.786678211104991   0: 0.062997046007044   1: 0.061907394349561   3: 0.027967326155187   8: 0.010101972649933   7: 0.010071246308171   5: 0.010070663012776   9: 0.010069922338464   2: 0.010068194648902   4: 0.010068023424970 

test_19869        6: 0.549027986700891   7: 0.318648613870451   1: 0.034301572351658   3: 0.014098645248646   0: 0.013997681060598   2: 0.013989114857064   5: 0.013987940632587   8: 0.013984168304538   4: 0.013982732640583   9: 0.013981544332984 

test_19870        0: 0.769188332651302   1: 0.081510093823503   5: 0.018677129903962   6: 0.018667667695486   2: 0.018664271878415   3: 0.018663478350139   4: 0.018658713658584   8: 0.018656891846392   9: 0.018656776732636   7: 0.018656643459582 

test_19872        2: 0.534559494347940   7: 0.218685415770399   1: 0.030874152818345   5: 0.030851798607345   0: 0.030849194434288   6: 0.030842484716699   4: 0.030836605945553   9: 0.030835653745378   3: 0.030832921056585   8: 0.030832278557468 

test_19874        5: 0.805020632769736   6: 0.021670221419570   1: 0.021667509774840   8: 0.021666637348229   0: 0.021665569273316   2: 0.021664074250867   9: 0.021663170526189   4: 0.021661396091708   7: 0.021660650051023   3: 0.021660138494522 

test_19875        6: 0.507864081121667   0: 0.297981543873074   1: 0.090035237419363   3: 0.037183699893998   2: 0.011160553437898   9: 0.011160218101382   5: 0.011155040877168   4: 0.011153915048152   8: 0.011152989018251   7: 0.011152721209047 

test_19880        1: 0.449726574594988   2: 0.182729214670997   7: 0.137606794722278   4: 0.118141257763240   5: 0.018639428852465   0: 0.018637872251537   6: 0.018635145169910   9: 0.018628818873189   8: 0.018627596041231   3: 0.018627297060164 

test_19882        6: 0.601338258391429   1: 0.194774565240030   0: 0.127168716859647   8: 0.017213587495494   3: 0.009926080270300   5: 0.009916164784782   9: 0.009915788188502   7: 0.009915729129569   4: 0.009915625405660   2: 0.009915484234586 

test_19887        5: 0.465392135257311   0: 0.325805717961676   4: 0.026105757027168   3: 0.026099729231432   8: 0.026099694320288   2: 0.026099551446184   9: 0.026099486762719   1: 0.026099402219684   7: 0.026099298831374   6: 0.026099226942165 

test_19890        2: 0.426048345741432   6: 0.248894287166136   1: 0.134069507117446   8: 0.043116149418056   4: 0.035897733007089   9: 0.022878348964143   0: 0.022293869615925   5: 0.022287597172620   7: 0.022258619616920   3: 0.022255542180233 

test_19892        1: 0.648942855522381   6: 0.180818882684407   5: 0.021291130139917   9: 0.021289807463852   4: 0.021279988005918   0: 0.021279135472749   3: 0.021277367669046   8: 0.021274363475946   2: 0.021273286774006   7: 0.021273182791778 

test_19895        2: 0.516475511778444   1: 0.188897985247094   3: 0.146103823057478   4: 0.041048453520421   0: 0.017921758633557   6: 0.017918601835197   5: 0.017913824001158   9: 0.017907170961583   8: 0.017906536230744   7: 0.017906334734325 

test_19900        1: 0.729655376997948   4: 0.030045279070082   6: 0.030039889990002   0: 0.030039138288326   5: 0.030037806442516   3: 0.030036697122773   2: 0.030036660635560   7: 0.030036487385597   9: 0.030036393007233   8: 0.030036271059962 

test_19902        3: 0.452199680324660   1: 0.371145261690115   6: 0.022099288709760   0: 0.022096578464254   5: 0.022089524487297   4: 0.022074941235884   7: 0.022074002236147   9: 0.022073660806420   8: 0.022073610502079   2: 0.022073451543384 

test_19903        6: 0.466710925453178   3: 0.298292455211401   5: 0.078517942333310   9: 0.069944681399683   1: 0.014434844452091   8: 0.014420515411948   2: 0.014420318836151   7: 0.014419960615192   4: 0.014419315488216   0: 0.014419040798831 

test_19906        6: 0.766541164812959   9: 0.065013396797317   5: 0.021064509778406   1: 0.021060846972542   4: 0.021057003028999   0: 0.021056970521164   2: 0.021052689523729   8: 0.021051580765189   3: 0.021051312759649   7: 0.021050525040046 

test_19912        1: 0.760275039211910   5: 0.049384854175022   0: 0.045737060168078   2: 0.020803178339515   6: 0.020636712353532   4: 0.020634567595785   9: 0.020632655603273   8: 0.020632335625927   7: 0.020631977433249   3: 0.020631619493710 

test_19913        2: 0.732809118548255   6: 0.029729397813116   1: 0.029707556244992   0: 0.029693807618736   5: 0.029680261669373   8: 0.029679551359331   9: 0.029678251935938   7: 0.029677590723199   4: 0.029674756537451   3: 0.029669707549608 

test_19915        5: 0.617573240803187   8: 0.193135858563653   4: 0.023664463255961   6: 0.023663174614160   0: 0.023661073719926   1: 0.023660954519274   3: 0.023660466579219   9: 0.023660419401137   2: 0.023660218630712   7: 0.023660129912773 

test_19918        6: 0.516246324364554   7: 0.267531700958805   1: 0.085753509958607   9: 0.050439573050190   0: 0.013424248003288   5: 0.013365468897494   2: 0.013325508681151   3: 0.013312674758590   8: 0.013307393195688   4: 0.013293598131634 

test_19921        2: 0.580116614950634   5: 0.182307530852395   1: 0.029703790047215   0: 0.029700047847827   9: 0.029699608440369   8: 0.029695919006450   6: 0.029695350296398   7: 0.029694543818597   4: 0.029694405757674   3: 0.029692188982440 

test_19927        6: 0.741146790676919   7: 0.127960171280317   2: 0.016425204431440   5: 0.016372473546508   4: 0.016371473211222   0: 0.016345713846809   3: 0.016345340174338   1: 0.016345263837051   8: 0.016344155009935   9: 0.016343413985461 

test_19930        1: 0.571703139535917   2: 0.248137539589305   9: 0.079730514593227   3: 0.018507418097605   0: 0.013934601804864   5: 0.013666412440983   6: 0.013593370775921   4: 0.013582758484226   8: 0.013572282641744   7: 0.013571962036207 

test_19933        5: 0.793473221544152   1: 0.022983247602633   6: 0.022951983191647   4: 0.022946025424330   0: 0.022942651623028   8: 0.022940694318091   7: 0.022940590018684   9: 0.022940568825792   3: 0.022940509949044   2: 0.022940507502600 

test_19935        2: 0.522819848923063   6: 0.192332633858116   7: 0.069146659022759   4: 0.058648058268657   1: 0.050174085812947   9: 0.021459450095101   0: 0.021388807821487   5: 0.021350973062763   3: 0.021339899780142   8: 0.021339583354965 

test_19939        1: 0.331877456336724   6: 0.252662771125934   3: 0.173143951059153   9: 0.082980695631839   0: 0.026559056741148   5: 0.026556543672369   4: 0.026556255749264   2: 0.026554628856490   7: 0.026554364896734   8: 0.026554275930345 

test_19943        1: 0.829222279213797   6: 0.018991137382281   5: 0.018976024983495   9: 0.018976005359914   0: 0.018975256754778   4: 0.018973687096132   8: 0.018971607142005   3: 0.018971444082430   7: 0.018971394499894   2: 0.018971163485275 

test_19946        6: 0.415197493266500   3: 0.163065959227116   9: 0.140277785935252   1: 0.139191922517390   7: 0.053223659070208   0: 0.032634335378020   5: 0.014103735285536   4: 0.014103446188245   8: 0.014100869357338   2: 0.014100793774394 

test_19947        6: 0.689177594095828   3: 0.123980651665997   0: 0.080237208921639   8: 0.027850097747540   4: 0.027485049187693   5: 0.010270610147122   1: 0.010252742867312   7: 0.010248974229712   9: 0.010248897989813   2: 0.010248173147344 

test_19950        4: 0.294022849213687   6: 0.286828979140967   5: 0.252088702254208   9: 0.063205559003227   8: 0.030755576993119   7: 0.014833752066573   1: 0.014704544600492   0: 0.014601800591899   2: 0.014479280515901   3: 0.014478955619926 

test_19955        1: 0.817416339051939   0: 0.050421058851981   6: 0.016551208079052   5: 0.016519386231623   7: 0.016518463245831   9: 0.016517618871208   4: 0.016514748159287   8: 0.016514697209806   2: 0.016513486435762   3: 0.016512993863511 

test_19957        5: 0.726117066961271   6: 0.115664414659427   8: 0.019784106201661   4: 0.019780617747694   1: 0.019780163641719   9: 0.019775063465424   0: 0.019774859454772   3: 0.019774641210021   2: 0.019774551134964   7: 0.019774515523047 

test_19959        7: 0.569669147480049   1: 0.230265192117024   0: 0.074453440232812   6: 0.017960263989058   4: 0.017951786187194   5: 0.017945557791441   2: 0.017944017696996   9: 0.017943222581379   8: 0.017934998335231   3: 0.017932373588817 

test_19962        7: 0.460693834379715   5: 0.352686077012696   6: 0.044194513684300   9: 0.020493521230381   1: 0.020330507119152   0: 0.020324177187543   2: 0.020320970628160   4: 0.020318966947951   3: 0.020318915068261   8: 0.020318516741840 

test_19963        1: 0.528415780121229   8: 0.294960410658487   6: 0.022097595053857   5: 0.022082146821966   0: 0.022079168871908   4: 0.022075163825191   9: 0.022072629741511   2: 0.022072580651786   7: 0.022072512721164   3: 0.022072011532901 

test_19964        6: 0.837421190623235   1: 0.048417774175266   0: 0.026453820407865   3: 0.012533152508378   8: 0.012529688933333   5: 0.012529266623230   4: 0.012528920522490   7: 0.012528803336552   9: 0.012528753530222   2: 0.012528629339430 

test_19965        5: 0.336664785226466   0: 0.268981085195861   4: 0.196453190705398   2: 0.028273482467287   1: 0.028273215931263   6: 0.028272457757317   8: 0.028271495153186   7: 0.028270312607346   3: 0.028270037928363   9: 0.028269937027515 

test_19966        5: 0.682383366082781   0: 0.116081740443649   1: 0.025201108618985   4: 0.025193365939378   6: 0.025190258189463   8: 0.025190184258662   3: 0.025190109995970   2: 0.025189985162410   7: 0.025189957531915   9: 0.025189923776787 

test_19968        6: 0.340605421456387   5: 0.311031245872357   3: 0.238936234371617   1: 0.019359102330285   7: 0.015550834347429   9: 0.014961956487459   0: 0.014929306140329   4: 0.014887999290278   2: 0.014869009494531   8: 0.014868890209328 

test_19975        1: 0.644440415425855   0: 0.101176626412959   7: 0.061493934081403   9: 0.060754518741182   4: 0.022038575397708   5: 0.022021695230244   6: 0.022019985650794   2: 0.022018400315605   3: 0.022018020184305   8: 0.022017828559945 

test_19978        5: 0.767753454591041   4: 0.025808783281144   8: 0.025804906173407   3: 0.025804854884271   2: 0.025804790374334   9: 0.025804680657863   1: 0.025804662425545   0: 0.025804659273170   7: 0.025804646003673   6: 0.025804562335553 

test_19981        1: 0.791228981380300   5: 0.023205232280890   6: 0.023198921881289   0: 0.023198424193973   4: 0.023197800323104   8: 0.023195011652115   9: 0.023194179675154   7: 0.023194039114898   2: 0.023193847454488   3: 0.023193562043790 

test_19982        0: 0.404537040882081   6: 0.354605259289279   3: 0.111815586077839   2: 0.030356128954024   9: 0.026580065610678   1: 0.014455231438641   5: 0.014413315975824   8: 0.014412656969500   7: 0.014412413949583   4: 0.014412300852552 

test_19983        5: 0.446280542384520   0: 0.249942790564206   4: 0.106843064203247   2: 0.059531407162911   6: 0.054623423798603   1: 0.016796761064610   7: 0.016612748614536   9: 0.016471395259007   8: 0.016449039468091   3: 0.016448827480270 

test_19984        8: 0.481855832622770   1: 0.354122746549732   9: 0.020609312189317   6: 0.020508574373569   5: 0.020487443398978   0: 0.020485471454935   2: 0.020483007747966   4: 0.020482858274819   3: 0.020482581772298   7: 0.020482171615617 

test_19985        6: 0.468543088428091   7: 0.289831649403952   5: 0.030242527628999   3: 0.030202232548134   9: 0.030198780243598   1: 0.030197975858691   0: 0.030197642268987   8: 0.030195869276307   2: 0.030195145642285   4: 0.030195088700956 

test_19986        6: 0.509140328009391   7: 0.327277756338727   8: 0.052426877708805   5: 0.015903662187260   0: 0.015884836361074   1: 0.015880829150900   4: 0.015873628669875   3: 0.015872000620415   9: 0.015870651560870   2: 0.015869429392684 

test_19989        6: 0.808355217032912   3: 0.049545897031653   9: 0.036704538520180   7: 0.015072099012662   1: 0.015056603274874   0: 0.015055840189695   5: 0.015053616043312   8: 0.015053230778219   2: 0.015051689014002   4: 0.015051269102489 

test_19991        6: 0.623741697914782   3: 0.152537003478201   0: 0.027974385829492   1: 0.027966855580835   8: 0.027964624575940   5: 0.027964313843406   7: 0.027962979147841   2: 0.027962781098217   4: 0.027962729831697   9: 0.027962628699590 

test_19993        6: 0.744362684035063   0: 0.128585454873182   1: 0.015895221788075   3: 0.015890857796760   5: 0.015885003604957   4: 0.015877618147864   8: 0.015876796558532   9: 0.015875560273469   7: 0.015875472762878   2: 0.015875330159221 

test_19996        6: 0.717269639899916   9: 0.063264827077992   8: 0.052532816203701   1: 0.048964548944452   0: 0.036605827125644   3: 0.016274108961355   5: 0.016272176858535   7: 0.016272140653448   2: 0.016272011352356   4: 0.016271902922600 

test_19998        6: 0.597462944351777   9: 0.176825155189440   7: 0.087031533612304   1: 0.064917465413017   0: 0.012299654536559   3: 0.012296023048893   5: 0.012292186986321   8: 0.012292078398176   2: 0.012291656792656   4: 0.012291301670856 

test_20001        1: 0.337813222104533   0: 0.309155445112151   6: 0.270389192663405   7: 0.018158974546101   9: 0.010754444034778   5: 0.010746256052380   8: 0.010745826110819   4: 0.010745798177071   3: 0.010745740959275   2: 0.010745100239486 

test_20005        6: 0.722198836687477   7: 0.122632480542912   0: 0.052144233648389   1: 0.032513428451182   9: 0.011833968429473   5: 0.011787141183515   4: 0.011727103180300   8: 0.011724459337366   2: 0.011719774605876   3: 0.011718573933509 

test_20008        6: 0.692861412246537   4: 0.147823446655484   0: 0.043630107529891   5: 0.016551812285070   9: 0.016525131652421   2: 0.016522703152208   1: 0.016522150679924   7: 0.016521480526521   8: 0.016520929034390   3: 0.016520826237553 

test_20009        6: 0.296618822869297   1: 0.199054229038340   8: 0.197202709797513   3: 0.130606261452987   0: 0.029429764753380   5: 0.029419706567987   9: 0.029417560470885   7: 0.029417188360699   4: 0.029416880582784   2: 0.029416876106126 

test_20012        6: 0.554539703826611   1: 0.296446789622039   8: 0.040697772200860   3: 0.015491677116543   0: 0.015474606507444   5: 0.015470999520506   2: 0.015469820248768   9: 0.015469661895435   7: 0.015469644224978   4: 0.015469324836817 

test_20013        6: 0.830543483869611   9: 0.035379493827290   0: 0.032515743601898   1: 0.014574356122964   5: 0.014498996037894   8: 0.014497932243684   4: 0.014497802052502   7: 0.014497432230171   3: 0.014497386573316   2: 0.014497373440669 

test_20016        8: 0.551195384321567   5: 0.241284000434143   6: 0.025958294506431   9: 0.025942679071685   1: 0.025940007934461   0: 0.025938732355555   7: 0.025936499298301   4: 0.025936057515532   3: 0.025934258893736   2: 0.025934085668589 

test_20018        6: 0.361828852600556   0: 0.147206396137025   3: 0.140932011267797   4: 0.130082835708621   7: 0.110285295991862   8: 0.021939838540884   5: 0.021934170045758   9: 0.021931264319865   1: 0.021930566809450   2: 0.021928768578182 

test_20019        6: 0.507256052531992   0: 0.249491405500056   3: 0.077125034981123   5: 0.043695762877822   7: 0.042766404714129   2: 0.015994126763062   9: 0.015937974593525   4: 0.015912378864113   8: 0.015910431356583   1: 0.015910427817594 

test_20021        6: 0.434511154517859   0: 0.394179104984834   1: 0.068405773015711   8: 0.025115070380216   5: 0.013082239163488   2: 0.012979966825711   9: 0.012935607703181   7: 0.012930605487167   3: 0.012930282372572   4: 0.012930195549262 

test_20025        6: 0.616729241941968   0: 0.196586963390812   8: 0.052317070535687   1: 0.043930135909982   9: 0.015075509187652   5: 0.015073832627339   7: 0.015072013545274   2: 0.015071961186800   4: 0.015071711819265   3: 0.015071559855223 

test_20030        6: 0.676099257790520   0: 0.158707341319419   2: 0.056445331894831   9: 0.041074134549774   1: 0.011283759771554   3: 0.011282319893246   7: 0.011281370034581   5: 0.011278703886960   8: 0.011275306469939   4: 0.011272474389176 

test_20031        6: 0.346229182654969   3: 0.273481311949628   0: 0.186986083903275   9: 0.069604346314218   2: 0.020648714729605   1: 0.020613023344545   4: 0.020610589478032   8: 0.020609857105545   5: 0.020608995394604   7: 0.020607895125578 

test_20032        6: 0.549369328878163   7: 0.218960129201892   0: 0.028962656317088   1: 0.028960891442703   5: 0.028959337564216   9: 0.028958078331163   8: 0.028957537869277   4: 0.028957491619686   3: 0.028957406741505   2: 0.028957142034308 

test_20034        6: 0.494638056537540   8: 0.342174537754030   0: 0.041025223888289   1: 0.017510211518559   9: 0.017450221088558   7: 0.017446379223303   3: 0.017440186547260   5: 0.017438626371139   4: 0.017438385120635   2: 0.017438171950688 

test_20035        1: 0.424836303887756   0: 0.177799524530033   5: 0.153668363980463   8: 0.098210467293293   9: 0.056793328004576   6: 0.017754258629479   2: 0.017735530637659   3: 0.017734335043249   4: 0.017733995091294   7: 0.017733892902196 

test_20037        4: 0.540216256617882   1: 0.194052220640768   6: 0.161983870553280   7: 0.014835912308795   2: 0.014825687540670   3: 0.014819964972572   5: 0.014817864209277   0: 0.014816498805857   8: 0.014816438347711   9: 0.014815286003188 

test_20038        6: 0.564231376649465   0: 0.287775458240378   7: 0.054737648164727   1: 0.023531147102076   8: 0.016386802058347   9: 0.010709532179163   3: 0.010657658983824   5: 0.010657141653338   2: 0.010656617941049   4: 0.010656617027631 

test_20039        6: 0.694853587012504   1: 0.153323676729162   5: 0.033949952341091   0: 0.029668599058235   9: 0.014713182094189   8: 0.014698833387970   4: 0.014698123644639   3: 0.014698100258936   2: 0.014697999345533   7: 0.014697946127742 

test_20045        6: 0.812199834955165   0: 0.062430731342817   5: 0.042411289190712   8: 0.011855872946451   9: 0.011854045116634   1: 0.011851536647468   7: 0.011850887708904   4: 0.011848937838408   2: 0.011848532561062   3: 0.011848331692379 

test_20048        6: 0.804433684272686   0: 0.092811200721039   1: 0.035286953462254   7: 0.009889538896370   2: 0.009598014045117   5: 0.009597173903903   8: 0.009596825708245   9: 0.009596043426789   4: 0.009595333899780   3: 0.009595231663818 

test_20052        6: 0.443361901817804   3: 0.347802482538658   0: 0.057058497970694   4: 0.043490880166525   1: 0.018066073570170   8: 0.018045403034069   7: 0.018043969852381   5: 0.018043810674780   9: 0.018043601832947   2: 0.018043378541972 

test_20055        5: 0.590279962190563   6: 0.193438179186287   9: 0.027043207721080   7: 0.027035621091996   0: 0.027034792385910   2: 0.027034721697151   8: 0.027034573733230   4: 0.027034351588734   1: 0.027032475942178   3: 0.027032114462870 

test_20058        7: 0.416300607159975   6: 0.201793782531634   1: 0.180117669955724   3: 0.089189200197659   9: 0.018819507912495   5: 0.018756573301417   0: 0.018756503070354   8: 0.018755658934314   2: 0.018755427559737   4: 0.018755069376691 

test_20062        6: 0.748002177969801   9: 0.028013813723598   8: 0.028002021741869   0: 0.027997988583278   5: 0.027997859817969   1: 0.027997758265851   7: 0.027997298310662   2: 0.027997060132394   3: 0.027997047187983   4: 0.027996974266595 

test_20063        6: 0.754572836244451   9: 0.027288223262151   8: 0.027277670260184   3: 0.027267236808292   1: 0.027266704442773   5: 0.027266568979277   0: 0.027265932741681   7: 0.027265127582571   2: 0.027264880062656   4: 0.027264819615964 

test_20068        6: 0.502950358992135   7: 0.251634494292832   0: 0.030691439258752   8: 0.030681721042483   1: 0.030675413034155   5: 0.030673581306742   3: 0.030673563686677   9: 0.030673167549173   2: 0.030673140296184   4: 0.030673120540867 

test_20071        6: 0.782515440388543   1: 0.110009611458374   3: 0.013446689272501   0: 0.013435659817380   7: 0.013435254860750   5: 0.013432454544399   8: 0.013432164066617   2: 0.013431785396371   4: 0.013430534531939   9: 0.013430405663127 

test_20079        6: 0.647479004438142   1: 0.223411194859500   0: 0.028493005857684   7: 0.014377737097868   8: 0.014375168898606   5: 0.014373427280099   2: 0.014373043360056   9: 0.014372564689932   4: 0.014372514010389   3: 0.014372339507723 

test_20080        6: 0.777315034827199   0: 0.100698645597735   3: 0.015282220751731   8: 0.015246192138723   1: 0.015245005829905   5: 0.015244491159603   9: 0.015242548013101   7: 0.015242214763296   2: 0.015241988694473   4: 0.015241658224235 

test_20081        6: 0.745104531619296   8: 0.028324770592647   0: 0.028323440231894   9: 0.028321771363821   1: 0.028321675671988   7: 0.028320912085855   5: 0.028320873284100   3: 0.028320811693119   2: 0.028320608369158   4: 0.028320605088121 

test_20082        0: 0.392326608972954   6: 0.377464654621549   9: 0.028778463822082   1: 0.028777292019326   7: 0.028776910287997   8: 0.028776416444580   3: 0.028775244614375   5: 0.028775010980656   2: 0.028774721046830   4: 0.028774677189652 

test_20083        6: 0.557773770845827   0: 0.213277694438498   8: 0.028622169902337   5: 0.028619232089644   1: 0.028619089104585   9: 0.028618769521090   7: 0.028617463170634   4: 0.028617305382947   3: 0.028617286982575   2: 0.028617218561863 

test_20087        6: 0.787737246403150   0: 0.057720247835597   1: 0.045029651138692   3: 0.015767139207333   8: 0.015631185232705   5: 0.015629652907853   2: 0.015621603141537   7: 0.015621185007666   4: 0.015621111667653   9: 0.015620977457813 

test_20089        6: 0.713007142255166   0: 0.144105388656082   1: 0.017862382070581   4: 0.017862179918346   8: 0.017861552765225   7: 0.017860456719598   9: 0.017860448070835   5: 0.017860288622766   3: 0.017860157971038   2: 0.017860002950363 

test_20090        6: 0.431446631563517   8: 0.318081632678798   9: 0.151863304921943   0: 0.014101118427471   7: 0.014097927871536   5: 0.014086805834704   3: 0.014081201949933   1: 0.014080720804001   4: 0.014080455834522   2: 0.014080200113576 

test_20092        6: 0.414653099812976   8: 0.318660429378514   9: 0.145512795811930   3: 0.030980804011514   1: 0.015052402090685   0: 0.015038531551083   5: 0.015027325821073   4: 0.015024984738516   7: 0.015024817422589   2: 0.015024809361119 

test_20093        9: 0.327366466263982   6: 0.254339167680125   2: 0.229173034499851   3: 0.065209497654511   0: 0.058703404703656   5: 0.013044129418292   1: 0.013042171669985   8: 0.013041516443092   4: 0.013040509672869   7: 0.013040101993638 

test_20095        6: 0.736480111956784   0: 0.082037056690031   2: 0.071633914827165   3: 0.044875085483553   8: 0.011048095868362   1: 0.010964722071457   9: 0.010740733179842   5: 0.010740672675370   7: 0.010740294860342   4: 0.010739312387095 

test_20096        1: 0.772499527873535   6: 0.025293435036162   7: 0.025278892857588   0: 0.025277965543017   2: 0.025277541512328   9: 0.025276333520923   5: 0.025276308737767   8: 0.025274344262010   4: 0.025273693912952   3: 0.025271956743719 

test_20101        6: 0.612746677238955   8: 0.205078083523494   9: 0.064811205399900   1: 0.041846665273161   0: 0.019307673216608   7: 0.011259649178952   3: 0.011237905287485   5: 0.011237620479045   2: 0.011237603761673   4: 0.011236916640725 

test_20103        6: 0.414618919580578   8: 0.318744863471241   9: 0.145462326587531   3: 0.030980824926135   1: 0.015052389299733   0: 0.015038738201082   5: 0.015027326244102   4: 0.015024984859678   7: 0.015024817416589   2: 0.015024809413330 

test_20105        5: 0.496645317757260   3: 0.333455831908572   4: 0.021241017666991   1: 0.021237234996662   6: 0.021237175136539   0: 0.021236954147936   9: 0.021236897183680   8: 0.021236691128624   2: 0.021236507161584   7: 0.021236372912152 

test_20106        6: 0.558280519288119   5: 0.228962817003984   9: 0.026596037041329   0: 0.026595713379637   1: 0.026595470017629   8: 0.026595137463760   7: 0.026594051987854   4: 0.026593951648625   2: 0.026593242323130   3: 0.026593059845932 

test_20112        5: 0.740831618010100   4: 0.028799462542222   6: 0.028797711889429   8: 0.028796014688078   1: 0.028795996882921   0: 0.028795956019438   3: 0.028795861090318   7: 0.028795801144473   2: 0.028795790691635   9: 0.028795787041385 

test_20114        6: 0.627013279022026   3: 0.126486060420382   5: 0.125798254628594   0: 0.017250492651112   1: 0.017248025333564   4: 0.017241775797264   9: 0.017240749004131   2: 0.017240672770176   7: 0.017240409978030   8: 0.017240280394721 

test_20116        6: 0.716368787883001   9: 0.132971317835153   0: 0.018886324170022   5: 0.018835052414085   1: 0.018827813633802   7: 0.018823680662038   4: 0.018822269208698   3: 0.018821941573681   8: 0.018821425690455   2: 0.018821386929066 

test_20117        5: 0.772776891653378   4: 0.025249369274337   2: 0.025248299838683   8: 0.025246570929072   6: 0.025246569287084   1: 0.025246561738021   0: 0.025246495118912   3: 0.025246489209867   9: 0.025246439682385   7: 0.025246313268260 

test_20118        4: 0.755919533704743   5: 0.027129136369298   8: 0.027119103762902   0: 0.027119021612939   3: 0.027118974906252   9: 0.027118937323049   2: 0.027118922321765   1: 0.027118818581449   6: 0.027118810034282   7: 0.027118741383320 

test_20119        4: 0.826583245318058   5: 0.019275253223124   0: 0.019268065264672   6: 0.019267870249283   1: 0.019267855360982   8: 0.019267654156595   2: 0.019267521262538   3: 0.019267519493202   9: 0.019267517512107   7: 0.019267498159437 

test_20127        6: 0.762660155867909   5: 0.026449757388684   4: 0.026427935609250   8: 0.026359365140015   0: 0.026356246413396   3: 0.026350847976477   2: 0.026349631005168   7: 0.026349193771360   9: 0.026348881867162   1: 0.026347984960579 

test_20129        5: 0.720384213302446   1: 0.071253114530026   7: 0.053174378674515   4: 0.050534734994120   0: 0.017461339901456   6: 0.017461278591256   3: 0.017434800558712   2: 0.017432979290148   8: 0.017431708066991   9: 0.017431452090329 

test_20132        5: 0.618417609749729   8: 0.190291589506707   4: 0.023914005821244   6: 0.023912225156702   1: 0.023912089156605   0: 0.023911861826545   2: 0.023910287037693   3: 0.023910236581809   9: 0.023910070018222   7: 0.023910025144744 

test_20135        5: 0.779095809264945   8: 0.081466776102271   1: 0.017433644692886   6: 0.017432363319722   4: 0.017431122417214   0: 0.017429049577624   9: 0.017428882053886   2: 0.017428001424066   7: 0.017427306577820   3: 0.017427044569567 

test_20137        9: 0.421185557129263   6: 0.344579773667272   1: 0.061007296121833   0: 0.048045961729449   8: 0.020888488764864   5: 0.020864326498687   4: 0.020860903228165   7: 0.020856832671953   2: 0.020856465310837   3: 0.020854394877677 

test_20138        5: 0.728508727600251   2: 0.115557621105751   4: 0.019495795645856   6: 0.019495410501039   0: 0.019491441840162   9: 0.019490926173089   8: 0.019490687328138   1: 0.019490617882618   7: 0.019489518833227   3: 0.019489253089869 

test_20140        5: 0.771334932483175   4: 0.025409970286094   8: 0.025407199208067   6: 0.025407098474926   1: 0.025407077601829   9: 0.025406958522274   0: 0.025406851581374   3: 0.025406784296773   2: 0.025406571129612   7: 0.025406556415878 

test_20142        1: 0.694897216586843   8: 0.115536809411962   5: 0.051561803587595   6: 0.019727520960872   2: 0.019724338108170   0: 0.019716148870959   4: 0.019713657622840   3: 0.019708498519864   9: 0.019707160987396   7: 0.019706845343499 

test_20145        2: 0.456800631530139   6: 0.329084706791034   0: 0.026768757704660   9: 0.026765570253540   8: 0.026765402038684   5: 0.026764272569775   1: 0.026763936975331   7: 0.026763318482659   3: 0.026762041695240   4: 0.026761361958937 

test_20151        5: 0.422956428701384   1: 0.396382154208080   0: 0.022587660588092   4: 0.022584953127072   6: 0.022582656448369   9: 0.022581836545050   8: 0.022581651386610   3: 0.022580994363051   7: 0.022580848553738   2: 0.022580816078555 

test_20153        2: 0.765460705685446   6: 0.026077063882465   0: 0.026064701752079   9: 0.026064336156973   8: 0.026062890873692   1: 0.026056732098689   5: 0.026055094977580   7: 0.026054075904497   3: 0.026052893076546   4: 0.026051505592034 

test_20159        6: 0.564034704333475   0: 0.289449119602910   1: 0.058152721255763   2: 0.012636389736287   8: 0.012622832925232   9: 0.012621874232495   5: 0.012621699129167   4: 0.012620311732870   7: 0.012620306959712   3: 0.012620040092088 

test_20161        5: 0.566543364040802   7: 0.245497686144838   6: 0.023507337773276   9: 0.023505231109626   4: 0.023493467959812   1: 0.023492795740879   8: 0.023490672794855   0: 0.023489942041530   2: 0.023489796275837   3: 0.023489706118545 

test_20165        5: 0.777327774380484   6: 0.024776274810920   2: 0.024766066257770   0: 0.024740886566139   8: 0.024739385532043   3: 0.024734257734342   1: 0.024731697770369   4: 0.024729757555835   9: 0.024727517330360   7: 0.024726382061737 

test_20166        5: 0.809595654457008   4: 0.021158157706304   6: 0.021156131358964   8: 0.021156106897124   9: 0.021155976454773   1: 0.021155966092340   0: 0.021155677785011   3: 0.021155463119165   2: 0.021155449381757   7: 0.021155416747554 

test_20168        4: 0.408146341386844   5: 0.268781448380595   1: 0.116008887136560   0: 0.076794837347806   6: 0.070688806020485   9: 0.011916934107449   8: 0.011916716834188   2: 0.011915766205930   7: 0.011915232974820   3: 0.011915029605322 

test_20170        5: 0.790412578721567   4: 0.023292417509390   6: 0.023288211327284   0: 0.023288010432545   8: 0.023287490388314   9: 0.023286932677090   1: 0.023286214230068   7: 0.023286123902148   2: 0.023286100017436   3: 0.023285920794156 

test_20174        5: 0.804095930353292   0: 0.066448967784713   3: 0.016200027516413   6: 0.016180854815130   4: 0.016180317548365   9: 0.016179439705237   1: 0.016179086041555   8: 0.016178866071259   7: 0.016178266899491   2: 0.016178243264545 

test_20176        5: 0.840010379599063   6: 0.017790791998196   4: 0.017780433106099   9: 0.017777997013313   1: 0.017775266678978   3: 0.017773364331961   8: 0.017773177992697   0: 0.017773122607641   7: 0.017772741253028   2: 0.017772725419022 

test_20180        4: 0.482284990712306   5: 0.363713231734197   6: 0.019251433984608   8: 0.019250443052768   0: 0.019250441792689   9: 0.019250387651869   1: 0.019249940564807   7: 0.019249799623849   2: 0.019249717076564   3: 0.019249613806341 

test_20181        5: 0.478362796094162   8: 0.289504112268620   4: 0.029023914970698   3: 0.029015817014562   2: 0.029015722140517   9: 0.029015711997953   7: 0.029015571753140   6: 0.029015474582227   0: 0.029015469097638   1: 0.029015410080483 

test_20186        6: 0.698341186793782   1: 0.144055624033255   0: 0.071922897339149   8: 0.026698035695662   4: 0.009873807034333   5: 0.009831708821740   7: 0.009829636405118   3: 0.009817644266420   2: 0.009815474180048   9: 0.009813985430494 

test_20187        5: 0.543936400805479   2: 0.289135073806015   6: 0.053771799006776   8: 0.016174910328132   0: 0.016166155494053   9: 0.016165097569584   4: 0.016163719128324   1: 0.016162709647841   7: 0.016162653585666   3: 0.016161480628130 

test_20189        5: 0.515419077784617   8: 0.299148175438059   6: 0.023183386838133   4: 0.023181377680837   0: 0.023178344687665   9: 0.023178231830373   1: 0.023177960516778   3: 0.023177863648824   2: 0.023177813459608   7: 0.023177768115106 

test_20191        5: 0.810078035186670   4: 0.021105389257198   6: 0.021103424831136   8: 0.021102483668185   9: 0.021102124246723   0: 0.021102057888263   1: 0.021101792386800   7: 0.021101628881172   2: 0.021101548869765   3: 0.021101514784088 

test_20193        6: 0.384712171933524   1: 0.369769035233670   4: 0.030699206390648   0: 0.030692491124013   5: 0.030688843649915   2: 0.030687966535668   7: 0.030687690092152   3: 0.030687664579784   9: 0.030687473962175   8: 0.030687456498451 

test_20195        5: 0.761120296874273   4: 0.026546705320482   2: 0.026542069344554   8: 0.026541807418937   3: 0.026541707287847   0: 0.026541557913454   1: 0.026541553115249   9: 0.026541454379652   7: 0.026541443828361   6: 0.026541404517190 

test_20206        5: 0.787075787445286   4: 0.023661728718472   6: 0.023658477856870   8: 0.023658034106879   9: 0.023657942170019   0: 0.023657800878385   2: 0.023657639718946   1: 0.023657560761796   3: 0.023657526349581   7: 0.023657501993767 

test_20207        5: 0.744830981394166   1: 0.093737699284424   6: 0.020180896158037   8: 0.020180165668607   4: 0.020179644885114   0: 0.020178508326731   9: 0.020178220627239   7: 0.020178106225733   3: 0.020177903286848   2: 0.020177874143102 

test_20208        6: 0.477007462057423   5: 0.385893074224468   0: 0.029645208689329   7: 0.015375538249752   1: 0.015365915473689   4: 0.015356432446931   8: 0.015349158491151   2: 0.015336766149561   9: 0.015335518336249   3: 0.015334925881447 

test_20210        1: 0.390760978487801   6: 0.359052767904962   0: 0.073169155146186   5: 0.057480221348828   8: 0.019928624485530   4: 0.019924330032681   9: 0.019921634974421   2: 0.019921180621364   7: 0.019920766343830   3: 0.019920340654397 

test_20213        5: 0.492908985399509   2: 0.323542712498887   4: 0.022948457378544   8: 0.022943324368434   6: 0.022943205574967   9: 0.022943001240589   3: 0.022942623686998   0: 0.022942611901965   7: 0.022942609468940   1: 0.022942468481168 

test_20214        9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

test_20215        5: 0.764687135866062   4: 0.026149862726025   8: 0.026145578613783   6: 0.026145559169925   9: 0.026145432589933   0: 0.026145419497617   2: 0.026145307151110   1: 0.026145270818656   3: 0.026145262226786   7: 0.026145171340102 

test_20216        6: 0.629136572739508   1: 0.149797695241905   5: 0.118454732788651   0: 0.014708329027994   9: 0.014666772843674   4: 0.014650509696544   8: 0.014646953822867   2: 0.014646270588220   7: 0.014646130913510   3: 0.014646032337127 

test_20217        5: 0.843487783897317   4: 0.017392888409708   6: 0.017390206897526   0: 0.017390047702085   1: 0.017390009740056   8: 0.017389918375878   9: 0.017389869542951   7: 0.017389854892646   2: 0.017389749565962   3: 0.017389670975869 

test_20220        5: 0.396555095624516   1: 0.380795754462675   7: 0.091209465550309   6: 0.018856044889764   0: 0.018776169258251   4: 0.018763881977225   9: 0.018761221847516   8: 0.018761078506250   2: 0.018760720894187   3: 0.018760566989306 

test_20221        5: 0.759121200508417   4: 0.026767888776192   8: 0.026764090092998   3: 0.026763965605996   2: 0.026763923418840   9: 0.026763832490290   7: 0.026763809648353   0: 0.026763787982223   1: 0.026763752211109   6: 0.026763749265581 

test_20223        4: 0.697550539980688   0: 0.114423575305930   6: 0.023513544775856   5: 0.023512263488317   1: 0.023502400537375   8: 0.023500357014683   9: 0.023500264276222   2: 0.023499758185442   7: 0.023498691840351   3: 0.023498604595136 

test_20226        5: 0.746241252760622   7: 0.063017705932366   3: 0.060561008365884   4: 0.018601546776585   6: 0.018597014008484   8: 0.018597011456545   9: 0.018596336958510   1: 0.018596295619584   0: 0.018596201093829   2: 0.018595627027591 

test_20228        5: 0.552292960747949   3: 0.281665642014979   4: 0.020756859689528   6: 0.020756268019449   1: 0.020755355780051   2: 0.020755101443426   0: 0.020754817076393   9: 0.020754715999777   8: 0.020754305236549   7: 0.020753973991900 

test_20230        6: 0.615324752111459   1: 0.218152279367378   3: 0.051005640705036   7: 0.016510518944001   0: 0.016506387271094   2: 0.016501367448782   5: 0.016500363004220   8: 0.016499880872612   9: 0.016499652735526   4: 0.016499157539892 

test_20231        6: 0.699136054806564   5: 0.102123327207335   1: 0.093281639169429   4: 0.021756006956406   2: 0.014112707247445   0: 0.013923795751659   8: 0.013921421747928   9: 0.013916003806553   7: 0.013914619130001   3: 0.013914424176679 

test_20232        6: 0.568914174614114   5: 0.136021237424121   2: 0.102093540625406   0: 0.082842693900456   8: 0.035972043603721   1: 0.023674580323255   4: 0.012621583364475   7: 0.012620323090639   9: 0.012620150650178   3: 0.012619672403636 

test_20233        5: 0.768208126355447   4: 0.025757801473102   6: 0.025755328156685   8: 0.025754802800459   9: 0.025754622044122   0: 0.025754027039616   2: 0.025753871375948   7: 0.025753838847993   3: 0.025753805436700   1: 0.025753776469928 

test_20234        5: 0.806927555084759   1: 0.021454358365660   4: 0.021453000467656   6: 0.021452290769190   7: 0.021452282082726   0: 0.021452186337750   9: 0.021452119663885   8: 0.021452090184821   3: 0.021452068718296   2: 0.021452048325258 

test_20235        5: 0.795796090719145   4: 0.022692540422275   2: 0.022691419834866   8: 0.022688907950642   6: 0.022688896864869   9: 0.022688617069659   1: 0.022688393173432   7: 0.022688390060044   0: 0.022688376300947   3: 0.022688367604121 

test_20237        5: 0.751281203853976   9: 0.061695568313408   7: 0.054013606325705   4: 0.019007163436940   0: 0.019000647661440   6: 0.019000587996267   1: 0.019000450316408   2: 0.019000284985596   8: 0.019000265396625   3: 0.019000221713635 

test_20239        6: 0.681789489499573   5: 0.137605084096171   8: 0.050117169022608   0: 0.018649222955588   1: 0.018642250883849   7: 0.018640096045452   9: 0.018639305049688   4: 0.018639284342680   2: 0.018639141440244   3: 0.018638956664148 

test_20241        5: 0.783312782601145   6: 0.077166129545425   9: 0.017468956894088   3: 0.017454931822386   8: 0.017446759122064   0: 0.017431721417097   2: 0.017430581828188   1: 0.017430423388965   4: 0.017429530919825   7: 0.017428182460818 

test_20247        6: 0.771256643870187   9: 0.081541393503230   5: 0.018406252676883   1: 0.018400884785022   4: 0.018400548531143   0: 0.018399541880280   8: 0.018399164351914   7: 0.018398685526133   3: 0.018398508477969   2: 0.018398376397239 

test_20248        9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

test_20249        5: 0.421194464569761   6: 0.264460902380366   9: 0.148838738002936   4: 0.023648001565031   8: 0.023643418275826   1: 0.023643122061382   7: 0.023643059258371   2: 0.023643016723405   0: 0.023642969293265   3: 0.023642307869657 

test_20251        5: 0.445226256656408   3: 0.317956329377612   6: 0.029606310397846   4: 0.029605817560600   9: 0.029602783309261   8: 0.029601005949238   1: 0.029600991642134   0: 0.029600696242895   7: 0.029599909778873   2: 0.029599899085133 

test_20252        5: 0.497543998729679   3: 0.303674093525898   4: 0.024852776308758   1: 0.024847768619011   0: 0.024847272223435   8: 0.024847013833927   2: 0.024846878858964   6: 0.024846767364160   9: 0.024846753679577   7: 0.024846676856592 

test_20255        5: 0.746210923738109   1: 0.081224304888706   4: 0.021573701630367   8: 0.021572972589111   3: 0.021569748145476   2: 0.021569725530532   0: 0.021569710931068   9: 0.021569681499327   6: 0.021569621464454   7: 0.021569609582850 

test_20256        5: 0.816755517539341   6: 0.020362440722300   4: 0.020361175579770   8: 0.020361126764816   9: 0.020360690512539   0: 0.020360478062968   1: 0.020360410326106   2: 0.020359508793122   7: 0.020359426372216   3: 0.020359225326823 

test_20257        5: 0.746870320614168   4: 0.028129259758734   8: 0.028125264510535   3: 0.028125151390339   2: 0.028125123355000   0: 0.028125058265053   9: 0.028124983231273   7: 0.028124974830236   1: 0.028124942903273   6: 0.028124921141389 

test_20258        6: 0.388481718947462   7: 0.262056452840712   5: 0.112564735462469   8: 0.107873544783354   0: 0.021528503935592   9: 0.021500848886389   1: 0.021499260230864   4: 0.021498399463368   2: 0.021498378509869   3: 0.021498156939920 

test_20259        6: 0.548114487359417   0: 0.288831174734370   1: 0.097280170449443   4: 0.019097013759180   7: 0.008022509894081   8: 0.007889740621922   3: 0.007706816470011   5: 0.007691035999509   9: 0.007683608375150   2: 0.007683442336916 

test_20261        6: 0.580214501408591   3: 0.180168201972056   8: 0.076186331512543   7: 0.036593933747586   4: 0.035387702970573   1: 0.018292056085877   9: 0.018290355519680   0: 0.018289930986369   5: 0.018288538508062   2: 0.018288447288664 

test_20262        6: 0.671267495870465   0: 0.150081563550981   8: 0.105659127707662   1: 0.018246344581828   5: 0.011555109782085   2: 0.008785847485159   7: 0.008633093978592   9: 0.008592720266327   4: 0.008589484968683   3: 0.008589211808218 

test_20263        8: 0.525021664455245   0: 0.202031235171487   6: 0.155846084274116   1: 0.016729921279131   7: 0.016729861035503   5: 0.016729449860779   9: 0.016728922377734   4: 0.016727715371826   2: 0.016727661630338   3: 0.016727484543841 

test_20264        6: 0.877373957789597   5: 0.013626457182795   8: 0.013625608309312   0: 0.013625288346347   9: 0.013625059494467   1: 0.013625004373180   4: 0.013624867207786   7: 0.013624671007056   3: 0.013624563115069   2: 0.013624523174390 

test_20265        6: 0.742592382221277   0: 0.028601748167792   7: 0.028601657870072   9: 0.028601579547874   8: 0.028601393990262   1: 0.028600876505852   3: 0.028600756013569   5: 0.028600132213370   2: 0.028599841313529   4: 0.028599632156403 

test_20266        5: 0.776058600456598   4: 0.024884793936005   6: 0.024882507240938   8: 0.024882368841396   9: 0.024882249463658   0: 0.024882056486528   2: 0.024881898823664   1: 0.024881868787263   3: 0.024881849252172   7: 0.024881806711777 

test_20267        7: 0.565035974557631   6: 0.197111915853332   5: 0.072896665216198   0: 0.055339479346807   1: 0.018283746494104   9: 0.018273117942085   2: 0.018271355607540   8: 0.018266584340227   3: 0.018263803808554   4: 0.018257356833522 

test_20269        5: 0.470474383686434   8: 0.332758013335426   4: 0.024601139256859   6: 0.024595711094677   9: 0.024595431879285   3: 0.024595135401961   2: 0.024595131977383   0: 0.024595128565500   7: 0.024594969831872   1: 0.024594954970602 

test_20270        6: 0.531730207647568   1: 0.297177479189082   2: 0.068817330728469   9: 0.018210226135716   3: 0.016933933420280   0: 0.016374408690652   5: 0.012715171582566   4: 0.012680700199364   7: 0.012680643735902   8: 0.012679898670401 

test_20273        5: 0.526833616995153   4: 0.301390363898730   6: 0.021472957679963   9: 0.021472367952478   8: 0.021472187976686   7: 0.021471966518060   0: 0.021471906470077   1: 0.021471731368032   2: 0.021471517650788   3: 0.021471383490033 

test_20274        4: 0.436016897355935   5: 0.384187401321373   6: 0.022477761239440   9: 0.022474489314219   0: 0.022474457092368   1: 0.022474286559489   8: 0.022473880577869   3: 0.022473690766513   2: 0.022473583260101   7: 0.022473552512693 

test_20275        6: 0.761924300878497   3: 0.026468489104084   2: 0.026453868194468   9: 0.026451304027049   0: 0.026451253978041   5: 0.026451235303901   8: 0.026450925471531   1: 0.026450464523769   7: 0.026449246983133   4: 0.026448911535527 

test_20278        4: 0.707028152580414   9: 0.100336318450465   5: 0.024083023413365   0: 0.024081478192306   1: 0.024079106746981   3: 0.024078811986297   6: 0.024078646482298   8: 0.024078235467903   2: 0.024078214135603   7: 0.024078012544367 

test_20279        5: 0.827573286022540   4: 0.019160668154794   6: 0.019158938181380   0: 0.019158604726538   8: 0.019158592778486   1: 0.019158313772010   9: 0.019158260918212   3: 0.019157876387264   2: 0.019157778711075   7: 0.019157680347701 

test_20284        4: 0.774755085531379   5: 0.025033994557352   8: 0.025026549204210   3: 0.025026480639828   2: 0.025026403461753   7: 0.025026398737394   0: 0.025026315037635   9: 0.025026310337661   1: 0.025026301312247   6: 0.025026161180541 

test_20286        5: 0.671178453874153   9: 0.170293905055802   8: 0.019829235823429   0: 0.019816215838901   4: 0.019816033088733   1: 0.019813646646998   6: 0.019813410649831   7: 0.019813336787027   2: 0.019812976243898   3: 0.019812785991228 

test_20291        5: 0.637555301697738   0: 0.182325439967619   7: 0.050730828593901   4: 0.018487589003232   6: 0.018483698031948   1: 0.018483688316451   9: 0.018483433426657   8: 0.018483409341535   3: 0.018483316764958   2: 0.018483294855961 

test_20297        5: 0.730886803476279   1: 0.029935135081583   6: 0.029910475515545   0: 0.029905830165313   4: 0.029898349732334   7: 0.029893591879307   9: 0.029893510648030   8: 0.029892652721328   2: 0.029892315217606   3: 0.029891335562675 

test_20298        0: 0.818129903754688   1: 0.020212964262005   5: 0.020210919250189   6: 0.020210157710333   4: 0.020207128780619   2: 0.020206152777383   9: 0.020206031925961   8: 0.020205637996638   7: 0.020205620713978   3: 0.020205482828205 

test_20299        5: 0.587938502936662   3: 0.139758870698364   2: 0.098959680570503   4: 0.075056201201330   6: 0.016384314809274   0: 0.016383574241797   8: 0.016380866421454   1: 0.016379791311948   9: 0.016379609957353   7: 0.016378587851314 

test_20300        5: 0.401285626044348   4: 0.354998205762612   0: 0.101221591252103   3: 0.048999435577604   9: 0.015585082814019   6: 0.015584463372636   1: 0.015582570639994   7: 0.015581363269309   8: 0.015580892672049   2: 0.015580768595326 

test_20302        4: 0.772763150302432   5: 0.025257908198563   8: 0.025247525758335   0: 0.025247521530828   3: 0.025247431718855   2: 0.025247402581325   1: 0.025247372640896   9: 0.025247342289424   6: 0.025247196702385   7: 0.025247148276956 

test_20304        5: 0.497605599518385   6: 0.261385740235232   8: 0.109030654813246   4: 0.042794129069200   7: 0.014865369235931   1: 0.014864662313377   0: 0.014864503788900   9: 0.014863762181604   2: 0.014862874184431   3: 0.014862704659693 

test_20306        6: 0.752302019160696   1: 0.027524590068830   0: 0.027524196650229   5: 0.027522418439897   4: 0.027521753343674   2: 0.027521318066098   7: 0.027521287567758   9: 0.027520870075228   3: 0.027520866198374   8: 0.027520680429216 

test_20308        5: 0.821681362260258   8: 0.046085760718775   0: 0.016531879156942   4: 0.016530371164116   6: 0.016530254240515   1: 0.016528541370020   9: 0.016528238975065   7: 0.016527914823719   2: 0.016527849353486   3: 0.016527827937104 

test_20309        5: 0.527252053102810   4: 0.300971939999648   6: 0.021472954724261   9: 0.021472365864846   8: 0.021472186334502   7: 0.021471964775094   0: 0.021471905150391   1: 0.021471730222858   2: 0.021471516880301   3: 0.021471382945291 

test_20310        5: 0.409732927062650   9: 0.365717621604550   4: 0.028073205881335   0: 0.028068997827372   8: 0.028068405450980   3: 0.028067982053907   2: 0.028067837747828   7: 0.028067727431781   1: 0.028067696578211   6: 0.028067598361387 

test_20311        1: 0.437907030793160   5: 0.372991238505311   0: 0.045027532702997   6: 0.029616029712648   2: 0.019599731611041   9: 0.018973915135675   4: 0.018971817828974   7: 0.018971398300189   8: 0.018970746056218   3: 0.018970559353787 

test_20314        5: 0.773332486897637   4: 0.025187737375463   8: 0.025185061968819   0: 0.025185025682920   3: 0.025185008323186   2: 0.025184994352496   1: 0.025184950289919   6: 0.025184943229765   9: 0.025184935581797   7: 0.025184856297997 

test_20318        9: 0.555727402149248   6: 0.194693690033177   1: 0.031211286588819   5: 0.031199557518589   2: 0.031198279263174   3: 0.031196326863224   7: 0.031195053102899   0: 0.031193885938796   8: 0.031192415300310   4: 0.031192103241764 

test_20319        5: 0.760212461618719   7: 0.085670162976207   4: 0.019268781098947   6: 0.019264714087215   0: 0.019264381193686   1: 0.019264087908279   9: 0.019264066139801   8: 0.019264055878141   2: 0.019263675356051   3: 0.019263613742953 

test_20321        6: 0.669144606087629   1: 0.165017992643817   5: 0.020734780782574   0: 0.020733716263318   4: 0.020729251608706   2: 0.020728492181357   8: 0.020728128562851   9: 0.020727846747825   3: 0.020727726090403   7: 0.020727459031521 

test_20324        5: 0.771076753635704   7: 0.082530033357301   4: 0.018301815454042   0: 0.018299425726440   6: 0.018299264970777   8: 0.018299098601520   9: 0.018298737335132   1: 0.018298677279740   2: 0.018298184808814   3: 0.018298008830529 

test_20328        4: 0.549385644438605   1: 0.245662085496068   6: 0.025624939457514   5: 0.025623241930542   0: 0.025620401268876   9: 0.025619292145026   2: 0.025617186159664   7: 0.025616341647871   3: 0.025615564515510   8: 0.025615302940324 

test_20332        5: 0.475551219988227   2: 0.319887023126211   0: 0.077400972322236   1: 0.018167953438825   4: 0.018167415629994   6: 0.018166194424662   8: 0.018165088760452   9: 0.018164802476436   3: 0.018164735892192   7: 0.018164593940765 

test_20333        6: 0.426948723835092   8: 0.237301021166768   9: 0.104023130945107   0: 0.098185333143558   1: 0.067243615557442   7: 0.021842149232940   3: 0.011117190489058   5: 0.011113879002981   2: 0.011112703142940   4: 0.011112253484114 

test_20334        5: 0.775164564653077   6: 0.024983771276795   4: 0.024983462196372   8: 0.024982508812036   9: 0.024981844334143   0: 0.024980985449703   1: 0.024980890215247   7: 0.024980769328277   2: 0.024980728488317   3: 0.024980475246034 

test_20335        6: 0.693953592629306   5: 0.095485065492002   1: 0.085475203058115   0: 0.053632757665984   7: 0.011911853859694   3: 0.011908784060291   8: 0.011908620260558   9: 0.011908465120763   4: 0.011907853136570   2: 0.011907804716717 

test_20337        4: 0.784221766249208   5: 0.023981835230342   6: 0.023976511423545   8: 0.023975397576865   9: 0.023975219346126   1: 0.023974167910797   0: 0.023974104490614   7: 0.023973753083333   2: 0.023973660836989   3: 0.023973583852182 

test_20339        5: 0.827636532041244   4: 0.019153374067227   6: 0.019152213388843   2: 0.019151707223672   1: 0.019151219886248   9: 0.019151190252185   3: 0.019151060884590   0: 0.019150993797915   8: 0.019150866278952   7: 0.019150842179124 

test_20340        5: 0.728092790805553   7: 0.113133374014403   6: 0.019894514310609   4: 0.019842575924732   8: 0.019840060544750   9: 0.019839789816962   0: 0.019839507533208   1: 0.019839316439028   2: 0.019839090883000   3: 0.019838979727754 

test_20341        6: 0.384013146555213   9: 0.241101167881753   1: 0.171514185839387   0: 0.116199360065835   5: 0.014530930337989   2: 0.014529062119424   7: 0.014528261250566   8: 0.014528048302266   3: 0.014528042436633   4: 0.014527795210935 

test_20343        8: 0.492231846637482   7: 0.261871160728402   6: 0.030744046062834   5: 0.030739850243527   0: 0.030736533136125   1: 0.030736111155252   9: 0.030735775777311   3: 0.030735598665987   4: 0.030734790308256   2: 0.030734287284823 

test_20344        5: 0.622241606866564   6: 0.111796868263109   0: 0.081475555459365   8: 0.079965551258746   4: 0.017421639219175   1: 0.017420498985271   9: 0.017419960442502   7: 0.017419873119254   2: 0.017419299472638   3: 0.017419146913377 

test_20347        6: 0.535127565725137   7: 0.223058437108195   0: 0.030233150456015   1: 0.030229311630360   9: 0.030225603945991   3: 0.030225362638069   5: 0.030225288668373   8: 0.030225229285515   2: 0.030225125329624   4: 0.030224925212721 

test_20348        6: 0.746767805823297   3: 0.105926946926164   0: 0.018414730812992   1: 0.018413827464584   9: 0.018413063842301   8: 0.018413017337642   7: 0.018412878051715   5: 0.018412750025842   2: 0.018412535713436   4: 0.018412444002027 

test_20352        9: 0.623752122915392   6: 0.191082670731458   1: 0.023170265861082   5: 0.023157393827202   0: 0.023144573998284   3: 0.023142477619035   2: 0.023140238038797   4: 0.023137823692960   8: 0.023137232811475   7: 0.023135200504314 

test_20353        5: 0.758367271666241   4: 0.026851093203242   3: 0.026847841473163   8: 0.026847783135881   0: 0.026847755414542   2: 0.026847752265863   9: 0.026847680833989   1: 0.026847679267349   7: 0.026847599907654   6: 0.026847542832077 

test_20357        1: 0.403306799971690   5: 0.392142985616877   4: 0.025575425659422   8: 0.025568348269428   3: 0.025568112015292   2: 0.025567916437299   9: 0.025567682426556   7: 0.025567672845795   0: 0.025567624169187   6: 0.025567432588454 

test_20358        5: 0.818507249059713   4: 0.020167138543165   8: 0.020166621194601   6: 0.020166396113930   1: 0.020166172570267   0: 0.020165858354853   9: 0.020165782137378   2: 0.020164987981284   7: 0.020164912023984   3: 0.020164882020824 

test_20363        5: 0.569818096300396   8: 0.239681812026958   7: 0.071078371227730   0: 0.030874464208257   1: 0.014779537343793   4: 0.014755858450696   6: 0.014753697721762   3: 0.014752828621284   9: 0.014752807957391   2: 0.014752526141733 

test_20364        5: 0.761047130275203   1: 0.026554715816420   4: 0.026553472118142   0: 0.026549664878330   3: 0.026549288753091   8: 0.026549281918523   6: 0.026549261219247   2: 0.026549232075635   7: 0.026548997494204   9: 0.026548955451206 

test_20365        5: 0.797675978525981   6: 0.022484217431936   4: 0.022482079009209   8: 0.022481523166744   9: 0.022480148407121   1: 0.022479762227739   0: 0.022479591323292   7: 0.022479043364914   2: 0.022478953501464   3: 0.022478703041600 

test_20366        6: 0.686291683905665   7: 0.085768707197702   8: 0.083250580207444   0: 0.020673814148763   1: 0.020670069209139   5: 0.020669871164633   9: 0.020669444169882   4: 0.020668908586364   2: 0.020668678194716   3: 0.020668243215693 

test_20367        5: 0.772744652281015   6: 0.025253811326568   4: 0.025252281958568   1: 0.025251078421546   9: 0.025250552188248   0: 0.025250159465794   8: 0.025249959336775   3: 0.025249228665489   7: 0.025249221139578   2: 0.025249055216418 

test_20368        5: 0.579416850428735   7: 0.203495572480913   4: 0.027143027029327   8: 0.027135393090283   3: 0.027135078744650   2: 0.027134979740321   9: 0.027134946924071   0: 0.027134740173813   6: 0.027134734393466   1: 0.027134676994421 

test_20370        5: 0.813229210039564   0: 0.020760392873092   6: 0.020752959524402   4: 0.020751848458098   9: 0.020751667552245   1: 0.020751507598328   8: 0.020751331037079   2: 0.020750782126291   3: 0.020750205047953   7: 0.020750095742949 

test_20371        5: 0.658399728483456   3: 0.163042034718546   8: 0.022320983882928   4: 0.022320660710091   1: 0.022320498571406   6: 0.022320104194971   0: 0.022319517740373   9: 0.022319458143056   2: 0.022318722215702   7: 0.022318291339471 

test_20372        5: 0.756953670007021   1: 0.027017470446396   4: 0.027005749361786   0: 0.027004420764634   6: 0.027003343695421   8: 0.027003162063008   3: 0.027003129090615   9: 0.027003046777736   7: 0.027003016758981   2: 0.027002991034401 

test_20373        5: 0.558191692038113   7: 0.215692490110503   4: 0.028267933599699   8: 0.028264093344160   6: 0.028264078027970   3: 0.028264066174405   2: 0.028263961206042   0: 0.028263940403409   1: 0.028263910556740   9: 0.028263834538959 

test_20374        5: 0.801197046133450   1: 0.022095187177405   0: 0.022092659110635   4: 0.022092023225265   6: 0.022088357901770   8: 0.022087165166710   3: 0.022086987467526   2: 0.022086901747335   7: 0.022086856443242   9: 0.022086815626662 

test_20376        5: 0.454262818089416   9: 0.330630231101735   4: 0.026894298569868   3: 0.026887793266592   8: 0.026887709923249   2: 0.026887579889412   0: 0.026887567035252   1: 0.026887358044649   7: 0.026887356956366   6: 0.026887287123462 

test_20377        6: 0.648089558342513   7: 0.154119929164242   0: 0.024732272469221   1: 0.024724700492888   3: 0.024722449839034   9: 0.024722354162021   5: 0.024722254627906   8: 0.024722214649367   2: 0.024722174020300   4: 0.024722092232508 

test_20378        5: 0.821660152461087   6: 0.019817360261920   4: 0.019816432708118   8: 0.019816160475068   9: 0.019815670892496   0: 0.019815438989989   1: 0.019815310324687   2: 0.019814586744414   7: 0.019814524389095   3: 0.019814362753126 

test_20379        1: 0.412960857594436   2: 0.401377860807565   6: 0.039136436891155   5: 0.020940999800921   0: 0.020933711865622   9: 0.020930829250381   4: 0.020930669881345   8: 0.020929897971305   7: 0.020929748567056   3: 0.020928987370214 

test_20380        5: 0.595509179218629   2: 0.210409673335376   4: 0.024266947722156   6: 0.024259575451765   8: 0.024259544774226   9: 0.024259183250838   1: 0.024259160514939   0: 0.024259069190618   3: 0.024258926908579   7: 0.024258739632873 

test_20381        4: 0.402530705575373   9: 0.367767219153761   5: 0.028721702751860   6: 0.028714544969874   8: 0.028711210061135   3: 0.028711125996287   0: 0.028710992961429   2: 0.028710919343644   1: 0.028710804326552   7: 0.028710774860084 

test_20382        6: 0.789673293628606   2: 0.060053573229940   5: 0.042007765177661   3: 0.030532749168612   0: 0.013136194535965   8: 0.013050359954439   1: 0.012956365386023   9: 0.012864598297774   7: 0.012863963609743   4: 0.012861137011237 

test_20384        5: 0.741729307508245   7: 0.105932583445640   4: 0.019044481541260   6: 0.019042396481230   8: 0.019042295789261   9: 0.019041967583388   0: 0.019041949344591   1: 0.019041886779271   2: 0.019041627755900   3: 0.019041503771216 

test_20385        5: 0.715159826721441   0: 0.112743836961925   4: 0.021514387327517   3: 0.021513248321900   6: 0.021512921057669   9: 0.021511393068798   1: 0.021511286380670   8: 0.021511107151333   2: 0.021511029672210   7: 0.021510963336537 

test_20386        5: 0.590705711333251   4: 0.237326802025793   8: 0.021505118371503   6: 0.021496827827445   0: 0.021494658280513   1: 0.021494549237506   9: 0.021494504707943   2: 0.021494195362356   3: 0.021493864950366   7: 0.021493767903323 

test_20388        5: 0.742911861877739   4: 0.028569243136230   3: 0.028565033154686   8: 0.028565012161769   2: 0.028564957979751   0: 0.028564879815153   7: 0.028564799895856   1: 0.028564763815898   9: 0.028564751240283   6: 0.028564696922634 

test_20389        6: 0.803822942180474   3: 0.058642221830008   8: 0.032112777375732   0: 0.024922246976553   7: 0.013433267314367   5: 0.013429654692821   1: 0.013419320006640   4: 0.013412683175982   2: 0.013403207274730   9: 0.013401679172693 

test_20391        5: 0.795930149101782   4: 0.022677336744887   6: 0.022675178641469   0: 0.022674259416464   8: 0.022674176820212   9: 0.022674027155807   3: 0.022673751990765   2: 0.022673749092203   7: 0.022673732305348   1: 0.022673638731062 

test_20392        5: 0.751713623356512   0: 0.116755849488767   6: 0.016444809264109   4: 0.016443007818515   1: 0.016441261918564   8: 0.016440949264325   7: 0.016440280779699   3: 0.016440220193908   9: 0.016440115961698   2: 0.016439881953903 

test_20393        5: 0.497631982908247   4: 0.346663921858462   1: 0.037202442984881   0: 0.016960618273442   6: 0.016926113997257   9: 0.016923919394174   8: 0.016923266357408   7: 0.016923068292288   2: 0.016922418589429   3: 0.016922247344412 

test_20395        5: 0.598392521277268   7: 0.235761304519531   4: 0.020733192150474   6: 0.020732020677074   0: 0.020730760792779   9: 0.020730532870512   8: 0.020730026414797   2: 0.020729954979230   1: 0.020729849111618   3: 0.020729837206717 

test_20396        1: 0.550324660492946   6: 0.317255318033534   5: 0.016612906603659   0: 0.016555321603074   4: 0.016550341281253   3: 0.016542517187985   8: 0.016540202932296   2: 0.016539710179694   9: 0.016539515428874   7: 0.016539506256685 

test_20398        5: 0.418781923900977   4: 0.188467076529802   6: 0.160939878643586   3: 0.111461288384029   1: 0.020062333801677   0: 0.020058571216444   9: 0.020058185558380   8: 0.020057937170865   2: 0.020057332434622   7: 0.020055472359618 

test_20400        5: 0.783281749181534   4: 0.024085289108902   8: 0.024079371899236   3: 0.024079238131260   2: 0.024079173778177   7: 0.024079087145088   9: 0.024079054894224   1: 0.024079045829617   0: 0.024079042537815   6: 0.024078947494146 

test_20401        5: 0.611345050530265   2: 0.228904114650799   4: 0.019971909465314   6: 0.019969357313677   0: 0.019968455455444   1: 0.019968454354848   8: 0.019968195700075   7: 0.019968182241235   3: 0.019968152897645   9: 0.019968127390697 

test_20406        6: 0.749645112346509   5: 0.062057983786175   8: 0.023690433141199   4: 0.023536259937382   2: 0.023516306609237   9: 0.023512190716888   3: 0.023511990939086   1: 0.023511098118045   7: 0.023509690358610   0: 0.023508934046868 

test_20407        5: 0.805138268085590   4: 0.021653935038669   6: 0.021652083400209   0: 0.021651142400333   8: 0.021650875237526   7: 0.021650800971891   9: 0.021650772582777   1: 0.021650761634693   3: 0.021650689800860   2: 0.021650670847452 

test_20409        0: 0.460841084576435   6: 0.417069799281465   7: 0.015262936719059   8: 0.015262796701135   1: 0.015262231368332   9: 0.015260989860258   2: 0.015260452642736   5: 0.015260191280909   4: 0.015259775607499   3: 0.015259741962172 

test_20412        5: 0.796168895438189   4: 0.022649354239619   6: 0.022649161412983   8: 0.022648381009396   9: 0.022647946076872   0: 0.022647378093234   1: 0.022647303053988   7: 0.022647279576114   2: 0.022647228469172   3: 0.022647072630433 

test_20414        5: 0.744102962657318   4: 0.028438256832604   8: 0.028432639732428   3: 0.028432446654914   2: 0.028432376404889   9: 0.028432367480351   7: 0.028432307866497   0: 0.028432223792371   6: 0.028432221885601   1: 0.028432196693027 

test_20415        5: 0.793708343079748   6: 0.022927235847258   4: 0.022921835984634   7: 0.022921365933898   1: 0.022921099346446   9: 0.022920638549538   8: 0.022920628203308   0: 0.022920397636023   3: 0.022919272086203   2: 0.022919183332943 

test_20419        5: 0.762759555717550   9: 0.086598966366417   4: 0.018832920950213   6: 0.018831869454804   1: 0.018829876526261   0: 0.018829802045232   2: 0.018829756687411   8: 0.018829205841338   3: 0.018829028180435   7: 0.018829018230340 

test_20420        2: 0.756340832858096   1: 0.056004099731060   5: 0.052977619377372   8: 0.019245166760226   6: 0.019242377592150   0: 0.019239496791713   4: 0.019237971294634   7: 0.019237745403571   9: 0.019237704308216   3: 0.019236985882961 

test_20421        5: 0.463951970267883   2: 0.232999243197763   9: 0.137330354806769   4: 0.023679941568825   8: 0.023673435637430   3: 0.023673203264666   7: 0.023673052675407   0: 0.023672963960121   1: 0.023672922494069   6: 0.023672912127067 

test_20432        5: 0.786003105563244   7: 0.069792620118114   1: 0.018037124535187   4: 0.018025952545428   6: 0.018024618018294   0: 0.018024397546480   2: 0.018023548806841   8: 0.018023011676383   9: 0.018022855690147   3: 0.018022765499883 

test_20438        4: 0.761551711382496   5: 0.026502371664508   8: 0.026493544939150   3: 0.026493471479151   2: 0.026493357969177   9: 0.026493169230299   1: 0.026493168382397   0: 0.026493150120251   7: 0.026493092087078   6: 0.026492962745494 

test_20439        6: 0.523976674958646   1: 0.327911776330023   0: 0.040685192203556   7: 0.015356469936796   3: 0.015356272293488   8: 0.015344579187658   9: 0.015342672739842   4: 0.015342386157457   2: 0.015342015082550   5: 0.015341961109986 

test_20440        5: 0.462776924420480   4: 0.380606958772557   6: 0.019578530742331   9: 0.019578394557060   1: 0.019577102595985   0: 0.019576570252733   3: 0.019576544634787   7: 0.019576457023666   8: 0.019576282308016   2: 0.019576234692386 

test_20441        6: 0.630250934389009   5: 0.236941965964571   3: 0.024681284255849   1: 0.024214547527737   0: 0.014031916706667   9: 0.013976804657908   4: 0.013975815245933   8: 0.013975700932856   2: 0.013975662519823   7: 0.013975367799646 

test_20442        5: 0.570296118801004   3: 0.214053213811424   4: 0.026962730898986   8: 0.026955889027779   2: 0.026955524554693   9: 0.026955429587236   7: 0.026955332507269   0: 0.026955286106645   6: 0.026955252865611   1: 0.026955221839355 

test_20443        5: 0.821394060406618   4: 0.019847369079122   0: 0.019845756662284   1: 0.019845212946478   6: 0.019845043847456   8: 0.019844951922030   2: 0.019844929280795   9: 0.019844301618144   3: 0.019844275545355   7: 0.019844098691718 

test_20444        6: 0.360640430356492   3: 0.315947503412070   1: 0.148095304663753   8: 0.025046041484838   0: 0.025045725513503   5: 0.025045450644161   9: 0.025045149390386   7: 0.025044922914886   2: 0.025044781257260   4: 0.025044690362650 

test_20446        5: 0.559735916298809   3: 0.196353561431249   0: 0.102876833045163   4: 0.020160906299232   1: 0.020158589884687   6: 0.020146362355621   8: 0.020142594054867   9: 0.020142115565925   7: 0.020141667586041   2: 0.020141453478404 

test_20448        5: 0.789407983343989   4: 0.023406224204235   7: 0.023400799670940   0: 0.023399253000360   6: 0.023398958478319   1: 0.023398927188913   3: 0.023397080284007   9: 0.023397016674294   8: 0.023396920645687   2: 0.023396836509257 

test_20450        5: 0.453920407423726   8: 0.289963930947213   9: 0.094770004790856   4: 0.023052944036843   6: 0.023051381286210   0: 0.023048770913257   1: 0.023048562821686   7: 0.023048062965690   3: 0.023048008693990   2: 0.023047926120530 

test_20453        4: 0.524828557676876   9: 0.301020112098736   5: 0.021773879015472   1: 0.021769978594005   2: 0.021768833517997   0: 0.021768693244575   6: 0.021768432382459   7: 0.021767502907798   8: 0.021767025797822   3: 0.021766984764260 

test_20455        5: 0.794686780052003   4: 0.022816614631676   7: 0.022814444772656   6: 0.022812488369973   0: 0.022812018059918   1: 0.022811945631585   2: 0.022811549082574   8: 0.022811494481982   3: 0.022811378199827   9: 0.022811286717805 

test_20457        1: 0.840068155194841   6: 0.017775251681486   5: 0.017774038449223   0: 0.017770893355383   8: 0.017769076820770   3: 0.017768959876170   4: 0.017768728668545   2: 0.017768367243282   9: 0.017768348318605   7: 0.017768180391694 

test_20458        1: 0.534201226164165   6: 0.307379357495491   4: 0.040176640495653   7: 0.025032139471461   0: 0.015651496278477   5: 0.015512137152055   8: 0.015511961807043   9: 0.015511893036246   3: 0.015511708048352   2: 0.015511440051058 

test_20459        6: 0.689801560234420   8: 0.090573961016916   0: 0.072813536461355   7: 0.045673393828597   1: 0.016862203789023   9: 0.016856245732826   5: 0.016855374124456   3: 0.016854811193456   2: 0.016854628354586   4: 0.016854285264365 

test_20461        6: 0.810193353373359   0: 0.060021855034679   4: 0.031339142947690   1: 0.019526128532741   7: 0.013635990918053   8: 0.013060113285671   9: 0.013059362639097   5: 0.013055477633963   2: 0.013054326172938   3: 0.013054249461809 

test_20462        6: 0.806576785877431   9: 0.070160352817731   0: 0.050186959735608   1: 0.010559024202848   2: 0.010421935952618   7: 0.010419809130444   5: 0.010419537585603   3: 0.010418678824208   4: 0.010418491508914   8: 0.010418424364594 

test_20463        5: 0.665926898840995   9: 0.144871559793293   4: 0.023653105660918   6: 0.023652763937804   2: 0.023649891108848   0: 0.023649833482553   8: 0.023649528285138   1: 0.023649002173033   7: 0.023648816915733   3: 0.023648599801683 

test_20464        6: 0.492996156990820   3: 0.260458307054458   1: 0.100984576133810   7: 0.036925851261913   5: 0.034012933407568   0: 0.023032473607476   2: 0.012904991796159   9: 0.012898053760050   4: 0.012894909478077   8: 0.012891746509668 

test_20465        6: 0.858713172016325   5: 0.016034720642985   8: 0.015665207859996   1: 0.015656019386154   4: 0.015655992037082   9: 0.015655861675091   0: 0.015655512409708   3: 0.015654632210811   7: 0.015654488468369   2: 0.015654393293478 

test_20467        3: 0.409465310605245   0: 0.407272055031415   8: 0.050413783762895   6: 0.018994927924991   5: 0.018984190226002   9: 0.018979936287318   1: 0.018977003625765   4: 0.018971673988410   2: 0.018970747117607   7: 0.018970371430352 

test_20468        5: 0.836260183949894   1: 0.018208617889502   0: 0.018205392552521   6: 0.018194643212248   4: 0.018189802034063   8: 0.018188747130402   9: 0.018188709875305   2: 0.018188032858783   3: 0.018187944852485   7: 0.018187925644798 

test_20469        6: 0.728934327596083   5: 0.095659817608268   8: 0.061690946959057   1: 0.040621059991826   0: 0.012212455625094   3: 0.012177811880601   9: 0.012176615481254   7: 0.012175736581520   2: 0.012175620897973   4: 0.012175607378324 

test_20470        5: 0.764044877325695   4: 0.026221654702921   6: 0.026216991655160   2: 0.026216778186758   0: 0.026216757319255   8: 0.026216676493478   3: 0.026216667634805   1: 0.026216662806338   9: 0.026216518921488   7: 0.026216414954101 

test_20471        5: 0.568048967455815   7: 0.240935763451396   1: 0.023887484535589   4: 0.023881667830160   6: 0.023874564405650   3: 0.023874526352887   2: 0.023874342823689   8: 0.023874309855821   0: 0.023874273366743   9: 0.023874099922251 

test_20473        5: 0.785690136161005   2: 0.023867715487928   4: 0.023808482317700   3: 0.023805214790611   8: 0.023804928513394   7: 0.023804756739086   9: 0.023804739941919   0: 0.023804692473671   1: 0.023804678394849   6: 0.023804655179837 

test_20474        6: 0.766366448055086   1: 0.062082809532271   8: 0.045297632339647   0: 0.041869884059174   3: 0.014066956213478   9: 0.014065046710889   5: 0.014063678809943   4: 0.014062612698071   7: 0.014062484025173   2: 0.014062447556268 

test_20476        4: 0.747628180669424   0: 0.080828469146206   1: 0.021450930531663   5: 0.021447119049705   6: 0.021441463831087   8: 0.021440916207361   3: 0.021440852372887   2: 0.021440746749439   9: 0.021440707338156   7: 0.021440614104072 

test_20479        5: 0.461556076633972   6: 0.346812299059465   1: 0.023963512123505   4: 0.023957008016739   0: 0.023954391340163   8: 0.023952545282349   3: 0.023951268972086   2: 0.023951049505757   9: 0.023950983508167   7: 0.023950865557797 

test_20480        4: 0.624087020730970   8: 0.165028187726231   5: 0.026368381689682   3: 0.026359786816592   2: 0.026359638789571   0: 0.026359535872587   1: 0.026359503426069   9: 0.026359393124461   7: 0.026359376737090   6: 0.026359175086746 

test_20485        6: 0.687203070569933   2: 0.157565431628129   5: 0.042923667504759   3: 0.016177676962075   4: 0.016035521618738   1: 0.016020420682575   0: 0.016019931142497   9: 0.016018469592563   8: 0.016018011096563   7: 0.016017799202168 

test_20488        5: 0.639348851019046   4: 0.182924696744418   1: 0.022217054339738   0: 0.022216015928728   6: 0.022215928210374   9: 0.022215610620235   8: 0.022215548674129   2: 0.022215507092242   3: 0.022215466576790   7: 0.022215320794300 

test_20489        0: 0.417887100802951   1: 0.403449794428717   6: 0.049685436797240   9: 0.018426986359966   5: 0.018426795215740   2: 0.018425321124337   4: 0.018425193854283   8: 0.018424737587670   3: 0.018424468018664   7: 0.018424165810432 

test_20490        5: 0.778112287592517   4: 0.024659089535243   1: 0.024653771163466   0: 0.024653763559588   8: 0.024653675640310   3: 0.024653554016192   2: 0.024653537943206   6: 0.024653531225590   7: 0.024653409092246   9: 0.024653380231642 

test_20493        5: 0.837846951733646   4: 0.018018171026992   6: 0.018017658629319   0: 0.018017204042538   1: 0.018017066223824   9: 0.018016881156523   3: 0.018016719227974   2: 0.018016533898415   7: 0.018016432084026   8: 0.018016381976744 

test_20494        5: 0.742978138710408   3: 0.069871601007204   7: 0.067105551663440   6: 0.017152569832082   0: 0.017149081975004   1: 0.017149076424281   9: 0.017148988344832   8: 0.017148721478038   4: 0.017148538231277   2: 0.017147732333434 

test_20496        6: 0.738860194180750   1: 0.089964203910643   0: 0.070943919589165   8: 0.014489307902199   9: 0.014304054956581   5: 0.014287870965037   2: 0.014287867362394   7: 0.014287573622116   3: 0.014287537987177   4: 0.014287469523938 

test_20497        5: 0.809312068930256   4: 0.021192706915030   6: 0.021187861762030   0: 0.021187191338962   1: 0.021186883165455   3: 0.021186847858321   8: 0.021186691442873   9: 0.021186681973178   2: 0.021186544925885   7: 0.021186521688011 

test_20498        5: 0.561884562489124   8: 0.253308025774887   4: 0.023107885815416   1: 0.023100825802851   3: 0.023100699338854   0: 0.023099951555355   2: 0.023099628266704   7: 0.023099524618455   6: 0.023099451808818   9: 0.023099444529539 

test_20499        5: 0.440006108297197   8: 0.365260398238907   1: 0.024357747815446   4: 0.024345659081884   3: 0.024338521499565   2: 0.024338401866505   7: 0.024338334591339   9: 0.024338302502865   6: 0.024338276841573   0: 0.024338249264719 

test_20500        6: 0.694673310515191   0: 0.189769199103899   1: 0.050430987459615   8: 0.013256000489902   7: 0.008646292526358   3: 0.008646272839655   5: 0.008644956075399   4: 0.008644500614667   9: 0.008644489677696   2: 0.008643990697617 

test_20502        5: 0.719537690957619   9: 0.098670437361094   6: 0.022738428142933   3: 0.022728361808812   4: 0.022722829136320   2: 0.022721680779655   7: 0.022720348018392   1: 0.022720127680187   8: 0.022720058852035   0: 0.022720037262953 

test_20507        4: 0.788868171236227   5: 0.023464719635222   8: 0.023458570838562   3: 0.023458469296628   0: 0.023458457730009   2: 0.023458399177221   1: 0.023458380224865   9: 0.023458346203867   7: 0.023458264858706   6: 0.023458220798693 

test_20511        6: 0.802815652289413   0: 0.087839072158265   8: 0.018232412246479   2: 0.018148860598141   5: 0.016672749736764   4: 0.011271077079386   1: 0.011260263928292   7: 0.011258951956329   9: 0.011250843082757   3: 0.011250116924175 

test_20514        5: 0.779495509140442   0: 0.024502744075836   4: 0.024500583191499   2: 0.024500531988911   3: 0.024500444174169   1: 0.024500145917296   6: 0.024500104391379   9: 0.024500063113615   7: 0.024499976274238   8: 0.024499897732614 

test_20515        5: 0.418080609098510   0: 0.235018160014001   9: 0.181397424712694   1: 0.056310327179227   4: 0.018202352518914   2: 0.018201479428602   6: 0.018200795664830   8: 0.018196411805513   7: 0.018196220826626   3: 0.018196218751081 

test_20517        5: 0.577516941691794   1: 0.217298098699024   0: 0.101826914489836   4: 0.014767276882682   6: 0.014766651379879   9: 0.014765736226091   2: 0.014765688534858   3: 0.014764327390588   7: 0.014764187542647   8: 0.014764177162600 

test_20523        5: 0.813057524154197   4: 0.020773384397174   6: 0.020771921361653   0: 0.020771368117425   1: 0.020771177326485   8: 0.020771017976158   9: 0.020770939503519   3: 0.020770930824009   2: 0.020770887117852   7: 0.020770849221527 

test_20525        3: 0.506215974582872   1: 0.338608880128971   2: 0.019509875589672   8: 0.019395435848325   4: 0.019391177880763   6: 0.019381533722127   5: 0.019375551012254   0: 0.019374716555939   9: 0.019374577353153   7: 0.019372277325923 

test_20527        4: 0.438024632288342   5: 0.373605317658156   6: 0.023554143489108   0: 0.023551315528384   1: 0.023548027815589   9: 0.023545591659551   3: 0.023543716774621   8: 0.023542711282873   2: 0.023542408674794   7: 0.023542134828583 

test_20529        5: 0.452948743633211   4: 0.337529557037673   0: 0.054586973678041   7: 0.049524759844328   6: 0.017570094618524   1: 0.017569844228675   8: 0.017567566841973   3: 0.017567556838233   2: 0.017567496105514   9: 0.017567407173828 

test_20531        5: 0.821686838470117   0: 0.019821167082356   4: 0.019813509982774   6: 0.019812468547413   1: 0.019811561719175   8: 0.019811269578229   9: 0.019810929015470   3: 0.019810795971542   2: 0.019810775179244   7: 0.019810684453680 

test_20532        6: 0.786814102691870   0: 0.097630736694807   9: 0.014458009025319   5: 0.014443725903932   1: 0.014443610116945   7: 0.014442816868786   3: 0.014442029287415   8: 0.014441866399907   2: 0.014441582828332   4: 0.014441520182686 

test_20533        5: 0.538891272602790   3: 0.212660740863797   6: 0.071752581046071   4: 0.053242384374211   8: 0.046921209316290   1: 0.015429993786609   2: 0.015303478295264   0: 0.015280253664255   9: 0.015259217849630   7: 0.015258868201083 

test_20535        5: 0.850461283963305   0: 0.016624149154909   4: 0.016616516483928   6: 0.016614826289848   9: 0.016614228270405   8: 0.016614101057762   1: 0.016613853504703   3: 0.016613750924249   2: 0.016613680113840   7: 0.016613610237052 

test_20545        5: 0.645741489393706   0: 0.154422627802130   1: 0.060318590091875   4: 0.019935443062904   7: 0.019930893383699   3: 0.019930310073930   6: 0.019930256622739   8: 0.019930197723160   9: 0.019930195485919   2: 0.019929996359938 

test_20546        5: 0.789659981323969   0: 0.094174768731558   8: 0.014649991058032   4: 0.014505037358039   1: 0.014503489664447   6: 0.014502708879471   7: 0.014501641662128   3: 0.014501142941925   2: 0.014500728353127   9: 0.014500510027303 

test_20548        5: 0.510123892902892   2: 0.206098331551742   6: 0.105154144369088   1: 0.025527793453366   4: 0.025520792266370   8: 0.025518711274511   9: 0.025514275116881   3: 0.025514213362310   0: 0.025513938869125   7: 0.025513906833714 

test_20550        6: 0.436975670179986   7: 0.365413747468716   3: 0.024715871948243   5: 0.024700832482223   2: 0.024700236429459   8: 0.024699212056547   1: 0.024699146640550   0: 0.024698964314670   9: 0.024698601791053   4: 0.024697716688552 

test_20552        4: 0.591370133236784   1: 0.217489685521920   6: 0.023900221103222   5: 0.023896341733519   0: 0.023893522133693   2: 0.023891009099917   7: 0.023890835403997   3: 0.023889722340904   9: 0.023889312079527   8: 0.023889217346518 

test_20557        5: 0.831327812343732   4: 0.018743519412192   6: 0.018742387860151   8: 0.018741626811596   1: 0.018741574658847   0: 0.018741329162869   9: 0.018741077737150   2: 0.018740349561764   7: 0.018740184906147   3: 0.018740137545551 

test_20558        5: 0.765555480077064   4: 0.026051528927283   6: 0.026050715057805   1: 0.026049467792339   8: 0.026048969559561   0: 0.026048796710405   3: 0.026048784618193   7: 0.026048757282128   9: 0.026048750328824   2: 0.026048749646399 

test_20561        5: 0.700003233940233   1: 0.114735767806226   0: 0.023161778241240   4: 0.023160754448518   8: 0.023156482372900   3: 0.023156475451247   6: 0.023156467037760   2: 0.023156392472634   9: 0.023156341103363   7: 0.023156307125879 

test_20562        5: 0.808634081141217   4: 0.021265657441723   6: 0.021263359908346   0: 0.021262652328322   1: 0.021262596075365   9: 0.021262410183929   8: 0.021262369193018   7: 0.021262338481478   3: 0.021262287494434   2: 0.021262247752169 

test_20564        5: 0.776229374773243   4: 0.024866559432068   0: 0.024866376459799   1: 0.024865519708409   2: 0.024862661632568   8: 0.024862386172707   9: 0.024862025388901   3: 0.024861860239338   6: 0.024861831546621   7: 0.024861404646345 

test_20566        5: 0.401633972204552   7: 0.270381692285756   3: 0.155601307418973   6: 0.024630874262483   4: 0.024627458871515   8: 0.024626676314489   2: 0.024625856909286   0: 0.024625271644220   1: 0.024623787509349   9: 0.024623102579378 

test_20567        4: 0.765648250006723   6: 0.026057578801820   5: 0.026046523259215   9: 0.026038943061790   1: 0.026037855980504   0: 0.026037734308381   8: 0.026034244032660   7: 0.026033660668141   3: 0.026032792327610   2: 0.026032417553157 

test_20569        5: 0.679625348110617   0: 0.138318090519367   8: 0.053776090491041   3: 0.018335060963417   4: 0.018331377541093   6: 0.018326461114805   9: 0.018322513876188   1: 0.018322391174705   2: 0.018321602791043   7: 0.018321063417724 

test_20583        5: 0.628846555154646   1: 0.108187738938644   2: 0.106677490056942   4: 0.022330798654164   8: 0.022328399372682   0: 0.022326161611768   6: 0.022326150681259   3: 0.022325697620907   7: 0.022325524133146   9: 0.022325483775842 

test_20584        7: 0.610765377058848   0: 0.160951190254898   8: 0.064715159715949   9: 0.023411167534995   4: 0.023384439236658   5: 0.023360006846070   6: 0.023359045187646   1: 0.023358611101410   2: 0.023347715019488   3: 0.023347288044038 

test_20586        5: 0.800538822710756   4: 0.022169708509947   0: 0.022162177397252   6: 0.022162150726922   1: 0.022161862470526   8: 0.022161348322750   2: 0.022161076531526   9: 0.022160980888213   7: 0.022160956230828   3: 0.022160916211281 

test_20593        5: 0.755928291673870   4: 0.027122048649176   8: 0.027118851103994   3: 0.027118763476217   0: 0.027118755239770   2: 0.027118731539973   9: 0.027118704234129   1: 0.027118631446408   6: 0.027118617083418   7: 0.027118605553045 

test_20596        5: 0.796721198573519   4: 0.022587825297350   6: 0.022587416229259   8: 0.022586839783809   0: 0.022586579016911   9: 0.022586495474942   1: 0.022586352833978   7: 0.022585820022989   3: 0.022585739120615   2: 0.022585733646629 

test_20598        5: 0.432257306234673   7: 0.361734506306909   4: 0.076804615543598   0: 0.018476676690501   6: 0.018476640129720   9: 0.018452030688996   2: 0.018451817929175   1: 0.018449200220425   8: 0.018448942065067   3: 0.018448264190936 

test_20600        4: 0.580482227488823   8: 0.229948089626974   5: 0.023704288215329   6: 0.023695218218577   1: 0.023695212282927   0: 0.023695206677993   3: 0.023695106130133   9: 0.023695007374238   2: 0.023694891269209   7: 0.023694752715798 

test_20605        5: 0.455363156309710   2: 0.340754770676435   4: 0.025488901691447   0: 0.025485121413705   8: 0.025484866000324   3: 0.025484798140299   6: 0.025484723124824   9: 0.025484611094593   1: 0.025484563134746   7: 0.025484488413918 

test_20606        5: 0.793888915876060   4: 0.022905820309524   0: 0.022902020150895   7: 0.022900766291725   6: 0.022900643084843   9: 0.022900509749751   8: 0.022900508249457   1: 0.022900470138430   3: 0.022900191107919   2: 0.022900155041397 

test_20611        6: 0.461061137284448   5: 0.386695789796192   1: 0.019039193947084   0: 0.019034039315538   8: 0.019031465743234   7: 0.019029713676226   3: 0.019028209242796   2: 0.019027232424125   4: 0.019026681229333   9: 0.019026537341025 

test_20618        4: 0.462771817705861   6: 0.244858825728559   1: 0.152571844715023   5: 0.019976915377080   0: 0.019975780500447   8: 0.019969261275755   2: 0.019969239922675   9: 0.019969124584033   7: 0.019969033848384   3: 0.019968156342183 

test_20620        6: 0.481822467287220   8: 0.361300889746979   9: 0.049709283601109   5: 0.015341504123257   3: 0.015305743318321   0: 0.015304610961422   7: 0.015303995853217   4: 0.015303885170128   2: 0.015303832714442   1: 0.015303787223904 

test_20624        6: 0.641081844225227   3: 0.241963564670303   1: 0.025230151388013   0: 0.013112604749668   7: 0.013109224854455   5: 0.013101668794259   8: 0.013101310804029   9: 0.013100018752766   2: 0.013099828052122   4: 0.013099783709157 

test_20628        5: 0.836382224592587   3: 0.047272213878325   6: 0.014545851124036   1: 0.014543499313417   4: 0.014543396751917   0: 0.014542983988844   8: 0.014542567973858   9: 0.014542471355485   2: 0.014542421795864   7: 0.014542369225667 

test_20630        5: 0.379719564923094   8: 0.361324079689044   4: 0.032378983150218   2: 0.032368480118582   3: 0.032368383270070   0: 0.032368223789911   1: 0.032368184011175   9: 0.032368109783125   7: 0.032368036492797   6: 0.032367954771986 

test_20631        6: 0.576049970653643   0: 0.305677058004082   7: 0.014827063758117   8: 0.014793396291959   1: 0.014777421085256   3: 0.014776296417832   5: 0.014774983973292   2: 0.014774668549853   4: 0.014774602598182   9: 0.014774538667784 

test_20632        6: 0.564054623583625   0: 0.137221001141768   1: 0.134443909998408   8: 0.062210928488299   9: 0.033242897175883   7: 0.030975045790104   4: 0.009571640247814   3: 0.009428999020820   5: 0.009425722170197   2: 0.009425232383083 

test_20634        5: 0.827769444095911   4: 0.019140232160634   1: 0.019136719209150   6: 0.019136577868369   0: 0.019136282082576   8: 0.019136255100260   3: 0.019136148178967   2: 0.019136145211445   9: 0.019136137390966   7: 0.019136058701722 

test_20637        6: 0.741540066632652   7: 0.028719326616554   1: 0.028718861209780   0: 0.028718439634429   8: 0.028717788633349   5: 0.028717465155985   9: 0.028717172776730   2: 0.028717147092509   4: 0.028717022630277   3: 0.028716709617736 

test_20639        4: 0.718655085220313   7: 0.108920340102191   5: 0.021558533817929   8: 0.021552417017579   6: 0.021552367702034   9: 0.021552318198079   0: 0.021552294664137   2: 0.021552267535801   3: 0.021552252681637   1: 0.021552123060300 

test_20640        5: 0.754135948271489   4: 0.027322151983790   8: 0.027317905951517   2: 0.027317897585610   0: 0.027317787111930   3: 0.027317786307572   9: 0.027317711710948   1: 0.027317622256114   6: 0.027317610514751   7: 0.027317578306279 

test_20641        6: 0.686554818083861   0: 0.097779415904611   3: 0.068224183630774   2: 0.045872645334149   5: 0.016929644890704   1: 0.016928938352665   4: 0.016928876184447   9: 0.016927561250224   7: 0.016927139185986   8: 0.016926777182578 

test_20645        6: 0.836645326933099   5: 0.018154435374487   4: 0.018151061913888   0: 0.018150621267274   8: 0.018150439758518   1: 0.018150265407057   7: 0.018149796121120   9: 0.018149707582363   2: 0.018149202830453   3: 0.018149142811739 

test_20646        4: 0.726107057058516   6: 0.092846528860833   5: 0.022639859167493   3: 0.022630718461962   1: 0.022630483034424   7: 0.022629928008406   0: 0.022629797313754   9: 0.022628704529415   2: 0.022628490143010   8: 0.022628433422188 

test_20648        5: 0.643779662350529   0: 0.164119582824119   4: 0.024017765745832   1: 0.024011979674425   8: 0.024011978156570   6: 0.024011952885463   3: 0.024011951100219   2: 0.024011784437657   7: 0.024011696439235   9: 0.024011646385950 

test_20649        6: 0.868846615002442   1: 0.014573068565761   0: 0.014572899488739   7: 0.014572813821315   5: 0.014572736559712   4: 0.014572520829845   8: 0.014572495359877   9: 0.014572355122646   2: 0.014572264722928   3: 0.014572230526733 

test_20650        4: 0.819166443999473   5: 0.020098975402611   0: 0.020092855336764   1: 0.020092637803058   6: 0.020092266586488   9: 0.020091852218025   8: 0.020091639660181   3: 0.020091180449293   2: 0.020091093599257   7: 0.020091054944848 

test_20651        5: 0.795513663085081   6: 0.022735951641895   4: 0.022724124469651   3: 0.022719116494210   8: 0.022718380190584   1: 0.022718026596354   7: 0.022717988397249   0: 0.022717859554363   9: 0.022717462888855   2: 0.022717426681757 

test_20652        5: 0.803576492437550   6: 0.021839356714092   0: 0.021828933498527   8: 0.021828548467765   9: 0.021825761846814   4: 0.021821693307617   1: 0.021820973652497   7: 0.021819993271104   3: 0.021819340081301   2: 0.021818906722733 

test_20653        0: 0.325036945717959   9: 0.318993668269353   6: 0.185611910649222   1: 0.053915796714165   8: 0.033371878441922   7: 0.030737345819204   4: 0.013135877411812   5: 0.013067894595451   2: 0.013064973722294   3: 0.013063708658619 

test_20654        5: 0.745005813475081   4: 0.028335431264447   8: 0.028333791837379   6: 0.028333275754765   9: 0.028333071120311   0: 0.028332522020092   1: 0.028331871066457   3: 0.028331467909757   2: 0.028331414000665   7: 0.028331341551046 

test_20655        4: 0.792632300421535   5: 0.023047040262884   6: 0.023040827814285   8: 0.023040157623591   1: 0.023040063687292   3: 0.023040045205754   0: 0.023040017479861   2: 0.023039923853963   9: 0.023039816956951   7: 0.023039806693883 

test_20657        5: 0.783021013425933   4: 0.024115716110286   8: 0.024108249531410   6: 0.024108056665604   3: 0.024108056018810   1: 0.024108006382450   0: 0.024107805041111   7: 0.024107728990789   2: 0.024107722133152   9: 0.024107645700456 

test_20658        5: 0.806419121783629   1: 0.021611621966471   8: 0.021526235742810   6: 0.021521055047279   0: 0.021500702497953   4: 0.021490900583674   2: 0.021484556177466   7: 0.021482077714147   9: 0.021481889355112   3: 0.021481839131458 

test_20660        5: 0.795291858083015   4: 0.022749749424415   3: 0.022744919235265   8: 0.022744905547752   2: 0.022744833053095   0: 0.022744796509998   9: 0.022744768945459   1: 0.022744761172607   7: 0.022744731787823   6: 0.022744676240571 

test_20662        6: 0.389107128055656   7: 0.340474285506191   5: 0.109345004222289   9: 0.045985190114050   0: 0.019279928802166   4: 0.019173332517529   2: 0.019160375900753   1: 0.019160105857200   3: 0.019157342908066   8: 0.019157306116099 

test_20666        9: 0.503109497079057   6: 0.344619922129890   5: 0.034351454442070   0: 0.017429891792249   1: 0.016782787197753   8: 0.016748497717292   7: 0.016745794545575   3: 0.016738951159858   2: 0.016738245088829   4: 0.016734958847428 

test_20667        1: 0.677395261796953   7: 0.162509738246205   0: 0.033438436515330   8: 0.018103840725678   6: 0.018101480361555   5: 0.018093557597719   9: 0.018092201526526   3: 0.018089230686707   4: 0.018088128329137   2: 0.018088124214190 

test_20668        5: 0.776126916511859   2: 0.091887464217226   9: 0.016561361353159   3: 0.016526537708096   8: 0.016508080660043   6: 0.016484726017656   1: 0.016483305288347   0: 0.016476945542519   4: 0.016472818854488   7: 0.016471843846608 

test_20669        0: 0.351133188126138   5: 0.310813264508550   1: 0.105773161755681   2: 0.072646203178814   9: 0.069405529128137   4: 0.018051155149211   6: 0.018048875553109   7: 0.018043172842938   8: 0.018042865303160   3: 0.018042584454260 

test_20670        5: 0.628456942555001   7: 0.197951609340249   0: 0.021709033902457   4: 0.021699884220772   2: 0.021698743657723   6: 0.021698580556516   1: 0.021698270615077   8: 0.021695979221138   9: 0.021695672037861   3: 0.021695283893207 

test_20671        5: 0.802592826463970   4: 0.021937924263812   1: 0.021936908135084   6: 0.021935459263447   0: 0.021934888488503   7: 0.021934367885192   3: 0.021932075664441   9: 0.021932001527648   8: 0.021931881180628   2: 0.021931667127276 

test_20672        5: 0.634906883093869   1: 0.106569389796865   2: 0.104848900235775   4: 0.021957108839671   8: 0.021954940603832   6: 0.021953420833265   0: 0.021952853892183   3: 0.021952224198425   7: 0.021952176309828   9: 0.021952102196288 

test_20673        5: 0.618306899703859   9: 0.190042886674197   4: 0.023962964460735   6: 0.023957680957994   1: 0.023956623486994   3: 0.023955431816430   0: 0.023955311007067   8: 0.023954354770931   7: 0.023954001526583   2: 0.023953845595211 

test_20678        6: 0.455591985439794   1: 0.399126301174409   0: 0.045194989852359   5: 0.014299265960142   8: 0.014298570367711   4: 0.014297973128264   2: 0.014297871536176   9: 0.014297862838497   7: 0.014297662691224   3: 0.014297517011424 

test_20679        1: 0.581662767069404   2: 0.193796984973520   5: 0.112539691691303   0: 0.016025655547360   6: 0.016006137015372   9: 0.015998517467834   8: 0.015998112410967   4: 0.015991394290132   7: 0.015990616754734   3: 0.015990122779375 

test_20680        5: 0.421680352365045   7: 0.239828823750064   6: 0.148518171516576   4: 0.027143932465994   8: 0.027138662039689   9: 0.027138257911971   0: 0.027138033049193   3: 0.027137996316054   2: 0.027137942404068   1: 0.027137828181345 

test_20682        6: 0.717926332389243   0: 0.154496133486104   4: 0.015979477160646   7: 0.015956443648488   3: 0.015946702530263   5: 0.015946313016674   1: 0.015937458619492   8: 0.015937367068164   9: 0.015936996132994   2: 0.015936775947932 

test_20685        5: 0.680476969623771   3: 0.083126683217837   8: 0.068708503471194   6: 0.045785332994159   7: 0.044804575676285   1: 0.015423019011799   4: 0.015420625739670   2: 0.015418670839870   9: 0.015417822016467   0: 0.015417797408949 

test_20692        2: 0.740560609830115   5: 0.028834946798548   4: 0.028830127454465   9: 0.028827102287795   6: 0.028826247335471   8: 0.028825143110564   0: 0.028824313888423   1: 0.028824248198637   3: 0.028823711883849   7: 0.028823549212134 

test_20693        5: 0.575614678970457   8: 0.268145823668661   3: 0.034590417506446   6: 0.017395279957307   0: 0.017384954137202   7: 0.017383067701393   1: 0.017380143931990   2: 0.017371166269033   4: 0.017367270784021   9: 0.017367197073489 

test_20695        5: 0.730297278295658   4: 0.029969336298345   8: 0.029967320590622   1: 0.029967210807339   9: 0.029966956191617   0: 0.029966748051884   6: 0.029966625230635   3: 0.029966309389182   2: 0.029966152437908   7: 0.029966062706810 

test_20698        1: 0.421281042180425   6: 0.159443878049659   5: 0.139073116721907   0: 0.110529233815074   2: 0.107871765553769   8: 0.012376895545894   7: 0.012369367856198   9: 0.012351811009846   4: 0.012351676251540   3: 0.012351213015688 

test_20699        6: 0.404059075559011   3: 0.245277145108227   0: 0.156843845601931   9: 0.062458034929839   7: 0.047077588729783   2: 0.016861168451136   5: 0.016856941319791   1: 0.016856766256989   8: 0.016855054560130   4: 0.016854379483162 

test_20706        5: 0.785293068193483   7: 0.055300715619470   9: 0.052637202557073   1: 0.015255880434508   6: 0.015254168392563   8: 0.015254071600398   0: 0.015252435557763   4: 0.015251708999679   2: 0.015250597872768   3: 0.015250150772295 

test_20708        5: 0.675145257792603   3: 0.142792270452889   4: 0.022762078857127   6: 0.022759347282477   1: 0.022758481195616   0: 0.022757057194398   9: 0.022756852652748   8: 0.022756545215509   2: 0.022756077211078   7: 0.022756032145555 

test_20709        2: 0.555289901616373   5: 0.135949479796437   6: 0.124554433532982   8: 0.088856628733051   0: 0.015905547081678   1: 0.015889848544352   9: 0.015889149421068   7: 0.015888662931449   4: 0.015888398877789   3: 0.015887949464820 

test_20710        0: 0.694977882856353   8: 0.143882041765665   6: 0.020189857327440   1: 0.020137429855883   5: 0.020137111833424   3: 0.020136819420223   9: 0.020136310080958   7: 0.020135106905334   4: 0.020133892080004   2: 0.020133547874716 

test_20711        5: 0.777609551176425   8: 0.024713436289950   4: 0.024711443169513   6: 0.024710990685565   7: 0.024710252191638   0: 0.024709525124866   1: 0.024708986885880   9: 0.024708856557904   3: 0.024708485212168   2: 0.024708472706092 

test_20712        5: 0.778682062636057   4: 0.024594990473050   1: 0.024594702118546   0: 0.024593224847297   8: 0.024589829947243   3: 0.024589234601256   2: 0.024589192462590   9: 0.024588965665788   6: 0.024588920716747   7: 0.024588876531426 

test_20715        5: 0.518978835402768   3: 0.291574182610488   4: 0.023685008674248   6: 0.023680728852675   8: 0.023680668828468   9: 0.023680472726173   0: 0.023680183299023   2: 0.023680034248392   1: 0.023679954238475   7: 0.023679931119289 

test_20719        6: 0.573795679317150   0: 0.132222656635787   1: 0.100208460597384   3: 0.087183681797775   9: 0.029063426260153   8: 0.026139779427980   7: 0.012848614893854   2: 0.012847889571898   5: 0.012845546948002   4: 0.012844264550017 

test_20721        2: 0.595835176536269   1: 0.189619897908549   6: 0.088848476236499   5: 0.017962429907848   0: 0.017956490029854   4: 0.017956404745784   9: 0.017955973070639   3: 0.017955188580478   7: 0.017955085275186   8: 0.017954877708894 

test_20723        6: 0.304214511435076   7: 0.250278105179640   1: 0.195712091114700   5: 0.094003718848735   0: 0.074577737131280   3: 0.016357405560754   8: 0.016215042131646   9: 0.016214250784444   2: 0.016213645068181   4: 0.016213492745544 

test_20725        4: 0.434718219489154   6: 0.229306350443362   0: 0.149677946164465   9: 0.074944627899974   5: 0.018568387253753   7: 0.018565113241971   1: 0.018556848644958   8: 0.018554851185686   2: 0.018554468994386   3: 0.018553186682291 

test_20728        5: 0.784910277091716   4: 0.023901727571367   6: 0.023899535636836   0: 0.023898872122395   8: 0.023898717572241   3: 0.023898480299670   7: 0.023898361590410   2: 0.023898149294012   1: 0.023897964890929   9: 0.023897913930424 

test_20730        2: 0.745459604265013   5: 0.028288829731760   4: 0.028284544380425   9: 0.028283425828015   6: 0.028281242566995   8: 0.028281221892045   7: 0.028280889321226   3: 0.028280344498853   1: 0.028279995341690   0: 0.028279902173979 

test_20734        1: 0.401303670044200   7: 0.282826041824059   3: 0.137807469801321   6: 0.025474724119501   5: 0.025462399791711   4: 0.025441405999536   0: 0.025433403360916   2: 0.025417358657040   9: 0.025416893987704   8: 0.025416632414012 

test_20735        5: 0.761514545588203   6: 0.026504489239907   1: 0.026504020883387   9: 0.026501574300835   4: 0.026498711224088   2: 0.026496178552912   8: 0.026495572308493   3: 0.026495057690438   0: 0.026494999317673   7: 0.026494850894064 

test_20736        5: 0.771689120026900   4: 0.025374467686540   8: 0.025367366683027   3: 0.025367163093415   2: 0.025367078766429   0: 0.025367061030532   1: 0.025366994735200   9: 0.025366983320721   7: 0.025366956567349   6: 0.025366808089885 

test_20738        6: 0.565674505914126   0: 0.260282897116729   8: 0.050801341933883   5: 0.017607964911565   1: 0.017606793428607   7: 0.017605770879198   9: 0.017605729318753   4: 0.017605049154538   2: 0.017605025749163   3: 0.017604921593438 

test_20744        6: 0.348527410667294   1: 0.266236267503202   8: 0.255191481430965   2: 0.030471019146765   0: 0.028245263384605   9: 0.014705761761983   7: 0.014167160679704   5: 0.014153697415173   3: 0.014151133304845   4: 0.014150804705463 

test_20746        5: 0.756016195952494   7: 0.073734506792561   4: 0.021286997649561   8: 0.021280430108346   0: 0.021280361654452   3: 0.021280342655051   2: 0.021280330906013   9: 0.021280291388365   1: 0.021280287653188   6: 0.021280255239967 

test_20747        5: 0.594067291732006   6: 0.209814551009336   4: 0.024520525795083   7: 0.024515887070762   9: 0.024513850496301   3: 0.024513756322167   8: 0.024513755010145   2: 0.024513591922457   0: 0.024513427569438   1: 0.024513363072306 

test_20753        4: 0.665574462281064   5: 0.169400667166518   6: 0.020630875008520   1: 0.020629550838297   0: 0.020628656114612   2: 0.020627342214843   7: 0.020627265022187   8: 0.020627173725613   9: 0.020627004628804   3: 0.020627002999542 

test_20754        0: 0.622124384221675   1: 0.159889844120194   6: 0.027249290545324   5: 0.027248489016206   7: 0.027248279105513   4: 0.027248149887852   2: 0.027248049297280   9: 0.027247877288328   3: 0.027247852495927   8: 0.027247784021702 

test_20755        0: 0.645801750301507   6: 0.134148838851330   5: 0.027510348161867   1: 0.027507945205677   4: 0.027506449631687   7: 0.027505597257981   9: 0.027504843964946   2: 0.027504785550855   3: 0.027504727735227   8: 0.027504713338924 

test_20756        6: 0.511304558612803   3: 0.276481423444957   0: 0.089633042251824   9: 0.045699212089524   5: 0.012829863711831   8: 0.012824803765354   1: 0.012813145084635   2: 0.012808822045988   7: 0.012803914557854   4: 0.012801214435230 

test_20757        6: 0.786878751865600   5: 0.089483619880500   8: 0.015455563823147   4: 0.015455171442561   0: 0.015454896552448   9: 0.015454842362669   1: 0.015454449555098   7: 0.015454348448550   3: 0.015454208090106   2: 0.015454147979321 

test_20759        6: 0.710263979898045   0: 0.032195220616517   1: 0.032193616942417   5: 0.032193071397007   9: 0.032192861162071   3: 0.032192415409973   8: 0.032192344540877   2: 0.032192273628842   7: 0.032192219254500   4: 0.032191997149751 

test_20763        6: 0.697948175685919   8: 0.124370684988381   0: 0.043350420085172   5: 0.019214808449926   4: 0.019207444019853   1: 0.019186667257582   7: 0.019181074590270   3: 0.019180894763493   2: 0.019180222029718   9: 0.019179608129685 

test_20764        6: 0.595615066505841   0: 0.216434463568847   1: 0.128823941313467   7: 0.015064316876502   9: 0.007347191461654   2: 0.007344377933492   8: 0.007342860620786   3: 0.007342726991994   5: 0.007342713256719   4: 0.007342341470698 

test_20766        1: 0.447135673484538   2: 0.404800194458063   6: 0.018520943617008   5: 0.018511912822135   0: 0.018507520561960   7: 0.018505846809438   9: 0.018505341212333   4: 0.018504836383648   8: 0.018504075144529   3: 0.018503655506348 

test_20767        5: 0.831913796146234   4: 0.018677224974661   6: 0.018676775092344   9: 0.018676498911471   0: 0.018676455425299   1: 0.018676116803407   8: 0.018675938226087   2: 0.018675856130881   7: 0.018675850428338   3: 0.018675487861278 

test_20768        5: 0.741622922316311   4: 0.028712224053383   6: 0.028709580519013   3: 0.028708080204575   8: 0.028708002382941   2: 0.028707966916348   7: 0.028707848029371   0: 0.028707805078790   9: 0.028707788838770   1: 0.028707781660499 

test_20769        6: 0.724443921595054   0: 0.141712086708355   4: 0.016767651199879   1: 0.016727286219973   5: 0.016726510578948   8: 0.016725125177096   9: 0.016724895020610   2: 0.016724221676444   7: 0.016724158596159   3: 0.016724143227483 

test_20770        5: 0.765379121785872   1: 0.086151268941795   0: 0.018568864273571   6: 0.018566656090126   4: 0.018558298948717   8: 0.018556157556103   7: 0.018555065417589   9: 0.018554963137477   2: 0.018554841827872   3: 0.018554762020877 

test_20771        5: 0.791877530334849   4: 0.023128558928872   8: 0.023124387927507   6: 0.023124310993705   3: 0.023124278768698   1: 0.023124253724313   9: 0.023124189298039   0: 0.023124187040974   2: 0.023124168908895   7: 0.023124134074148 

test_20773        0: 0.756438949085378   6: 0.055698168785210   7: 0.034590629249531   5: 0.032942610033903   1: 0.020091426454043   4: 0.020049929377847   8: 0.020047600227991   9: 0.020047576743683   2: 0.020046639428960   3: 0.020046470613455 

test_20774        6: 0.612885897815830   1: 0.222153539424039   8: 0.063152485471482   9: 0.024328272714858   0: 0.019763899978368   7: 0.018331270151368   5: 0.009882463861615   3: 0.009837262972152   2: 0.009834063958928   4: 0.009830843651360 

test_20775        6: 0.766403165535158   5: 0.050756245887314   4: 0.023083618649690   0: 0.022866469922276   1: 0.022827296488473   2: 0.022814264604708   3: 0.022813077479520   9: 0.022812095305299   7: 0.022812085988022   8: 0.022811680139539 

test_20776        4: 0.633289183930807   5: 0.134140988029617   3: 0.029072855576111   7: 0.029072014628366   0: 0.029071393599209   6: 0.029070964187342   9: 0.029070877345712   8: 0.029070657921314   1: 0.029070549443325   2: 0.029070515338198 

test_20778        6: 0.478952864891827   8: 0.141898766244380   9: 0.138313905375891   3: 0.096437671515656   1: 0.071314211272776   5: 0.014619411133289   0: 0.014619175364275   4: 0.014616244406819   7: 0.014614062299940   2: 0.014613687495145 

test_20779        5: 0.774126773154643   4: 0.025101263706048   8: 0.025096657983974   3: 0.025096598761555   0: 0.025096523053243   2: 0.025096511900048   9: 0.025096482740901   7: 0.025096423295960   6: 0.025096391631675   1: 0.025096373771952 

test_20784        5: 0.623151607345186   8: 0.177964257058267   4: 0.024864240952087   1: 0.024863336316736   6: 0.024860975054961   0: 0.024860017413056   3: 0.024859007770077   2: 0.024858960766071   9: 0.024858832600486   7: 0.024858764723073 

test_20787        6: 0.639391114974091   1: 0.199678816520634   9: 0.039373240764930   4: 0.029166220587541   8: 0.027243767917441   0: 0.013038333356803   5: 0.013030152243333   3: 0.013026187675351   7: 0.013026117644616   2: 0.013026048315260 

test_20790        6: 0.409241724782826   8: 0.322461282957066   3: 0.120473462406303   9: 0.046377344083706   7: 0.026694043968496   1: 0.015003719068293   2: 0.014954118767043   0: 0.014932336643647   5: 0.014931395114955   4: 0.014930572207665 

test_20791        5: 0.724026466163292   0: 0.092247721576020   9: 0.022974006369163   4: 0.022967607856189   6: 0.022966625708569   8: 0.022965353685330   1: 0.022963232066176   7: 0.022963044721928   3: 0.022963018600574   2: 0.022962923252760 

test_20792        1: 0.449473576812253   0: 0.350839778273204   6: 0.070106902032866   5: 0.018524964941010   4: 0.018511746942893   9: 0.018508758109980   8: 0.018508748426097   7: 0.018508747703841   3: 0.018508500541535   2: 0.018508276216320 

test_20793        5: 0.775500482734808   4: 0.024949302972937   6: 0.024944945634280   0: 0.024943820940464   9: 0.024943767338541   1: 0.024943731716051   7: 0.024943643943822   2: 0.024943512259673   8: 0.024943465574728   3: 0.024943326884696 

test_20794        5: 0.822466345788824   4: 0.019729910113824   6: 0.019726595108607   1: 0.019725636084376   0: 0.019725495325163   8: 0.019725417754512   7: 0.019725403087318   9: 0.019725263855978   2: 0.019724984219063   3: 0.019724948662336 

test_20795        6: 0.742607957414108   0: 0.141469441866841   2: 0.014527070893455   3: 0.014502147764273   1: 0.014484679000506   5: 0.014482643675636   8: 0.014482440611998   9: 0.014482002764871   4: 0.014480848234698   7: 0.014480767773615 

test_20797        1: 0.828201005407128   4: 0.019095254227808   6: 0.019094655504075   5: 0.019089658280625   9: 0.019087468094589   0: 0.019087368904275   7: 0.019087006245430   8: 0.019086582043940   2: 0.019085704883208   3: 0.019085296408922 

test_20798        5: 0.317027809035528   2: 0.315498516677665   0: 0.248004065281630   6: 0.017098713436169   1: 0.017072436136175   4: 0.017061892813767   9: 0.017060241993846   8: 0.017059293820866   3: 0.017058593639038   7: 0.017058437165316 

test_20800        5: 0.452925516090781   7: 0.332485161555628   4: 0.026831232304001   3: 0.026822925509343   8: 0.026822916614420   2: 0.026822698405554   9: 0.026822519966923   0: 0.026822390217184   1: 0.026822345175390   6: 0.026822294160777 

test_20801        5: 0.783244735285614   4: 0.024086891766394   0: 0.024084435849791   1: 0.024083985736222   3: 0.024083606030217   2: 0.024083424859606   6: 0.024083388800400   8: 0.024083246895396   9: 0.024083224508593   7: 0.024083060267766 

test_20802        5: 0.737206185459038   4: 0.029206525322941   8: 0.029198726623719   3: 0.029198457558934   0: 0.029198447678826   2: 0.029198433597097   7: 0.029198373514471   1: 0.029198368910292   9: 0.029198316478882   6: 0.029198164855799 

test_20803        5: 0.766312316905770   2: 0.071485667891996   1: 0.020289343089972   6: 0.020278569793623   0: 0.020278323922079   7: 0.020275037882261   4: 0.020272249152840   9: 0.020269721166688   8: 0.020269467210397   3: 0.020269302984374 

test_20804        5: 0.756024158183989   4: 0.027114800119448   8: 0.027107991236510   3: 0.027107693020178   2: 0.027107619371084   0: 0.027107609201518   9: 0.027107604078119   7: 0.027107569893640   1: 0.027107520778584   6: 0.027107434116930 

test_20807        5: 0.660311457997122   6: 0.136655068904370   2: 0.025403309230478   0: 0.025378322950207   4: 0.025377484893809   8: 0.025376329535878   9: 0.025375775428535   1: 0.025374356252672   7: 0.025374149942374   3: 0.025373744864555 

test_20811        1: 0.455865157459918   2: 0.204946835750375   6: 0.168439898484251   8: 0.048020585550234   0: 0.027891084503092   5: 0.019025095654060   4: 0.019017949850351   9: 0.018931944170590   7: 0.018930790911086   3: 0.018930657666044 

test_20812        5: 0.803015511922789   4: 0.021888739681614   0: 0.021887733000320   9: 0.021887468101389   1: 0.021887156047843   6: 0.021887084854803   8: 0.021886985423402   2: 0.021886628478909   7: 0.021886442344805   3: 0.021886250144126 

test_20813        5: 0.548954151761110   3: 0.260671482368652   6: 0.023821435093470   0: 0.023820107382649   1: 0.023808203061129   4: 0.023789587640175   7: 0.023788818134668   9: 0.023783299323801   8: 0.023781594846965   2: 0.023781320387380 

test_20814        5: 0.783921085057619   3: 0.071437222684628   6: 0.018081824881739   4: 0.018081396908053   0: 0.018080639548508   1: 0.018080217227953   9: 0.018079632272786   8: 0.018079496454674   7: 0.018079246455878   2: 0.018079238508163 

test_20817        5: 0.716983132391104   4: 0.031448245517455   6: 0.031448094827333   0: 0.031446080863665   1: 0.031445942222393   3: 0.031445833696659   8: 0.031445738143951   7: 0.031445728591231   2: 0.031445665473424   9: 0.031445538272784 

test_20822        5: 0.654743735744940   8: 0.145138180093944   6: 0.080067034634429   0: 0.017153971779045   4: 0.017150939411170   1: 0.017150742346880   9: 0.017149364969504   7: 0.017148739402506   2: 0.017148666479053   3: 0.017148625138529 

test_20824        0: 0.424594434384809   6: 0.371251647648546   5: 0.113884325404948   1: 0.012919362778319   3: 0.012896303727371   7: 0.012893773074632   8: 0.012891576436732   9: 0.012889588948584   4: 0.012889561746535   2: 0.012889425849523 

test_20825        5: 0.492964142973465   7: 0.307640310108724   4: 0.024929628753415   6: 0.024924180937530   8: 0.024923968501791   0: 0.024923752461691   9: 0.024923572193420   3: 0.024923538950719   2: 0.024923480998369   1: 0.024923424120875 

test_20826        5: 0.676378617019070   4: 0.151391200254606   6: 0.021530053868061   0: 0.021530051265444   8: 0.021529062771627   9: 0.021528646899640   7: 0.021528487002103   1: 0.021528324115925   2: 0.021527867078717   3: 0.021527689724807 

test_20828        6: 0.748748058222323   1: 0.141508309740239   9: 0.023336677547359   3: 0.012348267854775   8: 0.012345507996401   0: 0.012343181677192   5: 0.012342985218057   7: 0.012342453671772   2: 0.012342341288746   4: 0.012342216783136 

test_20829        6: 0.690122189878172   1: 0.136053988986944   7: 0.053187988898416   0: 0.042847679717469   9: 0.012988077505080   5: 0.012961135655568   3: 0.012960572133963   8: 0.012959552116744   4: 0.012959421145503   2: 0.012959393962139 

test_20833        5: 0.456455739375355   2: 0.390958354845530   4: 0.019075720819072   6: 0.019074338343143   0: 0.019073781673236   8: 0.019072750146585   9: 0.019072558765826   1: 0.019072284245618   7: 0.019072257387842   3: 0.019072214397794 

test_20834        5: 0.309039296926088   6: 0.299670404936136   8: 0.265087338313000   9: 0.018031788270846   1: 0.018030819055494   0: 0.018029397480112   4: 0.018027919207314   7: 0.018027844393747   2: 0.018027700471202   3: 0.018027490946059 

test_20835        1: 0.786398130176953   8: 0.058992119568285   5: 0.019331885704391   4: 0.019331076259976   6: 0.019328867663018   9: 0.019325811797069   0: 0.019324354283462   3: 0.019323118245904   2: 0.019322416898207   7: 0.019322219402735 

test_20836        5: 0.762503880080126   4: 0.026391611337206   6: 0.026388512514229   8: 0.026388217797064   0: 0.026388019321318   3: 0.026388008805881   2: 0.026387974393230   9: 0.026387968689057   7: 0.026387910677232   1: 0.026387896384657 

test_20837        5: 0.806628817957991   6: 0.021488255098069   4: 0.021487294208757   8: 0.021486517702430   9: 0.021485789771825   0: 0.021485169559586   1: 0.021485126259169   7: 0.021484450314826   2: 0.021484384284954   3: 0.021484194842394 

test_20838        5: 0.795618827346936   4: 0.022712217677002   6: 0.022709142270795   8: 0.022708677839942   0: 0.022708603985827   1: 0.022708582859748   3: 0.022708537720056   7: 0.022708485696120   9: 0.022708474875365   2: 0.022708449728209 

test_20840        0: 0.767203294766154   9: 0.058709349599332   3: 0.021794107667213   2: 0.021768868404133   5: 0.021762283593088   6: 0.021757559557229   4: 0.021751630703950   1: 0.021751334983582   8: 0.021750988206242   7: 0.021750582519075 

test_20858        6: 0.595234155953197   3: 0.170239887470328   0: 0.029317826980619   1: 0.029316787771041   5: 0.029316084835854   8: 0.029315933007462   9: 0.029315057533230   7: 0.029314803237870   2: 0.029314748326346   4: 0.029314714884052 

test_20862        6: 0.762257898483185   1: 0.026435705743748   8: 0.026415527892415   0: 0.026415436105416   7: 0.026413231539198   9: 0.026412972522963   5: 0.026412644421792   3: 0.026412345648008   2: 0.026412126979162   4: 0.026412110664113 

test_20865        6: 0.794518965634726   0: 0.097234086635823   7: 0.032031821739191   3: 0.010893036213596   5: 0.010887713454923   1: 0.010887573180690   8: 0.010886824954281   9: 0.010886812173228   4: 0.010886638929410   2: 0.010886527084131 

test_20868        6: 0.588106455900257   0: 0.303230411709859   1: 0.041204232154925   8: 0.019197505754943   7: 0.008049977107319   2: 0.008043471068993   3: 0.008042899418140   9: 0.008042231778675   5: 0.008041613823172   4: 0.008041201283718 

test_20869        6: 0.503282355637011   7: 0.272241710957937   9: 0.123613309798461   1: 0.024781484367176   5: 0.012833789113733   0: 0.012668250347274   4: 0.012649644902490   2: 0.012645042418019   8: 0.012642570906812   3: 0.012641841551089 

test_20878        6: 0.769412522604709   1: 0.070743713721111   7: 0.047668170656888   0: 0.028903164244734   8: 0.014088438063441   9: 0.013898777097430   5: 0.013825534273609   4: 0.013822636694173   2: 0.013818883363670   3: 0.013818159280235 

test_20879        5: 0.680468454863375   3: 0.135152193799161   4: 0.023053102527707   6: 0.023047867400105   8: 0.023047637416699   9: 0.023046940468578   0: 0.023046336697743   1: 0.023046066288141   7: 0.023045869312566   2: 0.023045531225926 

test_20881        6: 0.737224635861412   9: 0.173392589738719   4: 0.011568273529452   0: 0.011204167019498   1: 0.011146377323877   8: 0.011094058182417   5: 0.011093307843565   3: 0.011092744332250   2: 0.011092129380537   7: 0.011091716788273 

test_20882        6: 0.803903869619989   9: 0.070467235815997   5: 0.030320531002017   8: 0.013623850059160   3: 0.013615453719651   1: 0.013614500431602   0: 0.013613940968637   7: 0.013613803791961   2: 0.013613421129303   4: 0.013613393461684 

test_20883        5: 0.457760450088232   4: 0.361468829388839   6: 0.022597939578658   1: 0.022596850726815   8: 0.022596415015570   0: 0.022596200773759   3: 0.022595968019541   7: 0.022595950733043   2: 0.022595698032628   9: 0.022595697642916 

test_20885        5: 0.475122068904665   4: 0.374193282445048   1: 0.018868778649377   0: 0.018831478118228   6: 0.018830983065670   2: 0.018830837781075   8: 0.018830693769345   7: 0.018830641495864   3: 0.018830621549640   9: 0.018830614221089 

test_20887        5: 0.733237406956593   0: 0.086825531786144   1: 0.022668741330690   7: 0.022496551913020   6: 0.022478328527403   8: 0.022460012246784   9: 0.022459170641797   4: 0.022458433015595   2: 0.022458171769067   3: 0.022457651812908 

test_20888        5: 0.628242996858759   4: 0.215062007756847   6: 0.019589198544892   8: 0.019587624612583   0: 0.019587507367940   1: 0.019587328199424   9: 0.019586629980937   7: 0.019585630428488   3: 0.019585539833495   2: 0.019585536416637 

test_20890        6: 0.579076702789872   1: 0.179920921940385   3: 0.077860898407570   8: 0.074546062095929   9: 0.032250927951928   7: 0.011357429454956   5: 0.011318544818745   0: 0.011226701237908   2: 0.011220914523024   4: 0.011220896779682 

test_20893        6: 0.757114855831581   3: 0.127410078415769   0: 0.014511720307997   1: 0.014447185345658   7: 0.014425027884145   5: 0.014419057795484   9: 0.014418494008500   8: 0.014418358274019   2: 0.014417666170222   4: 0.014417555966623 

test_20894        5: 0.810544053824169   6: 0.021054859914157   2: 0.021053648702520   4: 0.021051694852635   8: 0.021049773474899   0: 0.021049756506196   1: 0.021049497105559   7: 0.021048973142281   9: 0.021048893650951   3: 0.021048848826632 

test_20896        5: 0.469414131928575   4: 0.382957063474311   7: 0.018462957746395   6: 0.018455801034769   1: 0.018453935234625   0: 0.018453047557087   8: 0.018451165217335   9: 0.018450713160417   2: 0.018450648699923   3: 0.018450535946564 

test_20898        2: 0.358859751785462   6: 0.355620092420749   0: 0.150699167384464   5: 0.019268877636650   1: 0.019262850193200   7: 0.019260638645510   9: 0.019258341217793   4: 0.019257406867434   8: 0.019256723873282   3: 0.019256149975455 

test_20900        5: 0.811454173847559   8: 0.020973248131534   0: 0.020950105246467   4: 0.020948291406711   7: 0.020946100331245   9: 0.020945917492683   6: 0.020945912557689   1: 0.020945578380053   2: 0.020945414984161   3: 0.020945257621898 

test_20901        0: 0.346794595307046   5: 0.270366950578039   2: 0.189123972241735   1: 0.027681104701344   6: 0.027680955633498   9: 0.027673029033223   7: 0.027671908180979   8: 0.027670481049573   4: 0.027669008422413   3: 0.027667994852152 

test_20902        6: 0.657154752774184   9: 0.176366244964779   0: 0.054189322238030   1: 0.027915767913470   3: 0.014069081170097   2: 0.014065153565769   5: 0.014061482731251   7: 0.014061120219528   4: 0.014058706068369   8: 0.014058368354524 

test_20904        5: 0.495072346403748   6: 0.319270123447468   4: 0.023213582632725   8: 0.023206609304865   3: 0.023206362311679   2: 0.023206320584035   9: 0.023206245818618   7: 0.023206185925057   0: 0.023206115613658   1: 0.023206107958146 

test_20905        1: 0.481233423983667   2: 0.362390257405198   0: 0.038224753609769   4: 0.016898006602371   5: 0.016889600246028   6: 0.016875181064767   8: 0.016873987767668   9: 0.016872418464215   3: 0.016871390330174   7: 0.016870980526143 

test_20907        6: 0.675649135994630   0: 0.228784482050719   7: 0.011958025167653   1: 0.011947751792300   3: 0.011945555075182   8: 0.011945416856784   9: 0.011942961366140   5: 0.011942688740829   2: 0.011942015034260   4: 0.011941967921503 

test_20909        6: 0.341640110441609   3: 0.236575099809198   0: 0.144848585470010   9: 0.126900914286139   1: 0.048148318706184   8: 0.045436947855469   7: 0.014120938478233   2: 0.014109741223012   5: 0.014109718726015   4: 0.014109625004132 

test_20910        5: 0.481280475548227   8: 0.257624022858716   9: 0.090326073544002   7: 0.078013157912535   6: 0.015473684150560   1: 0.015464697243956   0: 0.015460648681218   2: 0.015455059730472   4: 0.015452560241626   3: 0.015449620088688 

test_20911        6: 0.820351154402532   0: 0.080535027935372   7: 0.020942402449319   8: 0.011168536279930   9: 0.011168151257256   1: 0.011167632157443   5: 0.011167300046259   3: 0.011166634377319   2: 0.011166602699513   4: 0.011166558395056 

test_20913        5: 0.458479237920231   4: 0.382308153050473   1: 0.019910486049619   0: 0.019905514172077   6: 0.019905425898017   2: 0.019899514603046   9: 0.019898055122479   8: 0.019897950173374   7: 0.019897878921869   3: 0.019897784088816 

test_20915        5: 0.792832033950107   4: 0.023024812293251   6: 0.023018587053611   0: 0.023017996804135   8: 0.023017975311240   9: 0.023017960384711   1: 0.023017753438239   3: 0.023017654661470   2: 0.023017622638060   7: 0.023017603465177 

test_20917        0: 0.813130547731111   1: 0.020775675932106   6: 0.020765355780643   5: 0.020765224938528   4: 0.020762915268597   2: 0.020760551616004   7: 0.020760054687530   3: 0.020760022804930   9: 0.020759853272429   8: 0.020759797968123 

test_20918        5: 0.537456633586688   8: 0.286435228643138   4: 0.022016331204958   6: 0.022015363339211   9: 0.022013232604538   0: 0.022013183566057   1: 0.022012601256501   7: 0.022012546964830   2: 0.022012520635331   3: 0.022012358198747 

test_20919        2: 0.516828172831695   6: 0.331119002204944   5: 0.019010585879806   4: 0.019006769463831   1: 0.019006537273413   0: 0.019006230007899   9: 0.019005993026990   3: 0.019005714737540   7: 0.019005499353748   8: 0.019005495220134 

test_20920        5: 0.788957292212593   4: 0.023454834296272   1: 0.023451358365937   0: 0.023449645803802   6: 0.023448977721987   8: 0.023448251655503   9: 0.023447924280122   3: 0.023447464805219   7: 0.023447146626083   2: 0.023447104232481 

test_20921        5: 0.451599020491983   4: 0.334932555488193   1: 0.026690032625399   0: 0.026689745323265   6: 0.026687882038450   2: 0.026685399362290   9: 0.026681204414773   8: 0.026678361682581   7: 0.026678086995083   3: 0.026677711577982 

test_20922        6: 0.489746813679294   0: 0.203822334514959   9: 0.181177403883389   5: 0.035337371797521   1: 0.014990580775542   8: 0.014988003370780   3: 0.014985724412428   7: 0.014984001803392   2: 0.014983975441354   4: 0.014983790321343 

test_20925        6: 0.769806477021617   0: 0.131012778448720   1: 0.012650854535937   3: 0.012374899670438   7: 0.012362203264142   8: 0.012359220065492   5: 0.012359188397249   9: 0.012358263071111   2: 0.012358084012057   4: 0.012358031513235 

test_20926        5: 0.726727707141129   4: 0.030366623597708   0: 0.030363901429763   6: 0.030363498993619   1: 0.030363163672243   8: 0.030363137895177   3: 0.030363040607562   7: 0.030363005085473   2: 0.030362993440026   9: 0.030362928137299 

test_20927        4: 0.623793209840804   8: 0.158922948039324   5: 0.027170097597144   3: 0.027159424977325   2: 0.027159243406355   0: 0.027159127427680   1: 0.027159100061156   9: 0.027159095058872   7: 0.027158964204250   6: 0.027158789387091 

test_20930        5: 0.798524489745006   6: 0.022390037317055   9: 0.022389655996411   8: 0.022389498802230   1: 0.022386897184738   0: 0.022385784756778   4: 0.022385346030333   2: 0.022383061290802   7: 0.022382630022314   3: 0.022382598854334 

test_20931        5: 0.820935391666520   6: 0.019897833303189   8: 0.019897598735220   4: 0.019897141868208   0: 0.019895974759355   9: 0.019895782595905   1: 0.019895312784637   7: 0.019895166561984   2: 0.019895019183482   3: 0.019894778541500 

test_20932        5: 0.788128020189134   4: 0.023544569949544   1: 0.023541258682707   8: 0.023541147316721   0: 0.023541079610889   9: 0.023541070188872   6: 0.023541040662258   3: 0.023540660135610   2: 0.023540632205833   7: 0.023540521058433 

test_20936        2: 0.546689592198436   7: 0.213511018388167   6: 0.120466251971010   5: 0.017053143930452   4: 0.017047782098562   0: 0.017047293116678   9: 0.017047058948394   1: 0.017046928219266   8: 0.017045709027712   3: 0.017045222101322 

test_20937        5: 0.845265358635506   6: 0.017232219097473   0: 0.017202825500843   1: 0.017194932761303   4: 0.017184654274687   7: 0.017184608356364   9: 0.017184353450533   8: 0.017183868906066   3: 0.017183786350466   2: 0.017183392666759 

test_20938        4: 0.786176146649596   9: 0.064741622629117   5: 0.018647718093582   0: 0.018634706695948   6: 0.018634671956104   7: 0.018633829130670   1: 0.018632965711447   8: 0.018632951069675   2: 0.018632728508173   3: 0.018632659555687 

test_20941        6: 0.685735220445934   3: 0.123724190734235   0: 0.023824403164753   8: 0.023818551057225   1: 0.023818449571088   5: 0.023816639394130   9: 0.023816247197643   2: 0.023815813634126   7: 0.023815413395392   4: 0.023815071405473 

test_20943        5: 0.798524913257772   6: 0.022389850808377   9: 0.022389653412518   8: 0.022389496351207   1: 0.022386895508771   0: 0.022385783489086   4: 0.022385117635485   2: 0.022383060985074   7: 0.022382629854652   3: 0.022382598697057 

test_20944        2: 0.570819648953144   7: 0.210646330156069   5: 0.027322973969982   6: 0.027319595968916   9: 0.027318494760835   4: 0.027318408041449   1: 0.027314047484528   8: 0.027313979977238   0: 0.027313706392437   3: 0.027312814295403 

test_20945        5: 0.496409760686228   1: 0.243099397995372   2: 0.088327525780553   3: 0.057297275202088   6: 0.019150850437285   0: 0.019145214193518   9: 0.019143029103661   8: 0.019142598202305   7: 0.019142391411912   4: 0.019141956987078 

test_20946        9: 0.727882861974767   5: 0.104995476624873   3: 0.020896765442377   6: 0.020895693026428   1: 0.020891879735351   0: 0.020889645450139   4: 0.020887887539146   2: 0.020886873788394   8: 0.020886720637823   7: 0.020886195780703 

test_20947        5: 0.764883764649541   4: 0.078861222033925   6: 0.019532581600107   0: 0.019531989947590   1: 0.019531860460412   9: 0.019531855352801   8: 0.019531806291716   3: 0.019531676116169   2: 0.019531624275975   7: 0.019531619271765 

test_20948        6: 0.592944482081325   0: 0.211505316294244   1: 0.024447253595851   5: 0.024443709404594   7: 0.024443635457933   8: 0.024443342336420   3: 0.024443228662592   9: 0.024443097529429   4: 0.024443059056820   2: 0.024442875580792 

test_20949        5: 0.592883895498273   8: 0.198726193751967   1: 0.066234332964001   4: 0.020311886986552   6: 0.020309050286215   0: 0.020307576784847   9: 0.020306882252538   3: 0.020306805003002   7: 0.020306766648321   2: 0.020306609824283 

test_20954        5: 0.795183455096230   4: 0.022759877420580   6: 0.022759663823484   8: 0.022757538963869   0: 0.022757332889410   9: 0.022757061331053   1: 0.022756853138615   2: 0.022756229914767   7: 0.022756150263616   3: 0.022755837158376 

test_20958        6: 0.593358694453760   0: 0.211091091715232   1: 0.024447266933080   5: 0.024443708684432   7: 0.024443635297733   8: 0.024443342014182   3: 0.024443229135261   9: 0.024443097328630   4: 0.024443058875871   2: 0.024442875561818 

test_20959        6: 0.475226921286777   1: 0.368967246962532   3: 0.039232890595845   9: 0.030647519880245   0: 0.014327191941878   8: 0.014322650141760   5: 0.014319213744412   7: 0.014318909814936   4: 0.014318789897099   2: 0.014318665734515 

test_20968        5: 0.716338507797465   9: 0.106935351242990   4: 0.022096834844156   2: 0.022090920958664   6: 0.022090345572540   8: 0.022089718716167   0: 0.022089692944758   3: 0.022089647810407   1: 0.022089509583392   7: 0.022089470529462 

test_20969        4: 0.757393801834109   5: 0.026961945234865   3: 0.026955724729473   8: 0.026955723383037   2: 0.026955648287145   1: 0.026955506160529   0: 0.026955488918570   9: 0.026955431981837   7: 0.026955428470519   6: 0.026955300999917 

test_20972        5: 0.685804961642210   4: 0.173674809194965   8: 0.017568031081336   0: 0.017566481999868   6: 0.017566014234728   9: 0.017564597822909   7: 0.017564207961506   1: 0.017564009903443   2: 0.017563507479290   3: 0.017563378679746 

test_20973        5: 0.684166449752156   2: 0.145326692639989   4: 0.021315098399571   6: 0.021314466404964   8: 0.021313719477862   1: 0.021313240786012   9: 0.021313161071700   0: 0.021313101441488   7: 0.021312054394085   3: 0.021312015632172 

test_20974        5: 0.776705376838794   4: 0.024813545598437   1: 0.024811770237438   0: 0.024810964067746   9: 0.024810517519980   6: 0.024809907747419   8: 0.024809668844586   7: 0.024809487134744   3: 0.024809385417650   2: 0.024809376593206 

test_20975        4: 0.486540727994582   5: 0.354050063869380   1: 0.019934803012343   6: 0.019931591260803   0: 0.019930993913813   2: 0.019923273835509   9: 0.019922282801576   8: 0.019922148875164   7: 0.019922138963748   3: 0.019921975473083 

test_20976        5: 0.825115761878236   4: 0.019435390347457   0: 0.019431428805873   6: 0.019431330476955   1: 0.019431139255123   8: 0.019431075630455   9: 0.019431025546511   2: 0.019430954595038   3: 0.019430954170561   7: 0.019430939293791 

test_20979        9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

test_20981        6: 0.336381281846267   8: 0.291258818726961   9: 0.149619316611926   1: 0.102525452987288   3: 0.058167493854914   7: 0.012417811962496   0: 0.012416645771721   4: 0.012405118313189   5: 0.012404255822405   2: 0.012403804102834 

test_20982        3: 0.367151016549834   0: 0.307248864127251   6: 0.187857693645763   7: 0.033495840676020   1: 0.017401461366699   5: 0.017373509079262   9: 0.017368328139980   4: 0.017368037887648   8: 0.017367923319764   2: 0.017367325207779 

test_20983        5: 0.738629739587887   4: 0.029045604537262   8: 0.029040768891088   3: 0.029040698323972   2: 0.029040677128128   0: 0.029040547742055   7: 0.029040521304010   1: 0.029040503786084   9: 0.029040483075757   6: 0.029040455623757 

test_20984        5: 0.785060734892726   8: 0.023897151278468   6: 0.023886227057052   0: 0.023884151813571   9: 0.023881709262670   4: 0.023881496819679   7: 0.023878172333715   3: 0.023876898170405   2: 0.023876785937579   1: 0.023876672434135 

test_20988        5: 0.792674651925828   4: 0.023039848095811   6: 0.023037908680249   0: 0.023035696965136   8: 0.023035554287602   1: 0.023035495798976   3: 0.023035469962533   9: 0.023035208871328   2: 0.023035128097145   7: 0.023035037315393 

test_20989        6: 0.817776540078939   1: 0.067623080776276   3: 0.023265114056468   8: 0.022925077309333   5: 0.011406432567744   0: 0.011403894818202   9: 0.011400876880013   7: 0.011399953298144   4: 0.011399598945567   2: 0.011399431269315 

test_20991        6: 0.742988434523963   9: 0.064549560590882   1: 0.063675897498004   0: 0.047287779306015   8: 0.013588015519006   3: 0.013585353511562   5: 0.013584376974446   2: 0.013581947190199   4: 0.013579529127989   7: 0.013579105757935 

test_20995        3: 0.733820016056058   9: 0.029612963830333   6: 0.029587023647708   0: 0.029584679714454   8: 0.029577688253455   1: 0.029569240139825   5: 0.029563782908974   4: 0.029563267687119   2: 0.029560867931463   7: 0.029560469830611 

test_21000        7: 0.416891097559342   6: 0.286088825764491   9: 0.146834534336351   5: 0.021470917505473   1: 0.021458769970338   0: 0.021455661398297   8: 0.021452335154324   2: 0.021449760875014   3: 0.021449272143214   4: 0.021448825293155 

test_21002        6: 0.669758511443624   8: 0.129966699397679   9: 0.068496885519598   1: 0.056991307103517   0: 0.030364210905988   7: 0.009407399417513   3: 0.008757278242427   2: 0.008754402152924   5: 0.008752191158413   4: 0.008751114658316 

test_21003        7: 0.553644704149532   1: 0.235595107712842   6: 0.026349309298113   0: 0.026348332367582   5: 0.026346237782377   2: 0.026345137577307   4: 0.026344309051310   9: 0.026342743361978   8: 0.026342143986743   3: 0.026341974712215 

test_21006        6: 0.617927228197409   8: 0.148577448699047   1: 0.127038400642090   9: 0.039026272991006   2: 0.015873508468260   5: 0.011701461017275   3: 0.010353608005035   0: 0.009854741293879   4: 0.009842200777728   7: 0.009805129908270 

test_21007        1: 0.380605411249029   7: 0.255870441630478   6: 0.141533234641350   0: 0.057968991510314   5: 0.054668593588422   4: 0.021874941867718   2: 0.021871662927701   3: 0.021871028438206   8: 0.021868314052226   9: 0.021867380094556 

test_21012        5: 0.769999474458806   4: 0.025558248058071   0: 0.025555727960467   8: 0.025555433720308   6: 0.025555360903373   9: 0.025555245706929   3: 0.025555182721431   2: 0.025555162649189   7: 0.025555093345850   1: 0.025555070475575 

test_21013        6: 0.600520735097386   1: 0.176794067513684   0: 0.059952910762535   8: 0.042759803743777   9: 0.037565040554165   3: 0.030588394081073   7: 0.024760353616952   2: 0.009028079516333   5: 0.009017004765822   4: 0.009013610348273 

test_21014        4: 0.637521141418317   5: 0.168185584152701   2: 0.024292647525298   6: 0.024289378421334   8: 0.024285477747111   3: 0.024285283775237   0: 0.024285182340792   9: 0.024285171882517   1: 0.024285087656356   7: 0.024285045080337 

test_21016        5: 0.691717686081290   3: 0.120633093820849   6: 0.023461490740094   4: 0.023456876393655   8: 0.023456264367169   9: 0.023456022458107   0: 0.023455159861074   1: 0.023454584571560   2: 0.023454436008457   7: 0.023454385697745 

test_21017        5: 0.760607482831239   2: 0.087620395724045   6: 0.018980527913912   0: 0.018972541499576   4: 0.018970875727461   1: 0.018970542083624   9: 0.018969630424734   7: 0.018969627263428   8: 0.018969195500277   3: 0.018969181031705 

test_21018        2: 0.557766914135888   6: 0.218018070407311   9: 0.069819196143174   8: 0.059751896898533   4: 0.015793256427889   1: 0.015783812148084   3: 0.015780311221208   0: 0.015766960160994   5: 0.015760246810996   7: 0.015759335645922 

test_21019        1: 0.493038740844178   6: 0.369967988554400   0: 0.017138440208403   9: 0.017127207310886   5: 0.017123947045816   8: 0.017122217301466   3: 0.017120628552974   4: 0.017120553907200   2: 0.017120202708914   7: 0.017120073565765 

test_21022        5: 0.754493277271181   4: 0.027281129548879   6: 0.027279016110828   1: 0.027278924462068   0: 0.027278657361591   3: 0.027277935081349   8: 0.027277879902318   7: 0.027277753899290   2: 0.027277727029828   9: 0.027277699332667 

test_21023        6: 0.787940952993288   1: 0.085755994330058   0: 0.015791361215985   9: 0.015788286656103   8: 0.015787871925602   5: 0.015787554409559   7: 0.015787246833355   4: 0.015786936347955   2: 0.015786909948871   3: 0.015786885339223 

test_21028        5: 0.846543153702216   3: 0.017053426573168   6: 0.017051935359037   0: 0.017050961735752   1: 0.017050701282253   4: 0.017050408488798   8: 0.017050342415975   9: 0.017050050206441   2: 0.017049541010988   7: 0.017049479225372 

test_21030        1: 0.673196346618494   0: 0.182757389447290   2: 0.018016129544429   6: 0.018011009563545   5: 0.018008252041404   9: 0.018003463108150   4: 0.018002148859396   7: 0.018001939029845   8: 0.018001856769028   3: 0.018001465018420 

test_21031        6: 0.697888087143969   1: 0.175470594180101   5: 0.015845883049956   9: 0.015833658237710   0: 0.015828600470174   4: 0.015827623346986   2: 0.015826815454919   7: 0.015826531412620   3: 0.015826117022691   8: 0.015826089680873 

test_21032        5: 0.760437870119468   4: 0.026621047839636   6: 0.026617895029333   1: 0.026617805203587   0: 0.026617703350601   8: 0.026617696526679   3: 0.026617584011240   9: 0.026617546019708   2: 0.026617439673374   7: 0.026617412226374 

test_21034        4: 0.701751842638502   2: 0.086380668914052   7: 0.066237394392654   5: 0.020810999291854   6: 0.020803799234317   0: 0.020803718258880   1: 0.020803095803585   8: 0.020802954345631   9: 0.020802837110370   3: 0.020802690010156 

test_21036        5: 0.758665659101259   4: 0.026817211727940   6: 0.026816999903280   8: 0.026815449489586   1: 0.026815352960303   9: 0.026815004959463   7: 0.026814092085969   0: 0.026814027893958   2: 0.026813252179339   3: 0.026812949698903 

test_21037        5: 0.770397396209111   0: 0.025523277113044   4: 0.025513144145527   8: 0.025509640858855   3: 0.025509577124024   2: 0.025509479811945   1: 0.025509409641346   9: 0.025509404661659   7: 0.025509403572002   6: 0.025509266862487 

test_21038        5: 0.767654666543247   4: 0.025820711027175   8: 0.025815817039491   3: 0.025815670535880   0: 0.025815621624681   1: 0.025815599893172   6: 0.025815537589335   2: 0.025815516327014   9: 0.025815441717251   7: 0.025815417702753 

test_21039        5: 0.635370907316172   7: 0.154772757451451   3: 0.069002639473523   6: 0.020139970476060   8: 0.020129424640060   0: 0.020127853655628   9: 0.020126031613601   1: 0.020112332768349   4: 0.020109389404053   2: 0.020108693201103 

test_21040        6: 0.479437917176351   3: 0.360103249762702   4: 0.020244186873676   0: 0.020124787048237   1: 0.020039291960813   5: 0.020015476177622   9: 0.020009672709573   2: 0.020009094390356   8: 0.020008772956794   7: 0.020007550943876 

test_21041        5: 0.756422380593039   1: 0.082871536888323   6: 0.020097903651925   0: 0.020088723699807   2: 0.020087001062884   4: 0.020086769027395   7: 0.020086560779422   8: 0.020086478721254   3: 0.020086325323892   9: 0.020086320252058 

test_21042        5: 0.588131686525638   3: 0.209326520066426   4: 0.025321235724422   0: 0.025319153265182   6: 0.025317483937563   1: 0.025317365138176   2: 0.025316786770260   7: 0.025316754820821   8: 0.025316540378321   9: 0.025316473373191 

test_21044        4: 0.611543922396261   5: 0.196590653878727   6: 0.023993384693341   1: 0.023989669926173   0: 0.023985089947838   8: 0.023984170242045   7: 0.023980212993444   2: 0.023978013158970   9: 0.023977820543214   3: 0.023977062219988 

test_21045        5: 0.513281712056853   3: 0.278833988989079   4: 0.025990719068371   0: 0.025987543441950   6: 0.025984889670631   1: 0.025984780356450   8: 0.025984542744993   9: 0.025984035768013   2: 0.025983954907929   7: 0.025983832995731 

test_21046        9: 0.528156515052552   6: 0.260010674121878   0: 0.058252593894052   5: 0.021975474822878   1: 0.021964917105655   4: 0.021939775154397   2: 0.021926189016256   7: 0.021925414925197   3: 0.021925146946075   8: 0.021923298961061 

test_21047        5: 0.545964873623467   2: 0.259184641536790   4: 0.024364083366078   6: 0.024356828552030   8: 0.024355983103362   0: 0.024355020925847   3: 0.024354735285024   9: 0.024354713784419   1: 0.024354640014644   7: 0.024354479808339 

test_21049        5: 0.646714670454452   0: 0.158199097891365   4: 0.024389946971135   9: 0.024387749158045   1: 0.024386459041102   8: 0.024384515686382   7: 0.024384465815739   3: 0.024384428140486   2: 0.024384416920637   6: 0.024384249920658 

test_21050        5: 0.818725580354791   1: 0.020143923945528   0: 0.020143454663542   6: 0.020143432337264   2: 0.020141942731300   9: 0.020141537924702   8: 0.020140283945047   4: 0.020140263927626   7: 0.020140090984855   3: 0.020139489185345 

test_21051        5: 0.542889265839315   8: 0.331660094333746   4: 0.015684245252330   1: 0.015683143773711   6: 0.015682515600451   0: 0.015682273010189   2: 0.015680372765576   3: 0.015679921002466   9: 0.015679161197983   7: 0.015679007224233 

test_21053        5: 0.780146434102550   4: 0.024432239724662   1: 0.024427895828444   0: 0.024427855517261   6: 0.024427718553235   8: 0.024427653777347   3: 0.024427631957189   2: 0.024427575615468   7: 0.024427504098051   9: 0.024427490825790 

test_21055        4: 0.794662002283736   1: 0.022824845614330   5: 0.022820773851139   6: 0.022815033787212   9: 0.022813603248366   8: 0.022813481221603   0: 0.022813304006196   7: 0.022812369077924   2: 0.022812362613888   3: 0.022812224295607 

test_21058        9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

test_21059        3: 0.371279813853666   1: 0.258463870036209   4: 0.164136338119724   0: 0.029459246195388   6: 0.029446582927465   5: 0.029443747394001   9: 0.029442791130671   8: 0.029442782125451   2: 0.029442503183308   7: 0.029442325034116 

test_21060        6: 0.580106520121202   5: 0.276883189034922   1: 0.017891110550970   0: 0.017884750267743   2: 0.017874162569936   4: 0.017874151590909   9: 0.017872525549591   8: 0.017871530454374   3: 0.017871358221157   7: 0.017870701639196 

test_21061        9: 0.495522641423581   5: 0.286884956479227   1: 0.027225903209566   6: 0.027225388175900   0: 0.027203955898335   4: 0.027187993099017   7: 0.027187992139798   2: 0.027187216064218   8: 0.027187062200914   3: 0.027186891309445 

test_21063        9: 0.545912743631136   5: 0.236501738561915   6: 0.027218565724527   1: 0.027207501045824   0: 0.027198870185567   4: 0.027193290371746   3: 0.027192493046466   8: 0.027192347047047   7: 0.027191929263399   2: 0.027190521122373 

test_21065        5: 0.591590140228194   6: 0.223963814867661   4: 0.044208902456834   1: 0.040632320951800   0: 0.016620379173882   7: 0.016606953108996   8: 0.016603520683296   2: 0.016592457026770   9: 0.016590804964029   3: 0.016590706538538 

test_21067        2: 0.784617167682857   1: 0.046638192478729   5: 0.042677670588842   8: 0.018018041011737   6: 0.018010910319175   0: 0.018008667083543   7: 0.018007718965636   4: 0.018007584648962   9: 0.018007274775442   3: 0.018006772445077 

test_21071        1: 0.489044350338192   6: 0.338708733211854   5: 0.021535308547493   0: 0.021531801968394   4: 0.021531015185001   9: 0.021530049873604   2: 0.021529998778549   7: 0.021529620105253   8: 0.021529619388491   3: 0.021529502603169 

test_21073        5: 0.717832744247356   7: 0.097456438729910   1: 0.043134047759132   6: 0.020232255192964   0: 0.020230376945688   9: 0.020225365278210   8: 0.020224397715863   4: 0.020222564962781   2: 0.020221003322219   3: 0.020220805845878 

test_21076        6: 0.670787787271214   7: 0.101291599643933   3: 0.071599381289750   9: 0.051124807811049   8: 0.017533898541253   1: 0.017533176513826   0: 0.017533028314731   2: 0.017532485755834   5: 0.017532078758982   4: 0.017531756099429 

test_21077        5: 0.635191999858675   6: 0.163495180948953   0: 0.025168840165361   1: 0.025165519547987   4: 0.025164242930744   3: 0.025164174774034   8: 0.025163124407997   9: 0.025162788898995   7: 0.025162229381221   2: 0.025161899086033 

test_21078        0: 0.444138585185646   5: 0.310999995642991   2: 0.112848993855350   1: 0.028090109544828   6: 0.025168352543364   3: 0.015997241832192   8: 0.015731006049806   4: 0.015689600847152   9: 0.015673037853841   7: 0.015663076644830 

test_21080        6: 0.551297376849056   8: 0.230499001550759   0: 0.061035400607044   7: 0.048300661546153   4: 0.037006340309005   3: 0.023334597613590   5: 0.012141609033802   1: 0.012138706828920   9: 0.012123519668422   2: 0.012122785993250 

test_21081        5: 0.644403834127987   1: 0.159706145364502   4: 0.024490872476939   8: 0.024485726057469   3: 0.024485655330834   0: 0.024485593275177   9: 0.024485570336811   2: 0.024485536770614   7: 0.024485533734311   6: 0.024485532525357 

test_21082        9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

test_21091        8: 0.595943595443526   1: 0.183406395215356   6: 0.027606721531147   7: 0.027579347832592   0: 0.027578543079092   9: 0.027577238746033   5: 0.027577236008246   2: 0.027577037144610   3: 0.027576981187961   4: 0.027576903811437 

test_21093        7: 0.414041837720753   6: 0.346729905893906   5: 0.087013481094039   1: 0.021751478481794   0: 0.021747772084627   8: 0.021745666944908   9: 0.021744116392218   4: 0.021743062223958   2: 0.021742638863433   3: 0.021740040300364 

test_21095        4: 0.695708905798542   1: 0.122233271484816   5: 0.022761752694856   0: 0.022758565451001   7: 0.022758555418264   6: 0.022758479330625   8: 0.022755505574625   9: 0.022755484670390   2: 0.022754774890651   3: 0.022754704686230 

test_21096        6: 0.773548710000190   9: 0.063520326038147   5: 0.020367519451422   0: 0.020366601022931   8: 0.020366590671661   1: 0.020366476922851   7: 0.020366146753163   4: 0.020366083979416   2: 0.020365876329584   3: 0.020365668830636 

test_21097        1: 0.497503259899253   5: 0.179230269860711   8: 0.176598010436883   6: 0.020964716577406   2: 0.020953359033392   0: 0.020952215677991   3: 0.020949882146523   4: 0.020949613480584   9: 0.020949468276508   7: 0.020949204610748 

test_21100        5: 0.577757722749690   3: 0.219155611934373   1: 0.025388856345977   4: 0.025388338225667   0: 0.025386972314298   6: 0.025385044772099   2: 0.025384494823366   8: 0.025384446343207   7: 0.025384266205963   9: 0.025384246285360 

test_21103        5: 0.570435037760033   4: 0.228712223343088   7: 0.079101284985655   1: 0.017396081890640   9: 0.017393672870963   6: 0.017392882454682   0: 0.017392392015622   8: 0.017392290143372   3: 0.017392074604430   2: 0.017392059931516 

test_21105        5: 0.750358206286493   4: 0.027741991374799   8: 0.027739196486235   6: 0.027738754714697   9: 0.027738333229515   0: 0.027737409305189   1: 0.027736846093122   3: 0.027736492205257   2: 0.027736396669397   7: 0.027736373635295 

test_21106        5: 0.667636045108985   8: 0.139307657332596   4: 0.024137417392271   6: 0.024133870452326   1: 0.024133283525983   0: 0.024132298966105   7: 0.024130156521279   3: 0.024129854982028   9: 0.024129713363084   2: 0.024129702355344 

test_21109        5: 0.760153775409494   8: 0.074654824314942   6: 0.020650674006243   4: 0.020650264435471   7: 0.020648982875463   9: 0.020648976712657   0: 0.020648367644416   1: 0.020648155347590   2: 0.020648031820750   3: 0.020647947432974 

test_21112        5: 0.667609607928656   2: 0.167542273596820   6: 0.020630027579378   0: 0.020606779239623   1: 0.020604949598484   3: 0.020603605084058   8: 0.020603339150112   4: 0.020603019258832   9: 0.020598517486655   7: 0.020597881077382 

test_21113        5: 0.619913421045254   1: 0.179136843685727   4: 0.025121072909754   6: 0.025121012483334   8: 0.025119614566564   9: 0.025118542510715   0: 0.025117649174938   7: 0.025117429039659   2: 0.025117408355532   3: 0.025117006228523 

test_21114        5: 0.553646753303667   4: 0.190822750783818   3: 0.107320037815524   1: 0.021182693420840   2: 0.021173231717658   6: 0.021171720721306   0: 0.021171505190235   7: 0.021170498949641   8: 0.021170461199514   9: 0.021170346897797 

test_21117        4: 0.775313379774774   5: 0.024972694964327   6: 0.024966759848444   8: 0.024965203908792   9: 0.024965122954544   0: 0.024963869201603   7: 0.024963524540462   2: 0.024963230807241   1: 0.024963204770443   3: 0.024963009229370 

test_21122        0: 0.440574665089124   6: 0.290917384565128   3: 0.148563782337282   1: 0.017136383966550   8: 0.017135110257196   7: 0.017135029190764   5: 0.017134876248468   9: 0.017134500461534   2: 0.017134178935927   4: 0.017134088948026 

test_21123        6: 0.830455914818254   0: 0.044124112948174   5: 0.015689149900568   8: 0.015682640928082   1: 0.015682151213029   9: 0.015673913320379   4: 0.015673246502238   7: 0.015673219397091   2: 0.015672913063075   3: 0.015672737909108 

test_21124        6: 0.393657933700002   9: 0.383140557383281   8: 0.027903805964343   5: 0.027903741378810   4: 0.027901406100017   0: 0.027901142386405   1: 0.027899996260222   7: 0.027898147686750   2: 0.027896803421790   3: 0.027896465718380 

test_21128        6: 0.611053724166678   3: 0.126263779916996   5: 0.085651034823889   0: 0.048967316799190   1: 0.039217333246393   7: 0.017778589265185   8: 0.017770625356094   2: 0.017767239026665   9: 0.017765202986201   4: 0.017765154412708 

test_21129        5: 0.746236290759295   1: 0.073194937812218   0: 0.042731308751350   2: 0.019758474754609   4: 0.019748269827387   6: 0.019675913377608   9: 0.019664872505353   8: 0.019664414074073   7: 0.019663094215927   3: 0.019662423922180 

test_21130        6: 0.372023982471902   0: 0.285432650296568   5: 0.154547178845082   1: 0.088762766992330   8: 0.016547437249197   3: 0.016542447014916   9: 0.016536855712656   7: 0.016535882209583   2: 0.016535821494642   4: 0.016534977713126 

test_21131        6: 0.567387809788648   1: 0.179118966945970   8: 0.141141559523982   0: 0.040930888584472   9: 0.019124961268449   7: 0.016582986645414   2: 0.008932161917562   5: 0.008929607320183   3: 0.008927141018443   4: 0.008923916986876 

test_21132        5: 0.794395858414734   6: 0.022848781369633   7: 0.022848028587763   1: 0.022847447871461   4: 0.022846413934334   0: 0.022843343645916   8: 0.022843141742826   9: 0.022842778159795   3: 0.022842338050988   2: 0.022841868222549 

test_21133        1: 0.481170726612478   9: 0.301436140132769   7: 0.077377343015028   0: 0.020006653851463   5: 0.020004398380386   6: 0.020003711613719   4: 0.020001228622770   8: 0.020000547521262   2: 0.019999731484396   3: 0.019999518765728 

test_21134        4: 0.550632685121217   7: 0.224609866481753   1: 0.062134996732118   0: 0.023298426856275   6: 0.023295100701442   5: 0.023246654179051   2: 0.023216690782180   3: 0.023196700907982   9: 0.023195770384945   8: 0.023173107853036 

test_21135        5: 0.817917588625615   4: 0.020233753704436   6: 0.020231885896563   0: 0.020231214819968   7: 0.020231019189809   8: 0.020230968364591   9: 0.020230958021787   3: 0.020230909713634   2: 0.020230854621328   1: 0.020230847042269 

test_21136        5: 0.599521744467807   0: 0.232573385081249   1: 0.020994469555145   3: 0.020992944148764   6: 0.020988004591868   7: 0.020986739542260   4: 0.020986587640682   2: 0.020985935450883   8: 0.020985155635641   9: 0.020985033885703 

test_21138        6: 0.454585353976395   0: 0.276296905112421   3: 0.163484188179369   4: 0.015389592414418   7: 0.015255951741740   1: 0.015012700814580   8: 0.014994124780842   5: 0.014993910735470   9: 0.014993716190465   2: 0.014993556054300 

test_21140        5: 0.479950282148440   6: 0.359811755150322   3: 0.020033513593708   1: 0.020033178019424   0: 0.020030777799527   4: 0.020028952712119   9: 0.020028387774342   2: 0.020027930435461   7: 0.020027701313512   8: 0.020027521053145 

test_21142        5: 0.490218337715143   4: 0.365702365174985   0: 0.018018452999199   6: 0.018011012486522   8: 0.018009769991212   9: 0.018008817193953   1: 0.018008320826701   2: 0.018007973151475   7: 0.018007570292817   3: 0.018007380167992 

test_21143        5: 0.497380950083871   6: 0.315281691099618   9: 0.023431619175594   8: 0.023418149932371   1: 0.023417791124126   3: 0.023416090272097   0: 0.023414287910749   2: 0.023413753440683   4: 0.023413297631621   7: 0.023412369329273 

test_21146        5: 0.565422854960271   4: 0.272734780134707   6: 0.020232025803797   8: 0.020230710194552   0: 0.020230352542525   9: 0.020230255874146   1: 0.020230237170596   2: 0.020229668026073   7: 0.020229632931589   3: 0.020229482361744 

test_21148        5: 0.581109796872495   2: 0.190189123767547   6: 0.028593981880958   4: 0.028592809895685   0: 0.028587528183981   3: 0.028585695085257   8: 0.028585443534402   1: 0.028585253545417   9: 0.028585233568719   7: 0.028585133665539 

test_21149        8: 0.371425748255919   6: 0.370501797369911   9: 0.139333648892805   0: 0.036046072344668   3: 0.022258899509419   1: 0.012110210232911   7: 0.012086834115670   5: 0.012079609219552   2: 0.012078697931792   4: 0.012078482127352 

test_21151        0: 0.425602498918635   6: 0.232583049727544   5: 0.149351051053143   8: 0.027523118467662   3: 0.027506241604982   7: 0.027489412850414   1: 0.027488112601807   2: 0.027485628606695   4: 0.027485444264891   9: 0.027485441904227 

test_21152        6: 0.693350555244709   0: 0.198474399735128   3: 0.013526076943088   5: 0.013522861486564   1: 0.013521999195007   8: 0.013521196413169   9: 0.013521173806812   4: 0.013520761057493   7: 0.013520491466326   2: 0.013520484651704 

test_21157        6: 0.626362472341827   0: 0.155891730594683   1: 0.072108822910601   5: 0.068531021006742   7: 0.012866638693284   8: 0.012850547284458   9: 0.012847362934300   3: 0.012847188454018   2: 0.012847120183758   4: 0.012847095596329 

test_21163        6: 0.304274104395415   0: 0.281093173101969   3: 0.237040801542331   5: 0.025371195781578   1: 0.025371120538149   9: 0.025370182127970   8: 0.025370065558109   7: 0.025369852445860   2: 0.025369752381625   4: 0.025369752126994 

test_21164        5: 0.536084310537778   4: 0.300407787677253   6: 0.020440116372723   1: 0.020438952597923   0: 0.020438742437038   9: 0.020438448967150   3: 0.020438048846903   8: 0.020438028439344   7: 0.020437795815675   2: 0.020437768308214 

test_21165        5: 0.829940027137224   4: 0.018896388119065   6: 0.018896173725560   2: 0.018895785983653   1: 0.018895737951998   8: 0.018895654813256   0: 0.018895561356889   9: 0.018895086187849   7: 0.018894835597174   3: 0.018894749127332 

test_21166        5: 0.742138740035880   0: 0.095716559896748   4: 0.020269925097860   6: 0.020269126911811   8: 0.020267839511031   1: 0.020267782587386   9: 0.020267719345966   7: 0.020267523434943   3: 0.020267405118738   2: 0.020267378059638 

test_21168        6: 0.776393180327378   5: 0.024853278621361   0: 0.024845551052659   4: 0.024845061990437   1: 0.024844841862750   3: 0.024844589307442   8: 0.024843920192517   9: 0.024843602513660   2: 0.024843029431909   7: 0.024842944699885 

test_21172        7: 0.742130096685125   8: 0.028689308021777   6: 0.028664630964299   5: 0.028655514350044   0: 0.028653124853205   1: 0.028651163835694   9: 0.028644496195264   2: 0.028637613240195   4: 0.028637274584338   3: 0.028636777270059 

test_21173        5: 0.735564015250597   8: 0.089938405366179   6: 0.021813622644779   4: 0.021813550479332   7: 0.021812629655607   9: 0.021811802627175   0: 0.021811677235908   1: 0.021811540870081   3: 0.021811387255680   2: 0.021811368614663 

test_21175        5: 0.649525258737941   4: 0.223163491460185   1: 0.015921040850402   6: 0.015916703404585   0: 0.015915011682073   7: 0.015912174199845   9: 0.015911823869053   8: 0.015911796477447   2: 0.015911364857195   3: 0.015911334461273 

test_21176        5: 0.776880582693055   4: 0.024798098337356   6: 0.024790777076919   8: 0.024790751318253   9: 0.024790430917105   0: 0.024790031740823   2: 0.024789860631435   3: 0.024789839313088   7: 0.024789824012791   1: 0.024789803959175 

test_21177        8: 0.435345149531529   6: 0.363004941730872   1: 0.025207492748754   9: 0.025206929140752   7: 0.025206788948571   0: 0.025206516178904   5: 0.025206314895035   3: 0.025205458607383   2: 0.025205211043727   4: 0.025205197174473 

test_21178        5: 0.599333383986548   8: 0.227114139938205   4: 0.021700280790211   6: 0.021693454653469   0: 0.021693310292667   3: 0.021693109173551   7: 0.021693099101127   2: 0.021693091712519   9: 0.021693087485171   1: 0.021693042866532 

test_21179        5: 0.815022641212304   4: 0.020556123430328   6: 0.020554024253245   0: 0.020552882959318   1: 0.020552587731257   9: 0.020552459896063   7: 0.020552414872173   8: 0.020552335609541   3: 0.020552275065320   2: 0.020552254970452 

test_21181        5: 0.472896852333959   1: 0.289001603913785   4: 0.029767021070443   8: 0.029762459780507   3: 0.029762248914436   2: 0.029762132170625   7: 0.029762047412008   0: 0.029761937525008   9: 0.029761921358397   6: 0.029761775520833 

test_21182        5: 0.763659878537433   6: 0.026263398998588   4: 0.026261511283054   1: 0.026260197957969   2: 0.026259839668777   9: 0.026259836012228   0: 0.026259405650594   8: 0.026259016443470   3: 0.026258528446796   7: 0.026258387001090 

test_21187        6: 0.554582347983927   9: 0.161475199328411   0: 0.142787689948025   3: 0.052199071483324   1: 0.014959642995998   8: 0.014853407113389   7: 0.014799674581251   5: 0.014782115697239   4: 0.014780726743698   2: 0.014780124124738 

test_21189        5: 0.552474599732732   2: 0.224369156780082   4: 0.027901902327754   3: 0.027893843620488   8: 0.027893839021088   9: 0.027893444683765   7: 0.027893424643737   0: 0.027893309460862   1: 0.027893264429639   6: 0.027893215299853 

test_21190        5: 0.785890320330124   6: 0.023793722395143   4: 0.023791597046521   9: 0.023789986657252   1: 0.023789900351183   0: 0.023789719243299   8: 0.023789699076070   7: 0.023788368311497   2: 0.023788352666741   3: 0.023788333922170 

test_21191        5: 0.632223646173696   1: 0.171822910586603   4: 0.024497349808391   8: 0.024496388603797   6: 0.024495094941753   9: 0.024494209318661   0: 0.024493387336711   2: 0.024492451826259   3: 0.024492315534246   7: 0.024492245869884 

test_21192        5: 0.756091856558447   4: 0.027110053453932   0: 0.027099916194982   8: 0.027099882335646   1: 0.027099816403777   6: 0.027099791990577   3: 0.027099769212736   7: 0.027099698524654   2: 0.027099691320867   9: 0.027099524004383 

test_21193        5: 0.616533783112685   7: 0.196061498091929   3: 0.076879120809130   6: 0.015795703846949   9: 0.015791321610798   4: 0.015788937405518   1: 0.015788823333910   0: 0.015787652623171   8: 0.015786727590106   2: 0.015786431575804 

test_21194        5: 0.778361123024312   4: 0.024632182085550   8: 0.024626084654090   6: 0.024625930465581   3: 0.024625866621408   0: 0.024625841891007   2: 0.024625792790437   7: 0.024625776313775   9: 0.024625744457778   1: 0.024625657696061 

test_21195        5: 0.679291478518028   7: 0.132475592378145   4: 0.023533176125206   0: 0.023530655754622   6: 0.023528902183849   1: 0.023528319750333   8: 0.023528058243424   3: 0.023528004388087   2: 0.023527965566106   9: 0.023527847092200 

test_21196        4: 0.540112997416046   3: 0.252571097706598   5: 0.025922341193690   8: 0.025913723057680   2: 0.025913473599246   0: 0.025913352372484   9: 0.025913350645911   1: 0.025913303565048   7: 0.025913277315914   6: 0.025913083127384 

test_21197        6: 0.813327817722663   4: 0.032244356852169   1: 0.030984542527786   9: 0.029853652659836   3: 0.015607842131166   8: 0.015597786973955   0: 0.015596510766317   5: 0.015596215777651   7: 0.015595638208764   2: 0.015595636379693 

test_21199        5: 0.791552948625356   6: 0.023163632926981   4: 0.023163211208239   8: 0.023161024508633   1: 0.023160450179948   0: 0.023160011102125   9: 0.023159837398739   2: 0.023159717827882   3: 0.023159594478616   7: 0.023159571743481 

test_21201        1: 0.689571348302984   6: 0.127144925294645   0: 0.054233458932807   7: 0.029524622462767   5: 0.016906454882182   4: 0.016527446694583   2: 0.016526453727779   9: 0.016522240554108   8: 0.016522154716506   3: 0.016520894431638 

test_21202        6: 0.585167234278563   0: 0.277221509569780   8: 0.060813853489059   2: 0.010987081016372   7: 0.010971810773109   3: 0.010970022068617   1: 0.010968190364917   9: 0.010966991470636   5: 0.010966814959799   4: 0.010966492009148 

test_21203        5: 0.551989306998683   7: 0.235323837063273   6: 0.026605890856416   4: 0.026592039480080   3: 0.026581752175164   9: 0.026581708682650   1: 0.026581670490680   8: 0.026581647110811   0: 0.026581138002436   2: 0.026581009139807 

test_21205        5: 0.562020818756289   3: 0.141377004155999   1: 0.140810348578438   4: 0.022258689474623   6: 0.022256886632936   9: 0.022255832103369   0: 0.022255721146707   2: 0.022255029357656   7: 0.022254837096670   8: 0.022254832697313 

test_21206        5: 0.757299824393204   4: 0.026969488698069   0: 0.026966555974187   6: 0.026966542580826   8: 0.026966338718922   3: 0.026966296429325   7: 0.026966284302633   1: 0.026966265322207   2: 0.026966249906281   9: 0.026966153674345 

test_21207        6: 0.522002233254119   1: 0.253693845086812   5: 0.028051371636514   4: 0.028040317770173   0: 0.028039236369843   7: 0.028035927304739   9: 0.028035742452801   3: 0.028034135491063   8: 0.028034000457826   2: 0.028033190176110 

test_21208        5: 0.761601824167778   4: 0.026496566027023   8: 0.026488001003110   3: 0.026487812532843   0: 0.026487729165205   2: 0.026487707128889   9: 0.026487684227146   1: 0.026487611213402   7: 0.026487582615069   6: 0.026487481919535 

test_21209        5: 0.405257764634659   6: 0.333163781053591   9: 0.121391330373417   1: 0.020073356876793   4: 0.020049951203112   8: 0.020015411277900   0: 0.020012916549950   2: 0.020012044841172   3: 0.020011779237723   7: 0.020011663951683 

test_21210        6: 0.374663885946902   0: 0.347978046157597   1: 0.177130864917777   8: 0.014321032882262   5: 0.014318943338809   4: 0.014318603907741   9: 0.014317404452404   7: 0.014317162894416   3: 0.014317028868414   2: 0.014317026633680 

test_21211        5: 0.630433322718784   0: 0.157698262290754   4: 0.026488287142307   8: 0.026483130222763   2: 0.026482932100712   3: 0.026482915627808   9: 0.026482821714119   7: 0.026482785807993   6: 0.026482776112952   1: 0.026482766261808 

test_21212        9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

test_21214        4: 0.666337412438929   8: 0.134704056962163   5: 0.024879289063943   3: 0.024868690378126   2: 0.024868576338460   0: 0.024868467603401   9: 0.024868447672592   1: 0.024868446636517   7: 0.024868389582029   6: 0.024868223323839 

test_21215        4: 0.814921008799461   5: 0.020571735907311   6: 0.020567990912563   0: 0.020566428153183   1: 0.020563489753189   9: 0.020562136304726   7: 0.020561939323403   3: 0.020561841811394   8: 0.020561789663382   2: 0.020561639371386 

test_21216        6: 0.481934200700335   8: 0.336866640692150   9: 0.049521956040323   2: 0.036711761208774   3: 0.015834956139710   1: 0.015826840297340   0: 0.015826619741323   5: 0.015825895455453   7: 0.015825700790085   4: 0.015825428934507 

test_21218        4: 0.811164535756523   5: 0.020987270183835   6: 0.020982255746797   0: 0.020981899778450   1: 0.020981184771157   8: 0.020980662975784   2: 0.020980601444768   3: 0.020980567122439   9: 0.020980532225881   7: 0.020980489994365 

test_21219        4: 0.774991873576532   5: 0.025005637489032   8: 0.025000446055772   0: 0.025000405443334   3: 0.025000364794719   9: 0.025000322070427   2: 0.025000302873067   7: 0.025000217293069   6: 0.025000215382805   1: 0.025000215021242 

test_21221        5: 0.706307145472983   9: 0.090151602778153   1: 0.071879044059980   6: 0.018811008991083   8: 0.018810445065145   4: 0.018808725730411   0: 0.018808423384718   7: 0.018807942221094   3: 0.018807882499913   2: 0.018807779796522 

test_21222        5: 0.786262157075558   8: 0.023784930037727   9: 0.023753100585753   6: 0.023750003596185   0: 0.023747708607233   4: 0.023742608466453   1: 0.023741618003666   7: 0.023740403532585   2: 0.023738858735076   3: 0.023738611359764 

test_21224        5: 0.520238718445618   8: 0.276145728599838   1: 0.025470604830258   4: 0.025457633346680   3: 0.025448071737607   9: 0.025447971352751   2: 0.025447941508125   0: 0.025447878893464   7: 0.025447785732015   6: 0.025447665553644 

test_21227        5: 0.573638769998545   3: 0.212626827817933   4: 0.026722461798242   1: 0.026716496063493   8: 0.026716190857922   2: 0.026715937846424   9: 0.026715852388763   6: 0.026715841524997   0: 0.026715830395363   7: 0.026715791308318 

test_21228        0: 0.723762541163039   5: 0.128902381215238   1: 0.018484315574347   4: 0.018425834579988   6: 0.018415457420271   8: 0.018403382021590   7: 0.018402409724731   2: 0.018401416505353   9: 0.018401367583521   3: 0.018400894211923 

test_21230        6: 0.433254627621671   1: 0.240827995975020   4: 0.131458118463231   0: 0.027789230953397   5: 0.027778553861498   2: 0.027778359875264   8: 0.027778325368142   9: 0.027778265916092   7: 0.027778264131291   3: 0.027778257834393 

test_21232        5: 0.558280274709695   3: 0.217007940918234   2: 0.079977622705611   1: 0.020687641033319   6: 0.020679865470444   0: 0.020677955021962   7: 0.020674972283182   4: 0.020673216319495   9: 0.020670605755759   8: 0.020669905782299 

test_21233        4: 0.516963217981610   2: 0.274508822192301   5: 0.026073850787117   8: 0.026065290117079   9: 0.026065011598592   3: 0.026064962992981   0: 0.026064804838876   1: 0.026064687031536   6: 0.026064676363934   7: 0.026064676095973 

test_21234        5: 0.742800201893185   4: 0.099435934865601   9: 0.019721917038294   6: 0.019721208001095   1: 0.019721046559899   8: 0.019720225654877   0: 0.019720201135670   3: 0.019720121923195   2: 0.019719573726947   7: 0.019719569201237 

test_21236        5: 0.781728336876832   8: 0.079809470472221   6: 0.017325626320771   4: 0.017306148771238   1: 0.017305625064205   0: 0.017305227591724   9: 0.017305149637470   7: 0.017304973255655   3: 0.017304834946688   2: 0.017304607063196 

test_21237        5: 0.748464310266437   2: 0.089787688547061   6: 0.020225188779463   8: 0.020219787378737   4: 0.020219002595509   0: 0.020218874514798   9: 0.020217420845675   1: 0.020216604003270   7: 0.020215632210613   3: 0.020215490858437 

test_21238        5: 0.706937199828319   0: 0.112232361804622   4: 0.022611420619217   6: 0.022603300040332   8: 0.022603048228337   9: 0.022602850521337   1: 0.022602804618137   2: 0.022602412452118   3: 0.022602330582461   7: 0.022602271305119 

test_21240        5: 0.759798549029555   4: 0.026691739717593   8: 0.026688928509733   3: 0.026688756486382   9: 0.026688712745382   2: 0.026688707103759   0: 0.026688688006127   7: 0.026688677498418   1: 0.026688631822738   6: 0.026688609080314 

test_21242        4: 0.834837533424457   5: 0.018369107091490   1: 0.018353021671354   0: 0.018349943320387   6: 0.018349474206898   3: 0.018348416542457   8: 0.018348361981532   9: 0.018348141633521   2: 0.018348116932782   7: 0.018347883195121 

test_21243        6: 0.587912005397168   0: 0.154499962578132   4: 0.142719597246898   7: 0.030089333484874   8: 0.014133631392658   1: 0.014131389987069   5: 0.014130210555321   3: 0.014128827527958   9: 0.014127688018992   2: 0.014127353810929 

test_21244        5: 0.816861970675116   3: 0.046411461237518   0: 0.017093104186015   4: 0.017092248295819   6: 0.017091166372995   1: 0.017090925348225   2: 0.017090074324443   9: 0.017089803222806   8: 0.017089686278539   7: 0.017089560058523 

test_21245        6: 0.754412796538222   5: 0.027290798029904   9: 0.027289994478578   0: 0.027288724556755   7: 0.027287146782892   1: 0.027286915727387   8: 0.027286254460652   4: 0.027285830680342   2: 0.027285803388444   3: 0.027285735356825 

test_21248        5: 0.601270190405365   4: 0.212788942496300   7: 0.070866375739719   6: 0.016557669205172   1: 0.016491075643135   8: 0.016405883550373   9: 0.016405613038459   0: 0.016405591117791   2: 0.016404472808121   3: 0.016404185995564 

test_21251        2: 0.457095915827165   1: 0.245251606684372   6: 0.172866319068313   9: 0.038444573473762   5: 0.014434625428103   8: 0.014394854291104   0: 0.014390475890002   4: 0.014385853397549   7: 0.014368339386534   3: 0.014367436553096 

test_21252        5: 0.743994808368620   4: 0.028447081753195   8: 0.028444919822982   6: 0.028444815222676   0: 0.028444769175799   3: 0.028444758657072   7: 0.028444735384883   2: 0.028444723353874   9: 0.028444711377333   1: 0.028444676883567 

test_21253        4: 0.611846954500815   6: 0.211588364294302   5: 0.022081834247842   1: 0.022075533048999   0: 0.022072351365169   3: 0.022068523938159   9: 0.022066756572145   8: 0.022066605128443   2: 0.022066591215861   7: 0.022066485688265 

test_21255        4: 0.444490070259556   5: 0.337557023912087   8: 0.027244619959613   3: 0.027244174396644   2: 0.027244152572547   0: 0.027244148760714   6: 0.027244114074211   7: 0.027243946295991   1: 0.027243896901313   9: 0.027243852867325 

test_21256        5: 0.775086009793092   4: 0.024993251190336   6: 0.024991255830958   2: 0.024990871545728   9: 0.024990369636006   8: 0.024989725761340   0: 0.024989694388840   3: 0.024989678153212   1: 0.024989605998199   7: 0.024989537702289 

test_21257        5: 0.743449776465247   4: 0.028510543756572   0: 0.028506032040935   6: 0.028506016563705   7: 0.028505301327799   3: 0.028504686097493   1: 0.028504590061107   2: 0.028504483205492   8: 0.028504389563577   9: 0.028504180918073 

test_21259        5: 0.772140858432145   7: 0.077544166435206   6: 0.018822219846392   0: 0.018797420509578   1: 0.018788028389808   8: 0.018784590860257   4: 0.018781739468094   9: 0.018781076684024   3: 0.018780018436958   2: 0.018779880937538 

test_21260        5: 0.691648126098308   1: 0.177521027356133   4: 0.046554216420882   8: 0.012042494035978   6: 0.012042371994829   9: 0.012041650153965   0: 0.012039803145774   7: 0.012037251608078   2: 0.012036773650806   3: 0.012036285535249 

test_21261        4: 0.615414579832775   6: 0.248063346300733   3: 0.017066434901733   8: 0.017066383830776   0: 0.017066363206405   1: 0.017066275495395   5: 0.017064834523178   9: 0.017064547787426   7: 0.017063643201055   2: 0.017063590920522 

test_21262        5: 0.755163252840961   4: 0.027207902656388   0: 0.027204209861997   7: 0.027204009473559   3: 0.027203600116531   8: 0.027203526673828   2: 0.027203483265616   1: 0.027203397470909   9: 0.027203392580791   6: 0.027203225059421 

test_21264        5: 0.492869714889240   3: 0.211351812826545   7: 0.113910691905344   1: 0.025989162996282   4: 0.025984672582845   6: 0.025980589282104   8: 0.025978856608172   9: 0.025978377886845   2: 0.025978110949755   0: 0.025978010072868 

test_21265        5: 0.775816605634242   7: 0.072067357333538   1: 0.019018805224136   9: 0.019016364184284   4: 0.019014462962419   6: 0.019013830551300   0: 0.019013486583949   8: 0.019013097942834   2: 0.019013007823661   3: 0.019012981759637 

test_21266        5: 0.688409849546698   4: 0.095211160343748   8: 0.076608972057136   1: 0.019969074408967   6: 0.019967914336419   2: 0.019967675488059   7: 0.019966964377719   9: 0.019966309643706   0: 0.019966196839360   3: 0.019965882958187 

test_21267        2: 0.608978695290726   1: 0.242109647532723   7: 0.042373586447111   6: 0.015226078357300   5: 0.015221668664777   0: 0.015219096509003   4: 0.015218409209220   9: 0.015218188478696   3: 0.015217548230572   8: 0.015217081279871 

test_21271        5: 0.711469414301479   1: 0.099648842154405   4: 0.023616541155647   0: 0.023610995408894   7: 0.023609749987835   9: 0.023609013465523   8: 0.023608976311759   3: 0.023608849487307   2: 0.023608817622855   6: 0.023608800104295 

test_21272        4: 0.777642412134835   2: 0.024719718002142   5: 0.024714572029969   6: 0.024704874066418   1: 0.024704530161268   0: 0.024703080803620   3: 0.024702949085896   8: 0.024702771379440   9: 0.024702579261250   7: 0.024702513075164 

test_21274        2: 0.762109110022629   6: 0.026481245324920   5: 0.026448697064051   7: 0.026424269335544   1: 0.026424266030379   0: 0.026424251541959   4: 0.026424205079350   3: 0.026423368726212   9: 0.026420939788651   8: 0.026419647086304 

test_21275        5: 0.829052239159317   0: 0.039130641041351   4: 0.033051531023360   8: 0.014129100958612   3: 0.014111518097630   6: 0.014109610583891   9: 0.014108838692418   1: 0.014102783187999   2: 0.014102000072315   7: 0.014101737183106 

test_21277        6: 0.526586235959392   0: 0.241138480637111   1: 0.124636186461622   3: 0.053435494082279   7: 0.009068625007091   9: 0.009027666495639   5: 0.009027473799358   8: 0.009026850004784   2: 0.009026585852385   4: 0.009026401700339 

test_21278        1: 0.420269222870869   4: 0.287862263570309   6: 0.103849299816454   3: 0.058841148447756   0: 0.021547500932158   5: 0.021531588691656   2: 0.021524940956974   7: 0.021524823501040   8: 0.021524754397572   9: 0.021524456815213 

test_21281        5: 0.825884325535721   4: 0.019348956061048   6: 0.019347188100962   3: 0.019345781744651   0: 0.019345725684432   8: 0.019345725597285   7: 0.019345624161023   1: 0.019345588848320   2: 0.019345558920093   9: 0.019345525346465 

test_21282        4: 0.748189369206071   6: 0.027981947840397   1: 0.027981930203969   8: 0.027979730557961   7: 0.027979371809467   5: 0.027978141773563   2: 0.027977843865754   3: 0.027977683735096   0: 0.027977390552550   9: 0.027976590455171 

test_21283        5: 0.824985228687383   4: 0.019450173370913   6: 0.019446119412857   0: 0.019445802652919   1: 0.019445643168915   8: 0.019445556580593   3: 0.019445483960861   9: 0.019445397358445   7: 0.019445304357184   2: 0.019445290449930 

test_21285        8: 0.725243019524920   2: 0.121607382187309   6: 0.019148217140059   1: 0.019144586488095   0: 0.019144374646943   5: 0.019143072974019   9: 0.019142789347676   7: 0.019142465434042   4: 0.019142134578621   3: 0.019141957678316 

test_21286        4: 0.795661703747729   5: 0.022712824606436   6: 0.022706204998065   7: 0.022703255144908   3: 0.022702994661059   0: 0.022702778488843   9: 0.022702732324530   8: 0.022702654069010   1: 0.022702442733314   2: 0.022702409226107 

test_21287        1: 0.669957222386486   6: 0.201114195795736   0: 0.030202931348911   5: 0.014144973720240   4: 0.014123418734741   8: 0.014095896071251   2: 0.014092955062836   9: 0.014089771472949   3: 0.014089337007075   7: 0.014089298399774 

test_21291        4: 0.593195782736617   0: 0.220002974060045   6: 0.023408797073340   1: 0.023384106387685   3: 0.023338862872353   5: 0.023337087086221   9: 0.023335865266339   7: 0.023334110932572   2: 0.023331433097373   8: 0.023330980487456 

test_21292        0: 0.642274770728504   2: 0.178145464394534   6: 0.022479617521304   1: 0.022445537723795   5: 0.022445306763867   4: 0.022443874757616   8: 0.022441950884112   3: 0.022441477175356   9: 0.022441055877728   7: 0.022440944173183 

test_21293        6: 0.806551318603726   7: 0.054954870451132   9: 0.044745854928497   0: 0.013666844228167   3: 0.013419873645873   2: 0.013333812774940   4: 0.013332972972218   1: 0.013332305315311   5: 0.013331486454282   8: 0.013330660625853 

test_21295        5: 0.776377765052413   4: 0.024855096824673   6: 0.024847152983495   3: 0.024846112028698   8: 0.024845897392873   0: 0.024845771627503   1: 0.024845657602372   2: 0.024845534113849   9: 0.024845531937495   7: 0.024845480436628 

test_21297        1: 0.531065893205727   0: 0.294207143929468   4: 0.021872956690352   8: 0.021867519435062   5: 0.021834980969627   9: 0.021834815530150   6: 0.021830853295436   7: 0.021830275463265   3: 0.021827859111860   2: 0.021827702369053 

test_21298        5: 0.746715577240790   4: 0.028146367701689   0: 0.028142571398833   1: 0.028142532855268   8: 0.028142350897486   6: 0.028142316739297   3: 0.028142158783980   2: 0.028142146495607   9: 0.028141997648247   7: 0.028141980238803 

test_21300        4: 0.835721787767950   5: 0.018260034637826   0: 0.018256297044763   6: 0.018255866418596   8: 0.018251339645307   1: 0.018251163721179   9: 0.018251136427708   7: 0.018251088713289   3: 0.018250680529155   2: 0.018250605094227 

test_21301        0: 0.589137447388651   6: 0.137460240812209   7: 0.134156885336813   1: 0.019897833568058   4: 0.019895773600598   5: 0.019893419723414   9: 0.019890434691109   2: 0.019890273254856   8: 0.019889083869678   3: 0.019888607754613 

test_21302        5: 0.637031264368473   4: 0.201910991704571   0: 0.055665442733168   6: 0.015068539622790   9: 0.015066069252272   1: 0.015052412375218   8: 0.015051644816466   7: 0.015051361586028   2: 0.015051201140991   3: 0.015051072400023 

test_21303        6: 0.715432731245854   0: 0.146869573070893   1: 0.017214129383841   8: 0.017212763265914   5: 0.017212627145134   9: 0.017211796311811   7: 0.017211668206264   2: 0.017211632859606   3: 0.017211579194137   4: 0.017211499316547 

test_21307        6: 0.432659364493335   8: 0.346094955617861   1: 0.027666285605875   0: 0.027661401130942   2: 0.027655377416629   5: 0.027654922611765   4: 0.027653894477536   9: 0.027651893524635   7: 0.027651075715983   3: 0.027650829405439 

test_21308        5: 0.796545840058111   7: 0.053029154575580   0: 0.018805556931048   4: 0.018804168861024   6: 0.018802865670793   1: 0.018802768692706   3: 0.018802463456540   8: 0.018802446488799   9: 0.018802406391169   2: 0.018802328874230 

test_21314        2: 0.526599834594942   6: 0.288641576889299   5: 0.059253870980704   3: 0.018166848014503   0: 0.017930450080937   9: 0.017921444555776   8: 0.017890211126967   1: 0.017871759198882   7: 0.017862013322435   4: 0.017861991235554 

test_21315        5: 0.399651173487587   9: 0.395740500304482   8: 0.074389926265579   4: 0.018605430935821   7: 0.018602534771640   0: 0.018602514334929   1: 0.018602341383264   6: 0.018602067007876   2: 0.018601756841357   3: 0.018601754667466 

test_21318        5: 0.388538032160352   2: 0.290501545104869   1: 0.180672602093560   4: 0.020181741220982   6: 0.020060763472446   9: 0.020028721439835   0: 0.020008116880445   3: 0.020003002838448   7: 0.020002987569614   8: 0.020002487219450 

test_21319        1: 0.613551610329037   3: 0.192144853692166   0: 0.064838641011038   5: 0.018505671764858   6: 0.018504725156938   4: 0.018491553402567   8: 0.018491211008453   9: 0.018490970775868   2: 0.018490679258504   7: 0.018490083600570 

test_21321        6: 0.600429789417806   0: 0.267851001318256   1: 0.020859860201965   3: 0.016412736776554   9: 0.015940885236589   5: 0.015806142156310   8: 0.015791227519536   7: 0.015641960352782   2: 0.015633207396333   4: 0.015633189623868 

test_21322        5: 0.784486928124885   9: 0.073939925000434   4: 0.017698353559674   6: 0.017697315758541   8: 0.017696742633178   1: 0.017696688795299   0: 0.017696554821301   3: 0.017695910820478   2: 0.017695843147383   7: 0.017695737338827 

test_21323        6: 0.379394692476388   0: 0.368262243061066   8: 0.031550417381314   1: 0.031545039811809   5: 0.031542423118549   9: 0.031541229933530   3: 0.031541223992347   7: 0.031540976897915   4: 0.031540877957162   2: 0.031540875369920 

test_21324        5: 0.556126748065712   9: 0.260036634088113   8: 0.058410707665092   4: 0.017920908627586   6: 0.017918816392501   1: 0.017918568736536   3: 0.017917480634043   0: 0.017916964928601   2: 0.017916808877752   7: 0.017916361984064 

test_21325        5: 0.708554532759646   8: 0.147475768414033   6: 0.017998284660500   4: 0.017997574787736   0: 0.017996170568893   7: 0.017995870599894   9: 0.017995833183622   3: 0.017995356279219   1: 0.017995308507327   2: 0.017995300239131 

test_21330        5: 0.758759153396283   4: 0.026807764259516   6: 0.026804922307837   8: 0.026804457116197   9: 0.026804326809973   1: 0.026804167057964   0: 0.026804052829190   2: 0.026803753924261   7: 0.026803742047367   3: 0.026803660251413 

test_21331        6: 0.381814332366965   9: 0.374106800032883   7: 0.030512116250063   0: 0.030511605353389   8: 0.030510322420345   1: 0.030509619670057   3: 0.030509434355548   5: 0.030508992824714   2: 0.030508555847182   4: 0.030508220878854 

test_21333        5: 0.425353351750731   1: 0.256881247675050   0: 0.137082794104742   6: 0.037752613935188   8: 0.037484588654604   3: 0.028827160496682   4: 0.026393124434141   9: 0.016743903089263   2: 0.016740814680869   7: 0.016740401178731 

test_21336        5: 0.664646300694735   6: 0.177969505497382   4: 0.061787714503777   2: 0.013691386845867   7: 0.013655518694534   1: 0.013650706735398   0: 0.013650399482812   8: 0.013649787007034   9: 0.013649420202964   3: 0.013649260335497 

test_21337        5: 0.651024900008618   3: 0.103462045669441   2: 0.067993738517672   0: 0.064443002924601   6: 0.018856111326465   4: 0.018847590466160   9: 0.018847589447758   8: 0.018844253287276   1: 0.018840439257577   7: 0.018840329094431 

test_21339        6: 0.735173023840667   3: 0.113500426184689   7: 0.042273698669171   1: 0.015751617163242   5: 0.015610920173356   2: 0.015561204538402   0: 0.015544285705809   4: 0.015542489330621   8: 0.015530723105688   9: 0.015511611288355 

test_21342        6: 0.540931966695173   8: 0.249975026720615   2: 0.071241026682963   1: 0.019822557387292   0: 0.019680528927185   9: 0.019671312217760   5: 0.019671264213040   4: 0.019668975658478   7: 0.019668893149010   3: 0.019668448348483 

test_21343        8: 0.793628384631537   2: 0.048522312850557   3: 0.042908560579529   6: 0.016502843652928   0: 0.016469456518706   5: 0.016424118521649   1: 0.016413374175697   9: 0.016377711635621   7: 0.016376814126485   4: 0.016376423307292 

test_21346        5: 0.808837579197525   9: 0.021247953079317   4: 0.021241641953697   6: 0.021241030902047   0: 0.021239138400658   2: 0.021238665645173   7: 0.021238609503812   8: 0.021238507332605   1: 0.021238484225225   3: 0.021238389759940 

test_21350        4: 0.740764031870957   5: 0.028813897588196   3: 0.028803051013185   8: 0.028802988581717   2: 0.028802948814339   1: 0.028802774073222   0: 0.028802739609893   7: 0.028802587496179   9: 0.028802569717576   6: 0.028802411234735 

test_21352        4: 0.641149611651694   3: 0.152814044610203   5: 0.025764127874945   6: 0.025754293631215   0: 0.025753129239890   8: 0.025753104280352   2: 0.025753035279475   1: 0.025752958641958   9: 0.025752956544485   7: 0.025752738245784 

test_21354        5: 0.369142155402250   4: 0.356092230123308   3: 0.114555052546851   1: 0.056126468766724   6: 0.017354472387789   8: 0.017346112766031   0: 0.017346008522682   9: 0.017345885882520   2: 0.017345822416114   7: 0.017345791185731 

test_21356        5: 0.625436797022833   2: 0.123574372670520   6: 0.088743746815734   4: 0.023180777476124   9: 0.023178124974595   8: 0.023177983008594   0: 0.023177317946643   1: 0.023177046788659   7: 0.023176951081453   3: 0.023176882214844 

test_21357        1: 0.793784569522113   6: 0.047419289462045   5: 0.024637393614071   0: 0.019436601831164   8: 0.019264299753157   7: 0.019237387346315   2: 0.019121184455860   3: 0.019048990561729   9: 0.019047041502560   4: 0.019003241950985 

test_21358        2: 0.306844564236212   1: 0.299054297117284   5: 0.236103407234935   0: 0.041833105078095   3: 0.019431953565832   6: 0.019352770901662   9: 0.019345891079138   7: 0.019345560462456   8: 0.019344596750396   4: 0.019343853573990 

test_21359        5: 0.560917256076236   4: 0.286967956475126   2: 0.039802952871819   6: 0.016045274107629   0: 0.016045252792056   1: 0.016044659873444   9: 0.016044283558030   7: 0.016044231951104   8: 0.016044208934919   3: 0.016043923359637 

test_21360        5: 0.761753040440018   6: 0.026473408279909   4: 0.026473303121837   8: 0.026472428958507   9: 0.026471722818920   0: 0.026471622182009   1: 0.026471388106196   7: 0.026471324855407   2: 0.026470925065486   3: 0.026470836171711 

test_21362        5: 0.845357705008632   6: 0.017183838098935   8: 0.017183299825800   4: 0.017182817160212   1: 0.017182550977761   0: 0.017182253075683   9: 0.017182110170214   2: 0.017181902140585   7: 0.017181779300160   3: 0.017181744242018 

test_21363        2: 0.527991786612474   6: 0.215241607087841   7: 0.129771374595702   5: 0.018145543722145   1: 0.018144765626911   4: 0.018142014742202   0: 0.018141732807650   9: 0.018141094143962   8: 0.018140531146361   3: 0.018139549514752 

test_21367        6: 0.716501892561004   0: 0.111956041553904   9: 0.043859775969532   5: 0.039736176214845   1: 0.024294647108209   8: 0.012734220461680   3: 0.012729380448765   7: 0.012729324853415   2: 0.012729271027503   4: 0.012729269801142 

test_21368        6: 0.693590235201726   3: 0.136328324043790   0: 0.052778126204597   1: 0.043335963635043   5: 0.020577535368079   8: 0.010682951796157   4: 0.010679301977851   7: 0.010676353695157   9: 0.010676250583398   2: 0.010674957494202 

test_21369        6: 0.766156230377488   5: 0.098114827466398   8: 0.032855368512778   1: 0.028785049883313   9: 0.019273001280861   0: 0.011000023449654   7: 0.010961239605728   3: 0.010952328495788   2: 0.010951015299959   4: 0.010950915628035 

test_21371        6: 0.487296096187150   1: 0.158392284178862   9: 0.147457747891768   0: 0.101459321592110   5: 0.033122859629329   8: 0.014466951597356   7: 0.014452996541613   2: 0.014450761635510   4: 0.014450525932297   3: 0.014450454814006 

test_21372        5: 0.786620234226114   6: 0.023712714049086   7: 0.023712534047583   1: 0.023711613427091   4: 0.023709293662109   0: 0.023707988195247   3: 0.023707326468554   2: 0.023706164235013   8: 0.023706112037642   9: 0.023706019651562 

test_21373        7: 0.407910641502088   5: 0.395501982054616   4: 0.024577890810132   6: 0.024573368316394   8: 0.024573211137251   9: 0.024573020590743   0: 0.024572679329247   3: 0.024572456901417   2: 0.024572448699066   1: 0.024572300659046 

test_21375        1: 0.604756156707732   6: 0.178253128066495   5: 0.027125630813472   0: 0.027125432340947   8: 0.027125056005466   4: 0.027123145610855   7: 0.027122927073988   2: 0.027122889109206   3: 0.027122847415821   9: 0.027122786856017 

test_21376        5: 0.470675913261773   1: 0.395273862240174   6: 0.016782359599169   0: 0.016773960251776   4: 0.016749839315572   2: 0.016749258620136   7: 0.016749037003641   9: 0.016748858837148   8: 0.016748641099852   3: 0.016748269770757 

test_21378        5: 0.469774106210101   4: 0.227648508228900   1: 0.113896300419947   7: 0.074995115299326   2: 0.018953233415180   0: 0.018949234795712   6: 0.018947756381350   8: 0.018945583207721   9: 0.018945298401710   3: 0.018944863640051 

test_21380        2: 0.479040616134820   7: 0.170062492408395   6: 0.160267204521293   5: 0.027242622378347   1: 0.027239943288956   4: 0.027235753074658   9: 0.027228611796366   3: 0.027227736634738   0: 0.027227730823582   8: 0.027227288938844 

test_21382        0: 0.791227395633342   5: 0.066242098905120   8: 0.042256296053570   6: 0.021917702907357   1: 0.013199363385859   3: 0.013062865436113   7: 0.013024427356231   9: 0.013023775542647   2: 0.013023250261506   4: 0.013022824518256 

test_21385        5: 0.589010591843932   1: 0.213071185360045   6: 0.024744623517931   4: 0.024742688982159   3: 0.024740208777132   8: 0.024738992145933   0: 0.024738647256028   9: 0.024737912911210   2: 0.024737627654318   7: 0.024737521551312 

test_21386        5: 0.717819361347857   6: 0.110459809409349   3: 0.038649720567993   9: 0.033997639957713   4: 0.016539680471475   8: 0.016508456795547   0: 0.016506730092445   7: 0.016506402958612   2: 0.016506236931821   1: 0.016505961467188 

test_21387        9: 0.730885397075734   8: 0.031371644651421   0: 0.029979981471162   6: 0.029745694861885   1: 0.029687012778967   2: 0.029686704679976   5: 0.029681712340143   4: 0.029655846745588   3: 0.029654482086215   7: 0.029651523308908 

test_21388        5: 0.761975565062627   4: 0.086655884540553   6: 0.018922792774449   8: 0.018922480501312   0: 0.018921064655976   1: 0.018921011946326   9: 0.018920663133715   2: 0.018920397051816   7: 0.018920099654239   3: 0.018920040678986 

test_21391        6: 0.809193498554769   0: 0.078161901063384   2: 0.026859668904448   7: 0.012315534282503   5: 0.012257732932516   1: 0.012244811766910   9: 0.012243136895833   3: 0.012241320519862   8: 0.012241250247038   4: 0.012241144832738 

test_21392        6: 0.633542265267457   0: 0.235737607348024   5: 0.016343003064531   1: 0.016341361613841   9: 0.016340090298395   4: 0.016339560238907   7: 0.016339312229329   8: 0.016339305294507   3: 0.016338843769409   2: 0.016338650875601 

test_21393        6: 0.491033177194531   4: 0.265408516247745   1: 0.076208656490098   2: 0.050917404222895   0: 0.019421771718942   7: 0.019404383264001   5: 0.019403579702562   9: 0.019401449529796   3: 0.019400712680693   8: 0.019400348948736 

test_21394        1: 0.309823926298243   2: 0.282505819815809   5: 0.246857637895351   0: 0.042771462018451   6: 0.019680416122532   9: 0.019673379762283   7: 0.019672979763131   8: 0.019672044281629   4: 0.019671327890575   3: 0.019671006151995 

test_21401        5: 0.577241522691907   9: 0.116726051813785   1: 0.063959629957635   2: 0.063733330302205   0: 0.057973367089963   4: 0.044474829179184   7: 0.018976750426030   6: 0.018975559607553   3: 0.018975128766326   8: 0.018963830165413 

test_21403        5: 0.824057663456971   6: 0.019552309927379   4: 0.019550133062466   8: 0.019549693214544   9: 0.019549480081523   0: 0.019548773130600   1: 0.019548592834972   7: 0.019547889150186   2: 0.019547883641266   3: 0.019547581500093 

test_21404        6: 0.353592627583727   9: 0.329306723661315   4: 0.140624128757289   7: 0.046749498398411   2: 0.034943112961873   8: 0.029045409011174   5: 0.016472770952165   1: 0.016441827023648   0: 0.016418661924136   3: 0.016405239726261 

test_21405        4: 0.579502018132390   5: 0.250295147177351   6: 0.021311675764127   0: 0.021271687862243   9: 0.021271571686074   7: 0.021270028801626   2: 0.021269865875280   1: 0.021269498115923   8: 0.021269380104010   3: 0.021269126480976 

test_21406        4: 0.523005363896281   8: 0.276529675071390   5: 0.025066250011287   3: 0.025057257800793   2: 0.025057102341105   0: 0.025056972588154   1: 0.025056938936994   9: 0.025056924794019   7: 0.025056861786774   6: 0.025056652773204 

test_21408        1: 0.774922024427494   2: 0.041172484771810   8: 0.039789596013755   0: 0.020602418229403   6: 0.020591460801886   4: 0.020587407179166   5: 0.020586448060615   9: 0.020583356823375   3: 0.020582782159523   7: 0.020582021532974 

test_21410        0: 0.697503574908225   1: 0.033639706629320   5: 0.033611943059452   4: 0.033611226115521   6: 0.033608008849437   9: 0.033605286354708   8: 0.033605257632129   3: 0.033605105498852   2: 0.033604991055167   7: 0.033604899897190 

test_21411        4: 0.414347940343064   1: 0.409916092533920   5: 0.021974359276533   6: 0.021968296477235   0: 0.021967716339680   2: 0.021965476722813   9: 0.021965364989717   3: 0.021965138910080   7: 0.021964849492681   8: 0.021964764914278 

test_21412        5: 0.437054142988908   4: 0.346566351037936   6: 0.110133933520536   9: 0.015184835336518   3: 0.015179917800889   2: 0.015178983127624   8: 0.015177446247747   1: 0.015176960676750   0: 0.015174977701569   7: 0.015172451561523 

test_21413        5: 0.774476168159641   4: 0.025061048259905   8: 0.025058092873637   3: 0.025057905643019   2: 0.025057860611346   9: 0.025057844035809   7: 0.025057799420749   1: 0.025057793745689   0: 0.025057781675220   6: 0.025057705574986 

test_21414        5: 0.624358253310741   9: 0.125542602797964   2: 0.093913038509883   4: 0.022315673942032   6: 0.022312415709775   8: 0.022312162860885   7: 0.022311749189892   0: 0.022311484752190   1: 0.022311315466484   3: 0.022311303460153 

test_21415        5: 0.821405146964773   6: 0.019848006343083   4: 0.019846646665937   0: 0.019843151139035   8: 0.019843044290049   9: 0.019842847583768   3: 0.019842831369879   1: 0.019842783011179   2: 0.019842780449158   7: 0.019842762183140 

test_21416        5: 0.734919446082593   8: 0.087894491793778   4: 0.022155219449518   9: 0.022147997182434   6: 0.022147927179927   7: 0.022147170498125   1: 0.022147054765216   0: 0.022147010000365   3: 0.022146865355751   2: 0.022146817692294 

test_21417        5: 0.726875012457877   7: 0.070246184101908   1: 0.044301224432945   2: 0.042008859080620   3: 0.019498760918528   6: 0.019419652064279   0: 0.019418332706580   9: 0.019412257522898   8: 0.019409965267976   4: 0.019409751446390 

test_21419        1: 0.478941399358546   7: 0.216214628740099   5: 0.134553688089041   6: 0.060876131968434   8: 0.018241658327627   0: 0.018241638011126   4: 0.018233385401994   9: 0.018232840577674   2: 0.018232536313311   3: 0.018232093212149 

test_21421        6: 0.711509364165606   1: 0.032064680953647   5: 0.032062546477929   0: 0.032060517190514   4: 0.032054409347867   7: 0.032051722223459   2: 0.032050860089468   9: 0.032048955112842   8: 0.032048826599504   3: 0.032048117839163 

test_21423        6: 0.720926205382459   1: 0.104907216284984   3: 0.091422028331218   0: 0.011845963445804   4: 0.011823431935195   5: 0.011819247582616   8: 0.011815907623628   9: 0.011815175329238   7: 0.011812534337686   2: 0.011812289747171 

test_21427        5: 0.743078256075027   1: 0.028560277348487   0: 0.028551990911034   2: 0.028550667885805   6: 0.028547829750492   4: 0.028545541330087   9: 0.028542422728880   8: 0.028541056942215   3: 0.028541019471685   7: 0.028540937556289 

test_21429        5: 0.381342967919242   0: 0.301793421565466   9: 0.146970873742959   7: 0.063271894646120   6: 0.017778785282911   1: 0.017775362661633   4: 0.017767648621293   3: 0.017766717436574   2: 0.017766507968204   8: 0.017765820155597 

test_21430        5: 0.799746740255784   4: 0.022253696593427   1: 0.022250480582434   0: 0.022250459000304   6: 0.022249834921308   8: 0.022249826200785   2: 0.022249792409004   3: 0.022249770308637   9: 0.022249753053292   7: 0.022249646675025 

test_21431        4: 0.757193928946139   5: 0.026984684189903   6: 0.026979255501942   8: 0.026977807396862   0: 0.026977730219906   1: 0.026977463836827   7: 0.026977423648209   9: 0.026977319537381   2: 0.026977258034053   3: 0.026977128688777 

test_21435        5: 0.483909500843531   4: 0.247945660627562   0: 0.078257391306702   2: 0.077114248169780   6: 0.018796637410047   1: 0.018796420508906   8: 0.018795546961578   7: 0.018794920044593   9: 0.018794912266944   3: 0.018794761860356 

test_21436        5: 0.820468909861652   4: 0.019949981901332   6: 0.019948174336835   0: 0.019947920471825   1: 0.019947645872160   2: 0.019947605265650   8: 0.019947550767670   9: 0.019947499840479   3: 0.019947379581812   7: 0.019947332100586 

test_21437        5: 0.718667187556469   6: 0.139685010658235   0: 0.017707826132090   4: 0.017707642656574   1: 0.017705753517970   8: 0.017705463263518   7: 0.017705336615343   9: 0.017705317161311   3: 0.017705257514469   2: 0.017705204924022 

test_21440        1: 0.482540853811867   6: 0.179973752763661   7: 0.152666233500112   0: 0.026405407416476   4: 0.026404491531921   8: 0.026402418316573   5: 0.026402348201308   2: 0.026402174734070   9: 0.026401247425855   3: 0.026401072298159 

test_21441        5: 0.812816138331460   4: 0.020800510694958   6: 0.020799643574522   7: 0.020798328088989   0: 0.020797873730227   8: 0.020797624317140   9: 0.020797545417153   1: 0.020797535715648   3: 0.020797406270679   2: 0.020797393859224 

test_21443        8: 0.370824184657719   6: 0.328238923881642   9: 0.114286509473409   1: 0.089006688974223   4: 0.026887051392117   7: 0.014163415906360   3: 0.014154733951321   0: 0.014148438841103   5: 0.014145137756771   2: 0.014144915165335 

test_21447        4: 0.846123328946045   5: 0.017103734594622   0: 0.017101668056002   6: 0.017101055184754   8: 0.017098699505888   1: 0.017098396065691   9: 0.017094907193422   2: 0.017092878875815   3: 0.017092712483543   7: 0.017092619094217 

test_21448        5: 0.830760185369072   6: 0.018831754451131   0: 0.018817184020352   1: 0.018801791982936   4: 0.018800506268385   8: 0.018799037315877   9: 0.018797975951644   3: 0.018797274484661   2: 0.018797160689555   7: 0.018797129466387 

test_21451        5: 0.728561379715312   4: 0.030164181437633   8: 0.030159508109123   3: 0.030159484465393   2: 0.030159386617592   1: 0.030159283267785   9: 0.030159271889240   0: 0.030159251221748   7: 0.030159198990855   6: 0.030159054285319 

test_21453        5: 0.647783142357928   0: 0.178408531031338   1: 0.065936462439591   4: 0.015419111210309   9: 0.015411230193684   2: 0.015409983588244   6: 0.015409700482508   8: 0.015407400244349   7: 0.015407257374778   3: 0.015407181077270 

test_21454        0: 0.537262495862728   7: 0.194004207024846   6: 0.084928712323735   3: 0.073187453989874   4: 0.018446951648209   5: 0.018439252843542   1: 0.018438839611712   9: 0.018430978325719   2: 0.018430863715884   8: 0.018430244653750 

test_21455        5: 0.672277314652118   6: 0.174641307288005   9: 0.019137229743351   4: 0.019136249699767   0: 0.019135807230478   1: 0.019135175825758   8: 0.019134409148707   7: 0.019134204185259   3: 0.019134186302740   2: 0.019134115923818 

test_21459        6: 0.425661655657820   1: 0.230437712361743   8: 0.126181707414706   9: 0.118501007427750   7: 0.021772657356184   4: 0.015558707648716   0: 0.015475701877117   3: 0.015475276012647   5: 0.015468105984055   2: 0.015467468259263 

test_21460        5: 0.583880884574252   8: 0.205501336512013   2: 0.080290889283392   1: 0.018621671425658   4: 0.018620335217502   0: 0.018618128399931   6: 0.018618106868927   9: 0.018616312757844   3: 0.018616171864323   7: 0.018616163096159 

test_21462        0: 0.541907040614089   7: 0.196841570913251   6: 0.079936557512367   3: 0.071748309628471   4: 0.018271913889145   5: 0.018263946976054   1: 0.018263505764432   9: 0.018255906428702   2: 0.018255895947196   8: 0.018255352326294 

test_21465        6: 0.430936622243296   1: 0.190307939788419   9: 0.177728582206916   8: 0.028737295561894   3: 0.028730208432035   0: 0.028712936278615   2: 0.028712063624700   7: 0.028711622543548   5: 0.028711376166233   4: 0.028711353154344 

test_21466        1: 0.572548620745320   5: 0.220408189424539   6: 0.049520877747967   0: 0.031939259883011   2: 0.021526052169176   7: 0.020820970099483   8: 0.020817184234438   9: 0.020806936901350   4: 0.020806051547086   3: 0.020805857247630 

test_21468        6: 0.538349415728234   9: 0.242226938829935   8: 0.027433459838001   0: 0.027431643027975   1: 0.027429128470901   7: 0.027426950211506   3: 0.027425878577509   5: 0.027425811275539   2: 0.027425471850285   4: 0.027425302190116 

test_21469        1: 0.363040356563409   6: 0.268654442066204   9: 0.252414956586752   5: 0.029738294323398   0: 0.014751603935389   8: 0.014287908554151   4: 0.014284919011060   7: 0.014284523268025   2: 0.014271554958501   3: 0.014271440733111 

test_21473        6: 0.740746341334510   0: 0.159375880067675   1: 0.023345973808197   8: 0.010934766433235   5: 0.010933981494557   7: 0.010933455852572   4: 0.010932730908982   9: 0.010932607383698   2: 0.010932131499979   3: 0.010932131216595 

test_21474        5: 0.722505052292460   6: 0.089155845804825   4: 0.023547417847854   1: 0.023542386993993   7: 0.023541673471273   8: 0.023541609072365   3: 0.023541558554679   0: 0.023541524093529   9: 0.023541468634324   2: 0.023541463234698 

test_21475        6: 0.749954016655901   9: 0.092671395769181   7: 0.055640715645606   8: 0.025298182418489   0: 0.012952630098291   4: 0.012708365825460   1: 0.012704835980627   5: 0.012692164862496   2: 0.012691144906079   3: 0.012686547837870 

test_21477        0: 0.719439130554880   3: 0.148137241623671   6: 0.016711063161438   1: 0.016577886434926   2: 0.016526090885522   5: 0.016523375453674   7: 0.016521760806814   8: 0.016521562026001   9: 0.016521318916218   4: 0.016520570136857 

test_21478        1: 0.500676937463686   4: 0.260716697698713   9: 0.029836012852666   0: 0.029826361129827   5: 0.029826339247505   6: 0.029825858154934   2: 0.029823292817001   3: 0.029823016257135   7: 0.029822880387771   8: 0.029822603990760 

test_21479        5: 0.762246632780875   4: 0.026420613469853   8: 0.026416879386280   3: 0.026416674814989   2: 0.026416626187043   1: 0.026416546969025   7: 0.026416543336111   9: 0.026416543261785   0: 0.026416529652905   6: 0.026416410141132 

test_21480        5: 0.754818789497495   8: 0.080512280420955   4: 0.020586029655862   9: 0.020583470660060   7: 0.020583331057445   0: 0.020583321551612   6: 0.020583243627186   3: 0.020583237545615   1: 0.020583171746553   2: 0.020583124237217 

test_21482        6: 0.385861555348879   7: 0.243825710481887   8: 0.222075190262005   9: 0.021222286462849   1: 0.021175906399919   0: 0.021174886006701   4: 0.021172087686913   5: 0.021168035725160   3: 0.021163517799845   2: 0.021160823825842 

test_21484        9: 0.292871331533489   6: 0.224905516257246   8: 0.207203533967779   4: 0.128309998544902   5: 0.024453935089574   7: 0.024452910704069   3: 0.024452551369248   1: 0.024451230911209   0: 0.024449896056297   2: 0.024449095566187 

test_21485        9: 0.282190065958429   6: 0.236783831528690   8: 0.205181220160507   4: 0.127284222479296   5: 0.024762546701113   7: 0.024761217483854   3: 0.024760910049893   1: 0.024760373742576   0: 0.024757971576113   2: 0.024757640319529 

test_21486        6: 0.652812801309737   9: 0.138269537766742   1: 0.064523059921035   0: 0.057950340835236   7: 0.029361073521400   2: 0.011692200518309   8: 0.011354037721827   5: 0.011346600528801   3: 0.011345423122144   4: 0.011344924754771 

test_21488        5: 0.463394290937972   4: 0.305916191515038   0: 0.095384349755855   6: 0.019331236674015   1: 0.019329299897226   7: 0.019328982003731   9: 0.019328967303363   2: 0.019328946377895   8: 0.019328929457307   3: 0.019328806077599 

test_21489        4: 0.772895151575047   5: 0.025241154050455   8: 0.025233072333127   6: 0.025233027261421   7: 0.025233025399701   3: 0.025233002418564   0: 0.025232947251089   2: 0.025232926679635   9: 0.025232862411259   1: 0.025232830619702 

test_21490        5: 0.768951356524348   0: 0.057415620184210   3: 0.054697128305915   4: 0.016993000973363   6: 0.016991641718574   1: 0.016991302778891   8: 0.016990192862105   9: 0.016990020683104   2: 0.016989888752365   7: 0.016989847217125 

test_21492        6: 0.727937516150217   1: 0.079143779140392   9: 0.077438166856529   8: 0.029997842874455   3: 0.014259700394207   7: 0.014249432149576   2: 0.014248544306446   0: 0.014243364753341   5: 0.014241245248649   4: 0.014240408126189 

test_21493        6: 0.466676561101488   1: 0.330322455256460   7: 0.084121305278632   0: 0.016984554687707   5: 0.016982980730968   8: 0.016982880783965   9: 0.016982692688470   2: 0.016982328277035   3: 0.016982164666129   4: 0.016982076529147 

test_21496        0: 0.753325547591361   1: 0.027443218073817   6: 0.027408197703868   5: 0.027406920110826   9: 0.027405233610712   4: 0.027404107225044   8: 0.027402716545948   7: 0.027402195057597   3: 0.027401105785502   2: 0.027400758295325 

test_21497        6: 0.587002824718649   0: 0.256837450677219   7: 0.062358096401235   2: 0.022611481287382   8: 0.011872725976621   1: 0.011864316049264   9: 0.011863958390992   5: 0.011863921562058   4: 0.011862616773102   3: 0.011862608163478 

test_21501        6: 0.669192523738263   8: 0.120141631773433   1: 0.103878696348056   9: 0.015261877701381   7: 0.015255145974087   0: 0.015255092490250   2: 0.015254656781448   3: 0.015254416918739   5: 0.015253317687055   4: 0.015252640587288 

test_21502        0: 0.376317376685460   6: 0.357826541251344   3: 0.134988825835854   7: 0.036647446371735   9: 0.023340938717034   2: 0.014311219677803   5: 0.014147280036230   1: 0.014145665489222   4: 0.014138025413282   8: 0.014136680522035 

test_21503        9: 0.375624631429958   6: 0.289890643977434   0: 0.205991982707146   5: 0.018363268577518   4: 0.018357818619523   1: 0.018357652786639   3: 0.018354472498810   7: 0.018353568057425   8: 0.018353256217291   2: 0.018352705128256 

test_21506        6: 0.430087134336828   3: 0.397040901337584   7: 0.040577024825818   8: 0.038866730786500   0: 0.015582779229894   1: 0.015578343793448   5: 0.015573980867748   4: 0.015566072442295   2: 0.015563723921218   9: 0.015563308458668 

test_21508        6: 0.692819212558192   1: 0.107016590452360   7: 0.094218892233401   0: 0.059954547117414   8: 0.007739759644909   9: 0.007655105791720   4: 0.007649368138971   5: 0.007649275084458   3: 0.007648908601743   2: 0.007648340376833 

test_21510        6: 0.620222567811372   1: 0.257400227829812   0: 0.015321960923058   5: 0.015297133796545   2: 0.015293526891371   9: 0.015293211408438   8: 0.015293044530239   7: 0.015292935759686   3: 0.015292761353338   4: 0.015292629696142 

test_21511        9: 0.416832665614741   0: 0.336589299335607   6: 0.030828722579452   8: 0.030827276989403   1: 0.030821979885667   7: 0.030820581375850   5: 0.030820088117309   2: 0.030820008085928   3: 0.030819753466239   4: 0.030819624549804 

test_21512        6: 0.532414042941641   0: 0.193461897045182   3: 0.180583352582837   1: 0.013374923304157   5: 0.013362968630200   4: 0.013360911349636   7: 0.013360668509819   8: 0.013360514182179   9: 0.013360488408289   2: 0.013360233046060 

test_21517        6: 0.715347258619646   7: 0.073995714014603   3: 0.073872852926545   8: 0.038541004346311   9: 0.028339754567229   0: 0.014058835946249   1: 0.013965194497061   5: 0.013960915480420   2: 0.013959287437321   4: 0.013959182164613 

test_21519        6: 0.625453282953599   3: 0.183588274510680   5: 0.054078215707269   1: 0.019710620740440   2: 0.019586846424130   9: 0.019577123738578   7: 0.019519045007310   0: 0.019508625930287   8: 0.019489405938699   4: 0.019488559049007 

test_21521        6: 0.675689827165942   0: 0.175991183167987   7: 0.041397944032362   3: 0.015283493462748   1: 0.015278710061464   5: 0.015274548578407   8: 0.015271539878452   4: 0.015271431563873   9: 0.015270700868574   2: 0.015270621220191 

test_21523        6: 0.469711432710640   2: 0.163923170093367   1: 0.142257170474384   7: 0.093911950913633   3: 0.056134545006294   0: 0.014825819888357   9: 0.014824922352666   5: 0.014806312317712   8: 0.014805170656472   4: 0.014799505586474 

test_21525        6: 0.806727119012480   1: 0.078123497742403   7: 0.028354097860790   3: 0.018885419437795   5: 0.017129822763200   8: 0.010171789426118   9: 0.010164705058496   2: 0.010159697761415   0: 0.010145494708037   4: 0.010138356229265 

test_21526        1: 0.384023035103288   6: 0.240489730072108   7: 0.158289883279332   2: 0.092614243170812   3: 0.045456038845892   9: 0.015831036404271   8: 0.015828728280425   0: 0.015827553814900   5: 0.015821346119360   4: 0.015818404909612 

test_21530        6: 0.748531452656385   7: 0.078635236109804   1: 0.054297297976926   0: 0.030013367894765   9: 0.014761435804211   8: 0.014755454749327   5: 0.014752857236944   3: 0.014751421949971   4: 0.014751117644677   2: 0.014750357976991 

test_21532        6: 0.619802429318032   0: 0.263771265233028   1: 0.025820630647893   7: 0.012951821151945   3: 0.012945325897690   5: 0.012943264088641   9: 0.012941647276701   8: 0.012941376461639   2: 0.012941121703352   4: 0.012941118221078 

test_21535        6: 0.544847646070483   9: 0.287485641176007   3: 0.036596649834035   1: 0.018952299448840   0: 0.018734373663953   8: 0.018682859978294   5: 0.018680895727046   7: 0.018675512825249   4: 0.018672093827473   2: 0.018672027448621 

test_21536        6: 0.562315371047607   8: 0.237082670285433   9: 0.071881535943872   4: 0.036313406801495   0: 0.021523067290510   7: 0.021096501927603   5: 0.012547564600360   3: 0.012428734287446   1: 0.012406811436902   2: 0.012404336378772 

test_21538        0: 0.779161537475541   5: 0.024684125462155   6: 0.024527187966344   7: 0.024521970533392   1: 0.024520797258424   9: 0.024519141777924   3: 0.024517013718354   2: 0.024516178965662   4: 0.024516059323669   8: 0.024515987518534 

test_21539        6: 0.584196360075602   7: 0.257055514590976   1: 0.056522553416344   8: 0.014613690701499   0: 0.014610193771219   9: 0.014601775884356   5: 0.014600339909739   3: 0.014599960560580   4: 0.014599954721124   2: 0.014599656368561 

test_21541        2: 0.503545586634270   6: 0.224634774884103   1: 0.128807145261748   9: 0.065547457625777   3: 0.019524268133308   0: 0.011598394218508   7: 0.011595063008809   5: 0.011586660807215   4: 0.011580413377606   8: 0.011580236048657 

test_21542        6: 0.593003311785798   0: 0.204476658938654   1: 0.137206687255388   3: 0.009332818479106   9: 0.009331637636451   5: 0.009330156636140   8: 0.009329903298576   7: 0.009329660189367   2: 0.009329589890503   4: 0.009329575890017 

test_21550        1: 0.485843699940125   5: 0.353757547643507   6: 0.020053166656732   8: 0.020051645963515   0: 0.020051102855575   2: 0.020050224614582   9: 0.020048448133095   4: 0.020048135303622   7: 0.020048070561003   3: 0.020047958328243 

test_21551        5: 0.513323011742617   2: 0.290006077494347   6: 0.024611851195394   1: 0.024604419960511   9: 0.024581629885926   7: 0.024578481463481   0: 0.024574595083405   4: 0.024573696409058   8: 0.024573419108810   3: 0.024572817656451 

test_21553        5: 0.519901431685835   2: 0.284754021725220   6: 0.024433776788985   1: 0.024428164631392   9: 0.024416889047368   7: 0.024414582060332   0: 0.024413663065444   4: 0.024413075173491   8: 0.024412399369820   3: 0.024411996452113 

test_21555        5: 0.731011814942042   1: 0.029901568971097   0: 0.029890294817965   2: 0.029885998102555   4: 0.029885819260548   9: 0.029885633050511   8: 0.029885283441183   6: 0.029884951707040   3: 0.029884482003486   7: 0.029884153703572 

test_21556        6: 0.532520729097257   0: 0.193332958700116   3: 0.180605592705943   1: 0.013374930176691   5: 0.013362972289248   4: 0.013360912558360   7: 0.013360668860631   8: 0.013360514187319   9: 0.013360488417264   2: 0.013360233007170 

test_21557        6: 0.437378449085764   1: 0.422541369432115   0: 0.046057683948322   7: 0.013508315816000   5: 0.013427830965806   9: 0.013420289560125   8: 0.013417157213612   2: 0.013416656025675   3: 0.013416136315484   4: 0.013416111637097 

test_21561        6: 0.515830316404453   0: 0.375874868273566   7: 0.023372290781636   5: 0.012589771673309   1: 0.012056119692905   9: 0.012055555479237   8: 0.012055471576516   4: 0.012055459977318   2: 0.012055121142053   3: 0.012055024999006 

test_21562        6: 0.539253278450780   0: 0.247545507142918   9: 0.078263813357743   5: 0.019279988083756   4: 0.019277522793177   8: 0.019276716077526   7: 0.019276149967491   1: 0.019275921145046   2: 0.019275636760866   3: 0.019275466220697 

test_21565        6: 0.527041382751207   8: 0.186946575339404   9: 0.165952852504131   2: 0.027999639632580   0: 0.025764517952239   3: 0.013308939504883   5: 0.013251556935270   1: 0.013246100855426   4: 0.013244954806278   7: 0.013243479718583 

test_21567        6: 0.682620040257718   7: 0.178975796935759   1: 0.036201864748458   4: 0.014607541508589   8: 0.014602278247921   5: 0.014599239660875   0: 0.014598635158474   9: 0.014598299342811   3: 0.014598189309627   2: 0.014598114829766 

test_21568        6: 0.491400173559654   8: 0.264220607580667   2: 0.105274349701117   0: 0.060093332831677   7: 0.014609248781830   9: 0.012902317128800   1: 0.012882197528386   5: 0.012880780344239   4: 0.012869193394185   3: 0.012867799149445 

test_21570        6: 0.680900597560128   7: 0.169189289365350   1: 0.018753974969375   0: 0.018747621367842   9: 0.018744950992254   5: 0.018740638937845   8: 0.018731994105286   4: 0.018730789508756   3: 0.018730153730011   2: 0.018729989463152 

test_21571        4: 0.419007759401270   6: 0.359184941375626   0: 0.074282155936820   1: 0.021086892178384   5: 0.021085669317573   9: 0.021072362079401   2: 0.021070230606435   7: 0.021070189935522   8: 0.021069990234625   3: 0.021069808934343 

test_21573        6: 0.581638242045645   0: 0.327891781656651   1: 0.022635933614061   2: 0.009738193980429   3: 0.009684022468710   7: 0.009682872582663   5: 0.009682756297773   8: 0.009682266914623   9: 0.009682090516528   4: 0.009681839922918 

test_21574        6: 0.741151586773146   0: 0.092659571926496   7: 0.045510491516540   9: 0.017257702866715   3: 0.017240428850231   5: 0.017239933750581   8: 0.017236050670120   1: 0.017235398378750   4: 0.017234593643393   2: 0.017234241624029 

test_21575        6: 0.842484208164776   0: 0.049050393869447   8: 0.030048355693427   9: 0.011324350585510   7: 0.011237956084624   5: 0.011207946904531   3: 0.011164039539223   4: 0.011161025327952   1: 0.011160986404533   2: 0.011160737425976 

test_21576        6: 0.434328743966473   5: 0.250108272699506   8: 0.146418740302784   9: 0.046409695533669   1: 0.040084903182726   0: 0.016533231648096   4: 0.016529731454477   2: 0.016529113950298   7: 0.016528807402232   3: 0.016528759859739 

training_1        6: 0.511449621708344   7: 0.301225637437196   0: 0.071914238402408   4: 0.031684994770291   2: 0.025258039441703   8: 0.014446349139815   5: 0.011032854529801   1: 0.011004242230911   3: 0.010993179957274   9: 0.010990842382258 

training_10       5: 0.575139258724126   6: 0.210530682795165   7: 0.057653576257729   2: 0.053055718446108   8: 0.024862346629477   0: 0.023358902653487   9: 0.013899024176767   4: 0.013837148775842   1: 0.013833743775631   3: 0.013829597765668 

training_100      6: 0.761680713113711   7: 0.089123212792850   8: 0.018653553219377   0: 0.018651174220899   9: 0.018651023738951   5: 0.018649768416491   1: 0.018648337035496   4: 0.018647749338446   2: 0.018647305714943   3: 0.018647162408835 

training_1000     6: 0.515986378391528   1: 0.323288462741324   5: 0.020116046652566   4: 0.020102411246458   0: 0.020086560458008   3: 0.020085257960468   2: 0.020084572575760   8: 0.020083609584243   9: 0.020083377234117   7: 0.020083323155528 

training_10000    5: 0.328015454741838   2: 0.313583525642423   6: 0.212168069570015   4: 0.021032212093005   0: 0.020871779567333   1: 0.020868951369650   9: 0.020865913839662   8: 0.020864868379500   7: 0.020864862593300   3: 0.020864362203274 

training_10002    5: 0.568700299600593   6: 0.235246387425741   1: 0.024509843648803   0: 0.024509217443046   2: 0.024507467082930   8: 0.024505572046870   4: 0.024505494742537   3: 0.024505458549425   9: 0.024505160389838   7: 0.024505099070217 

training_10005    6: 0.559533326827702   5: 0.312435437490121   0: 0.030443108518905   1: 0.013961582609372   9: 0.013939049492285   7: 0.013939001676131   2: 0.013938330634319   8: 0.013937597863413   3: 0.013936292355050   4: 0.013936272532703 

training_10008    5: 0.599573620416209   8: 0.223595410947863   4: 0.022110203575876   6: 0.022103338567516   0: 0.022103111069385   9: 0.022102933995302   3: 0.022102924148606   1: 0.022102908645394   2: 0.022102793251409   7: 0.022102755382440 

training_10011    9: 0.517071305046433   6: 0.291307771052363   2: 0.023954544976675   5: 0.023953923627843   0: 0.023952783301065   1: 0.023952494844413   8: 0.023952494605075   7: 0.023952103030122   4: 0.023951836166790   3: 0.023950743349220 

training_10014    6: 0.290995208412920   1: 0.274710119955002   7: 0.274101706642170   0: 0.038704200199304   8: 0.030969884419512   2: 0.030481868399053   5: 0.015011110298729   9: 0.015008706025923   4: 0.015008652341997   3: 0.015008543305392 

training_10015    6: 0.871338682846683   5: 0.014296678266858   1: 0.014296312747652   0: 0.014296089949364   4: 0.014295624929900   8: 0.014295434627273   9: 0.014295421842382   3: 0.014295279216392   7: 0.014295240925178   2: 0.014295234648318 

training_10018    3: 0.334924686487806   1: 0.298446653113175   5: 0.191048828918577   9: 0.060653298571400   6: 0.019158058078501   0: 0.019157797303157   7: 0.019153904548541   4: 0.019153115039692   8: 0.019151836315634   2: 0.019151821623516 

training_10023    5: 0.489731167213217   3: 0.218795504952243   4: 0.145720625282132   6: 0.020823097616728   1: 0.020822796945048   9: 0.020822108902722   0: 0.020821472397143   8: 0.020821153960591   7: 0.020821109186361   2: 0.020820963543816 

training_10025    8: 0.560758201037115   0: 0.223852297667248   5: 0.050604731586781   6: 0.023548699705214   1: 0.023544636959552   4: 0.023543183464085   7: 0.023537653368951   9: 0.023537453980561   2: 0.023537104312140   3: 0.023536037918353 

training_10027    4: 0.805925809297375   5: 0.021571416819795   6: 0.021564182212569   0: 0.021563940830367   1: 0.021563514231389   8: 0.021562811600642   3: 0.021562146109406   9: 0.021562123195963   7: 0.021562107479072   2: 0.021561948223421 

training_1003     5: 0.451392546983958   0: 0.407663490559380   4: 0.017621125680306   1: 0.017618995404542   6: 0.017618833800046   9: 0.017617198645058   8: 0.017617051022544   7: 0.017616948904345   2: 0.017616941620403   3: 0.017616867379418 

training_10032    4: 0.638349809000770   1: 0.131841316067049   7: 0.028736831526694   5: 0.028732489371472   8: 0.028723467004524   3: 0.028723370879443   2: 0.028723257184136   0: 0.028723224400492   9: 0.028723168763020   6: 0.028723065802400 

training_10035    4: 0.512267923729933   1: 0.238915146357145   5: 0.031109755223022   8: 0.031103979288639   0: 0.031101553696638   9: 0.031100983155980   3: 0.031100921711927   2: 0.031100375963204   6: 0.031099977038730   7: 0.031099383834783 

training_10037    5: 0.570602974293639   1: 0.237208126521951   0: 0.024031448616092   4: 0.024026636080422   8: 0.024022185621660   3: 0.024022025329156   9: 0.024021729635011   6: 0.024021656000556   2: 0.024021625568211   7: 0.024021592333300 

training_10038    9: 0.736945256954981   5: 0.140410939741590   6: 0.015335953321667   1: 0.015332496895427   0: 0.015332078114399   2: 0.015330889627713   3: 0.015328510820309   8: 0.015328134773249   4: 0.015327966355641   7: 0.015327773395025 

training_10040    4: 0.811882452865855   5: 0.020910027493889   6: 0.020901893266614   0: 0.020901755359328   1: 0.020901543570772   8: 0.020900946210374   3: 0.020900432812501   9: 0.020900367729402   7: 0.020900339294675   2: 0.020900241396590 

training_10041    6: 0.470971559543208   9: 0.331172244322208   3: 0.074000442313787   0: 0.018048446562673   1: 0.017893269566450   5: 0.017615675576449   4: 0.017589123613691   2: 0.017574182871993   8: 0.017567814543959   7: 0.017567241085581 

training_10042    0: 0.755360964284777   1: 0.027204582947083   2: 0.027186551840585   5: 0.027186145037714   6: 0.027180768016777   4: 0.027180725217012   9: 0.027176300592763   7: 0.027175072587389   3: 0.027174566535350   8: 0.027174322940549 

training_10043    6: 0.710876440333940   0: 0.086687136472217   8: 0.065911324735800   3: 0.031247268553664   5: 0.030196427263604   9: 0.015037894198263   7: 0.015014006672449   1: 0.015010571556049   2: 0.015009667372745   4: 0.015009262841269 

training_10046    4: 0.736838029413464   7: 0.084169323146999   5: 0.022381690285528   0: 0.022373327926015   1: 0.022373254536144   6: 0.022372977012766   9: 0.022372879604743   3: 0.022372866071515   2: 0.022372833616958   8: 0.022372818385868 

training_10048    6: 0.725910555994439   3: 0.102738640867639   1: 0.044607316836726   0: 0.042875382697372   8: 0.013986846088612   7: 0.013976935554120   9: 0.013976694312111   5: 0.013976621805380   2: 0.013975519847108   4: 0.013975485996494 

training_10049    0: 0.446411797988045   6: 0.430105593949861   1: 0.028340167280224   5: 0.021157762117015   4: 0.012390915881746   9: 0.012350745900440   8: 0.012313549985845   2: 0.012309882688408   7: 0.012309873824067   3: 0.012309710384349 

training_10050    5: 0.583886890538990   0: 0.209611902090619   6: 0.025817000829202   9: 0.025812589563173   1: 0.025812465415449   8: 0.025812299935021   7: 0.025812157753611   3: 0.025812022837396   2: 0.025811476627837   4: 0.025811194408702 

training_10052    3: 0.347457142473747   1: 0.215667939000860   5: 0.205073492150991   9: 0.106905911250383   6: 0.020820407689300   0: 0.020818962210690   7: 0.020816714147621   4: 0.020814583737872   2: 0.020812983004394   8: 0.020811864334142 

training_10053    5: 0.771106744062781   4: 0.025438333462614   0: 0.025432814472742   7: 0.025432091636181   8: 0.025431734834068   6: 0.025431716944036   3: 0.025431670904169   9: 0.025431644676344   2: 0.025431642615682   1: 0.025431606391383 

training_10054    5: 0.484974043002643   0: 0.325202019963852   2: 0.053907398403095   6: 0.019419333494162   1: 0.019419094758631   7: 0.019416330407952   9: 0.019415601123209   4: 0.019415480321602   8: 0.019415407710567   3: 0.019415290814287 

training_10057    1: 0.774747163166363   5: 0.025058275563240   3: 0.025026419752418   6: 0.025025994836494   0: 0.025025457031748   4: 0.025024467729877   8: 0.025023870016075   2: 0.025023416417106   7: 0.025022510878317   9: 0.025022424608361 

training_10058    4: 0.550899542661392   5: 0.233855073476476   6: 0.077670825537236   1: 0.019660248493462   0: 0.019657220376601   2: 0.019651654784872   3: 0.019651552117565   9: 0.019651526938046   7: 0.019651296414410   8: 0.019651059199940 

training_10061    5: 0.625634596627034   4: 0.186891269667939   6: 0.023435683556152   8: 0.023434958519810   9: 0.023434854770028   0: 0.023434232355430   3: 0.023433991804091   1: 0.023433876964168   2: 0.023433280976325   7: 0.023433254759024 

training_10062    5: 0.608627182462293   6: 0.180662829089361   7: 0.026379020632901   8: 0.026335793487953   3: 0.026334163320986   0: 0.026333949087860   1: 0.026332495121127   9: 0.026331896915300   4: 0.026331460195146   2: 0.026331209687074 

training_10064    5: 0.709419940417044   4: 0.032292479328888   6: 0.032287828870049   0: 0.032287014893801   7: 0.032287013233380   1: 0.032286020008701   8: 0.032285194625471   3: 0.032285003591048   9: 0.032285000264682   2: 0.032284504766936 

training_10065    9: 0.757662610166986   1: 0.026946249440384   6: 0.026935930134655   3: 0.026929222566436   5: 0.026928817688651   0: 0.026927839371809   2: 0.026920342886787   4: 0.026918363618170   7: 0.026915579466940   8: 0.026915044659182 

training_10066    6: 0.692416839386012   1: 0.160034841476068   5: 0.018449985645465   0: 0.018445248349368   4: 0.018443695571275   8: 0.018442231759996   2: 0.018442171249776   9: 0.018441992875461   3: 0.018441524460136   7: 0.018441469226441 

training_10067    4: 0.292244837778367   1: 0.265354664274427   6: 0.241212034854790   5: 0.093753506552656   2: 0.017932638441994   0: 0.017923122010629   8: 0.017906081940304   9: 0.017891755567270   3: 0.017890700512078   7: 0.017890658067486 

training_10068    5: 0.813195068378392   1: 0.020757256332505   6: 0.020756669316777   0: 0.020756245503244   3: 0.020756072333492   9: 0.020755994485936   2: 0.020755809849924   7: 0.020755651703590   4: 0.020755619046259   8: 0.020755613049881 

training_1007     4: 0.477040351097830   7: 0.279166203246306   6: 0.106355990881092   3: 0.019642753003307   5: 0.019637974549147   0: 0.019632707872989   1: 0.019631303871204   8: 0.019631229597176   9: 0.019630856002091   2: 0.019630629878859 

training_10071    9: 0.404799004662543   5: 0.266552091753805   1: 0.192204530740338   6: 0.048201023525561   0: 0.014711178442609   4: 0.014707771983863   7: 0.014707136053753   3: 0.014706116067403   8: 0.014705682129813   2: 0.014705464640312 

training_10073    0: 0.546410426973258   1: 0.298294315393699   9: 0.029926298128677   5: 0.018237022459960   2: 0.017864496780185   8: 0.017856564153509   6: 0.017854455753836   4: 0.017854355410091   7: 0.017851196875095   3: 0.017850868071690 

training_10074    5: 0.484174097804756   3: 0.318627279557164   6: 0.024652336709728   4: 0.024650136619567   2: 0.024649905966903   1: 0.024649398421276   9: 0.024649327806467   0: 0.024649288661046   8: 0.024649176589745   7: 0.024649051863347 

training_10075    0: 0.705009368950020   8: 0.032792771551413   6: 0.032791548032582   5: 0.032775024293177   1: 0.032774252765676   7: 0.032772644103047   4: 0.032771712961518   9: 0.032771336444882   2: 0.032770918968102   3: 0.032770421929584 

training_10076    5: 0.673450987249999   9: 0.136089273305826   4: 0.023821806521490   7: 0.023809166220697   3: 0.023805266186010   6: 0.023804765562377   8: 0.023804739384230   0: 0.023804717532145   1: 0.023804669322985   2: 0.023804608714243 

training_10078    6: 0.377184163028374   0: 0.247389116064068   9: 0.167343560922886   1: 0.131409572048730   5: 0.018968284509689   2: 0.011546969144466   4: 0.011540734547648   8: 0.011539461285917   3: 0.011539448294069   7: 0.011538690154154 

training_10079    8: 0.405937550159429   9: 0.378850841205465   5: 0.026918744793261   1: 0.026910865595912   6: 0.026902245632077   0: 0.026901339067181   7: 0.026895381726409   4: 0.026895001172467   2: 0.026894171765391   3: 0.026893858882406 

training_1008     9: 0.698310942240146   6: 0.144686943300471   8: 0.019638967593300   1: 0.019626248770548   5: 0.019623878582050   0: 0.019623423532914   3: 0.019623358159906   4: 0.019622263353076   2: 0.019622138862104   7: 0.019621835605486 

training_10080    6: 0.436775663744903   9: 0.272503254515440   1: 0.149961390296194   0: 0.069951799343898   2: 0.020429106194509   3: 0.015297124198919   7: 0.008859438141633   5: 0.008824645933473   4: 0.008750788213069   8: 0.008646789417962 

training_10081    6: 0.554351802487189   0: 0.333040791771046   8: 0.014077008853074   1: 0.014076629616443   5: 0.014076257848737   9: 0.014075696170615   7: 0.014075531187354   4: 0.014075479675537   2: 0.014075422097361   3: 0.014075380292644 

training_10083    4: 0.776827695465941   1: 0.024803640867054   5: 0.024802073736538   0: 0.024799990281171   6: 0.024795931196083   8: 0.024795910223720   9: 0.024794120445294   7: 0.024793880166081   3: 0.024793431896571   2: 0.024793325721547 

training_10085    5: 0.692521174457804   4: 0.125809039069579   6: 0.022710396856239   9: 0.022709443251494   8: 0.022709416828511   0: 0.022708903845369   1: 0.022708584311319   3: 0.022707780462342   2: 0.022707643974424   7: 0.022707616942919 

training_10086    5: 0.810413960500976   6: 0.021069883958019   1: 0.021065633462162   0: 0.021065539453812   9: 0.021064820041654   7: 0.021064150999049   2: 0.021064090451236   8: 0.021064018944573   4: 0.021064011514044   3: 0.021063890674476 

training_10088    5: 0.799599594043350   6: 0.022272591097019   0: 0.022269781272515   1: 0.022268800440434   7: 0.022268079021652   8: 0.022265027369415   9: 0.022265017166108   4: 0.022264750645349   2: 0.022264503479695   3: 0.022261855464464 

training_10089    5: 0.649482011195396   4: 0.134175791705447   1: 0.078914302601980   8: 0.019639171016999   6: 0.019634058086692   0: 0.019633825221809   2: 0.019630743756230   7: 0.019630566728499   9: 0.019630099639107   3: 0.019629430047841 

training_1009     8: 0.533679712301963   5: 0.251929832236269   4: 0.026803470555124   1: 0.026801665123089   0: 0.026800354788300   6: 0.026800344658853   2: 0.026796310234565   3: 0.026796265409746   7: 0.026796151873916   9: 0.026795892818174 

training_10090    6: 0.358932454752737   7: 0.259842431210909   1: 0.242558997850631   5: 0.019822368597295   4: 0.019812560186737   0: 0.019812201730785   8: 0.019806112115702   9: 0.019805895502284   3: 0.019803857455439   2: 0.019803120597482 

training_10091    6: 0.603813873540574   5: 0.163941813863207   0: 0.102883691430032   1: 0.043233119547908   8: 0.027163205581566   9: 0.011812395323366   4: 0.011795287057799   3: 0.011786957034597   2: 0.011785055823272   7: 0.011784600797678 

training_10092    5: 0.394524643468246   3: 0.268141137409050   1: 0.168927126808748   6: 0.024061907016617   9: 0.024059457968056   0: 0.024058397962929   4: 0.024057105382614   2: 0.024057093493041   7: 0.024056886085186   8: 0.024056244405515 

training_10094    5: 0.799720932587039   4: 0.022258716717855   0: 0.022254678365225   1: 0.022252718629351   3: 0.022252549720031   8: 0.022252199812796   6: 0.022252072420365   2: 0.022252052554040   7: 0.022252044204734   9: 0.022252034988565 

training_10095    0: 0.710868253047577   1: 0.144343524573373   8: 0.048340961865205   6: 0.013783866184148   5: 0.013782410749451   4: 0.013777715775436   2: 0.013777584370807   9: 0.013775792658585   7: 0.013774968722743   3: 0.013774922052675 

training_10096    8: 0.332581131552367   6: 0.286906003233041   7: 0.243131187390959   9: 0.019705852974614   5: 0.019625155900352   4: 0.019617141876134   0: 0.019612747870817   1: 0.019608723022073   3: 0.019606370446906   2: 0.019605685732736 

training_10097    5: 0.755439803974142   2: 0.061206645073918   0: 0.053940660389581   1: 0.018523578545486   6: 0.018487252146972   8: 0.018483865864616   4: 0.018482116830948   3: 0.018480216994481   7: 0.018478022088005   9: 0.018477838091850 

training_10098    1: 0.673107318165434   3: 0.111307746981352   0: 0.055787078807746   5: 0.022925354364504   6: 0.022846658160232   2: 0.022845023916591   7: 0.022795939732102   9: 0.022795152236915   8: 0.022795014921370   4: 0.022794712713754 

training_10099    5: 0.527330850524987   3: 0.284828417518606   1: 0.023504328265837   6: 0.023482823487162   7: 0.023479890099457   4: 0.023478562744502   0: 0.023474782211952   8: 0.023473824635517   9: 0.023473377554171   2: 0.023473142957810 

training_101      9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_1010     5: 0.827218001668739   4: 0.019202419464966   0: 0.019197990041996   1: 0.019197875192087   6: 0.019197585871582   9: 0.019197337516310   8: 0.019197305236367   3: 0.019197206465985   2: 0.019197157397980   7: 0.019197121143987 

training_10100    6: 0.762435373773079   8: 0.095520666179496   7: 0.039329802091341   1: 0.026674000623715   0: 0.012701458933324   5: 0.012668369266684   3: 0.012668010934963   9: 0.012667733667342   4: 0.012667302220147   2: 0.012667282309910 

training_10102    5: 0.766931004665021   6: 0.025902329746968   1: 0.025898090240691   0: 0.025896882208487   7: 0.025895931834899   4: 0.025895283284763   9: 0.025895208481127   8: 0.025895194199188   3: 0.025895154376424   2: 0.025894920962431 

training_10105    4: 0.349524374873306   5: 0.330255242396217   6: 0.154389437613898   7: 0.067580066233161   0: 0.016381759193163   1: 0.016375645007019   9: 0.016373878511689   8: 0.016373592008453   2: 0.016373008626858   3: 0.016372995536237 

training_10106    1: 0.518105664712816   6: 0.320745535958752   2: 0.050447168180993   0: 0.024193501636490   3: 0.020055602917966   4: 0.013390775157531   9: 0.013325208144202   7: 0.013256429139463   8: 0.013240454450266   5: 0.013239659701519 

training_10107    6: 0.761206084948341   8: 0.084642488044766   7: 0.038316088010724   1: 0.016555136603815   9: 0.016547432250482   0: 0.016547167641193   5: 0.016546845761873   2: 0.016546373330978   4: 0.016546208521599   3: 0.016546174886230 

training_10108    5: 0.674424092526384   1: 0.130517471932333   0: 0.024395265737806   4: 0.024382278198523   6: 0.024382186474999   8: 0.024379798096934   3: 0.024379787512628   7: 0.024379742125623   9: 0.024379695082191   2: 0.024379682312579 

training_10109    5: 0.679246257302644   8: 0.132356481752930   1: 0.023564863650322   4: 0.023549146589591   6: 0.023548303960709   9: 0.023547529218251   3: 0.023547107570954   0: 0.023546998420318   2: 0.023546739871116   7: 0.023546571663165 

training_1011     5: 0.584842043427109   4: 0.244109594951824   2: 0.046287352177527   6: 0.017830897312322   9: 0.017821946053326   8: 0.017821927783482   0: 0.017821800259121   1: 0.017821694739066   7: 0.017821389719169   3: 0.017821353577056 

training_10110    1: 0.772681681883715   0: 0.050585073294460   2: 0.037792295488669   6: 0.035092523435548   5: 0.017315873643706   7: 0.017311269605758   3: 0.017310707707354   4: 0.017304355876854   8: 0.017303111787246   9: 0.017303107276692 

training_10112    5: 0.723028152129917   6: 0.082806335587560   8: 0.024285377208583   1: 0.024269733709755   4: 0.024269217804371   0: 0.024268872265955   3: 0.024268291119126   2: 0.024268129926182   9: 0.024267965953961   7: 0.024267924294590 

training_10114    5: 0.741739874451998   6: 0.112649101168126   0: 0.018211119069315   1: 0.018202594292060   4: 0.018200533660039   8: 0.018200424680642   9: 0.018199654946240   3: 0.018199054410538   7: 0.018198990159877   2: 0.018198653161165 

training_10115    5: 0.504057435293982   3: 0.302913862964909   1: 0.024130273843236   4: 0.024129301256753   0: 0.024129091089331   2: 0.024128544159313   6: 0.024128246213736   7: 0.024127793823930   9: 0.024127778139479   8: 0.024127673215332 

training_10119    4: 0.688189087982630   0: 0.130254969977564   5: 0.022700742119962   2: 0.022694318646355   1: 0.022693635691438   3: 0.022693569696039   8: 0.022693474973023   6: 0.022693450952589   9: 0.022693424748247   7: 0.022693325212153 

training_10120    6: 0.803568109304526   5: 0.021828634902510   1: 0.021827027043858   0: 0.021826421397609   8: 0.021825279903086   7: 0.021825252059460   4: 0.021825225060080   9: 0.021824939084674   2: 0.021824604148135   3: 0.021824507096063 

training_10122    6: 0.762410876085581   8: 0.072782562036774   1: 0.046886875077124   3: 0.042826620645155   5: 0.012517993598342   0: 0.012516338009699   2: 0.012514703830613   4: 0.012514696534515   7: 0.012514684671301   9: 0.012514649510896 

training_10124    6: 0.795381526292439   0: 0.104095758088236   1: 0.024348910894490   7: 0.015369153208825   9: 0.010440204559334   5: 0.010210959907891   8: 0.010038563735743   3: 0.010038378613475   2: 0.010038314724961   4: 0.010038229974606 

training_10128    0: 0.807797746457118   5: 0.021363308244063   6: 0.021362593774820   8: 0.021355321984532   1: 0.021355203412595   4: 0.021354763647295   9: 0.021353061880788   3: 0.021352905763995   2: 0.021352722505366   7: 0.021352372329427 

training_10129    0: 0.426261748200409   2: 0.288023727176759   4: 0.142382925226842   6: 0.020494347917396   5: 0.020479571248945   1: 0.020473893292255   8: 0.020472286213177   7: 0.020471599967102   9: 0.020469993544547   3: 0.020469907212568 

training_1013     5: 0.570188566129777   7: 0.255997152956835   0: 0.021737239230264   6: 0.021730988712368   4: 0.021726650406040   9: 0.021725403530283   1: 0.021724908290994   3: 0.021723240515768   8: 0.021723060545813   2: 0.021722789681859 

training_10130    5: 0.500156424377199   3: 0.305863224615317   6: 0.064699159417848   4: 0.018470852697913   0: 0.018469308743002   8: 0.018468807582181   1: 0.018468387495202   9: 0.018468071329867   2: 0.018467948427628   7: 0.018467815313842 

training_10135    6: 0.666412077390496   9: 0.222670888771951   7: 0.013884685660675   5: 0.013865474061690   0: 0.013863771715991   1: 0.013860943815724   8: 0.013860710103411   4: 0.013860686565993   2: 0.013860425105899   3: 0.013860336808171 

training_10136    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_10139    6: 0.444414930775582   7: 0.402016650032179   3: 0.036730073803810   8: 0.016700188964033   1: 0.016693265544533   5: 0.016690707488648   0: 0.016690433200125   2: 0.016688610501318   4: 0.016687939019968   9: 0.016687200669805 

training_10140    0: 0.452443142035114   5: 0.417283050669113   1: 0.037020639240218   6: 0.013328156710891   4: 0.013321616378645   8: 0.013321234608217   9: 0.013321181918834   2: 0.013320727269829   3: 0.013320206871404   7: 0.013320044297734 

training_10146    6: 0.787636234478090   0: 0.039663715523149   4: 0.021678386900535   5: 0.021659321777562   1: 0.021569266642237   3: 0.021563117418480   2: 0.021560695750062   8: 0.021558248513475   7: 0.021555964062130   9: 0.021555048934279 

training_1015     1: 0.432977190930181   6: 0.415896290786072   0: 0.043851409800303   5: 0.015340214512721   7: 0.015334724283611   4: 0.015334158445520   9: 0.015320122086955   3: 0.015316335880309   8: 0.015314927834857   2: 0.015314625439473 

training_10151    4: 0.575542309965594   9: 0.155590644079107   6: 0.095994016251922   3: 0.043450929740177   0: 0.041218033850404   8: 0.017651114118459   1: 0.017642723959827   5: 0.017640020479838   2: 0.017635366116813   7: 0.017634841437858 

training_10153    6: 0.578566931149154   8: 0.202003241065763   5: 0.027435646064305   1: 0.027429938507905   0: 0.027429136608188   4: 0.027429086139917   7: 0.027427534627947   9: 0.027426613598739   2: 0.027426566743117   3: 0.027425305494967 

training_10154    6: 0.754947547789964   8: 0.027271596155563   5: 0.027229072684726   7: 0.027223971484604   4: 0.027222556303594   0: 0.027221832111594   9: 0.027221555307495   1: 0.027221406983983   2: 0.027220248517997   3: 0.027220212660480 

training_10155    5: 0.569870742888647   6: 0.290426042882171   8: 0.017465070776709   1: 0.017464001406529   0: 0.017463835389821   9: 0.017462816166176   7: 0.017462311756879   4: 0.017462175348598   2: 0.017461793776248   3: 0.017461209608221 

training_10156    8: 0.525611808715148   6: 0.318711409597662   5: 0.019465040039520   1: 0.019460875084581   0: 0.019460738524636   4: 0.019458930385379   9: 0.019458235852726   7: 0.019458021150079   2: 0.019457594009104   3: 0.019457346641164 

training_10158    1: 0.773593622890523   2: 0.051425092865653   5: 0.021875263257471   0: 0.021873133516745   6: 0.021873036118561   4: 0.021872569214126   8: 0.021871933090503   9: 0.021871920626488   3: 0.021871768014709   7: 0.021871660405221 

training_1016     5: 0.825094629025033   6: 0.019467439011651   8: 0.019432929547596   1: 0.019431076278904   0: 0.019431040007937   9: 0.019430701034529   4: 0.019428619537600   7: 0.019428386305296   3: 0.019427609441641   2: 0.019427569809814 

training_10162    5: 0.419964420383413   0: 0.257283278011084   2: 0.151911754201776   3: 0.024406665018802   4: 0.024406109482751   1: 0.024405784497293   6: 0.024405642113508   8: 0.024405573421066   7: 0.024405388887708   9: 0.024405383982599 

training_10163    5: 0.838151408607214   6: 0.017985187504359   0: 0.017984271506350   1: 0.017983490746344   2: 0.017983053052754   9: 0.017982946488925   7: 0.017982711350947   3: 0.017982354330913   4: 0.017982323208584   8: 0.017982253203610 

training_10165    4: 0.812413918609920   5: 0.020847829392894   1: 0.020842746320729   6: 0.020842464318749   0: 0.020842438416327   8: 0.020842234436032   9: 0.020842167721334   3: 0.020842085507413   2: 0.020842060308203   7: 0.020842054968400 

training_10168    9: 0.282825606879049   1: 0.249329155643069   0: 0.197453696425387   6: 0.196923573780507   7: 0.015699507735171   4: 0.011589732558186   5: 0.011555235994279   3: 0.011542137397261   2: 0.011540702017216   8: 0.011540651569874 

training_1017     5: 0.439319955488147   8: 0.354489168475999   4: 0.025782708362761   9: 0.025772801947589   3: 0.025772742566256   2: 0.025772660068944   0: 0.025772648378638   1: 0.025772582670543   7: 0.025772451579687   6: 0.025772280461438 

training_10171    6: 0.443042921350015   5: 0.384727112286093   1: 0.021538761216863   0: 0.021529974481168   2: 0.021528085822625   4: 0.021527065673178   3: 0.021526909606173   9: 0.021526508289093   7: 0.021526361881031   8: 0.021526299393760 

training_10172    6: 0.833146783905208   5: 0.018540586957096   8: 0.018540123771267   7: 0.018539402400661   0: 0.018539330733628   4: 0.018539162389684   9: 0.018538917155003   1: 0.018538892408310   2: 0.018538455250056   3: 0.018538345029087 

training_10173    0: 0.459645823140286   6: 0.328557529272277   2: 0.047594885467605   9: 0.047404922534178   8: 0.044442190193472   4: 0.014477308752971   5: 0.014474313617992   1: 0.014469020203617   3: 0.014467523254974   7: 0.014466483562626 

training_10174    5: 0.745015442592114   0: 0.086140030514295   1: 0.021119226319611   4: 0.021106087079038   6: 0.021105692497973   3: 0.021103123567647   9: 0.021102765639476   8: 0.021102563570547   2: 0.021102560018544   7: 0.021102508200756 

training_10175    6: 0.661782533476269   7: 0.221649134982555   5: 0.021820109533565   0: 0.019806316646263   4: 0.012501756656729   1: 0.012495940554050   8: 0.012486859235320   3: 0.012485907959442   9: 0.012485861057899   2: 0.012485579897908 

training_10176    8: 0.767159763358273   6: 0.025876757334127   5: 0.025873008415272   9: 0.025872941160817   0: 0.025870695905884   7: 0.025870551118227   1: 0.025869372664825   4: 0.025869326975699   2: 0.025868927605883   3: 0.025868655460994 

training_10177    8: 0.775167213914194   6: 0.024985790277066   9: 0.024983635415008   5: 0.024983438856873   0: 0.024980527605112   2: 0.024980380365651   1: 0.024980209240287   4: 0.024979985532898   7: 0.024979919162032   3: 0.024978899630879 

training_10178    8: 0.765240382618450   5: 0.026094163261974   4: 0.026088010021071   6: 0.026086307188434   0: 0.026082384255341   9: 0.026082123502631   7: 0.026081990968359   1: 0.026081953397970   2: 0.026081419166227   3: 0.026081265619544 

training_10180    5: 0.815726894457704   6: 0.020477126739740   8: 0.020475336386128   0: 0.020475279201398   1: 0.020475258946820   2: 0.020474299088990   4: 0.020474127734833   9: 0.020474115919731   7: 0.020473808194643   3: 0.020473753330014 

training_10181    5: 0.438131614087437   2: 0.260113869476402   6: 0.140091731242055   1: 0.023099553293947   0: 0.023097182149275   3: 0.023093469786170   4: 0.023093407553943   9: 0.023093371753679   7: 0.023092978132099   8: 0.023092822524991 

training_10183    8: 0.374773947051358   6: 0.353989262631871   7: 0.126133060924852   9: 0.020733329772999   5: 0.020731638457276   0: 0.020728980479246   4: 0.020728523198922   1: 0.020727492672278   2: 0.020727119299339   3: 0.020726645511859 

training_10185    5: 0.555541265167813   2: 0.215480839948232   1: 0.095008709210097   4: 0.019151071434300   6: 0.019147925968474   0: 0.019134617685363   8: 0.019133943553466   3: 0.019133893664903   7: 0.019133873085808   9: 0.019133860281544 

training_10186    5: 0.454920806763405   2: 0.343932347034545   6: 0.025147602296506   3: 0.025143625855410   0: 0.025143404537814   1: 0.025143317050781   4: 0.025142745498288   9: 0.025142345179463   7: 0.025141973074494   8: 0.025141832709293 

training_1019     6: 0.590085248327152   2: 0.223800941305553   5: 0.080655229769567   1: 0.035629042116873   0: 0.016765937994696   9: 0.010761640108332   8: 0.010688093843463   7: 0.010587200276282   4: 0.010514121412199   3: 0.010512544845882 

training_10190    6: 0.487572901027831   9: 0.381318846663669   8: 0.026118481928561   1: 0.024110653541978   5: 0.013482269621008   4: 0.013481458526778   2: 0.013481122213944   0: 0.013479610088561   7: 0.013477432522152   3: 0.013477223865518 

training_10191    1: 0.631655280849107   6: 0.222194633760036   0: 0.051781489388087   5: 0.013488026603530   4: 0.013483280988939   9: 0.013482624426375   3: 0.013479816626003   2: 0.013478633934384   8: 0.013478495336464   7: 0.013477718087075 

training_10192    6: 0.492544849125190   0: 0.246303357048643   7: 0.151120431353862   4: 0.040095687459749   8: 0.011662439622301   5: 0.011655805100976   1: 0.011654782397446   9: 0.011654380588964   2: 0.011654190299613   3: 0.011654077003256 

training_10196    2: 0.464789772688708   5: 0.337022701556281   6: 0.024832102659531   4: 0.024771593815463   8: 0.024764578747146   3: 0.024764451101525   9: 0.024763883009261   7: 0.024763734921909   1: 0.024763640497558   0: 0.024763541002618 

training_10197    0: 0.752465762276524   7: 0.098230599641393   5: 0.018675031416382   4: 0.018667524517655   6: 0.018663060089865   8: 0.018660037687715   1: 0.018659876056873   9: 0.018659766248913   2: 0.018659187987232   3: 0.018659154077449 

training_102      9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_1020     0: 0.303448347739326   2: 0.278933205757266   1: 0.276107332487586   3: 0.020220832845814   5: 0.020219014308996   9: 0.020218962635309   6: 0.020215697726671   4: 0.020213568214625   8: 0.020212101358010   7: 0.020210936926396 

training_10200    6: 0.795051481390029   2: 0.048053869740373   7: 0.043265325364184   5: 0.016235599278270   9: 0.016233384072881   1: 0.016232399787120   0: 0.016232218977413   4: 0.016232047953796   8: 0.016231957527760   3: 0.016231715908174 

training_10201    5: 0.626845257131209   0: 0.162613201387464   2: 0.026326477265312   6: 0.026325477761735   4: 0.026323049782646   1: 0.026314460960771   9: 0.026313746526790   3: 0.026313133947459   8: 0.026312708839061   7: 0.026312486397554 

training_10207    5: 0.519767744684947   6: 0.185161755249402   9: 0.138330045137833   0: 0.022397691249253   2: 0.022394662243992   4: 0.022392577814796   1: 0.022390141260814   3: 0.022388746273020   7: 0.022388363068329   8: 0.022388273017615 

training_10208    5: 0.721317854955219   8: 0.115075905392574   6: 0.020456778978909   0: 0.020455064394202   1: 0.020452054464751   9: 0.020451679542814   2: 0.020447861142242   7: 0.020447691353094   4: 0.020447577817299   3: 0.020447531958895 

training_10209    6: 0.841090498305445   0: 0.042116863319464   1: 0.014602256796331   5: 0.014601938641985   3: 0.014598815051346   9: 0.014598249345908   8: 0.014598018335530   7: 0.014597868779772   2: 0.014597836786630   4: 0.014597654637590 

training_10211    5: 0.694377048140865   8: 0.118380952666423   0: 0.060049852112535   4: 0.018172291728947   6: 0.018171158948578   9: 0.018169907211253   1: 0.018169874746494   2: 0.018169696628047   3: 0.018169613030120   7: 0.018169604786739 

training_10213    3: 0.404123147574617   1: 0.288613537013518   0: 0.159261658074503   5: 0.041132802838021   2: 0.017814479154785   6: 0.017814134217670   9: 0.017811332471532   4: 0.017810011892635   7: 0.017809535329405   8: 0.017809361433314 

training_10214    6: 0.659282611851653   4: 0.153452885889604   0: 0.081349215708005   2: 0.026592691448156   3: 0.013268457760412   5: 0.013234992875159   1: 0.013208265332071   7: 0.013205604367364   9: 0.013204081460451   8: 0.013201193307125 

training_10215    0: 0.426695207778491   5: 0.336333370759668   6: 0.029635046699336   4: 0.029627803407358   2: 0.029623049964166   1: 0.029619283046737   8: 0.029617040895492   3: 0.029616950786067   7: 0.029616373016488   9: 0.029615873646197 

training_10216    6: 0.789664477433946   0: 0.092508134493124   2: 0.026497679235588   3: 0.013089910932615   4: 0.013074320498899   5: 0.013053680934608   1: 0.013031167935800   7: 0.013028280536746   9: 0.013027404402712   8: 0.013024943595963 

training_10218    1: 0.683507274098946   6: 0.131142012160992   4: 0.023196469558734   5: 0.023176931756377   0: 0.023166321859885   8: 0.023163419450266   9: 0.023163225430067   7: 0.023162302588135   2: 0.023161308464922   3: 0.023160734631675 

training_10219    9: 0.450254782842057   6: 0.319629088615320   3: 0.087509661243112   1: 0.029724451344330   8: 0.018881101494631   2: 0.018814664405891   5: 0.018813721887362   7: 0.018799025965999   0: 0.018787087224515   4: 0.018786414976784 

training_1022     6: 0.607981245527172   1: 0.225042373323788   0: 0.058327075943437   7: 0.032667937393879   9: 0.021866950717329   3: 0.010837269774675   5: 0.010819502809938   4: 0.010819479033038   8: 0.010819359104488   2: 0.010818806372257 

training_10222    5: 0.735881018283118   0: 0.123389009676011   6: 0.017614075946766   1: 0.017607551297506   2: 0.017589215263628   4: 0.017586945246967   9: 0.017583779277079   7: 0.017582917788279   3: 0.017582775819397   8: 0.017582711401248 

training_10224    6: 0.830656970319430   5: 0.018853722550537   1: 0.018820391589523   0: 0.018812710798426   4: 0.018810321118965   8: 0.018809908510004   2: 0.018809522213574   3: 0.018808938778175   9: 0.018808830447128   7: 0.018808683674237 

training_10225    4: 0.404627388139317   0: 0.293646405434488   5: 0.189432897594396   1: 0.016069088800506   9: 0.016041762150939   6: 0.016039537575100   2: 0.016036801808622   8: 0.016036011430362   7: 0.016035056859548   3: 0.016035050206721 

training_10227    4: 0.411508112369897   6: 0.321652796219209   9: 0.117376087983421   5: 0.021359353442964   0: 0.021353254225461   1: 0.021351459709265   8: 0.021350139684102   3: 0.021349789162223   7: 0.021349766444979   2: 0.021349240758478 

training_10228    6: 0.461017012003004   2: 0.285278783755673   9: 0.178895844250815   7: 0.010864240463630   0: 0.010664136022620   1: 0.010658330929671   5: 0.010656821798292   4: 0.010655543055628   8: 0.010654685723085   3: 0.010654601997581 

training_1023     6: 0.586528132508316   1: 0.157349825162778   9: 0.149243167278429   5: 0.015271918600562   4: 0.015269791521635   0: 0.015269775205486   3: 0.015267242415532   7: 0.015266812602520   8: 0.015266809996011   2: 0.015266524708730 

training_10230    6: 0.430453821229783   0: 0.413321547727309   1: 0.075186232917082   7: 0.019209568278030   2: 0.010307725351202   9: 0.010307399631960   5: 0.010305117778924   4: 0.010303017933624   3: 0.010302812332888   8: 0.010302756819198 

training_10231    5: 0.584953528503144   6: 0.202127421275058   4: 0.026618196138624   0: 0.026616322394229   1: 0.026615453682435   8: 0.026615442075667   2: 0.026613645451059   9: 0.026613367267885   3: 0.026613363650145   7: 0.026613259561755 

training_10233    6: 0.344617296319195   0: 0.290843245722052   4: 0.269580831220458   5: 0.013570715701698   9: 0.013567347925326   1: 0.013566222432606   3: 0.013563915195209   8: 0.013563791830158   7: 0.013563612777877   2: 0.013563020875420 

training_10235    5: 0.629812547272213   2: 0.172835780674675   6: 0.024672126679526   8: 0.024670651939704   4: 0.024670151549535   9: 0.024669074020896   0: 0.024668128842914   1: 0.024667710311972   7: 0.024667183316684   3: 0.024666645391881 

training_10237    5: 0.763565261508731   1: 0.026310443930608   6: 0.026269513337183   0: 0.026269047529920   2: 0.026264460011989   7: 0.026264343503450   4: 0.026264295916603   8: 0.026264240735533   9: 0.026264198978575   3: 0.026264194547408 

training_10238    1: 0.703949308730386   6: 0.100627041350142   2: 0.069196050980531   0: 0.018141848419582   4: 0.018017007762141   5: 0.018014202479935   8: 0.018013887207822   7: 0.018013752524266   3: 0.018013455928347   9: 0.018013444616847 

training_1024     6: 0.362096301023254   7: 0.305482516998746   4: 0.203116944927001   5: 0.018486171776855   0: 0.018470777648633   3: 0.018470563160345   1: 0.018469488361643   8: 0.018469156964655   2: 0.018469042682622   9: 0.018469036456247 

training_10240    5: 0.494812211985727   4: 0.307150396897987   6: 0.024756667725472   9: 0.024755129697930   0: 0.024754918585473   1: 0.024754794427107   3: 0.024754608942560   8: 0.024753866054531   7: 0.024753718547284   2: 0.024753687135929 

training_10242    5: 0.762917343958390   3: 0.026343155521145   4: 0.026342830973904   6: 0.026342424100363   0: 0.026342414485882   2: 0.026342411704960   1: 0.026342410944397   7: 0.026342355196930   9: 0.026342330345073   8: 0.026342322768955 

training_10243    5: 0.598826984765998   9: 0.236135606869634   6: 0.020632167671182   0: 0.020629737234099   7: 0.020629666319876   4: 0.020629422665458   1: 0.020629182208226   3: 0.020629160671762   8: 0.020629106778142   2: 0.020628964815623 

training_10245    1: 0.475996596184187   4: 0.347746357422483   3: 0.047892163418816   6: 0.018352816284188   5: 0.018345621349608   0: 0.018342837710556   9: 0.018332492726273   8: 0.018330452598493   2: 0.018330437102291   7: 0.018330225203105 

training_10246    0: 0.329077661604648   6: 0.328626777423646   8: 0.271099562182830   1: 0.010195486524060   4: 0.010172039713602   5: 0.010168361879886   9: 0.010165440803631   7: 0.010164988740026   3: 0.010164871924215   2: 0.010164809203456 

training_10253    4: 0.776266361833402   5: 0.070188037898673   6: 0.019221344731802   9: 0.019199172462453   0: 0.019192134446877   1: 0.019190897434976   7: 0.019185717387618   3: 0.019185713308809   8: 0.019185395080986   2: 0.019185225414403 

training_10254    5: 0.823816765817640   4: 0.019579774204390   6: 0.019575873338743   8: 0.019575690229113   0: 0.019575498364428   1: 0.019575422728546   9: 0.019575292989513   3: 0.019575280361832   2: 0.019575224901745   7: 0.019575177064050 

training_10255    6: 0.693118275777327   0: 0.179498665206295   1: 0.055636862360676   8: 0.019307876233318   7: 0.008744365604757   9: 0.008739901602655   5: 0.008739258208878   3: 0.008738478245135   4: 0.008738249373519   2: 0.008738067387440 

training_10258    0: 0.439532288619335   6: 0.270923913846148   3: 0.119150626579434   4: 0.059027983147290   5: 0.018736897284910   7: 0.018548925561684   1: 0.018520291189912   9: 0.018519904812923   2: 0.018519723767142   8: 0.018519445191222 

training_1026     6: 0.863261990782133   0: 0.055561389824019   1: 0.010151734220823   5: 0.010147110990616   3: 0.010146971157644   7: 0.010146492758086   4: 0.010146450290322   9: 0.010146286244452   8: 0.010145853652944   2: 0.010145720078961 

training_10260    6: 0.768219397405800   7: 0.025754657528735   9: 0.025754156739793   0: 0.025753917574702   1: 0.025753786203770   8: 0.025753215063105   5: 0.025753018613674   3: 0.025752721004678   2: 0.025752701939546   4: 0.025752427926197 

training_10261    6: 0.790975926426770   3: 0.062053397673345   8: 0.045927063867593   7: 0.014479865465670   5: 0.014427935516536   9: 0.014427880009656   0: 0.014427640368146   1: 0.014427188662733   4: 0.014426626210738   2: 0.014426475798813 

training_10262    6: 0.677347705174864   7: 0.148454903655790   8: 0.021780553068061   0: 0.021775915283731   9: 0.021775561142974   5: 0.021774137673513   1: 0.021773224643043   4: 0.021772843224017   2: 0.021772736722661   3: 0.021772419411347 

training_10263    1: 0.745555189732468   6: 0.028280948787069   8: 0.028273331607362   0: 0.028272213119201   9: 0.028271976924443   7: 0.028270412714916   5: 0.028269492029210   3: 0.028268948392526   2: 0.028268787425377   4: 0.028268699267427 

training_10264    6: 0.620853267289957   1: 0.194739937092811   0: 0.106265363185225   7: 0.011166153618804   4: 0.011164431559288   5: 0.011162899386552   8: 0.011162096451162   9: 0.011162074324402   2: 0.011161909918097   3: 0.011161867173702 

training_10265    6: 0.854788620634703   0: 0.028902685380221   9: 0.028159323073730   5: 0.012594227926129   1: 0.012593917989696   3: 0.012592825819309   8: 0.012592334386461   2: 0.012592052656953   7: 0.012592023024287   4: 0.012591989108509 

training_10268    6: 0.738601278975079   0: 0.089775903630894   2: 0.046063491004285   9: 0.044766043501301   7: 0.023718202205474   4: 0.017941290027171   1: 0.009947191488103   3: 0.009760636837020   8: 0.009713210726466   5: 0.009712751604205 

training_10272    6: 0.474491648303284   9: 0.206315296927546   4: 0.113947676118414   0: 0.072606410883367   2: 0.058501908304238   1: 0.025925021131455   3: 0.012059454305899   7: 0.012056081430234   5: 0.012053722752104   8: 0.012042779843457 

training_10275    6: 0.513169422457988   9: 0.262018737441839   5: 0.089270111313852   0: 0.037656584329285   1: 0.028111613085722   8: 0.013959735471752   4: 0.013953625767921   3: 0.013953563307706   7: 0.013953348655167   2: 0.013953258168768 

training_10277    6: 0.727976681887476   5: 0.030226276022399   8: 0.030225475239815   2: 0.030225440860371   0: 0.030225174969817   9: 0.030225112960584   1: 0.030224491548437   3: 0.030224004902456   7: 0.030223942995673   4: 0.030223398612973 

training_10280    5: 0.738059534900530   3: 0.134273603536515   6: 0.015960542438991   1: 0.015959786105950   0: 0.015959172651817   4: 0.015958360312465   7: 0.015957396623655   9: 0.015957346699744   8: 0.015957264572292   2: 0.015956992158042 

training_10281    4: 0.459453583281392   6: 0.265295153256402   5: 0.034412607017967   8: 0.034406101190714   9: 0.034405667953087   2: 0.034405426456740   0: 0.034405422457355   3: 0.034405417447111   1: 0.034405314209842   7: 0.034405306729391 

training_10282    5: 0.758392398770372   3: 0.110157022483929   6: 0.016433363375833   1: 0.016432842223617   0: 0.016432373381682   4: 0.016431376975604   7: 0.016430312304414   9: 0.016430260692212   8: 0.016430176019965   2: 0.016429873772373 

training_10283    6: 0.773307120008636   9: 0.025189261201303   0: 0.025188676046520   1: 0.025188554824637   7: 0.025188502761803   5: 0.025188236283233   8: 0.025187995395034   2: 0.025187245800610   3: 0.025187237254512   4: 0.025187170423712 

training_10284    5: 0.523051263065597   6: 0.288251464545968   7: 0.077942740950629   3: 0.015837882105622   1: 0.015822473960670   4: 0.015820490325485   8: 0.015818900784933   0: 0.015818500644670   9: 0.015818352346535   2: 0.015817931269890 

training_10285    6: 0.719542624764931   7: 0.108857355249346   1: 0.040346894928993   4: 0.031690315462845   0: 0.026658792547379   5: 0.014590501604491   9: 0.014583092652089   8: 0.014579227312455   3: 0.014575669663081   2: 0.014575525814390 

training_10289    6: 0.612464013616625   0: 0.221096001938538   1: 0.050444669354239   5: 0.016572267805564   9: 0.016571588677461   7: 0.016570776426494   4: 0.016570456116095   8: 0.016570189538784   2: 0.016570145507422   3: 0.016569891018778 

training_1029     5: 0.710803060219217   2: 0.104840947877022   4: 0.023055845027003   6: 0.023053138128244   1: 0.023046137724423   0: 0.023045485696035   9: 0.023039362095148   3: 0.023038828916890   8: 0.023038613259743   7: 0.023038581056276 

training_10291    0: 0.333520631160242   6: 0.304314021026013   3: 0.270339864029690   1: 0.017847706830142   4: 0.012385725945992   5: 0.012334989011737   7: 0.012319374759952   9: 0.012316627640640   8: 0.012311108990105   2: 0.012309950605486 

training_10292    6: 0.612468128043172   5: 0.242561683166687   0: 0.036041737840969   4: 0.025686021965414   9: 0.020542043053736   7: 0.019172816411664   1: 0.010908441926679   2: 0.010883143117500   3: 0.010869552803691   8: 0.010866431670488 

training_10294    6: 0.509064875797029   5: 0.266621586176965   4: 0.028042927172669   9: 0.028042481473918   8: 0.028040652517744   0: 0.028038763499037   7: 0.028037870675175   1: 0.028037769370815   2: 0.028036729541154   3: 0.028036343775495 

training_10295    6: 0.728813836433098   9: 0.030134018362496   5: 0.030133826486557   8: 0.030131795559427   7: 0.030131735261015   0: 0.030131644037568   4: 0.030131623559080   1: 0.030131288112960   2: 0.030130274490183   3: 0.030129957697617 

training_10297    6: 0.810614693858273   0: 0.047885018934742   1: 0.017720842767511   7: 0.017697169659873   5: 0.017686898186174   8: 0.017682864367787   3: 0.017679072946319   9: 0.017678547102666   4: 0.017677927460695   2: 0.017676964715960 

training_10299    6: 0.830894142567108   3: 0.031355094990803   7: 0.017278266871905   8: 0.017211074083603   0: 0.017210838822939   2: 0.017210262248765   5: 0.017210223265212   1: 0.017210115747900   9: 0.017210097773178   4: 0.017209883628587 

training_103      9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_1030     6: 0.614118361766679   9: 0.237809241581525   5: 0.018510435692736   0: 0.018510043442127   1: 0.018509099025046   7: 0.018509047925579   2: 0.018508577025954   4: 0.018508509414774   8: 0.018508434877686   3: 0.018508249247895 

training_10300    6: 0.816278524000995   5: 0.020414004078362   0: 0.020413786968021   8: 0.020413693662467   2: 0.020413688616469   9: 0.020413521483588   7: 0.020413419803905   1: 0.020413334481685   4: 0.020413050162710   3: 0.020412976741798 

training_10302    6: 0.478670105592193   1: 0.364870638526420   0: 0.069740014835177   9: 0.020540842951053   7: 0.011036751429705   5: 0.011031597970231   3: 0.011030351847377   4: 0.011026854414592   8: 0.011026823103375   2: 0.011026019329875 

training_10305    6: 0.438390395340617   5: 0.252267701318425   7: 0.164774502462610   1: 0.042697424797471   3: 0.016982243174346   0: 0.016978706086384   8: 0.016978000060342   4: 0.016977135667163   9: 0.016977041524617   2: 0.016976849568025 

training_10306    6: 0.789778537473946   0: 0.109349065397005   1: 0.024733156696379   5: 0.011448419801667   8: 0.010918735975684   4: 0.010795208051959   7: 0.010745263051388   2: 0.010745092752870   9: 0.010743860055874   3: 0.010742660743227 

training_10308    6: 0.816131758769232   0: 0.053203726595962   5: 0.016334514713439   8: 0.016334238473193   1: 0.016334002132385   9: 0.016333144408628   7: 0.016332274426542   4: 0.016332272606087   3: 0.016332096498798   2: 0.016331971375735 

training_10310    6: 0.496340141116608   3: 0.188159506957135   8: 0.177415119295747   0: 0.019885618150895   4: 0.019760197777069   2: 0.019702656927536   5: 0.019687352681302   1: 0.019685350345340   9: 0.019682403694913   7: 0.019681653053456 

training_10311    1: 0.483776007690534   6: 0.237007372320918   5: 0.185104287066126   2: 0.021654950699078   4: 0.020672024262857   0: 0.013905176273916   8: 0.009473565923013   7: 0.009471016894968   9: 0.009467909538425   3: 0.009467689330164 

training_10313    0: 0.527028540641142   1: 0.228314414540848   6: 0.131445534284715   9: 0.016178795885583   5: 0.016175727534917   4: 0.016171967278038   2: 0.016171875025223   8: 0.016171385095532   7: 0.016171062098025   3: 0.016170697615977 

training_10314    6: 0.778158619831503   5: 0.077861204840790   7: 0.018007599251301   4: 0.017997562539617   8: 0.017997007939707   9: 0.017996633611545   0: 0.017996283518743   1: 0.017995513349981   2: 0.017994827700462   3: 0.017994747416351 

training_10315    6: 0.692863899215398   9: 0.120847346366702   1: 0.066430455912021   5: 0.017126277449874   0: 0.017123648980649   8: 0.017123290910416   4: 0.017121952233542   3: 0.017121211896526   2: 0.017120968942913   7: 0.017120948091959 

training_10318    1: 0.695947314111632   5: 0.160582405783502   9: 0.017947257899946   4: 0.017941170429441   6: 0.017939689051959   8: 0.017931088758913   0: 0.017931012320054   3: 0.017927061588692   7: 0.017926926228936   2: 0.017926073826925 

training_10319    6: 0.701444999071580   5: 0.160543857862958   3: 0.019444299872081   8: 0.017049088665584   1: 0.017022938988534   0: 0.017020578515642   7: 0.016872158570669   2: 0.016868276663898   4: 0.016867063645490   9: 0.016866738143564 

training_1032     0: 0.683651994876408   6: 0.182310637547836   7: 0.016761325158321   5: 0.016756915515726   1: 0.016755891971400   4: 0.016755484181577   9: 0.016752458090391   2: 0.016752233306813   8: 0.016751944995815   3: 0.016751114355713 

training_10321    9: 0.843509570463660   6: 0.017389864385519   5: 0.017388544980556   8: 0.017388405714357   0: 0.017387770992497   4: 0.017387620962702   1: 0.017387456274289   2: 0.017386944010611   3: 0.017386936889047   7: 0.017386885326761 

training_10322    6: 0.516554919481558   5: 0.307985863906880   7: 0.056504235897585   2: 0.017008644242715   9: 0.017003390238020   8: 0.016990345038335   0: 0.016988882857901   1: 0.016988757614112   4: 0.016988044099957   3: 0.016986916622937 

training_10323    6: 0.748293015446356   8: 0.027968749585303   1: 0.027968585339616   0: 0.027968338762784   7: 0.027967994123802   9: 0.027967341118160   5: 0.027966858836310   3: 0.027966595908812   2: 0.027966276075746   4: 0.027966244803113 

training_10324    6: 0.637956362900958   9: 0.199717468137062   0: 0.020300847453314   4: 0.020300815235883   5: 0.020297258286954   7: 0.020290058633493   8: 0.020285634250375   1: 0.020284417321792   2: 0.020283641603482   3: 0.020283496176686 

training_10328    6: 0.388926884837693   8: 0.320002402326618   5: 0.105765252008235   0: 0.082092275547958   2: 0.029777709871327   9: 0.014690380247677   4: 0.014687566808733   1: 0.014686480691655   7: 0.014685952756310   3: 0.014685094903795 

training_1033     2: 0.443039646473307   5: 0.343689190343257   4: 0.026666147877758   0: 0.026660935666689   6: 0.026658726076947   3: 0.026657382535507   8: 0.026657256704647   7: 0.026656930895796   1: 0.026656928614502   9: 0.026656854811590 

training_10330    6: 0.542547786325846   2: 0.194430957127215   7: 0.079428211460899   5: 0.050770850333791   4: 0.050426744510683   8: 0.016493611544607   3: 0.016483820582732   1: 0.016473687461906   0: 0.016472674651776   9: 0.016471656000544 

training_10332    6: 0.619075782473080   7: 0.228974860533988   1: 0.018994639809760   5: 0.018994426087380   0: 0.018994215055026   4: 0.018993683235539   3: 0.018993248374825   9: 0.018993133151352   8: 0.018993031522264   2: 0.018992979756786 

training_10334    9: 0.444175248658954   6: 0.375394682607741   0: 0.071389003313841   3: 0.026979923777654   1: 0.013691938738728   7: 0.013681088548936   4: 0.013677661083985   2: 0.013670671657648   5: 0.013670173968406   8: 0.013669607644106 

training_10335    6: 0.436992680303188   9: 0.320607381779185   0: 0.066008131289424   5: 0.042471538919537   2: 0.031399425245309   3: 0.025314524445243   1: 0.019339134595816   4: 0.019289608390056   8: 0.019289086851610   7: 0.019288488180632 

training_10337    6: 0.523469601596498   1: 0.245962707082318   0: 0.028846635522049   7: 0.028819116848043   8: 0.028818753180125   9: 0.028817094018410   5: 0.028816602034082   4: 0.028816543863765   2: 0.028816484182672   3: 0.028816461672038 

training_10338    1: 0.547419227387767   5: 0.198596636796851   6: 0.081869883027338   9: 0.024592836211895   4: 0.024589799870430   8: 0.024587229476795   0: 0.024586503926308   7: 0.024586188091408   3: 0.024586016123604   2: 0.024585679087603 

training_10339    6: 0.713492866112716   1: 0.125440430551000   3: 0.039784013366001   7: 0.017362455541662   9: 0.017340707860089   5: 0.017326479490634   4: 0.017321287255490   0: 0.017311481957328   8: 0.017311393916392   2: 0.017308883948686 

training_10340    6: 0.567188023994497   9: 0.309787151854462   3: 0.015390816731061   5: 0.015379014051962   0: 0.015378283483914   7: 0.015376008975864   1: 0.015375559487735   4: 0.015375416925384   8: 0.015375085376176   2: 0.015374639118944 

training_10341    6: 0.548679363802614   0: 0.352426680131293   8: 0.019665335025967   1: 0.018042492025050   7: 0.010239788197632   9: 0.010196416303621   3: 0.010188515093965   5: 0.010187966007943   2: 0.010186739720697   4: 0.010186703691218 

training_10342    9: 0.375446330271153   6: 0.292848479066775   0: 0.214202723112317   5: 0.016799879918567   4: 0.016793020912353   1: 0.016785685336549   2: 0.016781271326334   3: 0.016781112482962   8: 0.016780924878229   7: 0.016780572694762 

training_10344    6: 0.472968156810587   0: 0.438068397409911   8: 0.023414934571429   7: 0.009447169832036   1: 0.009359658196502   3: 0.009351615068126   9: 0.009349478191327   5: 0.009348295801228   4: 0.009346392653219   2: 0.009345901465635 

training_10347    6: 0.667550639643812   7: 0.120064406542574   0: 0.103967521215100   4: 0.031161515292471   5: 0.012892965052739   1: 0.012874540462378   8: 0.012873606335345   2: 0.012871651108234   9: 0.012871645778705   3: 0.012871508568642 

training_10348    6: 0.352730469125315   7: 0.272101175659200   2: 0.136931201257546   0: 0.115262463256821   5: 0.037429039537809   1: 0.017112245755423   4: 0.017109589641546   3: 0.017108358248449   9: 0.017107864716122   8: 0.017107592801769 

training_10349    5: 0.555609879764196   3: 0.255635098581841   7: 0.049454584734009   4: 0.044632776083690   6: 0.015815809844989   0: 0.015787299686538   1: 0.015767147811278   9: 0.015766055335330   8: 0.015765969462165   2: 0.015765378695965 

training_1035     9: 0.464840812855153   5: 0.330446566669764   6: 0.025595884086085   4: 0.025590586878411   8: 0.025588830014999   1: 0.025588138285459   7: 0.025588081116517   0: 0.025588063886719   2: 0.025586673778391   3: 0.025586362428503 

training_10352    6: 0.854782247883784   0: 0.028903553939022   9: 0.028164842060498   5: 0.012594213233548   1: 0.012593928652429   3: 0.012592815280552   8: 0.012592334184230   2: 0.012592052648456   7: 0.012592023027946   4: 0.012591989089535 

training_10354    8: 0.433941269185296   6: 0.343369997532925   5: 0.113701243509028   1: 0.015626263167907   9: 0.015561149191798   0: 0.015561094271589   7: 0.015560067272225   2: 0.015559922894589   3: 0.015559518584503   4: 0.015559474390140 

training_10355    6: 0.804779536375631   0: 0.087432826262761   1: 0.044322147975620   3: 0.012753935315923   9: 0.011459231696276   5: 0.007854725040234   4: 0.007850204947218   2: 0.007849675421792   8: 0.007849343655303   7: 0.007848373309241 

training_10356    9: 0.729196685769171   6: 0.103540002423069   8: 0.020913501954986   3: 0.020909915590869   5: 0.020907977523438   0: 0.020906927708011   1: 0.020906593678691   4: 0.020906439157774   2: 0.020906168747005   7: 0.020905787446986 

training_10357    6: 0.642727248973310   1: 0.173311395545276   7: 0.044437945906235   0: 0.043681514523527   3: 0.015987013936202   5: 0.015973323621032   9: 0.015971628684931   2: 0.015970567908190   4: 0.015969882425081   8: 0.015969478476214 

training_10358    6: 0.796452973028404   1: 0.061824641518877   7: 0.042563101718714   8: 0.014185609162913   0: 0.014175103954780   9: 0.014160286295172   5: 0.014160054572648   4: 0.014159569010810   2: 0.014159360811764   3: 0.014159299925918 

training_10359    6: 0.579559634465710   0: 0.234041802788232   8: 0.057538045214907   1: 0.018413940805320   9: 0.018410626771854   7: 0.018407616958985   2: 0.018407578889223   5: 0.018407502668343   4: 0.018406760590201   3: 0.018406490847225 

training_1036     6: 0.653935431827261   9: 0.199680502471747   7: 0.034963778226463   0: 0.015942727987031   5: 0.015919729440716   1: 0.015917822713948   4: 0.015911709361934   8: 0.015909772652773   3: 0.015909389860548   2: 0.015909135457581 

training_10361    5: 0.345438834079769   1: 0.272464250438140   7: 0.241907117865563   6: 0.020185448585231   0: 0.020171512140185   9: 0.020018963071641   8: 0.020002099284269   3: 0.019938680968434   4: 0.019937562478277   2: 0.019935531088492 

training_10362    5: 0.424708520769084   6: 0.365490446030857   9: 0.026234808436584   1: 0.026228846528972   4: 0.026224453300399   8: 0.026223582447742   0: 0.026222941405625   7: 0.026222697248474   3: 0.026221873290132   2: 0.026221830542130 

training_10364    6: 0.816117158146508   0: 0.053218326498316   5: 0.016334514937725   8: 0.016334238672286   1: 0.016334002155990   9: 0.016333144546024   7: 0.016332274477420   4: 0.016332272652377   3: 0.016332096526924   2: 0.016331971386431 

training_10367    6: 0.785670318412423   0: 0.077390982216451   8: 0.039843519927429   7: 0.032327607369290   1: 0.011249528841978   3: 0.010717195336604   5: 0.010712917496619   4: 0.010696147142554   2: 0.010695903465530   9: 0.010695879791122 

training_10368    6: 0.746210391370987   0: 0.028204369790032   1: 0.028201506123857   8: 0.028199975137428   7: 0.028199019537838   9: 0.028197511316392   5: 0.028197019725689   3: 0.028196844561760   4: 0.028196737200710   2: 0.028196625235306 

training_10370    6: 0.720681999171627   1: 0.031043464390634   0: 0.031035115878191   9: 0.031034969899269   5: 0.031034918873032   8: 0.031034756645583   7: 0.031034220311177   4: 0.031033598703416   3: 0.031033502118681   2: 0.031033454008390 

training_10371    6: 0.671767337157902   2: 0.171469348332558   0: 0.019766559724774   1: 0.019707589964035   7: 0.019554551474946   5: 0.019550652706754   3: 0.019546769205686   9: 0.019546515850004   4: 0.019545709650108   8: 0.019544965933234 

training_10372    6: 0.575318154736812   5: 0.261711157976090   9: 0.020375959671186   1: 0.020371328279338   8: 0.020371087460329   7: 0.020370922341480   0: 0.020370794316850   4: 0.020370465572085   2: 0.020370098177968   3: 0.020370031467861 

training_10373    6: 0.747204846737074   0: 0.146327148758422   7: 0.022062754189773   1: 0.012227591128429   2: 0.012036707954346   4: 0.012029790599294   5: 0.012028926011596   8: 0.012027583485012   3: 0.012027469787652   9: 0.012027181348401 

training_10375    6: 0.741044882580548   0: 0.100796055436534   2: 0.049361265479151   7: 0.034324890234344   9: 0.025007401378164   1: 0.009966440142360   4: 0.009876947208656   8: 0.009875746655725   3: 0.009873906647733   5: 0.009872464236785 

training_10376    6: 0.801399276769566   0: 0.054206238981699   1: 0.018073764157669   7: 0.018060079837561   5: 0.018047834390580   8: 0.018045419582644   9: 0.018042422794325   3: 0.018042242461502   4: 0.018041895439469   2: 0.018040825584985 

training_10377    6: 0.818786860111534   5: 0.020135285981634   9: 0.020135220318005   0: 0.020135119001117   1: 0.020135099541904   7: 0.020134920248811   4: 0.020134819622078   8: 0.020134459101877   2: 0.020134113562729   3: 0.020134102510309 

training_10381    4: 0.490778477980486   5: 0.312076071867881   0: 0.067714123988003   6: 0.018490800463957   1: 0.018490320070862   8: 0.018490156481959   9: 0.018490125642641   2: 0.018490045978763   3: 0.018489946520760   7: 0.018489931004688 

training_10382    6: 0.733810590581418   0: 0.132367468852732   1: 0.043461382495788   7: 0.012920078311188   5: 0.012914447430854   8: 0.012905945358775   9: 0.012905506809313   2: 0.012904971909036   4: 0.012904828731307   3: 0.012904779519589 

training_10384    6: 0.745354725071442   9: 0.028295467500361   7: 0.028294671511178   0: 0.028294466588441   8: 0.028294186215845   1: 0.028293872779321   5: 0.028293677807491   2: 0.028293277422816   3: 0.028292858360879   4: 0.028292796742226 

training_10385    6: 0.756526842159649   0: 0.102667798903216   7: 0.040304416414575   8: 0.020552137647756   1: 0.013327928351021   5: 0.013326269978625   9: 0.013324048558122   2: 0.013324027625797   3: 0.013323489003074   4: 0.013323041358164 

training_10387    5: 0.810547394762819   6: 0.021059255588131   1: 0.021052192869601   0: 0.021051576916459   8: 0.021048908949742   7: 0.021048638269445   9: 0.021048290518095   2: 0.021048064683067   3: 0.021047856115025   4: 0.021047821327616 

training_10388    6: 0.618914314766888   0: 0.219270530124051   1: 0.043013425226936   2: 0.017645291994965   9: 0.016961850752564   4: 0.016873910263383   5: 0.016841654870974   3: 0.016826412043571   8: 0.016826395782194   7: 0.016826214174475 

training_1039     5: 0.451739631804676   6: 0.216835625161361   4: 0.184172359608097   1: 0.021040643583050   8: 0.021039332673508   0: 0.021037678377065   9: 0.021035045587027   2: 0.021034457228729   3: 0.021032647210435   7: 0.021032578766051 

training_10390    3: 0.436018017645214   5: 0.317746201807310   4: 0.030792298072117   0: 0.030780507810951   2: 0.030777690734149   6: 0.030777590400621   8: 0.030776971534609   9: 0.030776961480923   1: 0.030776900721829   7: 0.030776859792278 

training_10391    7: 0.604390076507726   6: 0.141045558417786   0: 0.103041318676363   1: 0.021654157591774   8: 0.021645425221437   5: 0.021644961468608   9: 0.021644701055450   3: 0.021644695050172   2: 0.021644649442018   4: 0.021644456568666 

training_10393    5: 0.798749059215660   4: 0.049660172192206   3: 0.019013071094867   0: 0.018963752513039   6: 0.018952132584212   1: 0.018935046727340   9: 0.018934899972756   8: 0.018930889370291   7: 0.018930579370539   2: 0.018930396959091 

training_10394    6: 0.711047796193945   1: 0.093305446782480   7: 0.054757783029504   0: 0.020135967326929   5: 0.020128831252042   9: 0.020127724574722   4: 0.020124979438846   8: 0.020124178729933   3: 0.020123699445187   2: 0.020123593226413 

training_10395    0: 0.529075972097194   6: 0.345327238455205   1: 0.025207451091330   8: 0.022798175455265   7: 0.021823748117682   9: 0.011680479747830   4: 0.011157801314196   3: 0.011020376899853   2: 0.010974460763343   5: 0.010934296058102 

training_10397    6: 0.755875302059675   9: 0.027133257697017   8: 0.027129175310530   0: 0.027125023055136   7: 0.027123694838200   1: 0.027123674920686   4: 0.027122637703107   2: 0.027122541032271   5: 0.027122434918003   3: 0.027122258465375 

training_10398    1: 0.453313460935443   6: 0.400388171921669   0: 0.032390137777707   2: 0.022188761898630   3: 0.015347872479106   4: 0.015289033939282   8: 0.015276592742575   7: 0.015275595984234   5: 0.015265947861893   9: 0.015264424459460 

training_10399    7: 0.727557577860337   1: 0.030288589259803   0: 0.030275578420887   5: 0.030274127466961   6: 0.030271234162990   9: 0.030270572508517   3: 0.030269356932746   4: 0.030264886135173   8: 0.030264242640638   2: 0.030263834611947 

training_104      5: 0.497825865595300   6: 0.372681490083335   0: 0.016195815597446   4: 0.016187631069978   8: 0.016185690135082   2: 0.016185600459920   7: 0.016185019104618   1: 0.016184538023953   9: 0.016184491478800   3: 0.016183858451568 

training_1040     6: 0.581797697712856   7: 0.219745301889356   3: 0.060969344367666   0: 0.019648292809325   5: 0.019640903318301   9: 0.019640081597907   1: 0.019639928780283   8: 0.019639706327501   4: 0.019639622414541   2: 0.019639120782265 

training_10401    9: 0.567846404123326   5: 0.139795530447304   4: 0.036577704577046   3: 0.036541764642348   8: 0.036540920253432   2: 0.036540893744197   7: 0.036540045127313   0: 0.036539297013326   1: 0.036538821027560   6: 0.036538619044147 

training_10402    5: 0.643990857371581   3: 0.171497520675618   0: 0.023064798684196   4: 0.023064526867981   6: 0.023064131771486   1: 0.023064116036012   2: 0.023063606069361   7: 0.023063545378891   8: 0.023063528546438   9: 0.023063368598437 

training_10403    6: 0.720486786191055   1: 0.100062193077588   0: 0.092617498194676   9: 0.012766110910673   8: 0.012397431701640   3: 0.012350405656925   5: 0.012332987950115   2: 0.012330622156850   7: 0.012328050457013   4: 0.012327913703464 

training_10404    1: 0.526527102503045   7: 0.303037876741051   5: 0.047193008883552   0: 0.017708496068385   4: 0.017646433261414   6: 0.017585987646969   9: 0.017576497314845   2: 0.017574962034253   3: 0.017574837481332   8: 0.017574798065154 

training_10406    6: 0.708962242501474   0: 0.118499287819410   2: 0.058122623892811   9: 0.034461833956491   7: 0.021796198246430   4: 0.011638509953310   8: 0.011634477857536   5: 0.011629048671998   3: 0.011627936651398   1: 0.011627840449142 

training_10411    5: 0.617959093002160   9: 0.177452806745278   7: 0.073965892993075   4: 0.018662583275194   6: 0.018660256772088   8: 0.018660060948234   0: 0.018659886341923   1: 0.018659853108817   2: 0.018659787569900   3: 0.018659779243330 

training_10412    4: 0.394581314260283   0: 0.303875926369466   6: 0.037708437072771   9: 0.037694715110059   8: 0.037692998560886   1: 0.037691800878146   5: 0.037691230434832   7: 0.037689029352121   2: 0.037687693487073   3: 0.037686854474363 

training_10414    0: 0.567724625610881   5: 0.167266095875159   9: 0.091833573831073   6: 0.070515994955542   4: 0.017117072999889   1: 0.017109894670838   8: 0.017109097403213   2: 0.017108077869829   7: 0.017107956291041   3: 0.017107610492535 

training_10416    9: 0.785733161113431   6: 0.045481645061697   3: 0.021133989657532   8: 0.021108975386162   2: 0.021093690948232   1: 0.021092632385950   5: 0.021091832618481   0: 0.021089143457909   4: 0.021087700922382   7: 0.021087228448224 

training_10418    6: 0.770270336196973   2: 0.077422149826742   1: 0.043274641440956   0: 0.015577875157191   8: 0.015576473728491   9: 0.015576013343317   5: 0.015575961389732   7: 0.015575790764976   4: 0.015575424595313   3: 0.015575333556309 

training_10419    3: 0.488506674736853   5: 0.339267881471731   6: 0.021559045897933   0: 0.021536631306409   1: 0.021535911859686   2: 0.021527678099597   4: 0.021518360301712   9: 0.021517579713229   8: 0.021515256730166   7: 0.021514979882685 

training_10423    3: 0.416817439390883   6: 0.414837875457638   0: 0.035811122122606   8: 0.019464960249759   2: 0.018852619441500   5: 0.018852047377691   4: 0.018846588823444   1: 0.018844629836981   7: 0.018836381425312   9: 0.018836335874186 

training_10427    4: 0.735477458249537   7: 0.071023597394604   9: 0.024191127787858   5: 0.024188676899621   2: 0.024188239317675   6: 0.024187042941704   0: 0.024186254613299   1: 0.024186192437746   3: 0.024185728054817   8: 0.024185682303139 

training_10429    3: 0.521338636837415   6: 0.226753433285943   8: 0.071878808337103   1: 0.025725854994103   0: 0.025724679385418   5: 0.025724590420319   4: 0.025716522140725   7: 0.025712795604584   9: 0.025712567120852   2: 0.025712111873539 

training_10430    5: 0.586046480239365   7: 0.210725655964095   2: 0.054592435792368   0: 0.051295008346647   6: 0.016228782436351   4: 0.016223796991007   1: 0.016222377426046   9: 0.016221912177481   8: 0.016221865511215   3: 0.016221685115425 

training_10431    5: 0.745139691050104   8: 0.028329649476361   4: 0.028319354728999   9: 0.028316030348228   3: 0.028315996226365   2: 0.028315941055248   1: 0.028315893302829   7: 0.028315875393646   0: 0.028315839896922   6: 0.028315728521298 

training_10432    5: 0.436284601516639   1: 0.407789945368749   8: 0.019492348973319   6: 0.019492234975182   0: 0.019492103036851   2: 0.019490213584223   4: 0.019489740046031   9: 0.019489642579728   7: 0.019489587607917   3: 0.019489582311361 

training_10434    5: 0.561825069560840   9: 0.166179168487818   6: 0.160939794240097   4: 0.015893753407629   0: 0.015867238941437   3: 0.015861584001801   7: 0.015858799423828   1: 0.015858796773513   8: 0.015858097905894   2: 0.015857697257143 

training_10435    6: 0.362429171831322   5: 0.218431045463097   0: 0.184553206798521   4: 0.131090071131303   2: 0.017254108812486   1: 0.017252064998270   7: 0.017248661961121   9: 0.017247860129593   3: 0.017246935537285   8: 0.017246873337002 

training_10436    5: 0.601130173799041   8: 0.199804227925488   4: 0.070385900873622   6: 0.018387510388635   9: 0.018386385836551   0: 0.018385081469092   3: 0.018380976655802   1: 0.018380698502062   7: 0.018379639304299   2: 0.018379405245409 

training_10439    5: 0.454636102263791   4: 0.337830416277203   2: 0.025942492096457   3: 0.025942435872215   1: 0.025941737300476   6: 0.025941668484992   0: 0.025941532970350   9: 0.025941303217901   7: 0.025941287740810   8: 0.025941023775805 

training_1044     3: 0.416155079366040   5: 0.374881808902784   0: 0.056706635856263   6: 0.038338006030310   4: 0.018992234373374   8: 0.018989261449175   1: 0.018987121472383   2: 0.018986325891201   7: 0.018982053701194   9: 0.018981472957275 

training_10440    8: 0.336299678124347   5: 0.277417424543510   6: 0.208418995958521   3: 0.053160080412528   0: 0.020791069348301   1: 0.020785464082469   4: 0.020784357790556   9: 0.020781135526452   2: 0.020781081135370   7: 0.020780713077946 

training_10442    4: 0.678575383451619   6: 0.150803310263336   8: 0.021391984764637   1: 0.021331115865366   0: 0.021322624107330   5: 0.021319674044186   9: 0.021316362961550   2: 0.021314461041374   7: 0.021312749729012   3: 0.021312333771591 

training_10444    6: 0.540668632955218   0: 0.293132950389386   7: 0.047104194744782   5: 0.017014879877060   4: 0.017014824804580   1: 0.017013281766134   8: 0.017013047877502   9: 0.017012771118000   3: 0.017012750201589   2: 0.017012666265749 

training_10445    6: 0.351132293186162   4: 0.324904767121359   0: 0.200451471425705   1: 0.046726728738367   8: 0.022933128896359   7: 0.010955548193780   3: 0.010765880639082   5: 0.010712513268465   9: 0.010709276643562   2: 0.010708391887159 

training_10446    3: 0.655396936267431   1: 0.164109540824987   9: 0.037257275802852   8: 0.020493223322483   6: 0.020480032501530   0: 0.020470293336687   5: 0.020461706052815   4: 0.020448314944957   2: 0.020441577429614   7: 0.020441099516643 

training_10447    5: 0.813802622066370   6: 0.020701270653640   0: 0.020698895343415   1: 0.020688057426732   4: 0.020686959694849   8: 0.020685197574954   3: 0.020684838844206   7: 0.020684306131547   9: 0.020684054140721   2: 0.020683798123566 

training_10449    6: 0.805611653568911   0: 0.063736906163722   1: 0.016366019184765   8: 0.016333007742279   7: 0.016329372198039   4: 0.016326351953505   5: 0.016324539176214   9: 0.016324467657364   2: 0.016323863088194   3: 0.016323819267007 

training_10452    0: 0.502007202868088   6: 0.313211455906477   1: 0.065347928643171   9: 0.048046403402164   3: 0.011903215987530   7: 0.011902369099356   2: 0.011901920878188   5: 0.011894304183851   4: 0.011893522777883   8: 0.011891676253293 

training_10453    3: 0.422614501549701   5: 0.391712075487928   1: 0.023216319295309   2: 0.023214873585551   0: 0.023210999208539   6: 0.023210553095839   4: 0.023207786107414   9: 0.023205486921214   8: 0.023203864875204   7: 0.023203539873299 

training_10454    0: 0.756146627167410   1: 0.027110281462293   5: 0.027101936035707   6: 0.027094322436891   3: 0.027092823519464   2: 0.027091213749502   9: 0.027090824094192   7: 0.027090764834495   4: 0.027090753856326   8: 0.027090452843719 

training_10455    6: 0.718399101052044   1: 0.125444225364539   0: 0.043880022537162   2: 0.037015407456033   9: 0.034864378600443   8: 0.008236706084470   5: 0.008052459598721   3: 0.008036840030796   4: 0.008035573811049   7: 0.008035285464743 

training_10458    5: 0.718789204125817   1: 0.082481182584203   6: 0.024845750630330   0: 0.024842385028795   8: 0.024842372745214   4: 0.024840401716517   2: 0.024839980488763   9: 0.024839758040371   3: 0.024839523254151   7: 0.024839441385840 

training_10459    4: 0.641419992822799   5: 0.150899029182561   1: 0.025965552166773   0: 0.025962768088313   6: 0.025962467693323   8: 0.025958588942632   2: 0.025958401141428   7: 0.025957841127716   3: 0.025957751641984   9: 0.025957607192469 

training_10462    1: 0.610901611843105   0: 0.257032187055734   5: 0.016555401526411   4: 0.016524175825375   9: 0.016505625118742   8: 0.016500694302702   6: 0.016496909733277   3: 0.016495126244436   2: 0.016494531841627   7: 0.016493736508590 

training_10464    8: 0.838868306966883   6: 0.017907913071347   0: 0.017904959563276   1: 0.017903787746294   9: 0.017903410772783   5: 0.017902938000759   7: 0.017902498014560   2: 0.017902185370216   4: 0.017902103869031   3: 0.017901896624851 

training_10467    6: 0.537920286080452   1: 0.328437227850681   5: 0.016706732369286   0: 0.016706574505559   4: 0.016705364731723   2: 0.016705274206297   9: 0.016705078314783   3: 0.016704610135445   7: 0.016704451192885   8: 0.016704400612890 

training_1047     6: 0.322413312401869   0: 0.266973987090690   3: 0.208268419329532   5: 0.120672270927103   4: 0.013614499102888   9: 0.013612833973682   1: 0.013612101765572   8: 0.013611227871160   7: 0.013610750425682   2: 0.013610597111821 

training_10470    5: 0.500679726367981   6: 0.346672812291486   1: 0.048304123398531   4: 0.024799199716488   3: 0.013272313228748   0: 0.013256393792509   8: 0.013255759632208   2: 0.013253808985758   7: 0.013252932815438   9: 0.013252929770853 

training_10471    6: 0.745649574123145   1: 0.028263262645937   8: 0.028263197200201   5: 0.028262801112983   0: 0.028261280310286   2: 0.028260398560314   7: 0.028260003439051   3: 0.028259899708126   4: 0.028259818988062   9: 0.028259763911895 

training_10472    5: 0.653434096237395   6: 0.215231521857322   3: 0.033987462420162   7: 0.013919594057303   1: 0.013905669720634   0: 0.013905555569459   2: 0.013905151584972   8: 0.013903979551812   4: 0.013903696603601   9: 0.013903272397342 

training_10473    1: 0.702824491549856   6: 0.132859873403966   4: 0.034409421322711   0: 0.021811781724320   5: 0.018020845029345   9: 0.018015744317517   8: 0.018015699711214   3: 0.018014629528170   7: 0.018013760058827   2: 0.018013753354076 

training_10475    6: 0.657449512336604   8: 0.127480111511264   0: 0.051366097085492   1: 0.051113017412925   7: 0.018807024110433   4: 0.018758368216420   5: 0.018756963872623   9: 0.018756775855635   2: 0.018756259877789   3: 0.018755869720815 

training_10478    5: 0.461731389089312   2: 0.295643336991299   6: 0.030336921153833   4: 0.030332143346887   7: 0.030330277665936   8: 0.030325988429015   0: 0.030325462349112   3: 0.030324991994590   9: 0.030324889338360   1: 0.030324599641655 

training_10484    3: 0.777686626013125   5: 0.024717021108610   4: 0.024702397699253   0: 0.024699375237691   6: 0.024699270733271   8: 0.024699227605912   1: 0.024699216687450   2: 0.024699169104929   7: 0.024698936033632   9: 0.024698759776128 

training_10485    6: 0.648428941943435   9: 0.215146293368741   7: 0.017065483551134   5: 0.017055416867446   0: 0.017053178188595   8: 0.017051533725002   1: 0.017051160654870   4: 0.017050072200380   2: 0.017048962359486   3: 0.017048957140909 

training_10487    6: 0.586330182278112   9: 0.128513584142175   8: 0.125835664518297   5: 0.062931867922526   1: 0.026110235674216   4: 0.014114824388141   0: 0.014070901070385   2: 0.014035095837153   7: 0.014029150928237   3: 0.014028493240758 

training_10489    6: 0.574489940916959   5: 0.188963502108213   0: 0.088263109220130   1: 0.021185699436221   7: 0.021185231669544   9: 0.021182810878719   8: 0.021182761191759   2: 0.021182349175369   3: 0.021182314052930   4: 0.021182281350157 

training_1049     6: 0.632692685738949   5: 0.142299102676361   9: 0.028137571835923   4: 0.028136619410279   0: 0.028127714397741   7: 0.028121986095775   8: 0.028121800347161   3: 0.028120942531765   2: 0.028120889763969   1: 0.028120687202077 

training_10491    6: 0.630847517170075   0: 0.144596082891563   2: 0.028086128091694   7: 0.028073424049920   8: 0.028070067996899   5: 0.028069745483220   1: 0.028065691411461   9: 0.028064294594421   4: 0.028063527928907   3: 0.028063520381838 

training_10494    6: 0.680321344400835   0: 0.163604703518579   7: 0.050529931510870   8: 0.030726903715467   1: 0.012472515615309   5: 0.012469700435338   9: 0.012468958060745   4: 0.012468829301134   2: 0.012468628625192   3: 0.012468484816530 

training_10498    5: 0.495388892566101   1: 0.264712257887999   4: 0.092970528106134   3: 0.045724497479738   7: 0.016881553800460   6: 0.016867180900560   8: 0.016866274667901   9: 0.016863738141456   0: 0.016863414228441   2: 0.016861662221209 

training_10499    5: 0.605045319006771   6: 0.158884674298762   7: 0.085104269417017   3: 0.021578684760566   4: 0.021577628938938   0: 0.021567311574948   9: 0.021560980422516   1: 0.021560850614830   8: 0.021560324559908   2: 0.021559956405743 

training_105      8: 0.391145304305449   6: 0.377585583223722   1: 0.046612830170012   7: 0.046235614683688   9: 0.029923681917754   4: 0.021902268765009   0: 0.021707018780947   2: 0.021697793939524   5: 0.021596169063055   3: 0.021593735150840 

training_1050     6: 0.632553436348644   5: 0.142613250415778   4: 0.028116712220227   9: 0.028105535764088   0: 0.028103020914328   8: 0.028102344781813   7: 0.028102312951951   2: 0.028101267915411   1: 0.028101209422677   3: 0.028100909265081 

training_10500    4: 0.729972404746650   5: 0.030012787594951   0: 0.030003137417132   6: 0.030002721494614   2: 0.030001641365569   3: 0.030001567954249   8: 0.030001523931696   7: 0.030001494080876   9: 0.030001383562216   1: 0.030001337852047 

training_10503    8: 0.790109773385184   2: 0.064574026905172   0: 0.018168024562999   6: 0.018167153162217   1: 0.018164502359901   5: 0.018163868946766   9: 0.018163667567713   7: 0.018163166317983   4: 0.018163036322955   3: 0.018162780469110 

training_10505    6: 0.759183499321185   8: 0.106106861057796   0: 0.024322708188031   1: 0.024087542770078   4: 0.014576083103126   9: 0.014404605243828   3: 0.014331669133967   2: 0.014329483907100   5: 0.014328870796521   7: 0.014328676478368 

training_10506    6: 0.651172964750762   0: 0.117367322194147   1: 0.083417200384986   2: 0.021155413683179   8: 0.021150848309534   5: 0.021149742034160   7: 0.021149339559031   4: 0.021146696119731   9: 0.021145699729920   3: 0.021144773234550 

training_10508    3: 0.301931940468852   6: 0.263226668002036   2: 0.257648051429685   0: 0.048800629346331   1: 0.021421914276754   9: 0.021417370411492   5: 0.021391418568644   4: 0.021389303830134   7: 0.021386626570884   8: 0.021386077095188 

training_10509    5: 0.488516947643860   3: 0.331697740949638   6: 0.022482317869592   1: 0.022476992535084   0: 0.022472456657535   4: 0.022472120485679   8: 0.022470625058818   2: 0.022470607637288   7: 0.022470148865282   9: 0.022470042297224 

training_10515    0: 0.814422601486668   6: 0.020623032140807   5: 0.020622694242706   1: 0.020620312743372   3: 0.020619369028599   7: 0.020618837968386   4: 0.020618733099029   9: 0.020618629613018   8: 0.020618035733695   2: 0.020617753943720 

training_10518    5: 0.576134332441924   1: 0.235947526900163   4: 0.063432822406565   6: 0.017788018857986   0: 0.017784815314637   9: 0.017782893740168   8: 0.017782751983601   2: 0.017782693031490   7: 0.017782216367719   3: 0.017781928955745 

training_10519    6: 0.487795700714634   0: 0.308249966513808   7: 0.054502065093000   8: 0.038393051968520   3: 0.030763312403241   5: 0.016061050044074   1: 0.016060643315968   9: 0.016060105407563   4: 0.016057238888881   2: 0.016056865650311 

training_1052     1: 0.439842636202599   6: 0.365009766284798   2: 0.073785323417269   0: 0.031510639245165   9: 0.015004380322226   7: 0.014977045476251   5: 0.014969501384941   3: 0.014967270944612   4: 0.014966920416714   8: 0.014966516305425 

training_10520    6: 0.525749642221838   1: 0.316745518087582   0: 0.047718829477211   5: 0.015684891197241   7: 0.015684330905349   9: 0.015683684499547   4: 0.015683439202121   8: 0.015683391590436   3: 0.015683179081527   2: 0.015683093737148 

training_10521    2: 0.530125010857348   6: 0.268842836495042   1: 0.082901706526458   7: 0.031710081422417   0: 0.014463821578353   8: 0.014428691866045   3: 0.014406636891748   5: 0.014394388922490   9: 0.014365540596968   4: 0.014361284843133 

training_10524    4: 0.703911325083824   6: 0.082597737110806   0: 0.026692862101033   5: 0.026690903045029   1: 0.026689587317734   7: 0.026688421853201   9: 0.026683956030729   8: 0.026683515372247   3: 0.026681039414880   2: 0.026680652670517 

training_10527    5: 0.736255700430041   1: 0.105402024570565   6: 0.019798731725423   9: 0.019797437723912   0: 0.019795754424728   8: 0.019792514212572   4: 0.019789993636319   2: 0.019789706831426   7: 0.019789091608219   3: 0.019789044836796 

training_10529    5: 0.750361651290914   4: 0.027743281052858   8: 0.027737139486798   3: 0.027736959265954   9: 0.027736910972231   6: 0.027736904909205   2: 0.027736847289338   7: 0.027736813830357   0: 0.027736777290686   1: 0.027736714611660 

training_10530    6: 0.584112850713946   1: 0.275086597706945   7: 0.043442232607785   8: 0.026077149574650   0: 0.011894048668863   4: 0.011878910695926   5: 0.011878213794892   9: 0.011876953032983   3: 0.011876527714893   2: 0.011876515489115 

training_10531    6: 0.627719012146726   5: 0.212170359387663   9: 0.041586382707849   0: 0.032736584817550   1: 0.029473349257906   8: 0.011263388631513   7: 0.011263067466684   2: 0.011262722995441   4: 0.011262671105378   3: 0.011262461483290 

training_10532    5: 0.729858999112368   7: 0.098496225196753   4: 0.021459048852479   6: 0.021455505451386   8: 0.021455134948044   0: 0.021455134423109   9: 0.021455127564784   1: 0.021454966507277   3: 0.021454930600215   2: 0.021454927343584 

training_10534    5: 0.736417496360688   1: 0.102550423123612   4: 0.020133230565999   6: 0.020129278871205   7: 0.020128546065300   0: 0.020128404240274   8: 0.020128256421802   9: 0.020128209811355   2: 0.020128086135541   3: 0.020128068404223 

training_10536    5: 0.478472237337665   7: 0.170405344831332   2: 0.160811241241958   6: 0.027190073220589   0: 0.027188267769336   1: 0.027187819815394   9: 0.027187641977283   8: 0.027186255157666   3: 0.027185654819635   4: 0.027185463829143 

training_10537    6: 0.728941092458203   0: 0.107341327355668   5: 0.060162299567812   7: 0.023591516404601   9: 0.020359601666663   8: 0.012013480796204   2: 0.011952312850147   3: 0.011941675340280   1: 0.011854667679449   4: 0.011842025880973 

training_10538    4: 0.752870905163869   5: 0.027465029275113   0: 0.027458144183477   8: 0.027458096193597   3: 0.027458048872518   2: 0.027457996131462   6: 0.027457950777499   1: 0.027457944479966   7: 0.027457942792290   9: 0.027457942130208 

training_10539    6: 0.367486300778883   0: 0.361220956480627   1: 0.150018661251510   4: 0.027115445257357   9: 0.024754282393467   7: 0.014092044273495   3: 0.013844536954042   5: 0.013834802987512   8: 0.013816529800649   2: 0.013816439822459 

training_10541    5: 0.803696614446768   0: 0.021853226535498   4: 0.021825890340685   1: 0.021822320062519   6: 0.021802212679756   9: 0.021801109227001   3: 0.021800245065834   2: 0.021799856361042   8: 0.021799659758074   7: 0.021798865522823 

training_10542    5: 0.524188293339541   6: 0.287284341958250   3: 0.023568228553420   4: 0.023566068044766   8: 0.023565603822117   0: 0.023565594447498   7: 0.023565570324619   1: 0.023565521499303   2: 0.023565431543426   9: 0.023565346467060 

training_10544    4: 0.523743582240871   5: 0.319159276600815   6: 0.020751836877045   7: 0.019492747028115   0: 0.019490795529440   3: 0.019474066490749   2: 0.019473310026448   8: 0.019472198928788   9: 0.019471203641040   1: 0.019470982636687 

training_10545    6: 0.842517216229797   0: 0.030233671854033   5: 0.025317384273498   2: 0.014617151170529   1: 0.014557413887685   8: 0.014551644465658   4: 0.014551537658763   9: 0.014551467849926   7: 0.014551303084953   3: 0.014551209525159 

training_10546    6: 0.732315140542256   0: 0.146889141817536   2: 0.022696185824753   7: 0.018295433446370   4: 0.017638009639418   1: 0.016256704363059   3: 0.015406392992390   5: 0.010182597234319   9: 0.010160573846287   8: 0.010159820293612 

training_10547    5: 0.453329717457821   2: 0.222455950573233   7: 0.137306569506714   0: 0.062572513638604   6: 0.020723576524349   1: 0.020723359212204   9: 0.020722290504988   4: 0.020722103947913   3: 0.020722019909953   8: 0.020721898724219 

training_10548    1: 0.683481192498587   0: 0.126186499936828   5: 0.048181534553211   6: 0.038405227977215   3: 0.017304323910417   7: 0.017292873258141   8: 0.017289320005240   9: 0.017288095907243   4: 0.017285957931294   2: 0.017284974021824 

training_10551    3: 0.328275637679489   1: 0.322763490275360   5: 0.213171412489881   6: 0.019414515336187   0: 0.019401893790650   9: 0.019396593419006   7: 0.019394549548885   4: 0.019394501285986   8: 0.019394156040413   2: 0.019393250134142 

training_10553    6: 0.616680561934220   0: 0.250793753255399   8: 0.047914772365714   1: 0.019988619732292   7: 0.010841428646417   9: 0.010795085298710   5: 0.010749332592377   4: 0.010746453146082   2: 0.010745127303974   3: 0.010744865724814 

training_10555    6: 0.429356680113689   4: 0.222340943495059   0: 0.146915948556572   3: 0.049569967429092   7: 0.047545525849956   1: 0.045112069856059   2: 0.014792121461273   5: 0.014790613945899   8: 0.014788137868826   9: 0.014787991423575 

training_10556    5: 0.740165791612177   8: 0.080077454501242   4: 0.022475221888717   0: 0.022472593436022   1: 0.022470623589351   2: 0.022468044801210   7: 0.022468022275453   6: 0.022467841700395   3: 0.022467280989919   9: 0.022467125205513 

training_10559    1: 0.557757602950902   6: 0.234776935024951   8: 0.063699051100056   0: 0.042266820914762   7: 0.016929423862154   5: 0.016921253266117   4: 0.016916229340570   3: 0.016911092668228   9: 0.016910908912805   2: 0.016910681959456 

training_10561    5: 0.666703233506130   8: 0.167747292329300   4: 0.020697783173739   6: 0.020695549045312   1: 0.020695340694175   7: 0.020693303116495   3: 0.020692110990335   2: 0.020692055871116   0: 0.020691930874489   9: 0.020691400398909 

training_10563    6: 0.344480261334180   3: 0.324352542109460   1: 0.219420703816480   2: 0.041411423076045   0: 0.011734266221702   5: 0.011722475790650   4: 0.011719724533747   9: 0.011719711050520   7: 0.011719554345969   8: 0.011719337721248 

training_10564    5: 0.519713520361983   8: 0.285202489277330   4: 0.024389614314722   6: 0.024386127997532   0: 0.024385997397124   9: 0.024384654679136   3: 0.024384511826486   2: 0.024384454132734   7: 0.024384315206119   1: 0.024384314806833 

training_10565    5: 0.549359845089081   8: 0.257995401994107   0: 0.024081543395096   6: 0.024081388616011   4: 0.024080927277267   2: 0.024080656379710   3: 0.024080628303512   1: 0.024080132410252   9: 0.024079745308073   7: 0.024079731226891 

training_10566    3: 0.348105857746183   5: 0.253805798738775   1: 0.227098419615099   0: 0.024434113360494   6: 0.024429737868410   2: 0.024427121622993   8: 0.024425704912913   4: 0.024424647387240   9: 0.024424357247274   7: 0.024424241500620 

training_10567    6: 0.748042357307649   1: 0.072329728016366   0: 0.051322725639689   9: 0.036707461981446   3: 0.015539049666196   4: 0.015216322897699   7: 0.015216192610996   2: 0.015210389192772   5: 0.015208497166502   8: 0.015207275520686 

training_10569    6: 0.798320212194745   0: 0.088036597742098   7: 0.022027803853307   2: 0.013115463277768   4: 0.013088601974427   9: 0.013083508765040   1: 0.013082163085470   5: 0.013082143670193   8: 0.013081931901553   3: 0.013081573535399 

training_1057     6: 0.757810197012936   7: 0.057955242361302   9: 0.057723994378349   5: 0.018079880647145   0: 0.018078839703836   8: 0.018073530307582   1: 0.018070567393167   4: 0.018069938860206   2: 0.018069028932244   3: 0.018068780403234 

training_10573    5: 0.367395404144622   3: 0.299293342783830   1: 0.097602697627115   7: 0.094720525383931   4: 0.023501155640090   8: 0.023500722197872   6: 0.023497638409301   0: 0.023496822392866   9: 0.023496414801127   2: 0.023495276619246 

training_10576    0: 0.646083305231899   4: 0.135631338986640   1: 0.027287012208200   6: 0.027286572858564   5: 0.027286351797519   9: 0.027285370521220   2: 0.027285286345388   7: 0.027285206277760   8: 0.027284789667163   3: 0.027284766105648 

training_1058     9: 0.745600822031174   6: 0.028279347379640   0: 0.028266171337405   5: 0.028265987368080   1: 0.028265457027723   8: 0.028265434878468   7: 0.028265145538444   3: 0.028264057458639   2: 0.028263909818729   4: 0.028263667161699 

training_10581    6: 0.547383207960265   9: 0.174416549628995   5: 0.093051736159726   0: 0.072508769707178   1: 0.018780413642723   4: 0.018776903372459   8: 0.018771884827853   7: 0.018771585814159   2: 0.018771292265484   3: 0.018767656621158 

training_10582    1: 0.564375522976362   6: 0.234119076736681   2: 0.059710827248002   5: 0.045462245940819   0: 0.032746999229855   4: 0.012730206313705   7: 0.012723342301000   9: 0.012721355695116   8: 0.012708897730435   3: 0.012701525828026 

training_10584    6: 0.456534685347186   8: 0.311559955821330   1: 0.104818521356288   0: 0.031012066103057   4: 0.016042386292815   5: 0.016007010852932   9: 0.016007004106651   7: 0.016006839449074   3: 0.016005775528795   2: 0.016005755141872 

training_10585    4: 0.680293785843843   1: 0.035527986963930   5: 0.035525144263722   0: 0.035524883579862   6: 0.035523320207700   2: 0.035522067229065   7: 0.035521495066410   9: 0.035521191813735   3: 0.035520303067017   8: 0.035519821964716 

training_10586    6: 0.689977783933857   8: 0.178077957515335   0: 0.016497499791844   2: 0.016495664968325   1: 0.016493961287017   5: 0.016492935453278   7: 0.016492644127615   4: 0.016490642522626   9: 0.016490580231474   3: 0.016490330168627 

training_10587    4: 0.555490576983513   0: 0.167807564088401   1: 0.034589577336222   6: 0.034589160385987   5: 0.034588277479221   2: 0.034587490986401   3: 0.034586963100304   9: 0.034586845567981   8: 0.034586805013373   7: 0.034586739058597 

training_10588    0: 0.475732319775512   6: 0.317437158300786   7: 0.069014173529347   1: 0.062464449357452   3: 0.012563944594837   9: 0.012561384666808   2: 0.012560731493174   5: 0.012556194160251   4: 0.012554872068044   8: 0.012554772053789 

training_1059     5: 0.567845905412049   4: 0.171827992845754   1: 0.099600718032012   8: 0.061274161849572   6: 0.016577260989342   0: 0.016576623439588   9: 0.016574614666198   2: 0.016574299014752   3: 0.016574256395571   7: 0.016574167355163 

training_10590    6: 0.525148136992274   8: 0.308421982850974   1: 0.020804901658780   5: 0.020804420552330   0: 0.020804261324920   9: 0.020804167111216   4: 0.020804020819503   3: 0.020802749896169   2: 0.020802740803647   7: 0.020802617990187 

training_10592    8: 0.766962052805729   6: 0.025900665779609   9: 0.025895180235729   5: 0.025893129253374   1: 0.025892836832559   7: 0.025892518686272   0: 0.025891552408329   4: 0.025890986223120   3: 0.025890664325160   2: 0.025890413450117 

training_10593    6: 0.432755996182798   1: 0.199104289308880   8: 0.158971637690109   9: 0.138130992538466   5: 0.013648605044871   0: 0.011903599387196   7: 0.011443159102635   2: 0.011423751846416   3: 0.011309192197096   4: 0.011308776701534 

training_10594    6: 0.852539839917375   8: 0.016389903951191   5: 0.016385227772289   9: 0.016384819826702   7: 0.016383856656005   0: 0.016383648901122   4: 0.016383636832781   1: 0.016383538298134   2: 0.016382845457471   3: 0.016382682386929 

training_10596    5: 0.349628330415125   6: 0.213275724349968   3: 0.196210215383763   4: 0.115879160403213   1: 0.020890994659967   9: 0.020827619802424   0: 0.020827149421237   8: 0.020821290563509   7: 0.020820329484830   2: 0.020819185515965 

training_10597    4: 0.614057721303520   8: 0.161177593658642   5: 0.028104341675529   6: 0.028096911790123   0: 0.028095041219026   9: 0.028094044911234   1: 0.028093786284481   7: 0.028093570302067   3: 0.028093568639757   2: 0.028093420215620 

training_10598    5: 0.487567282642436   7: 0.348021810743143   4: 0.020558106813046   6: 0.020550850612335   0: 0.020550477204108   8: 0.020550435532260   1: 0.020550351885934   9: 0.020550309693133   2: 0.020550199772220   3: 0.020550175101386 

training_10599    4: 0.809071462736280   1: 0.021222198267266   5: 0.021221605532652   0: 0.021216221707918   8: 0.021212555237102   6: 0.021211998659756   9: 0.021211342791331   2: 0.021210948095242   7: 0.021210883879803   3: 0.021210783092652 

training_106      0: 0.723940180062037   6: 0.030689762560628   8: 0.030675959058010   7: 0.030672432047875   1: 0.030670915726355   2: 0.030670397636691   9: 0.030670374910431   3: 0.030670272864793   5: 0.030670038403070   4: 0.030669666730111 

training_10600    5: 0.519576732900991   7: 0.290762054623023   0: 0.047061370471045   1: 0.020435674376213   6: 0.020371535486537   8: 0.020365248896007   4: 0.020360872881094   3: 0.020358245817485   9: 0.020354470832479   2: 0.020353793715126 

training_10601    4: 0.743160043922068   6: 0.089997783774238   5: 0.020861786154952   7: 0.020855451781893   1: 0.020854594007353   0: 0.020854393561997   8: 0.020854093663800   9: 0.020854009557251   3: 0.020853945435545   2: 0.020853898140903 

training_10602    7: 0.493849418147724   5: 0.305413590916399   1: 0.025105838983836   6: 0.025099240506462   0: 0.025091519238937   9: 0.025090418485806   8: 0.025089687265856   4: 0.025088846878703   3: 0.025085841747852   2: 0.025085597828426 

training_10604    6: 0.699115144472287   7: 0.126898718682537   0: 0.054143113049787   5: 0.017125558436080   9: 0.017122432804352   8: 0.017120373684331   1: 0.017119528055430   4: 0.017118780553670   3: 0.017118703786417   2: 0.017117646475110 

training_10606    6: 0.577195302926667   0: 0.292281511413430   5: 0.035334888178427   3: 0.021067391101669   8: 0.019282861669116   9: 0.010985847723650   1: 0.010964111280405   2: 0.010962804815827   7: 0.010962689668560   4: 0.010962591222249 

training_10608    1: 0.431520128373426   6: 0.355433969090892   9: 0.079680492364534   0: 0.044566037879819   3: 0.033995619442668   7: 0.010963343876370   5: 0.010960594386273   8: 0.010960066733530   4: 0.010959944078072   2: 0.010959803774415 

training_10609    5: 0.468330259696003   3: 0.336604748851188   6: 0.024387875484695   0: 0.024385720776465   8: 0.024385110644627   4: 0.024382980972453   1: 0.024381541830684   2: 0.024380622253103   9: 0.024380572451204   7: 0.024380567039580 

training_10610    5: 0.459309747834537   3: 0.246383744185923   6: 0.125002586557200   1: 0.024192944271608   0: 0.024187249777562   9: 0.024185898473546   4: 0.024185303431292   8: 0.024185272504430   7: 0.024183645118756   2: 0.024183607845146 

training_10611    5: 0.364033424792364   3: 0.334235591873976   6: 0.132216653400285   4: 0.024218526945314   1: 0.024217118178191   0: 0.024216488127448   8: 0.024216480710542   9: 0.024215411770795   7: 0.024215210181788   2: 0.024215094019298 

training_10612    5: 0.720542345806809   9: 0.121886068987022   0: 0.019710165663096   7: 0.019707157818220   6: 0.019700842921006   4: 0.019692101200275   8: 0.019691126421766   3: 0.019690969843946   1: 0.019690220395693   2: 0.019689000942167 

training_10613    6: 0.499961625532855   8: 0.303873187449145   3: 0.054396715573337   1: 0.020255592376246   2: 0.020252849995563   5: 0.020252768019625   0: 0.020252560587878   9: 0.020251702861929   7: 0.020251514181020   4: 0.020251483422403 

training_10615    6: 0.511778699740954   7: 0.345348358536422   0: 0.017873961903079   9: 0.017866611903452   8: 0.017856838500936   1: 0.017856453689662   5: 0.017856322233542   2: 0.017854787663992   3: 0.017854131152454   4: 0.017853834675506 

training_10616    9: 0.500124209984343   6: 0.376264411764073   0: 0.015555518023519   7: 0.015448942349230   5: 0.015444647831174   1: 0.015434381180817   2: 0.015433024020486   3: 0.015432129047216   8: 0.015431725122013   4: 0.015431010677130 

training_10617    6: 0.812422804085676   0: 0.097665061085210   1: 0.022662794159749   5: 0.011165148562647   2: 0.010158817862201   7: 0.009236638692380   8: 0.009172341864380   3: 0.009172179894405   9: 0.009172178086318   4: 0.009172035707035 

training_10618    6: 0.617084302801036   7: 0.243516525058986   0: 0.034595519969504   1: 0.024524220237662   8: 0.013386892602658   5: 0.013380428616468   9: 0.013378646887512   2: 0.013378109289045   3: 0.013377845531790   4: 0.013377509005339 

training_10619    6: 0.683602147957222   8: 0.092150947729411   1: 0.079542166373373   7: 0.020675891962639   5: 0.020672574905183   0: 0.020671949440276   2: 0.020671327807031   9: 0.020671125623628   4: 0.020671003567527   3: 0.020670864633710 

training_10620    0: 0.490271994423331   6: 0.262064943022172   1: 0.143571291319412   7: 0.014884246055445   3: 0.014878595322083   9: 0.014869224547217   8: 0.014865410161769   2: 0.014864945245450   5: 0.014864801710143   4: 0.014864548192977 

training_10621    6: 0.416428076656967   0: 0.416368301268038   1: 0.051134763480345   8: 0.034915817812641   5: 0.026962298229289   3: 0.010841336316802   9: 0.010839068533705   7: 0.010837247981731   2: 0.010836836288723   4: 0.010836253431760 

training_10622    0: 0.466059964359432   6: 0.321307622783635   4: 0.068796394441946   5: 0.040908727083181   7: 0.033502090512157   1: 0.013895766832168   9: 0.013883264571167   2: 0.013883196128144   8: 0.013881739870096   3: 0.013881233418075 

training_10623    6: 0.646327498782020   1: 0.145124115608046   9: 0.110277468743720   5: 0.027455281861611   3: 0.019954115337824   0: 0.014519208916658   8: 0.009090535915103   2: 0.009084029888026   7: 0.009083912267512   4: 0.009083832679480 

training_10625    2: 0.409576934330067   6: 0.405946519108799   0: 0.023120775272334   1: 0.023063594402056   5: 0.023054195896229   4: 0.023048632062295   8: 0.023047985350130   9: 0.023047527309939   7: 0.023047153036978   3: 0.023046683231173 

training_10627    0: 0.507835803093922   6: 0.374992091085352   8: 0.034604121250873   3: 0.022693980222176   7: 0.010102231907521   9: 0.010017203177961   5: 0.009946118538957   1: 0.009943534298690   2: 0.009932576381294   4: 0.009932340043254 

training_1063     5: 0.819815648846018   1: 0.020025299725205   0: 0.020023535844339   4: 0.020020305031952   6: 0.020019860522506   9: 0.020019312442736   8: 0.020019146561708   2: 0.020019143035416   7: 0.020018898873903   3: 0.020018849116217 

training_10632    6: 0.717118952307590   4: 0.095943964630399   0: 0.077565758603608   3: 0.033857644430612   1: 0.012631276706497   7: 0.012586874500975   5: 0.012575076819465   9: 0.012573993663228   8: 0.012573345799211   2: 0.012573112538416 

training_10633    6: 0.659403231024654   0: 0.216090880624384   3: 0.031564261859561   8: 0.021234312864773   7: 0.011968442686887   1: 0.011948592626888   5: 0.011948337405573   9: 0.011947470438477   2: 0.011947239806817   4: 0.011947230661986 

training_10634    6: 0.481785182358501   0: 0.323620115585442   4: 0.063556699695537   7: 0.018734139758364   5: 0.018720091044914   8: 0.018718309329264   1: 0.018717128615810   9: 0.018716282530382   2: 0.018716061513153   3: 0.018715989568632 

training_10636    6: 0.825630353920060   9: 0.036942596146311   1: 0.017269776730797   8: 0.017244146373897   0: 0.017210452901272   7: 0.017200001739975   4: 0.017129393198622   5: 0.017125386852564   2: 0.017123954109935   3: 0.017123938026567 

training_10638    3: 0.484667679167007   6: 0.271601790571560   1: 0.153899453578042   0: 0.012921986793655   7: 0.012879807754082   4: 0.012811353793390   5: 0.012805180682653   8: 0.012804833906707   9: 0.012804002784530   2: 0.012803910968375 

training_10640    6: 0.780178325903008   0: 0.049196979744338   5: 0.037097992638096   7: 0.033300900388833   1: 0.023181762007144   8: 0.023134701617305   3: 0.013578653007754   9: 0.013467425317710   4: 0.013431684614448   2: 0.013431574761365 

training_10641    0: 0.503440007534669   6: 0.343257435283652   7: 0.049741920811837   1: 0.033149552505089   3: 0.011779059258367   8: 0.011776614679138   9: 0.011714953569531   5: 0.011713910636588   2: 0.011713513752361   4: 0.011713031968767 

training_10642    6: 0.486673772990241   1: 0.325130993143237   9: 0.106573493842217   3: 0.020894817243652   5: 0.010159360189605   0: 0.010122527516521   2: 0.010113666665741   7: 0.010112249128757   8: 0.010110042984452   4: 0.010109076295578 

training_10643    6: 0.779841077648465   0: 0.097134213406917   3: 0.036731177850609   1: 0.030637796674565   9: 0.009276527355074   5: 0.009276153017955   8: 0.009275908554647   4: 0.009275790454593   2: 0.009275726960202   7: 0.009275628076974 

training_10644    5: 0.466503824661617   6: 0.381825645179042   0: 0.029266536448079   7: 0.017543272421878   9: 0.017484098493811   1: 0.017480471708659   8: 0.017474463170079   4: 0.017474264564025   3: 0.017473930095583   2: 0.017473493257226 

training_10648    6: 0.527337293094589   5: 0.365079762620188   2: 0.018511684748500   0: 0.012955485603218   1: 0.012723016506958   4: 0.012683303607158   3: 0.012682911326712   8: 0.012675630166277   9: 0.012675488313923   7: 0.012675424012476 

training_1065     5: 0.654603486201113   0: 0.152950246404606   4: 0.024056368486430   3: 0.024056199304987   1: 0.024055869738617   6: 0.024055753069231   2: 0.024055579228710   7: 0.024055516858033   8: 0.024055502668652   9: 0.024055478039621 

training_10650    1: 0.749645397897660   5: 0.027859453012863   6: 0.027822399657428   3: 0.027815949138214   0: 0.027812318133403   8: 0.027810010332231   7: 0.027809891410975   9: 0.027808600134281   4: 0.027808271992720   2: 0.027807708290225 

training_10651    1: 0.580925116914305   7: 0.200526720498318   6: 0.027325878936466   8: 0.027320231959616   0: 0.027319147966706   9: 0.027318925786640   5: 0.027316483684866   3: 0.027315961843257   2: 0.027315818279796   4: 0.027315714130032 

training_10652    1: 0.719258901902173   6: 0.031224487639729   9: 0.031197335501900   8: 0.031194937707658   7: 0.031192202012837   0: 0.031191770174550   5: 0.031185440289625   3: 0.031185104806074   2: 0.031184931442215   4: 0.031184888523240 

training_10653    6: 0.753250300717453   8: 0.027421243848904   9: 0.027418050590441   1: 0.027417915728607   5: 0.027416936082321   0: 0.027416922365796   4: 0.027415282653556   7: 0.027415162079459   2: 0.027414289680260   3: 0.027413896253204 

training_10654    6: 0.678550825783727   1: 0.193786996068850   0: 0.015961724850630   5: 0.015958578238607   8: 0.015957748586745   9: 0.015957159773660   4: 0.015956934653373   3: 0.015956823116996   2: 0.015956640834727   7: 0.015956568092686 

training_10657    6: 0.418710590590828   1: 0.321092597529709   0: 0.032526931324208   9: 0.032525516734732   8: 0.032525303063249   7: 0.032524851525754   5: 0.032524186293247   4: 0.032523415215354   3: 0.032523315169223   2: 0.032523292553694 

training_10658    1: 0.448941665538562   6: 0.323606366630497   0: 0.028440495920204   5: 0.028432978012285   4: 0.028432429738845   8: 0.028430215470995   9: 0.028429121980941   2: 0.028429103120009   7: 0.028429097385825   3: 0.028428526201837 

training_10659    6: 0.543746506939543   1: 0.261968418975403   7: 0.071297186729712   0: 0.041842283979056   9: 0.013525980188609   5: 0.013525342824361   8: 0.013523921666648   3: 0.013523729411400   4: 0.013523331467353   2: 0.013523297817916 

training_1066     3: 0.427297170305993   5: 0.259530585242125   0: 0.142151207762825   2: 0.024433031491458   4: 0.024432340252896   9: 0.024431960409296   6: 0.024431568502865   1: 0.024431122285949   7: 0.024430601558422   8: 0.024430412188171 

training_10660    6: 0.838006000514055   9: 0.046730742140185   5: 0.014473267485956   1: 0.014403795717407   8: 0.014402724530304   0: 0.014398197227679   3: 0.014398156453669   2: 0.014396222285252   4: 0.014395499420585   7: 0.014395394224908 

training_10661    6: 0.532180900679129   0: 0.209131226076380   1: 0.123671181406035   5: 0.054949470372582   2: 0.013405170831787   9: 0.013333262059002   8: 0.013333081690598   7: 0.013332034700185   3: 0.013331902615425   4: 0.013331769568876 

training_10662    6: 0.714834950708540   0: 0.110931017415396   4: 0.070845436128973   3: 0.014798133292996   9: 0.014768436470596   5: 0.014766901389784   1: 0.014763959584509   2: 0.014763785139509   7: 0.014763761327654   8: 0.014763618542044 

training_10665    6: 0.605195148645758   1: 0.263643169054711   0: 0.041800834398198   5: 0.012766833738604   4: 0.012765816135052   8: 0.012765807477722   9: 0.012765715814269   7: 0.012765588816586   3: 0.012765582409254   2: 0.012765503509845 

training_10669    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_1067     6: 0.823859566939943   1: 0.050039690145971   8: 0.015764425677466   5: 0.015763132492873   7: 0.015762727040314   9: 0.015762510571738   0: 0.015762205553897   4: 0.015762091984710   3: 0.015761849702788   2: 0.015761799890300 

training_10674    3: 0.282492506052774   6: 0.247943589164131   4: 0.205713460168270   0: 0.144570839400283   2: 0.029661622949022   1: 0.018002092969752   7: 0.017914725228672   5: 0.017906520379323   9: 0.017897607591886   8: 0.017897036095887 

training_10676    1: 0.514056645665603   6: 0.302309485367883   2: 0.088926788253093   0: 0.020303505062068   9: 0.012516004767354   5: 0.012381761795450   8: 0.012377062520444   4: 0.012376531494881   7: 0.012376337167037   3: 0.012375877906188 

training_10678    6: 0.360941398805912   0: 0.287047717971018   1: 0.210263497285039   5: 0.020251893427946   3: 0.020250675661792   9: 0.020249633621751   7: 0.020249338087422   2: 0.020248791073854   4: 0.020248556581432   8: 0.020248497483833 

training_10679    6: 0.759054913568506   1: 0.026775103554449   9: 0.026773368164461   5: 0.026771974123965   0: 0.026771957135914   4: 0.026771694911230   8: 0.026770513351979   7: 0.026770289728822   2: 0.026770269607606   3: 0.026769915853069 

training_1068     6: 0.860962070338852   5: 0.015451225425928   0: 0.015450264640925   9: 0.015450220490246   4: 0.015448578125915   1: 0.015448549442722   7: 0.015447773458525   8: 0.015447384560830   2: 0.015447005161578   3: 0.015446928354477 

training_10681    6: 0.605636222901830   0: 0.178263036171856   3: 0.027017732489589   5: 0.027012412924252   8: 0.027012303076063   7: 0.027012058073884   9: 0.027011985304137   4: 0.027011890958052   1: 0.027011725870219   2: 0.027010632230118 

training_10682    7: 0.798363398877302   2: 0.022425511541360   6: 0.022417898075670   1: 0.022408288408036   0: 0.022403545629253   5: 0.022401230211621   8: 0.022397152361756   4: 0.022395507901929   9: 0.022394336044544   3: 0.022393130948530 

training_10684    6: 0.824129393644579   0: 0.052183101575377   1: 0.028513359252377   3: 0.013598561348988   7: 0.013597961151155   9: 0.013597152715443   5: 0.013595344097567   2: 0.013595123645015   8: 0.013595041047379   4: 0.013594961522121 

training_10685    9: 0.575285645700693   0: 0.189292699341835   4: 0.029436033432128   6: 0.029435399661843   5: 0.029434677902813   1: 0.029426768127917   8: 0.029423945295382   3: 0.029422485550029   7: 0.029421318741025   2: 0.029421026246336 

training_10687    6: 0.558741144325565   0: 0.269093965326389   8: 0.063091860332443   5: 0.026127905293802   1: 0.013824302591968   9: 0.013824266219744   7: 0.013824262575363   2: 0.013824223182932   3: 0.013824103894758   4: 0.013823966257038 

training_10688    5: 0.415226291190752   6: 0.339707338801774   9: 0.078255313674061   1: 0.023836754927024   0: 0.023834035534627   3: 0.023833137158257   8: 0.023829622400386   4: 0.023826345743653   2: 0.023825903536642   7: 0.023825257032823 

training_10689    6: 0.692321849005072   1: 0.182756556845399   0: 0.053240778748791   9: 0.020863662668424   5: 0.010302005053501   4: 0.008186054360552   3: 0.008100557738076   8: 0.008100265621812   2: 0.008073540753553   7: 0.008054729204819 

training_1069     6: 0.619747311017552   1: 0.158656904978010   0: 0.110828502170130   5: 0.015826045119899   8: 0.015824382339547   2: 0.015823624816342   9: 0.015823418986830   7: 0.015823358290398   3: 0.015823305514359   4: 0.015823146766934 

training_10692    0: 0.520807782795441   4: 0.238771138474866   9: 0.030114586580898   8: 0.030082049895197   3: 0.030042771002495   5: 0.030041286735314   6: 0.030041051296825   1: 0.030039276821845   2: 0.030030241990688   7: 0.030029814406432 

training_10693    6: 0.772897846752466   0: 0.096052249148502   7: 0.045263996125446   9: 0.019002310200017   3: 0.018496594442164   1: 0.009669845696829   4: 0.009660276306957   5: 0.009654924526223   8: 0.009654638665866   2: 0.009647318135530 

training_10694    0: 0.694858196548253   4: 0.158669199718718   8: 0.027204695420602   9: 0.017223914426492   1: 0.017138706930033   6: 0.017116146244924   5: 0.016950712698879   3: 0.016947134055079   7: 0.016945653840421   2: 0.016945640116599 

training_10695    6: 0.548671103567137   0: 0.213073468121058   1: 0.104910021659244   9: 0.075571275685611   4: 0.009631723513792   3: 0.009630093126206   5: 0.009628773970462   8: 0.009627992492992   7: 0.009627833204797   2: 0.009627714658703 

training_10696    6: 0.670300777657684   0: 0.139498842860504   9: 0.090386630831462   1: 0.028135368503409   3: 0.012042599066185   8: 0.011940769833486   5: 0.011924662706704   7: 0.011923533666204   2: 0.011923476508117   4: 0.011923338366246 

training_10699    1: 0.559871155651148   5: 0.273412344228261   6: 0.020860653520953   7: 0.020840427195857   0: 0.020838184702601   9: 0.020836704054727   8: 0.020836207156294   4: 0.020835097973992   3: 0.020834725571864   2: 0.020834499944302 

training_1070     8: 0.415170455236764   5: 0.382694398259688   4: 0.025273296017804   9: 0.025266233729457   3: 0.025266197621145   2: 0.025266005856131   6: 0.025265934257665   7: 0.025265896272966   0: 0.025265840693081   1: 0.025265742055299 

training_10701    6: 0.662278934030900   0: 0.157536217931134   1: 0.077831670290276   9: 0.029620950349512   5: 0.012123937653916   8: 0.012123917072673   7: 0.012121511390249   2: 0.012121107901191   4: 0.012121041289253   3: 0.012120712090897 

training_10702    6: 0.500408222487088   0: 0.365405361089056   1: 0.032786319096940   5: 0.014488096166172   4: 0.014487706069704   9: 0.014485282950411   8: 0.014484974270793   7: 0.014484709598325   3: 0.014484676933303   2: 0.014484651338208 

training_10703    6: 0.589876347465086   1: 0.163873480288103   9: 0.137499610895523   0: 0.036328707872925   3: 0.012093242510600   5: 0.012072066799532   4: 0.012071013092911   2: 0.012062058140730   8: 0.012061915936430   7: 0.012061556998160 

training_10704    6: 0.680573085189538   0: 0.123147323939686   7: 0.091043017077586   9: 0.034100426063235   1: 0.011865834729547   8: 0.011862309381142   3: 0.011853428620689   5: 0.011852632002331   4: 0.011851014303124   2: 0.011850928693122 

training_10705    6: 0.692232090956157   7: 0.099546577280071   3: 0.090183265008182   8: 0.016873006115129   4: 0.016862645499836   5: 0.016862056099175   0: 0.016860574264866   1: 0.016860493566866   9: 0.016859652927208   2: 0.016859638282509 

training_10708    6: 0.454644073720465   9: 0.392824858373837   5: 0.019069151552452   7: 0.019067709366720   0: 0.019067024658617   8: 0.019066876813139   4: 0.019065707804731   1: 0.019065319362329   2: 0.019064666093107   3: 0.019064612254604 

training_10709    6: 0.432569491047253   9: 0.401945434188897   7: 0.041236826372559   8: 0.017788401316809   5: 0.017747114573000   1: 0.017745316419275   0: 0.017743096806517   3: 0.017742053999088   2: 0.017741261208182   4: 0.017741004068420 

training_1071     5: 0.502044952290633   2: 0.324049283083241   8: 0.021746207412407   1: 0.021738254284019   0: 0.021737318962557   6: 0.021737100024225   3: 0.021737035684511   9: 0.021736795659129   4: 0.021736675299240   7: 0.021736377300039 

training_10710    9: 0.824973607536487   6: 0.043395348203951   0: 0.016591365745464   8: 0.016438050999851   7: 0.016434756949293   5: 0.016434053430437   1: 0.016434013889194   4: 0.016433270465088   2: 0.016432807613833   3: 0.016432725166403 

training_10712    6: 0.701018023935609   1: 0.116210106703401   3: 0.064057655688384   5: 0.016976419437481   4: 0.016956783556165   0: 0.016956709548086   7: 0.016956205634477   8: 0.016956204573021   9: 0.016956016058917   2: 0.016955874864460 

training_10714    1: 0.641853414355974   6: 0.162374697348958   5: 0.024481107592548   4: 0.024472676683801   9: 0.024472084139967   3: 0.024470960154890   8: 0.024469945719480   0: 0.024469882248973   7: 0.024467677639863   2: 0.024467554115547 

training_10715    1: 0.807393654236355   3: 0.036499041788541   0: 0.032756213051835   9: 0.017828700232178   5: 0.017599538262625   2: 0.017595899711014   6: 0.017592936893730   4: 0.017581826680840   8: 0.017576285709945   7: 0.017575903432937 

training_10717    6: 0.750893609568696   1: 0.057044253972719   3: 0.051741788284264   8: 0.042504119427889   7: 0.027973242487125   0: 0.022196213913434   5: 0.011915290111453   4: 0.011913246883861   9: 0.011909589282851   2: 0.011908646067708 

training_10718    6: 0.680812312795319   9: 0.153018311457809   0: 0.064220513480871   8: 0.014566698681162   3: 0.014565313447009   1: 0.014563917221773   7: 0.014563616060743   5: 0.014563381988521   2: 0.014563102105359   4: 0.014562832761433 

training_1072     4: 0.445832948636690   6: 0.242857885926924   2: 0.175352399145410   0: 0.019423817110891   5: 0.019423339892044   9: 0.019423052449828   1: 0.019422400804074   7: 0.019422126257629   8: 0.019421363257558   3: 0.019420666518951 

training_10720    6: 0.844948980701532   1: 0.028733529227078   8: 0.027094028781480   9: 0.014200867679487   5: 0.014196861801893   0: 0.014165856860160   4: 0.014165316519588   2: 0.014164938314854   7: 0.014164821372348   3: 0.014164798741581 

training_10721    5: 0.518782930005870   6: 0.233258337096192   2: 0.108163888090911   0: 0.030921030819698   4: 0.028289133812427   1: 0.016138823168210   7: 0.016115679944561   9: 0.016110422486181   8: 0.016109960039502   3: 0.016109794536448 

training_10724    6: 0.704193666389921   9: 0.144604915725460   0: 0.018904095873959   1: 0.018903027609559   5: 0.018899795299413   7: 0.018899538323775   8: 0.018899265154627   3: 0.018898714191440   2: 0.018898503938246   4: 0.018898477493599 

training_10729    7: 0.585628499330874   6: 0.239376546564771   0: 0.077713774022510   4: 0.022589028311269   8: 0.012513073840959   9: 0.012439696088498   5: 0.012439590463510   3: 0.012433888422369   1: 0.012433827821309   2: 0.012432075133931 

training_10731    6: 0.405177686716682   0: 0.332987241384131   5: 0.032733858911631   1: 0.032730529894520   8: 0.032729589538414   9: 0.032728892174165   7: 0.032728725433652   3: 0.032727862356781   4: 0.032727844088722   2: 0.032727769501302 

training_10734    6: 0.458332004267696   1: 0.377776614213288   7: 0.075278245272369   2: 0.012664450308632   5: 0.012662368833816   0: 0.012658021459415   9: 0.012657675175869   8: 0.012657281609309   4: 0.012656745851694   3: 0.012656593007911 

training_10736    6: 0.758524536238262   0: 0.108472570428218   5: 0.016628260978002   1: 0.016626324690472   3: 0.016625668960154   9: 0.016625086116324   7: 0.016624532312409   8: 0.016624519460644   2: 0.016624273930792   4: 0.016624226884722 

training_10737    6: 0.651987886242179   8: 0.214291709778378   1: 0.034354839728922   9: 0.014203603846004   7: 0.014196812575731   5: 0.014195664078573   0: 0.014194910660044   4: 0.014191830810851   3: 0.014191539330694   2: 0.014191202948623 

training_10738    0: 0.472657402054274   6: 0.353275282617105   2: 0.058256072284390   5: 0.016841756291681   7: 0.016506082582815   9: 0.016495403463812   8: 0.016493902459892   1: 0.016493069748526   4: 0.016491103741569   3: 0.016489924755937 

training_1074     6: 0.797499568226401   1: 0.022508056394323   5: 0.022503499946545   0: 0.022500459654161   4: 0.022500172130010   9: 0.022498386110718   2: 0.022497884937727   3: 0.022497428835013   7: 0.022497284828903   8: 0.022497258936199 

training_10742    6: 0.830447318918960   1: 0.045689186974897   7: 0.015490842680690   5: 0.015482874411344   0: 0.015482181527290   8: 0.015481930525609   4: 0.015481530854782   2: 0.015481458299686   9: 0.015481339586294   3: 0.015481336220448 

training_10743    6: 0.417934030628536   1: 0.289841793496538   9: 0.140149140222444   0: 0.079022485310347   5: 0.012178963713976   3: 0.012178356095844   4: 0.012174216402761   7: 0.012173870520210   2: 0.012173653417731   8: 0.012173490191613 

training_10744    0: 0.395167175840521   6: 0.242486057573891   2: 0.205243418635563   5: 0.062206805650108   1: 0.015819474974359   3: 0.015818137944725   8: 0.015815165897747   9: 0.015814816606734   4: 0.015814522521768   7: 0.015814424354584 

training_10746    6: 0.575199298690641   9: 0.253440067136628   0: 0.051025588822812   1: 0.017222945192533   5: 0.017200325527145   7: 0.017195103516434   8: 0.017186959434464   3: 0.017177881088816   4: 0.017176986683912   2: 0.017174843906617 

training_10748    1: 0.575742489666301   6: 0.242650603383373   0: 0.049713219561427   9: 0.049076519629512   3: 0.020902721001187   4: 0.020422496430999   5: 0.010376244832269   2: 0.010372441849484   8: 0.010372003958590   7: 0.010371259686857 

training_10749    6: 0.628086840411043   1: 0.234256044095743   0: 0.037955609872521   3: 0.014257293847862   9: 0.014242326809678   5: 0.014241501412909   2: 0.014240887061998   4: 0.014240146813063   8: 0.014239753889176   7: 0.014239595786008 

training_10750    9: 0.480656509941636   6: 0.335990556744769   8: 0.076284672697419   1: 0.015318685178381   0: 0.015317513388623   2: 0.015291971972161   5: 0.015290703391835   3: 0.015287678777088   7: 0.015280906238063   4: 0.015280801670025 

training_10751    6: 0.717412595062709   1: 0.143825973704143   0: 0.038120587504789   7: 0.014380297238405   9: 0.014379140278815   8: 0.014376736508096   5: 0.014376424591076   2: 0.014376107416375   4: 0.014376071702913   3: 0.014376065992680 

training_10752    6: 0.656109176179408   0: 0.109821930721031   5: 0.093971344876359   1: 0.048394311379552   8: 0.015368213096980   3: 0.015292896598440   7: 0.015273116510940   9: 0.015258910794817   2: 0.015257062086689   4: 0.015253037755785 

training_10754    6: 0.658772731114390   9: 0.156948371534645   1: 0.043015652969507   5: 0.033904318087710   0: 0.017931717624061   4: 0.017910964577027   8: 0.017903151012101   7: 0.017874735219687   2: 0.017870987960949   3: 0.017867369899923 

training_10755    9: 0.552943931736025   6: 0.286197974923948   1: 0.020109165068996   8: 0.020108834883022   5: 0.020107993139348   0: 0.020107970528829   4: 0.020106340924365   7: 0.020106028333363   2: 0.020105881756778   3: 0.020105878705325 

training_10756    6: 0.633579858462726   1: 0.206591356123428   9: 0.036030774139206   8: 0.017701013145672   7: 0.017693065526290   0: 0.017684469998297   5: 0.017682794168476   4: 0.017679028700917   3: 0.017678860285275   2: 0.017678779449713 

training_10757    6: 0.511099060854937   9: 0.288446060305335   8: 0.071220925228236   1: 0.018471780199060   0: 0.018466375643446   5: 0.018460288891234   7: 0.018459730393896   4: 0.018459073790213   2: 0.018458496772762   3: 0.018458207920882 

training_10758    6: 0.498386460904705   3: 0.208107713387769   0: 0.121307080403059   8: 0.058495500907618   5: 0.018951738264544   7: 0.018950862034771   2: 0.018950633919128   1: 0.018950182418709   9: 0.018950121975300   4: 0.018949705784399 

training_1076     6: 0.766949447694605   1: 0.089881586385083   3: 0.030048202842589   8: 0.027531285218955   7: 0.014397707839547   0: 0.014244836271073   9: 0.014237993334885   5: 0.014237380124728   2: 0.014235793521895   4: 0.014235766766638 

training_10760    6: 0.827122261237128   0: 0.050737313544530   8: 0.030328882181551   1: 0.025303655430293   4: 0.011088578535136   2: 0.011085741488890   3: 0.011083696690036   7: 0.011083505297707   9: 0.011083438718154   5: 0.011082926876575 

training_10762    6: 0.824158742899890   0: 0.052155003772413   1: 0.028512028488271   3: 0.013598606583888   7: 0.013597977239300   9: 0.013597167892106   5: 0.013595344091421   2: 0.013595126562571   8: 0.013595040980501   4: 0.013594961489639 

training_10766    6: 0.758459772637252   0: 0.108537350992502   5: 0.016628251326899   1: 0.016626324377817   3: 0.016625663636999   9: 0.016625084593260   7: 0.016624532411041   8: 0.016624519563781   2: 0.016624273577599   4: 0.016624226882851 

training_10767    6: 0.605717097836337   1: 0.176413764448700   9: 0.124072171053338   3: 0.024869656577175   8: 0.011502509400253   0: 0.011486223913999   5: 0.011485807899900   4: 0.011484407694733   7: 0.011484387319103   2: 0.011483973856465 

training_10768    6: 0.437820577784989   7: 0.400455035282323   4: 0.046104933056760   0: 0.024431896189928   1: 0.015275554200406   8: 0.015192351810816   9: 0.015191763279729   5: 0.015180185221720   2: 0.015174175602867   3: 0.015173527570461 

training_10769    6: 0.543727332671907   1: 0.261916337746197   7: 0.070925213108866   0: 0.042285484388195   9: 0.013526007328493   5: 0.013525338648770   8: 0.013523921679030   3: 0.013523735291080   4: 0.013523331352194   2: 0.013523297785267 

training_1077     6: 0.646913985203226   5: 0.192542083709777   8: 0.036302860871253   1: 0.031622048057094   3: 0.015937253751693   0: 0.015507243555575   7: 0.015301494668114   9: 0.015300608457348   2: 0.015288197291610   4: 0.015284224434309 

training_10770    6: 0.830794644879554   9: 0.047467891152387   5: 0.015279488569969   8: 0.015212319137117   1: 0.015211002945362   0: 0.015209881781800   4: 0.015206351052666   2: 0.015206216464606   3: 0.015206170226945   7: 0.015206033789593 

training_10771    6: 0.692336561733791   1: 0.182926386057001   0: 0.053053267795172   9: 0.020866695696961   5: 0.010301912063014   4: 0.008186029039894   3: 0.008100583788085   8: 0.008100292608187   2: 0.008073541119431   7: 0.008054730098464 

training_10773    6: 0.458408601917064   1: 0.377701537807299   7: 0.075276744800467   2: 0.012664451957839   5: 0.012662347954163   0: 0.012658020191020   9: 0.012657674819449   8: 0.012657281712286   4: 0.012656745818055   3: 0.012656593022359 

training_10774    6: 0.532438576143197   0: 0.208786867291567   1: 0.123855360493469   5: 0.054842828023853   2: 0.013414316890149   9: 0.013333262056316   8: 0.013333081622810   7: 0.013332034812915   3: 0.013331902884156   4: 0.013331769781568 

training_10779    6: 0.481699218960981   1: 0.329102599253454   9: 0.107278449595844   3: 0.020995158365550   5: 0.010192563128112   0: 0.010155411257925   2: 0.010146556683811   7: 0.010145140322681   8: 0.010142937927539   4: 0.010141964504104 

training_1078     8: 0.502266768586113   6: 0.373638439634437   0: 0.015513981280959   9: 0.015513939090436   5: 0.015512893151616   1: 0.015512214952915   4: 0.015511028648427   2: 0.015510430852855   7: 0.015510288155799   3: 0.015510015646443 

training_10780    6: 0.806186762412793   1: 0.124086223270094   0: 0.018080923112522   3: 0.007846210841137   9: 0.007308954236659   7: 0.007301086314770   5: 0.007298163319692   8: 0.007297609738183   2: 0.007297079673315   4: 0.007296987080835 

training_10781    6: 0.605064042900302   1: 0.264002299523593   0: 0.041572810283472   5: 0.012766833243833   4: 0.012765816161690   8: 0.012765807416784   9: 0.012765715667451   7: 0.012765588850058   3: 0.012765582412009   2: 0.012765503540809 

training_10782    6: 0.650440873350226   0: 0.225187773875202   5: 0.015549576002501   1: 0.015549508871868   7: 0.015548624168289   8: 0.015545431688518   9: 0.015544835276518   3: 0.015544673268800   4: 0.015544571302052   2: 0.015544132196027 

training_10784    1: 0.599198734259910   6: 0.252692693473992   2: 0.058459190098347   0: 0.018613901538223   9: 0.011942022346335   5: 0.011821308614502   3: 0.011818344017640   4: 0.011818111873429   8: 0.011818079477928   7: 0.011817614299694 

training_10786    2: 0.522923193291288   6: 0.276811211386154   0: 0.062865520164049   5: 0.019635971346580   1: 0.019633254528423   8: 0.019627945240193   4: 0.019626936488775   9: 0.019625748362788   7: 0.019625225902036   3: 0.019624993289714 

training_10787    0: 0.722329918106931   7: 0.122745906970129   5: 0.019372981941793   1: 0.019369738587621   6: 0.019365125197545   4: 0.019363942993245   8: 0.019363318692402   3: 0.019363118228035   2: 0.019363040586018   9: 0.019362908696280 

training_10788    2: 0.396494733779074   6: 0.311251883831960   0: 0.178456971747080   1: 0.016261164177973   5: 0.016258879177161   4: 0.016258057982420   8: 0.016256163479894   9: 0.016255077780662   7: 0.016253724540613   3: 0.016253343503163 

training_1079     6: 0.797769700510523   0: 0.056190453538507   5: 0.018257823235981   9: 0.018255445904130   1: 0.018254809062544   4: 0.018254640149875   8: 0.018254531950920   7: 0.018254284361300   3: 0.018254263815801   2: 0.018254047470420 

training_10790    1: 0.799091352716619   0: 0.042071451005185   5: 0.040084334928461   6: 0.017000877990044   9: 0.016959253334068   4: 0.016959014068772   8: 0.016958485399094   2: 0.016958467750014   3: 0.016958460541251   7: 0.016958302266493 

training_10794    5: 0.588698682826153   6: 0.221899384408135   1: 0.046770455936469   3: 0.020378312453121   0: 0.020378124157471   7: 0.020375367469455   9: 0.020375350500792   8: 0.020374871735968   2: 0.020374822583835   4: 0.020374627928601 

training_10796    9: 0.821168915589587   8: 0.019896040046155   1: 0.019872047422325   6: 0.019871851361655   5: 0.019866086360373   0: 0.019865992997309   4: 0.019865063453039   3: 0.019864748542641   7: 0.019864650264983   2: 0.019864603961932 

training_10797    0: 0.548073822606840   6: 0.262949628617453   1: 0.067919982661674   8: 0.046539425463183   4: 0.015814177961070   2: 0.015581143337672   9: 0.010820767725474   7: 0.010816865934835   5: 0.010743589737586   3: 0.010740595954215 

training_108      5: 0.528300057007686   4: 0.176266695726341   0: 0.131557125503683   3: 0.023412390177784   6: 0.023410790715318   8: 0.023410705093038   7: 0.023410700169605   2: 0.023410545954841   1: 0.023410511214868   9: 0.023410478436835 

training_1080     5: 0.628146626736296   0: 0.182695302987068   9: 0.070419539745637   1: 0.030687061366645   6: 0.026631969258799   4: 0.012287458346817   2: 0.012284460881997   8: 0.012282976208515   7: 0.012282418809748   3: 0.012282185658478 

training_10803    7: 0.515130260729370   6: 0.221255765855860   2: 0.113159651651810   3: 0.041071611964347   0: 0.018244455458278   8: 0.018229188426401   5: 0.018228360197877   9: 0.018227885690158   1: 0.018227873457724   4: 0.018224946568177 

training_10804    6: 0.761321279045793   1: 0.076527712038301   0: 0.055203030573765   5: 0.038647659468377   7: 0.011450561210808   8: 0.011371079734706   9: 0.011370386178495   4: 0.011369710769766   3: 0.011369417019389   2: 0.011369163960600 

training_10805    5: 0.431783193422605   8: 0.274988294956429   2: 0.106962856611756   1: 0.062800237343426   6: 0.020596413961263   7: 0.020592892599323   0: 0.020569897937932   4: 0.020568862437393   3: 0.020568854957936   9: 0.020568495771937 

training_10807    6: 0.670209625771728   0: 0.139419156930733   9: 0.090198058803330   1: 0.028495921150168   3: 0.012042738636488   8: 0.011939498691988   5: 0.011924661116410   7: 0.011923530777457   2: 0.011923472903705   4: 0.011923335217992 

training_10808    6: 0.628266908123519   1: 0.234074757050620   0: 0.037956827968389   3: 0.014257292232351   9: 0.014242326555496   5: 0.014241503103184   2: 0.014240887451038   4: 0.014240147616431   8: 0.014239754073452   7: 0.014239595825521 

training_10809    6: 0.469202826384966   0: 0.279544495217008   1: 0.176812761683021   8: 0.010677388882652   5: 0.010629155029609   7: 0.010627226510012   4: 0.010626865382070   9: 0.010626776489101   3: 0.010626263002314   2: 0.010626241419247 

training_10811    6: 0.691297861655593   0: 0.108551735797684   4: 0.099384448163292   5: 0.014424256483364   3: 0.014412495111910   9: 0.014389295060941   8: 0.014385150626973   1: 0.014385047578557   2: 0.014384882210191   7: 0.014384827311496 

training_10815    0: 0.575761628588737   9: 0.177898846739767   1: 0.030808715286897   5: 0.030792158166648   4: 0.030791358204204   6: 0.030790434699655   2: 0.030789530605818   3: 0.030789513572673   8: 0.030789014682752   7: 0.030788799452849 

training_10816    6: 0.579903566684885   3: 0.178740112875995   4: 0.120246091762208   1: 0.017332226623992   5: 0.017305439587369   0: 0.017296781558116   9: 0.017296039067362   2: 0.017294560123361   7: 0.017292651636031   8: 0.017292530080681 

training_10817    5: 0.790134543922863   6: 0.023351349072217   0: 0.023328641845202   9: 0.023314727460128   1: 0.023312852408007   8: 0.023312450664269   7: 0.023312036470755   4: 0.023311233794598   2: 0.023311138422232   3: 0.023311025939728 

training_1082     4: 0.359240015725655   6: 0.271573083795720   2: 0.212490082943892   7: 0.039091841751024   0: 0.019626930637113   5: 0.019596681248888   9: 0.019596190174890   1: 0.019595697871250   8: 0.019595451159851   3: 0.019594024691717 

training_10822    5: 0.811453033848303   0: 0.055903151437847   7: 0.029924933816879   2: 0.014706482971380   6: 0.014681709464799   1: 0.014668725428460   9: 0.014666250989167   8: 0.014666176288517   4: 0.014664829778804   3: 0.014664705975844 

training_10825    6: 0.487916315494178   7: 0.314251784312032   3: 0.068224642989238   0: 0.018561999565231   1: 0.018508827965718   5: 0.018508175404858   8: 0.018507775241819   9: 0.018507718809107   4: 0.018506623357910   2: 0.018506136859908 

training_10826    9: 0.348506902258283   6: 0.305515316259328   5: 0.171156588113935   0: 0.071217858877002   8: 0.026417761927371   1: 0.015521213904423   7: 0.015418018671439   3: 0.015417617312394   4: 0.015415657360946   2: 0.015413065314878 

training_10827    6: 0.849378237513717   0: 0.050637316151143   9: 0.012513419802386   5: 0.012500071784763   4: 0.012496742538332   1: 0.012495901847598   7: 0.012494765468573   3: 0.012494625661151   8: 0.012494574770156   2: 0.012494344462181 

training_10830    6: 0.771689399184320   7: 0.071051372940908   0: 0.060738422609557   1: 0.038477210233460   5: 0.009674546934344   8: 0.009674309853157   2: 0.009673807024329   9: 0.009673741060970   4: 0.009673661795626   3: 0.009673528363329 

training_10831    1: 0.398279686523282   2: 0.320799733727797   6: 0.117024307887209   5: 0.043314576622176   8: 0.020099321269759   0: 0.020099053862008   7: 0.020098264676960   9: 0.020096277509247   4: 0.020094769533131   3: 0.020094008388431 

training_10832    5: 0.506627358678145   6: 0.249490554248927   0: 0.067316737928157   3: 0.065987910731645   1: 0.018430703036265   4: 0.018430295306452   9: 0.018429581026535   8: 0.018429110706173   7: 0.018429011873541   2: 0.018428736464159 

training_10833    9: 0.625522727744923   5: 0.171336939421649   6: 0.025401063329439   0: 0.025394886246322   4: 0.025393845044482   1: 0.025392386532250   7: 0.025390721071421   3: 0.025389287516457   8: 0.025389094979377   2: 0.025389048113679 

training_10834    0: 0.394769768705859   6: 0.261733800286959   4: 0.204768677618222   5: 0.019824381544308   1: 0.019819113222472   9: 0.019817194713645   7: 0.019817183185324   2: 0.019816823212831   3: 0.019816566640406   8: 0.019816490869975 

training_10839    2: 0.386820531676379   5: 0.373539511928839   0: 0.091353751637870   1: 0.021191124749176   4: 0.021187241800794   6: 0.021183929198055   9: 0.021181483243167   8: 0.021181115465415   3: 0.021180659284906   7: 0.021180651015398 

training_1084     5: 0.698262397716349   6: 0.136183547850478   4: 0.035171090113300   0: 0.033894758890785   7: 0.033086000008860   2: 0.012698638520917   9: 0.012677576570588   3: 0.012675592189915   8: 0.012675289864074   1: 0.012675108274733 

training_10840    4: 0.811119241357302   5: 0.039798697116954   2: 0.018755544011361   6: 0.018651680674908   1: 0.018638155951047   9: 0.018626154450736   0: 0.018606998548534   7: 0.018603684755550   8: 0.018602029586723   3: 0.018597813546886 

training_10841    0: 0.756412142134846   8: 0.095507286349838   6: 0.018515339942917   4: 0.018513511674612   5: 0.018512861340208   1: 0.018508476296987   9: 0.018508394425629   7: 0.018507554656801   2: 0.018507362840116   3: 0.018507070338045 

training_10843    1: 0.755842119151418   5: 0.089000577231553   6: 0.043865309081536   0: 0.015902200219474   8: 0.015898806455215   4: 0.015898523198512   2: 0.015898516602423   3: 0.015898036954959   7: 0.015897983842668   9: 0.015897927262241 

training_10844    9: 0.506823895285887   5: 0.287740895073301   1: 0.025684050175949   6: 0.025683499376796   0: 0.025682129988252   7: 0.025677814448297   4: 0.025677676912162   8: 0.025677026222654   3: 0.025676523997799   2: 0.025676488518903 

training_10845    6: 0.599558546375058   2: 0.168589047674549   5: 0.123254272541173   9: 0.015516914925329   0: 0.015515136061613   7: 0.015514859754547   4: 0.015513483447734   8: 0.015513367645594   1: 0.015513227930452   3: 0.015511143643951 

training_10847    1: 0.533810502360158   6: 0.263154183112255   8: 0.084100226868567   5: 0.016993002094262   2: 0.016991557122629   4: 0.016991025489901   0: 0.016990791326908   9: 0.016989904259852   7: 0.016989532357457   3: 0.016989275008012 

training_10848    4: 0.476870618347508   2: 0.283885335527231   1: 0.088303069118607   0: 0.021610676842463   6: 0.021604189523103   3: 0.021550631694268   5: 0.021549126332320   9: 0.021543445873964   8: 0.021542728496716   7: 0.021540178243819 

training_10849    5: 0.668193296846566   6: 0.142499021343935   7: 0.023674777762114   1: 0.023667712448731   9: 0.023666961400917   0: 0.023663237172277   4: 0.023659086426073   3: 0.023658801443635   2: 0.023658575260366   8: 0.023658529895385 

training_1085     6: 0.792837036890304   3: 0.082137261801720   0: 0.022314486534151   2: 0.014836186761217   7: 0.014720119649048   9: 0.014660514993503   8: 0.014639952632852   5: 0.014634507492480   4: 0.014610439305997   1: 0.014609493938728 

training_10851    4: 0.786715779329297   5: 0.023705442727186   1: 0.023698620810904   0: 0.023697731423975   6: 0.023697494731730   9: 0.023697102963358   3: 0.023697023709593   8: 0.023696990139207   2: 0.023696971601623   7: 0.023696842563125 

training_10853    4: 0.719061276739511   5: 0.088991092921430   7: 0.023994982982867   8: 0.023993440386772   1: 0.023993346713090   2: 0.023993309810287   3: 0.023993253846614   0: 0.023993106760669   6: 0.023993105614302   9: 0.023993084224458 

training_10855    4: 0.587140909978165   3: 0.142707501341307   0: 0.113198035531779   5: 0.022428916223266   6: 0.022421892821924   1: 0.022421176734540   8: 0.022420607836028   2: 0.022420355538516   9: 0.022420340846109   7: 0.022420263148364 

training_10856    5: 0.624667486810343   0: 0.146553184384353   6: 0.122602706899702   8: 0.015173138949148   9: 0.015169192825690   1: 0.015167546022445   4: 0.015167460094253   7: 0.015166665693146   2: 0.015166637646093   3: 0.015165980674828 

training_10857    8: 0.453889751248284   6: 0.336473242176466   0: 0.026208797904441   5: 0.026204630234336   9: 0.026204426203314   4: 0.026204419116876   7: 0.026204234141770   1: 0.026203780181355   3: 0.026203362228402   2: 0.026203356564756 

training_10859    8: 0.715386447252065   5: 0.031629639484083   4: 0.031624787680316   6: 0.031624743619312   0: 0.031623627052231   9: 0.031622399511060   3: 0.031622213897470   1: 0.031622176548010   7: 0.031622100114658   2: 0.031621864840795 

training_10860    6: 0.778588490347242   5: 0.024852512767155   4: 0.024736253768303   2: 0.024576036000523   3: 0.024559298354784   8: 0.024542641472672   7: 0.024538727755515   0: 0.024536100736495   9: 0.024535386458705   1: 0.024534552338606 

training_10864    8: 0.790108492796460   2: 0.064575314131230   0: 0.018168004458865   6: 0.018167166362137   1: 0.018164502461262   5: 0.018163869008895   9: 0.018163667620437   7: 0.018163166344798   4: 0.018163036341111   3: 0.018162780474806 

training_10867    2: 0.297964598829621   6: 0.208627637650052   5: 0.184081476225844   1: 0.169055563572979   9: 0.068379139722924   8: 0.014550369433896   0: 0.014345041754809   3: 0.014332879433466   7: 0.014331686613905   4: 0.014331606762504 

training_10868    6: 0.485187095147868   7: 0.279084736264860   1: 0.098076929842831   8: 0.044770081417416   5: 0.015485942439146   2: 0.015481953794103   4: 0.015481345919921   0: 0.015479398682527   9: 0.015477214653455   3: 0.015475301837873 

training_1087     5: 0.466740907390418   8: 0.336088797265840   2: 0.024653629991889   4: 0.024650548816222   9: 0.024644750479302   1: 0.024644505000459   3: 0.024644304097778   0: 0.024644274600788   6: 0.024644260505583   7: 0.024644021851722 

training_10870    4: 0.776604689538472   5: 0.024831727781261   1: 0.024820924955868   0: 0.024820819401063   8: 0.024820427180051   2: 0.024820360027363   6: 0.024820347610409   3: 0.024820329526247   9: 0.024820208052390   7: 0.024820165926876 

training_10871    5: 0.724713986163292   1: 0.030603976421596   0: 0.030587097233014   6: 0.030586811922235   4: 0.030585402287271   2: 0.030584980645566   7: 0.030584819778417   9: 0.030584618652166   3: 0.030584322075953   8: 0.030583984820489 

training_10872    9: 0.439286867332643   6: 0.272521835150011   1: 0.151148397432113   5: 0.019582494148607   0: 0.019580144336833   8: 0.019577155003475   4: 0.019576708764731   7: 0.019575843512883   2: 0.019575430321993   3: 0.019575123996710 

training_10873    6: 0.599764410895657   2: 0.168611823085221   5: 0.123025577909316   9: 0.015516933534238   0: 0.015515144574174   7: 0.015514871940212   4: 0.015513487463172   8: 0.015513373925054   1: 0.015513232588165   3: 0.015511144084789 

training_10874    2: 0.551221720123342   1: 0.217424375585690   4: 0.066644995537002   8: 0.023545421421087   3: 0.023534606176738   0: 0.023528306009887   5: 0.023526543683024   9: 0.023526527100623   6: 0.023526409328144   7: 0.023521095034463 

training_10876    6: 0.753558151886192   3: 0.079745732624245   0: 0.048066652437188   8: 0.033670755103979   1: 0.014181525390494   5: 0.014156043745703   2: 0.014155717637081   7: 0.014155274037127   9: 0.014155218266371   4: 0.014154928871619 

training_10877    5: 0.748260954416492   1: 0.078229113264762   0: 0.058409607291797   2: 0.016452606538034   4: 0.016445380397446   6: 0.016443051728987   8: 0.016440971840549   9: 0.016439729505772   7: 0.016439340222517   3: 0.016439244793644 

training_10879    4: 0.593592911469568   2: 0.205193778890508   5: 0.025190073104083   0: 0.025158907954458   3: 0.025152661246907   8: 0.025142598621983   9: 0.025142337043813   7: 0.025142267499296   6: 0.025142242963463   1: 0.025142221205920 

training_1088     6: 0.781557628710122   1: 0.082476466600679   0: 0.041381289517024   3: 0.013524283118682   5: 0.013510948591626   9: 0.013510561183799   2: 0.013510480806242   8: 0.013509652493066   7: 0.013509347570762   4: 0.013509341407997 

training_10882    6: 0.522869550318989   8: 0.326414263388640   5: 0.018841522992444   0: 0.018840378435183   4: 0.018840204300506   7: 0.018839245048085   9: 0.018839175815526   1: 0.018839118934794   3: 0.018838273925514   2: 0.018838266840318 

training_10883    1: 0.441347339252810   7: 0.241537261251210   9: 0.179407780395279   6: 0.019678764311402   0: 0.019674922536720   5: 0.019672343096849   3: 0.019670598217728   2: 0.019670350850445   8: 0.019670342627905   4: 0.019670297459653 

training_10884    4: 0.766751203311471   5: 0.025921883395970   3: 0.025915969202881   1: 0.025915930804353   8: 0.025915905633664   6: 0.025915883502264   2: 0.025915872884586   7: 0.025915822609740   0: 0.025915818413583   9: 0.025915710241487 

training_10885    5: 0.402785818878771   7: 0.378227661287903   4: 0.027376331405751   1: 0.027374441558121   6: 0.027373281380478   8: 0.027373147890212   9: 0.027372815941263   0: 0.027372730558790   3: 0.027372012013163   2: 0.027371759085548 

training_10886    6: 0.721914352824160   1: 0.058386388532498   2: 0.056009543930168   0: 0.045110673605646   5: 0.019822924966443   4: 0.019783637040683   8: 0.019747176624399   9: 0.019745358105963   3: 0.019742158418405   7: 0.019737785951635 

training_10887    5: 0.608843478476992   1: 0.216817655286388   0: 0.037862496257627   6: 0.019520735067496   9: 0.019493532776559   8: 0.019492890799514   7: 0.019492668309965   4: 0.019492514481132   2: 0.019492071384253   3: 0.019491957160073 

training_10891    5: 0.447347048333023   2: 0.339447010086277   4: 0.026657656639748   3: 0.026650026338326   8: 0.026650014186534   0: 0.026649680447943   9: 0.026649665147287   6: 0.026649649517015   7: 0.026649628811428   1: 0.026649620492419 

training_10892    1: 0.312673524962175   0: 0.253530592587334   8: 0.245376329166784   4: 0.058950930715468   9: 0.021584228078621   5: 0.021582157555732   6: 0.021579433296180   3: 0.021575012622373   2: 0.021574163999037   7: 0.021573627016295 

training_10893    2: 0.386745686268955   5: 0.312125898624411   1: 0.188244111919739   0: 0.016130148484488   6: 0.016129886495860   9: 0.016125337529086   8: 0.016125106997724   7: 0.016124924585086   4: 0.016124677674700   3: 0.016124221419950 

training_10894    5: 0.824885809226763   6: 0.019467340267037   2: 0.019462416147818   1: 0.019458095983177   9: 0.019457618764498   0: 0.019455810121686   8: 0.019454362161222   4: 0.019453312620935   7: 0.019452839338506   3: 0.019452395368356 

training_10895    1: 0.751773686449019   0: 0.092976682781609   4: 0.044133648291884   6: 0.015877076072964   5: 0.015877000398052   8: 0.015873798582824   7: 0.015872897051579   9: 0.015872522655465   2: 0.015871450452583   3: 0.015871237264020 

training_10897    5: 0.797514176265993   6: 0.022500153305391   4: 0.022499135606466   7: 0.022498960387897   1: 0.022498348926547   0: 0.022498141926719   8: 0.022497950422697   9: 0.022497923891406   2: 0.022497619409337   3: 0.022497589857547 

training_10899    5: 0.619564690147169   2: 0.097005529657584   1: 0.082676938558882   8: 0.068539835380766   6: 0.022043795626942   0: 0.022041212591636   9: 0.022035721549963   4: 0.022031221211418   7: 0.022030849518456   3: 0.022030205757184 

training_109      6: 0.466099016143143   8: 0.439499386263741   0: 0.016748018376204   1: 0.011265691151746   7: 0.011081257951575   5: 0.011066832331944   9: 0.011060543473146   4: 0.011060144827298   3: 0.011060004023157   2: 0.011059105458046 

training_1090     5: 0.785837950231913   4: 0.023796257448799   3: 0.023796098297780   6: 0.023795845782632   9: 0.023795785424603   8: 0.023795663632608   0: 0.023795658636303   1: 0.023795610810222   2: 0.023795580842781   7: 0.023795548892359 

training_10901    9: 0.356104332940838   0: 0.191407587852729   1: 0.179485974838035   6: 0.178567453122449   2: 0.015758710272517   5: 0.015740791517481   7: 0.015734469480514   3: 0.015733771227758   4: 0.015733564573463   8: 0.015733344174217 

training_10902    6: 0.816446144490565   8: 0.057609736069477   0: 0.052569386758275   7: 0.014637030583833   1: 0.013742835607790   5: 0.009006543683076   9: 0.009000623699081   3: 0.008997107486601   2: 0.008995324283663   4: 0.008995267337640 

training_10903    6: 0.782049577753165   5: 0.061722344686824   9: 0.043866059191652   0: 0.016066196030359   2: 0.016050791272388   1: 0.016050301878373   4: 0.016048934521151   3: 0.016048615481636   8: 0.016048597293904   7: 0.016048581890548 

training_10904    5: 0.595062881607221   6: 0.256886504558992   4: 0.030453847770416   8: 0.016841607319261   0: 0.016828554276678   1: 0.016821578354396   9: 0.016802028225203   3: 0.016786012154687   7: 0.016759401779206   2: 0.016757583953941 

training_10905    6: 0.801829980612762   0: 0.076565653316831   1: 0.043707277991784   9: 0.019336653179223   3: 0.013044996676919   5: 0.012199282433407   8: 0.008351386551298   7: 0.008321766207073   4: 0.008321546038553   2: 0.008321456992149 

training_10907    5: 0.818348345197037   4: 0.020185157221210   6: 0.020184030178484   0: 0.020183573688118   1: 0.020183472489631   8: 0.020183250557352   9: 0.020183158126168   2: 0.020183075859359   7: 0.020182980054334   3: 0.020182956628307 

training_10908    6: 0.455411494765425   1: 0.214711933270295   0: 0.195233599149875   7: 0.019375459319885   5: 0.019217832943668   9: 0.019217461896056   2: 0.019213369578757   4: 0.019208068082154   8: 0.019205869857006   3: 0.019204911136879 

training_10909    4: 0.437005364988987   1: 0.316473745511550   6: 0.083027184607314   9: 0.055349009407182   0: 0.018038107245226   5: 0.018033022665373   8: 0.018018676336788   2: 0.018018539669984   7: 0.018018360254759   3: 0.018017989312837 

training_1091     5: 0.717924053232816   6: 0.031347139992519   9: 0.031342980967152   8: 0.031342067170285   7: 0.031341939779064   4: 0.031341508835401   1: 0.031340645725721   0: 0.031340213034102   3: 0.031339938474643   2: 0.031339512788298 

training_10913    8: 0.658068867457084   6: 0.185345752330158   1: 0.019580798949366   5: 0.019574922568366   0: 0.019573836129844   9: 0.019572725863111   4: 0.019571775646157   7: 0.019570994195378   2: 0.019570323841489   3: 0.019570003019047 

training_10917    5: 0.768221898570573   4: 0.025756505011984   6: 0.025753170934432   8: 0.025752780789847   0: 0.025752762125880   3: 0.025752682287395   2: 0.025752598182155   7: 0.025752559717947   9: 0.025752529659909   1: 0.025752512719878 

training_10918    1: 0.525321109166024   5: 0.343917521080813   6: 0.016666354752120   0: 0.016307345369168   9: 0.016306593486200   3: 0.016304055212154   8: 0.016294365692175   7: 0.016294300524692   4: 0.016294214507739   2: 0.016294140208916 

training_10919    5: 0.823807806743562   4: 0.019581685516671   6: 0.019576881935656   0: 0.019576369382970   1: 0.019576314333735   8: 0.019576236902659   7: 0.019576225678276   9: 0.019576190185226   3: 0.019576152277721   2: 0.019576137043524 

training_10921    5: 0.782170488253490   4: 0.024204371108482   6: 0.024204101800698   1: 0.024203533539390   9: 0.024203331341125   0: 0.024203192186031   7: 0.024203012145801   8: 0.024202808197405   2: 0.024202643185931   3: 0.024202518241647 

training_10922    5: 0.771288991190566   6: 0.025417554542192   0: 0.025414170785256   9: 0.025413652491084   1: 0.025412073915973   8: 0.025411745633033   4: 0.025411190181192   7: 0.025410637737615   2: 0.025410456140759   3: 0.025409527382330 

training_10923    4: 0.746282562653508   0: 0.100438586060023   6: 0.019164275781721   5: 0.019163832142252   1: 0.019161488652953   9: 0.019158623138244   3: 0.019158199005647   8: 0.019158145858204   7: 0.019157188485776   2: 0.019157098221672 

training_10924    4: 0.749743385993968   5: 0.027813701991101   6: 0.027805993560963   1: 0.027805719686965   0: 0.027805582096678   3: 0.027805262612932   9: 0.027805204895265   8: 0.027805142692750   2: 0.027805032055085   7: 0.027804974414293 

training_10925    5: 0.545125329229839   3: 0.309222345262718   4: 0.018215903087736   6: 0.018205763015215   0: 0.018205685581153   1: 0.018205114299238   8: 0.018205060770902   9: 0.018205018696875   2: 0.018204912568838   7: 0.018204867487487 

training_10926    0: 0.546605821159684   5: 0.280979691814092   6: 0.021583418423789   4: 0.021553969889290   8: 0.021547323672676   7: 0.021546136569280   3: 0.021545988524611   1: 0.021545963871256   2: 0.021545847128525   9: 0.021545838946798 

training_10928    1: 0.854183706895117   5: 0.016204593559374   0: 0.016203094138117   6: 0.016202605736055   8: 0.016201258834474   4: 0.016201252208253   9: 0.016201105261674   2: 0.016200995610052   7: 0.016200872941623   3: 0.016200514815262 

training_10931    6: 0.476165285789607   1: 0.222240102361871   5: 0.113962058519476   9: 0.078289089345846   0: 0.056227340492656   8: 0.015889848730033   7: 0.009311125993779   3: 0.009309908233084   2: 0.009304090753255   4: 0.009301149780393 

training_1094     6: 0.605928382816471   7: 0.158787883974991   1: 0.125428770349279   3: 0.030057168973381   0: 0.013336026866949   8: 0.013292622243624   9: 0.013292395988279   5: 0.013292393623107   2: 0.013292291129066   4: 0.013292064034852 

training_10941    4: 0.633476933540716   1: 0.179008872522691   7: 0.046804182304397   8: 0.020128344364730   6: 0.020114860335666   0: 0.020109313872364   9: 0.020099386262605   5: 0.020088592962983   3: 0.020084903215788   2: 0.020084610618060 

training_10943    5: 0.749838310705824   4: 0.027801793667144   0: 0.027795175076668   8: 0.027795125523424   6: 0.027795029255851   1: 0.027795018972171   9: 0.027795005115071   2: 0.027794874467652   7: 0.027794844171701   3: 0.027794823044494 

training_10944    6: 0.488885451386370   2: 0.369526227701271   5: 0.017704292402784   4: 0.017700035789012   0: 0.017699669382780   1: 0.017698807828896   9: 0.017696610655764   3: 0.017696361157021   8: 0.017696291140137   7: 0.017696252555965 

training_10946    5: 0.799075343344174   6: 0.022327458504633   7: 0.022325535546809   4: 0.022325459529849   1: 0.022324766832643   0: 0.022324603426022   9: 0.022324404655194   8: 0.022324381293269   2: 0.022324039234238   3: 0.022324007633170 

training_10947    6: 0.438336210779772   9: 0.437132315277911   2: 0.032207113141292   3: 0.013447497306634   4: 0.013359791508263   1: 0.013123057235242   7: 0.013109421154676   5: 0.013103591478787   0: 0.013091243567544   8: 0.013089758549879 

training_10950    1: 0.746554203999849   6: 0.101938712737556   0: 0.018944557049756   5: 0.018938433731115   2: 0.018937493639510   8: 0.018937419992570   4: 0.018937407836313   9: 0.018937373031914   7: 0.018937264296744   3: 0.018937133684672 

training_10956    6: 0.803755363129926   0: 0.070019037434407   5: 0.015783632013997   8: 0.015778521690635   9: 0.015778102288597   2: 0.015777401871166   4: 0.015777335138438   7: 0.015777238703758   1: 0.015776759940939   3: 0.015776607788138 

training_10959    6: 0.764442320036739   8: 0.079391921732431   1: 0.059214921973854   0: 0.030573231272874   7: 0.011069575810570   5: 0.011062263952282   4: 0.011061597610308   3: 0.011061504102726   9: 0.011061472430085   2: 0.011061191078131 

training_1096     9: 0.493622308374110   5: 0.343130949857872   6: 0.020410726790416   4: 0.020408796650036   1: 0.020406015759285   0: 0.020405774097245   7: 0.020404464791487   8: 0.020403857051842   3: 0.020403613578651   2: 0.020403493049056 

training_10960    4: 0.405486284231312   0: 0.350192375354059   7: 0.093801510978771   5: 0.021510020184128   1: 0.021506514603302   6: 0.021505560197695   9: 0.021499950305432   3: 0.021499345424701   2: 0.021499307916138   8: 0.021499130804463 

training_10961    5: 0.679993059207419   6: 0.120910808270957   8: 0.064765946878099   0: 0.019207282295718   3: 0.019202933974766   2: 0.019191839910282   4: 0.019191398566096   1: 0.019183005251972   7: 0.019176901267573   9: 0.019176824377120 

training_10962    4: 0.655903686585616   5: 0.173828411684643   6: 0.021313928946014   0: 0.021297064540787   8: 0.021294866164078   1: 0.021281658779688   9: 0.021274322846088   7: 0.021270100901952   2: 0.021268131051798   3: 0.021267828499337 

training_10963    4: 0.761990530932807   5: 0.026450407695581   8: 0.026445077771303   3: 0.026444950944653   2: 0.026444901000497   0: 0.026444899202857   1: 0.026444836876461   9: 0.026444835271636   7: 0.026444787689065   6: 0.026444772615140 

training_10964    5: 0.811611272453079   7: 0.049839640319550   4: 0.017321966639267   6: 0.017318568140924   8: 0.017318423752995   0: 0.017318223073946   9: 0.017318151857917   1: 0.017318029609319   3: 0.017317863409002   2: 0.017317860744002 

training_10966    4: 0.526376910531280   2: 0.272404382122383   5: 0.025160955473071   8: 0.025151900010582   1: 0.025151632084041   9: 0.025151455670074   0: 0.025151012824196   6: 0.025150994997243   3: 0.025150590971038   7: 0.025150165316092 

training_10969    6: 0.487199949387342   5: 0.343581940638594   9: 0.042471748958238   2: 0.036056064403306   1: 0.015123889821653   0: 0.015122984480884   7: 0.015116290077419   4: 0.015109874750390   8: 0.015109303568530   3: 0.015107953913644 

training_10971    0: 0.743748785843144   6: 0.106696116265109   4: 0.018709760292173   2: 0.018709738641380   8: 0.018696121309189   5: 0.018692709216122   1: 0.018688513153407   7: 0.018686287663607   9: 0.018686101049223   3: 0.018685866566646 

training_10972    5: 0.416205395013996   3: 0.374298533844948   4: 0.026191252582952   6: 0.026187016116608   8: 0.026186676138254   0: 0.026186418462906   1: 0.026186409221576   2: 0.026186226209939   9: 0.026186090859549   7: 0.026185981549269 

training_10973    5: 0.448008961901573   4: 0.411845778393545   6: 0.017524110991728   0: 0.017520071214681   1: 0.017517870928346   9: 0.017517648885760   8: 0.017516585613926   7: 0.017516367348438   2: 0.017516346667341   3: 0.017516258054664 

training_10974    4: 0.803167305864246   5: 0.021876771309407   6: 0.021870768126109   0: 0.021870031228287   7: 0.021869366939216   1: 0.021869231382692   3: 0.021869182170634   9: 0.021869134574915   8: 0.021869122772766   2: 0.021869085631726 

training_10978    6: 0.692883887010789   0: 0.107857238816947   4: 0.026209220743671   8: 0.025893072822002   5: 0.024593148907293   1: 0.024528403642878   2: 0.024511954483639   9: 0.024508354885578   3: 0.024507828459508   7: 0.024506890227696 

training_10980    5: 0.810560672647948   4: 0.021054357052202   0: 0.021048557151877   6: 0.021048419273387   1: 0.021048221955934   8: 0.021048083133249   3: 0.021047997460025   9: 0.021047953710331   2: 0.021047880509876   7: 0.021047857105171 

training_10983    5: 0.761631396655168   4: 0.026490525643247   8: 0.026485123940102   3: 0.026485051936972   9: 0.026484792223566   7: 0.026484754514638   0: 0.026484672453777   2: 0.026484595899703   1: 0.026484577186811   6: 0.026484509546016 

training_10985    1: 0.803372647480313   5: 0.021853720641364   0: 0.021850291051575   6: 0.021849595370273   4: 0.021848836753546   2: 0.021845391092951   7: 0.021845251133550   8: 0.021844836982836   9: 0.021844798192417   3: 0.021844631301175 

training_10988    0: 0.380583574531928   3: 0.334871212261414   6: 0.134585945940955   1: 0.021442194891241   5: 0.021425585377622   4: 0.021422805086771   8: 0.021420211887016   7: 0.021416795868914   9: 0.021416222454047   2: 0.021415451700092 

training_10989    5: 0.600831825484641   0: 0.223675820860306   4: 0.049872416022197   1: 0.017963979972526   6: 0.017948031114597   9: 0.017944053406750   8: 0.017941923656244   7: 0.017941593834339   3: 0.017940356959941   2: 0.017939998688459 

training_1099     9: 0.424025283687597   6: 0.388530356336357   7: 0.038630284344187   0: 0.032640968391953   1: 0.019600638190522   5: 0.019393254476513   4: 0.019296811897205   8: 0.019294288816920   3: 0.019294220345472   2: 0.019293893513273 

training_10992    4: 0.399204825035191   6: 0.351460704368993   1: 0.063371988279581   8: 0.059979012378139   0: 0.021011539367717   5: 0.021000666452721   2: 0.020996845831646   3: 0.020992490477610   9: 0.020990979268339   7: 0.020990948540062 

training_10994    6: 0.528710483642255   5: 0.271882204186242   2: 0.061571641680042   9: 0.045413352528409   1: 0.015415034915113   0: 0.015413849705708   3: 0.015403285413045   4: 0.015397072961441   7: 0.015396832086642   8: 0.015396242881104 

training_10998    1: 0.620101733132295   0: 0.201578212411278   6: 0.055026939424217   3: 0.017737512347547   9: 0.017598038727836   4: 0.017595785610920   5: 0.017592585481536   8: 0.017590751710997   2: 0.017590198018198   7: 0.017588243135177 

training_10999    5: 0.826954546079480   4: 0.019231603085546   6: 0.019227517938788   0: 0.019226912563398   1: 0.019226864917282   9: 0.019226642822864   8: 0.019226571835164   7: 0.019226538861322   2: 0.019226408604937   3: 0.019226393291218 

training_11       5: 0.811312612682320   6: 0.020992778675747   4: 0.020963458455415   1: 0.020962853052934   0: 0.020961797563365   8: 0.020961596922494   7: 0.020961588163386   9: 0.020961224305853   2: 0.020961064203745   3: 0.020961025974742 

training_110      1: 0.433511197039986   6: 0.200438215556041   0: 0.187777804959352   7: 0.114151255196867   5: 0.010859447773186   3: 0.010790896713648   9: 0.010621788958660   8: 0.010617095937605   4: 0.010616298670759   2: 0.010615999193896 

training_1100     6: 0.746272789348689   7: 0.111292005314813   5: 0.017819171330058   4: 0.017812196189326   0: 0.017804212831726   9: 0.017801074861567   8: 0.017800868844625   1: 0.017799373173236   2: 0.017799184700012   3: 0.017799123405948 

training_11000    6: 0.743046865026982   1: 0.095976993292198   0: 0.084507273893308   7: 0.015563120534485   9: 0.010160612452161   8: 0.010153731786413   5: 0.010148815563050   2: 0.010147669880186   3: 0.010147565492007   4: 0.010147352079209 

training_11006    9: 0.321141846754086   1: 0.297171748555018   4: 0.188562409669704   6: 0.027595211405654   0: 0.027594824570515   5: 0.027587691464131   3: 0.027586969660909   2: 0.027586619307889   7: 0.027586526164136   8: 0.027586152447959 

training_11007    6: 0.488823257433484   2: 0.317415353889918   5: 0.098864995492786   0: 0.026469178794677   7: 0.011461327474439   3: 0.011401449160312   9: 0.011397060192406   1: 0.011390492193308   4: 0.011388590619977   8: 0.011388294748694 

training_1101     5: 0.605833773856007   8: 0.232143247286961   4: 0.020260621068393   6: 0.020253081980374   0: 0.020251898508907   9: 0.020251812182072   1: 0.020251531529476   2: 0.020251418868308   3: 0.020251377300915   7: 0.020251237418588 

training_11012    8: 0.595968494752883   1: 0.183391716915070   6: 0.027596515274035   7: 0.027579341043701   0: 0.027578538521359   9: 0.027577237671983   5: 0.027577234926751   2: 0.027577036548167   3: 0.027576980760201   4: 0.027576903585852 

training_11015    5: 0.446097091875292   0: 0.335028973794245   1: 0.104688372283754   6: 0.016316641088037   4: 0.016311994738851   8: 0.016311468733457   2: 0.016311437343907   9: 0.016311343281556   3: 0.016311341193803   7: 0.016311335667099 

training_11018    4: 0.735800888100996   7: 0.089375481515980   5: 0.021856612691786   6: 0.021855676013979   1: 0.021854753216489   0: 0.021853749867811   9: 0.021851198492429   8: 0.021850632148344   3: 0.021850561830168   2: 0.021850446122017 

training_11019    5: 0.581869284478753   8: 0.150803973782641   0: 0.092322741687028   9: 0.025009507679876   4: 0.025007722597360   3: 0.024997886438046   2: 0.024997395541745   1: 0.024997259155900   7: 0.024997223936860   6: 0.024997004701790 

training_1102     6: 0.852928259109775   5: 0.016346381435140   9: 0.016342771753151   0: 0.016341925573394   4: 0.016341923708925   7: 0.016340351136204   1: 0.016339931506812   8: 0.016339869616159   3: 0.016339336550769   2: 0.016339249609671 

training_11025    6: 0.586166375208856   2: 0.259112995838869   3: 0.038782140008991   7: 0.036990745843388   0: 0.013206225968796   1: 0.013171200702588   9: 0.013144918842181   5: 0.013143187055349   4: 0.013141320090976   8: 0.013140890440005 

training_11027    2: 0.411405276836265   5: 0.388385521743601   6: 0.025028582693643   8: 0.025027804184003   0: 0.025026884496345   1: 0.025026725551664   9: 0.025026269099081   7: 0.025024515269112   4: 0.025024213035736   3: 0.025024207090550 

training_11028    5: 0.649692911828005   8: 0.187477919218727   4: 0.020358140548777   1: 0.020353497824689   0: 0.020353332213727   6: 0.020353093958189   3: 0.020352884017161   9: 0.020352826216827   2: 0.020352737398967   7: 0.020352656774931 

training_11029    1: 0.329428159767955   9: 0.246491142972264   6: 0.232804293952037   4: 0.072278656074452   5: 0.042617394472709   0: 0.015281665248392   2: 0.015275076239117   3: 0.015274640891969   8: 0.015274488492314   7: 0.015274481888791 

training_1103     9: 0.513960732485984   1: 0.295278587507799   7: 0.034947474834227   0: 0.022266455879018   6: 0.022265099693440   5: 0.022264683562586   4: 0.022264522982067   2: 0.022251218155974   8: 0.022250667943935   3: 0.022250556954971 

training_11030    6: 0.730631151675064   7: 0.101572400464021   5: 0.020977503291893   8: 0.020975827108126   0: 0.020975286926847   9: 0.020974997852906   1: 0.020974481688896   4: 0.020972951281522   2: 0.020972753408608   3: 0.020972646302117 

training_11031    5: 0.828649239468317   4: 0.019045005842399   1: 0.019038833866293   0: 0.019038800232013   6: 0.019038579026238   9: 0.019037962406547   3: 0.019037908414731   8: 0.019037904300395   7: 0.019037885795313   2: 0.019037880647753 

training_11034    4: 0.634877141226588   1: 0.213444548573759   5: 0.018967726318229   0: 0.018960181465974   6: 0.018959035998635   3: 0.018958442907617   2: 0.018958368246092   8: 0.018958215996373   9: 0.018958209832025   7: 0.018958129434708 

training_11035    1: 0.576687857887349   5: 0.272396445091935   4: 0.018866958904643   9: 0.018865854623741   6: 0.018865683919166   2: 0.018865269599000   0: 0.018864098297777   7: 0.018862778149782   8: 0.018862680848720   3: 0.018862372677887 

training_11036    4: 0.760849087313864   5: 0.026578933533369   1: 0.026574332046559   9: 0.026572219025860   6: 0.026571711287669   0: 0.026571480410887   7: 0.026570654545655   3: 0.026570634358875   2: 0.026570523662030   8: 0.026570423815230 

training_11039    1: 0.533465803379284   6: 0.259935578565733   3: 0.044504747176552   9: 0.041172417271222   0: 0.039671506580628   5: 0.016255851138755   4: 0.016251226586830   2: 0.016247878249075   8: 0.016247565197575   7: 0.016247425854346 

training_1104     4: 0.398726658624757   0: 0.232582971581313   2: 0.216680072143913   9: 0.042086819977213   6: 0.018334699771637   5: 0.018325111660601   1: 0.018320646927634   8: 0.018315518777123   7: 0.018313981164099   3: 0.018313519371709 

training_11040    6: 0.641448005750839   0: 0.114577382898364   1: 0.084511203558027   8: 0.042383780553150   4: 0.040884587960871   7: 0.015244008176748   9: 0.015238636906079   5: 0.015238503515183   3: 0.015237314036472   2: 0.015236576644267 

training_11041    9: 0.490890753700819   1: 0.328520762796887   6: 0.039741974164958   7: 0.020296356520803   0: 0.020111301034994   5: 0.020101255464471   8: 0.020085341866055   4: 0.020084879358016   2: 0.020084072671154   3: 0.020083302421843 

training_11043    6: 0.805828864367175   5: 0.035665218861636   7: 0.034592148013954   0: 0.017827568532301   8: 0.017744518334533   9: 0.017706011166393   1: 0.017659944496336   4: 0.017658907178545   2: 0.017658417408523   3: 0.017658401640605 

training_11046    4: 0.815369964696745   2: 0.020528804420187   9: 0.020521812835680   6: 0.020518962778889   5: 0.020518001763962   0: 0.020514758784996   1: 0.020507538220147   7: 0.020506836622560   8: 0.020506671367002   3: 0.020506648509832 

training_11047    5: 0.517452171036171   3: 0.317766574039579   1: 0.020600936081883   4: 0.020600644085776   0: 0.020599939189525   8: 0.020596841427316   6: 0.020596014347321   9: 0.020595938304926   2: 0.020595508798071   7: 0.020595432689432 

training_11048    1: 0.593685121094712   0: 0.272677668692195   6: 0.016709747934163   5: 0.016707468356855   4: 0.016704243634587   2: 0.016703438401826   8: 0.016703262466240   9: 0.016703187734866   3: 0.016702974148658   7: 0.016702887535898 

training_11049    5: 0.765552373912102   0: 0.057268017844379   3: 0.050557194086510   6: 0.018109845255360   1: 0.018086843436734   4: 0.018086763145616   9: 0.018085124972108   8: 0.018084912329299   7: 0.018084570628845   2: 0.018084354389047 

training_1105     6: 0.409648658104330   9: 0.268364871182393   5: 0.199057806972335   0: 0.017746977752497   1: 0.017534377833033   4: 0.017530775784416   8: 0.017530017232298   7: 0.017529168757798   2: 0.017528769548006   3: 0.017528576832893 

training_11051    1: 0.480966380674164   4: 0.358256444824777   6: 0.020109049939256   0: 0.020098317278384   5: 0.020097385827705   2: 0.020096233648460   8: 0.020095322677996   9: 0.020093709299309   7: 0.020093584585656   3: 0.020093571244294 

training_11052    6: 0.440185032966406   7: 0.274427685199967   3: 0.115246389576787   1: 0.024308982570877   8: 0.024307312803273   0: 0.024306621439682   5: 0.024305092682458   2: 0.024304525115916   4: 0.024304442493688   9: 0.024303915150947 

training_11056    5: 0.726648305078687   6: 0.117820340841424   2: 0.019676797120022   1: 0.019553310785914   4: 0.019472721734138   0: 0.019423583069392   8: 0.019353689867842   9: 0.019351191479785   7: 0.019350108896175   3: 0.019349951126622 

training_11057    5: 0.761728488861072   4: 0.026475522880962   3: 0.026475333414906   7: 0.026474531337844   2: 0.026474403289912   0: 0.026474372603706   1: 0.026474365900659   6: 0.026474359829365   8: 0.026474325712674   9: 0.026474296168901 

training_11058    5: 0.808211614332997   4: 0.021315018660021   0: 0.021309587995588   1: 0.021309514810685   3: 0.021309419778059   6: 0.021309185501968   8: 0.021309018794941   9: 0.021308901309584   2: 0.021308869593251   7: 0.021308869222904 

training_11059    6: 0.790592916818671   5: 0.049729300181685   0: 0.019970362131374   2: 0.019963392405579   1: 0.019961864117064   4: 0.019959696405654   8: 0.019958933792885   9: 0.019958204473481   3: 0.019953177983497   7: 0.019952151690108 

training_11060    5: 0.775092992839408   4: 0.089144592210947   0: 0.016970563482836   6: 0.016970542628571   1: 0.016970433177009   9: 0.016970308949283   8: 0.016970276402897   2: 0.016970149570223   3: 0.016970115191168   7: 0.016970025547659 

training_11063    1: 0.624751451718899   6: 0.253276604256082   5: 0.015250263444476   0: 0.015246759349254   9: 0.015246482028317   8: 0.015246352655702   4: 0.015246061068703   2: 0.015245690570694   7: 0.015245177064544   3: 0.015245157843329 

training_11064    6: 0.777628672836350   0: 0.083310933082050   7: 0.038004768971128   8: 0.014458226687688   1: 0.014447379199684   4: 0.014443729757996   5: 0.014431434587952   2: 0.014426493307675   9: 0.014424274504076   3: 0.014424087065401 

training_11065    6: 0.621290946041850   1: 0.203165872818224   0: 0.021947924220076   5: 0.021945585800165   8: 0.021943489290703   7: 0.021941820694765   9: 0.021941815944005   3: 0.021941067700097   2: 0.021940755708353   4: 0.021940721781763 

training_11066    1: 0.729296902007176   5: 0.030104660279946   0: 0.030083320811710   3: 0.030077623502333   6: 0.030074755859876   2: 0.030073348074739   9: 0.030072718768450   4: 0.030072336089373   8: 0.030072192704100   7: 0.030072141902297 

training_11070    6: 0.590869634997685   5: 0.205198062384123   9: 0.025495134788626   2: 0.025493030483204   4: 0.025492623550066   1: 0.025491581394452   0: 0.025491283337145   8: 0.025490071345288   3: 0.025489289509681   7: 0.025489288209730 

training_11071    0: 0.458647603859908   6: 0.240876210582654   8: 0.204949820128161   5: 0.013797529104358   7: 0.013624859391257   9: 0.013621955127113   1: 0.013621795167284   2: 0.013620106557263   3: 0.013620072128623   4: 0.013620047953379 

training_11074    6: 0.368149467465822   0: 0.241222000626992   9: 0.218380941784835   4: 0.087447430256417   1: 0.014137506779225   5: 0.014136133768097   2: 0.014131881997083   8: 0.014131724059980   7: 0.014131503467746   3: 0.014131409793802 

training_11076    6: 0.622613971281173   1: 0.219366169222249   0: 0.046171710797732   8: 0.029988642863600   9: 0.028498924845541   3: 0.010702550797878   4: 0.010676590974917   5: 0.010661910431157   7: 0.010661735245531   2: 0.010657793540221 

training_11078    1: 0.763511336330797   5: 0.084278124959478   0: 0.019031632516386   6: 0.019027087298494   3: 0.019025867597830   8: 0.019025706334775   2: 0.019025338407133   4: 0.019024979303162   7: 0.019024977261467   9: 0.019024949990476 

training_1108     5: 0.788019310063493   6: 0.023555532952103   4: 0.023554224865774   9: 0.023553878702568   8: 0.023553721621525   7: 0.023553215571453   0: 0.023553056079547   1: 0.023552568337066   2: 0.023552259674091   3: 0.023552232132380 

training_11083    0: 0.487776730425129   6: 0.424715323260396   8: 0.030175927432145   7: 0.008302474985360   1: 0.008174126910577   9: 0.008172995852203   5: 0.008172109201936   4: 0.008170209481027   2: 0.008170146940842   3: 0.008169955510385 

training_11085    0: 0.854354467456930   5: 0.016218408271436   4: 0.016210412986568   6: 0.016183013137691   8: 0.016176019246356   7: 0.016173235065838   9: 0.016171928021216   2: 0.016171831821836   1: 0.016170586996447   3: 0.016170096995682 

training_11086    1: 0.745563919130825   9: 0.109609100230879   5: 0.018108514459011   0: 0.018106625224175   6: 0.018103160180140   4: 0.018102403011737   3: 0.018101795569259   8: 0.018101706774503   7: 0.018101584966056   2: 0.018101190453415 

training_11087    5: 0.601594463009196   6: 0.258694021408450   7: 0.034812761594263   1: 0.015072920848352   0: 0.015014796756064   8: 0.014989966269230   4: 0.014957771575155   3: 0.014954729582431   9: 0.014954482503073   2: 0.014954086453785 

training_11088    2: 0.712035061921800   1: 0.032160432605137   5: 0.032062357378468   6: 0.031976578437312   0: 0.031966316781111   4: 0.031963156082163   9: 0.031961364072329   8: 0.031958986623307   3: 0.031957948198384   7: 0.031957797899989 

training_1109     5: 0.724579913998775   6: 0.030610538781565   9: 0.030608878291033   8: 0.030604206232869   0: 0.030601182479978   1: 0.030600425308735   4: 0.030600030141865   3: 0.030598525916197   7: 0.030598425787035   2: 0.030597873061946 

training_11090    5: 0.602558730912778   1: 0.191285344118180   7: 0.025777403040883   6: 0.025769521793806   0: 0.025768801502995   9: 0.025768685149318   8: 0.025768123563498   2: 0.025767824889160   3: 0.025767805038841   4: 0.025767759990541 

training_11091    6: 0.534091942435898   0: 0.344231972408733   1: 0.032614043303746   4: 0.012736562328492   8: 0.012726272435086   5: 0.012724105620088   2: 0.012719632458067   7: 0.012719482023746   9: 0.012718186207073   3: 0.012717800779071 

training_11093    5: 0.597314913660824   6: 0.223667681310111   0: 0.038783898202178   1: 0.020037647513030   4: 0.020036284906505   7: 0.020034425873072   2: 0.020031744930681   8: 0.020031652448727   9: 0.020031257452901   3: 0.020030493701969 

training_11095    1: 0.808600629339777   9: 0.050548909327278   2: 0.017635684088375   6: 0.017604553645881   5: 0.017603949104619   0: 0.017603551766922   7: 0.017601550962500   4: 0.017600914971008   8: 0.017600246253998   3: 0.017600010539641 

training_11098    3: 0.515571582864404   5: 0.254289611271231   4: 0.028768497835226   6: 0.028767440494507   0: 0.028767293684699   8: 0.028767273390025   7: 0.028767228568879   2: 0.028767067397649   1: 0.028767058248450   9: 0.028766946244928 

training_111      8: 0.420616203609809   6: 0.300361973024384   7: 0.125199578511228   9: 0.021979851992589   5: 0.021976970000417   0: 0.021974334310109   4: 0.021973873164576   1: 0.021972829645048   2: 0.021972405455411   3: 0.021971980286428 

training_1110     6: 0.852705521700734   0: 0.054857422729505   8: 0.011612647429537   3: 0.011579143189037   5: 0.011552144272731   1: 0.011541431307716   9: 0.011538517897322   2: 0.011538032516402   7: 0.011537955252310   4: 0.011537183704706 

training_11100    9: 0.335847152326889   3: 0.265642561075407   6: 0.200121129431437   2: 0.050050422733096   4: 0.049917268970496   0: 0.019698410165088   7: 0.019688854613279   5: 0.019687478270740   1: 0.019683472003045   8: 0.019663250410522 

training_11101    1: 0.497622121789152   7: 0.282445788922368   4: 0.059810782325047   2: 0.036980246253470   0: 0.035771811052029   5: 0.017587620053538   6: 0.017449032079003   3: 0.017444646990446   9: 0.017444026891222   8: 0.017443923643725 

training_11102    6: 0.523812748987680   1: 0.339487876415256   8: 0.034023270194314   0: 0.023073058283911   3: 0.019894866353804   5: 0.011944093833055   9: 0.011941094065048   7: 0.011941086313381   4: 0.011941083299833   2: 0.011940822253716 

training_11103    6: 0.586458604302278   1: 0.295859694402202   0: 0.014712509902951   8: 0.014711362632027   9: 0.014710465791628   5: 0.014710121223253   4: 0.014709615234476   7: 0.014709480214414   2: 0.014709118154870   3: 0.014709028141901 

training_11104    5: 0.411904318494484   6: 0.403990350066511   0: 0.054270143974734   9: 0.018595069786770   1: 0.018559686164592   4: 0.018537851094577   8: 0.018536229814048   2: 0.018535591032202   7: 0.018535475626577   3: 0.018535283945504 

training_11105    4: 0.365853950775008   1: 0.273606917153387   5: 0.189952029057071   8: 0.066607170518158   6: 0.017339389163887   9: 0.017330271728587   0: 0.017330166152491   7: 0.017327454432623   2: 0.017326361520982   3: 0.017326289497805 

training_11106    5: 0.820114136175377   4: 0.019991075916095   0: 0.019987296919570   6: 0.019987239744326   8: 0.019986940404229   1: 0.019986792222799   9: 0.019986740519290   7: 0.019986599484166   3: 0.019986589699409   2: 0.019986588914737 

training_11107    1: 0.437774750280156   5: 0.380005754150490   0: 0.056919584445104   4: 0.017938223686959   9: 0.017912422718386   6: 0.017894832687973   3: 0.017893912544713   8: 0.017887258499218   7: 0.017886699646629   2: 0.017886561340372 

training_11109    4: 0.813671296796275   5: 0.020713229750105   6: 0.020702792654304   2: 0.020702275626869   9: 0.020702196222890   3: 0.020701945369881   1: 0.020701682415844   0: 0.020701584391923   7: 0.020701549849867   8: 0.020701446922043 

training_1111     5: 0.550744367448847   8: 0.232861086310145   7: 0.080175534070870   4: 0.019463501656012   6: 0.019460085257095   0: 0.019459480197123   1: 0.019459445457237   9: 0.019458890346888   2: 0.019458807204063   3: 0.019458802051719 

training_11111    5: 0.557608556465818   7: 0.234604029721427   8: 0.079951409634330   6: 0.018264365620624   4: 0.018263405940922   0: 0.018262464510864   1: 0.018261940269625   2: 0.018261456064395   9: 0.018261353053369   3: 0.018261018718627 

training_11112    5: 0.449226892604260   8: 0.349273249325211   4: 0.025193358198779   3: 0.025186730694738   9: 0.025186723661576   2: 0.025186695205609   6: 0.025186607897871   0: 0.025186585236037   1: 0.025186582772387   7: 0.025186574403531 

training_11113    4: 0.506696201550874   6: 0.253520674017742   0: 0.082102946626619   8: 0.022550468916908   5: 0.022525646527300   1: 0.022523046466321   9: 0.022521006912340   2: 0.022520167079898   7: 0.022520009820991   3: 0.022519832081006 

training_11115    5: 0.705078409682872   4: 0.032775115118911   3: 0.032768462309894   8: 0.032768419102239   0: 0.032768367929480   2: 0.032768340204411   9: 0.032768308112577   1: 0.032768228088466   7: 0.032768202778844   6: 0.032768146672305 

training_11118    6: 0.551202366852942   2: 0.221886845825882   0: 0.079264835410614   7: 0.065453732850722   5: 0.021466184589666   8: 0.017443248723322   1: 0.010840115857866   9: 0.010823548343192   4: 0.010810729907259   3: 0.010808391638535 

training_11119    6: 0.470195257818104   0: 0.385543515965814   1: 0.047386993903419   9: 0.013849210299286   8: 0.013843064936744   5: 0.013841297059383   7: 0.013835940043335   2: 0.013834968433313   4: 0.013834925105187   3: 0.013834826435415 

training_1112     6: 0.590368135051657   9: 0.241393997834116   7: 0.053534829077532   0: 0.029213707889551   8: 0.014249711466056   5: 0.014249607598239   1: 0.014248688824592   4: 0.014247450077976   3: 0.014246950330233   2: 0.014246921850047 

training_11120    6: 0.756956837720007   1: 0.116938161621184   5: 0.036268030376191   0: 0.012908630529629   7: 0.012838934845661   8: 0.012821044766401   9: 0.012817245959193   4: 0.012817107873899   2: 0.012817021473436   3: 0.012816984834400 

training_11121    9: 0.530693732346504   6: 0.200692944827424   1: 0.142917386225598   5: 0.017976119646771   0: 0.017961649257011   4: 0.017956343115323   7: 0.017952398112267   2: 0.017951082533824   3: 0.017949311005796   8: 0.017949032929482 

training_11123    6: 0.548823014892965   5: 0.176891607479057   4: 0.138821596263675   1: 0.047738842074962   2: 0.026724736838240   7: 0.013656500548035   0: 0.012023937783248   8: 0.011779323036960   9: 0.011771052167347   3: 0.011769388915511 

training_11124    7: 0.495381442272562   6: 0.349158866898972   0: 0.032519794080363   5: 0.028012993076891   8: 0.015840038070514   4: 0.015822375134586   1: 0.015817175785507   9: 0.015816272843135   2: 0.015815878267270   3: 0.015815163570200 

training_11126    9: 0.796640809136368   8: 0.022632283406344   1: 0.022619941213066   5: 0.022602865561991   6: 0.022592805344383   0: 0.022589833062215   2: 0.022583511767438   4: 0.022580509580937   3: 0.022578868124407   7: 0.022578572802852 

training_11127    8: 0.505010454725482   6: 0.265443330922547   5: 0.028707372858311   4: 0.028697040643784   9: 0.028695577295874   0: 0.028691559368192   7: 0.028690910116359   1: 0.028688360250533   2: 0.028687923669050   3: 0.028687470149865 

training_11128    5: 0.405700834064083   1: 0.398495739901328   4: 0.024483000907228   0: 0.024474699503166   6: 0.024474567333463   8: 0.024474388803269   7: 0.024474252297808   3: 0.024474208896599   9: 0.024474159154141   2: 0.024474149138913 

training_11132    4: 0.524868366641354   8: 0.269589931864372   5: 0.025701756431551   9: 0.025691716589812   3: 0.025691615985658   2: 0.025691433922688   0: 0.025691367215506   7: 0.025691288172183   6: 0.025691275133924   1: 0.025691248042954 

training_11133    6: 0.607233188741930   5: 0.223047825038009   4: 0.021217258834627   1: 0.021216208392146   8: 0.021216063579516   0: 0.021215892893185   3: 0.021213656920321   9: 0.021213476060843   2: 0.021213393857042   7: 0.021213035682380 

training_11134    4: 0.623339419568734   6: 0.169748949182012   9: 0.065609451275445   0: 0.020193868383521   1: 0.020191023327882   5: 0.020186581544399   2: 0.020182836238873   8: 0.020182764017678   7: 0.020182695253276   3: 0.020182411208180 

training_11135    6: 0.744780600071956   1: 0.144460836182408   9: 0.019040671063822   5: 0.018272861665246   0: 0.017523508269373   8: 0.011191211303893   3: 0.011184027955085   7: 0.011183279648318   4: 0.011181510794929   2: 0.011181493044969 

training_11136    9: 0.413565181613137   5: 0.256417036911574   0: 0.208347441411349   6: 0.017394116651076   1: 0.017388945755692   8: 0.017379228046534   7: 0.017379029169364   4: 0.017377275188219   2: 0.017376170734414   3: 0.017375574518640 

training_11137    6: 0.487120025173291   7: 0.369124492570461   8: 0.017977941684092   5: 0.017972575259904   0: 0.017970315760713   4: 0.017968624737745   9: 0.017967511870681   1: 0.017966414305888   2: 0.017966080548443   3: 0.017966018088782 

training_11139    1: 0.596390039760836   2: 0.180468782004730   0: 0.027896894611768   6: 0.027894563541798   5: 0.027892216358313   7: 0.027891710882236   4: 0.027891675535303   9: 0.027891456529626   8: 0.027891351121091   3: 0.027891309654299 

training_11143    1: 0.452554747116689   2: 0.403796191093444   5: 0.017974588813897   0: 0.017969879989124   6: 0.017960287797199   4: 0.017952135670152   7: 0.017950278400024   8: 0.017947548697033   9: 0.017947520925212   3: 0.017946821497225 

training_11144    1: 0.571651810662434   6: 0.152379720933356   0: 0.113151416766701   2: 0.074577633093617   7: 0.028933072056582   9: 0.011877892402422   4: 0.011860507371991   8: 0.011856118778109   5: 0.011856047421345   3: 0.011855780513441 

training_11145    4: 0.519007689283756   0: 0.203790566984937   5: 0.158494501740757   2: 0.034172318252314   1: 0.014106575181113   6: 0.014093789987218   3: 0.014085994654423   7: 0.014083105319180   8: 0.014082730366772   9: 0.014082728229529 

training_11149    6: 0.824380412567569   1: 0.081757532453776   0: 0.011735023283474   5: 0.011733972981498   7: 0.011732566276197   9: 0.011732539686190   2: 0.011732321945638   8: 0.011732043027006   4: 0.011731814468250   3: 0.011731773310401 

training_11153    5: 0.482724453103352   8: 0.319961290672590   4: 0.024673959733291   1: 0.024664465033214   0: 0.024663602853344   6: 0.024663045401910   3: 0.024662377690072   2: 0.024662304932273   7: 0.024662254398509   9: 0.024662246181446 

training_11154    5: 0.532720344360352   3: 0.274001648023566   6: 0.024162216622291   7: 0.024160562841563   0: 0.024159854586954   9: 0.024159663101487   4: 0.024159147098105   1: 0.024159092915227   8: 0.024158898692379   2: 0.024158571758076 

training_11156    5: 0.457024122880170   1: 0.273807539347429   7: 0.106685628382669   3: 0.023241986348106   6: 0.023208508639607   0: 0.023206888668806   4: 0.023206659344985   9: 0.023206378445129   2: 0.023206193477307   8: 0.023206094465794 

training_11158    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_11159    6: 0.538538039430164   7: 0.235934744651904   9: 0.028193606632183   0: 0.028191559930916   1: 0.028191521384692   8: 0.028191317012866   5: 0.028190385095277   2: 0.028189686437766   3: 0.028189633693890   4: 0.028189505730340 

training_11160    6: 0.606509199552897   7: 0.228901584661502   8: 0.046699085619930   9: 0.027224339973336   4: 0.015554139011554   5: 0.015024804374981   1: 0.015022775143326   0: 0.015022139725563   3: 0.015021323587264   2: 0.015020608349647 

training_11161    1: 0.408682260412664   6: 0.299597419309125   2: 0.199395839775324   5: 0.013200935433826   0: 0.013190056278340   3: 0.013187578568378   4: 0.013187277303425   7: 0.013186355721858   9: 0.013186180122418   8: 0.013186097074642 

training_11162    6: 0.733210258593245   1: 0.029646908090034   0: 0.029643452179670   7: 0.029643132000944   9: 0.029643004843852   5: 0.029642778103013   3: 0.029642691351434   8: 0.029642618610185   2: 0.029642582056242   4: 0.029642574171380 

training_11163    6: 0.818475566257971   1: 0.059426165514580   0: 0.029525069923135   5: 0.013227412580957   4: 0.013224890353208   8: 0.013224327206185   9: 0.013224244492967   7: 0.013224237055730   2: 0.013224080891301   3: 0.013224005723967 

training_11164    1: 0.730120480481407   6: 0.029995803142121   8: 0.029989171605992   0: 0.029987669793212   9: 0.029987398662978   7: 0.029985383167065   5: 0.029984187013774   3: 0.029983476445911   2: 0.029983271734473   4: 0.029983157953066 

training_11166    6: 0.685527010497096   3: 0.094783468791227   2: 0.062988893872046   7: 0.047619632968788   5: 0.018182446214556   9: 0.018182031614581   0: 0.018179791163190   1: 0.018179689361677   4: 0.018178669273671   8: 0.018178366243168 

training_11168    5: 0.535394699809682   8: 0.269540995842882   7: 0.056780604595360   3: 0.019787355212381   4: 0.019752370065707   1: 0.019751968600674   6: 0.019748963705638   9: 0.019748429007166   0: 0.019747851307468   2: 0.019746761853043 

training_1117     8: 0.379574334833313   5: 0.350544316866472   4: 0.033750629818193   3: 0.033733215105486   0: 0.033733183603717   2: 0.033733011144716   1: 0.033732986246564   9: 0.033732852723607   6: 0.033732779311817   7: 0.033732690346115 

training_11170    6: 0.762186001020803   1: 0.087022447421672   0: 0.018914481413868   9: 0.018846745938318   5: 0.018842144604607   4: 0.018839679410601   3: 0.018837493003918   7: 0.018837256326153   8: 0.018837018382588   2: 0.018836732477471 

training_11171    0: 0.427385695007899   5: 0.252061722012638   6: 0.167224488327707   2: 0.061264249909526   8: 0.015358701528936   1: 0.015352477638142   4: 0.015339555319352   9: 0.015338799956788   7: 0.015337349270079   3: 0.015336961028933 

training_11173    6: 0.510960943631880   5: 0.177395689176275   7: 0.164556007935753   0: 0.021013448812704   8: 0.021013307939548   9: 0.021012980735102   1: 0.021012213616846   4: 0.021012042425302   2: 0.021011704368364   3: 0.021011661358226 

training_11174    6: 0.776693648178526   0: 0.084852090344256   1: 0.035199930904544   7: 0.014752837530742   5: 0.014750783055038   4: 0.014750222877269   8: 0.014750162366604   9: 0.014750131173268   2: 0.014750126064775   3: 0.014750067504978 

training_11175    6: 0.647856554111547   0: 0.190942718670389   1: 0.076937955575773   5: 0.016131235027135   9: 0.014377251854516   8: 0.010882766038171   3: 0.010816142331276   7: 0.010700803305612   4: 0.010698039516178   2: 0.010656533569404 

training_11177    6: 0.705875800423837   9: 0.107104130408387   0: 0.052502499287711   4: 0.027604470139775   7: 0.027471835578751   8: 0.024909921223254   2: 0.016823239802210   5: 0.012620293675659   1: 0.012550462122126   3: 0.012537347338288 

training_11179    6: 0.787886205080161   2: 0.071106707760154   5: 0.017628906774473   8: 0.017627799876921   1: 0.017626154514553   0: 0.017625196491964   3: 0.017624834630266   9: 0.017624828819730   4: 0.017624788320475   7: 0.017624577731302 

training_1118     1: 0.619084126182035   5: 0.242641788080023   0: 0.017290354153692   6: 0.017287569567419   9: 0.017283511033529   7: 0.017283211239288   4: 0.017283210020263   8: 0.017282452726779   2: 0.017282008001754   3: 0.017281768995219 

training_11181    0: 0.479030411474212   6: 0.229822711019592   5: 0.183214218073776   1: 0.026444392691157   7: 0.013588889989221   4: 0.013580536211673   8: 0.013580093440306   9: 0.013579815733832   2: 0.013579569093935   3: 0.013579362272297 

training_11183    6: 0.760653030393851   7: 0.109327926173641   5: 0.016256835729983   2: 0.016254286766789   0: 0.016253987400125   8: 0.016251256877647   1: 0.016251018409194   9: 0.016250722099077   3: 0.016250489825250   4: 0.016250446324443 

training_11185    6: 0.768802541056299   3: 0.069034459005876   5: 0.020271514535461   9: 0.020271461086803   8: 0.020270593726733   0: 0.020270390242768   7: 0.020269982943595   4: 0.020269823473556   1: 0.020269665569637   2: 0.020269568359272 

training_11190    6: 0.696298409195659   0: 0.103234254391038   7: 0.066149031521157   3: 0.019201216167228   5: 0.019199839799479   4: 0.019191530150048   1: 0.019183311654846   9: 0.019183050836234   8: 0.019179800974187   2: 0.019179555310123 

training_11191    6: 0.603733506336837   7: 0.262367457291260   5: 0.016739051861420   0: 0.016738282778775   3: 0.016737606141568   1: 0.016737332943672   9: 0.016737286769100   8: 0.016736654629049   4: 0.016736424217941   2: 0.016736397030378 

training_11192    0: 0.238025975849711   3: 0.232844293227760   6: 0.172191833402839   5: 0.145676434874267   2: 0.116488847739507   1: 0.033156992439079   7: 0.015616234078687   9: 0.015334187233982   4: 0.015333585241560   8: 0.015331615912607 

training_11193    9: 0.637648055042998   6: 0.207684756876873   8: 0.019335919893618   0: 0.019334554447977   1: 0.019334541181146   5: 0.019332711210119   7: 0.019332635797351   4: 0.019332389468854   2: 0.019332254139445   3: 0.019332181941619 

training_11196    1: 0.519408686862605   6: 0.327423887253322   5: 0.019773489416230   4: 0.019069206171353   8: 0.019057718352729   0: 0.019055802622726   7: 0.019053192017626   9: 0.019052779024097   2: 0.019052639557878   3: 0.019052598721434 

training_11197    6: 0.798096937861151   8: 0.056033937150758   3: 0.018249916986822   5: 0.018232394857399   0: 0.018231913557531   9: 0.018231498953754   1: 0.018231162307632   7: 0.018231059546282   4: 0.018230619250279   2: 0.018230559528391 

training_11198    6: 0.747144723366880   1: 0.151560384180403   9: 0.038807892557525   5: 0.011821407525232   0: 0.008508015279901   4: 0.008455356227943   2: 0.008435865128912   7: 0.008422880504468   8: 0.008421757239386   3: 0.008421717989349 

training_1120     8: 0.715386520957614   5: 0.031629562850493   4: 0.031624786838004   6: 0.031624745851870   0: 0.031623628893756   9: 0.031622399437645   3: 0.031622213827198   1: 0.031622176491616   7: 0.031622100053082   2: 0.031621864798721 

training_11200    9: 0.564225432973705   6: 0.287294198990058   8: 0.018565667518720   1: 0.018560494265985   0: 0.018560172692160   5: 0.018559904164199   3: 0.018558744153176   4: 0.018558685177258   7: 0.018558432681868   2: 0.018558267382872 

training_11201    1: 0.614833817771186   6: 0.170561499078513   3: 0.096696673978731   4: 0.016855618621043   5: 0.016851847374281   2: 0.016849908392552   0: 0.016845397138896   8: 0.016838247033695   9: 0.016835147159705   7: 0.016831843451399 

training_11202    6: 0.323854695909217   0: 0.267714488638991   1: 0.228323699218571   5: 0.093947072597328   8: 0.014361624364672   9: 0.014360105989357   2: 0.014359914828737   7: 0.014359547394361   4: 0.014359448555366   3: 0.014359402503399 

training_11203    6: 0.594674291197138   0: 0.249463025460464   9: 0.064626239637721   1: 0.024879774035918   8: 0.011061647374776   5: 0.011059413840884   2: 0.011059014461464   7: 0.011059000517564   4: 0.011058843840820   3: 0.011058749633251 

training_11205    6: 0.816799756791559   4: 0.020371526936561   5: 0.020371002099628   9: 0.020363945594543   3: 0.020349590251420   0: 0.020349527885469   8: 0.020349332703632   1: 0.020348935062808   2: 0.020348882056094   7: 0.020347500618286 

training_11208    6: 0.823923745457769   5: 0.019566006221593   9: 0.019564754045640   7: 0.019564164990011   8: 0.019563992580405   4: 0.019563756092313   1: 0.019563661068090   0: 0.019563641494329   2: 0.019563166062681   3: 0.019563111987169 

training_11209    6: 0.640377350737700   0: 0.239073583682951   3: 0.033555325081836   1: 0.012430419673646   7: 0.012427894024438   5: 0.012427779862165   9: 0.012427110066789   8: 0.012427011588028   4: 0.012426872687174   2: 0.012426652595274 

training_11210    3: 0.498800482580035   1: 0.321335921084459   6: 0.022584096630543   0: 0.022473543155793   5: 0.022471250341914   9: 0.022469300181566   4: 0.022468311325150   8: 0.022466411915517   2: 0.022465608718409   7: 0.022465074066615 

training_11211    1: 0.368871305028760   6: 0.258724760059952   8: 0.213032294736423   0: 0.051126285111332   2: 0.018090968318567   5: 0.018036775721871   4: 0.018030531891355   9: 0.018030153343924   7: 0.018028619144422   3: 0.018028306643394 

training_11212    6: 0.784872791664693   7: 0.049069136111324   1: 0.044791524931190   0: 0.017334502334189   8: 0.017323230841795   9: 0.017322222064482   5: 0.017321837693690   2: 0.017321640511128   3: 0.017321567247587   4: 0.017321546599922 

training_11213    6: 0.742701053132346   9: 0.065083297725742   1: 0.051555882659924   7: 0.048022002841474   4: 0.027559254895641   0: 0.021723232839118   5: 0.010880639066498   8: 0.010825418518957   2: 0.010824726911411   3: 0.010824491408889 

training_11216    6: 0.693615612151421   5: 0.148586729774550   2: 0.038169590621241   0: 0.034980992371715   8: 0.014130288548238   1: 0.014107041267800   9: 0.014106992077126   3: 0.014101412619837   7: 0.014100681623435   4: 0.014100658944637 

training_1122     5: 0.472002522691507   8: 0.329598471064952   4: 0.024803709187671   1: 0.024800819427206   0: 0.024799584110533   2: 0.024799287402008   6: 0.024799121174492   9: 0.024798957411174   3: 0.024798769309110   7: 0.024798758221346 

training_11220    5: 0.529298225936075   0: 0.258575295541581   1: 0.088619525804191   6: 0.040561199969675   4: 0.013827762013395   9: 0.013825451807671   8: 0.013824992603617   3: 0.013823037967187   7: 0.013822278040162   2: 0.013822230316445 

training_11221    5: 0.219602581912496   1: 0.198334765601398   8: 0.196324455585527   6: 0.156645505515090   3: 0.137010226599765   9: 0.018421564552080   4: 0.018416922469675   0: 0.018415152570966   7: 0.018414523604636   2: 0.018414301588368 

training_11222    6: 0.757997629591031   0: 0.088072383229398   8: 0.044975150407612   1: 0.026117766835084   2: 0.013860794625778   5: 0.013808777527507   7: 0.013798622795450   9: 0.013790617414209   3: 0.013789381853875   4: 0.013788875720055 

training_11224    6: 0.779477660904323   1: 0.107720136751193   0: 0.062020227018088   8: 0.010351941250267   3: 0.006905757606655   7: 0.006814150185044   2: 0.006729812075314   5: 0.006661365587838   9: 0.006659497578007   4: 0.006659451043271 

training_11225    6: 0.574852044393038   9: 0.109135835305780   1: 0.107405506059555   5: 0.082739622207665   0: 0.055983732756282   8: 0.022106761178688   7: 0.015512665494764   4: 0.014507583114793   3: 0.008913772968771   2: 0.008842476520664 

training_11227    5: 0.432020697419150   6: 0.229970967257489   3: 0.210898689219640   9: 0.018160897356667   2: 0.018159089734071   8: 0.018158885652339   1: 0.018158779942264   4: 0.018158226348020   0: 0.018157943057687   7: 0.018155824012673 

training_11228    9: 0.764948825583427   6: 0.090777144884276   0: 0.018036168766281   8: 0.018036104085654   1: 0.018034657997550   5: 0.018034636308128   7: 0.018033403383370   4: 0.018033100942447   2: 0.018033009680436   3: 0.018032948368431 

training_11229    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_1123     6: 0.799712155198484   5: 0.022267191175865   4: 0.022261774115308   1: 0.022253236810855   0: 0.022252780395611   2: 0.022250987478214   8: 0.022250895640768   3: 0.022250563993076   7: 0.022250254272391   9: 0.022250160919429 

training_11230    6: 0.469360375425040   5: 0.211153329824138   7: 0.090519190565898   4: 0.088078427983501   8: 0.045292365487022   9: 0.019131073147766   0: 0.019118313009482   1: 0.019116282134842   3: 0.019115330795299   2: 0.019115311627013 

training_11231    6: 0.723614259924272   0: 0.071810743092626   7: 0.070271445120257   1: 0.029316500150085   9: 0.028432085774517   8: 0.015316654335952   5: 0.015315101164451   3: 0.015309285664076   2: 0.015307312193538   4: 0.015306612580225 

training_11232    6: 0.563056972853360   9: 0.253613710471739   0: 0.080556272246629   5: 0.026080114687812   4: 0.012806872211700   3: 0.012795424118676   8: 0.012785733341800   2: 0.012769358008818   1: 0.012769174110770   7: 0.012766367948696 

training_11233    7: 0.798271143667450   6: 0.022424412622279   9: 0.022415227484094   0: 0.022413990965459   8: 0.022413551581670   1: 0.022413515745384   2: 0.022412739332136   5: 0.022412614001516   4: 0.022411671889533   3: 0.022411132710480 

training_11234    6: 0.680171345187516   0: 0.222446291460429   1: 0.022824766484324   2: 0.015444232205625   8: 0.009870645459583   7: 0.009858018832492   9: 0.009847600358578   5: 0.009846256880349   4: 0.009845448510649   3: 0.009845394620454 

training_11236    6: 0.740513201767299   0: 0.078412163344819   9: 0.053523112789727   2: 0.025036196725937   7: 0.024814696750626   1: 0.015549043962734   8: 0.015547468367673   5: 0.015536337548250   3: 0.015534938530309   4: 0.015532840212627 

training_11237    6: 0.604617545666754   7: 0.218147799769398   5: 0.037999360388674   4: 0.028897262798390   1: 0.018407830856138   0: 0.018396924909342   3: 0.018384882124418   9: 0.018383875650968   8: 0.018383364589727   2: 0.018381153246192 

training_11238    6: 0.784873780985582   7: 0.049069540735412   1: 0.044790413580726   0: 0.017334219915635   8: 0.017323230737956   9: 0.017322222022232   5: 0.017321837674650   2: 0.017321640504243   3: 0.017321567245096   4: 0.017321546598469 

training_11239    1: 0.772303300660226   6: 0.057326797851734   7: 0.039398293513985   4: 0.018748163920165   0: 0.018706597820246   9: 0.018706210571658   5: 0.018704560442813   8: 0.018702141722665   2: 0.018702037370625   3: 0.018701896125883 

training_1124     5: 0.807103759091621   0: 0.021446674016827   1: 0.021443825042793   6: 0.021431021763208   3: 0.021430096906862   4: 0.021429640931529   7: 0.021429517507636   9: 0.021429393030006   8: 0.021429152056170   2: 0.021426919653348 

training_11241    6: 0.575928189999860   5: 0.146599248793432   1: 0.139566238885506   0: 0.019713901966745   4: 0.019700566802340   2: 0.019700527114047   9: 0.019699112815507   8: 0.019697893797921   7: 0.019697328911045   3: 0.019696990913599 

training_11242    8: 0.389011360787241   0: 0.222746445977085   6: 0.142095337564592   9: 0.114852714335683   5: 0.038721527101905   1: 0.018781440679402   4: 0.018496861706758   3: 0.018463308392177   7: 0.018416134249515   2: 0.018414869205643 

training_11243    0: 0.486167668590344   6: 0.326727706124991   5: 0.077292647668011   8: 0.022194509751870   2: 0.014677129058919   4: 0.014591894560139   1: 0.014590135284662   3: 0.014586579137357   9: 0.014586381879427   7: 0.014585347944279 

training_11244    6: 0.784655299421803   8: 0.098907878732307   9: 0.014570773208427   0: 0.014554716474704   1: 0.014554592035607   5: 0.014553299911858   4: 0.014551033536051   7: 0.014550997781913   3: 0.014550737335484   2: 0.014550671561845 

training_11249    6: 0.634099771027905   3: 0.189875987251068   0: 0.088217681801856   1: 0.012576513341528   5: 0.012548438980907   4: 0.012546479012644   9: 0.012534889047009   8: 0.012534003901869   7: 0.012533443184995   2: 0.012532792450219 

training_1125     8: 0.790107061320845   2: 0.064574262364120   6: 0.018169583180508   0: 0.018168065133155   1: 0.018164504568128   5: 0.018163870369103   9: 0.018163668744835   7: 0.018163166915809   4: 0.018163036774964   3: 0.018162780628532 

training_11251    1: 0.432035945370658   6: 0.341196866619390   0: 0.066022749534981   8: 0.040668846588222   3: 0.038882044411117   7: 0.016239967779067   5: 0.016239868381084   9: 0.016239039989625   2: 0.016237363032282   4: 0.016237308293573 

training_11252    3: 0.592422576402312   6: 0.217008831061464   8: 0.065347926270487   1: 0.017896782687930   5: 0.017891701505600   0: 0.017889791256319   4: 0.017886406620571   9: 0.017885632917127   2: 0.017885211913001   7: 0.017885139365191 

training_11253    1: 0.441726560288897   6: 0.284972020589641   2: 0.177609859357589   0: 0.013673019689348   5: 0.013672960627233   4: 0.013669408966517   9: 0.013669107684182   8: 0.013669103699896   7: 0.013669003024293   3: 0.013668956072402 

training_11254    6: 0.826146533958508   0: 0.046182808911394   9: 0.032651513361123   1: 0.025230856765366   5: 0.011636553005649   4: 0.011630916673211   8: 0.011630694864260   3: 0.011630061367202   7: 0.011630053538864   2: 0.011630007554423 

training_11255    3: 0.527266227593596   1: 0.309415028339721   5: 0.020446805996374   6: 0.020430271605469   4: 0.020428889216818   2: 0.020410890809638   7: 0.020402233374325   9: 0.020401465618582   0: 0.020399700273918   8: 0.020398487171560 

training_11256    9: 0.771465950023538   1: 0.078471701710879   5: 0.018772292341706   6: 0.018758427262194   8: 0.018756619272867   3: 0.018756384100488   0: 0.018755256415311   7: 0.018755082739039   4: 0.018754498847483   2: 0.018753787286493 

training_11257    4: 0.516937026152926   6: 0.267818533686591   3: 0.067765574236794   7: 0.047029932012093   1: 0.016744120207531   0: 0.016743855293963   5: 0.016742645329071   2: 0.016739895115660   9: 0.016739425529121   8: 0.016738992436249 

training_11259    9: 0.763786958232422   5: 0.026252803446931   6: 0.026251611551729   4: 0.026247181752691   8: 0.026247144438979   0: 0.026243732667371   7: 0.026243322367024   1: 0.026243292512952   2: 0.026242005751644   3: 0.026241947278257 

training_11260    6: 0.569621942941510   1: 0.223294248504051   5: 0.108472480770535   8: 0.027397433939022   9: 0.011903574605694   0: 0.011864372965339   4: 0.011861883470322   3: 0.011861751750437   7: 0.011861317598101   2: 0.011860993454990 

training_11261    6: 0.682608865508094   9: 0.198928390051071   0: 0.024786123444163   7: 0.013387417322276   5: 0.013383430550469   1: 0.013383154316869   4: 0.013381346317101   8: 0.013380933312177   2: 0.013380184240528   3: 0.013380154937252 

training_11263    8: 0.695347537553116   6: 0.139242723130825   5: 0.020683776376768   9: 0.020681514424247   3: 0.020676263751549   0: 0.020674377175948   1: 0.020674246442535   4: 0.020673304014290   2: 0.020673170258385   7: 0.020673086872336 

training_11265    6: 0.808860117295353   0: 0.050752168183275   5: 0.037969785077914   3: 0.019865291841964   2: 0.019335347852613   8: 0.016535216962041   1: 0.012133717373833   7: 0.011667119971812   9: 0.011446383666998   4: 0.011434851774197 

training_11268    5: 0.500370499005073   6: 0.175953622272936   0: 0.158485755362617   1: 0.059650849827656   7: 0.017610875027741   4: 0.017590720448805   2: 0.017590357426142   8: 0.017584624431762   9: 0.017581609484321   3: 0.017581086712948 

training_11269    6: 0.749825279675256   1: 0.075024559335176   0: 0.063103740768454   5: 0.016018751521328   2: 0.016007745783592   3: 0.016006026693557   9: 0.016003713376285   4: 0.016003471009439   7: 0.016003430488841   8: 0.016003281348072 

training_11270    6: 0.585390148816495   9: 0.191274308161429   1: 0.078285080059503   3: 0.042259277024639   0: 0.033914155108554   5: 0.013840868951326   4: 0.013763154806351   8: 0.013758788175523   2: 0.013757229215601   7: 0.013756989680578 

training_11271    6: 0.618596685744515   7: 0.152784653897159   3: 0.092704672396523   0: 0.039801028511458   2: 0.016034845525759   4: 0.016018085163525   5: 0.016017377574803   1: 0.016014872388103   8: 0.016013963338209   9: 0.016013815459945 

training_11272    9: 0.345939273851796   5: 0.253551513870646   6: 0.191604283405669   1: 0.088988607218350   7: 0.020050709164289   0: 0.019979875801608   8: 0.019973099461897   4: 0.019972608876150   3: 0.019970021867360   2: 0.019970006482235 

training_11273    6: 0.458681685819746   5: 0.237441466710527   0: 0.160895929032770   1: 0.059894892477184   8: 0.021572616949474   9: 0.012309924215207   7: 0.012301172185753   3: 0.012300854454542   4: 0.012300793339931   2: 0.012300664814865 

training_11274    4: 0.499033948903631   3: 0.217802597608859   6: 0.153481169119370   0: 0.018545570695298   1: 0.018535874604795   9: 0.018524109557676   5: 0.018523571753464   7: 0.018517978981338   2: 0.018517911289178   8: 0.018517267486391 

training_11276    7: 0.444606759342911   6: 0.356686453274819   5: 0.024841006377610   9: 0.024839218435957   8: 0.024838882230740   0: 0.024838245991996   1: 0.024837882473313   2: 0.024837420556638   3: 0.024837205505506   4: 0.024836925810510 

training_11277    7: 0.407556190365456   5: 0.347846078005272   2: 0.030576697385049   1: 0.030575147799417   6: 0.030574922035114   0: 0.030574877912861   9: 0.030574334269577   3: 0.030574193615014   4: 0.030573784679480   8: 0.030573773932759 

training_11278    6: 0.439865873319055   1: 0.334553191960518   8: 0.112562746935314   0: 0.031052120342494   5: 0.013676782385061   9: 0.013670436348817   2: 0.013655317705315   7: 0.013654574578170   3: 0.013654480856508   4: 0.013654475568749 

training_11279    0: 0.637063109661594   6: 0.211053945907173   1: 0.028672507238667   3: 0.028337109516877   8: 0.015814968873534   9: 0.015814658258111   5: 0.015812470343064   4: 0.015811006292420   2: 0.015810342336902   7: 0.015809881571658 

training_1128     4: 0.788302525575817   5: 0.023527267980253   0: 0.023521474015521   9: 0.023521350932267   6: 0.023521349256519   8: 0.023521298199875   1: 0.023521290675886   2: 0.023521168820168   3: 0.023521167671270   7: 0.023521106872422 

training_11281    6: 0.571198061118604   0: 0.311040421129308   1: 0.014720835949221   5: 0.014720833696906   8: 0.014720385110890   9: 0.014720093493190   7: 0.014719919033805   3: 0.014719907695655   2: 0.014719792942986   4: 0.014719749829435 

training_11282    5: 0.556705426006150   7: 0.276443627738095   1: 0.020856970626021   0: 0.020856705752934   6: 0.020856703852823   2: 0.020856683751913   4: 0.020856069177078   3: 0.020856018797622   9: 0.020855921458741   8: 0.020855872838622 

training_11283    5: 0.746183359032698   4: 0.028205052296897   8: 0.028201719575998   6: 0.028201668468895   1: 0.028201560596023   9: 0.028201487270137   0: 0.028201373367751   3: 0.028201365817633   7: 0.028201210403648   2: 0.028201203170320 

training_11284    9: 0.801850822868397   8: 0.022020571804837   6: 0.022019063152111   5: 0.022016748224829   0: 0.022016147541519   1: 0.022016142901199   7: 0.022015257512600   4: 0.022015238644559   2: 0.022015008785612   3: 0.022014998564337 

training_11285    1: 0.396971536620886   6: 0.359509655024073   5: 0.150142581984394   9: 0.013382014860977   0: 0.013339460263078   3: 0.013332124734178   2: 0.013331009721896   8: 0.013330777785970   7: 0.013330490795896   4: 0.013330348208651 

training_11287    6: 0.696234924798700   1: 0.144550437001274   0: 0.056293632123137   5: 0.026026842044753   9: 0.012834099490039   2: 0.012816216310917   7: 0.012811656485547   8: 0.012811222850169   3: 0.012810684162136   4: 0.012810284733328 

training_11289    4: 0.717557321215498   1: 0.031389162400088   0: 0.031386090710147   9: 0.031386065055281   5: 0.031385374310567   6: 0.031381627837725   7: 0.031379282939903   2: 0.031379106767998   8: 0.031378311596395   3: 0.031377657166398 

training_11291    6: 0.783356741982498   2: 0.069612823869108   0: 0.059730340774191   7: 0.012536138388518   9: 0.012466376303424   1: 0.012461629634842   5: 0.012460857948212   8: 0.012458551528692   4: 0.012458272553380   3: 0.012458267017135 

training_11292    6: 0.410377023172090   7: 0.386106980990701   1: 0.103178775009478   0: 0.016439109355159   5: 0.014510870619038   8: 0.013879724329692   9: 0.013877332615091   4: 0.013877260188201   3: 0.013876681381870   2: 0.013876242338681 

training_11295    4: 0.413347835995055   6: 0.352196337559573   9: 0.029314466219601   5: 0.029311522971566   1: 0.029309810807309   0: 0.029309377583301   7: 0.029303128107432   2: 0.029302907795213   8: 0.029302637478396   3: 0.029301975482555 

training_11297    6: 0.662517519338906   0: 0.188921511752801   3: 0.032099346924971   1: 0.031272360886324   7: 0.014199481880691   5: 0.014198238873538   9: 0.014198232290399   8: 0.014197898340966   2: 0.014197723407893   4: 0.014197686303511 

training_11299    4: 0.378363136955336   6: 0.300146974226794   1: 0.207250455948993   2: 0.023470026350621   7: 0.015144837269710   0: 0.015132457078329   5: 0.015123874271696   9: 0.015123574452672   8: 0.015123016236845   3: 0.015121647209004 

training_113      5: 0.754601613284590   6: 0.063870112368320   4: 0.051842284377591   0: 0.018537907020220   9: 0.018526484668120   1: 0.018526102581266   8: 0.018524922443846   7: 0.018523778442340   3: 0.018523418018611   2: 0.018523376795097 

training_11300    4: 0.578766330742204   6: 0.130107454091203   3: 0.118900283299412   5: 0.024610973894776   9: 0.024603698610011   8: 0.024602666062041   1: 0.024602469169214   0: 0.024602457597026   7: 0.024601857995948   2: 0.024601808538165 

training_11301    4: 0.829812455864330   5: 0.018917068523627   6: 0.018909234403695   0: 0.018909113101181   1: 0.018908964704800   8: 0.018908707635625   9: 0.018908669633810   7: 0.018908629634921   2: 0.018908587629198   3: 0.018908568868811 

training_11302    5: 0.816828278055244   4: 0.020357509637519   6: 0.020351964784819   0: 0.020351893684154   1: 0.020351858959343   8: 0.020351804094836   9: 0.020351759639628   3: 0.020351659468857   2: 0.020351654075038   7: 0.020351617600561 

training_11305    4: 0.763453940006319   3: 0.079575495551610   5: 0.019625806300305   8: 0.019621199546626   6: 0.019620734698040   9: 0.019620663111688   2: 0.019620647581421   0: 0.019620640530992   1: 0.019620470368960   7: 0.019620402304038 

training_11306    5: 0.581220243658323   6: 0.168292591336981   0: 0.068049164935907   4: 0.066087270302722   3: 0.019393844983569   2: 0.019392358990000   9: 0.019391407723131   7: 0.019391169364065   1: 0.019391101996122   8: 0.019390846709181 

training_11307    5: 0.784467534219476   0: 0.023955104794465   1: 0.023954411881860   4: 0.023949745444385   6: 0.023945774820518   8: 0.023945620612309   3: 0.023945513796012   9: 0.023945481379367   2: 0.023945450406562   7: 0.023945362645045 

training_11308    4: 0.684614703124962   6: 0.115669809017824   5: 0.024973224077653   8: 0.024963397658079   3: 0.024963275715114   2: 0.024963173944454   0: 0.024963156532373   9: 0.024963112956203   1: 0.024963112675901   7: 0.024963034297437 

training_1131     6: 0.668662222645840   8: 0.198434178177288   3: 0.028779455229022   0: 0.023274113602963   5: 0.013493679105051   4: 0.013474072527908   1: 0.013471849725013   2: 0.013471549151700   9: 0.013470042779655   7: 0.013468837055559 

training_11314    6: 0.426005347120925   0: 0.375547513143883   8: 0.056100262962304   3: 0.045454134498132   5: 0.016150272392054   1: 0.016148966698924   4: 0.016148869752844   9: 0.016148802182723   2: 0.016147960467999   7: 0.016147870780211 

training_11315    6: 0.711276953371255   7: 0.162583121758657   1: 0.015773853080944   9: 0.015770759609533   0: 0.015769624974928   5: 0.015767454774578   8: 0.015765501682612   4: 0.015764617457595   2: 0.015764196454368   3: 0.015763916835530 

training_11316    6: 0.775193972501448   0: 0.096896871030557   9: 0.015999684883664   1: 0.015989615746761   2: 0.015987747455863   5: 0.015987331987796   8: 0.015986683677820   7: 0.015986228399865   4: 0.015986082668127   3: 0.015985781648099 

training_11317    5: 0.784534618255542   4: 0.023945622956886   8: 0.023940219013823   9: 0.023940154199574   0: 0.023940011639265   3: 0.023939933716574   2: 0.023939888144701   6: 0.023939862282051   1: 0.023939855287935   7: 0.023939834503649 

training_11320    5: 0.633791515463874   0: 0.213044247653222   9: 0.048096084807333   6: 0.015018723132526   4: 0.015009902473012   1: 0.015008704287892   8: 0.015007940149471   7: 0.015007670856077   3: 0.015007633547909   2: 0.015007577628684 

training_11322    6: 0.769434360161991   0: 0.091184044246456   1: 0.034587764159790   3: 0.031013106126721   5: 0.012297599114561   8: 0.012296762367665   9: 0.012296720633997   4: 0.012296688972395   2: 0.012296526436768   7: 0.012296427779657 

training_11324    6: 0.802899326389437   0: 0.070273634878531   3: 0.015878840327721   5: 0.015857639461547   4: 0.015853279430277   9: 0.015849347470513   1: 0.015848847869535   2: 0.015846724147612   8: 0.015846255166214   7: 0.015846104858611 

training_11327    6: 0.746373979139439   0: 0.145788916706718   7: 0.031495055073083   4: 0.018416535207887   1: 0.009681813911402   8: 0.009660051182701   5: 0.009646883141430   9: 0.009646252702741   2: 0.009645261102584   3: 0.009645251832016 

training_11330    6: 0.595605602651394   5: 0.166557612666353   0: 0.132894063046559   2: 0.038481389313724   8: 0.012886277340591   7: 0.010787156448745   3: 0.010758862123951   9: 0.010676409268978   1: 0.010676321366889   4: 0.010676305772816 

training_11333    5: 0.536845757606998   9: 0.210164947763106   1: 0.118988629728211   4: 0.019146871762662   6: 0.019142795756722   0: 0.019142669727305   8: 0.019142311494322   2: 0.019142072849668   7: 0.019141990098527   3: 0.019141953212479 

training_11335    6: 0.275778375547498   5: 0.208758037637249   4: 0.173312048427799   3: 0.124257400636037   1: 0.114655492047873   0: 0.020649785055619   9: 0.020647807886174   7: 0.020647715394690   2: 0.020646986310315   8: 0.020646351056746 

training_11336    5: 0.657114784167255   8: 0.160694362852953   4: 0.022779710141744   0: 0.022773175372690   9: 0.022773144475626   6: 0.022773140092089   1: 0.022773099885656   3: 0.022772938704561   2: 0.022772836505958   7: 0.022772807801468 

training_11338    4: 0.806892481055777   5: 0.021462128754607   6: 0.021456309285373   0: 0.021455893622358   1: 0.021455738844528   8: 0.021455631517235   9: 0.021455531494513   3: 0.021455512070469   2: 0.021455420125284   7: 0.021455353229857 

training_1134     5: 0.550866365914192   8: 0.272250593865878   6: 0.022112748571204   4: 0.022112624745910   7: 0.022109903325055   1: 0.022109842273850   0: 0.022109829237386   9: 0.022109827721455   2: 0.022109133504372   3: 0.022109130840699 

training_11340    5: 0.746903067970578   4: 0.028128061170694   8: 0.028121243770057   0: 0.028121171163565   3: 0.028121137373053   2: 0.028121125432647   1: 0.028121085456941   7: 0.028121079327495   6: 0.028121017148659   9: 0.028121011186311 

training_11341    6: 0.791610234839863   1: 0.050487283462273   0: 0.034606417604343   3: 0.018046559076685   5: 0.017560132264300   8: 0.017556477897066   7: 0.017536041726565   4: 0.017532918059110   9: 0.017532117352073   2: 0.017531817717722 

training_11343    6: 0.377681973228959   1: 0.365461598912009   5: 0.148008032703999   0: 0.015631918297605   8: 0.015536867041348   2: 0.015536154983241   7: 0.015536030176518   9: 0.015535966786983   3: 0.015535765013893   4: 0.015535692855445 

training_11344    7: 0.420567260400072   6: 0.394754216345490   1: 0.074893283076389   0: 0.015690354075954   8: 0.015689677703800   5: 0.015683589690241   9: 0.015681569714810   4: 0.015680368009508   2: 0.015679935786959   3: 0.015679745196778 

training_11348    9: 0.489432852056793   0: 0.250386515307678   3: 0.085996525040328   4: 0.050733846492757   6: 0.020748538872480   1: 0.020544136391699   5: 0.020544090311989   8: 0.020542740625722   2: 0.020535458293087   7: 0.020535296607467 

training_11349    5: 0.623399587112060   6: 0.206148986175437   4: 0.034410193320799   7: 0.027899464192954   1: 0.018873166525775   2: 0.018162754972245   0: 0.017867904858373   9: 0.017751572475517   3: 0.017743267195766   8: 0.017743103171073 

training_1135     4: 0.768472628872339   5: 0.025733787581666   0: 0.025725954589668   1: 0.025725212273605   6: 0.025724785845213   8: 0.025723979654795   3: 0.025723647411152   7: 0.025723508731648   9: 0.025723381513533   2: 0.025723113526382 

training_11350    6: 0.574106787119343   9: 0.309874314782072   2: 0.026895461404601   1: 0.017800996364822   0: 0.011919071887522   5: 0.011883420050438   4: 0.011880901909188   3: 0.011880132502088   7: 0.011879586990875   8: 0.011879326989051 

training_11352    6: 0.662069716004948   1: 0.198035094925365   0: 0.034354685361661   8: 0.021646448694618   7: 0.021181072643903   3: 0.012626237796208   9: 0.012522378716108   5: 0.012521711089965   4: 0.012521403578819   2: 0.012521251188406 

training_11354    0: 0.446745117536313   4: 0.356939624429882   5: 0.024547918804772   8: 0.024538350698659   3: 0.024538309934950   6: 0.024538246711991   1: 0.024538185208607   7: 0.024538170424438   2: 0.024538068412915   9: 0.024538007837473 

training_11356    0: 0.575386121234015   6: 0.289732666217463   8: 0.016898364687372   1: 0.016857910935857   9: 0.016857370102594   5: 0.016855647171959   4: 0.016853660144078   7: 0.016853119426684   3: 0.016852595854796   2: 0.016852544225183 

training_11357    6: 0.829183161344492   1: 0.050814917037090   8: 0.015055667895219   0: 0.015008018598076   4: 0.014991012191350   5: 0.014989696623260   3: 0.014989468099363   2: 0.014989382300580   9: 0.014989360821979   7: 0.014989315088591 

training_11358    0: 0.607243278220741   5: 0.227827635647639   6: 0.034874335310273   8: 0.018588904074502   1: 0.018587171273655   3: 0.018576326867524   4: 0.018575802883960   7: 0.018575769961315   2: 0.018575516522661   9: 0.018575259237728 

training_11359    0: 0.456063842096649   5: 0.351147129792754   6: 0.059050095356497   9: 0.019120370300260   4: 0.019105349823390   1: 0.019103395907594   7: 0.019103238886067   8: 0.019102785218941   3: 0.019101933346646   2: 0.019101859271203 

training_11362    9: 0.689317560584756   6: 0.144796586909478   1: 0.020748511405761   5: 0.020739431231110   0: 0.020739228832294   2: 0.020734230965520   4: 0.020733117289258   7: 0.020730736769015   3: 0.020730515587747   8: 0.020730080425062 

training_11365    6: 0.578886315574653   9: 0.278126471689025   7: 0.033089955656001   0: 0.015700793116177   5: 0.015700635583670   8: 0.015700369474428   1: 0.015700157865226   4: 0.015698990873135   3: 0.015698173625287   2: 0.015698136542399 

training_11369    4: 0.411771540110977   1: 0.385628420130934   6: 0.025342255659392   0: 0.025325692387637   9: 0.025325037232548   5: 0.025323345614174   7: 0.025323108654498   2: 0.025320608524675   8: 0.025320037321240   3: 0.025319954363924 

training_1137     4: 0.741179617367334   7: 0.092375109054363   5: 0.020812734039628   6: 0.020806844799367   0: 0.020806322204569   1: 0.020805181358518   9: 0.020803827342837   3: 0.020803660983438   8: 0.020803654924424   2: 0.020803047925521 

training_11370    4: 0.304691199714968   9: 0.234905872441857   5: 0.226755266832461   1: 0.122063691044631   6: 0.018600453289832   2: 0.018599546442567   0: 0.018597561349230   7: 0.018595893281439   8: 0.018595624257497   3: 0.018594891345518 

training_11371    6: 0.494130082792508   9: 0.345178600278836   3: 0.020120107594795   8: 0.020088937789843   4: 0.020084153326961   5: 0.020083421249535   7: 0.020080090242658   0: 0.020078454976998   1: 0.020078377406121   2: 0.020077774341745 

training_11372    6: 0.727859358858358   1: 0.113044070786303   7: 0.040253217318128   3: 0.033393199271370   8: 0.014473079540134   9: 0.014202535914147   5: 0.014196387404340   0: 0.014193276755747   4: 0.014192871581115   2: 0.014192002570359 

training_11373    7: 0.512170956244609   6: 0.178928278617708   4: 0.162583799828538   0: 0.042943599167722   1: 0.017247529448176   5: 0.017235300122372   2: 0.017223202265450   9: 0.017223083261286   3: 0.017222337247616   8: 0.017221913796523 

training_11374    5: 0.377032179466524   6: 0.291054531812667   7: 0.134908714425495   8: 0.094278572331239   1: 0.017145846967353   0: 0.017117929409601   4: 0.017116160505021   2: 0.017115569093218   9: 0.017115309426402   3: 0.017115186562480 

training_11377    5: 0.613697314410511   1: 0.140061683829797   8: 0.098244900980264   9: 0.021151826634773   6: 0.021142514942242   4: 0.021141512574910   0: 0.021141430414205   2: 0.021139705927618   7: 0.021139595523406   3: 0.021139514762273 

training_11378    9: 0.519142580765184   5: 0.224074398182850   6: 0.134353667172524   1: 0.017494733378308   4: 0.017494012460445   0: 0.017490179088133   2: 0.017488198415618   7: 0.017487716036838   3: 0.017487663407980   8: 0.017486851092121 

training_11379    6: 0.695618181364856   0: 0.137062910771956   1: 0.063107918037509   3: 0.014905688103503   8: 0.014888997081824   5: 0.014884038934822   9: 0.014883418759576   7: 0.014883397462318   2: 0.014882897192454   4: 0.014882552291183 

training_1138     5: 0.465441520452857   7: 0.387218419426929   0: 0.048453734448103   1: 0.014216540797401   8: 0.014180276476128   6: 0.014112442326882   9: 0.014100378946808   2: 0.014096500918517   4: 0.014091952593941   3: 0.014088233612434 

training_11380    6: 0.667252304521895   0: 0.114535903496529   8: 0.075063895295162   1: 0.037644970363250   5: 0.034803975138666   7: 0.014141057380527   3: 0.014139884424762   2: 0.014139429704494   4: 0.014139296922052   9: 0.014139282752665 

training_11381    5: 0.714970495189477   0: 0.115469391426308   6: 0.059544874427590   2: 0.015761997745038   4: 0.015757537510556   8: 0.015723386922629   1: 0.015696588169519   7: 0.015693103216541   9: 0.015692159233223   3: 0.015690466159120 

training_11384    6: 0.494465127434787   9: 0.265538000393910   1: 0.030003159210613   5: 0.030002196829416   0: 0.030000758216071   8: 0.029999012851234   2: 0.029998470477139   7: 0.029998328348534   4: 0.029997559759399   3: 0.029997386478896 

training_11385    6: 0.566237882837730   5: 0.216055741479498   1: 0.103086215778348   0: 0.016378580193761   7: 0.016375225423396   2: 0.016374128396693   3: 0.016373535688657   8: 0.016373527194905   9: 0.016372752270118   4: 0.016372410736893 

training_11386    1: 0.645308563629797   6: 0.220674325579218   8: 0.035644023568614   4: 0.014067831312835   5: 0.014061469781352   0: 0.014051013035096   9: 0.014048691239906   2: 0.014048112211903   7: 0.014048025598344   3: 0.014047944042936 

training_11387    6: 0.840533183281005   1: 0.035364077496900   9: 0.015569028091649   0: 0.015541140418262   2: 0.015512599685332   7: 0.015511106905812   5: 0.015506632135180   8: 0.015487796541720   4: 0.015487219535658   3: 0.015487215908482 

training_11388    6: 0.442151676449185   9: 0.236781356100063   5: 0.214588262006840   2: 0.025992555083629   8: 0.013636987243460   4: 0.013472038235393   0: 0.013378149739927   1: 0.013338040828160   3: 0.013330554222871   7: 0.013330380090470 

training_11390    6: 0.830321566692535   9: 0.045537449462932   0: 0.028689635149455   5: 0.013658415259738   3: 0.013636893503243   1: 0.013632477282808   4: 0.013631454205044   8: 0.013630903987401   7: 0.013630771887061   2: 0.013630432569784 

training_11392    6: 0.606565341300108   0: 0.177353663585501   7: 0.118463619924985   3: 0.024933553495469   1: 0.012119644238768   8: 0.012114132851506   9: 0.012112792250274   2: 0.012112572283357   5: 0.012112509507782   4: 0.012112170562249 

training_11393    1: 0.493805621880752   5: 0.345000648078372   6: 0.020153787117799   2: 0.020153611649820   9: 0.020149310805697   0: 0.020149147431552   4: 0.020147764900031   7: 0.020146743052245   3: 0.020146726669934   8: 0.020146638413799 

training_11394    4: 0.507974126234369   6: 0.250457862778917   5: 0.030203295436570   7: 0.030198280097911   1: 0.030195986061056   0: 0.030195115909292   8: 0.030194882830512   9: 0.030194477335876   2: 0.030193010977042   3: 0.030192962338455 

training_11395    0: 0.713603140413912   7: 0.162202971443987   6: 0.015609599814458   5: 0.015531718750558   1: 0.015528170771164   4: 0.015518355858927   3: 0.015504005514050   2: 0.015502034014825   9: 0.015501985722879   8: 0.015498017695240 

training_11396    5: 0.720681325112452   3: 0.073116828013365   6: 0.060431063553904   0: 0.020861163450483   1: 0.020829373396572   4: 0.020821395458672   8: 0.020818687254988   2: 0.020813894655896   7: 0.020813183302383   9: 0.020813085801285 

training_11397    6: 0.568696455295591   0: 0.290646297360847   3: 0.033528128248474   9: 0.030011331618300   1: 0.012893176101563   5: 0.012852950823219   4: 0.012843563818632   8: 0.012842798888171   2: 0.012842737767746   7: 0.012842560077457 

training_11399    6: 0.691519023491865   5: 0.122693129632319   1: 0.077437818772101   0: 0.015484198508617   7: 0.015478520042377   9: 0.015478148940278   3: 0.015477829454495   8: 0.015477393441294   2: 0.015477107574459   4: 0.015476830142194 

training_11400    5: 0.679963856078650   1: 0.106603590252189   0: 0.051120231080315   9: 0.048090160768941   8: 0.019134829151339   6: 0.019022645886584   4: 0.019019036148316   2: 0.019018110246114   7: 0.019013888591302   3: 0.019013651796250 

training_11402    1: 0.598991759980445   0: 0.242673302807824   6: 0.019796290383014   5: 0.019794242079859   4: 0.019791413609440   9: 0.019791214398150   3: 0.019791014596540   7: 0.019790467789704   8: 0.019790465262532   2: 0.019789829092493 

training_11403    1: 0.275310793293719   6: 0.212480519316294   9: 0.190895604757761   5: 0.146044742555588   8: 0.083207073714918   0: 0.031896516186201   2: 0.015059572700309   4: 0.015035484788856   3: 0.015035183706314   7: 0.015034508980041 

training_11405    0: 0.817799365068467   6: 0.020260091189495   1: 0.020244893351316   5: 0.020244188765584   4: 0.020242818706815   8: 0.020241965589717   9: 0.020241739521501   2: 0.020241724264453   7: 0.020241664368087   3: 0.020241549174565 

training_11406    9: 0.381327309671532   6: 0.317048889521095   2: 0.183668227132775   8: 0.027062309857473   5: 0.022464774363345   1: 0.013753025404376   0: 0.013715085352143   3: 0.013678737076466   4: 0.013640844187748   7: 0.013640797433046 

training_11407    5: 0.524654058886726   0: 0.129704191374858   1: 0.124450127468974   7: 0.075727780330308   6: 0.055813693486833   4: 0.017932212736760   3: 0.017931032314600   2: 0.017930189417641   8: 0.017928530088246   9: 0.017928183895053 

training_11413    5: 0.457529463677741   7: 0.242025710269036   6: 0.160599451487390   0: 0.036676794948747   3: 0.017206294264970   9: 0.017198794894218   1: 0.017195579353187   8: 0.017192875075635   4: 0.017188602280017   2: 0.017186433749059 

training_11415    6: 0.551842721006611   7: 0.276235565032474   5: 0.021492708793124   0: 0.021491689262625   1: 0.021489953231400   8: 0.021489850361446   4: 0.021489702121375   3: 0.021489376147666   9: 0.021489369298613   2: 0.021489064744664 

training_11416    5: 0.657728864279292   9: 0.205653389916319   6: 0.017086697048047   4: 0.017079658798860   1: 0.017075741112527   0: 0.017075732133936   7: 0.017075271351856   8: 0.017075028566734   2: 0.017074826388212   3: 0.017074790404217 

training_11417    6: 0.763728121263660   0: 0.026260898977807   1: 0.026253247685352   9: 0.026251712675029   8: 0.026251452033169   7: 0.026251437818159   2: 0.026250926609314   5: 0.026250842634521   3: 0.026250785039834   4: 0.026250575263154 

training_11418    7: 0.371059966196228   5: 0.258831753633867   6: 0.220434005694972   0: 0.054221251748847   1: 0.015915139672075   4: 0.015911240312268   9: 0.015908097324654   8: 0.015907752408360   2: 0.015905533402763   3: 0.015905259605967 

training_11420    6: 0.762721607081130   0: 0.026370946396586   5: 0.026365649943331   4: 0.026364474899105   9: 0.026363829850825   8: 0.026363351298737   1: 0.026363349934000   7: 0.026362765231984   2: 0.026362414026894   3: 0.026361611337409 

training_11421    6: 0.618176208242810   1: 0.167330804129448   0: 0.026816622458888   9: 0.026811402833017   7: 0.026811133131163   2: 0.026811109613320   5: 0.026811106470941   8: 0.026811001311672   4: 0.026810314500784   3: 0.026810297307957 

training_11422    8: 0.715385645789478   5: 0.031630434513647   4: 0.031624789138826   6: 0.031624744801224   0: 0.031623627802543   9: 0.031622400247728   3: 0.031622214524945   1: 0.031622177168104   7: 0.031622100698813   2: 0.031621865314692 

training_11424    0: 0.422391738688239   4: 0.373403608859903   5: 0.025533296786117   6: 0.025525264714552   8: 0.025524994738575   1: 0.025524680891573   7: 0.025524417668697   3: 0.025524062901318   2: 0.025524035384308   9: 0.025523899366718 

training_11425    8: 0.790111295196409   2: 0.064571235594982   6: 0.018168267472643   0: 0.018168176992474   1: 0.018164503374870   5: 0.018163869597714   9: 0.018163668105045   7: 0.018163166589273   4: 0.018163036532253   3: 0.018162780544336 

training_11427    6: 0.812145081235891   7: 0.083690634201926   8: 0.013167889675819   1: 0.013009645616885   2: 0.013003785294300   0: 0.012997081085176   5: 0.012996668710320   9: 0.012996543509550   4: 0.012996418686092   3: 0.012996251984041 

training_11428    5: 0.514066921412744   3: 0.295059266783673   6: 0.058556107120914   1: 0.018903184421992   0: 0.018903035376472   8: 0.018902573562872   4: 0.018902429329263   7: 0.018902308391082   9: 0.018902113817741   2: 0.018902059783248 

training_11429    4: 0.418947541773200   8: 0.367094332823526   5: 0.026753715180303   3: 0.026743671450323   2: 0.026743527850430   0: 0.026743524639476   6: 0.026743462294166   7: 0.026743419928033   9: 0.026743410413901   1: 0.026743393646643 

training_1143     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_11430    6: 0.632236740388192   0: 0.237561986828980   3: 0.035139779295530   5: 0.013589748293688   1: 0.013580253443245   7: 0.013578489132778   9: 0.013578446690131   8: 0.013578311024856   2: 0.013578228021874   4: 0.013578016880726 

training_11431    0: 0.410043356665170   8: 0.368904768711198   9: 0.058460010299813   1: 0.055267538370035   7: 0.017962529652494   2: 0.017882118435323   5: 0.017880540203550   6: 0.017872102660016   4: 0.017866657542531   3: 0.017860377459870 

training_11433    5: 0.661675623814663   4: 0.112452210876704   3: 0.073113321189709   6: 0.021825806605595   0: 0.021823826587104   1: 0.021822859932000   2: 0.021822075155334   9: 0.021821613181604   7: 0.021821487674149   8: 0.021821174983138 

training_11435    5: 0.413756671449036   7: 0.367933334177661   9: 0.071653161433433   3: 0.021177501599916   1: 0.021091609112774   0: 0.021078461492556   4: 0.020994429951093   6: 0.020808156649567   2: 0.020753995763008   8: 0.020752678370956 

training_11436    6: 0.809687079342306   1: 0.051600390611306   8: 0.034772777608148   9: 0.014853935850962   5: 0.014850177270311   0: 0.014847773757659   7: 0.014847422855307   4: 0.014846946948904   3: 0.014846806928184   2: 0.014846688826915 

training_11437    6: 0.776379160975526   1: 0.101995330949541   0: 0.015214871686661   3: 0.015204127030566   2: 0.015203135955204   5: 0.015200968536863   4: 0.015200713793030   9: 0.015200673503680   7: 0.015200536896447   8: 0.015200480672481 

training_11440    5: 0.533997646646574   6: 0.280255023183978   4: 0.063007084468194   1: 0.017539856446914   0: 0.017536995064148   9: 0.017533118923657   8: 0.017532755413436   7: 0.017532616247933   3: 0.017532612147054   2: 0.017532291458112 

training_11441    3: 0.434709704054538   6: 0.226896306059804   2: 0.160834161538174   5: 0.066707829333524   1: 0.018482877964812   0: 0.018476510981889   4: 0.018475212658302   9: 0.018473470750765   8: 0.018472132079401   7: 0.018471794578790 

training_11443    5: 0.597785768564956   3: 0.237027112689550   4: 0.020649909239703   6: 0.020648781089548   2: 0.020648750318850   1: 0.020648676164100   0: 0.020648514084477   8: 0.020647642804240   7: 0.020647444939603   9: 0.020647400104974 

training_11444    6: 0.827702648076124   3: 0.043727986585960   0: 0.016072737954740   1: 0.016071598466396   5: 0.016071377478959   4: 0.016071068484985   9: 0.016070836892563   2: 0.016070603731568   7: 0.016070576125723   8: 0.016070566202983 

training_11445    6: 0.675882983332297   7: 0.168638804905666   0: 0.019435599560192   1: 0.019435215648718   8: 0.019434980655541   5: 0.019434849496096   9: 0.019434742432178   4: 0.019434397580487   2: 0.019434313758900   3: 0.019434112629926 

training_11446    6: 0.777390399636002   3: 0.068747640353030   0: 0.019237717808973   1: 0.019233352736176   9: 0.019232107096097   5: 0.019232009563731   8: 0.019231901636680   7: 0.019231753994407   4: 0.019231621999981   2: 0.019231495174923 

training_11447    6: 0.689896598512064   0: 0.173697626187095   1: 0.050215682200766   2: 0.012339115436586   5: 0.012309112816762   8: 0.012308919075892   9: 0.012308415834218   7: 0.012308228558015   4: 0.012308197292453   3: 0.012308104086149 

training_11449    1: 0.771312671083805   5: 0.076075877212842   6: 0.019089690544632   0: 0.019077146543980   4: 0.019076255802845   3: 0.019075412526469   2: 0.019073772359841   7: 0.019073348771713   9: 0.019073085482235   8: 0.019072739671637 

training_11450    6: 0.423711625198781   0: 0.406465288296465   3: 0.051277108980728   1: 0.016955191675178   5: 0.016934478606657   7: 0.016931700941541   9: 0.016931461765017   2: 0.016931135896073   8: 0.016931017984269   4: 0.016930990655290 

training_11451    5: 0.767219052857278   6: 0.109080089355836   1: 0.015468654263023   2: 0.015465693275935   0: 0.015464952294853   7: 0.015461115629933   4: 0.015460152028636   8: 0.015460148720649   3: 0.015460097175262   9: 0.015460044398595 

training_11452    4: 0.728525157113049   7: 0.079816194354221   5: 0.023963715365530   6: 0.023957364914774   0: 0.023956863887448   1: 0.023956789504783   8: 0.023956150924243   3: 0.023956092235958   2: 0.023955860156500   9: 0.023955811543494 

training_11455    6: 0.680234237354023   2: 0.152813103862965   3: 0.037792431009539   1: 0.037415360542063   0: 0.015313218193788   5: 0.015302557292115   4: 0.015287886900171   7: 0.015284960494496   8: 0.015278335985588   9: 0.015277908365253 

training_11459    6: 0.696887599118220   4: 0.102624948085175   7: 0.079493257893108   8: 0.040899964594204   1: 0.020970590084950   0: 0.011842902764363   9: 0.011822121963015   2: 0.011821879293108   5: 0.011818861605132   3: 0.011817874598725 

training_11460    6: 0.663987880075868   0: 0.202395605045721   8: 0.016797195404112   1: 0.016691007802251   9: 0.016689095843090   7: 0.016688117969316   3: 0.016688100808627   2: 0.016688019876975   4: 0.016687628855791   5: 0.016687348318248 

training_11461    6: 0.789984711526322   9: 0.067327247565784   1: 0.017839286301633   5: 0.017836769220041   0: 0.017836031115658   8: 0.017835542554789   7: 0.017835171990904   3: 0.017835153769530   4: 0.017835113386602   2: 0.017834972568737 

training_11462    6: 0.797778475590578   3: 0.037213787264271   0: 0.034592449854663   1: 0.033103944527265   5: 0.016224322544859   8: 0.016218761797701   4: 0.016217420201601   2: 0.016217125683559   9: 0.016216905037457   7: 0.016216807498046 

training_11464    1: 0.430295425414705   2: 0.360668008941917   0: 0.068757723976628   6: 0.020472376896720   5: 0.019980964184559   4: 0.019965518361092   7: 0.019965139640780   9: 0.019964974053432   8: 0.019964938248119   3: 0.019964930282049 

training_11465    2: 0.518883266130701   3: 0.199498472220607   6: 0.154747934782982   0: 0.018273092243690   5: 0.018103336334475   1: 0.018102986119086   4: 0.018099137637080   9: 0.018098231323874   8: 0.018096874508083   7: 0.018096668699421 

training_11466    5: 0.543464498266643   6: 0.188891466832456   7: 0.133053401234407   4: 0.031315096790721   9: 0.017228203113129   2: 0.017223691822643   0: 0.017207279838788   8: 0.017206021933864   1: 0.017205294414705   3: 0.017205045752644 

training_11468    1: 0.735815191385498   6: 0.126562244225565   0: 0.017206743743197   3: 0.017205584130527   9: 0.017205375601799   5: 0.017205121189975   4: 0.017200602715632   7: 0.017199916516908   8: 0.017199822495062   2: 0.017199397995838 

training_11469    1: 0.563759032600422   0: 0.221325049364843   6: 0.026874698983110   8: 0.026866072886241   5: 0.026864436129440   2: 0.026863761658812   7: 0.026862631754022   4: 0.026862243375274   9: 0.026861381476580   3: 0.026860691771254 

training_1147     6: 0.825213238925611   5: 0.019422069885390   0: 0.019421319344066   9: 0.019421108107045   7: 0.019420759562212   8: 0.019420596101540   1: 0.019420451302270   4: 0.019420367661456   2: 0.019420122442967   3: 0.019419966667443 

training_11470    4: 0.797581183813088   5: 0.022499279551858   0: 0.022492565314291   6: 0.022490842580493   7: 0.022489671074759   3: 0.022489424768578   9: 0.022489416278576   8: 0.022489291709385   2: 0.022489245632918   1: 0.022489079276054 

training_11475    5: 0.553519113705412   2: 0.293070664502541   4: 0.019177856883443   1: 0.019177393140699   6: 0.019177154240303   9: 0.019177055761024   8: 0.019176697959817   0: 0.019176630477101   7: 0.019173728230130   3: 0.019173705099531 

training_11476    4: 0.491316534697655   5: 0.318191503210594   1: 0.023813332611346   0: 0.023812249792717   2: 0.023812133319359   6: 0.023811558592886   3: 0.023811472995706   9: 0.023810656956837   7: 0.023810319749440   8: 0.023810238073459 

training_11477    0: 0.747789943894948   1: 0.069640716435073   3: 0.022847416660252   9: 0.022833948966039   5: 0.022817379522145   4: 0.022817186864618   2: 0.022814127479561   6: 0.022813539442916   8: 0.022813220423651   7: 0.022812520310797 

training_11478    5: 0.505580067726542   7: 0.303132754681586   4: 0.023914572936039   0: 0.023910798086717   6: 0.023910572816585   1: 0.023910455477858   2: 0.023910238093793   8: 0.023910230336861   3: 0.023910191679598   9: 0.023910118164420 

training_11479    5: 0.758344319339283   4: 0.075495762204064   1: 0.020882549387660   0: 0.020785813781202   2: 0.020783337211642   8: 0.020743880915263   6: 0.020741698549835   3: 0.020741081018559   9: 0.020740907660857   7: 0.020740649931635 

training_1148     6: 0.629416357035426   0: 0.194483103639194   7: 0.075371757666483   1: 0.014400601046983   5: 0.014388944794718   9: 0.014388295952841   8: 0.014388104518634   3: 0.014387676005750   4: 0.014387593028083   2: 0.014387566311889 

training_11481    5: 0.760669020748854   4: 0.026595886408678   9: 0.026592465267536   8: 0.026592005948190   3: 0.026591865893491   6: 0.026591823573482   2: 0.026591779234214   7: 0.026591752842058   0: 0.026591724394856   1: 0.026591675688642 

training_11484    7: 0.624756786709941   6: 0.161209516065805   5: 0.026767839467338   4: 0.026755068169912   2: 0.026754926593674   0: 0.026754699424919   1: 0.026753607542989   9: 0.026750062744030   3: 0.026749904374520   8: 0.026747588906872 

training_11487    6: 0.708573287512648   0: 0.172307072563611   1: 0.043048373627471   8: 0.023149565930859   3: 0.008991920673003   7: 0.008829258226385   5: 0.008776792787706   9: 0.008775553861973   4: 0.008774274106116   2: 0.008773900710228 

training_11488    1: 0.730276010245443   6: 0.029974826688184   8: 0.029973127810416   2: 0.029973030958817   7: 0.029970316431667   0: 0.029969670189746   9: 0.029966197867134   5: 0.029966062889142   4: 0.029965847850868   3: 0.029964909068583 

training_11490    6: 0.649254273232080   0: 0.184513349411973   1: 0.051839029939909   7: 0.038625634818957   2: 0.025714722873669   5: 0.010221610875951   8: 0.009974698297957   3: 0.009957511357647   9: 0.009951133206455   4: 0.009948035985402 

training_11491    6: 0.635139625601402   2: 0.191836441395945   9: 0.067096999125721   0: 0.022612092094525   7: 0.015094086368777   1: 0.013665237036747   5: 0.013640461622194   8: 0.013640342234756   4: 0.013637726197087   3: 0.013636988322846 

training_11492    1: 0.518963165396885   0: 0.326302771254520   2: 0.050251022017547   6: 0.040555251403863   5: 0.011784460327590   8: 0.010429208340680   3: 0.010429160420763   7: 0.010429060382217   9: 0.010428751048149   4: 0.010427149407785 

training_11494    5: 0.489767545486880   4: 0.283021170067680   8: 0.086252210320914   6: 0.020141286673679   7: 0.020137018046007   0: 0.020136904294320   1: 0.020136836882254   3: 0.020135806915476   9: 0.020135634055883   2: 0.020135587256907 

training_11496    6: 0.556137998798335   9: 0.221606123040587   0: 0.027784371245714   1: 0.027783108705334   3: 0.027781721627267   5: 0.027781412705610   8: 0.027781374956568   2: 0.027781326625297   7: 0.027781312780499   4: 0.027781249514791 

training_11497    1: 0.684039273011956   5: 0.164969142300674   6: 0.033414530941260   0: 0.016803056671135   9: 0.016797413438662   4: 0.016796877570602   8: 0.016795450199403   7: 0.016795402320037   2: 0.016795268335863   3: 0.016793585210408 

training_11498    6: 0.625876836140750   1: 0.258064702685431   0: 0.029519660750386   7: 0.023617668341863   8: 0.016597416176585   2: 0.009270161884973   9: 0.009266596991904   3: 0.009264338171657   5: 0.009262158946216   4: 0.009260459910235 

training_11499    5: 0.777903146235943   1: 0.024710634418908   6: 0.024685541787709   0: 0.024676489519030   4: 0.024673610143186   8: 0.024670374622316   3: 0.024670117516185   9: 0.024670058311514   7: 0.024670030162219   2: 0.024669997282989 

training_11500    4: 0.726764490918629   5: 0.030364511953943   1: 0.030359128173220   3: 0.030358979472151   8: 0.030358936769880   2: 0.030358878144246   0: 0.030358860514253   6: 0.030358771849549   9: 0.030358751623408   7: 0.030358690580722 

training_11501    1: 0.442048916764406   4: 0.337645477325536   6: 0.027546075179050   5: 0.027543440187097   0: 0.027541363238128   8: 0.027536221650547   7: 0.027535718697427   9: 0.027534774089750   3: 0.027534714972004   2: 0.027533297896054 

training_11503    3: 0.438013131881876   5: 0.357839780897298   4: 0.025523964170974   1: 0.025518595110078   6: 0.025517692188323   2: 0.025517438910094   8: 0.025517410837044   7: 0.025517369844795   0: 0.025517359800255   9: 0.025517256359262 

training_11504    0: 0.266083297133985   6: 0.192668478723961   9: 0.178366255821115   1: 0.152166588643061   4: 0.148784276310205   2: 0.017761964107091   8: 0.011424829658724   5: 0.011167420509692   3: 0.010788893976562   7: 0.010787995115604 

training_11505    4: 0.325597105492751   6: 0.292483146012181   1: 0.272855720587285   5: 0.015584278696278   0: 0.015582127386552   8: 0.015580091374276   9: 0.015579942152609   2: 0.015579847371479   7: 0.015578906691306   3: 0.015578834235283 

training_11506    1: 0.773438120029775   0: 0.067379047372920   5: 0.019956658059724   4: 0.019927143405206   6: 0.019889537546565   3: 0.019883414113700   8: 0.019882909256974   7: 0.019881776187717   9: 0.019881048255205   2: 0.019880345772214 

training_11507    6: 0.672492969489196   0: 0.170058158219014   2: 0.036239117860006   7: 0.035370763957044   1: 0.014321658765464   5: 0.014309886124997   9: 0.014302036595096   3: 0.014301927766696   4: 0.014301890839182   8: 0.014301590383304 

training_11508    0: 0.628658648729867   7: 0.178045051821728   2: 0.061939267758969   1: 0.018813185995688   5: 0.018786451024062   6: 0.018760686481031   8: 0.018753770411983   4: 0.018749267196295   3: 0.018746974665613   9: 0.018746695914764 

training_1151     6: 0.408474235577386   7: 0.392571197982255   5: 0.024873443066378   1: 0.024872171591519   4: 0.024869603784070   8: 0.024869136634822   0: 0.024868941244883   3: 0.024868228015169   2: 0.024866927491610   9: 0.024866114611909 

training_11510    5: 0.553225474901377   0: 0.272801569455035   9: 0.021752619907633   1: 0.021747356554057   6: 0.021746092826298   2: 0.021745861972776   3: 0.021745422502777   4: 0.021745407758060   8: 0.021745097435030   7: 0.021745096686957 

training_11514    4: 0.764904580844417   6: 0.050130654929067   1: 0.023423378951973   0: 0.023092175777829   8: 0.023083129858989   5: 0.023078310433107   7: 0.023075429301796   2: 0.023071714302487   9: 0.023071345614951   3: 0.023069279985384 

training_11515    5: 0.782073221084979   1: 0.024240708160954   0: 0.024227066384719   2: 0.024214739863535   6: 0.024210828490934   9: 0.024208805855942   4: 0.024206520231767   3: 0.024206245657975   7: 0.024206149737138   8: 0.024205714532058 

training_11519    6: 0.619591195460468   3: 0.154405088644030   0: 0.103352236579674   1: 0.017669963589980   8: 0.017550977190214   7: 0.017495029110305   5: 0.017484693030127   4: 0.017484062586520   9: 0.017483420898096   2: 0.017483332910586 

training_1152     6: 0.496072793187339   5: 0.361521155488085   0: 0.054655701192512   8: 0.012574103896739   9: 0.012530684614853   4: 0.012529896609667   1: 0.012529326306487   7: 0.012528893147811   2: 0.012528814051968   3: 0.012528631504539 

training_11522    5: 0.450147120790218   8: 0.279408286425719   6: 0.108812467161552   0: 0.040839271017983   4: 0.020134335289146   1: 0.020133815196365   2: 0.020133102849707   9: 0.020131594199625   7: 0.020130507080585   3: 0.020129499989099 

training_11523    4: 0.402409797073900   5: 0.276038729692132   6: 0.190599711990374   0: 0.018713536078651   1: 0.018710458818705   9: 0.018706906262822   2: 0.018705553826636   7: 0.018705268361709   3: 0.018705197748575   8: 0.018704840146495 

training_11526    4: 0.721912767121318   6: 0.098366338735962   5: 0.022481988184188   1: 0.022475249009787   0: 0.022467994869299   3: 0.022463185675839   8: 0.022460302524436   7: 0.022457623827398   9: 0.022457275913169   2: 0.022457274138604 

training_11527    4: 0.632231474597228   5: 0.157701607063307   8: 0.065375853718887   6: 0.020673810272539   0: 0.020672938477183   1: 0.020672414019719   9: 0.020668349330017   2: 0.020668247218069   3: 0.020668037972420   7: 0.020667267330632 

training_11528    5: 0.534301638798544   1: 0.178807095752775   6: 0.146320195917094   0: 0.020084136189630   8: 0.020083886026055   4: 0.020081987612747   2: 0.020081419723353   9: 0.020079961109620   3: 0.020079901213876   7: 0.020079777656304 

training_11529    4: 0.764449422828655   5: 0.026176225686911   0: 0.026173278826254   6: 0.026172684703846   1: 0.026171875896384   9: 0.026171854107651   7: 0.026171349518529   2: 0.026171143132449   8: 0.026171124125316   3: 0.026171041174006 

training_1153     9: 0.493105896447457   1: 0.336386752048097   0: 0.032917851753362   3: 0.026113106637952   6: 0.018626740806744   7: 0.018588399718403   5: 0.018579438665225   8: 0.018563780512763   2: 0.018563124461920   4: 0.018554908948077 

training_11536    6: 0.566446205653916   0: 0.307870306281659   5: 0.038297225302437   7: 0.012511252121331   8: 0.012486455425607   9: 0.012479325158217   1: 0.012477544809762   2: 0.012477275508546   4: 0.012477244305677   3: 0.012477165432848 

training_11539    0: 0.628394670033550   6: 0.190789506220264   7: 0.051919887917744   9: 0.034538926596064   1: 0.015802669357469   5: 0.015716871554823   4: 0.015711878833172   2: 0.015710846199280   8: 0.015707621852299   3: 0.015707121435336 

training_1154     6: 0.675180234481459   8: 0.170596533097940   1: 0.019281908432517   7: 0.019279950745525   5: 0.019278930026987   0: 0.019278692226809   9: 0.019277439075361   2: 0.019275856607636   4: 0.019275361537452   3: 0.019275093768314 

training_11540    5: 0.569786177333080   0: 0.238528084413090   4: 0.046408734605311   3: 0.020761178923705   6: 0.020755509181479   1: 0.020754086222011   9: 0.020752293154083   8: 0.020751492345111   7: 0.020751315509425   2: 0.020751128312704 

training_11541    6: 0.845160544037274   0: 0.039710967372691   1: 0.026648435675432   7: 0.012642481265170   9: 0.012641180962245   5: 0.012639607516033   8: 0.012639477619713   2: 0.012639218454242   4: 0.012639074207070   3: 0.012639012890130 

training_11543    4: 0.790301974059824   5: 0.023307499267006   0: 0.023300236192795   1: 0.023299030802199   7: 0.023298772940381   6: 0.023298703505318   8: 0.023298635094333   9: 0.023298487129491   3: 0.023298400618869   2: 0.023298260389784 

training_11544    6: 0.635268250633793   0: 0.207293626968477   9: 0.046004424510630   1: 0.015920966258255   7: 0.015920317232187   5: 0.015919636081973   2: 0.015918385753056   4: 0.015918358191063   8: 0.015918032866824   3: 0.015918001503742 

training_11545    6: 0.679496261182257   0: 0.194586109252044   9: 0.044489652371050   3: 0.011639877555970   1: 0.011634908668850   7: 0.011632530764242   5: 0.011630671623023   8: 0.011630400460607   4: 0.011629855335070   2: 0.011629732786888 

training_11546    6: 0.490737591434160   0: 0.300351337644274   9: 0.091079873873761   1: 0.016853211763839   7: 0.016830162439952   5: 0.016829997857789   8: 0.016829681234260   4: 0.016829426795827   2: 0.016829372647133   3: 0.016829344309006 

training_11549    5: 0.789306336005785   4: 0.023416169645446   6: 0.023409926263556   7: 0.023409800819163   0: 0.023409789673381   8: 0.023409646165811   3: 0.023409603292781   9: 0.023409580121831   2: 0.023409579693011   1: 0.023409568319235 

training_11550    4: 0.645857601785421   6: 0.148349538999620   1: 0.054952237194065   9: 0.021568903197888   0: 0.021561750413152   8: 0.021546598034580   5: 0.021543852955060   3: 0.021540435247993   2: 0.021539738915693   7: 0.021539343256529 

training_11551    6: 0.430529516957519   0: 0.398832787066112   3: 0.050936834044112   1: 0.017120471722430   5: 0.017099361917640   7: 0.017096631693481   9: 0.017096396227835   2: 0.017096070679962   8: 0.017095998645559   4: 0.017095931045350 

training_11553    4: 0.520056046625340   8: 0.250480488081560   5: 0.087883588222083   6: 0.020252154365321   0: 0.020227617399837   1: 0.020224853096128   9: 0.020223249191624   2: 0.020218229366408   3: 0.020217311990436   7: 0.020216461661262 

training_11554    6: 0.474457312316323   1: 0.267557091287271   0: 0.032258391874875   8: 0.032247219467989   7: 0.032246920842389   5: 0.032246784318286   9: 0.032246742967286   3: 0.032246586543170   4: 0.032246492590953   2: 0.032246457791458 

training_11555    6: 0.725471710138979   1: 0.163717386552129   0: 0.013853299325083   5: 0.013852786794787   7: 0.013851609785370   8: 0.013851125931165   9: 0.013850860877158   4: 0.013850446633866   3: 0.013850433395343   2: 0.013850340566120 

training_11558    6: 0.526966992006185   1: 0.214400921963435   3: 0.158021017938660   9: 0.014435301921303   0: 0.014375094059228   5: 0.014363823104563   4: 0.014361965641590   8: 0.014358592351808   7: 0.014358247600571   2: 0.014358043412658 

training_11559    6: 0.533918939503667   2: 0.335229757139091   0: 0.016401404787000   1: 0.016388856070627   5: 0.016345718812219   9: 0.016344623767739   7: 0.016344410031155   4: 0.016342419109811   3: 0.016341983773485   8: 0.016341887005205 

training_1156     6: 0.707500987705069   1: 0.123085866721649   0: 0.063909101374950   2: 0.026915172585928   3: 0.013144565669337   9: 0.013092723786684   5: 0.013088365507354   8: 0.013088126964852   4: 0.013087653994129   7: 0.013087435690048 

training_11563    5: 0.776441863856341   6: 0.024852937918188   0: 0.024845740873504   1: 0.024841843264188   4: 0.024836826868182   9: 0.024836361552638   3: 0.024836289539341   2: 0.024836253158855   7: 0.024835947577211   8: 0.024835935391552 

training_11564    5: 0.769755444689428   4: 0.025585719024720   2: 0.025582513436446   8: 0.025582485141688   3: 0.025582408089068   9: 0.025582394256752   6: 0.025582299523546   7: 0.025582269343839   0: 0.025582257671857   1: 0.025582208822656 

training_11565    4: 0.599543952178199   6: 0.158484391062761   5: 0.030252187858618   7: 0.030248442120956   8: 0.030245316546190   3: 0.030245234743099   9: 0.030245220460116   0: 0.030245145751937   2: 0.030245108798971   1: 0.030245000479151 

training_11566    5: 0.824217805985393   7: 0.056491136822361   6: 0.014925610720261   4: 0.014911235646674   8: 0.014909467324220   0: 0.014909426147916   3: 0.014909162678606   9: 0.014908908901642   1: 0.014908866513869   2: 0.014908379259058 

training_11567    5: 0.627975034651650   6: 0.132052803609332   2: 0.111879984158206   3: 0.018370287329709   1: 0.018296761277275   4: 0.018288114668139   8: 0.018285262199810   0: 0.018285072738163   9: 0.018283478956791   7: 0.018283200410925 

training_11568    5: 0.808017725717315   6: 0.021338833534636   4: 0.021334565442182   1: 0.021333121000240   0: 0.021332062624867   2: 0.021329457965518   8: 0.021328740566130   9: 0.021328568179334   3: 0.021328464225493   7: 0.021328460744285 

training_11569    5: 0.829289713024878   4: 0.018971559156235   6: 0.018967958242724   0: 0.018967535880522   1: 0.018967345934308   9: 0.018967251226976   7: 0.018967201405798   2: 0.018967165343388   8: 0.018967158826707   3: 0.018967110958465 

training_1157     5: 0.564497579986442   1: 0.239378962611986   4: 0.024520457873204   2: 0.024519473230395   0: 0.024514977664069   6: 0.024514836354095   7: 0.024514192250359   8: 0.024513322345293   9: 0.024513127058325   3: 0.024513070625833 

training_11570    4: 0.774591375745212   5: 0.025052074880919   6: 0.025045779168271   0: 0.025044762412376   1: 0.025044502582179   8: 0.025044458059856   9: 0.025044299708124   3: 0.025044287385299   7: 0.025044273126435   2: 0.025044186931330 

training_11571    5: 0.454370077931805   2: 0.305023100788884   3: 0.030077050284814   4: 0.030076572539475   0: 0.030075721471707   8: 0.030075624024393   6: 0.030075614399552   1: 0.030075556648848   7: 0.030075381491742   9: 0.030075300418779 

training_11572    5: 0.430639286683760   9: 0.318377206606563   3: 0.031374283517924   4: 0.031373581408510   8: 0.031372746967064   0: 0.031372736130299   6: 0.031372730258853   2: 0.031372495059470   1: 0.031372483629328   7: 0.031372449738228 

training_11574    6: 0.647279479423600   8: 0.112095372669627   1: 0.111879916592921   5: 0.043408376816168   0: 0.014226091603947   3: 0.014223603026619   9: 0.014221981482209   4: 0.014221972075541   7: 0.014221609705734   2: 0.014221596603633 

training_11575    1: 0.415373991961686   6: 0.254138303982998   0: 0.229110804785772   5: 0.014523768507085   9: 0.014481585228234   8: 0.014475533302510   4: 0.014475421418058   2: 0.014473666493915   3: 0.014473473039997   7: 0.014473451279745 

training_11578    4: 0.763486180757731   5: 0.026282756247678   6: 0.026279283530057   1: 0.026279101640201   8: 0.026279075924816   0: 0.026279037160876   3: 0.026278742592339   9: 0.026278701365649   2: 0.026278584939889   7: 0.026278535840765 

training_11579    1: 0.499890543723563   6: 0.233118259029993   3: 0.066043646693433   5: 0.045142380520537   7: 0.043432300043449   2: 0.041683862758695   0: 0.017692446485731   4: 0.017675602015976   8: 0.017660506718257   9: 0.017660452010366 

training_1158     6: 0.801943848736740   9: 0.022007709908153   8: 0.022007218111001   5: 0.022006978412234   0: 0.022006262484201   1: 0.022006248504562   7: 0.022005827399052   2: 0.022005378678696   3: 0.022005285464370   4: 0.022005242300991 

training_11580    6: 0.520537129036687   1: 0.273809690285881   3: 0.129560537678783   9: 0.010893378148932   0: 0.010881982001720   5: 0.010866315485598   4: 0.010864610562148   8: 0.010862311206140   7: 0.010862102945732   2: 0.010861942648380 

training_11584    3: 0.674089768775305   1: 0.036248956573397   0: 0.036238080325615   6: 0.036225759785489   7: 0.036205447636939   4: 0.036202661070211   5: 0.036201487401943   9: 0.036201322696698   2: 0.036193693857114   8: 0.036192821877288 

training_11587    6: 0.703062792983152   1: 0.084003899301360   0: 0.064284691195520   3: 0.040534671013199   2: 0.027808495825751   7: 0.026606759342473   5: 0.013430627459930   8: 0.013422808220014   4: 0.013422765515358   9: 0.013422489143242 

training_11588    4: 0.806269785246713   8: 0.021536127175066   5: 0.021527864543511   6: 0.021527432464404   0: 0.021524726073385   9: 0.021524076353988   2: 0.021523683710603   7: 0.021522339505450   3: 0.021521986505474   1: 0.021521978421406 

training_1159     1: 0.543021698259202   8: 0.315410728713367   5: 0.017699213100533   6: 0.017696638893543   0: 0.017696161499966   4: 0.017695885092389   9: 0.017695277732566   3: 0.017695121131152   2: 0.017694781013948   7: 0.017694494563333 

training_11597    0: 0.516413291613961   3: 0.190068389253769   1: 0.138132403963435   4: 0.048555180434109   6: 0.017807546710625   9: 0.017807156347516   5: 0.017805383499503   8: 0.017804613069653   7: 0.017803231263383   2: 0.017802803844046 

training_11598    4: 0.428359626349252   6: 0.368203377727947   1: 0.066570846080917   5: 0.019556160810121   0: 0.019554650596627   2: 0.019551742079669   3: 0.019551422518978   9: 0.019550757110818   7: 0.019550719950540   8: 0.019550696775129 

training_11599    6: 0.592642679479082   1: 0.223815684967650   5: 0.038562244457490   4: 0.029163489551764   9: 0.019930628826551   0: 0.019927489715177   2: 0.019062961200562   7: 0.018967771606497   3: 0.018966468771985   8: 0.018960581423242 

training_1160     4: 0.812170732805529   5: 0.020879185142455   0: 0.020871641583104   1: 0.020868968393358   3: 0.020868790258458   2: 0.020868595343871   9: 0.020868139517147   7: 0.020868037212818   6: 0.020867956018183   8: 0.020867953725075 

training_11602    5: 0.381268032379747   3: 0.303590139173806   6: 0.168794001592252   0: 0.020915110668103   1: 0.020911255139177   4: 0.020904493875144   2: 0.020904447595480   9: 0.020904357906417   7: 0.020904298460055   8: 0.020903863209819 

training_11607    6: 0.613635160910419   7: 0.166128994417708   8: 0.027538748772007   4: 0.027531648601143   5: 0.027528676378929   9: 0.027527819713431   3: 0.027527802937464   0: 0.027527374647812   1: 0.027526907180807   2: 0.027526866440280 

training_11608    6: 0.564948025260886   0: 0.207476090974052   5: 0.028449104673237   7: 0.028448684010185   8: 0.028446812085545   1: 0.028446370407211   2: 0.028446366568472   9: 0.028446225676884   3: 0.028446162301451   4: 0.028446158042078 

training_11609    6: 0.708006148590761   7: 0.032455577120102   5: 0.032445216915553   8: 0.032443754895857   9: 0.032442268538790   0: 0.032441790524775   3: 0.032441434199756   1: 0.032441317526899   2: 0.032441287403724   4: 0.032441204283784 

training_11610    6: 0.436137724904967   0: 0.327228033532033   5: 0.029584674243174   1: 0.029580042076089   8: 0.029579851486001   7: 0.029578816899179   2: 0.029578377269900   9: 0.029577781492441   3: 0.029577385476495   4: 0.029577312619721 

training_11611    6: 0.462955330135232   5: 0.289293222464961   7: 0.030972437315740   9: 0.030969682655647   8: 0.030969382361996   0: 0.030968606089126   3: 0.030968548522356   1: 0.030967713345004   2: 0.030967597310421   4: 0.030967479799517 

training_11612    0: 0.504175170107797   6: 0.266204914868633   5: 0.028706224005519   8: 0.028704603206059   7: 0.028702962251891   1: 0.028702596728745   2: 0.028701249023541   9: 0.028701005232946   3: 0.028700698125500   4: 0.028700576449370 

training_11614    4: 0.451348591631774   6: 0.309544191089275   1: 0.029901328173689   5: 0.029894621188900   0: 0.029888647838722   8: 0.029885017019288   9: 0.029884480106832   2: 0.029884425770831   3: 0.029884372213010   7: 0.029884324967678 

training_11617    6: 0.566092238610578   1: 0.280171569239923   5: 0.019281793956080   4: 0.019219744152707   3: 0.019209368653917   9: 0.019205889737945   8: 0.019205281929807   2: 0.019205059060621   0: 0.019204657600215   7: 0.019204397058205 

training_11619    0: 0.756878362848623   4: 0.073298438866405   5: 0.021230501750912   1: 0.021230426901826   6: 0.021228405430979   2: 0.021227133518413   9: 0.021227108886488   8: 0.021226640358679   3: 0.021226582156833   7: 0.021226399280842 

training_11621    5: 0.756296185421578   4: 0.027083069474162   6: 0.027077891413686   1: 0.027077817998363   0: 0.027077810859085   3: 0.027077537356290   8: 0.027077512998027   2: 0.027077437235334   7: 0.027077421294897   9: 0.027077315948578 

training_11622    4: 0.659873088452941   5: 0.144935769268726   1: 0.024410050667770   0: 0.024402890870318   6: 0.024398075442050   7: 0.024396743194855   8: 0.024395891825967   3: 0.024395850804775   2: 0.024395837481264   9: 0.024395801991335 

training_11623    4: 0.635094124102063   9: 0.120479171208521   6: 0.074946222150096   8: 0.045480401878729   5: 0.020671064098927   0: 0.020668944293301   1: 0.020667883797827   2: 0.020664347282299   3: 0.020664010641762   7: 0.020663830546476 

training_11625    6: 0.629930525536213   1: 0.113039859073283   5: 0.083338350691046   4: 0.053716664928696   8: 0.032367779972193   9: 0.017526694181275   2: 0.017523607020278   7: 0.017520890154511   0: 0.017517865167198   3: 0.017517763275306 

training_11627    4: 0.391159404028789   6: 0.245131264498012   0: 0.154635814232989   9: 0.102988597036101   2: 0.017690261688529   7: 0.017682589952633   8: 0.017678861035526   5: 0.017678237465793   1: 0.017677661301471   3: 0.017677308760157 

training_11628    5: 0.776729375667109   3: 0.024808360036465   4: 0.024808151167481   6: 0.024808147008393   0: 0.024807796975573   7: 0.024807794223799   1: 0.024807677800445   2: 0.024807600501048   9: 0.024807554183988   8: 0.024807542435701 

training_11629    5: 0.643300505427315   0: 0.152228611231288   4: 0.025562619947854   3: 0.025558497626189   8: 0.025558495033232   2: 0.025558375257678   9: 0.025558281956119   7: 0.025558270892599   1: 0.025558185795861   6: 0.025558156831867 

training_11630    5: 0.788596778651591   3: 0.065580896660705   4: 0.018234902318822   6: 0.018227345369959   0: 0.018226843434145   1: 0.018226763399730   7: 0.018226673715006   8: 0.018226667758683   9: 0.018226612751445   2: 0.018226515939914 

training_11632    6: 0.413233446560095   4: 0.269796411186917   1: 0.144038362712685   2: 0.073741839108192   5: 0.016553813054994   9: 0.016535911171410   3: 0.016528690663561   0: 0.016527023569660   8: 0.016523311199858   7: 0.016521190772629 

training_11633    5: 0.787476264950618   9: 0.062900361083754   4: 0.018705267304047   0: 0.018704076987708   6: 0.018702702612971   1: 0.018702586730172   8: 0.018702268053703   2: 0.018702180181797   3: 0.018702158706772   7: 0.018702133388457 

training_11634    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_11635    5: 0.690889159948621   1: 0.172781217032282   4: 0.017043347065931   6: 0.017042035145914   9: 0.017041455687479   2: 0.017041374726457   0: 0.017040434293787   7: 0.017040426985349   8: 0.017040302017488   3: 0.017040247096692 

training_11636    5: 0.545585564104845   1: 0.290022279328702   6: 0.020552594977234   4: 0.020551174875799   9: 0.020550362979657   2: 0.020549381408660   0: 0.020547855345914   7: 0.020547072522103   8: 0.020546972163516   3: 0.020546742293571 

training_11637    6: 0.415701902558796   0: 0.320178766918127   1: 0.153741101338309   5: 0.026299830265238   9: 0.025601672622876   4: 0.011750053049286   7: 0.011686694596926   3: 0.011680189873542   8: 0.011679988006351   2: 0.011679800770549 

training_11638    4: 0.410244035706850   6: 0.235053468926860   0: 0.150549382447680   9: 0.099929337830810   2: 0.017379873468763   7: 0.017372429173408   8: 0.017368712149864   5: 0.017368081255227   1: 0.017367513359014   3: 0.017367165681524 

training_11639    6: 0.597220610358198   7: 0.186419546852678   0: 0.070198971254916   9: 0.069581275762849   1: 0.012822419636213   2: 0.012773749933694   3: 0.012752652136014   5: 0.012747461610649   8: 0.012741908206246   4: 0.012741404248542 

training_1164     1: 0.502731919002515   0: 0.263202115196722   5: 0.029265559426264   6: 0.029263391775646   4: 0.029258228468072   9: 0.029256078950310   2: 0.029256068658734   7: 0.029256017237197   3: 0.029255411114920   8: 0.029255210169621 

training_11640    6: 0.661694470230519   5: 0.220334463202894   0: 0.024001831003108   2: 0.013635619682610   8: 0.013453780834710   1: 0.013388501781030   4: 0.013375082185985   3: 0.013372839284598   9: 0.013371711959936   7: 0.013371699834609 

training_11643    5: 0.674131269748118   0: 0.168571195389630   1: 0.019665198450489   6: 0.019663846738873   2: 0.019661678479614   4: 0.019661657711785   9: 0.019661380656340   3: 0.019661321699100   7: 0.019661274834186   8: 0.019661176291866 

training_11644    5: 0.627342463643842   6: 0.191389141095670   1: 0.022666438136741   4: 0.022662091376458   0: 0.022659334578899   8: 0.022656357027329   3: 0.022656166799964   9: 0.022656050289368   2: 0.022655992674799   7: 0.022655964376929 

training_11645    6: 0.444315954236555   0: 0.313246759570675   1: 0.083473518772157   7: 0.049903137140790   4: 0.018178771607468   5: 0.018178427272712   8: 0.018176177386150   9: 0.018175813730916   2: 0.018175746449618   3: 0.018175693832957 

training_11649    5: 0.758390813841676   8: 0.062576527940775   1: 0.051685796353820   3: 0.038597746325098   4: 0.014795082435688   6: 0.014791416558670   0: 0.014790965671704   7: 0.014790807705064   9: 0.014790444114698   2: 0.014790399052807 

training_11655    6: 0.681115694600249   5: 0.098201476073594   7: 0.068954979049092   0: 0.046697262834392   8: 0.017512775922377   4: 0.017509561477293   1: 0.017502520933492   3: 0.017502230521606   9: 0.017501836907474   2: 0.017501661680432 

training_11657    1: 0.749202108334557   3: 0.083100395754658   0: 0.020969756874800   6: 0.020964774300701   5: 0.020964182664982   4: 0.020961065092309   2: 0.020960585570987   9: 0.020959334302301   7: 0.020958992308993   8: 0.020958804795711 

training_11658    6: 0.612127989379820   0: 0.132423867422019   9: 0.118684457988566   7: 0.047873677062344   1: 0.014818134726786   8: 0.014814593642138   5: 0.014814555106611   4: 0.014814253890977   3: 0.014814236193178   2: 0.014814234587562 

training_11660    6: 0.706417886732669   2: 0.032622891668147   5: 0.032621976873099   0: 0.032621408654258   1: 0.032620711811676   9: 0.032620689999612   3: 0.032619844338961   7: 0.032618662973454   8: 0.032618346686137   4: 0.032617580261987 

training_11661    6: 0.372406973847355   9: 0.220099514515840   4: 0.162753371886993   0: 0.117409192456077   2: 0.047183495502574   1: 0.021006775442423   5: 0.014793962234597   3: 0.014782956062363   7: 0.014781982080745   8: 0.014781775971033 

training_11663    1: 0.665029833285555   0: 0.146987246676914   2: 0.086526781892084   6: 0.014645039638322   8: 0.014477557249586   5: 0.014471469686564   4: 0.014466309137617   9: 0.014465396146091   3: 0.014465282621447   7: 0.014465083665821 

training_11664    5: 0.429213021655918   7: 0.362861773167733   4: 0.025994744453496   6: 0.025991775738004   0: 0.025990300167028   8: 0.025989923139869   1: 0.025989731504061   2: 0.025989659333090   3: 0.025989617761884   9: 0.025989453078915 

training_11665    6: 0.770365858469405   0: 0.076635072679473   8: 0.019132520370786   5: 0.019126274786341   9: 0.019125786566552   1: 0.019123809633740   4: 0.019123412757157   2: 0.019122463760616   7: 0.019122441187516   3: 0.019122359788416 

training_11666    5: 0.297518647690859   1: 0.260339073381530   6: 0.185940692366640   8: 0.104586312949289   4: 0.025274450369380   0: 0.025269142523336   7: 0.025268531232621   3: 0.025267895846074   2: 0.025267678937512   9: 0.025267574702760 

training_11667    9: 0.415984932159144   6: 0.264549711313608   5: 0.176094316900676   4: 0.020485052142009   0: 0.020482504872260   1: 0.020482113064294   7: 0.020480818349794   2: 0.020480407753028   8: 0.020480192519659   3: 0.020479950925526 

training_11668    8: 0.429376681731900   7: 0.224456416459814   5: 0.149848974372002   6: 0.028056051595747   2: 0.028051635372882   4: 0.028047366272072   0: 0.028044690371635   1: 0.028041649393675   3: 0.028038837165173   9: 0.028037697265099 

training_1167     5: 0.748564500047142   6: 0.027954156006111   1: 0.027939052143546   0: 0.027938594019462   9: 0.027936404072341   2: 0.027935221361580   3: 0.027933767092339   8: 0.027932934298971   4: 0.027932873075819   7: 0.027932497882690 

training_11671    6: 0.815395863897234   0: 0.046874902792352   5: 0.017220009879683   4: 0.017217571403529   1: 0.017215759715469   8: 0.017215724188025   9: 0.017215400914679   2: 0.017215081573860   7: 0.017214860126365   3: 0.017214825508804 

training_11674    6: 0.399891196330891   7: 0.353183535723834   5: 0.058571746496515   2: 0.056531233722971   1: 0.042937859642599   8: 0.017782162854111   4: 0.017777455697953   0: 0.017776308913159   9: 0.017774433707943   3: 0.017774066910024 

training_11679    5: 0.729738271341776   1: 0.114580139286840   6: 0.019475391879665   0: 0.019462371961956   4: 0.019457824202824   9: 0.019457668111779   7: 0.019457386649111   8: 0.019457377446545   2: 0.019456808318107   3: 0.019456760801396 

training_11682    5: 0.743189494965004   6: 0.028541845337118   0: 0.028536788656550   1: 0.028535204829189   2: 0.028534065818523   4: 0.028533558364984   9: 0.028533126051644   8: 0.028532225797356   3: 0.028531899007188   7: 0.028531791172443 

training_11683    5: 0.494317606153077   4: 0.351540230734024   6: 0.019269873353311   0: 0.019268389744483   1: 0.019268130625990   8: 0.019267543273760   9: 0.019267136254431   3: 0.019267060720704   7: 0.019267030905037   2: 0.019266998235182 

training_11684    5: 0.659282451667730   2: 0.179314086685723   6: 0.020206784645585   0: 0.020179135361975   1: 0.020176644527601   4: 0.020170872837851   7: 0.020167968364517   9: 0.020167581415644   8: 0.020167296539399   3: 0.020167177953975 

training_11685    5: 0.770444809606532   0: 0.071205075353913   4: 0.019799865197849   6: 0.019793185186817   8: 0.019792994672394   3: 0.019792874922857   2: 0.019792811716909   9: 0.019792802690102   1: 0.019792797925508   7: 0.019792782727118 

training_11687    4: 0.717004476065130   6: 0.031641001532831   1: 0.031435287291196   7: 0.031425566185628   0: 0.031423069329932   5: 0.031418376152017   9: 0.031413721170243   3: 0.031413479471590   8: 0.031412544498183   2: 0.031412478303249 

training_11689    5: 0.719726618158790   6: 0.031151358697663   1: 0.031150724341849   4: 0.031148645642269   0: 0.031139338997908   9: 0.031139281884790   8: 0.031136152153868   2: 0.031136094311552   3: 0.031136000113921   7: 0.031135785697389 

training_1169     6: 0.330017307118019   5: 0.269862827287893   3: 0.260855316445314   4: 0.019895910025374   9: 0.019895192921665   0: 0.019895027978955   1: 0.019894814973903   8: 0.019894542110205   7: 0.019894538921113   2: 0.019894522217558 

training_11690    4: 0.815813207179039   5: 0.020469827863824   6: 0.020464716605392   0: 0.020464688426877   3: 0.020464681048551   8: 0.020464655689964   1: 0.020464608355183   9: 0.020464602945418   2: 0.020464533561811   7: 0.020464478323942 

training_11694    7: 0.577205922348978   6: 0.265198601688053   3: 0.019745482354752   1: 0.019699801524381   5: 0.019696003814383   0: 0.019692527501577   4: 0.019690601517053   8: 0.019690526932864   9: 0.019690484521098   2: 0.019690047796860 

training_11696    4: 0.760365331083998   5: 0.026635308665328   1: 0.026630351933266   0: 0.026626544387239   8: 0.026624840841516   6: 0.026623861800892   3: 0.026623521210324   9: 0.026623434886456   2: 0.026623416379048   7: 0.026623388811933 

training_11697    4: 0.747318950925559   5: 0.028080444436691   2: 0.028075797066405   6: 0.028075546559340   9: 0.028075346719643   7: 0.028074952668779   1: 0.028074793665882   8: 0.028074767518218   0: 0.028074747441145   3: 0.028074652998336 

training_11699    2: 0.738153201242440   5: 0.029100178473988   4: 0.029094921913023   9: 0.029094180508894   1: 0.029093437132546   6: 0.029093153656520   7: 0.029093094127886   0: 0.029092839259895   8: 0.029092826733686   3: 0.029092166951120 

training_1170     5: 0.368888837933508   7: 0.277532041927686   3: 0.182370889227320   1: 0.024459064552482   6: 0.024458605063358   4: 0.024458516979410   0: 0.024458503780540   8: 0.024457925992206   2: 0.024457831198673   9: 0.024457783344816 

training_11700    5: 0.654921497946800   0: 0.104555180311252   7: 0.081720470716459   6: 0.022693992947844   4: 0.022690556345702   8: 0.022683820827962   2: 0.022683674096945   1: 0.022683632953608   9: 0.022683609283872   3: 0.022683564569555 

training_11701    0: 0.562534530061372   8: 0.192284649380584   4: 0.030696173271011   5: 0.030688012544096   6: 0.030653588760123   3: 0.030628931423949   7: 0.030628859416785   2: 0.030628697026937   1: 0.030628569897115   9: 0.030627988218027 

training_11702    4: 0.401996738319955   7: 0.342456068980320   6: 0.031954700530271   9: 0.031946065923478   8: 0.031944327249777   5: 0.031943741642485   1: 0.031942652008985   2: 0.031940464904533   0: 0.031939201462243   3: 0.031936038977953 

training_11705    5: 0.311099586403516   4: 0.263710253798592   6: 0.255975156355994   0: 0.066433144801768   7: 0.017134270836870   1: 0.017130424653172   8: 0.017130097611442   9: 0.017129302502727   2: 0.017129093827799   3: 0.017128669208120 

training_11706    6: 0.583598757634286   5: 0.196442317853659   0: 0.081745738729510   1: 0.056855262320845   9: 0.013565615564898   2: 0.013559688405703   4: 0.013558280749583   8: 0.013558183771977   3: 0.013558088717816   7: 0.013558066251722 

training_11707    5: 0.592130252171497   0: 0.216382885132979   1: 0.053097064451382   7: 0.045537172518835   9: 0.015489521404662   4: 0.015478737351098   6: 0.015477916732485   3: 0.015469785651064   8: 0.015468477310178   2: 0.015468187275820 

training_11708    5: 0.316596668356922   1: 0.316333544005873   6: 0.221798236888481   3: 0.047548278464510   0: 0.016293847532591   2: 0.016292687724409   4: 0.016291657135559   9: 0.016282342464962   8: 0.016281589649238   7: 0.016281147777454 

training_11711    6: 0.467379768754648   0: 0.180662805464464   4: 0.133215066612887   5: 0.124866560976600   7: 0.028043188402939   2: 0.021735228877217   1: 0.013915816544968   9: 0.010064032713109   3: 0.010061090798700   8: 0.010056440854468 

training_11713    5: 0.786442785792442   0: 0.091652211501859   6: 0.015245619483638   9: 0.015244771636989   7: 0.015237405632467   4: 0.015237085989745   1: 0.015235225663059   8: 0.015235039697692   3: 0.015234929035400   2: 0.015234925566709 

training_11714    5: 0.596496285721963   6: 0.198109576428871   9: 0.082053354809915   1: 0.017642669068106   7: 0.017629220268859   0: 0.017617389353825   4: 0.017613351280946   8: 0.017613019317052   2: 0.017612656574376   3: 0.017612477176085 

training_11716    6: 0.480294890895681   4: 0.296664442729810   2: 0.027889233498746   5: 0.027881001335298   0: 0.027880015889801   9: 0.027879444185553   1: 0.027879357818580   8: 0.027878079576199   3: 0.027877232725728   7: 0.027876301344606 

training_11717    5: 0.395413470111172   6: 0.301523624101838   0: 0.196835574319495   4: 0.023624413497985   3: 0.022087982794015   1: 0.012108523665115   9: 0.012102557618082   2: 0.012101567816516   8: 0.012101168699958   7: 0.012101117375824 

training_11721    5: 0.703743272580210   4: 0.114384048045254   8: 0.022744274883699   6: 0.022737766164792   7: 0.022735114536341   0: 0.022732560650904   9: 0.022731878542936   1: 0.022731262605876   2: 0.022730067270150   3: 0.022729754719837 

training_11722    0: 0.752839047094724   5: 0.027471453078434   4: 0.027470079631583   3: 0.027464005421480   1: 0.027463474153761   8: 0.027460417948737   6: 0.027458894380693   9: 0.027457775322228   7: 0.027457661997642   2: 0.027457190970718 

training_11723    6: 0.795888249717431   7: 0.049140126563498   1: 0.046471912202597   5: 0.015500463134365   0: 0.015500419949376   9: 0.015500277769388   2: 0.015500010981419   4: 0.015499814930453   8: 0.015499632092413   3: 0.015499092659060 

training_11724    4: 0.820041830602287   5: 0.020011666995045   6: 0.019993981828661   9: 0.019993787552604   2: 0.019993687778256   3: 0.019993470775259   1: 0.019993424666501   0: 0.019993093820772   8: 0.019992605765284   7: 0.019992450215333 

training_11725    4: 0.447088752656324   6: 0.406659881658799   8: 0.018287226761621   0: 0.018284921841126   5: 0.018283417584877   1: 0.018280618193032   9: 0.018279282119962   2: 0.018278771502247   7: 0.018278745525716   3: 0.018278382156296 

training_11726    6: 0.284607735866878   1: 0.283367576687672   5: 0.182851042628409   4: 0.116274175206493   9: 0.038814762054826   0: 0.034015530256295   3: 0.015019079857276   2: 0.015016798358750   8: 0.015016722590527   7: 0.015016576492872 

training_11727    5: 0.662659408811092   0: 0.141768213761211   6: 0.024449643200795   9: 0.024449274549800   4: 0.024449227714915   7: 0.024445591067839   1: 0.024445523891000   3: 0.024444862497819   8: 0.024444177330077   2: 0.024444077175452 

training_11728    5: 0.571493012815094   7: 0.268579228816252   6: 0.020003692091878   0: 0.019992106805014   1: 0.019990753905009   9: 0.019989280038500   2: 0.019988487453326   4: 0.019988365680819   8: 0.019987600324101   3: 0.019987472070007 

training_11729    6: 0.492450938975623   3: 0.224743618019090   0: 0.094408787994514   2: 0.062964861941755   5: 0.020929953297897   8: 0.020909122840714   1: 0.020899725741333   7: 0.020899625281713   9: 0.020899040244937   4: 0.020894325662424 

training_1173     5: 0.739912072478623   6: 0.099611008437192   9: 0.020072079361497   0: 0.020069693151651   1: 0.020059017756025   4: 0.020055756283894   8: 0.020055207023040   2: 0.020055178125486   7: 0.020055105223281   3: 0.020054882159312 

training_11730    5: 0.763864902360239   4: 0.026243028871170   6: 0.026238017531538   1: 0.026237004653282   0: 0.026236954617061   9: 0.026236910922938   8: 0.026236117884627   2: 0.026235824454596   7: 0.026235696302676   3: 0.026235542401874 

training_11731    9: 0.754141630999288   5: 0.027334770869500   2: 0.027332582957848   6: 0.027321317597623   0: 0.027315711419791   1: 0.027315499428422   3: 0.027310181012819   8: 0.027309896877154   4: 0.027309720033608   7: 0.027308688803945 

training_11733    4: 0.766529252707617   5: 0.025947974950968   6: 0.025940819675908   0: 0.025940528833968   8: 0.025940322305554   3: 0.025940296932736   9: 0.025940296876885   2: 0.025940207401211   1: 0.025940166469320   7: 0.025940133845833 

training_11734    6: 0.531320696431603   0: 0.238193180868255   5: 0.095620309646266   1: 0.042163743487256   9: 0.033469694131791   7: 0.020823518220311   2: 0.009606686826876   8: 0.009601138109751   3: 0.009600543317617   4: 0.009600488960275 

training_11736    5: 0.441815129517309   2: 0.331112216712290   4: 0.028396183868147   9: 0.028384111108309   6: 0.028383295103011   8: 0.028382115626887   1: 0.028381956150988   3: 0.028381895541123   7: 0.028381642403267   0: 0.028381453968669 

training_11738    2: 0.606833163816666   1: 0.194930835894488   6: 0.024788727727606   0: 0.024782598050528   5: 0.024781631501327   9: 0.024777053369811   8: 0.024776870365019   7: 0.024776720874727   4: 0.024776636367813   3: 0.024775762032015 

training_11739    6: 0.759188837974592   1: 0.127148568835569   7: 0.017866198569199   8: 0.017004344445795   0: 0.016373507900666   2: 0.016280232145219   5: 0.011562645159556   3: 0.011530823096564   9: 0.011523367921922   4: 0.011521473950919 

training_1174     6: 0.630680999830608   3: 0.201242008368862   9: 0.047585895713023   5: 0.017221427338327   4: 0.017216223180752   0: 0.017212524250260   1: 0.017211997836277   8: 0.017211245095774   7: 0.017209058230320   2: 0.017208620155797 

training_11743    1: 0.479732931890923   6: 0.288026920097209   9: 0.070134483979476   0: 0.043340873003376   2: 0.039314508999555   8: 0.015946033886098   5: 0.015881933964863   4: 0.015875620370618   3: 0.015873569553073   7: 0.015873124254809 

training_11744    1: 0.360820621824747   9: 0.200357941217646   7: 0.161752817227171   6: 0.149065961628714   0: 0.021339200585929   5: 0.021335803778748   3: 0.021331993164719   2: 0.021331932603015   8: 0.021331925493134   4: 0.021331802476177 

training_11746    6: 0.471660612527995   0: 0.428311047062789   8: 0.024106890426591   1: 0.012929950568853   3: 0.010536331339617   5: 0.010528091669633   7: 0.010518487933146   9: 0.010498663099570   2: 0.010484284624314   4: 0.010425640747493 

training_11748    1: 0.823172686890706   7: 0.038676924792959   8: 0.017306970537432   6: 0.017278539951258   5: 0.017262861535636   9: 0.017261069229305   0: 0.017260777247465   2: 0.017260272784025   4: 0.017260227437862   3: 0.017259669593352 

training_11750    4: 0.647787148360905   1: 0.123871934631904   7: 0.028551321308882   5: 0.028545266233807   3: 0.028541227643201   8: 0.028540740654682   6: 0.028540608239734   0: 0.028540595197338   9: 0.028540579065842   2: 0.028540578663704 

training_11751    3: 0.354599786933428   6: 0.325423426315991   5: 0.143090955896216   4: 0.057942498285155   0: 0.019834383407108   2: 0.019831087498022   1: 0.019822859967018   7: 0.019821957142275   8: 0.019816732841425   9: 0.019816311713361 

training_11752    6: 0.529244193933369   5: 0.276840644137340   0: 0.066438447943417   1: 0.048566025770262   8: 0.028260542301359   4: 0.010131533228542   9: 0.010129834951053   3: 0.010129687244041   2: 0.010129599650396   7: 0.010129490840220 

training_11753    6: 0.632859179481734   0: 0.187476551661467   1: 0.104614555175555   3: 0.020410843385400   8: 0.015467606796933   9: 0.007844220093307   4: 0.007832915780474   7: 0.007832287215845   5: 0.007831037107642   2: 0.007830803301643 

training_11754    4: 0.793435464600890   5: 0.022957161337916   7: 0.022951297002532   8: 0.022950938321384   3: 0.022950922907615   9: 0.022950877666543   0: 0.022950877575088   6: 0.022950847466144   2: 0.022950834182173   1: 0.022950778939716 

training_11755    1: 0.764718177452482   4: 0.054966418090353   0: 0.040807492605792   7: 0.019961103619902   9: 0.019928293202565   5: 0.019926868304838   6: 0.019924976742597   8: 0.019923451326797   2: 0.019921818759468   3: 0.019921399895206 

training_11756    5: 0.643424642183865   7: 0.155800294967214   6: 0.025098089610664   3: 0.025097198576361   4: 0.025097170964893   0: 0.025097025903269   2: 0.025096466609947   1: 0.025096388209450   8: 0.025096368995886   9: 0.025096353978451 

training_11758    4: 0.548786228114330   0: 0.144635283384315   9: 0.127299382854289   2: 0.065772734062204   5: 0.018935973081822   6: 0.018919346266313   7: 0.018916532763428   1: 0.018913589959280   8: 0.018910675987194   3: 0.018910253526824 

training_1176     4: 0.809515204399127   5: 0.021171873441778   0: 0.021165639941356   1: 0.021164497920759   6: 0.021164366779627   9: 0.021164032664985   8: 0.021163900586290   2: 0.021163559238938   7: 0.021163481806575   3: 0.021163443220564 

training_11762    0: 0.573934761741234   1: 0.198866482270831   6: 0.028409872935761   5: 0.028405924660604   2: 0.028402334197970   8: 0.028401443310170   4: 0.028395695091008   7: 0.028395354581111   3: 0.028394126749916   9: 0.028394004461395 

training_11763    0: 0.642237699751155   1: 0.224053777941891   5: 0.026870517506435   8: 0.020072202831484   6: 0.014540830251293   4: 0.014462017049356   7: 0.014450547933899   2: 0.014437739982606   9: 0.014437640414497   3: 0.014437026337383 

training_11764    1: 0.730120509884944   6: 0.029995773992365   8: 0.029989171522444   0: 0.029987669732499   9: 0.029987398606348   7: 0.029985383138083   5: 0.029984186999961   3: 0.029983476440531   2: 0.029983271731465   4: 0.029983157951358 

training_11765    6: 0.798432633258686   1: 0.057192539797174   8: 0.018048494939090   9: 0.018047837096851   0: 0.018047821718713   5: 0.018046918708073   7: 0.018046525341808   4: 0.018045841894734   2: 0.018045748632331   3: 0.018045638612540 

training_11767    9: 0.276045302638348   6: 0.245317696049842   0: 0.232565844172769   8: 0.098555722878197   2: 0.024589564045590   5: 0.024587279361365   1: 0.024585696179828   7: 0.024584990385764   4: 0.024584534113691   3: 0.024583370174606 

training_11768    6: 0.766837314318972   0: 0.102405526617320   5: 0.047366558851463   1: 0.025287135052431   3: 0.012222449522814   8: 0.009339213683966   9: 0.009221203143837   2: 0.009134208660430   7: 0.009098049809612   4: 0.009088340339154 

training_11769    6: 0.705156673843819   0: 0.147526600221298   5: 0.038938385229145   4: 0.032023199575435   8: 0.021189072586086   1: 0.011065131297157   9: 0.011053510780229   7: 0.011016736492544   2: 0.011015455643658   3: 0.011015234330628 

training_1177     5: 0.745666932986451   4: 0.028263587084515   3: 0.028258821254795   8: 0.028258815012595   9: 0.028258776800206   0: 0.028258733126074   2: 0.028258712131323   1: 0.028258583342159   7: 0.028258545147811   6: 0.028258493114072 

training_11771    6: 0.809297528504131   8: 0.039187517305366   1: 0.032942852575748   7: 0.016991033922410   9: 0.016939185983161   5: 0.016931015704685   0: 0.016928908404751   4: 0.016928174784379   2: 0.016927017878106   3: 0.016926764937264 

training_11772    6: 0.492455021118376   7: 0.275000611279680   1: 0.029074225451959   8: 0.029070911566125   0: 0.029069507249291   9: 0.029067528418919   5: 0.029065977866759   4: 0.029065526054851   2: 0.029065410782025   3: 0.029065280212015 

training_11773    6: 0.418314621835787   0: 0.365103102837705   5: 0.128979336168726   1: 0.022595251951859   7: 0.018613904687370   9: 0.009366097325241   8: 0.009261269616682   4: 0.009255970344132   3: 0.009255392335683   2: 0.009255052896815 

training_11774    6: 0.779999723473263   7: 0.064292817303099   8: 0.019467783755720   1: 0.019466912579104   9: 0.019465027685047   0: 0.019464852130341   5: 0.019461235151166   4: 0.019460609284077   2: 0.019460552668087   3: 0.019460485970096 

training_11775    7: 0.529941176344493   6: 0.265223154901488   5: 0.060844703624310   2: 0.020571872435595   0: 0.020571177070788   1: 0.020570494647556   8: 0.020569888749064   9: 0.020569591915955   3: 0.020569021759357   4: 0.020568918551395 

training_11776    0: 0.471576419182722   6: 0.397992434490201   9: 0.036153458670123   8: 0.025726995571358   1: 0.011456866968058   5: 0.011437046754631   2: 0.011418757768851   4: 0.011413210892229   7: 0.011412678288645   3: 0.011412131413181 

training_11778    6: 0.602147542259640   7: 0.209408993047717   5: 0.046377001604406   2: 0.020296512015657   9: 0.020295322317783   1: 0.020295179988006   0: 0.020295135512018   8: 0.020294964707216   3: 0.020294698505681   4: 0.020294650041874 

training_1178     4: 0.802385988814540   5: 0.021962696936189   8: 0.021956552753205   0: 0.021956484131673   1: 0.021956471714142   6: 0.021956437130102   9: 0.021956434219395   3: 0.021956356270455   2: 0.021956329606780   7: 0.021956248423520 

training_11783    6: 0.627138545916975   1: 0.240143100432327   0: 0.016590780599637   9: 0.016589904256697   8: 0.016589811316239   5: 0.016589692901396   7: 0.016589685339889   2: 0.016589509837097   3: 0.016589491567583   4: 0.016589477832159 

training_11787    5: 0.754922994319023   6: 0.027276397125571   9: 0.027268429748461   1: 0.027238799086614   0: 0.027220717574586   7: 0.027217898855049   8: 0.027216968905747   4: 0.027213635597856   2: 0.027212198261861   3: 0.027211960525232 

training_11789    0: 0.526123548441273   6: 0.335070194094164   1: 0.017351769317879   5: 0.017351763506706   9: 0.017351357784445   8: 0.017351342781677   4: 0.017350276716248   7: 0.017350267907635   2: 0.017349798558590   3: 0.017349680891382 

training_11790    6: 0.751700928552291   1: 0.027596636271101   0: 0.027590686482563   8: 0.027588493969873   9: 0.027587970095908   2: 0.027587881631403   5: 0.027587162686113   4: 0.027586767396851   7: 0.027586764449924   3: 0.027586708463972 

training_11791    6: 0.833067669925217   3: 0.037237531873650   7: 0.016237575707352   1: 0.016212701556191   2: 0.016211599815344   5: 0.016207736988742   0: 0.016207342994114   4: 0.016206468578333   8: 0.016205937397411   9: 0.016205435163645 

training_11793    6: 0.820935707950670   3: 0.054751564555918   5: 0.015552285873248   8: 0.015541393796581   1: 0.015538855768125   0: 0.015537701374540   4: 0.015535856050820   2: 0.015535729833491   9: 0.015535570919803   7: 0.015535333876803 

training_11794    9: 0.836656571988381   6: 0.040090163073343   1: 0.015410191154201   8: 0.015409648262833   0: 0.015407158403467   5: 0.015405895845410   4: 0.015405294919674   7: 0.015405131677247   2: 0.015405003107838   3: 0.015404941567606 

training_11795    6: 0.463175222471292   0: 0.294200266992108   5: 0.092541413178702   9: 0.039174174189924   3: 0.037398287322393   1: 0.014702480079089   8: 0.014702302545439   4: 0.014702194602404   7: 0.014701937692023   2: 0.014701720926627 

training_11798    9: 0.624446536467572   6: 0.225061210590448   8: 0.018816650682659   1: 0.018812096816190   0: 0.018811925590698   5: 0.018811285859447   3: 0.018810444935023   4: 0.018810244856271   7: 0.018809838136660   2: 0.018809766065031 

training_11801    6: 0.351170351091495   7: 0.260045722016780   0: 0.184067178620999   1: 0.113320206260308   9: 0.015239733681593   2: 0.015232312454256   5: 0.015231728813988   8: 0.015231075410784   3: 0.015230950255596   4: 0.015230741394200 

training_11802    5: 0.431072064171735   1: 0.405543292651155   3: 0.020425763619563   6: 0.020425368478638   0: 0.020423809161867   4: 0.020423085237234   8: 0.020421938712693   9: 0.020421803118323   7: 0.020421607195082   2: 0.020421267653709 

training_11808    7: 0.422107639956336   6: 0.349820300661975   9: 0.061887025553372   2: 0.056211475289778   8: 0.018343979037949   1: 0.018339036841283   0: 0.018331787889918   5: 0.018321959195872   4: 0.018319963920770   3: 0.018316831652748 

training_1181     5: 0.726100564635662   7: 0.128929609363903   1: 0.018166672149868   8: 0.018127684498399   6: 0.018125251109858   0: 0.018115885088687   4: 0.018112231368204   2: 0.018108149230446   3: 0.018106994682746   9: 0.018106957872227 

training_11811    6: 0.695169626618286   8: 0.123839645385390   1: 0.022625859069842   5: 0.022625022660985   0: 0.022624420128882   7: 0.022623838271946   9: 0.022623459091856   2: 0.022622817452678   4: 0.022622799698903   3: 0.022622511621233 

training_11812    0: 0.791559052990227   3: 0.064519468820294   6: 0.017996610384877   9: 0.017994030066937   7: 0.017992190484825   1: 0.017991149825992   8: 0.017988127387392   5: 0.017987807434630   4: 0.017986518391034   2: 0.017985044213791 

training_11813    6: 0.812725459619044   0: 0.086940859169013   2: 0.012543103668401   5: 0.012541952036174   9: 0.012541668197794   1: 0.012541665209416   8: 0.012541432433798   7: 0.012541423513236   4: 0.012541288555073   3: 0.012541147598052 

training_11815    6: 0.792670218192756   5: 0.068911950908276   8: 0.017304750688180   0: 0.017303112495727   1: 0.017302425751368   9: 0.017302138462693   7: 0.017301838940066   4: 0.017301732008085   3: 0.017301000011456   2: 0.017300832541392 

training_11816    6: 0.535500514450226   4: 0.231694009423575   9: 0.090241443018188   3: 0.043060071546905   8: 0.028002549046482   0: 0.014325521162614   5: 0.014298440391117   1: 0.014296528479778   7: 0.014290752074875   2: 0.014290170406239 

training_11817    6: 0.662862048594407   8: 0.152639660165962   0: 0.083627212334652   1: 0.014412628763198   4: 0.014411889786004   9: 0.014410197376786   5: 0.014409410237528   2: 0.014409276650178   7: 0.014408876232499   3: 0.014408799858785 

training_1182     5: 0.671954188628759   6: 0.161572537731361   8: 0.020812502396610   0: 0.020809005709528   1: 0.020808968789765   3: 0.020808717052000   9: 0.020808676405416   4: 0.020808607780858   7: 0.020808464196009   2: 0.020808331309694 

training_11820    6: 0.620425177781967   0: 0.263162931644717   1: 0.033857691095075   9: 0.021855489726392   8: 0.010124739434749   7: 0.010119071061630   5: 0.010117268128997   4: 0.010113013639656   3: 0.010112349651738   2: 0.010112267835078 

training_11821    6: 0.638607572651765   3: 0.139171754079668   5: 0.027786559210312   4: 0.027779066543787   1: 0.027778442810443   0: 0.027775922828713   2: 0.027775627000317   8: 0.027775223436836   9: 0.027775159701155   7: 0.027774671737004 

training_11822    2: 0.431448851513893   6: 0.204415857997679   5: 0.134520575013484   8: 0.077161291474847   0: 0.068494950711633   9: 0.016906739832969   1: 0.016771386835360   3: 0.016767057677396   7: 0.016756956294787   4: 0.016756332647951 

training_11825    6: 0.552011644617993   0: 0.150913642828165   3: 0.116095577577692   8: 0.025866694128110   5: 0.025857974411716   1: 0.025853065171468   4: 0.025852268850568   2: 0.025850063323972   9: 0.025849897909879   7: 0.025849171180437 

training_11826    6: 0.824007692673797   7: 0.041707429904523   9: 0.016811518837444   0: 0.016786356951647   2: 0.016781663649680   3: 0.016781405762212   5: 0.016781222857394   1: 0.016781219071598   4: 0.016780811587645   8: 0.016780678704060 

training_11829    6: 0.787663208898913   3: 0.056721768982974   1: 0.042921340616884   4: 0.016124657084596   0: 0.016116898254700   8: 0.016103633852981   5: 0.016101838309475   9: 0.016085705528408   2: 0.016080791720278   7: 0.016080156750792 

training_11830    6: 0.628461431704483   1: 0.226805814239897   8: 0.039621525028168   0: 0.030454110106662   9: 0.016326123044093   7: 0.011686434414326   5: 0.011676012481299   4: 0.011661515744401   3: 0.011653650163027   2: 0.011653383073643 

training_11831    6: 0.710676751613938   1: 0.091093895013956   2: 0.065175642292247   8: 0.033097571609022   7: 0.033085690399985   0: 0.022282507719334   9: 0.011150024474654   5: 0.011149076985787   4: 0.011144638119342   3: 0.011144201771735 

training_11832    9: 0.813732808610882   6: 0.020698526710934   8: 0.020698223341778   5: 0.020697602367303   0: 0.020696311740758   4: 0.020695789396142   1: 0.020695748579723   7: 0.020695141799084   2: 0.020694933499298   3: 0.020694913954098 

training_11833    7: 0.472836576439310   6: 0.375998485591173   1: 0.018938050474152   9: 0.018897128400988   0: 0.018891775322442   3: 0.018891569157901   5: 0.018889240382712   4: 0.018886845688179   2: 0.018885411501688   8: 0.018884917041455 

training_11834    6: 0.839346810003998   8: 0.017854226819321   9: 0.017851950878795   1: 0.017850190969438   5: 0.017850147777589   0: 0.017849734170690   4: 0.017849594835828   7: 0.017849575857718   3: 0.017848888824557   2: 0.017848879862066 

training_11836    6: 0.651128297922081   7: 0.182412210139165   0: 0.037184611044807   5: 0.018827497576133   4: 0.018410708834593   9: 0.018410606889719   1: 0.018407020873921   8: 0.018406482551043   3: 0.018406366216095   2: 0.018406197952443 

training_11837    1: 0.490766286178344   6: 0.233718865987852   9: 0.156430189176811   8: 0.017277659372138   3: 0.016972624617715   4: 0.016968369433792   7: 0.016967238072925   0: 0.016966792831955   2: 0.016966369624645   5: 0.016965604703823 

training_11839    6: 0.621397369439443   1: 0.134864333994910   8: 0.091320686589199   9: 0.049322096184696   7: 0.028352926105028   5: 0.014972812185967   0: 0.014953262847426   2: 0.014944872286186   4: 0.014936045968472   3: 0.014935594398673 

training_1184     0: 0.651610503365205   6: 0.153104845042560   5: 0.035929806677822   7: 0.033595174437631   8: 0.020968637842597   3: 0.020968522009852   9: 0.020957080467078   4: 0.020955721414567   1: 0.020955566754887   2: 0.020954141987802 

training_11840    6: 0.749535711646429   1: 0.064024247443071   8: 0.053910749210783   3: 0.035943928281943   7: 0.030726034926655   0: 0.013202554656927   5: 0.013165907510456   9: 0.013164014037998   4: 0.013163496370807   2: 0.013163355914931 

training_11841    6: 0.796274003854565   1: 0.045512251265298   3: 0.042096249110902   4: 0.016682288880469   8: 0.016616081802815   0: 0.016588161626335   9: 0.016567066356205   5: 0.016561695189262   2: 0.016551449086459   7: 0.016550752827691 

training_11843    6: 0.854085343087085   7: 0.043191611879651   0: 0.012868149212150   4: 0.012843792766083   5: 0.012843349853315   1: 0.012835304468932   8: 0.012834537611766   9: 0.012833558837889   3: 0.012832260603926   2: 0.012832091679203 

training_11844    6: 0.627089965017418   1: 0.240191681228003   0: 0.016590780730553   9: 0.016589904257652   8: 0.016589811320966   5: 0.016589692909413   7: 0.016589685343304   2: 0.016589509811697   3: 0.016589491566293   4: 0.016589477814702 

training_11847    0: 0.617672150432086   1: 0.196261475627167   3: 0.045262638836331   5: 0.020121080908962   6: 0.020118343845659   4: 0.020113764939402   2: 0.020113057018023   9: 0.020112788267902   8: 0.020112384617831   7: 0.020112315506639 

training_11848    6: 0.662893421820364   8: 0.152786549043140   0: 0.083448952075573   1: 0.014412626647040   4: 0.014411889240765   9: 0.014410198107789   5: 0.014409410458944   2: 0.014409276766996   7: 0.014408876040993   3: 0.014408799798395 

training_1185     0: 0.356623264813063   6: 0.259591612999610   1: 0.192796581495244   5: 0.061756778965110   3: 0.021563355736760   8: 0.021548437626411   9: 0.021531580703960   2: 0.021529721869476   7: 0.021529568023579   4: 0.021529097766788 

training_11850    5: 0.423036670565444   8: 0.330089151570891   1: 0.098009369667048   3: 0.047016214030103   6: 0.016990353388637   9: 0.016980888538409   0: 0.016977180524075   4: 0.016968595714182   7: 0.016965827576458   2: 0.016965748424753 

training_11852    6: 0.621396427971796   1: 0.134864892336578   8: 0.091320587270548   9: 0.049322069235681   7: 0.028353614484402   5: 0.014972694601155   0: 0.014953201313444   2: 0.014944872415680   4: 0.014936045974999   3: 0.014935594395716 

training_11854    7: 0.509976281608565   5: 0.168785285359455   6: 0.161455772264119   3: 0.042095970058457   1: 0.019618797008994   0: 0.019618069618207   2: 0.019613376521026   4: 0.019612633274182   9: 0.019612280760097   8: 0.019611533526897 

training_11855    5: 0.473719283320070   1: 0.354807207142930   9: 0.021448116902303   8: 0.021438995466690   6: 0.021438733248925   2: 0.021433584018154   0: 0.021429225598834   4: 0.021429208264288   3: 0.021429038642998   7: 0.021426607394809 

training_11856    5: 0.722714133967217   9: 0.030860916516189   8: 0.030832801813726   1: 0.030805757867351   2: 0.030805309106910   3: 0.030802359485108   6: 0.030797968654381   4: 0.030794396953669   0: 0.030794053599803   7: 0.030792302035645 

training_11858    0: 0.440358675910783   6: 0.396770749284448   3: 0.052476833350856   8: 0.015786046013613   1: 0.015774017626019   9: 0.015768548108932   5: 0.015767185329547   7: 0.015766011403784   2: 0.015765967777092   4: 0.015765965194925 

training_11859    5: 0.694704183567380   1: 0.161286928572108   6: 0.018009684796768   3: 0.018009415942240   9: 0.018004252247644   8: 0.018000548621162   0: 0.017998076725110   2: 0.017996845352987   4: 0.017995327327084   7: 0.017994736847518 

training_11860    6: 0.749235469521282   1: 0.063855834521585   0: 0.047648468597156   3: 0.037890161814525   5: 0.016962868903142   8: 0.016911723012015   7: 0.016874998412917   9: 0.016874753440808   4: 0.016873615368850   2: 0.016872106407720 

training_11861    6: 0.555743261984115   0: 0.260091857483095   1: 0.058138976598801   8: 0.056135619232551   4: 0.011652676260659   5: 0.011648829539247   2: 0.011647783635031   9: 0.011647231740476   3: 0.011647067437953   7: 0.011646696088072 

training_11862    6: 0.655811009287836   0: 0.127751525339446   5: 0.054075024340733   7: 0.023194947646053   8: 0.023194944146057   1: 0.023194790412355   9: 0.023194659465050   3: 0.023194552460908   2: 0.023194309136137   4: 0.023194237765425 

training_11863    6: 0.523549531886308   1: 0.283563571791786   2: 0.065195932344938   4: 0.039599829055307   0: 0.023993527978850   9: 0.016330904972202   3: 0.011958781666522   5: 0.011938201169919   8: 0.011935227112912   7: 0.011934492021255 

training_11864    9: 0.713364405227599   6: 0.113362963701778   8: 0.021677115101604   5: 0.021657330340469   0: 0.021657130785987   7: 0.021656472465556   1: 0.021656356368941   4: 0.021656134097400   2: 0.021656061345231   3: 0.021656030565436 

training_11866    6: 0.825864206585398   0: 0.051515257020986   9: 0.034247822594104   3: 0.013197836316129   1: 0.012538615964406   8: 0.012532073706150   7: 0.012526757418650   5: 0.012526420145477   2: 0.012525537859536   4: 0.012525472389165 

training_11867    0: 0.733208085210930   8: 0.079288892907214   1: 0.023464685600654   6: 0.023461818602255   5: 0.023443339152249   7: 0.023433826626347   4: 0.023425189953183   9: 0.023424805132678   3: 0.023424740407487   2: 0.023424616407004 

training_11871    0: 0.621572406142826   2: 0.159528775520590   5: 0.027364460646376   6: 0.027364046227173   1: 0.027363454330211   4: 0.027362577272246   7: 0.027361361139869   9: 0.027361307158017   8: 0.027360997271566   3: 0.027360614291126 

training_11872    6: 0.560976048271105   9: 0.299966040788230   5: 0.017385872252394   1: 0.017385782239948   0: 0.017385202488956   4: 0.017381410389527   2: 0.017380512486301   7: 0.017379905749252   3: 0.017379851800614   8: 0.017379373533672 

training_11873    2: 0.508785705755839   1: 0.278388588210302   7: 0.062381615920347   6: 0.021504556912272   0: 0.021495410293820   5: 0.021491611724372   4: 0.021489740979729   9: 0.021488274794737   8: 0.021487335428308   3: 0.021487159980275 

training_11876    7: 0.742683045793609   1: 0.028628046512203   0: 0.028596715537000   5: 0.028592897869153   6: 0.028586959722276   4: 0.028586846356303   2: 0.028584074201419   9: 0.028583521367362   3: 0.028579911275508   8: 0.028577981365168 

training_11877    5: 0.695458872255982   6: 0.103832097042850   0: 0.077806046473507   1: 0.017567092656848   4: 0.017559002241499   9: 0.017555815161240   8: 0.017555787646652   3: 0.017555102882209   7: 0.017555099297270   2: 0.017555084341942 

training_11878    4: 0.797978525115410   5: 0.057493286596993   6: 0.018073858972693   9: 0.018065747988219   1: 0.018065698665015   0: 0.018064996806018   8: 0.018064697336120   3: 0.018064468682693   2: 0.018064369268277   7: 0.018064350568563 

training_11879    3: 0.549256118977287   4: 0.218566915509661   5: 0.029038115950513   6: 0.029020413788275   0: 0.029020255923523   8: 0.029020162807336   9: 0.029019655445648   2: 0.029019626963663   7: 0.029019408658584   1: 0.029019325975510 

training_1188     5: 0.696444745593920   4: 0.097076488158239   0: 0.077199075728657   1: 0.018602269237039   7: 0.018451066640304   6: 0.018445852586363   8: 0.018445213552150   3: 0.018445166654214   2: 0.018445071483200   9: 0.018445050365914 

training_11880    6: 0.559353847337392   3: 0.156034388969282   2: 0.109441733030404   1: 0.053606472266957   7: 0.041828446795789   9: 0.016000864316200   5: 0.015934060792744   8: 0.015933988040400   0: 0.015933520138941   4: 0.015932678311891 

training_11882    6: 0.852777011094181   0: 0.045439570004009   7: 0.029497238940166   1: 0.010395934577745   3: 0.010320596235833   5: 0.010318778796739   4: 0.010313746766558   8: 0.010312785829424   9: 0.010312459142485   2: 0.010311878612860 

training_11883    5: 0.409263059476040   6: 0.368089368258140   9: 0.069935635333926   1: 0.046142194251720   0: 0.017783026392662   3: 0.017768306308124   4: 0.017755285842910   8: 0.017754539237939   7: 0.017754448078372   2: 0.017754136820166 

training_11884    5: 0.764462850511643   9: 0.070988012687734   4: 0.020571728460034   6: 0.020570275840873   1: 0.020569385160136   0: 0.020568349344677   7: 0.020567696274290   8: 0.020567500280600   2: 0.020567204425524   3: 0.020566997014490 

training_11885    6: 0.637343483328979   0: 0.150297803416364   5: 0.054680467201414   3: 0.036880665826199   7: 0.036617333318546   4: 0.016841453102369   8: 0.016839439273943   2: 0.016834091270649   9: 0.016832732893813   1: 0.016832530367724 

training_11886    6: 0.650035995507485   4: 0.154256420374539   7: 0.056103175725973   0: 0.039187193064657   5: 0.016738692248090   1: 0.016736366702817   8: 0.016735630536120   9: 0.016735537869614   3: 0.016735495369792   2: 0.016735492600913 

training_11888    0: 0.772681791357882   2: 0.080967145302140   1: 0.043644209181842   6: 0.014677789496492   8: 0.014673107416518   5: 0.014672537400759   4: 0.014671212402688   7: 0.014670878971664   9: 0.014670828316517   3: 0.014670500153498 

training_11891    6: 0.375766434841876   1: 0.297576667986543   7: 0.239839670039906   5: 0.012407034558691   8: 0.012405626362421   0: 0.012403557366850   4: 0.012401144665551   9: 0.012400994601155   2: 0.012399651445982   3: 0.012399218131025 

training_11892    4: 0.615016213219348   6: 0.193674543507020   2: 0.050729504331131   5: 0.020096438637099   1: 0.020090846813444   0: 0.020085045347831   9: 0.020077966184513   8: 0.020077202172172   7: 0.020076499370188   3: 0.020075740417253 

training_11893    6: 0.862723251943388   0: 0.026497728395597   5: 0.013956267935651   8: 0.013859876891649   9: 0.013844980456758   1: 0.013823970242435   7: 0.013823675246759   2: 0.013823477745553   4: 0.013823429697090   3: 0.013823341445118 

training_11894    6: 0.710377302393284   0: 0.128167814973858   5: 0.020184115243759   9: 0.020182276741345   8: 0.020181965314746   1: 0.020181738197835   7: 0.020181697980750   2: 0.020181201542744   3: 0.020180975311028   4: 0.020180912300650 

training_11895    0: 0.644372211936127   3: 0.130744740839239   9: 0.091454334455895   6: 0.019066838802935   8: 0.019063540037065   5: 0.019062402768104   1: 0.019060584160173   4: 0.019059363403029   2: 0.019058465511218   7: 0.019057518086216 

training_11896    5: 0.613336997181406   3: 0.209132039933836   0: 0.022212782605790   6: 0.022209154264451   1: 0.022200348197353   4: 0.022186931859637   7: 0.022183902325792   9: 0.022180122017867   8: 0.022179025932977   2: 0.022178695680892 

training_11898    5: 0.780574791346687   9: 0.063975870963063   3: 0.019444913393308   8: 0.019438139923054   6: 0.019431602759288   4: 0.019429541886292   2: 0.019427750149433   0: 0.019426859216428   1: 0.019426054604333   7: 0.019424475758115 

training_11900    6: 0.837668454899075   7: 0.018049498400909   0: 0.018039972683619   5: 0.018036691992959   3: 0.018035351680143   1: 0.018035121851533   8: 0.018034761077763   9: 0.018033430317622   2: 0.018033367149447   4: 0.018033349946929 

training_11903    2: 0.748583954981097   6: 0.027947669283644   0: 0.027940460025698   9: 0.027939177209235   8: 0.027933848724631   1: 0.027932705176341   5: 0.027931575409137   7: 0.027930895886994   3: 0.027930184069053   4: 0.027929529234170 

training_11904    4: 0.762844535068091   7: 0.076322232133267   5: 0.020109245191569   0: 0.020103890262566   1: 0.020103608735055   8: 0.020103389733336   6: 0.020103370511211   9: 0.020103336210088   2: 0.020103234341188   3: 0.020103157813629 

training_11905    1: 0.428028001380431   6: 0.367372120510909   0: 0.025580499208732   5: 0.025575593781055   4: 0.025574910208054   7: 0.025574637938319   9: 0.025573750671360   3: 0.025573592384208   2: 0.025573518939504   8: 0.025573374977428 

training_11907    6: 0.481896722128648   2: 0.311288436554505   3: 0.073091601420762   5: 0.019135436148404   0: 0.019128627363364   1: 0.019114658086013   4: 0.019099948384919   9: 0.019082227398223   8: 0.019081624308440   7: 0.019080718206722 

training_11908    5: 0.419906666498231   1: 0.307355300585295   4: 0.114014141496564   6: 0.022676707884466   0: 0.022676379714212   2: 0.022675996539596   9: 0.022674665277105   3: 0.022674095916365   7: 0.022673145661679   8: 0.022672900426487 

training_11909    9: 0.353775809208246   4: 0.249464602718263   0: 0.240511368551947   8: 0.046227812019306   5: 0.018374546435389   6: 0.018338672989042   1: 0.018330615326396   3: 0.018326228890996   2: 0.018325249190111   7: 0.018325094670305 

training_1191     5: 0.501003512047042   8: 0.273535505749222   7: 0.075069955357804   4: 0.021491101382107   3: 0.021485169779762   0: 0.021483044606324   9: 0.021482952834361   2: 0.021482952217700   1: 0.021482909483496   6: 0.021482896542182 

training_11910    6: 0.754473753483271   1: 0.113681419858342   8: 0.032439395159474   5: 0.014208394665911   4: 0.014206431438660   0: 0.014202203190935   2: 0.014197397305670   9: 0.014197244514134   7: 0.014196890459644   3: 0.014196869923959 

training_11911    7: 0.441769467292546   6: 0.300593712124087   2: 0.129140738001519   0: 0.018372180297777   8: 0.018369569518617   3: 0.018352933509772   5: 0.018350864127920   1: 0.018350422731624   9: 0.018350157534918   4: 0.018349954861220 

training_11913    6: 0.329013190173396   2: 0.306672213114965   8: 0.213353442884634   4: 0.021597268568237   5: 0.021566775699650   3: 0.021563071177929   0: 0.021561271329286   1: 0.021561064629561   9: 0.021556287374114   7: 0.021555415048228 

training_11914    6: 0.545490460160595   0: 0.312390388380011   1: 0.064889422259888   9: 0.013519783859117   7: 0.011076948990146   2: 0.010552377445589   8: 0.010534206582110   5: 0.010520387100859   4: 0.010516024002841   3: 0.010510001218845 

training_11915    6: 0.443481237920697   1: 0.336771161089635   0: 0.096363252542289   5: 0.017628090124424   2: 0.017626647026426   4: 0.017626611120022   7: 0.017625958528481   9: 0.017625736164896   3: 0.017625667750329   8: 0.017625637732800 

training_11916    9: 0.405401889525902   0: 0.384842468934450   1: 0.050443653639447   8: 0.049658875848368   2: 0.018349357210533   6: 0.018330416542085   5: 0.018269396256878   4: 0.018235332138989   7: 0.018234341221536   3: 0.018234268681811 

training_11918    6: 0.433799870401263   9: 0.364454858746477   0: 0.082685794467261   1: 0.029120172948620   5: 0.014995658286520   4: 0.014993765252951   8: 0.014987997530849   3: 0.014987852134871   2: 0.014987203796384   7: 0.014986826434804 

training_1192     5: 0.776598994063945   4: 0.024824425369812   6: 0.024824372706134   0: 0.024822230821137   7: 0.024822056470025   9: 0.024821996588303   1: 0.024821972394351   8: 0.024821378531451   2: 0.024821311195958   3: 0.024821261858885 

training_11920    1: 0.430105805036964   7: 0.395611586500291   9: 0.052483494668436   5: 0.017401674485572   6: 0.017401512633665   0: 0.017401020475673   4: 0.017399626426244   2: 0.017398646809060   8: 0.017398451532385   3: 0.017398181431711 

training_11923    0: 0.550889506379068   1: 0.260376433650997   5: 0.023597628750039   4: 0.023593590950010   6: 0.023592652333878   9: 0.023590500458547   3: 0.023590334116103   2: 0.023589842036744   8: 0.023589768831547   7: 0.023589742493068 

training_11925    4: 0.582857258798207   6: 0.224340822610885   0: 0.052801618899408   1: 0.020034813874808   5: 0.020002283883712   9: 0.019993060076072   2: 0.019992835638744   7: 0.019992734299405   3: 0.019992343620911   8: 0.019992228297847 

training_1193     6: 0.530377867802725   5: 0.314218203635235   0: 0.063115925039339   8: 0.031322210918559   1: 0.010175340981671   7: 0.010159394562923   9: 0.010158767010969   4: 0.010157950110359   3: 0.010157205223788   2: 0.010157134714431 

training_11930    5: 0.770080540229231   3: 0.025547330661580   4: 0.025547015814338   0: 0.025546535637263   8: 0.025546499369654   1: 0.025546466236678   6: 0.025546465811734   2: 0.025546433927923   7: 0.025546373568639   9: 0.025546338742961 

training_11932    7: 0.527730242675916   5: 0.332193414991453   6: 0.017519562381914   2: 0.017510403525830   0: 0.017509041007923   8: 0.017508754809152   9: 0.017508553642919   1: 0.017508188686869   4: 0.017506196179008   3: 0.017505642099017 

training_11933    0: 0.516247153239082   5: 0.358646730969261   6: 0.015642147201512   1: 0.015639506239683   9: 0.015637991087844   7: 0.015637482328767   2: 0.015637401343026   4: 0.015637291731024   3: 0.015637164614072   8: 0.015637131245729 

training_11934    2: 0.505460806852054   6: 0.309900101524866   1: 0.023094753136869   5: 0.023079635413713   0: 0.023079425896219   9: 0.023079220720088   8: 0.023078317741596   7: 0.023076063822143   4: 0.023076030361388   3: 0.023075644531064 

training_11935    6: 0.441614117346837   3: 0.343402318175987   5: 0.026878529408207   4: 0.026875116717157   1: 0.026874314491521   7: 0.026873340424743   0: 0.026873109822773   2: 0.026870472190433   9: 0.026869430506662   8: 0.026869250915680 

training_11936    8: 0.497848717326075   6: 0.193512249839161   5: 0.186915349233361   2: 0.017422643816127   1: 0.017400692627420   7: 0.017393170524705   3: 0.017391876598726   0: 0.017379947537573   9: 0.017367845341970   4: 0.017367507154882 

training_11938    8: 0.753734246338269   6: 0.027377920632995   9: 0.027367453046090   0: 0.027366411257073   5: 0.027363291292420   7: 0.027360620024202   2: 0.027358405243867   1: 0.027357956790010   4: 0.027357463314223   3: 0.027356232060851 

training_11939    6: 0.593726420814082   8: 0.197815926168581   5: 0.112770562871357   0: 0.013698989523920   2: 0.013667728852724   1: 0.013664779779402   9: 0.013663976642136   7: 0.013663971186543   3: 0.013663824805369   4: 0.013663819355885 

training_11940    2: 0.516982648074817   6: 0.169751264506603   5: 0.137319555354893   0: 0.025139435474477   9: 0.025136982618637   8: 0.025136702521242   1: 0.025134233965463   7: 0.025133523428718   3: 0.025132961829423   4: 0.025132692225726 

training_11941    9: 0.753606809591809   6: 0.027383098454847   5: 0.027382717179003   8: 0.027380615504451   0: 0.027378018045815   1: 0.027375721561308   4: 0.027374427549990   2: 0.027374090407298   7: 0.027372958531787   3: 0.027371543173692 

training_11944    0: 0.768762239543610   5: 0.025700487107328   6: 0.025698207802825   8: 0.025693864246671   9: 0.025693091403661   3: 0.025691705034774   1: 0.025690962617713   7: 0.025690607743437   2: 0.025689571718129   4: 0.025689262781851 

training_11945    5: 0.410800826872890   0: 0.393790233940648   7: 0.024448974432302   6: 0.024428971761531   1: 0.024424860734564   2: 0.024424253334275   9: 0.024420756441759   4: 0.024420466497004   8: 0.024420423361377   3: 0.024420232623650 

training_11946    6: 0.408124550561962   8: 0.372897420379183   0: 0.111036889063660   1: 0.015425195415037   5: 0.015421226446730   2: 0.015419599777242   9: 0.015419272091945   4: 0.015419194893937   7: 0.015418399707131   3: 0.015418251663174 

training_11947    1: 0.747305548205164   5: 0.028118549860261   4: 0.028093516604039   0: 0.028071465668856   9: 0.028071296891685   6: 0.028070910574245   3: 0.028068639717885   8: 0.028067717967283   7: 0.028066242152809   2: 0.028066112357773 

training_11949    6: 0.838355770827686   0: 0.047728072111771   7: 0.029244254225322   1: 0.012262307049931   5: 0.012070366084071   8: 0.012068514320490   3: 0.012068337202286   9: 0.012067879857906   4: 0.012067332488342   2: 0.012067165832196 

training_11953    5: 0.422618412250605   0: 0.237042005082315   6: 0.204596653202915   2: 0.039043687636858   7: 0.016144304054440   9: 0.016117051552858   8: 0.016110043053254   3: 0.016109430723823   4: 0.016109314558644   1: 0.016109097884288 

training_11954    0: 0.582727377213258   4: 0.181067508232049   5: 0.071951144256429   9: 0.039012971181201   8: 0.037524496043607   1: 0.017550111818449   6: 0.017548439882517   2: 0.017542704533947   7: 0.017537658641701   3: 0.017537588196843 

training_11957    5: 0.446079759583141   0: 0.286600893133692   6: 0.091006537958677   8: 0.046860450030110   9: 0.029156057185680   7: 0.020570626275042   2: 0.019940635573163   1: 0.019932384150995   3: 0.019926371306050   4: 0.019926284803451 

training_11958    6: 0.460218750432395   3: 0.329129857036727   5: 0.026337106649181   4: 0.026333784331004   1: 0.026332114588697   7: 0.026331566302707   0: 0.026331318211878   2: 0.026329213080879   9: 0.026328259052955   8: 0.026328030313578 

training_11960    2: 0.708786481164874   5: 0.073466242130729   6: 0.027230138714976   0: 0.027228038095109   9: 0.027219877545891   8: 0.027219446252552   4: 0.027217923097602   1: 0.027212781467600   7: 0.027210069997592   3: 0.027209001533075 

training_11961    5: 0.631634716491412   6: 0.197685635833149   9: 0.036065208237555   7: 0.019254583775141   0: 0.019240762278527   8: 0.019224149382006   3: 0.019224050119187   1: 0.019223994971443   4: 0.019223586471409   2: 0.019223312440170 

training_11962    2: 0.467354669255757   1: 0.293990357136115   0: 0.108029967471506   8: 0.018670367983774   6: 0.018667389145256   5: 0.018664308093279   9: 0.018656979738895   4: 0.018656317812755   7: 0.018654929576454   3: 0.018654713786210 

training_11964    6: 0.555460003622162   0: 0.203952021179350   2: 0.116104640875794   7: 0.029322627980571   5: 0.015860446609067   1: 0.015860412180306   9: 0.015860110885555   8: 0.015860000871431   4: 0.015859940770511   3: 0.015859795025253 

training_11966    5: 0.748307155632148   4: 0.027973266333809   0: 0.027965132514135   8: 0.027965123544016   6: 0.027965121426878   1: 0.027964979974715   7: 0.027964824456755   3: 0.027964820019005   2: 0.027964799050358   9: 0.027964777048183 

training_11967    5: 0.774231397917581   6: 0.072865069579573   4: 0.019115491727580   8: 0.019114428251951   9: 0.019113266746671   0: 0.019112801516252   7: 0.019112089089501   2: 0.019111927163887   1: 0.019111779844760   3: 0.019111748162243 

training_11968    1: 0.830092013658126   0: 0.037498538586183   8: 0.016558712753266   5: 0.016556625724552   6: 0.016554046390952   9: 0.016552830428266   3: 0.016547495820379   4: 0.016547015677115   7: 0.016546407750657   2: 0.016546313210504 

training_1197     6: 0.822601115937012   1: 0.041129199641473   0: 0.038853356764386   7: 0.022543981287879   8: 0.012480692604331   5: 0.012478882132525   9: 0.012478384261917   2: 0.012478145522261   4: 0.012478128146430   3: 0.012478113701785 

training_11970    5: 0.420640215769287   6: 0.394122710849558   0: 0.023157122737009   8: 0.023156974584114   1: 0.023156448995671   7: 0.023153760101451   9: 0.023153723052594   2: 0.023153447390406   3: 0.023152869457742   4: 0.023152727062168 

training_11972    6: 0.503154959442713   3: 0.307015098120671   0: 0.051763316355625   5: 0.019763312819101   1: 0.019742195292227   7: 0.019720397414199   9: 0.019711917358315   2: 0.019711657820504   8: 0.019709018866988   4: 0.019708126509657 

training_11976    5: 0.672642048990577   0: 0.132458022015993   4: 0.024365230482125   6: 0.024363502745330   1: 0.024363243401798   9: 0.024362010533577   8: 0.024361662130536   3: 0.024361615493156   2: 0.024361358364166   7: 0.024361305842741 

training_11977    5: 0.733803659227317   4: 0.029580699651928   6: 0.029577525781929   0: 0.029577344871791   1: 0.029577222471238   8: 0.029576818965682   9: 0.029576791829793   3: 0.029576758030931   7: 0.029576601620934   2: 0.029576577548457 

training_11978    5: 0.750611121330361   4: 0.027716126026681   1: 0.027709847731205   8: 0.027709254025918   0: 0.027709156396722   6: 0.027709006200132   9: 0.027708911113623   2: 0.027708893918751   3: 0.027708864302470   7: 0.027708818954137 

training_11979    4: 0.592575317262533   6: 0.239561920705651   2: 0.020989397172766   0: 0.020987272874134   5: 0.020986644384959   1: 0.020983252448124   8: 0.020979693850991   9: 0.020979438920052   7: 0.020978686496060   3: 0.020978375884730 

training_1198     5: 0.550121729701889   2: 0.273486563514805   7: 0.051677685197009   6: 0.017819600909673   0: 0.017817717206775   4: 0.017817462589815   1: 0.017815929506384   3: 0.017814787486352   9: 0.017814309331691   8: 0.017814214555607 

training_11980    5: 0.763723276210173   4: 0.026257768376212   8: 0.026252504146722   3: 0.026252473139465   2: 0.026252406912951   7: 0.026252358442600   0: 0.026252323091230   6: 0.026252322084744   9: 0.026252290901934   1: 0.026252276693970 

training_11981    6: 0.628492945773438   5: 0.162797877945702   8: 0.069819868494317   1: 0.019848009453162   0: 0.019842442412274   4: 0.019841382107504   3: 0.019840044711185   2: 0.019839559142083   9: 0.019839038501689   7: 0.019838831458647 

training_11982    4: 0.328161139210208   6: 0.273909115222954   1: 0.258891262335292   9: 0.047721881803283   0: 0.015222395894909   5: 0.015221406586912   2: 0.015218914179931   8: 0.015218718431315   7: 0.015217628840009   3: 0.015217537495187 

training_11983    1: 0.710128890202468   0: 0.126993547672767   5: 0.020384037926459   4: 0.020363560233081   6: 0.020357234480873   9: 0.020356390029506   3: 0.020355982335570   2: 0.020354764281713   8: 0.020353163403644   7: 0.020352429433920 

training_11984    6: 0.563551190741638   8: 0.235752979733449   0: 0.072672548460053   3: 0.035906468398662   1: 0.023389264371853   2: 0.013800376399820   5: 0.013761664659724   9: 0.013722748244471   7: 0.013721523200820   4: 0.013721235789511 

training_11989    8: 0.738468614578030   2: 0.029141133736560   5: 0.029115151016997   6: 0.029066114210633   1: 0.029065786286103   0: 0.029050283245155   9: 0.029040407462574   7: 0.029025357748902   3: 0.029018176039384   4: 0.029008975675663 

training_11990    5: 0.663577863042478   0: 0.150993376382814   4: 0.060448335186553   6: 0.017866182296493   3: 0.017860987203101   9: 0.017852469519392   7: 0.017851369409756   8: 0.017850259237297   1: 0.017849625517685   2: 0.017849532204430 

training_11993    4: 0.784124193815849   6: 0.024000598861252   5: 0.023988162517968   8: 0.023984941911513   0: 0.023984183531689   9: 0.023984092470389   3: 0.023983605212266   2: 0.023983439419115   7: 0.023983404594227   1: 0.023983377665733 

training_11994    5: 0.685897151719131   0: 0.122140158101109   1: 0.023997879288671   3: 0.023995356291135   4: 0.023995235306714   8: 0.023995191186963   6: 0.023994828904342   2: 0.023994761210000   7: 0.023994734994157   9: 0.023994702997778 

training_11996    2: 0.573819398083605   4: 0.254526589423182   1: 0.021464816630077   6: 0.021459802100325   0: 0.021458997626460   5: 0.021458524436492   9: 0.021453814249785   8: 0.021453198572130   7: 0.021452569134425   3: 0.021452289743518 

training_11997    4: 0.458915068539456   6: 0.250965740785063   5: 0.146424448757121   8: 0.036648520925042   9: 0.017891968595277   0: 0.017836789413235   1: 0.017832276190094   2: 0.017828746803391   3: 0.017828224648074   7: 0.017828215343247 

training_11999    6: 0.458194222641909   5: 0.279805587409054   9: 0.152262566487231   0: 0.015681233321813   1: 0.015678478247430   4: 0.015676294993737   7: 0.015676070341240   2: 0.015675670469439   3: 0.015675055366713   8: 0.015674820721433 

training_12       6: 0.564409163348268   5: 0.238920558589023   0: 0.058185115647646   2: 0.046786148736061   1: 0.015307441819268   9: 0.015279683485377   4: 0.015278926289390   3: 0.015278016590790   7: 0.015277631490902   8: 0.015277314003273 

training_1200     4: 0.833355495247357   5: 0.018521001498237   6: 0.018517040813198   0: 0.018516309432324   1: 0.018515211728773   9: 0.018515161583035   2: 0.018515004007745   8: 0.018515000812437   3: 0.018514943911606   7: 0.018514830965287 

training_12001    5: 0.733062453176113   8: 0.093908508370880   6: 0.021632161384544   4: 0.021628795403045   3: 0.021628774080961   0: 0.021628089687033   1: 0.021627925451572   2: 0.021627896489867   9: 0.021627749224161   7: 0.021627646731826 

training_12002    6: 0.732592425235809   0: 0.148230368027389   8: 0.034384709508747   1: 0.031036871600756   9: 0.008960918787542   5: 0.008959293517736   3: 0.008959048201484   7: 0.008958895632931   2: 0.008958747152045   4: 0.008958722335562 

training_12003    6: 0.682344248119524   2: 0.146733568609317   0: 0.021379002980545   1: 0.021365069948280   5: 0.021364375993163   4: 0.021363354684590   7: 0.021362949989132   9: 0.021362583243981   8: 0.021362502781491   3: 0.021362343649977 

training_12005    2: 0.411995565054758   5: 0.322811042666957   3: 0.097019495961803   0: 0.024031191474349   9: 0.024030114373973   1: 0.024028125362250   4: 0.024024265085211   6: 0.024022470826580   7: 0.024018873876460   8: 0.024018855317659 

training_12007    6: 0.455181641431493   5: 0.294393106124244   9: 0.134170398877897   0: 0.016613643067840   1: 0.016610060110685   4: 0.016607133523439   7: 0.016606554037889   2: 0.016606282543667   3: 0.016605688218939   8: 0.016605492063908 

training_12008    6: 0.577375348701010   3: 0.204065820449092   5: 0.027320215180993   1: 0.027320127167341   7: 0.027320081678766   8: 0.027319821635940   0: 0.027319749857894   9: 0.027319636302195   2: 0.027319617451077   4: 0.027319581575690 

training_12009    6: 0.474319024823282   0: 0.382390206403770   8: 0.042562792568273   1: 0.014390220473886   5: 0.014390074162574   3: 0.014390051517231   7: 0.014389517891876   2: 0.014389512813184   9: 0.014389459921263   4: 0.014389139424662 

training_1201     6: 0.733580795219883   0: 0.113456672877060   9: 0.048683044383525   1: 0.027504398389055   5: 0.012880678195147   3: 0.012787791047199   8: 0.012776924087450   7: 0.012776713665270   2: 0.012776495156831   4: 0.012776486978579 

training_12010    9: 0.798076756091399   5: 0.022441436619333   8: 0.022440881032634   6: 0.022439820756279   0: 0.022435229370075   4: 0.022434905647831   7: 0.022433209581374   1: 0.022433079038307   2: 0.022432860216733   3: 0.022431821646036 

training_12011    6: 0.813071877621952   1: 0.046201447200558   8: 0.039485081486443   0: 0.024810686142557   7: 0.017985772687474   3: 0.015560042056808   5: 0.010722648428167   9: 0.010720904446126   4: 0.010720800707701   2: 0.010720739222215 

training_12014    5: 0.365447044771361   7: 0.295311549051584   3: 0.163688352712598   4: 0.025082819304019   6: 0.025082170418967   0: 0.025078329614304   9: 0.025077774853967   8: 0.025077670664806   1: 0.025077301091505   2: 0.025076987516889 

training_12016    9: 0.763599178858687   5: 0.026272704965520   6: 0.026272552784531   8: 0.026270397665807   0: 0.026267770738940   1: 0.026265403061868   4: 0.026264283402044   2: 0.026263687347794   7: 0.026262699286661   3: 0.026261321888148 

training_12017    4: 0.518172416122862   1: 0.196845046467943   3: 0.132751082119306   5: 0.021753100484740   6: 0.021752793103238   0: 0.021746930876706   9: 0.021745663015939   8: 0.021744624049577   2: 0.021744353143408   7: 0.021743990616282 

training_12018    1: 0.549445551050256   2: 0.199391894189417   6: 0.031403710926624   5: 0.031398307701766   0: 0.031397453983184   8: 0.031394296375050   4: 0.031392599110649   9: 0.031392276888345   7: 0.031391976721778   3: 0.031391933052930 

training_12019    6: 0.747039176393423   8: 0.028128798455581   0: 0.028111005823997   1: 0.028104217347139   2: 0.028103940223538   9: 0.028103337294821   5: 0.028102584349665   7: 0.028102564214911   3: 0.028102336133765   4: 0.028102039763160 

training_12022    5: 0.804830906891519   6: 0.021688500491544   4: 0.021686283207187   1: 0.021685466066927   0: 0.021685320872337   7: 0.021685009001949   9: 0.021684974989546   2: 0.021684565630303   8: 0.021684532473344   3: 0.021684440375344 

training_12024    7: 0.666836030663274   2: 0.145446662092178   6: 0.023475970688478   5: 0.023471496899777   0: 0.023466573091286   1: 0.023466346661465   4: 0.023463415484955   3: 0.023458190180837   8: 0.023457706477419   9: 0.023457607760330 

training_12027    6: 0.722722658901522   1: 0.116433997140429   3: 0.047147697608517   8: 0.016245833960121   0: 0.016244451006026   9: 0.016241797343752   5: 0.016241446616061   2: 0.016240892559526   7: 0.016240737117697   4: 0.016240487746348 

training_12028    1: 0.623688955410910   2: 0.112040788770730   5: 0.087443886360699   4: 0.045128844991651   6: 0.042334057961183   0: 0.017941729370985   7: 0.017906146440940   8: 0.017863449332788   9: 0.017826944212455   3: 0.017825197147659 

training_1203     1: 0.793078227696702   0: 0.037998990291082   7: 0.021168610333743   9: 0.021114462722047   6: 0.021109844304132   5: 0.021107561536527   4: 0.021105753901297   2: 0.021105593025905   3: 0.021105555230780   8: 0.021105400957785 

training_12031    5: 0.784906817287306   1: 0.059979819482804   4: 0.019391465257448   6: 0.019390016750663   2: 0.019389010865303   0: 0.019388963031377   9: 0.019388845172693   7: 0.019388581811026   8: 0.019388332388347   3: 0.019388147953032 

training_12032    1: 0.719766366147491   0: 0.031143090803881   6: 0.031139803972194   8: 0.031136815256974   5: 0.031136457751398   9: 0.031136201704758   7: 0.031135603110918   4: 0.031135543678228   2: 0.031135403994056   3: 0.031134713580102 

training_12033    5: 0.822403208376194   4: 0.019737377332139   0: 0.019732970324295   6: 0.019732968739854   1: 0.019732704718088   8: 0.019732252382529   2: 0.019732172151698   7: 0.019732142610617   9: 0.019732126892592   3: 0.019732076471994 

training_12035    4: 0.671562267382991   5: 0.109744277366659   1: 0.027338731480630   7: 0.027337527415815   6: 0.027337065301368   0: 0.027337037006755   2: 0.027335894747048   9: 0.027335796141095   8: 0.027335788061588   3: 0.027335615096052 

training_12036    3: 0.580613392607557   5: 0.216703635297518   4: 0.025336895622566   0: 0.025335382942899   6: 0.025335378654478   8: 0.025335337697191   1: 0.025335284590041   2: 0.025335049231872   7: 0.025334891158567   9: 0.025334752197312 

training_12040    9: 0.773923804931880   6: 0.025125727997381   5: 0.025125722998609   8: 0.025123193508047   0: 0.025120529241259   1: 0.025118080995023   4: 0.025117142252221   2: 0.025116272258705   7: 0.025115433242585   3: 0.025114092574289 

training_12042    5: 0.786072601140099   4: 0.023772881947862   8: 0.023769609107211   6: 0.023769392106120   3: 0.023769317323561   9: 0.023769309654199   7: 0.023769287877787   2: 0.023769265726245   0: 0.023769190401873   1: 0.023769144715042 

training_12044    0: 0.348880985207002   6: 0.278743799026279   2: 0.252037065220166   3: 0.025295108000383   1: 0.022536901321415   7: 0.014648499313412   9: 0.014469999118183   5: 0.014469181967762   4: 0.014461823041655   8: 0.014456637783744 

training_12045    0: 0.614595324169039   5: 0.220027757692566   6: 0.020674233488766   1: 0.020672856854646   2: 0.020672275169743   9: 0.020671802934485   8: 0.020671570366920   4: 0.020671562504145   3: 0.020671469649515   7: 0.020671147170173 

training_12046    9: 0.618742076108651   6: 0.211660504617434   5: 0.021218470998607   0: 0.021210043528408   1: 0.021196318755100   7: 0.021195507164214   2: 0.021195160411148   8: 0.021194160099574   4: 0.021194147857426   3: 0.021193610459440 

training_12048    7: 0.295165736756228   1: 0.289537892626750   5: 0.267057951678288   0: 0.044486038375988   6: 0.017299846228823   3: 0.017299697467518   4: 0.017289220120999   9: 0.017288078477725   8: 0.017287892154851   2: 0.017287646112831 

training_12049    1: 0.567171622643788   0: 0.244411501785313   5: 0.053015874293826   6: 0.019377642339419   4: 0.019343279283654   3: 0.019336649438700   2: 0.019336521885846   8: 0.019335931763522   7: 0.019335495575442   9: 0.019335480990491 

training_1205     2: 0.452242614253643   5: 0.336213668482167   4: 0.026450536515235   8: 0.026442427201703   6: 0.026441978636452   9: 0.026441830196566   3: 0.026441824947622   0: 0.026441804177492   7: 0.026441698413062   1: 0.026441617176058 

training_12050    0: 0.313685887419454   6: 0.215711603292901   7: 0.213771178659458   9: 0.162049778708333   5: 0.015810430360182   2: 0.015809770515911   1: 0.015791383977988   4: 0.015790464812265   8: 0.015790348205889   3: 0.015789154047619 

training_12052    6: 0.794250656016651   0: 0.091582033222022   7: 0.014275096396670   2: 0.014271901900386   5: 0.014270990619349   1: 0.014270597394094   8: 0.014270075573309   4: 0.014269778560817   9: 0.014269648579384   3: 0.014269221737317 

training_12053    7: 0.359611621953831   6: 0.291865026071999   5: 0.215382066580746   1: 0.019029852453223   0: 0.019020302678775   9: 0.019020035529197   8: 0.019018408188843   3: 0.019017720634050   4: 0.019017530357356   2: 0.019017435551979 

training_12054    0: 0.772286647750002   6: 0.081106655768432   1: 0.018331283098817   5: 0.018328271042861   2: 0.018327082368536   8: 0.018326618888712   7: 0.018324142525736   4: 0.018323620122445   9: 0.018323156349498   3: 0.018322522084962 

training_12055    6: 0.709799283589056   7: 0.167708403095818   0: 0.015436597405762   8: 0.015298037071295   5: 0.015295035244327   1: 0.015293058515682   9: 0.015292768271903   4: 0.015292626625612   2: 0.015292141009239   3: 0.015292049171306 

training_12059    5: 0.572834273015872   6: 0.270729541271671   0: 0.019559049441938   1: 0.019555699874528   8: 0.019554440374492   9: 0.019554039804512   4: 0.019553888243114   7: 0.019553257097895   3: 0.019552908019632   2: 0.019552902856347 

training_12061    5: 0.774814420279977   0: 0.025117930586071   4: 0.025011078977217   6: 0.025008526846144   8: 0.025008490992862   7: 0.025008443372947   9: 0.025008033591186   3: 0.025007786086230   2: 0.025007698876158   1: 0.025007590391208 

training_12063    5: 0.707557659176215   4: 0.032496639278513   3: 0.032493320852820   6: 0.032493267972558   8: 0.032493267658259   2: 0.032493221699478   0: 0.032493200910737   7: 0.032493158790957   1: 0.032493135244232   9: 0.032493128416232 

training_12064    5: 0.592993124515101   4: 0.226293678830058   6: 0.022592767915506   3: 0.022589535352594   0: 0.022589000392106   1: 0.022588516499303   8: 0.022588483468964   9: 0.022588379571681   7: 0.022588259223515   2: 0.022588254231171 

training_12067    5: 0.796833880118003   3: 0.022574746984464   4: 0.022574285504347   1: 0.022574117245550   6: 0.022573977188155   2: 0.022573906925446   0: 0.022573847404191   7: 0.022573794170551   9: 0.022573740354145   8: 0.022573704105148 

training_12068    7: 0.356460409274807   6: 0.304509151372443   5: 0.205998685991164   1: 0.019013941907936   0: 0.019004685235034   9: 0.019004359594100   8: 0.019002813140465   3: 0.019002135044258   4: 0.019001943132581   2: 0.019001875307213 

training_1207     6: 0.798382690063164   0: 0.077517602109488   2: 0.015678093451526   7: 0.015492705204845   1: 0.015492667773012   5: 0.015488289062032   4: 0.015487763003018   8: 0.015486917846980   9: 0.015486653907329   3: 0.015486617578606 

training_12073    6: 0.858359482160366   1: 0.030164908755303   8: 0.013972187844005   0: 0.013943305316521   7: 0.013935802171058   9: 0.013925575082676   5: 0.013925334745305   4: 0.013924497732589   3: 0.013924456344156   2: 0.013924449848020 

training_12076    6: 0.397289659794790   7: 0.234482277896386   3: 0.188579352459914   1: 0.025667910611006   8: 0.025665449656753   0: 0.025665346469888   5: 0.025663169383898   2: 0.025662522154425   4: 0.025662447092950   9: 0.025661864479991 

training_12077    5: 0.578692663905478   4: 0.197224676733047   6: 0.068521702106640   7: 0.057781883064035   0: 0.016303892831182   3: 0.016298834259747   2: 0.016294993494511   1: 0.016294408181241   8: 0.016293604284572   9: 0.016293341139546 

training_12078    4: 0.807427594002021   1: 0.021419828430385   6: 0.021405385605300   5: 0.021397083080539   2: 0.021392854982763   8: 0.021392716445137   0: 0.021392081402777   7: 0.021391449940388   9: 0.021390531823223   3: 0.021390474287467 

training_12079    5: 0.793462807401141   6: 0.022956569760754   4: 0.022953577682745   0: 0.022952522428925   1: 0.022946299575009   9: 0.022946299167202   8: 0.022945966686353   7: 0.022945431217660   3: 0.022945292868789   2: 0.022945233211424 

training_1208     9: 0.460360522495574   5: 0.219558992144164   6: 0.151275676713936   0: 0.043776677310331   2: 0.026850088934787   1: 0.025787248715998   8: 0.018151149404461   4: 0.018080771803812   7: 0.018079500657851   3: 0.018079371819087 

training_12080    6: 0.520921012543387   0: 0.174012139510430   7: 0.103235127544458   3: 0.083531623228579   9: 0.019720191021353   5: 0.019719446300996   8: 0.019715588060029   1: 0.019715428812444   2: 0.019714842517364   4: 0.019714600460959 

training_12081    8: 0.841534096914797   5: 0.017679958951624   6: 0.017647319660632   4: 0.017602401364033   9: 0.017596921290222   0: 0.017589768408934   7: 0.017587777145318   3: 0.017587487698785   1: 0.017587217486251   2: 0.017587051079403 

training_12083    7: 0.351755901346002   6: 0.236253801535478   5: 0.192099900229082   0: 0.124571262482043   1: 0.016043366140234   8: 0.015861809620406   2: 0.015853833353337   4: 0.015853551945782   9: 0.015853550999438   3: 0.015853022348198 

training_12084    6: 0.803705590838895   2: 0.061308998732961   5: 0.038465872601440   8: 0.029474098893901   3: 0.013314156301748   1: 0.010799131007900   0: 0.010737656309973   7: 0.010733843032336   9: 0.010730515404066   4: 0.010730136876780 

training_12085    5: 0.483145975771054   6: 0.302170435345682   8: 0.076860568641949   2: 0.019691931893571   4: 0.019690310452051   1: 0.019690095297599   0: 0.019688636180865   7: 0.019687852210335   9: 0.019687247244036   3: 0.019686946962858 

training_12087    0: 0.713365510056420   3: 0.085149901240826   6: 0.056362213345343   1: 0.020798551596116   5: 0.020723278084797   9: 0.020721349788621   4: 0.020720902769967   8: 0.020719667323450   2: 0.020719450112422   7: 0.020719175682040 

training_1209     8: 0.406932405232967   1: 0.379661516433605   9: 0.069797539008023   6: 0.020534217772540   0: 0.020517174672309   5: 0.020516535890190   4: 0.020511711225313   7: 0.020509668825202   3: 0.020509615540316   2: 0.020509615399534 

training_12091    9: 0.451966112127608   6: 0.267227460966749   3: 0.084523222288392   1: 0.070697786451359   5: 0.021055735989310   0: 0.020913355494630   2: 0.020905289287893   8: 0.020903987897050   4: 0.020903701652803   7: 0.020903347844206 

training_12093    9: 0.438524218179552   5: 0.361666490094647   2: 0.062004392131828   7: 0.019692089205618   0: 0.019691745775778   6: 0.019688679441226   1: 0.019686851990339   8: 0.019683112557427   4: 0.019681804638347   3: 0.019680615985239 

training_12094    4: 0.393972140723251   6: 0.351213811859969   8: 0.116014936849002   5: 0.019838221008270   0: 0.019831970572700   1: 0.019829483119446   7: 0.019825601163405   2: 0.019825034035701   3: 0.019824638689871   9: 0.019824161978385 

training_12098    5: 0.759219723729601   4: 0.026756954020939   8: 0.026753069758573   3: 0.026753062464007   2: 0.026752989379735   9: 0.026752929077914   1: 0.026752863917407   0: 0.026752858837063   7: 0.026752839112759   6: 0.026752709702002 

training_121      6: 0.759552699405740   0: 0.105915130337225   8: 0.016821321198896   7: 0.016819265234559   1: 0.016818944777530   5: 0.016815389527455   4: 0.016814872605486   9: 0.016814633048378   2: 0.016813890859548   3: 0.016813853005184 

training_1210     6: 0.673545217963974   0: 0.097184575917453   1: 0.063622481279614   4: 0.058811974205673   2: 0.051160448014205   5: 0.011136409312475   9: 0.011135317178536   3: 0.011135076511943   8: 0.011134348284599   7: 0.011134151331529 

training_12101    6: 0.587369421711025   4: 0.279058525175657   2: 0.016732863785789   0: 0.016724963196695   7: 0.016697335678845   5: 0.016689369344696   8: 0.016685292927558   1: 0.016681616699611   9: 0.016681016916070   3: 0.016679594564056 

training_12102    3: 0.475785987034497   5: 0.286561713132843   2: 0.029722828923748   6: 0.029721723130905   0: 0.029719082960337   8: 0.029705410303685   9: 0.029700261051022   7: 0.029698235157787   1: 0.029695300150433   4: 0.029689458154743 

training_12106    6: 0.230817497109174   5: 0.230484142491032   1: 0.180532436675074   0: 0.162937560344177   4: 0.102953339424614   3: 0.018470455715304   2: 0.018454191655626   9: 0.018452260257080   8: 0.018449494749245   7: 0.018448621578674 

training_1211     6: 0.790398796170140   0: 0.052628617677853   7: 0.037374503959686   3: 0.026192567237684   2: 0.023149570512923   9: 0.023126715375362   1: 0.011804922763047   5: 0.011777348609188   8: 0.011776165733241   4: 0.011770791960876 

training_12110    4: 0.610341168590609   6: 0.218548624957479   8: 0.021399703181560   5: 0.021398012978765   3: 0.021393139352580   0: 0.021385062335843   1: 0.021384224817871   9: 0.021384044743900   7: 0.021383410764015   2: 0.021382608277376 

training_12112    8: 0.574035285364924   2: 0.217937709227439   3: 0.026016518040172   6: 0.026011798710836   9: 0.026003168751496   0: 0.026002828147294   5: 0.026001243726772   1: 0.025998657214646   4: 0.025996546873850   7: 0.025996243942573 

training_12114    5: 0.504455692664840   0: 0.323758255150891   1: 0.021473963296205   4: 0.021473788052123   3: 0.021473579620229   2: 0.021473346490076   6: 0.021473113600081   9: 0.021472977952019   8: 0.021472752685001   7: 0.021472530488533 

training_12115    5: 0.724969161569726   8: 0.098536739027977   0: 0.049673295370883   4: 0.018120581801544   6: 0.018117121740294   1: 0.018116860456971   9: 0.018116716392674   3: 0.018116534370519   7: 0.018116514916019   2: 0.018116474353391 

training_12117    6: 0.757192415314681   5: 0.073115063391706   0: 0.021232590849878   8: 0.021215829658271   9: 0.021212022868498   1: 0.021206862934412   2: 0.021206818867119   7: 0.021206208606090   4: 0.021206155364218   3: 0.021206032145129 

training_12119    5: 0.512418915069247   2: 0.302919529435139   3: 0.023083778697115   6: 0.023083584004418   9: 0.023082961487943   4: 0.023082794614913   1: 0.023082196982113   7: 0.023082115252852   0: 0.023082113053037   8: 0.023082011403224 

training_1212     6: 0.677367093353060   8: 0.139099657533911   0: 0.056112988284225   1: 0.054514955783348   5: 0.020724588171861   7: 0.010436366953581   9: 0.010436150990879   4: 0.010436094386482   2: 0.010436075228050   3: 0.010436029314604 

training_12121    6: 0.694582652172477   0: 0.140590531111285   1: 0.073606505431854   9: 0.013032171340564   5: 0.013031771959610   8: 0.013031616928244   7: 0.013031400341233   4: 0.013031145549957   3: 0.013031107945481   2: 0.013031097219295 

training_12122    6: 0.828229731185551   3: 0.044846632103598   0: 0.030995055860120   1: 0.013733833195697   5: 0.013706456985533   9: 0.013703482278602   8: 0.013696572344297   4: 0.013696139204382   2: 0.013696061433168   7: 0.013696035409054 

training_12125    5: 0.685884404941036   1: 0.128676023678291   6: 0.023213439725142   2: 0.023202472316379   0: 0.023183426507126   8: 0.023176968364860   9: 0.023168584065043   3: 0.023168522754843   7: 0.023164327380562   4: 0.023161830266719 

training_12127    5: 0.580157369790611   9: 0.150333732687494   6: 0.101638054035753   2: 0.068958169475419   4: 0.024370765729200   7: 0.023413664754845   8: 0.012792168393697   1: 0.012788704858425   0: 0.012784716670379   3: 0.012762653604176 

training_12128    5: 0.774803137420225   3: 0.025022461050097   4: 0.025022201469620   1: 0.025021988994848   0: 0.025021975614642   6: 0.025021824294640   2: 0.025021661004725   7: 0.025021602388001   8: 0.025021578932145   9: 0.025021568831057 

training_1213     1: 0.748790217627424   9: 0.088948932264607   8: 0.037529476669002   0: 0.034420062468474   3: 0.015765422944018   6: 0.014952286956884   5: 0.014905934460409   2: 0.014898792663597   7: 0.014895800043676   4: 0.014893073901909 

training_12131    1: 0.407234421779595   3: 0.405794563027157   6: 0.023380675293361   0: 0.023376775323513   9: 0.023374593516619   8: 0.023372026680006   5: 0.023368505271734   2: 0.023367311364169   7: 0.023366021595508   4: 0.023365106148337 

training_12132    5: 0.513745790433849   6: 0.288532064566737   1: 0.045446558193908   4: 0.029766342145383   3: 0.028921027293365   8: 0.027733259042955   0: 0.016473954374920   2: 0.016467084053318   7: 0.016457047644554   9: 0.016456872251011 

training_12133    3: 0.442369388014598   0: 0.238576191089874   9: 0.089275464862017   1: 0.068592231966944   7: 0.059436605808121   4: 0.020373939833875   5: 0.020351219152180   6: 0.020346813848216   8: 0.020339113684238   2: 0.020339031739938 

training_12135    6: 0.442187477236003   0: 0.320950076735498   7: 0.135511883009309   2: 0.014486966401184   9: 0.014481357230494   5: 0.014477712677368   1: 0.014476697437168   8: 0.014476077044666   4: 0.014475907731247   3: 0.014475844497062 

training_12136    6: 0.724166298354554   0: 0.164883771875055   1: 0.053562072965622   9: 0.010799978565266   5: 0.008105973931307   8: 0.007719738184249   4: 0.007696154534967   2: 0.007691905366843   7: 0.007688160421222   3: 0.007685945800915 

training_12138    1: 0.645865208974530   2: 0.153984500494701   6: 0.077996994604916   0: 0.017527186965984   5: 0.017449230313789   4: 0.017443228253953   7: 0.017433684728163   8: 0.017433661715108   9: 0.017433297080713   3: 0.017433006868143 

training_12139    0: 0.751500718935437   5: 0.027619937520115   6: 0.027613733146672   9: 0.027610877499471   1: 0.027610263781174   3: 0.027609487656135   8: 0.027609024552096   4: 0.027608671326179   2: 0.027608667128760   7: 0.027608618453962 

training_12140    1: 0.300029888573545   0: 0.264125053689219   6: 0.216981033693016   5: 0.031268085887098   3: 0.031266966503063   2: 0.031266500559905   4: 0.031266009417633   9: 0.031265684112989   7: 0.031265423181706   8: 0.031265354381826 

training_12145    6: 0.713968666863185   0: 0.118121241554851   9: 0.050926470651715   1: 0.041448882085347   3: 0.012596162089599   5: 0.012587944954645   8: 0.012587926695220   7: 0.012587658377105   2: 0.012587556239911   4: 0.012587490488422 

training_12146    1: 0.568651388344120   6: 0.298875256576689   5: 0.047648406705191   3: 0.012149505418327   0: 0.012115183772637   2: 0.012112510377093   4: 0.012112181265787   8: 0.012111879028223   9: 0.012111852146775   7: 0.012111836365158 

training_12147    6: 0.499962638606216   0: 0.308119077391933   5: 0.072321803704508   4: 0.017095342584214   3: 0.017088180438505   2: 0.017087605507256   8: 0.017084274148354   1: 0.017081565753945   9: 0.017080098706385   7: 0.017079413158685 

training_12149    4: 0.748032982778269   7: 0.073423429854745   6: 0.022330383730359   2: 0.022325377147518   5: 0.022320240691435   1: 0.022315733458510   9: 0.022315075197994   0: 0.022313615285162   8: 0.022311689894755   3: 0.022311471961253 

training_1215     6: 0.732209219895285   5: 0.140404052349408   8: 0.030859371095364   7: 0.013832630545969   0: 0.013785318629541   1: 0.013783065783320   4: 0.013782113576672   9: 0.013781534001611   2: 0.013781430347607   3: 0.013781263775225 

training_12150    5: 0.718669042679462   2: 0.112933284975199   4: 0.021051480942905   1: 0.021051143870811   6: 0.021050273643085   0: 0.021049610752177   9: 0.021049141859759   8: 0.021049021578661   3: 0.021048545825293   7: 0.021048453872647 

training_12152    6: 0.793097172939401   3: 0.065933350797342   0: 0.044426996203675   1: 0.013802793419952   7: 0.013792629860160   5: 0.013790344357603   9: 0.013789221408300   8: 0.013789191921219   2: 0.013789175799911   4: 0.013789123292435 

training_12153    4: 0.629653785458896   6: 0.187234370034907   5: 0.022894344239634   1: 0.022892241909788   8: 0.022888694554586   0: 0.022888564232003   3: 0.022887199983210   7: 0.022887131857766   9: 0.022886839055713   2: 0.022886828673496 

training_12154    4: 0.768653499054414   5: 0.025711899884144   2: 0.025704504082406   8: 0.025704493582030   9: 0.025704424576130   6: 0.025704398095859   3: 0.025704206593438   0: 0.025704205386737   7: 0.025704198440649   1: 0.025704170304195 

training_12155    5: 0.791402829152265   6: 0.023182113138347   9: 0.023180285473332   8: 0.023178362737254   0: 0.023177457810963   1: 0.023176947776573   2: 0.023175889568343   4: 0.023175569605501   3: 0.023175352531396   7: 0.023175192206027 

training_12156    0: 0.561097029504398   6: 0.281290528463614   1: 0.079535421077215   2: 0.011250371397021   5: 0.011150082712988   9: 0.011149412276482   7: 0.011143098511623   3: 0.011129203938465   4: 0.011128429778760   8: 0.011126422339434 

training_12159    5: 0.434791864593252   6: 0.431714812196879   8: 0.016692941520551   0: 0.016690874009147   1: 0.016687501294249   9: 0.016685711568263   2: 0.016684531562835   3: 0.016684460282888   4: 0.016684353495371   7: 0.016682949476565 

training_1216     6: 0.605759721613277   1: 0.155937113965141   8: 0.104768825985103   0: 0.019077341858096   7: 0.019077206379522   5: 0.019076271705440   3: 0.019076101141204   9: 0.019075996170681   2: 0.019075925524849   4: 0.019075495656687 

training_12160    6: 0.536208677758036   7: 0.317512267295633   0: 0.072519298115863   8: 0.010539904471875   1: 0.010538807905640   9: 0.010537664366099   4: 0.010537062498203   5: 0.010535976878764   3: 0.010535516165881   2: 0.010534824544007 

training_12161    2: 0.534651372164760   6: 0.267504995838388   8: 0.067261711592487   5: 0.018667485546763   3: 0.018662782312077   1: 0.018654750093268   0: 0.018650587089125   7: 0.018650198697975   9: 0.018648381539488   4: 0.018647735125670 

training_12162    2: 0.498614532269108   6: 0.233664499524665   1: 0.111054403875426   8: 0.022483737344810   5: 0.022365201877491   0: 0.022364984228869   9: 0.022363767780956   3: 0.022363727106798   7: 0.022362940677920   4: 0.022362205313956 

training_12163    4: 0.742568645990287   5: 0.028607680643800   8: 0.028603130103045   3: 0.028603035180572   9: 0.028602960482943   6: 0.028602959233758   0: 0.028602939112947   2: 0.028602923742169   1: 0.028602862859430   7: 0.028602862651051 

training_12164    6: 0.443986162919676   2: 0.380536714860776   1: 0.022077781428747   7: 0.021917924629129   0: 0.021915583030311   5: 0.021915058079471   9: 0.021912890597788   8: 0.021912668860753   3: 0.021912618789748   4: 0.021912596803601 

training_12166    4: 0.416308216883155   5: 0.402199630584503   7: 0.049929785916666   6: 0.018804851699840   0: 0.018793150538489   8: 0.018792962958055   9: 0.018792924695765   1: 0.018792864296612   2: 0.018792812512331   3: 0.018792799914584 

training_12169    4: 0.671009393615405   8: 0.134293300717510   5: 0.024344847273453   0: 0.024338067835689   6: 0.024336835480541   7: 0.024336062980159   1: 0.024335471694652   2: 0.024335439944464   9: 0.024335337285971   3: 0.024335243172158 

training_1217     1: 0.605610174752701   4: 0.234513857570750   5: 0.019990924391054   0: 0.019987782935320   6: 0.019986416758963   9: 0.019983420176653   3: 0.019983142079581   8: 0.019981619465679   2: 0.019981352874835   7: 0.019981308994466 

training_12171    9: 0.475176669839186   5: 0.354084797987055   6: 0.021385506259347   0: 0.021348344051966   1: 0.021337695238836   4: 0.021337559437341   2: 0.021333099212753   3: 0.021332498073298   7: 0.021332168730762   8: 0.021331661169455 

training_12172    7: 0.408354619946900   5: 0.353786216147332   3: 0.085189763579451   1: 0.021817862179191   0: 0.021811896024178   6: 0.021811335712094   4: 0.021808198379698   2: 0.021807614291140   9: 0.021806250695897   8: 0.021806243044118 

training_12173    1: 0.398187139887086   6: 0.309933534835090   3: 0.117913275993080   0: 0.066680070127987   5: 0.017889259968226   4: 0.017882467183093   8: 0.017879676592928   2: 0.017878519598411   9: 0.017878366777575   7: 0.017877689036523 

training_12174    2: 0.388516933883232   6: 0.296624976301715   7: 0.164249603765443   0: 0.054152336776423   1: 0.016123554604481   8: 0.016083366306902   9: 0.016072410491205   5: 0.016067518548229   4: 0.016054660491063   3: 0.016054638831307 

training_12176    5: 0.781531205100960   4: 0.024279548137825   2: 0.024274778026230   8: 0.024273757555009   1: 0.024273682174714   6: 0.024273653316232   0: 0.024273603068844   9: 0.024273423162014   3: 0.024273219754333   7: 0.024273129703839 

training_12177    8: 0.752830481694813   5: 0.027482684296859   9: 0.027462372147415   6: 0.027461433222066   4: 0.027461349072703   0: 0.027461029797460   1: 0.027460792134582   7: 0.027460340967578   2: 0.027459899009621   3: 0.027459617656904 

training_12178    6: 0.723641822153104   3: 0.119901048627000   0: 0.037352228675183   8: 0.029344506120114   5: 0.027211205555726   9: 0.012553547487286   1: 0.012526509344749   2: 0.012493087606406   4: 0.012488168162657   7: 0.012487876267775 

training_12179    7: 0.415851216403124   6: 0.296120234878966   5: 0.154755583986117   8: 0.019042542678539   0: 0.019040539858586   4: 0.019039521004372   1: 0.019039214040173   9: 0.019037436620012   3: 0.019037164098913   2: 0.019036546431197 

training_12182    4: 0.778223327814097   1: 0.024652331281171   0: 0.024647403709382   5: 0.024646357249537   6: 0.024643760193163   2: 0.024637988491535   9: 0.024637305653157   3: 0.024637212210545   8: 0.024637169300058   7: 0.024637144097355 

training_12183    8: 0.399737847716100   6: 0.395552923789528   0: 0.067171195604150   5: 0.019659920857679   1: 0.019656166340741   9: 0.019652782234940   3: 0.019645573538701   7: 0.019643839426160   4: 0.019640749363753   2: 0.019639001128248 

training_12184    5: 0.780348285839558   6: 0.024413765573322   1: 0.024409170196039   0: 0.024408687609047   7: 0.024404242986002   3: 0.024403832547644   8: 0.024403603092965   4: 0.024403086913565   9: 0.024402682288193   2: 0.024402642953664 

training_12185    3: 0.413836824166307   5: 0.262269398883268   4: 0.149652226702135   7: 0.024893304998121   6: 0.024892901362982   0: 0.024891700242566   8: 0.024890979931154   1: 0.024890976630833   9: 0.024890917740384   2: 0.024890769342252 

training_12186    1: 0.751989327064174   6: 0.081465937644496   5: 0.046397957892174   0: 0.017171805632064   9: 0.017170721601078   4: 0.017164904026071   2: 0.017164291816011   3: 0.017158552432040   8: 0.017158548381735   7: 0.017157953510156 

training_12187    5: 0.438281609868661   7: 0.268134197676236   3: 0.119159010079238   4: 0.024920418072122   8: 0.024920286860501   6: 0.024919885854077   2: 0.024917193660293   0: 0.024916609911719   1: 0.024915624074168   9: 0.024915163942985 

training_12191    6: 0.329824517230408   2: 0.322825814575383   5: 0.158855137543843   8: 0.049237261075866   4: 0.049017478744781   1: 0.018145049716254   9: 0.018031959483351   3: 0.018029749315897   0: 0.018021611106937   7: 0.018011421207282 

training_12192    6: 0.425504442850559   5: 0.275406223874643   8: 0.109137132428106   2: 0.075161452166759   0: 0.037618466033965   1: 0.015496599740021   7: 0.015428113053540   9: 0.015416054707198   3: 0.015415890554656   4: 0.015415624590553 

training_12195    0: 0.594125175991066   6: 0.278881898863043   1: 0.047276713217528   9: 0.013431438306371   5: 0.011118035275515   7: 0.011050815793480   2: 0.011033024694771   8: 0.011028028490797   4: 0.011027570024641   3: 0.011027299342790 

training_12197    6: 0.684239004500891   9: 0.094686206269560   1: 0.093393240953716   0: 0.034315685027321   5: 0.025075252214854   2: 0.013852968786954   4: 0.013648793258481   8: 0.013599201435797   7: 0.013596130823395   3: 0.013593516729031 

training_1220     0: 0.762246509218642   1: 0.100692716198249   5: 0.017159846921086   6: 0.017130927044285   7: 0.017130821510524   4: 0.017129800095766   9: 0.017127882472326   2: 0.017127377588412   3: 0.017127123692999   8: 0.017126995257711 

training_12201    9: 0.409828071121347   6: 0.291593429743205   5: 0.170923143298398   0: 0.018408817289927   1: 0.018295250102887   7: 0.018195734513360   3: 0.018190249947061   4: 0.018189995304234   8: 0.018188023766623   2: 0.018187284912958 

training_12202    7: 0.449924116145735   6: 0.390623693357649   5: 0.019941344288859   4: 0.019939951567371   0: 0.019931931133163   1: 0.019929958233613   9: 0.019929125489648   3: 0.019927530391054   8: 0.019926902312058   2: 0.019925447080850 

training_12203    6: 0.447073425977839   5: 0.289718986747800   8: 0.092139116780258   4: 0.043914711400389   7: 0.041772238215931   0: 0.030815679985221   9: 0.013691881572119   1: 0.013638978516358   3: 0.013617681252145   2: 0.013617299551942 

training_12204    5: 0.401979702826652   6: 0.229412367829135   0: 0.192637960390702   4: 0.025144717852506   8: 0.025138271149074   9: 0.025137580843495   3: 0.025137466045145   7: 0.025137372620240   2: 0.025137368956681   1: 0.025137191486370 

training_12205    1: 0.773082061320639   6: 0.058638503606076   9: 0.021095155204249   5: 0.021032610952941   4: 0.021027674963091   0: 0.021026310176119   8: 0.021024790007990   3: 0.021024493288110   2: 0.021024426788721   7: 0.021023973692065 

training_12207    5: 0.377063434625479   6: 0.324436026056091   0: 0.141796626847600   4: 0.022391366932401   9: 0.022386306838109   8: 0.022386007188961   7: 0.022385103907819   1: 0.022385070613966   3: 0.022385066419124   2: 0.022384990570451 

training_12208    6: 0.665998369827695   0: 0.166001163296168   1: 0.062040946622691   7: 0.052062894815177   8: 0.009233894275210   9: 0.008939328848827   2: 0.008932028887254   5: 0.008931416772680   4: 0.008930127674450   3: 0.008929828979849 

training_12209    6: 0.560110756637123   9: 0.197654910650782   2: 0.095085391284189   0: 0.079763410650856   5: 0.016893782420559   8: 0.016200050200960   3: 0.008618509185048   1: 0.008562686937752   7: 0.008557565840728   4: 0.008552936192004 

training_12211    1: 0.401555827136306   5: 0.398638162236840   4: 0.024979058382289   6: 0.024977591231080   8: 0.024975314862558   0: 0.024975159253187   9: 0.024975092508604   7: 0.024974748242141   2: 0.024974724946785   3: 0.024974321200210 

training_12213    0: 0.614095496171517   3: 0.154837697688242   7: 0.075990635730699   6: 0.056697352021362   1: 0.016414200507345   5: 0.016393743722649   9: 0.016393642184241   8: 0.016392658981774   4: 0.016392329449658   2: 0.016392243542514 

training_12215    7: 0.484128658778388   0: 0.322374182566015   5: 0.024198637136150   4: 0.024189417914258   6: 0.024189212084064   2: 0.024187997384072   1: 0.024187160286489   3: 0.024182245816750   8: 0.024181486231614   9: 0.024181001802200 

training_12216    0: 0.813291520975015   1: 0.040342162448208   3: 0.018309417484184   9: 0.018302478858881   6: 0.018300505588812   5: 0.018294150387095   8: 0.018292337945361   4: 0.018289637789624   2: 0.018289224949019   7: 0.018288563573800 

training_12219    2: 0.694175658748943   5: 0.058435931559419   0: 0.057727045344431   6: 0.027193481844559   4: 0.027104814450939   7: 0.027088894408919   3: 0.027072492069173   9: 0.027071771856145   1: 0.027067587480716   8: 0.027062322236755 

training_12221    5: 0.521143479404126   0: 0.246687813863397   9: 0.087455523688325   3: 0.046196761313248   6: 0.016421865942335   1: 0.016420332974991   8: 0.016419488556602   4: 0.016418363184212   2: 0.016418200228636   7: 0.016418170844129 

training_12222    2: 0.580916656707687   5: 0.189458445619019   8: 0.076670668092186   6: 0.021860222224471   0: 0.021852020583814   1: 0.021851938813718   4: 0.021849029222328   3: 0.021848676342031   7: 0.021846276111818   9: 0.021846066282928 

training_12223    5: 0.782222351305435   7: 0.024216911075677   0: 0.024205577211241   6: 0.024199846100330   1: 0.024198275243250   2: 0.024194805373953   3: 0.024192062887681   9: 0.024190354397548   8: 0.024190044359852   4: 0.024189772045033 

training_12224    6: 0.466959654583020   8: 0.194129342110231   5: 0.161165674818789   7: 0.049990686849077   1: 0.032470517242443   9: 0.029819443834411   3: 0.016375536818838   4: 0.016364576592419   0: 0.016363152306031   2: 0.016361414844741 

training_12225    6: 0.422191680012482   5: 0.409311198145734   2: 0.057672623257028   0: 0.015835979456100   1: 0.015833246633881   4: 0.015831513434502   7: 0.015831147894446   3: 0.015831012435348   9: 0.015830816076690   8: 0.015830782653787 

training_12226    2: 0.646603688426639   0: 0.169715081162916   6: 0.022975669076504   1: 0.022963785129734   5: 0.022963544148339   9: 0.022958664044702   3: 0.022956111471796   8: 0.022955288461724   4: 0.022954890723913   7: 0.022953277353734 

training_12227    5: 0.486173332455344   3: 0.305656998442029   4: 0.026021757988214   6: 0.026021239687158   0: 0.026021227410307   8: 0.026021212881585   2: 0.026021085354420   1: 0.026021077793997   7: 0.026021064732962   9: 0.026021003253984 

training_12229    6: 0.493920605331994   2: 0.321953748992734   5: 0.023018618785433   0: 0.023018409718758   1: 0.023016919491073   8: 0.023016152755603   9: 0.023014482191950   7: 0.023014209196524   4: 0.023013882288123   3: 0.023012971247808 

training_12231    5: 0.427910985905901   0: 0.235849253446903   4: 0.124915579326914   8: 0.084738990333056   1: 0.021097748363718   9: 0.021097746169566   6: 0.021097511348433   2: 0.021097412965429   7: 0.021097387812109   3: 0.021097384327970 

training_12235    0: 0.778834178292487   6: 0.024580221441188   2: 0.024579029537054   5: 0.024574767828983   9: 0.024573259442662   8: 0.024573009653867   1: 0.024572570216716   7: 0.024571118715866   3: 0.024571062480841   4: 0.024570782390337 

training_12236    6: 0.472510226590795   5: 0.380742903095408   2: 0.036690309132755   0: 0.015730377573634   1: 0.015723026073207   4: 0.015721117692761   7: 0.015720676557151   3: 0.015720559582621   9: 0.015720498450690   8: 0.015720305250979 

training_12237    5: 0.802794755417991   2: 0.052235342220973   1: 0.018128727579300   8: 0.018125618880136   6: 0.018123838571119   0: 0.018122871522927   7: 0.018117432347844   9: 0.018117248261532   3: 0.018117162748909   4: 0.018117002449270 

training_12239    5: 0.769066526983138   4: 0.025666125106716   6: 0.025658619936009   8: 0.025658610884472   0: 0.025658516483260   9: 0.025658342252527   3: 0.025658341318238   7: 0.025658319916067   2: 0.025658312314834   1: 0.025658284804737 

training_12240    4: 0.555280454775247   5: 0.234519076001240   7: 0.084270446505654   1: 0.018003529857938   9: 0.017995401008060   6: 0.017988704908949   0: 0.017986616432676   2: 0.017985541941677   3: 0.017985294445324   8: 0.017984934123235 

training_12243    6: 0.503566800184084   1: 0.298007257568791   0: 0.054428708970450   8: 0.020578137770119   7: 0.020573510909067   5: 0.020571570871631   2: 0.020569356236201   4: 0.020568469664888   9: 0.020568344594333   3: 0.020567843230436 

training_12244    5: 0.525385494553479   7: 0.140498402356205   0: 0.114475230536663   4: 0.067655420439181   3: 0.066663844229314   6: 0.017096517675110   1: 0.017062350630734   8: 0.017055045055544   9: 0.017053950814333   2: 0.017053743709437 

training_12246    6: 0.356780858847697   7: 0.241318645176734   3: 0.197033782561976   4: 0.073934306675762   2: 0.021826117478293   0: 0.021823637576609   5: 0.021822546159335   8: 0.021820358057960   1: 0.021820124185395   9: 0.021819623280238 

training_12249    6: 0.466883384444785   8: 0.386289801417215   0: 0.037822339223795   1: 0.015606198184062   5: 0.015577766376311   9: 0.015566718916781   2: 0.015564502343887   7: 0.015563196287586   3: 0.015563141181896   4: 0.015562951623683 

training_1225     5: 0.773908333818057   4: 0.025124055553818   6: 0.025123541308669   7: 0.025123055662903   1: 0.025122238738387   9: 0.025120154839406   0: 0.025120075985882   3: 0.025119697452244   8: 0.025119509088259   2: 0.025119337552375 

training_12250    1: 0.626490906663416   0: 0.119697982374348   5: 0.119666868966652   9: 0.045785594149116   6: 0.014731782918206   8: 0.014729368679710   4: 0.014724879643023   7: 0.014724388398987   2: 0.014724345464019   3: 0.014723882742523 

training_12251    6: 0.497839334259588   5: 0.258773596629273   9: 0.030425607853389   1: 0.030425305720739   0: 0.030425261451703   8: 0.030423580836193   7: 0.030422286127738   2: 0.030421991096054   3: 0.030421724566363   4: 0.030421311458960 

training_12254    6: 0.358762391359602   5: 0.198784466298353   8: 0.180346175524289   1: 0.103053904068640   7: 0.056296409272596   0: 0.041805674307983   9: 0.015273525909933   3: 0.015237389237868   2: 0.015220168382585   4: 0.015219895638152 

training_12255    5: 0.722569727463676   9: 0.079243417004299   4: 0.024782020998491   8: 0.024772313722955   0: 0.024772146272682   3: 0.024772102295175   2: 0.024772094421531   6: 0.024772081047714   7: 0.024772076571899   1: 0.024772020201578 

training_12257    6: 0.582949751092199   0: 0.193686097871693   9: 0.068712536735418   5: 0.022299401331161   1: 0.022079451531762   2: 0.022073242718516   7: 0.022062102215571   3: 0.022052310786784   4: 0.022042621792770   8: 0.022042483924127 

training_12258    5: 0.762961649619765   1: 0.073060046974271   4: 0.020503299945226   6: 0.020497631135252   3: 0.020496738974342   0: 0.020496401583621   8: 0.020496176157323   9: 0.020496118644772   7: 0.020496009231271   2: 0.020495927734159 

training_12259    6: 0.698846079904392   5: 0.149642883714782   9: 0.018942717678240   0: 0.018940411097420   1: 0.018938977894982   8: 0.018938869804205   2: 0.018938367597080   7: 0.018937412014586   3: 0.018937146826028   4: 0.018937133468284 

training_1226     6: 0.810707617460629   1: 0.062465302261740   8: 0.033040724077259   5: 0.013402331565952   0: 0.013400354361508   3: 0.013397507631991   4: 0.013396815838914   2: 0.013396709615081   9: 0.013396596091431   7: 0.013396041095494 

training_12260    6: 0.599171627410638   0: 0.187199872678255   5: 0.026721141597024   2: 0.026710483506891   1: 0.026705466311475   3: 0.026702828048042   4: 0.026702165491003   7: 0.026696313184484   8: 0.026695748579804   9: 0.026694353192383 

training_12261    6: 0.660796052001910   0: 0.167422047828122   3: 0.077787876805689   1: 0.013430279554221   5: 0.013427807487429   7: 0.013427512037601   8: 0.013427190499480   9: 0.013427133848630   4: 0.013427088947767   2: 0.013427010989151 

training_12266    5: 0.821430762714448   1: 0.019850614990748   0: 0.019843842014698   6: 0.019842538036974   4: 0.019841519900473   3: 0.019839586265645   2: 0.019838684044251   8: 0.019837499779775   9: 0.019837478434560   7: 0.019837473818429 

training_12267    2: 0.407919594163027   6: 0.371724849341177   5: 0.027547351449156   9: 0.027545986341398   4: 0.027545330553761   0: 0.027544332279347   1: 0.027544129842612   8: 0.027543994714462   7: 0.027542749642631   3: 0.027541681672429 

training_12269    6: 0.627533398967149   0: 0.127112830387363   2: 0.094533586470388   9: 0.021551187009271   5: 0.021548231069871   1: 0.021545630004913   8: 0.021544227873032   4: 0.021543766095716   7: 0.021543759788989   3: 0.021543382333307 

training_12270    6: 0.495736777693145   7: 0.346348767320367   0: 0.041226449402813   1: 0.033149347691448   9: 0.014056060840642   2: 0.013896882808490   8: 0.013896669870095   3: 0.013896564613721   5: 0.013896487981276   4: 0.013895991778003 

training_12271    5: 0.768987461204356   4: 0.025671514275174   0: 0.025670622906709   1: 0.025669126836269   2: 0.025668286398000   6: 0.025668177238643   3: 0.025666394610408   8: 0.025666264466007   9: 0.025666142115957   7: 0.025666009948476 

training_12274    2: 0.560371725329858   6: 0.224942886874693   5: 0.026844881405054   0: 0.026837859712613   8: 0.026837232555535   4: 0.026834784239776   3: 0.026834604687639   9: 0.026833559206786   1: 0.026831544544706   7: 0.026830921443341 

training_12275    6: 0.515254363717833   5: 0.296300780553688   7: 0.051611528702218   8: 0.019574719209110   0: 0.019549754744826   1: 0.019542723996044   3: 0.019542662559003   4: 0.019541428244470   9: 0.019541080194887   2: 0.019540958077921 

training_12276    3: 0.391341156494781   1: 0.267380072415816   6: 0.170012387857267   0: 0.045688530471270   5: 0.020935370190103   8: 0.020932100804992   4: 0.020929738876545   7: 0.020927356538596   9: 0.020926756480790   2: 0.020926529869840 

training_12278    6: 0.562014701609902   5: 0.271368230020466   0: 0.020829403864393   1: 0.020827364184049   9: 0.020827127783148   8: 0.020827092671000   4: 0.020826659528994   3: 0.020826491386593   7: 0.020826477213160   2: 0.020826451738296 

training_1228     3: 0.464663486988633   1: 0.303846688685032   0: 0.089772512863686   5: 0.020253067052890   9: 0.020246772803959   6: 0.020246505485364   4: 0.020244677923765   8: 0.020242913502619   7: 0.020241805406099   2: 0.020241569287954 

training_12281    6: 0.357449640575018   1: 0.300629265670596   4: 0.154298184934224   9: 0.104216265778562   0: 0.013924940171964   5: 0.013906994962493   7: 0.013900812562048   2: 0.013891475713230   3: 0.013891384514625   8: 0.013891035117240 

training_12283    6: 0.622108077880434   5: 0.151260366168983   4: 0.028345462676266   8: 0.028328284200041   0: 0.028326848542845   2: 0.028326660494160   9: 0.028326365958674   1: 0.028326279343692   3: 0.028325971669931   7: 0.028325683064975 

training_12285    6: 0.367099962770120   0: 0.363257566429871   4: 0.033736533555112   5: 0.033723201786234   3: 0.033700685183673   7: 0.033699938712229   8: 0.033697724706939   9: 0.033695429198005   1: 0.033695348108751   2: 0.033693609549066 

training_12286    2: 0.532196490575291   8: 0.239960877133094   5: 0.071131706941927   4: 0.036961220863742   7: 0.020175728292968   0: 0.020032715444708   1: 0.019911746528028   6: 0.019893592943072   9: 0.019870034343858   3: 0.019865886933311 

training_12288    5: 0.736724686817836   3: 0.078167989372019   7: 0.023156056862555   6: 0.023137253713256   0: 0.023136274636374   9: 0.023136139470201   1: 0.023136118109443   8: 0.023135639852296   4: 0.023134999577416   2: 0.023134841588605 

training_1229     5: 0.791023107750733   4: 0.023223235445230   6: 0.023220219880392   1: 0.023219629006456   0: 0.023219282811075   8: 0.023219082426430   3: 0.023218996128928   2: 0.023218867887127   9: 0.023218809300019   7: 0.023218769363609 

training_12293    5: 0.432351921003517   0: 0.319038755856781   6: 0.031083257173274   1: 0.031079691629277   3: 0.031075406303883   4: 0.031074699980988   9: 0.031074337903291   2: 0.031074015321310   8: 0.031073982924429   7: 0.031073931903250 

training_12294    4: 0.795459127640892   5: 0.022735361583205   6: 0.022732092587719   7: 0.022727259109094   1: 0.022725655196675   0: 0.022724938713326   8: 0.022724392442682   9: 0.022724247841694   3: 0.022723539854019   2: 0.022723385030694 

training_12296    5: 0.699696187234793   0: 0.123260323734042   6: 0.022142564392291   4: 0.022133419823573   7: 0.022128695019369   8: 0.022128127206436   3: 0.022127726330631   9: 0.022127718110550   2: 0.022127663304701   1: 0.022127574843615 

training_12298    1: 0.346520784240563   6: 0.242917689906741   9: 0.176124504024186   4: 0.085668123777237   0: 0.061790884282463   3: 0.017401070581002   5: 0.017397107765940   8: 0.017394782048464   2: 0.017392683936068   7: 0.017392369437336 

training_123      6: 0.517475616193874   4: 0.259289021533482   1: 0.103538024027437   5: 0.017103798151234   0: 0.017103778273178   9: 0.017098654253384   7: 0.017098046583282   8: 0.017097957925028   2: 0.017097682216904   3: 0.017097420842197 

training_12301    5: 0.536630676167217   0: 0.153762112418595   2: 0.119820365845136   8: 0.066871742596673   3: 0.020506656064586   6: 0.020489311646893   9: 0.020480988840387   4: 0.020480898602008   1: 0.020479324372581   7: 0.020477923445925 

training_12302    6: 0.499587417744249   8: 0.312695653859322   0: 0.023471373063149   2: 0.023470755507294   5: 0.023466945925131   7: 0.023463516071354   1: 0.023463222867024   9: 0.023461049736104   4: 0.023460448799645   3: 0.023459616426729 

training_12303    5: 0.510332837884258   6: 0.265489923715662   1: 0.028026105524283   0: 0.028023386579149   4: 0.028022844258066   3: 0.028021701347978   8: 0.028021236699337   9: 0.028020756427037   2: 0.028020603974664   7: 0.028020603589565 

training_12304    5: 0.774233291851319   6: 0.025086705854823   2: 0.025086218692938   0: 0.025085324028287   8: 0.025085024145674   4: 0.025084959812808   3: 0.025084959007369   1: 0.025084850089207   9: 0.025084399075721   7: 0.025084267441855 

training_12305    0: 0.827864466709949   7: 0.029426166048469   8: 0.028449580348396   9: 0.024966225451062   4: 0.014962092398984   6: 0.014873284085709   1: 0.014872428023305   5: 0.014868810732575   3: 0.014858558046209   2: 0.014858388155341 

training_12306    4: 0.557743884295053   5: 0.243109112911508   0: 0.056260352643484   6: 0.020433369309272   9: 0.020421775474329   7: 0.020410627504386   1: 0.020406379378270   8: 0.020405395575999   3: 0.020404717978525   2: 0.020404384929175 

training_12309    6: 0.420541512543035   0: 0.396089887710493   5: 0.046315925984506   8: 0.038898139437597   1: 0.016360603258497   2: 0.016359359780368   4: 0.016359126116234   9: 0.016358789876980   3: 0.016358503112490   7: 0.016358152179800 

training_12311    6: 0.752672904988639   0: 0.095330046492450   8: 0.043138684009562   7: 0.015561800523916   5: 0.015551981123806   1: 0.015551435668153   9: 0.015548616824137   4: 0.015548423187329   2: 0.015548062119856   3: 0.015548045062151 

training_12312    1: 0.609856744249081   6: 0.181541644215350   2: 0.026078320004775   9: 0.026078240446435   4: 0.026077735012091   5: 0.026076128139554   0: 0.026074265474864   7: 0.026073239810162   8: 0.026072614956361   3: 0.026071067691327 

training_12313    1: 0.577293587295452   6: 0.256455439385865   2: 0.020798397436216   9: 0.020782887945714   5: 0.020780014347862   7: 0.020779243353732   0: 0.020778698411951   4: 0.020778196868415   8: 0.020776917172393   3: 0.020776617782400 

training_12315    6: 0.773641113306092   5: 0.025556234597904   4: 0.025286382495607   2: 0.025098338980072   3: 0.025089364945623   7: 0.025070580822877   8: 0.025070387872045   9: 0.025063557842159   0: 0.025062999244602   1: 0.025061039893019 

training_12316    6: 0.539681095013461   1: 0.224193757664244   2: 0.069599415240922   0: 0.023824192963864   7: 0.023797601248308   5: 0.023785376532901   8: 0.023785134113594   9: 0.023780347486869   4: 0.023776839305510   3: 0.023776240430328 

training_12317    1: 0.668475098805061   0: 0.181724206541790   2: 0.050741806798822   5: 0.014155866743149   6: 0.014154953159803   4: 0.014150219491033   7: 0.014149968089146   8: 0.014149693240035   9: 0.014149125389986   3: 0.014149061741175 

training_12318    6: 0.464945400285762   5: 0.333640598750061   4: 0.052473791445045   0: 0.050576428790244   7: 0.029228534960657   8: 0.013937715282524   1: 0.013801617416244   3: 0.013799174721376   9: 0.013798514226489   2: 0.013798224121599 

training_12321    3: 0.428585076108965   0: 0.399358202149472   5: 0.021511836213981   1: 0.021511696158925   6: 0.021510257074800   4: 0.021507202803893   9: 0.021505340705067   8: 0.021503731819715   2: 0.021503690561794   7: 0.021502966403389 

training_12323    6: 0.788932306954354   8: 0.066515023434123   7: 0.036777327417167   9: 0.015506635577323   5: 0.015417083586336   1: 0.015382093328358   4: 0.015375220328938   0: 0.015365462637363   2: 0.015364474222839   3: 0.015364372513198 

training_12325    6: 0.759584113315616   0: 0.080550117244615   1: 0.019987530834638   5: 0.019983934703004   8: 0.019982850795033   7: 0.019982817243221   9: 0.019982554649725   3: 0.019982059604551   2: 0.019982040235989   4: 0.019981981373608 

training_12327    0: 0.723939666821810   6: 0.030690274092634   8: 0.030675959911527   7: 0.030672432414885   1: 0.030670915891893   2: 0.030670397733938   9: 0.030670375004095   3: 0.030670272945065   5: 0.030670038452719   4: 0.030669666731433 

training_12331    1: 0.582228709975251   6: 0.210592652394641   4: 0.087459597717311   5: 0.017110548210338   2: 0.017106675254175   8: 0.017102249485652   3: 0.017100930433980   0: 0.017099944854832   9: 0.017099462502281   7: 0.017099229171538 

training_12332    6: 0.703503144872734   0: 0.142069205697424   5: 0.019305800709211   1: 0.019305395017303   3: 0.019303156161161   8: 0.019303004228231   7: 0.019302809855806   9: 0.019302780846416   2: 0.019302581076340   4: 0.019302121535374 

training_12333    6: 0.493950248173355   0: 0.307172953932561   8: 0.059114845675571   5: 0.027548744769800   7: 0.025882517850046   2: 0.024908080887762   3: 0.023982444289135   1: 0.012488892104212   4: 0.012477195607082   9: 0.012474076710475 

training_12334    5: 0.615595521014554   9: 0.179135573700980   4: 0.025662384586226   6: 0.025658627870969   8: 0.025658232645007   3: 0.025658121614202   0: 0.025657946512014   2: 0.025657914983764   7: 0.025657901483741   1: 0.025657775588543 

training_12336    6: 0.734411451472800   2: 0.090119947543687   0: 0.021948022328505   7: 0.021935563737610   9: 0.021933046161090   5: 0.021932264528980   1: 0.021931814988845   8: 0.021930939954189   3: 0.021929193776362   4: 0.021927755507932 

training_12337    0: 0.467331619148973   6: 0.340023837367306   7: 0.064907645292894   9: 0.032827278083577   4: 0.024253329851071   1: 0.023991364585634   8: 0.014271127764126   5: 0.013862949299879   2: 0.009267651350778   3: 0.009263197255763 

training_12338    6: 0.589560303228493   8: 0.222293841572627   7: 0.042001611944516   3: 0.040430790652012   1: 0.017655668609601   5: 0.017628509318612   4: 0.017619890723374   0: 0.017604348805735   9: 0.017602680116427   2: 0.017602355028604 

training_12339    7: 0.350039118123659   6: 0.303609201253349   5: 0.204274181078551   1: 0.020306908821485   0: 0.020296993469592   9: 0.020296563573321   8: 0.020295015813626   3: 0.020294166619472   4: 0.020293963554596   2: 0.020293887692349 

training_1234     5: 0.463658225753193   4: 0.333941546422401   3: 0.025301149532099   8: 0.025300003044685   6: 0.025300001828846   0: 0.025299994475292   1: 0.025299797421490   2: 0.025299797272723   7: 0.025299774592124   9: 0.025299709657146 

training_12340    6: 0.813080419513344   0: 0.087413250024708   1: 0.028659615254815   8: 0.010125809782320   7: 0.010121572219465   5: 0.010120793108459   4: 0.010119849319910   9: 0.010119652240724   2: 0.010119557883907   3: 0.010119480652348 

training_12341    4: 0.772549676233279   6: 0.067557210273994   5: 0.019990190511071   1: 0.019986271887021   8: 0.019986244849712   0: 0.019986168883444   9: 0.019986121775013   2: 0.019986072213793   3: 0.019986061159290   7: 0.019985982213383 

training_12344    1: 0.551847341297243   6: 0.228734649010379   3: 0.097230309160591   5: 0.017457960034578   4: 0.017456573896480   2: 0.017456345759127   9: 0.017455377732337   0: 0.017455157524228   7: 0.017453461375735   8: 0.017452824209301 

training_12345    9: 0.504862110133487   1: 0.316565876544644   7: 0.057641023052749   0: 0.017282729143375   5: 0.017277948610127   6: 0.017277339852192   2: 0.017276332208797   4: 0.017275375556304   8: 0.017270754815800   3: 0.017270510082525 

training_12346    5: 0.684101635474216   1: 0.132391949305601   8: 0.022947522575917   6: 0.022939015764279   4: 0.022938240530135   0: 0.022937230514738   9: 0.022936362898352   7: 0.022936068647957   2: 0.022936010329476   3: 0.022935963959330 

training_12348    6: 0.604488996812074   5: 0.231795106601989   0: 0.020478421602500   1: 0.020463467648383   7: 0.020463421307764   8: 0.020463337763727   9: 0.020462684894806   4: 0.020461665721312   2: 0.020461650119526   3: 0.020461247527918 

training_12350    0: 0.802517683249088   5: 0.044878212698762   7: 0.019100289982170   9: 0.019082469979867   6: 0.019073681154314   8: 0.019071989543713   1: 0.019071960545857   4: 0.019068423274022   2: 0.019068354096000   3: 0.019066935476208 

training_12351    5: 0.797589243415862   4: 0.022495804017989   6: 0.022489691055526   0: 0.022489460298122   8: 0.022489418274824   1: 0.022489415853863   9: 0.022489250912074   2: 0.022489250152750   7: 0.022489249734385   3: 0.022489216284605 

training_12352    4: 0.550248700122575   5: 0.221152441489775   8: 0.028575094738818   9: 0.028575073496548   3: 0.028574912138784   6: 0.028574843273224   2: 0.028574781574310   0: 0.028574757285969   7: 0.028574715065218   1: 0.028574680814779 

training_12353    5: 0.680254605303363   3: 0.140634956915234   4: 0.022392659298046   1: 0.022389874315340   6: 0.022388800689472   0: 0.022388614036529   9: 0.022387931646493   8: 0.022387904739419   2: 0.022387390610204   7: 0.022387262445899 

training_12355    6: 0.869646935616271   0: 0.052358385950727   1: 0.018597283411204   8: 0.008494939008210   4: 0.008485114575874   7: 0.008485055546428   5: 0.008484763546202   2: 0.008482561723825   9: 0.008482537860243   3: 0.008482422761016 

training_12356    5: 0.569015349202208   1: 0.274688486438563   6: 0.019592652096922   3: 0.019544983374643   2: 0.019543187620857   0: 0.019525826583876   4: 0.019522646348135   8: 0.019522575827575   9: 0.019522249905971   7: 0.019522042601250 

training_12361    5: 0.460198379765881   6: 0.366790917035818   3: 0.021720891236185   7: 0.021623175670192   8: 0.021616871823225   0: 0.021610481959526   1: 0.021610041869142   9: 0.021609873957516   2: 0.021609755629666   4: 0.021609611052849 

training_12362    5: 0.688075480619576   0: 0.125422097057921   4: 0.023317629060431   6: 0.023312356134956   1: 0.023312266526681   9: 0.023312149051878   8: 0.023312078076436   3: 0.023312047222947   7: 0.023311949021335   2: 0.023311947227839 

training_12364    4: 0.806272830856665   5: 0.021532452653919   6: 0.021525052058881   0: 0.021524843452359   1: 0.021524632809768   8: 0.021524561365464   7: 0.021524096410148   3: 0.021523917225116   9: 0.021523838072946   2: 0.021523775094734 

training_12366    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_12368    6: 0.388077931056009   3: 0.277676173123150   1: 0.146256305507098   9: 0.076981901402452   5: 0.018507303862860   4: 0.018504020141299   0: 0.018503565562109   2: 0.018497748108694   7: 0.018497591305696   8: 0.018497459930635 

training_12371    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_12372    6: 0.799663769386698   1: 0.078521487646546   8: 0.041331505750447   0: 0.021831317712309   5: 0.009904341673357   3: 0.009820607874903   9: 0.009736136583464   4: 0.009732802876173   7: 0.009730127395298   2: 0.009727903100804 

training_12374    2: 0.555380584427451   1: 0.234507524641594   0: 0.026269684132323   6: 0.026268559821799   5: 0.026268536699380   9: 0.026262740346439   4: 0.026261501495007   7: 0.026261139131166   8: 0.026259956440435   3: 0.026259772864406 

training_12375    6: 0.784266002524350   0: 0.065221441700769   8: 0.018820979087165   5: 0.018815030595231   1: 0.018813959027975   4: 0.018812889642611   7: 0.018812847138273   9: 0.018812540298843   3: 0.018812242323950   2: 0.018812067660835 

training_12376    9: 0.434702544227341   6: 0.225488887635946   5: 0.108505409621187   0: 0.080688715289581   8: 0.053927281382840   4: 0.031947078605788   7: 0.016197074089766   1: 0.016182214442628   2: 0.016180642107970   3: 0.016180152596952 

training_12378    1: 0.269207317947831   6: 0.259334986339923   0: 0.258135152826162   5: 0.105437063433329   4: 0.017982382250585   7: 0.017981688424893   9: 0.017980820740203   3: 0.017980771713784   2: 0.017979999544415   8: 0.017979816778875 

training_12379    5: 0.780837089053681   4: 0.024356670933913   6: 0.024351007574281   8: 0.024350983471296   3: 0.024350761751477   0: 0.024350754658196   9: 0.024350748219759   7: 0.024350692431414   2: 0.024350676392956   1: 0.024350615513028 

training_1238     8: 0.337413707644293   0: 0.281950881059533   6: 0.232383618757734   1: 0.021211875278865   5: 0.021190920851192   2: 0.021185251168735   4: 0.021169821051432   7: 0.021165771861460   9: 0.021164142551521   3: 0.021164009775236 

training_12380    4: 0.791431787738659   5: 0.023179948662950   8: 0.023173835752628   1: 0.023173688182670   0: 0.023173659226995   6: 0.023173514120623   3: 0.023173500971307   2: 0.023173388155004   9: 0.023173388048672   7: 0.023173289140492 

training_12382    4: 0.545717637741645   9: 0.139392326879068   2: 0.132669676914622   5: 0.026039250561053   6: 0.026030574999559   1: 0.026030281395637   8: 0.026030246357797   0: 0.026030169592537   3: 0.026030074279411   7: 0.026029761278672 

training_12383    1: 0.455764514710846   5: 0.405761289693545   9: 0.017676271809682   6: 0.017261622631636   0: 0.017260639792045   4: 0.017256830982254   8: 0.017256145931174   7: 0.017254677543197   3: 0.017254176915995   2: 0.017253829989625 

training_12386    8: 0.302375224291157   6: 0.268127984028624   5: 0.266819604095723   1: 0.023246350133197   0: 0.023242342279756   4: 0.023238226311552   2: 0.023238123364349   9: 0.023237955107043   7: 0.023237299912483   3: 0.023236890476115 

training_12389    6: 0.599059747540639   0: 0.131217283277271   8: 0.081578097536875   2: 0.054484952591775   4: 0.041029964851917   3: 0.035867079211746   5: 0.014202817694297   1: 0.014188682227540   7: 0.014186439969592   9: 0.014184935098348 

training_1239     5: 0.791578755975844   6: 0.023233857631231   0: 0.023196638281062   4: 0.023141951433446   2: 0.023141763665863   3: 0.023141646695848   1: 0.023141584939742   8: 0.023141306502410   7: 0.023141302975944   9: 0.023141191898609 

training_12390    6: 0.576453800328035   8: 0.182937510847179   1: 0.116843266283923   5: 0.017687985950811   4: 0.017684301862766   2: 0.017680671192569   0: 0.017679711996359   7: 0.017678382227874   3: 0.017677291497885   9: 0.017677077812599 

training_12391    4: 0.813395612799591   6: 0.020747460629391   5: 0.020742265564378   0: 0.020738118380181   1: 0.020734194323114   3: 0.020729925234231   8: 0.020728599420509   2: 0.020728050299370   7: 0.020727940786009   9: 0.020727832563225 

training_12394    0: 0.397136405404622   6: 0.379322816336432   5: 0.076856079307922   3: 0.048680044631456   1: 0.044179049957568   4: 0.010766456951289   9: 0.010765082768808   8: 0.010765050582657   2: 0.010764721889157   7: 0.010764292170089 

training_12395    1: 0.667370630170276   6: 0.164151152483091   8: 0.045687166610681   3: 0.044757048839041   7: 0.013011654152449   0: 0.013008854338063   5: 0.013005217343151   9: 0.013003121866263   4: 0.013002795205213   2: 0.013002358991773 

training_12396    6: 0.635217953556261   0: 0.260060201260219   1: 0.021194384389704   3: 0.011947088166460   5: 0.011931351840479   4: 0.011930282995049   8: 0.011929834367503   9: 0.011929762815392   2: 0.011929698674285   7: 0.011929441934648 

training_12397    6: 0.613446950684546   1: 0.168543029113104   9: 0.124139604910023   3: 0.023998573630595   0: 0.015701150343099   5: 0.010846333559407   4: 0.010832940766990   8: 0.010831158510412   2: 0.010830652472386   7: 0.010829606009438 

training_12398    6: 0.550857923867450   9: 0.283380015627451   1: 0.043324232057925   0: 0.017521438086542   5: 0.017488023860629   8: 0.017486045325552   4: 0.017485749797311   2: 0.017485638245662   7: 0.017485501825929   3: 0.017485431305550 

training_12399    6: 0.736429871341930   7: 0.148914438314041   0: 0.014387900294324   3: 0.014367584508027   1: 0.014322165377281   9: 0.014317360553798   5: 0.014316977807110   8: 0.014315409738654   2: 0.014314152153630   4: 0.014314139911206 

training_124      6: 0.392264470980494   8: 0.391501173779016   5: 0.066537097872190   7: 0.021389516184895   0: 0.021386922878407   9: 0.021385600782141   1: 0.021384622314833   4: 0.021384062653960   2: 0.021383324208833   3: 0.021383208345232 

training_12400    0: 0.431531194582551   6: 0.416845881865019   8: 0.038021458217938   5: 0.016232591079609   4: 0.016231147439313   1: 0.016229751585118   9: 0.016228214848746   2: 0.016226676401710   7: 0.016226550313664   3: 0.016226533666331 

training_12401    6: 0.729214950811801   8: 0.093929238001255   1: 0.056043260098887   0: 0.028615104676224   9: 0.015387942445566   2: 0.015363907801915   7: 0.015363741345547   5: 0.015363588563622   4: 0.015359188822702   3: 0.015359077432481 

training_12403    6: 0.772125937896623   9: 0.025320490154717   0: 0.025320476557211   7: 0.025319775926920   5: 0.025319407016932   8: 0.025319324840261   1: 0.025319173984728   2: 0.025318491342657   3: 0.025318490594654   4: 0.025318431685297 

training_12404    6: 0.782739184596733   3: 0.049930887082487   5: 0.035410141646520   8: 0.026461194163021   1: 0.024476704929865   0: 0.024281524151215   7: 0.014177602296440   4: 0.014177579509673   2: 0.014174365866589   9: 0.014170815757458 

training_12406    6: 0.768323197028667   0: 0.093325714605209   1: 0.039211560078873   9: 0.014164050028440   5: 0.014163470836291   8: 0.014163112554924   4: 0.014162559437780   7: 0.014162477611618   3: 0.014161969294294   2: 0.014161888523905 

training_12407    6: 0.834616511407018   0: 0.041596272681647   9: 0.028376990203815   1: 0.013688310158720   5: 0.013637634259932   8: 0.013621417076829   4: 0.013619320971363   7: 0.013615223047231   3: 0.013615056605070   2: 0.013613263588376 

training_12408    3: 0.631430924653075   7: 0.136652715854059   5: 0.029002200350577   4: 0.028998018807814   9: 0.028992942815020   8: 0.028988835512868   1: 0.028984858313841   0: 0.028983890621418   6: 0.028983129241142   2: 0.028982483830186 

training_12409    1: 0.583622516199619   6: 0.191451490105773   5: 0.128297918550977   0: 0.022221494339976   8: 0.015771837719419   3: 0.014145239739441   2: 0.011407849722522   9: 0.011277158550357   4: 0.010906218378165   7: 0.010898276693751 

training_12410    6: 0.733828156068508   3: 0.087021364423298   7: 0.053646248598434   9: 0.017931268127746   8: 0.017930543186853   1: 0.017929950272692   0: 0.017929616256295   5: 0.017927896344055   2: 0.017927633276030   4: 0.017927323446089 

training_12411    6: 0.461501898257344   0: 0.331604522842890   9: 0.025863097247898   5: 0.025862933134846   7: 0.025862716281579   1: 0.025861537634258   2: 0.025861484439417   8: 0.025860913634552   4: 0.025860784752387   3: 0.025860111774830 

training_12413    9: 0.844618994897484   8: 0.017268760291686   6: 0.017265621641132   5: 0.017264716600839   0: 0.017264707536427   4: 0.017263829738052   1: 0.017263639050822   7: 0.017263295688924   2: 0.017263245679305   3: 0.017263188875329 

training_12415    6: 0.764523757521352   0: 0.079759169599476   1: 0.019470340607759   5: 0.019465964493002   7: 0.019464626445932   9: 0.019463853731280   2: 0.019463116488265   4: 0.019463088251472   3: 0.019463064181706   8: 0.019463018679756 

training_12416    6: 0.753766212279853   0: 0.098000274935714   9: 0.047374320834014   8: 0.014455620652589   4: 0.014412860193808   5: 0.014406045888282   1: 0.014397013012195   7: 0.014396981319022   2: 0.014395429500746   3: 0.014395241383777 

training_12417    6: 0.792859798001351   0: 0.079196216960799   7: 0.016001497982148   1: 0.015994277211305   5: 0.015993194979002   2: 0.015992498684891   8: 0.015991180131878   9: 0.015990555993913   4: 0.015990533726905   3: 0.015990246327807 

training_12418    6: 0.799030793411715   0: 0.074435183621383   1: 0.031356224331342   9: 0.013599269255541   8: 0.013597979123633   5: 0.013597009839442   7: 0.013596290754686   4: 0.013595944908561   2: 0.013595662379037   3: 0.013595642374660 

training_12420    6: 0.707612828090156   0: 0.117865725416895   2: 0.099609207339956   1: 0.012030778807887   7: 0.010513149410867   8: 0.010492039999742   5: 0.010473232366374   9: 0.010470348017900   3: 0.010466417047262   4: 0.010466273502960 

training_12421    9: 0.746455006735847   0: 0.028233191973704   6: 0.028202700160191   5: 0.028164723141259   1: 0.028163734779410   4: 0.028163287222244   7: 0.028156041041801   8: 0.028155701309003   3: 0.028153427678678   2: 0.028152185957863 

training_12422    6: 0.576058062364631   1: 0.312586787031792   0: 0.022619451462424   3: 0.012717621058527   9: 0.012675095284458   2: 0.012670615505852   5: 0.012669376805630   4: 0.012667835832435   8: 0.012667715155900   7: 0.012667439498349 

training_12423    6: 0.790480928564946   0: 0.107899952872899   5: 0.012705484483367   1: 0.012705405979976   2: 0.012702476435622   9: 0.012701497908068   8: 0.012701476181595   7: 0.012701381049711   4: 0.012700785708256   3: 0.012700610815561 

training_12424    6: 0.855460215204224   0: 0.026806971103126   8: 0.014782086614421   7: 0.014745913257605   3: 0.014715730492920   1: 0.014706860598524   9: 0.014695862438602   5: 0.014695621853515   4: 0.014695406471756   2: 0.014695331965307 

training_12425    6: 0.597938738216528   8: 0.154134577643768   5: 0.071142701284805   0: 0.056680156737130   4: 0.047064365524233   7: 0.014611082430911   1: 0.014609058950510   9: 0.014607341414837   2: 0.014606018249905   3: 0.014605959547374 

training_12426    6: 0.394833566848473   4: 0.236014119450603   8: 0.199722251877519   7: 0.045747155377383   5: 0.022234122840728   0: 0.020623394993799   1: 0.020213143259280   2: 0.020209119547798   3: 0.020207553471368   9: 0.020195572333048 

training_12428    6: 0.777921501268261   5: 0.089691901895103   0: 0.016552345747986   1: 0.016551866977405   7: 0.016549737378994   9: 0.016546877767773   8: 0.016546673830615   4: 0.016546620514175   3: 0.016546553305602   2: 0.016545921314086 

training_12429    6: 0.504329098774249   0: 0.310300824112299   4: 0.048570406648102   7: 0.042710129230135   8: 0.029974316391099   9: 0.012824109241409   5: 0.012823823116545   2: 0.012822818365238   1: 0.012822581820616   3: 0.012821892300307 

training_1243     6: 0.430554479548734   0: 0.372161098429942   7: 0.064185992195612   5: 0.019018339347766   4: 0.019016509700461   1: 0.019016344655052   8: 0.019012028109596   9: 0.019011981592019   2: 0.019011772153029   3: 0.019011454267789 

training_12432    6: 0.712823213001066   9: 0.101879818642446   1: 0.093426386962295   7: 0.019709970452154   3: 0.012114799943430   5: 0.012020092770416   4: 0.012011107331998   0: 0.012009226220251   2: 0.012002980856873   8: 0.012002403819072 

training_12433    9: 0.739579604796084   8: 0.028943880441052   6: 0.028942848084840   5: 0.028941450625568   0: 0.028934218604069   4: 0.028932518862166   7: 0.028932161574756   2: 0.028931691101894   1: 0.028931264717153   3: 0.028930361192419 

training_12435    6: 0.634318351067283   0: 0.218263903620018   9: 0.034260593088228   7: 0.030722603651986   5: 0.013743318231907   4: 0.013741104045323   1: 0.013739487472889   8: 0.013738676296054   2: 0.013736047844163   3: 0.013735914682149 

training_12436    6: 0.762743195582829   0: 0.082219458823453   5: 0.041413538260311   8: 0.016232672599757   7: 0.016232264218284   9: 0.016231921010386   1: 0.016231890131231   3: 0.016231748802029   4: 0.016231740154487   2: 0.016231570417233 

training_12437    6: 0.822519345257180   0: 0.034137839913235   5: 0.018216758591987   1: 0.018003523259023   3: 0.017966373855209   4: 0.017915321066471   2: 0.017892387189127   7: 0.017787600111640   8: 0.017781643421251   9: 0.017779207334878 

training_12439    7: 0.345307727390942   6: 0.291997340821976   9: 0.149474564242706   3: 0.067885331953118   0: 0.041568425892619   8: 0.020756073905850   5: 0.020753807808824   1: 0.020753059804628   4: 0.020751925071278   2: 0.020751743108058 

training_1244     5: 0.507647857937241   8: 0.279469247663230   6: 0.026611303944711   0: 0.026610778993124   3: 0.026610554428495   4: 0.026610468996662   1: 0.026610280308018   2: 0.026609981751105   9: 0.026609802937002   7: 0.026609723040413 

training_12441    0: 0.480609964806628   5: 0.161193110674365   3: 0.140249620312844   1: 0.101104229573240   2: 0.038241275606452   6: 0.015741270650006   4: 0.015716809876886   7: 0.015715917558092   8: 0.015713956572590   9: 0.015713844368898 

training_12442    6: 0.678567349988029   1: 0.113904217642929   5: 0.097145469708945   8: 0.028062173827578   0: 0.022600502971087   9: 0.011949306076467   2: 0.011944788603962   7: 0.011942842982189   4: 0.011942078915759   3: 0.011941269283055 

training_12443    0: 0.662911574698269   6: 0.190706577627975   4: 0.053832836331298   9: 0.014090340610691   1: 0.013438809281959   3: 0.013149439849671   7: 0.013030588742526   5: 0.012974081260456   8: 0.012933232839753   2: 0.012932518757402 

training_12447    6: 0.583243534349807   0: 0.287989850450250   9: 0.044368792652564   8: 0.030889869168513   4: 0.008937538091316   1: 0.008927374316329   3: 0.008912589383142   5: 0.008910813723513   7: 0.008909874121994   2: 0.008909763742573 

training_12448    9: 0.721508497307719   5: 0.030971900531487   4: 0.030969571561317   8: 0.030937371339204   6: 0.030936110895507   3: 0.030935874259337   0: 0.030935369334936   1: 0.030935215249850   2: 0.030935155608248   7: 0.030934933912395 

training_12449    1: 0.784553968062292   5: 0.039575967844762   8: 0.028067099099051   7: 0.026791601743660   6: 0.020207673378631   0: 0.020180055886145   4: 0.020169144634178   3: 0.020161747399775   2: 0.020146385374635   9: 0.020146356576870 

training_1245     5: 0.771481647198279   0: 0.068870547271433   4: 0.019960217369162   8: 0.019955527643346   6: 0.019955446089189   9: 0.019955420525494   1: 0.019955394475931   2: 0.019955307430754   3: 0.019955260951197   7: 0.019955231045215 

training_12453    8: 0.584754565807535   6: 0.254175118463333   9: 0.020140403925709   5: 0.020134766076794   0: 0.020133583897460   1: 0.020133271052057   4: 0.020132846832263   3: 0.020132282008864   7: 0.020131596765966   2: 0.020131565170019 

training_12454    1: 0.469915233331652   6: 0.275387158226853   5: 0.168408132025407   8: 0.012334309667696   0: 0.012332195812222   9: 0.012326810832797   3: 0.012324735525707   2: 0.012324001312555   7: 0.012323821331539   4: 0.012323601933571 

training_12455    6: 0.719157043344640   0: 0.031251056594913   5: 0.031200577555344   4: 0.031200227252856   7: 0.031200185986592   1: 0.031199428919115   3: 0.031198203388210   8: 0.031198132619457   9: 0.031197915311803   2: 0.031197229027070 

training_12456    6: 0.828867771866961   0: 0.019020737884663   5: 0.019016617838419   3: 0.019015064374983   1: 0.019013619158927   7: 0.019013614655906   9: 0.019013498800875   8: 0.019013424395324   4: 0.019013061721249   2: 0.019012589302694 

training_12457    6: 0.690085273801891   1: 0.111809298326349   0: 0.066251162870054   8: 0.042777810492153   5: 0.024416847310442   9: 0.021502776995111   7: 0.010790287124354   3: 0.010789375049532   4: 0.010788750495820   2: 0.010788417534294 

training_12458    6: 0.491520409442015   0: 0.366680112175610   7: 0.017740225463182   2: 0.017730477673583   5: 0.017722869567771   1: 0.017721627938096   9: 0.017721587896875   8: 0.017721077031241   4: 0.017721068763515   3: 0.017720544048112 

training_1246     6: 0.786099594779710   7: 0.071447890005901   1: 0.025703245282184   9: 0.016688084548624   5: 0.016677327268108   0: 0.016677020531326   3: 0.016676789284091   4: 0.016676756453638   8: 0.016676704067630   2: 0.016676587778789 

training_12460    1: 0.405401111384459   6: 0.317637327389644   9: 0.149658848774327   2: 0.038260484366258   8: 0.026498746056429   0: 0.012672083750856   5: 0.012470096484057   4: 0.012468652286436   3: 0.012468013939097   7: 0.012464635568437 

training_12461    6: 0.755733948813665   0: 0.132339617341490   1: 0.035457642181762   7: 0.010934804015571   9: 0.010925979409799   2: 0.010923658227323   5: 0.010921554766855   4: 0.010921031196117   8: 0.010920930885764   3: 0.010920833161654 

training_12462    6: 0.621304162514801   7: 0.196941288766849   5: 0.022726719389707   0: 0.022719371403969   1: 0.022719363766073   3: 0.022718513167581   9: 0.022717757225067   4: 0.022717665235027   2: 0.022717584531668   8: 0.022717573999258 

training_12463    6: 0.348994001883158   9: 0.309412170475746   5: 0.148150968407203   7: 0.076253285029178   0: 0.043460044104345   4: 0.014748490322399   1: 0.014746218576824   3: 0.014745307000189   2: 0.014744811993795   8: 0.014744702207162 

training_12464    6: 0.730933571631433   0: 0.121376269609547   5: 0.018463269413326   8: 0.018461549890332   4: 0.018461230969736   7: 0.018461194084971   9: 0.018461056433708   1: 0.018460950844144   2: 0.018460533519354   3: 0.018460373603449 

training_12465    6: 0.609516427065075   7: 0.086805179667768   0: 0.080072414876120   1: 0.075645299341274   8: 0.074791759128120   5: 0.014634978299474   9: 0.014633891476827   3: 0.014633438046648   4: 0.014633310741632   2: 0.014633301357064 

training_12466    6: 0.857761003185022   0: 0.032322329518370   1: 0.013754384136678   3: 0.013739665287058   7: 0.013739266728102   5: 0.013737458546264   9: 0.013737211560962   8: 0.013736317229026   4: 0.013736211483975   2: 0.013736152324541 

training_12468    6: 0.672059975147032   1: 0.134355069115524   5: 0.071986642476385   0: 0.017404751955064   9: 0.017367324901311   2: 0.017366836921479   4: 0.017366735230648   8: 0.017365596875381   7: 0.017363613345986   3: 0.017363454031189 

training_12469    6: 0.550416264340370   9: 0.283528971893752   0: 0.043563255869002   1: 0.017575032421670   5: 0.017488029978656   8: 0.017486048883209   4: 0.017485814363240   2: 0.017485641547781   7: 0.017485506712310   3: 0.017485433990010 

training_12470    1: 0.452502908071825   6: 0.254020728938388   8: 0.070566627393498   0: 0.069765388741091   7: 0.062523411002295   9: 0.018125075989765   5: 0.018124475499326   2: 0.018123828401184   3: 0.018123805835255   4: 0.018123750127373 

training_12471    6: 0.828867299468327   0: 0.019021208436267   5: 0.019016618492765   3: 0.019015064775533   1: 0.019013619336553   7: 0.019013614832795   9: 0.019013498961702   8: 0.019013424545351   4: 0.019013061818291   2: 0.019012589332416 

training_12472    6: 0.575683015707418   1: 0.271066804472621   0: 0.042168468305111   3: 0.031751741957929   9: 0.027916480956615   8: 0.010287795212763   5: 0.010282014596070   7: 0.010281277125579   2: 0.010281221948246   4: 0.010281179717647 

training_12473    6: 0.690205338570088   1: 0.111653156431268   0: 0.066288256400374   8: 0.042780149044475   5: 0.024412622673557   9: 0.021503648184817   7: 0.010790285531748   3: 0.010789374909484   4: 0.010788750718541   2: 0.010788417535648 

training_12480    6: 0.809218288668094   0: 0.046904316200692   7: 0.018104655929539   8: 0.018008592119668   9: 0.017986363366214   5: 0.017958026511368   1: 0.017957231668535   4: 0.017954913465698   3: 0.017953831449210   2: 0.017953780620980 

training_12483    6: 0.769385829018097   5: 0.025628484288912   2: 0.025626400600817   1: 0.025624044443749   0: 0.025623950178002   4: 0.025623818460511   9: 0.025622515645154   8: 0.025622066204213   3: 0.025621715448349   7: 0.025621175712196 

training_12484    6: 0.395222021002930   0: 0.249947572039795   8: 0.218695122318018   7: 0.019492492748501   9: 0.019446698006603   5: 0.019444770008735   4: 0.019441177262738   2: 0.019438453019895   1: 0.019436956299779   3: 0.019434737293006 

training_12485    0: 0.693258875410936   1: 0.166678449998479   3: 0.032573333330157   6: 0.015377161668728   9: 0.015367010271126   5: 0.015355904394898   4: 0.015347803519173   2: 0.015347275097458   8: 0.015347118537308   7: 0.015347067771738 

training_12487    6: 0.443556696454640   0: 0.400151870574322   1: 0.037431712865980   3: 0.034209548185641   7: 0.031110062069057   5: 0.011617864184482   9: 0.011588620202181   2: 0.010532077075649   4: 0.009913583887776   8: 0.009887964500273 

training_12488    6: 0.416476405907298   1: 0.247262964043937   0: 0.216889059411931   8: 0.026741050712124   5: 0.015446781317777   4: 0.015440342876211   9: 0.015436709081664   2: 0.015435747429510   3: 0.015435622913344   7: 0.015435316306204 

training_12489    1: 0.632538825405367   6: 0.205424805224354   2: 0.020383453374705   0: 0.020237636325577   5: 0.020236841374116   9: 0.020236605371470   7: 0.020236523443150   4: 0.020235700594432   8: 0.020235142628520   3: 0.020234466258309 

training_12490    6: 0.720952526935169   1: 0.121337787910306   7: 0.037265010886481   3: 0.030290455255831   0: 0.024764213030866   8: 0.013314299679805   5: 0.013021733496829   9: 0.013018931075241   2: 0.013017550795208   4: 0.013017490934264 

training_12492    2: 0.570482164578361   1: 0.230888904744732   3: 0.048397392984152   6: 0.021466632679177   0: 0.021462281864828   5: 0.021462233189750   9: 0.021462015430073   4: 0.021461030414301   7: 0.021459045402287   8: 0.021458298712340 

training_12494    9: 0.716576516382776   6: 0.109523199287539   8: 0.021756203156321   1: 0.021737785955785   3: 0.021736550022954   5: 0.021735564069264   0: 0.021734280698270   4: 0.021733689603698   2: 0.021733251304444   7: 0.021732959518948 

training_12495    6: 0.526578920902770   7: 0.247718676596654   9: 0.028214517626217   0: 0.028214039774320   8: 0.028213429310393   1: 0.028212549981559   3: 0.028212485595324   5: 0.028212098483880   2: 0.028211761505319   4: 0.028211520223564 

training_125      1: 0.549153485834831   8: 0.299457940960858   5: 0.018928026788753   6: 0.018927841610541   0: 0.018923714739692   9: 0.018922305046759   4: 0.018922271019263   2: 0.018921700938369   7: 0.018921583352650   3: 0.018921129708283 

training_12500    6: 0.838197737849374   8: 0.017984152153330   1: 0.017978030165600   0: 0.017977837951105   7: 0.017977644560530   9: 0.017977394444973   2: 0.017976849317146   5: 0.017976828782581   4: 0.017976816603984   3: 0.017976708171376 

training_12501    6: 0.630572634643510   7: 0.155469016306961   3: 0.058068431118865   0: 0.053492028818023   5: 0.017068580943442   8: 0.017067332679434   9: 0.017066778254934   1: 0.017066269726262   4: 0.017064512590921   2: 0.017064414917647 

training_12503    1: 0.438231330535112   6: 0.203879809929008   2: 0.200512958363237   4: 0.046439374836443   0: 0.018512787950475   5: 0.018490211827799   9: 0.018484103634284   3: 0.018483743539067   7: 0.018482922594182   8: 0.018482756790394 

training_12504    6: 0.385117984414701   5: 0.263942844829184   7: 0.232896948931308   9: 0.016866548863665   0: 0.016866152119190   1: 0.016864095359793   4: 0.016861948714728   3: 0.016861424424605   2: 0.016861419508849   8: 0.016860632833977 

training_12505    4: 0.580735636126048   6: 0.214864895402816   5: 0.025557041875147   8: 0.025549187388774   3: 0.025549017571113   1: 0.025548949745382   0: 0.025548936728563   2: 0.025548825865489   9: 0.025548825031097   7: 0.025548684265571 

training_12506    5: 0.731110566587500   6: 0.070671016324593   4: 0.024782237792368   2: 0.024780308122898   8: 0.024779750306435   0: 0.024775911383887   3: 0.024775783478109   7: 0.024775765196034   1: 0.024775254036198   9: 0.024773406771979 

training_12507    6: 0.571526025518934   7: 0.290365462391245   5: 0.017281443452362   3: 0.017262869859091   1: 0.017261828558358   8: 0.017261435105189   4: 0.017260784906868   0: 0.017260632348117   9: 0.017260152508188   2: 0.017259365351648 

training_12508    5: 0.459444170744670   3: 0.298504054084896   6: 0.030265518867855   0: 0.030258953145886   8: 0.030258105492545   9: 0.030256313360783   4: 0.030256118269505   1: 0.030254336819255   7: 0.030252419176775   2: 0.030250010037829 

training_12509    2: 0.760024459845156   6: 0.026727558013438   5: 0.026686936820114   0: 0.026673642003375   9: 0.026657345591700   8: 0.026656643220425   1: 0.026647330887613   4: 0.026644531490039   7: 0.026643417499895   3: 0.026638134628247 

training_1251     4: 0.821585680293087   5: 0.019830869995654   1: 0.019823380582127   0: 0.019823181814949   9: 0.019823108485839   6: 0.019823100406712   8: 0.019822850781472   2: 0.019822707971656   3: 0.019822562491934   7: 0.019822557176570 

training_12511    3: 0.401123898519797   5: 0.340466150720296   6: 0.032325163014740   0: 0.032301432331710   9: 0.032300283009848   8: 0.032299859786108   1: 0.032299522669902   2: 0.032295973169653   4: 0.032295736129351   7: 0.032291980648594 

training_12512    6: 0.587944171145617   1: 0.168762674261958   9: 0.116323212574882   3: 0.018145283744824   4: 0.018144801985795   5: 0.018141078360864   0: 0.018137408288688   2: 0.018134264033909   8: 0.018133636872890   7: 0.018133468730572 

training_12514    1: 0.740180152413805   6: 0.028893999893053   2: 0.028876664666879   0: 0.028870763818447   5: 0.028869904093023   8: 0.028864091720540   9: 0.028863729899146   3: 0.028862409388315   7: 0.028859818174926   4: 0.028858465931867 

training_12515    6: 0.481743966978941   5: 0.317392178054992   0: 0.094577666931086   1: 0.015186498043413   4: 0.015185305461080   8: 0.015183178567739   9: 0.015183166826069   7: 0.015182879148787   2: 0.015182810032327   3: 0.015182349955566 

training_12516    4: 0.814228343390641   5: 0.020646661689315   6: 0.020641673483208   8: 0.020640811143153   0: 0.020640786716473   1: 0.020640446231829   9: 0.020640392241074   7: 0.020640320481523   3: 0.020640311855253   2: 0.020640252767532 

training_12517    5: 0.778125298839357   6: 0.024697648060048   4: 0.024660349080107   0: 0.024653583660734   1: 0.024649438529784   7: 0.024643639668697   9: 0.024643024510765   8: 0.024642635339109   2: 0.024642306894592   3: 0.024642075416805 

training_1252     0: 0.556235762857655   6: 0.252051717961013   1: 0.086415604133552   9: 0.032318764347976   2: 0.012217926312800   5: 0.012173732605024   7: 0.012148090571585   8: 0.012146540978746   4: 0.012146304157112   3: 0.012145556074538 

training_12520    5: 0.783771781618721   4: 0.024028667273069   8: 0.024025252014665   9: 0.024025005364892   3: 0.024024985122615   2: 0.024024909830132   0: 0.024024895243890   7: 0.024024864155652   1: 0.024024829034856   6: 0.024024810341507 

training_12521    6: 0.366135372388618   5: 0.249828525405988   0: 0.141458046625612   3: 0.128261346753857   4: 0.040205382381043   7: 0.023751515846726   9: 0.016849863645604   1: 0.011171072933884   8: 0.011170088749496   2: 0.011168785269173 

training_12522    0: 0.774365045251662   5: 0.025079283216313   6: 0.025074195679259   8: 0.025071141911259   3: 0.025069814998299   9: 0.025069813924111   1: 0.025068586939601   7: 0.025067876816057   2: 0.025067187661141   4: 0.025067053602300 

training_12523    9: 0.790765421081961   8: 0.023253204361104   6: 0.023250554456545   5: 0.023248793448173   0: 0.023247539922903   1: 0.023247427641704   4: 0.023247179070109   7: 0.023246845268645   3: 0.023246553128956   2: 0.023246481619900 

training_12524    6: 0.449049608934256   8: 0.316872746659632   1: 0.073627732622740   2: 0.055202508274055   0: 0.017549895785224   5: 0.017543976019047   4: 0.017542154296430   9: 0.017538212525564   3: 0.017537543328998   7: 0.017535621554055 

training_12525    6: 0.747233978266965   1: 0.058014080291780   0: 0.050068553477663   4: 0.020904521332894   9: 0.020649838752167   7: 0.020629944776647   5: 0.020628093312079   2: 0.020624698734493   8: 0.020623188212769   3: 0.020623102842543 

training_12529    1: 0.461750878648537   4: 0.347184926302978   3: 0.078345348450767   0: 0.016109716503648   6: 0.016105830113468   5: 0.016105090622555   8: 0.016102761472773   9: 0.016098854643586   2: 0.016098675881363   7: 0.016097917360324 

training_12530    2: 0.576361516905050   4: 0.187801629440061   1: 0.029485757779477   6: 0.029481810856540   0: 0.029480822482531   5: 0.029479650081252   9: 0.029477459618747   7: 0.029477375907042   3: 0.029477371812001   8: 0.029476605117300 

training_12531    5: 0.554103960133622   4: 0.123997991217771   0: 0.107315144736153   1: 0.101660367794348   9: 0.018829491896813   6: 0.018828110828386   8: 0.018817268322812   2: 0.018816193099828   7: 0.018815984619624   3: 0.018815487350643 

training_12532    1: 0.318721441706272   2: 0.269567050899434   4: 0.178809386760785   0: 0.143906819281893   6: 0.014845592159848   8: 0.014832589150431   5: 0.014832300192117   3: 0.014830098771416   7: 0.014827536211837   9: 0.014827184865966 

training_12533    6: 0.588449047536020   1: 0.166827792964431   8: 0.087934240369997   7: 0.059130288355430   3: 0.040880408701830   0: 0.011569582321552   9: 0.011310535293449   2: 0.011301380300375   5: 0.011299219022543   4: 0.011297505134373 

training_12534    6: 0.548093535878321   7: 0.248327473317363   3: 0.065772788866544   0: 0.019692754534339   5: 0.019687511910849   9: 0.019685527116478   1: 0.019685425378869   8: 0.019685403122729   4: 0.019684950454936   2: 0.019684629419572 

training_12538    6: 0.447035445080941   5: 0.243317453867325   8: 0.143960350906805   3: 0.023700224556214   1: 0.023670043577607   0: 0.023668867344397   4: 0.023666870866643   2: 0.023660974354707   7: 0.023660210960673   9: 0.023659558484688 

training_12540    5: 0.766802484947867   6: 0.025915519037899   1: 0.025911491773893   0: 0.025911212538315   4: 0.025910562803926   2: 0.025910085411541   3: 0.025910010556428   7: 0.025909697205655   8: 0.025909491646487   9: 0.025909444077990 

training_12543    6: 0.486251540779143   8: 0.254429689152477   2: 0.116070529271166   5: 0.020503009788646   0: 0.020476703990734   3: 0.020472459466522   7: 0.020450241930453   1: 0.020449792154910   9: 0.020448051650586   4: 0.020447981815364 

training_12545    5: 0.762729297594762   6: 0.026378658852067   1: 0.026364912998405   0: 0.026362038041285   2: 0.026361296003294   3: 0.026361028878695   4: 0.026360928964175   8: 0.026360883759300   9: 0.026360488198413   7: 0.026360466709604 

training_12546    5: 0.440147096112631   6: 0.202854653673128   9: 0.141964598976463   2: 0.073519829757407   8: 0.046231707308787   3: 0.019162323517240   0: 0.019038208711675   1: 0.019034859087641   4: 0.019028157242985   7: 0.019018565612043 

training_12549    5: 0.483869018000894   2: 0.198660339201842   8: 0.131870594175588   0: 0.026519331478645   6: 0.026516507373062   1: 0.026516097547682   9: 0.026514183385146   4: 0.026511413019707   3: 0.026511267674839   7: 0.026511248142595 

training_12550    5: 0.547801343842805   0: 0.268704151564808   1: 0.036483449094773   8: 0.034579327434327   3: 0.032988561206199   7: 0.015922587078523   6: 0.015887402916577   9: 0.015878339279983   4: 0.015877459193295   2: 0.015877378388711 

training_12551    4: 0.668066872554576   2: 0.141104835345404   6: 0.023882871362556   0: 0.023858071660412   1: 0.023855671863433   5: 0.023854142775513   9: 0.023846067928321   7: 0.023845401553764   8: 0.023844711347524   3: 0.023841353608496 

training_12554    6: 0.600027715734294   9: 0.226026654540500   2: 0.056163565481206   0: 0.016830613724962   5: 0.016827553491245   8: 0.016825432619743   1: 0.016825361170665   7: 0.016824583912893   3: 0.016824442166647   4: 0.016824077157844 

training_12555    6: 0.685397397906853   0: 0.109185663083362   7: 0.066344491978432   1: 0.045340263518821   5: 0.015625150846952   4: 0.015623616573673   9: 0.015621844878848   8: 0.015621098384302   3: 0.015620268501585   2: 0.015620204327171 

training_12557    6: 0.629671546254999   0: 0.187213106366172   8: 0.046873297676110   1: 0.019470452429591   5: 0.019463787755973   9: 0.019462425871656   4: 0.019461473411840   2: 0.019461431660090   7: 0.019461396182495   3: 0.019461082391074 

training_12558    6: 0.604671776103449   0: 0.173529825972780   8: 0.027726497202699   1: 0.027726296992995   7: 0.027724388715780   9: 0.027724366307566   5: 0.027724305182098   3: 0.027724238972722   2: 0.027724178473489   4: 0.027724126076422 

training_12559    0: 0.536614794314307   5: 0.307631029734706   6: 0.043086485957169   8: 0.016136162623930   1: 0.016097629850199   9: 0.016087717029380   4: 0.016086747282250   2: 0.016086571178547   7: 0.016086556225012   3: 0.016086305804500 

training_12562    4: 0.778425682398510   8: 0.070668966143683   5: 0.018868470299168   6: 0.018866993140227   7: 0.018862286541279   9: 0.018862118430709   2: 0.018861910975215   0: 0.018861594505075   1: 0.018861176464995   3: 0.018860801101138 

training_12563    6: 0.762320459342684   0: 0.088300996623232   1: 0.058279939904955   2: 0.013014497743901   8: 0.013014385924603   5: 0.013014096541135   9: 0.013014073617837   3: 0.013013857662870   7: 0.013013847172048   4: 0.013013845466735 

training_12564    6: 0.662653626996686   1: 0.128035229104197   9: 0.108412646320987   0: 0.014438844494924   2: 0.014416648718096   3: 0.014411301753787   7: 0.014409997948261   8: 0.014407597518207   5: 0.014407579293295   4: 0.014406527851559 

training_12569    5: 0.640324967480717   2: 0.189387017893989   4: 0.021291388651830   8: 0.021285719617217   6: 0.021285647745636   1: 0.021285305013572   9: 0.021285201992157   0: 0.021285129026786   7: 0.021284921184938   3: 0.021284701393158 

training_1257     6: 0.835691113100066   1: 0.018342178974570   5: 0.018246733224406   7: 0.018246207521895   3: 0.018246175636558   0: 0.018245990405599   9: 0.018245558311938   4: 0.018245396859634   8: 0.018245369580359   2: 0.018245276384975 

training_12570    4: 0.715830754849519   2: 0.091116627015802   5: 0.024144368674942   0: 0.024131109407365   8: 0.024130597489471   6: 0.024130252057310   1: 0.024129878593429   7: 0.024128947116324   3: 0.024128744440712   9: 0.024128720355124 

training_12571    6: 0.563217536225165   3: 0.257982857707278   5: 0.022354127627543   8: 0.022351816319320   2: 0.022351263270597   0: 0.022350252339826   1: 0.022349096336784   4: 0.022348169663568   9: 0.022347956067711   7: 0.022346924442209 

training_12572    5: 0.700604652901751   7: 0.099234478597803   4: 0.025026300709411   0: 0.025019828238969   1: 0.025019551957070   8: 0.025019245891676   3: 0.025019060424567   2: 0.025019010550701   6: 0.025018938415994   9: 0.025018932312057 

training_12573    6: 0.402890874233742   5: 0.357878190146032   1: 0.130287529744529   9: 0.015575120429609   0: 0.015564441104617   4: 0.015561689272925   2: 0.015561147682636   8: 0.015560570634064   7: 0.015560264839846   3: 0.015560171912001 

training_12574    1: 0.453425078633699   5: 0.211546367968333   2: 0.173150766520369   8: 0.063630265435588   6: 0.016419563717222   0: 0.016369164603450   9: 0.016365393654594   3: 0.016364724139745   4: 0.016364513020121   7: 0.016364162306879 

training_12576    6: 0.497011305290052   0: 0.394857404642017   9: 0.013517972853815   1: 0.013517815653754   8: 0.013516553546658   5: 0.013516528223846   7: 0.013515750407318   4: 0.013515643057975   3: 0.013515524195106   2: 0.013515502129460 

training_12579    5: 0.574370658143155   0: 0.165330849252395   1: 0.121169756574124   6: 0.019878715475631   3: 0.019876669226002   2: 0.019875117426829   7: 0.019874638276536   4: 0.019874623605535   9: 0.019874580156025   8: 0.019874391863767 

training_1258     4: 0.832520031031780   0: 0.018731545685776   5: 0.018599006223945   9: 0.018593056191731   3: 0.018592994812917   1: 0.018592820606205   2: 0.018592732349353   8: 0.018592719670496   7: 0.018592688171451   6: 0.018592405256347 

training_12580    5: 0.519789854711386   3: 0.290481471367371   6: 0.023741309186648   0: 0.023727581507499   8: 0.023726771421105   9: 0.023722049178469   4: 0.023703323124335   7: 0.023702722194929   2: 0.023702472952363   1: 0.023702444355895 

training_12583    6: 0.831123988337494   8: 0.018768861458111   1: 0.018763993283789   0: 0.018763654569231   5: 0.018763641725119   7: 0.018763446531674   9: 0.018763398117171   3: 0.018763069296974   2: 0.018762974668126   4: 0.018762972012309 

training_12585    7: 0.396646504292473   6: 0.329018416935903   3: 0.094108041072119   2: 0.063683301627962   5: 0.019448231247785   0: 0.019420939937254   4: 0.019418899658490   1: 0.019418763287003   9: 0.019418451724859   8: 0.019418450216150 

training_12587    6: 0.542619566157418   0: 0.182335255542787   5: 0.121687043494731   1: 0.036983245117620   7: 0.036016922696994   2: 0.016075634531849   3: 0.016072647468358   9: 0.016071987697345   8: 0.016070096207714   4: 0.016067601085183 

training_12588    6: 0.728057911668865   0: 0.030217164071264   8: 0.030216454252910   9: 0.030216107773872   1: 0.030215739429378   5: 0.030215709818985   3: 0.030215328992904   4: 0.030215220382381   7: 0.030215204700140   2: 0.030215158909301 

training_12592    6: 0.536557416813321   5: 0.291618072972814   2: 0.021479608632056   1: 0.021479395352955   0: 0.021478801815215   8: 0.021478597770959   9: 0.021477725185424   3: 0.021477317040268   4: 0.021476603903001   7: 0.021476460513987 

training_12593    6: 0.712174412127659   0: 0.031981852317951   1: 0.031980978833547   7: 0.031980420462612   5: 0.031980419593518   9: 0.031980399465581   8: 0.031980398022359   2: 0.031980375954162   3: 0.031980372928529   4: 0.031980370294084 

training_126      4: 0.693418490264641   0: 0.115074472927873   5: 0.023943275197258   6: 0.023938215727794   8: 0.023937790281070   1: 0.023937729391935   9: 0.023937634646709   3: 0.023937567214052   2: 0.023937441417915   7: 0.023937382930754 

training_1260     4: 0.475794630363114   6: 0.384665216040644   7: 0.017512703779515   5: 0.017438180674181   0: 0.017434777698251   1: 0.017434687324257   2: 0.017431024116063   9: 0.017429926200020   3: 0.017429472700053   8: 0.017429381103902 

training_1263     9: 0.343590653443191   0: 0.296216240184228   6: 0.237889954967099   1: 0.026211901680824   5: 0.016062394552235   7: 0.016031440946930   2: 0.016007013173697   3: 0.015997914285858   8: 0.015997258367638   4: 0.015995228398301 

training_1264     5: 0.454046364215625   7: 0.322062278313711   4: 0.027995477592804   8: 0.027987336725763   0: 0.027985213691976   2: 0.027984814039425   3: 0.027984792436903   6: 0.027984628167963   9: 0.027984555413100   1: 0.027984539402730 

training_1265     5: 0.766590833121840   6: 0.025936319739975   4: 0.025936270036531   1: 0.025934289945447   0: 0.025933949833364   8: 0.025933728298870   7: 0.025933711543689   3: 0.025933699853341   2: 0.025933638895695   9: 0.025933558731249 

training_1268     6: 0.505160466294194   7: 0.272028211357934   1: 0.027852712789533   0: 0.027852305007496   8: 0.027851716435815   5: 0.027851301432714   9: 0.027850995169903   2: 0.027850944448795   4: 0.027850842494172   3: 0.027850504569445 

training_1269     6: 0.423936680299257   5: 0.385088395152799   4: 0.085697554598752   2: 0.019522516091444   8: 0.019059194121002   0: 0.013377822335580   1: 0.013340416742004   7: 0.013337679862318   9: 0.013322390409514   3: 0.013317350387329 

training_127      2: 0.425105600197195   6: 0.307949864387229   0: 0.148302890847609   1: 0.016950263069381   9: 0.016949665086514   5: 0.016949639729066   8: 0.016948532998410   7: 0.016948096203416   4: 0.016947863638366   3: 0.016947583842815 

training_1271     5: 0.755652078302073   4: 0.027160242168317   9: 0.027148798977355   8: 0.027148584575754   0: 0.027148471072958   1: 0.027148432896444   2: 0.027148395792842   3: 0.027148377516379   7: 0.027148373880846   6: 0.027148244817033 

training_1272     6: 0.554835895667553   0: 0.336073361672947   5: 0.032019688217409   8: 0.018172019025593   9: 0.009843122422613   2: 0.009827729543901   1: 0.009815192823033   4: 0.009805960792170   3: 0.009804098554892   7: 0.009802931279888 

training_12728    6: 0.425393423925336   9: 0.224662549074844   0: 0.191566693112790   1: 0.067169263514257   5: 0.015208811288838   2: 0.015202168671451   4: 0.015200173588330   8: 0.015199100216755   3: 0.015199096570922   7: 0.015198720036478 

training_1273     6: 0.666063641459014   7: 0.159349873205687   5: 0.021824549859373   1: 0.021823839302183   0: 0.021823775390286   4: 0.021823476955681   8: 0.021823252287911   9: 0.021822762430726   2: 0.021822531504019   3: 0.021822297605119 

training_12731    6: 0.809284497028277   0: 0.046681533490877   5: 0.018056683031801   1: 0.018027962360300   2: 0.017993094776570   8: 0.017992128632755   9: 0.017991257118965   3: 0.017991086510452   4: 0.017990917933856   7: 0.017990839116147 

training_12732    6: 0.692508917045895   9: 0.178398596557885   0: 0.045933253971397   1: 0.011889290296917   8: 0.011885178377934   5: 0.011880055148505   4: 0.011877161089664   7: 0.011876125541182   2: 0.011875991267054   3: 0.011875430703568 

training_12737    6: 0.570082043212345   5: 0.312074245242851   9: 0.014739527718058   4: 0.014734191058672   1: 0.014729815582794   0: 0.014729501389713   3: 0.014727740075051   8: 0.014727682216925   7: 0.014727658092898   2: 0.014727595410693 

training_12741    0: 0.545621181358415   9: 0.288538731726283   2: 0.049812184814088   6: 0.016580660333058   5: 0.016577422360020   1: 0.016575305146519   8: 0.016574538262195   7: 0.016573566894647   4: 0.016573561657730   3: 0.016572847447045 

training_12743    6: 0.664339891506007   7: 0.231713383137687   0: 0.012995939234606   1: 0.012994604898457   5: 0.012994217788156   8: 0.012993064638998   9: 0.012992659801456   4: 0.012992389968932   3: 0.012991941982043   2: 0.012991907043657 

training_12745    9: 0.852694178796796   8: 0.016371832596410   6: 0.016367896305984   5: 0.016367680571354   0: 0.016367459839798   4: 0.016366706609616   1: 0.016366274343449   7: 0.016366047513431   2: 0.016366021270985   3: 0.016365902152177 

training_12746    7: 0.437629577884449   6: 0.394806652742815   8: 0.033259967089272   1: 0.019211358155581   5: 0.019189342755866   3: 0.019181534531994   9: 0.019181360275030   0: 0.019180886572551   2: 0.019180478351955   4: 0.019178841640486 

training_12748    6: 0.545125036989410   8: 0.318383584011257   5: 0.017063552395199   0: 0.017063077394122   1: 0.017062529584972   9: 0.017061400159139   4: 0.017060508900319   3: 0.017060183166162   7: 0.017060132613505   2: 0.017059994785915 

training_12751    5: 0.743842105254013   7: 0.076333664474500   6: 0.022603669053619   0: 0.022495157245707   1: 0.022469064882107   8: 0.022454062607296   9: 0.022451628913287   2: 0.022450633756044   4: 0.022450027818418   3: 0.022449985995008 

training_12752    6: 0.451351155711271   7: 0.323156997184691   3: 0.077402003980004   9: 0.021156486245997   5: 0.021156431725742   0: 0.021156057049427   1: 0.021155741284641   8: 0.021155613390474   2: 0.021154804220907   4: 0.021154709206846 

training_12753    6: 0.466404021013696   7: 0.214958320635890   1: 0.111111602844333   5: 0.100726864571955   0: 0.030401724815716   8: 0.015281835252712   3: 0.015280531230652   9: 0.015278539103542   4: 0.015278488329940   2: 0.015278072201563 

training_12754    6: 0.487404016125871   0: 0.184000948620408   3: 0.169234319082659   1: 0.043699274129417   7: 0.035258130862510   5: 0.016261389458466   8: 0.016083043614792   9: 0.016045726858484   4: 0.016006872398444   2: 0.016006278848950 

training_12755    6: 0.782763204211463   7: 0.058299409145142   0: 0.053405165284896   2: 0.015095003949981   1: 0.015076050640465   5: 0.015073878742967   3: 0.015072809455620   8: 0.015071652050380   9: 0.015071558390451   4: 0.015071268128634 

training_12757    6: 0.740242518164545   5: 0.099464897434871   0: 0.020044765145308   8: 0.020039271226566   1: 0.020037964747563   2: 0.020034339409633   7: 0.020034291755673   9: 0.020034091194736   4: 0.020033959760131   3: 0.020033901160975 

training_12758    6: 0.773338685197054   9: 0.087005488022014   8: 0.017461899812385   0: 0.017458811582587   5: 0.017456888479479   7: 0.017456479743660   1: 0.017455602789447   2: 0.017455436413290   4: 0.017455372421521   3: 0.017455335538564 

training_12759    1: 0.548794344377090   6: 0.303965017122545   5: 0.018408575308401   9: 0.018406236632371   8: 0.018404970817866   0: 0.018404904616160   4: 0.018404848170711   3: 0.018404206670853   2: 0.018403467473226   7: 0.018403428810777 

training_1276     8: 0.389021124833439   6: 0.364826217752763   7: 0.075180402679385   9: 0.047811747066894   0: 0.020535583428049   5: 0.020528043076996   1: 0.020526470381570   4: 0.020524230975970   2: 0.020523669451597   3: 0.020522510353338 

training_12760    6: 0.651013809733385   7: 0.148579705943199   0: 0.069375307729501   8: 0.045054601864962   3: 0.014464808097127   5: 0.014315935299358   4: 0.014299546004524   1: 0.014299349354700   9: 0.014298572772800   2: 0.014298363200446 

training_12761    6: 0.793634908518724   1: 0.040918611100199   3: 0.039292268945512   5: 0.037985384670769   8: 0.014695118378015   2: 0.014694880146248   0: 0.014694874103502   7: 0.014694873800098   9: 0.014694625927500   4: 0.014694454409434 

training_12762    6: 0.848391032043685   4: 0.016856553920622   5: 0.016851731700367   9: 0.016847623363401   8: 0.016845444996530   0: 0.016842599773651   1: 0.016841693089081   3: 0.016841583959977   7: 0.016841155252789   2: 0.016840581899896 

training_12763    6: 0.784895589376722   8: 0.087970874603794   0: 0.041555936789618   9: 0.012233443629969   5: 0.012228564533286   2: 0.012225390291129   4: 0.012225013848200   1: 0.012222107146153   3: 0.012221662280239   7: 0.012221417500890 

training_12767    0: 0.477585591933194   6: 0.193258645139907   4: 0.167076402324724   8: 0.049170874894332   1: 0.018863834731796   9: 0.018813380428769   5: 0.018810164075196   3: 0.018807648145455   2: 0.018806924024159   7: 0.018806534302468 

training_12768    6: 0.763022466278514   8: 0.068835394618058   3: 0.048636211523454   1: 0.045384219027663   0: 0.012506383521844   2: 0.012326859660559   5: 0.012323260018148   9: 0.012321825795551   4: 0.012321739323739   7: 0.012321640232470 

training_1277     5: 0.797335724413627   6: 0.022519523097936   3: 0.022518685631688   4: 0.022518450329653   0: 0.022518138347876   1: 0.022518089413302   7: 0.022517892308274   8: 0.022517867543139   2: 0.022517840207967   9: 0.022517788706538 

training_12770    6: 0.690080387261723   5: 0.191148901502482   9: 0.028706892506018   7: 0.013079707896300   2: 0.012939950733045   0: 0.012809425701038   1: 0.012809006863728   4: 0.012808715370525   8: 0.012808569953437   3: 0.012808442211703 

training_12771    6: 0.820716155973464   1: 0.069289011316964   0: 0.013751327941958   9: 0.013749887887949   5: 0.013749280057021   7: 0.013749195583279   4: 0.013749114962111   8: 0.013749008271416   2: 0.013748567521014   3: 0.013748450484825 

training_12772    6: 0.629057163307264   7: 0.133267631317322   0: 0.132305075125408   8: 0.029610198985062   3: 0.012643410328999   9: 0.012640097183536   5: 0.012620062007942   1: 0.012619141339048   4: 0.012618618764053   2: 0.012618601641366 

training_12774    6: 0.541127378487655   0: 0.314679898689788   9: 0.037492122078398   7: 0.015245827020418   5: 0.015244286043734   8: 0.015244097205312   3: 0.015242116748292   1: 0.015242039329742   2: 0.015241482417784   4: 0.015240751978877 

training_12775    6: 0.587683011238710   9: 0.218341427329711   2: 0.110170580011340   7: 0.011974066584930   1: 0.011972931898039   5: 0.011972317797821   0: 0.011972151271950   4: 0.011971311728102   3: 0.011971256367301   8: 0.011970945772096 

training_12778    6: 0.675479470308626   7: 0.093367769402134   0: 0.089519984193168   9: 0.071198980745839   1: 0.017003861733421   4: 0.010692222820183   5: 0.010685140944819   8: 0.010684364646114   2: 0.010684234549991   3: 0.010683970655705 

training_12780    6: 0.573493604119393   0: 0.270963598061666   1: 0.063007327914276   7: 0.013383825697222   8: 0.013193499632088   4: 0.013192230771246   5: 0.013192221598507   9: 0.013191553837379   3: 0.013191080045018   2: 0.013191058323206 

training_12783    2: 0.392259009256611   5: 0.376417558909919   7: 0.073285923319911   6: 0.022581540323741   9: 0.022577909944885   4: 0.022576941142628   0: 0.022575978092086   8: 0.022575607474128   1: 0.022575308469306   3: 0.022574223066785 

training_12785    9: 0.687524406889197   8: 0.125096284706985   6: 0.023436068980835   5: 0.023421522991338   0: 0.023420811699555   4: 0.023420503227907   7: 0.023420288159581   1: 0.023420230755484   3: 0.023419948885831   2: 0.023419933703287 

training_12786    6: 0.387119864108565   7: 0.202819497870000   2: 0.190322371935013   3: 0.090177360166670   4: 0.045476799414430   8: 0.016822109736349   0: 0.016816584984467   1: 0.016815725101358   5: 0.016814894011714   9: 0.016814792671436 

training_12787    6: 0.661820990348499   5: 0.172524795277090   7: 0.020763339673266   8: 0.020714545330722   3: 0.020698364527592   9: 0.020697093223532   4: 0.020696054018516   0: 0.020695394920036   1: 0.020694882289716   2: 0.020694540391031 

training_12788    6: 0.740633496232837   0: 0.156204230771257   5: 0.022664883041302   9: 0.011587004397082   1: 0.011492575028299   7: 0.011483865517632   8: 0.011483855669839   3: 0.011483453860614   4: 0.011483353949313   2: 0.011483281531826 

training_12789    8: 0.595935945353940   9: 0.229897769353209   6: 0.021774235684714   5: 0.021772187759684   1: 0.021771497199041   0: 0.021771072263917   4: 0.021769748756629   2: 0.021769403272727   7: 0.021769299130299   3: 0.021768841225840 

training_12790    6: 0.850411400954273   7: 0.033188783945058   0: 0.022115005354237   1: 0.013491369293557   9: 0.013471951073745   2: 0.013469709447699   5: 0.013467331093351   3: 0.013462757256803   8: 0.013461198772079   4: 0.013460492809198 

training_12791    6: 0.790009319904603   0: 0.109412892597826   5: 0.022445615726219   1: 0.011266066045715   2: 0.011152898858685   7: 0.011145366549973   9: 0.011142274165760   8: 0.011142209840685   4: 0.011141828994410   3: 0.011141527316124 

training_12795    6: 0.826438860405335   1: 0.019287363195141   0: 0.019286523545360   5: 0.019286117686912   8: 0.019284301232752   9: 0.019283622921928   4: 0.019283615775168   7: 0.019283449649972   2: 0.019283203937940   3: 0.019282941649491 

training_12796    6: 0.475332266177798   8: 0.287076491341852   1: 0.080393853244465   5: 0.022469753081068   0: 0.022458432857708   2: 0.022455622820221   7: 0.022453604828922   3: 0.022453578917752   4: 0.022453204177827   9: 0.022453192552387 

training_12797    6: 0.675065914000705   7: 0.168914402144265   1: 0.019508042675145   5: 0.019505807460623   0: 0.019505149326860   4: 0.019500893637694   2: 0.019500345570844   9: 0.019500103717834   8: 0.019499957482445   3: 0.019499383983585 

training_12799    6: 0.827948048434120   1: 0.070276240475011   0: 0.019742457729152   5: 0.011731487729902   9: 0.011723834481181   2: 0.011723159818014   4: 0.011716942749463   3: 0.011712819833397   8: 0.011712664823135   7: 0.011712343926626 

training_128      2: 0.715050408693515   6: 0.070335209625350   5: 0.026843114301710   0: 0.026834587885650   1: 0.026833079947968   4: 0.026823759338741   3: 0.026820529469924   7: 0.026819946235198   8: 0.026819797117043   9: 0.026819567384900 

training_1280     5: 0.472929014422130   6: 0.305993418166816   0: 0.074067613494567   1: 0.021007567462538   4: 0.021005141858276   2: 0.021000190157039   8: 0.021000034353949   9: 0.020999786367818   7: 0.020998748283716   3: 0.020998485433150 

training_12801    6: 0.442501849709535   0: 0.389727222015207   5: 0.020985367993046   4: 0.020979668929924   8: 0.020972435921433   9: 0.020967535709081   7: 0.020967005832244   2: 0.020966579962234   3: 0.020966217916288   1: 0.020966116011007 

training_12802    6: 0.813872474314293   8: 0.052100341354000   1: 0.042357809802977   7: 0.013111315862175   9: 0.013095346080745   4: 0.013094695128533   0: 0.013094051560405   5: 0.013093618783990   2: 0.013090400887857   3: 0.013089946225025 

training_12803    1: 0.544363935756754   6: 0.216290793680376   8: 0.056015085153856   2: 0.045973630463417   3: 0.039615795378722   7: 0.027838423796047   0: 0.026176351705298   4: 0.014578663925323   9: 0.014578535432130   5: 0.014568784708077 

training_12805    6: 0.428622788369869   9: 0.350655281319010   8: 0.027594072482308   0: 0.027593096603110   7: 0.027590415805227   1: 0.027590235701685   4: 0.027588836161340   2: 0.027588665220511   5: 0.027588437503454   3: 0.027588170833487 

training_12806    6: 0.583765304796995   1: 0.234174339590871   0: 0.089453460644537   3: 0.028285234408283   9: 0.010832948160871   8: 0.010710241762857   5: 0.010698860268314   4: 0.010693638511288   7: 0.010693024044497   2: 0.010692947811488 

training_12810    6: 0.669675819941926   0: 0.182887953978725   9: 0.018444044306450   8: 0.018432765334588   7: 0.018429408973522   5: 0.018426840788553   1: 0.018426497885653   4: 0.018425750885890   3: 0.018425605499255   2: 0.018425312405438 

training_12812    9: 0.724797515868925   6: 0.104350032685936   8: 0.021376172693612   5: 0.021354936157817   0: 0.021354130892128   4: 0.021353775888504   7: 0.021353550860842   1: 0.021353439676252   3: 0.021353229682929   2: 0.021353215593057 

training_12813    6: 0.699962864655355   7: 0.124014421820728   8: 0.022008660733512   4: 0.022004300323421   9: 0.022002893107799   3: 0.022001642243238   0: 0.022001555693278   1: 0.022001307327708   5: 0.022001305510936   2: 0.022001048584024 

training_12814    6: 0.655040793894256   8: 0.145580563655788   1: 0.058770842082885   7: 0.020137103269988   3: 0.020080439572635   9: 0.020078976985056   5: 0.020078397023700   0: 0.020077798014721   4: 0.020077680095936   2: 0.020077405405036 

training_12815    6: 0.685284846111605   0: 0.202564655683052   1: 0.037428026465982   8: 0.017643028788536   9: 0.013019723266762   5: 0.009129132685177   3: 0.008736809806980   7: 0.008731745442923   2: 0.008731063448767   4: 0.008730968300216 

training_12817    6: 0.767474779787087   8: 0.025843527671507   5: 0.025839042476780   9: 0.025836115775863   0: 0.025835468424231   4: 0.025834675504977   1: 0.025834453205001   7: 0.025834428517776   2: 0.025833999839897   3: 0.025833508796880 

training_12818    6: 0.540631686704614   0: 0.282363987344343   7: 0.072051762959354   1: 0.028209739597228   8: 0.012935147183634   9: 0.012763798098573   5: 0.012762182957826   2: 0.012761422133329   4: 0.012761253358071   3: 0.012759019663028 

training_12819    8: 0.766737047137817   9: 0.060066107133847   6: 0.021656378475311   0: 0.021653645435009   1: 0.021651224400761   5: 0.021648934539957   4: 0.021647106719203   2: 0.021646572173951   7: 0.021646565244965   3: 0.021646418739178 

training_12822    4: 0.522674731450926   5: 0.312429403059724   1: 0.038531465136019   2: 0.018145698679115   0: 0.018062330613232   6: 0.018058225413022   7: 0.018040210930218   9: 0.018022239221537   8: 0.018018129859866   3: 0.018017565636341 

training_12823    6: 0.794723885959821   1: 0.041109429387608   3: 0.039071379774448   5: 0.037760116861622   8: 0.014556180224429   2: 0.014555944348398   7: 0.014555943015674   0: 0.014555896875464   9: 0.014555691371487   4: 0.014555532181048 

training_12824    5: 0.846305544914307   1: 0.017080620664739   6: 0.017079257572456   0: 0.017077868740425   9: 0.017076871975050   3: 0.017076139073993   2: 0.017076002178210   4: 0.017075989544929   7: 0.017075860495376   8: 0.017075844840515 

training_12827    6: 0.389258929665533   9: 0.370808061654442   5: 0.127889184359815   0: 0.036178399843218   8: 0.017233763172078   1: 0.012279817976332   4: 0.011588503094216   2: 0.011588032758486   7: 0.011587932667038   3: 0.011587374808841 

training_12829    6: 0.628501457654849   5: 0.184178009883643   8: 0.081158428805694   1: 0.015168469856739   0: 0.015167850785376   9: 0.015167416720282   4: 0.015165576199072   7: 0.015164464419612   2: 0.015164188153243   3: 0.015164137521490 

training_1283     5: 0.820113078864470   4: 0.019990065072843   1: 0.019989067567818   0: 0.019987603252071   8: 0.019987522836909   6: 0.019986981690662   9: 0.019986596560205   2: 0.019986444657594   7: 0.019986339171219   3: 0.019986300326209 

training_12830    6: 0.743258534463167   0: 0.151754147504546   5: 0.024183523411837   1: 0.011610980266286   9: 0.011546193111369   8: 0.011529442440968   7: 0.011529415477647   4: 0.011529398790968   3: 0.011529194467796   2: 0.011529170065415 

training_12831    2: 0.295047789178032   5: 0.291351611715937   0: 0.273048464893859   6: 0.020084358930195   9: 0.020080425723277   4: 0.020078349467942   7: 0.020077752424339   8: 0.020077661698825   1: 0.020077626820550   3: 0.020075959147043 

training_12834    6: 0.662935382295916   7: 0.175101990058390   1: 0.020250208119901   5: 0.020248958962706   0: 0.020248505821993   4: 0.020243622857086   2: 0.020243350812513   9: 0.020243009577978   8: 0.020242775151838   3: 0.020242196341678 

training_12836    0: 0.481887122879730   6: 0.272901484266811   1: 0.089777405475738   5: 0.060681663243591   2: 0.015852943945291   3: 0.015780120182676   9: 0.015779951783738   7: 0.015779851804664   8: 0.015779818767689   4: 0.015779637650072 

training_12839    1: 0.689951679650426   5: 0.034498566002375   3: 0.034452015956916   2: 0.034451087850002   0: 0.034444761764661   6: 0.034444537800672   4: 0.034441026668380   9: 0.034439001742795   7: 0.034438839938387   8: 0.034438482625386 

training_1284     5: 0.778112386124452   4: 0.024664958763281   1: 0.024654464875483   0: 0.024653931926533   6: 0.024653410522285   8: 0.024652329735357   2: 0.024652220952363   9: 0.024652121197750   7: 0.024652120685130   3: 0.024652055217366 

training_12840    9: 0.813552528145040   6: 0.020720028957467   8: 0.020719134511019   1: 0.020716926717614   5: 0.020716704636462   0: 0.020716231328978   2: 0.020715422691810   7: 0.020714820745246   4: 0.020714420854230   3: 0.020713781412135 

training_12841    6: 0.840966168491232   0: 0.017673403435470   5: 0.017672263868076   9: 0.017671553968238   1: 0.017671167070231   8: 0.017670880223975   4: 0.017668943152737   7: 0.017668884654786   2: 0.017668417353172   3: 0.017668317782083 

training_12842    6: 0.784183441505845   0: 0.088666112363982   5: 0.038456440778703   1: 0.013082353091278   7: 0.012608352614488   2: 0.012603651516240   8: 0.012600292704490   9: 0.012600259529945   4: 0.012599742243875   3: 0.012599353651156 

training_12843    6: 0.649372170820577   0: 0.192888539365940   4: 0.019724135224280   8: 0.019720482615514   5: 0.019720081040201   3: 0.019715946354413   2: 0.019714691078685   1: 0.019714676772477   7: 0.019714655174504   9: 0.019714621553407 

training_12846    6: 0.582453205982885   9: 0.229039138624991   0: 0.060288337772187   8: 0.018322604608417   1: 0.018317017904253   5: 0.018317013607122   7: 0.018316177082611   4: 0.018315714269389   3: 0.018315408946191   2: 0.018315381201955 

training_12848    6: 0.817866007366998   0: 0.063482125910558   1: 0.051956952243645   7: 0.016595847284700   9: 0.014623050011803   3: 0.007096004496775   5: 0.007095832668470   8: 0.007094951566764   2: 0.007094619850947   4: 0.007094608599342 

training_12849    6: 0.423635401602845   2: 0.362139011722031   7: 0.085553111649048   0: 0.044971557910039   9: 0.018331342335938   1: 0.018098496492802   4: 0.012410624298554   8: 0.011629617654468   5: 0.011616383384132   3: 0.011614452950142 

training_1285     5: 0.745863452736467   7: 0.095196384558325   4: 0.019871880352138   0: 0.019868232484768   6: 0.019866979681845   1: 0.019866943815399   8: 0.019866600398922   9: 0.019866542134324   2: 0.019866523049358   3: 0.019866460788452 

training_12851    0: 0.614118886258372   5: 0.189548563756055   2: 0.072969958169116   7: 0.017646978618879   9: 0.017629775157646   6: 0.017626181332717   1: 0.017615986044059   4: 0.017615734464397   8: 0.017614378097767   3: 0.017613558100991 

training_12852    7: 0.770006663109634   0: 0.025609700592869   5: 0.025594807442316   6: 0.025576764556324   1: 0.025565047019095   9: 0.025539248403111   4: 0.025531850963686   2: 0.025526915789892   8: 0.025525151985890   3: 0.025523850137184 

training_12853    9: 0.476051305792989   5: 0.286584454683466   2: 0.078192147959705   6: 0.022744230742656   1: 0.022740766421213   0: 0.022740256084472   8: 0.022737591754676   4: 0.022737202785357   7: 0.022736031635794   3: 0.022736012139673 

training_12857    1: 0.450929642688162   6: 0.378658037514160   0: 0.043860583470343   3: 0.031879005650951   9: 0.016041753990092   8: 0.015735277906727   5: 0.015729044343254   7: 0.015724229821952   4: 0.015721683287517   2: 0.015720741326841 

training_12858    1: 0.657376833444971   0: 0.188061491307292   2: 0.034596904006711   6: 0.017143277571464   5: 0.017138093472105   4: 0.017137471360168   9: 0.017136796108768   7: 0.017136444389131   8: 0.017136408759463   3: 0.017136279579928 

training_12860    4: 0.796180360813808   5: 0.022654388885627   0: 0.022647676357680   1: 0.022646755855680   3: 0.022645295125614   6: 0.022645242186378   9: 0.022645123082376   8: 0.022645068267500   2: 0.022645058613027   7: 0.022645030812311 

training_12861    1: 0.455285944480581   6: 0.377540600288372   0: 0.042360811673323   3: 0.030835182279559   9: 0.015880689771358   8: 0.015627426777956   5: 0.015622418571273   7: 0.015618174840035   4: 0.015614763154182   2: 0.015613988163362 

training_12862    5: 0.800920941492360   8: 0.022135822542387   6: 0.022130627390560   0: 0.022122386104938   9: 0.022119434548026   7: 0.022114863776596   4: 0.022114678729190   1: 0.022114435181342   2: 0.022114026877943   3: 0.022112783356659 

training_12866    1: 0.793903498974797   5: 0.056059777622927   6: 0.018787679384359   4: 0.018754248205604   9: 0.018751021109607   3: 0.018750800488314   2: 0.018750397246299   0: 0.018747997896813   8: 0.018747781017353   7: 0.018746798053928 

training_12869    5: 0.764943694144702   4: 0.026120886040599   8: 0.026117305093240   3: 0.026117181907160   9: 0.026116963535516   2: 0.026116896925853   7: 0.026116848970077   1: 0.026116746263121   0: 0.026116745672918   6: 0.026116731446814 

training_1287     5: 0.839693951458242   6: 0.017819393797320   7: 0.017813404150617   1: 0.017812353861629   0: 0.017812235510541   9: 0.017810725108603   8: 0.017810565719864   3: 0.017809495599230   2: 0.017809059939522   4: 0.017808814854432 

training_12872    6: 0.657611797433543   0: 0.150190177639101   5: 0.079029536566552   7: 0.029231691122285   3: 0.014271193477281   2: 0.013957995271008   9: 0.013950598234796   1: 0.013947407070865   4: 0.013922508826794   8: 0.013887094357775 

training_12874    5: 0.763075647982006   0: 0.062195663531452   4: 0.021846809176880   6: 0.021840479126671   1: 0.021840435683641   8: 0.021840259331772   9: 0.021840234102710   3: 0.021840216588979   2: 0.021840140746695   7: 0.021840113729194 

training_12875    6: 0.655319924233313   0: 0.226316100714312   5: 0.015120991629056   9: 0.014753036438695   4: 0.014749581997607   8: 0.014749403018776   1: 0.014748881771245   7: 0.014747528971057   3: 0.014747279655003   2: 0.014747271570936 

training_12877    0: 0.774361514320838   5: 0.025080657680936   6: 0.025076330694275   8: 0.025071148371757   3: 0.025069819465626   9: 0.025069818448625   1: 0.025068589690894   7: 0.025067878582842   2: 0.025067188491885   4: 0.025067054252323 

training_12878    6: 0.578231551805410   3: 0.236486647663380   0: 0.074706194524587   1: 0.025119479316140   7: 0.014280543892325   5: 0.014242439374707   9: 0.014236512737123   4: 0.014233359747701   2: 0.014232392453424   8: 0.014230878485202 

training_1288     4: 0.779839352620950   5: 0.054515732244583   1: 0.020710866249077   3: 0.020707696056921   0: 0.020706696776846   6: 0.020706208366529   7: 0.020704929837566   9: 0.020703610314178   8: 0.020702652875634   2: 0.020702254657717 

training_12880    9: 0.758528003052862   5: 0.026836077822876   6: 0.026835860754946   8: 0.026833875106653   0: 0.026831263688025   1: 0.026828932527708   4: 0.026827724872214   2: 0.026827259930064   7: 0.026826199297128   3: 0.026824802947524 

training_12882    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_12883    0: 0.742139805943906   1: 0.077375437304416   2: 0.039510583967063   6: 0.020144590461556   5: 0.020143552432767   8: 0.020137601256306   4: 0.020137477241695   9: 0.020137145080031   3: 0.020137042632220   7: 0.020136763680039 

training_12885    5: 0.827381434357300   6: 0.019189316093814   9: 0.019180776133042   0: 0.019180468930296   1: 0.019179023350515   8: 0.019178701085702   4: 0.019178059395255   7: 0.019177937251863   2: 0.019177222353190   3: 0.019177061049022 

training_12886    1: 0.587710835562396   0: 0.226335775582403   2: 0.043359040139034   7: 0.020377197306934   6: 0.020376873860144   5: 0.020371989877788   8: 0.020368310681654   9: 0.020367688086303   4: 0.020367396028842   3: 0.020364892874501 

training_12887    6: 0.661811576335494   1: 0.122512923646076   3: 0.071220303561846   7: 0.064912076542956   2: 0.023554314123909   9: 0.011900163305241   0: 0.011057993467766   8: 0.011011710943862   5: 0.011010095008702   4: 0.011008843064148 

training_12888    4: 0.449713132145936   1: 0.282866258164910   2: 0.101837364516010   6: 0.023659346201926   0: 0.023657996024354   5: 0.023656669766606   9: 0.023654577917993   8: 0.023651751079323   7: 0.023651504039053   3: 0.023651400143889 

training_12889    1: 0.817493529276076   5: 0.020290973853152   4: 0.020288970467898   0: 0.020277010434034   3: 0.020276745011993   6: 0.020276325587806   2: 0.020274262022409   8: 0.020274116587300   9: 0.020274044491261   7: 0.020274022268073 

training_12890    0: 0.720381322769253   9: 0.066896878280965   1: 0.053363248637351   7: 0.037853312610533   6: 0.020274350300809   3: 0.020248141060900   4: 0.020247406706825   5: 0.020246750512490   2: 0.020246376486613   8: 0.020242212634262 

training_12891    6: 0.583977104889447   0: 0.233668929124652   8: 0.069817885702205   9: 0.016081328208782   1: 0.016076485900057   5: 0.016076260710081   2: 0.016075857559152   7: 0.016075810295959   3: 0.016075236036510   4: 0.016075101573154 

training_12893    5: 0.795464495254234   4: 0.022729882272725   8: 0.022727050298640   6: 0.022725827859811   9: 0.022725647664873   0: 0.022725534379599   2: 0.022725466275444   7: 0.022725384130196   1: 0.022725372278847   3: 0.022725339585631 

training_12897    3: 0.467524506880565   5: 0.336505998299178   4: 0.024497198195176   6: 0.024496638540912   1: 0.024496328165775   2: 0.024496127399924   0: 0.024496100763129   9: 0.024495910922340   7: 0.024495630669790   8: 0.024495560163209 

training_12898    5: 0.764856952820938   3: 0.077966779886762   0: 0.019652912032720   4: 0.019648953573769   1: 0.019645929790890   6: 0.019645896196678   7: 0.019645725122867   2: 0.019645656705396   8: 0.019645616193918   9: 0.019645577676063 

training_129      5: 0.729841572714662   6: 0.030021404426825   1: 0.030020672534028   0: 0.030020200783722   2: 0.030016118857094   3: 0.030016084589235   9: 0.030016082619535   7: 0.030016009373606   4: 0.030015934801309   8: 0.030015919299984 

training_12900    2: 0.434503421706982   0: 0.256833773549586   5: 0.104886840980126   4: 0.079516733082789   6: 0.020718011183508   8: 0.020717906143359   1: 0.020710679490490   9: 0.020708078115735   7: 0.020702495975008   3: 0.020702059772418 

training_12901    5: 0.500054798556363   6: 0.130783363623562   1: 0.123419985262409   3: 0.121043855512100   4: 0.020785002644192   0: 0.020783169870195   9: 0.020782975232858   8: 0.020782467833622   2: 0.020782233722257   7: 0.020782147742442 

training_12904    5: 0.759847141362520   4: 0.026687189456482   8: 0.026683597983588   3: 0.026683311221898   9: 0.026683246984397   2: 0.026683209977663   7: 0.026683157420652   1: 0.026683059840490   0: 0.026683058038920   6: 0.026683027713391 

training_12905    1: 0.593544735611606   0: 0.241166358650290   4: 0.048925895964457   3: 0.017552847199611   8: 0.017026263234421   9: 0.016753851900499   5: 0.016340197760112   7: 0.016249671186946   6: 0.016230244545767   2: 0.016209933946291 

training_12907    6: 0.455698689537593   0: 0.331334277225623   8: 0.091477513047340   4: 0.052863118146269   1: 0.011447343531044   9: 0.011441333063619   7: 0.011438238067373   5: 0.011436467422909   2: 0.011431541609468   3: 0.011431478348761 

training_12908    9: 0.776108057357721   6: 0.024947674036914   5: 0.024878057871516   4: 0.024871921957989   1: 0.024869929892410   8: 0.024869818415626   2: 0.024865951141243   0: 0.024864921204217   7: 0.024862331666694   3: 0.024861336455669 

training_1291     1: 0.353699636749589   6: 0.320026594896829   2: 0.152985143885887   3: 0.057366438166565   5: 0.019351639727555   4: 0.019315357972701   0: 0.019314276721681   7: 0.019314210491816   8: 0.019313949452369   9: 0.019312751935007 

training_12910    7: 0.666808593218026   2: 0.145474725014848   6: 0.023475353679332   5: 0.023471493612398   0: 0.023466571655796   1: 0.023466345215454   4: 0.023463414204698   3: 0.023458189896965   8: 0.023457706041842   9: 0.023457607460642 

training_12912    9: 0.798076802514980   5: 0.022441277889141   8: 0.022441135259327   6: 0.022439679155378   0: 0.022435229273551   4: 0.022434905561034   7: 0.022433209536985   1: 0.022433078996375   2: 0.022432860179952   3: 0.022431821633277 

training_12914    5: 0.697933592752467   9: 0.119906283114272   4: 0.022774743727021   6: 0.022769644798814   0: 0.022769505622559   8: 0.022769395214913   1: 0.022769357583026   3: 0.022769170768240   7: 0.022769166327193   2: 0.022769140091495 

training_12915    5: 0.511527552961798   4: 0.303407727126832   0: 0.023142077998974   2: 0.023133818617021   6: 0.023133562555146   8: 0.023133549141963   9: 0.023130789869580   3: 0.023130344262885   7: 0.023130329578548   1: 0.023130247887253 

training_12917    1: 0.521745068527125   0: 0.271341276426974   4: 0.137202482767340   6: 0.011408722688069   2: 0.009802813356333   3: 0.009716847621553   8: 0.009705281197404   9: 0.009700323458467   5: 0.009690282702595   7: 0.009686901254140 

training_12919    9: 0.773925073216786   5: 0.025125717256887   6: 0.025124478739710   8: 0.025123189044371   0: 0.025120526133596   1: 0.025118079038861   4: 0.025117140697111   2: 0.025116271095496   7: 0.025115432440134   3: 0.025114092337048 

training_1292     6: 0.422751936553069   1: 0.265602161911780   2: 0.211158859637346   9: 0.023644028407081   4: 0.012942573138866   8: 0.012924713266115   5: 0.012769182260139   0: 0.012747292273073   7: 0.012733325501854   3: 0.012725927050676 

training_12923    8: 0.729081280770062   6: 0.142088039483251   0: 0.016106869721524   1: 0.016105784705529   5: 0.016103877123733   9: 0.016103748172245   7: 0.016103030968426   4: 0.016102564732687   2: 0.016102465690618   3: 0.016102338631926 

training_12924    7: 0.415892192913453   6: 0.296049408949103   5: 0.154785431675980   8: 0.019042543678934   0: 0.019040540047945   4: 0.019039519117006   1: 0.019039215230560   9: 0.019037437303818   3: 0.019037164328174   2: 0.019036546755028 

training_12929    5: 0.616406866947818   6: 0.216138332396566   0: 0.020938685845593   7: 0.020936217348007   3: 0.020932784383113   9: 0.020931470823014   8: 0.020929652190120   1: 0.020929086892064   4: 0.020928596630293   2: 0.020928306543411 

training_1293     5: 0.736495224893785   4: 0.029288319008365   2: 0.029281729167741   9: 0.029279774711254   6: 0.029279353930861   1: 0.029276001451824   7: 0.029275110211489   3: 0.029275062170891   8: 0.029274781765239   0: 0.029274642688551 

training_12933    5: 0.786236157163536   1: 0.023762154410093   0: 0.023754956279983   6: 0.023753033893501   4: 0.023749553106366   2: 0.023749289839034   8: 0.023749194721657   7: 0.023748605068652   3: 0.023748549366458   9: 0.023748506150721 

training_12935    6: 0.793911841363391   5: 0.023036298353186   4: 0.022954374794456   2: 0.022892268532910   3: 0.022875161756892   8: 0.022868139209173   7: 0.022866099620302   0: 0.022865518210656   9: 0.022865348402619   1: 0.022864949756414 

training_12937    2: 0.290100342877913   6: 0.269211737399075   5: 0.171281640569481   8: 0.148724501063550   4: 0.020119037990209   0: 0.020118262109491   1: 0.020118032152865   9: 0.020109295077476   3: 0.020109083316591   7: 0.020108067443350 

training_12940    6: 0.669121577731462   9: 0.166708305038148   1: 0.039503615857068   0: 0.035016256833505   5: 0.014942948112939   2: 0.014941946313757   4: 0.014941749645456   7: 0.014941495611671   3: 0.014941342954905   8: 0.014940761901089 

training_12943    0: 0.484427448942192   6: 0.303262430717993   9: 0.062649054465388   1: 0.060283908160506   8: 0.014900176433344   5: 0.014899244390569   4: 0.014896185504801   7: 0.014893872752145   2: 0.014893851156719   3: 0.014893827476344 

training_12948    6: 0.461581505612904   8: 0.182568960476027   0: 0.126012506481994   1: 0.100304821539752   9: 0.038403189432733   5: 0.029502939646563   7: 0.015410172704833   4: 0.015406704593445   3: 0.015404685239699   2: 0.015404514272050 

training_12949    4: 0.552958393453355   6: 0.261890729085013   2: 0.023187897894044   5: 0.023173098521285   1: 0.023138538628598   0: 0.023135266647828   8: 0.023129698644502   9: 0.023129588825810   7: 0.023128734486781   3: 0.023128053812783 

training_1295     6: 0.726920920688241   0: 0.135205134378009   5: 0.017236552865775   8: 0.017235045122098   4: 0.017234838790277   1: 0.017233963259172   3: 0.017233854891189   2: 0.017233413354290   9: 0.017233202229675   7: 0.017233074421274 

training_12956    0: 0.539337439376537   1: 0.284743349111554   4: 0.042753481258272   2: 0.019072158646685   5: 0.019018022493798   6: 0.019016898581815   7: 0.019016628951937   9: 0.019015586762580   8: 0.019014269171165   3: 0.019012165645657 

training_12959    7: 0.451755367085713   6: 0.385194674849805   2: 0.037200607534738   0: 0.017980648683480   5: 0.017980611846906   1: 0.017978830987489   9: 0.017977983999605   4: 0.017977528917752   3: 0.017977158746112   8: 0.017976587348401 

training_12962    5: 0.461754476635148   8: 0.277643981217907   3: 0.108046163259327   6: 0.021805784346599   0: 0.021795058564202   1: 0.021791977159175   4: 0.021791031648238   9: 0.021790991716291   2: 0.021790411040633   7: 0.021790124412480 

training_12963    6: 0.506428055559000   2: 0.288804153866093   0: 0.063380022700334   5: 0.034776649184135   8: 0.026218129753768   1: 0.016396517270766   4: 0.016001608827433   7: 0.016000047587219   9: 0.015997775620746   3: 0.015997039630506 

training_12965    0: 0.751087856416132   9: 0.073325446042582   1: 0.033419081950219   6: 0.020329863683024   5: 0.020307908018702   2: 0.020306355142412   4: 0.020306184395441   8: 0.020305862954711   7: 0.020305794326600   3: 0.020305647070177 

training_12969    6: 0.806608103585406   1: 0.021493053927939   5: 0.021492051833546   0: 0.021488961334574   8: 0.021487615503044   2: 0.021486562322314   7: 0.021486162317261   4: 0.021485947518067   3: 0.021485791828329   9: 0.021485749829520 

training_12971    6: 0.843453475146136   1: 0.050992357848617   7: 0.026536282706479   8: 0.014760511729195   2: 0.010738027506853   0: 0.010724648323973   9: 0.010704297216186   5: 0.010698693713306   4: 0.010696899722583   3: 0.010694806086671 

training_12973    1: 0.381177483080666   4: 0.353501543766776   8: 0.081234658832405   7: 0.047691953046930   0: 0.040582273046827   3: 0.019198897197832   9: 0.019173761498304   6: 0.019150871271355   5: 0.019145818845825   2: 0.019142739413078 

training_12974    4: 0.664247928398512   0: 0.152544854701130   6: 0.022916675230889   1: 0.022909437208542   5: 0.022904918696864   7: 0.022899592525075   2: 0.022896100045111   3: 0.022894165202890   9: 0.022893318872872   8: 0.022893009118114 

training_12978    1: 0.392105855548544   5: 0.308200963636786   9: 0.174009740099600   6: 0.017958731431673   0: 0.017957631513526   8: 0.017957198628273   2: 0.017952733289511   4: 0.017952565341450   7: 0.017952377913242   3: 0.017952202597393 

training_1298     5: 0.361752362770953   3: 0.225023477790244   0: 0.222538873566319   4: 0.027241379667470   6: 0.027240965529482   8: 0.027240788379847   7: 0.027240749671495   2: 0.027240515049227   1: 0.027240485656629   9: 0.027240401918334 

training_12980    6: 0.447758069518376   0: 0.401126801832440   7: 0.018932487119043   1: 0.018885365735189   5: 0.018883907915903   9: 0.018882958182355   4: 0.018882794823442   2: 0.018882679160810   8: 0.018882583301089   3: 0.018882352411354 

training_12981    1: 0.848313391516645   5: 0.025751814711779   4: 0.016056754315716   7: 0.015879978145651   6: 0.015715502207142   8: 0.015662931370185   9: 0.015656780592548   0: 0.015655314006307   2: 0.015653888983550   3: 0.015653644150479 

training_12982    6: 0.396811698375969   7: 0.234949012109044   3: 0.188590559751711   1: 0.025667919578999   8: 0.025665450820507   0: 0.025665352175243   5: 0.025663170389263   2: 0.025662523221170   4: 0.025662448167735   9: 0.025661865410358 

training_12986    6: 0.850578807631065   0: 0.049797266894333   1: 0.012465743756517   9: 0.012454128207652   5: 0.012451814110486   8: 0.012450912995309   4: 0.012450576210847   7: 0.012450512338926   3: 0.012450225663038   2: 0.012450012191826 

training_12987    6: 0.507700321180035   3: 0.247538667339050   5: 0.060327527186942   2: 0.047469036712322   1: 0.045493037898185   0: 0.028330114601117   7: 0.015924317609056   4: 0.015741904965528   8: 0.015738033829287   9: 0.015737038678479 

training_12988    2: 0.412625962949984   3: 0.269959553778967   6: 0.153214168124356   4: 0.055970876625393   0: 0.018134582647029   5: 0.018022657674078   1: 0.018022583774958   9: 0.018017172939092   7: 0.018016254819626   8: 0.018016186666517 

training_1299     6: 0.777631938747900   0: 0.093399379837042   1: 0.051356446564854   9: 0.011096032309629   2: 0.011093724961677   3: 0.011089556145765   8: 0.011084590163974   7: 0.011083013435905   5: 0.011082992756092   4: 0.011082325077162 

training_12992    6: 0.494446837993550   1: 0.344013300193916   2: 0.036903028714076   0: 0.033388730250636   5: 0.015210587434209   7: 0.015207975191787   9: 0.015207712481916   8: 0.015207664287341   4: 0.015207292002842   3: 0.015206871449727 

training_12995    1: 0.642556930816197   6: 0.224504127550964   5: 0.016620412668653   7: 0.016618936949576   0: 0.016617739997676   8: 0.016617411101731   9: 0.016617313049550   4: 0.016615942800057   2: 0.016615898964841   3: 0.016615286100755 

training_12996    2: 0.455402307255250   1: 0.228486220334909   6: 0.119560146169276   0: 0.054772896421005   5: 0.023633957417137   8: 0.023630694462441   4: 0.023629358462292   9: 0.023628722419689   7: 0.023628505076572   3: 0.023627191981430 

training_13       5: 0.801730870215659   4: 0.047316463827807   9: 0.019188303090159   7: 0.018934969727205   1: 0.018921509769965   8: 0.018869860542504   3: 0.018831976315208   6: 0.018750713768153   0: 0.018727800924524   2: 0.018727531818815 

training_130      6: 0.454104066075422   0: 0.380168376843758   1: 0.039148845795524   7: 0.036190835047184   4: 0.015071694374044   5: 0.015071325748218   9: 0.015061553542243   8: 0.015061229564605   2: 0.015061081124637   3: 0.015060991884364 

training_1300     0: 0.475720670663502   9: 0.199882904174673   6: 0.170370530771019   3: 0.045413628817237   1: 0.018111748997395   7: 0.018102716913729   5: 0.018102317561191   8: 0.018098674480662   2: 0.018098420396694   4: 0.018098387223898 

training_13003    6: 0.501185577248948   1: 0.341324627488408   2: 0.034417510533868   0: 0.031225238558967   5: 0.015310801466574   9: 0.015310243655455   3: 0.015307603811801   8: 0.015306988088823   7: 0.015306024020849   4: 0.015305385126307 

training_13005    1: 0.459090760824121   2: 0.244006408469600   5: 0.110118442957806   0: 0.083743806529714   6: 0.017194949601795   8: 0.017194565863945   4: 0.017186238438772   3: 0.017163320415406   9: 0.017150879364143   7: 0.017150627534699 

training_13006    5: 0.778487177307247   2: 0.024613245909830   4: 0.024613067002969   6: 0.024612756632423   3: 0.024612612395609   0: 0.024612563235166   1: 0.024612331054274   9: 0.024612135758288   7: 0.024612067747067   8: 0.024612042957126 

training_13007    6: 0.690798713599881   8: 0.165952979678070   5: 0.017906923754866   0: 0.017906782666230   9: 0.017906401251065   7: 0.017905904204051   1: 0.017905869144097   4: 0.017905629667928   2: 0.017905483452425   3: 0.017905312581387 

training_13008    6: 0.799542946889413   0: 0.064747725243644   9: 0.029269599894612   8: 0.015216304297950   5: 0.015206140162528   1: 0.015204289437814   4: 0.015203743805766   2: 0.015203371287585   7: 0.015203116465673   3: 0.015202762515016 

training_1301     5: 0.761136767830809   7: 0.072447467905136   4: 0.020807069433637   6: 0.020802380158982   2: 0.020801845308622   9: 0.020801727715214   0: 0.020800858680863   1: 0.020800785955809   8: 0.020800617030224   3: 0.020800479980704 

training_13010    8: 0.766960798425199   6: 0.025901904958700   9: 0.025895186554198   5: 0.025893131125988   1: 0.025892838570875   7: 0.025892520291504   0: 0.025891553595512   4: 0.025890987175725   3: 0.025890665139846   2: 0.025890414162452 

training_13011    6: 0.803260178623421   5: 0.021868174300941   1: 0.021863547190731   0: 0.021863347679529   4: 0.021860714937261   2: 0.021857702151751   9: 0.021857298760090   3: 0.021856715265189   7: 0.021856226361939   8: 0.021856094729147 

training_13014    4: 0.711369645721578   5: 0.032097835586179   6: 0.032079312440424   1: 0.032071522329215   9: 0.032068649865529   3: 0.032065966449236   0: 0.032064446967571   8: 0.032062148330092   2: 0.032060894602932   7: 0.032059577707246 

training_13019    6: 0.870214648860820   5: 0.014425418719395   8: 0.014421854978822   4: 0.014421770315585   9: 0.014421487065860   1: 0.014420071278253   0: 0.014419795476507   7: 0.014418642310151   2: 0.014418286522149   3: 0.014418024472457 

training_13021    0: 0.464658961583754   6: 0.197632234692542   5: 0.169968212084429   3: 0.056372930422240   1: 0.027295285618628   8: 0.025220609792581   9: 0.014713279749228   4: 0.014713246383386   2: 0.014712695538878   7: 0.014712544134334 

training_13023    0: 0.528919636724535   1: 0.254085404668488   6: 0.112113192686334   7: 0.026677645618571   8: 0.013057584596032   5: 0.013052918354049   4: 0.013024114507393   2: 0.013023297966387   9: 0.013023244273249   3: 0.013022960604963 

training_13024    6: 0.693073288817044   0: 0.177286366356244   1: 0.016207280975772   5: 0.016205632376807   8: 0.016205317966996   9: 0.016204639160845   2: 0.016204517048214   3: 0.016204403053234   7: 0.016204323518891   4: 0.016204230725952 

training_13025    5: 0.539862536350077   9: 0.246514899456719   7: 0.075089129984114   2: 0.019808690493129   6: 0.019799153499549   1: 0.019798901889056   4: 0.019785548825379   0: 0.019782281184777   8: 0.019779523004421   3: 0.019779335312777 

training_13026    5: 0.777986530913171   6: 0.024674424551742   4: 0.024670139445076   1: 0.024668958336338   0: 0.024668691302374   9: 0.024666427731088   8: 0.024666341656266   3: 0.024666183470664   2: 0.024666164957992   7: 0.024666137635289 

training_13027    5: 0.631715449354581   0: 0.198930374097583   4: 0.021175928380176   6: 0.021171355713428   1: 0.021170080144519   2: 0.021169273438774   8: 0.021167879396875   7: 0.021167168338141   9: 0.021166364191484   3: 0.021166126944440 

training_1303     1: 0.304994549440167   3: 0.279000692778986   2: 0.168693537795384   9: 0.103289076361830   8: 0.035743752906038   6: 0.035603350857077   5: 0.018197343426635   0: 0.018161600931391   4: 0.018158872949348   7: 0.018157222553145 

training_13031    5: 0.715587743291405   0: 0.087494270576085   3: 0.069658527987382   4: 0.018181935238360   1: 0.018180935408734   6: 0.018180238039131   8: 0.018179205738194   9: 0.018179141137527   2: 0.018179046447907   7: 0.018178956135273 

training_13032    5: 0.708454990951753   1: 0.107945956734738   0: 0.022983333612993   4: 0.022948007533865   7: 0.022944880235361   6: 0.022944812007717   8: 0.022944545863653   9: 0.022944524409629   3: 0.022944506076684   2: 0.022944442573607 

training_13036    2: 0.586951505874828   6: 0.247594953869639   5: 0.020689493923070   1: 0.020684607569842   0: 0.020682861331196   8: 0.020682605891469   4: 0.020681004681667   9: 0.020678420309196   7: 0.020677295599480   3: 0.020677250949613 

training_13037    1: 0.792021116785042   6: 0.044214854053843   5: 0.020481135414502   4: 0.020475650249734   0: 0.020471839712713   8: 0.020468021571792   9: 0.020467307986784   2: 0.020466905043482   7: 0.020466730608755   3: 0.020466438573353 

training_13039    6: 0.706880703983329   1: 0.130443709562338   0: 0.045663559122804   7: 0.039916522397108   3: 0.022096139378006   8: 0.011006313085327   5: 0.010999010944956   4: 0.010998469651988   9: 0.010997873629184   2: 0.010997698244962 

training_13041    5: 0.486348528046931   1: 0.324283981590214   6: 0.045823723316815   2: 0.044381914479700   0: 0.016589148108487   7: 0.016514767179029   9: 0.016514647683846   4: 0.016514581942915   3: 0.016514380752392   8: 0.016514326899671 

training_13043    0: 0.645395169163689   1: 0.152553214534578   4: 0.063088031137555   7: 0.019855434737895   6: 0.019855045967097   5: 0.019854840483472   2: 0.019849953362228   8: 0.019849951507340   9: 0.019849269333087   3: 0.019849089773059 

training_13045    6: 0.677754978465119   1: 0.132605910471774   7: 0.070766544480248   2: 0.051337075619290   9: 0.011493786531821   5: 0.011236993404492   0: 0.011227782873929   3: 0.011192463318762   8: 0.011192374128155   4: 0.011192090706409 

training_13046    6: 0.619803727423811   0: 0.206962451720289   7: 0.094125805494518   1: 0.020717264323402   3: 0.011211854652296   5: 0.009450367463775   9: 0.009440700939326   8: 0.009430600677790   2: 0.009430236483719   4: 0.009426990821075 

training_13052    6: 0.693907883988311   2: 0.081171011792863   3: 0.052447503527480   0: 0.049953580839759   7: 0.035598745277203   1: 0.017387779354795   5: 0.017384143327035   4: 0.017383277841978   8: 0.017383041319481   9: 0.017383032731094 

training_13053    0: 0.512479439558245   6: 0.391543433835739   7: 0.027750960083107   8: 0.013671562451351   1: 0.009112325587727   5: 0.009089133123035   3: 0.009088950266849   9: 0.009088387248276   4: 0.009088043853195   2: 0.009087763992476 

training_13054    4: 0.532956546727742   1: 0.293428795545112   0: 0.021755497934480   6: 0.021703766807825   5: 0.021698075601676   7: 0.021695129209283   9: 0.021692268100780   8: 0.021691247176184   2: 0.021690869147753   3: 0.021687803749166 

training_13059    5: 0.499650006277832   9: 0.300763071485524   3: 0.024978148502329   2: 0.024951903700248   6: 0.024948152439598   4: 0.024942742069257   0: 0.024942603810539   1: 0.024941829075156   7: 0.024940962189266   8: 0.024940580450252 

training_1306     6: 0.793038734039596   9: 0.060664885490810   0: 0.056368167820618   2: 0.028108136328796   1: 0.015194655899801   8: 0.009344130745908   7: 0.009322375480973   3: 0.009320165031168   5: 0.009319521550542   4: 0.009319227611788 

training_13060    1: 0.568366973128699   2: 0.278699787928594   0: 0.019248794627547   6: 0.019109899611308   4: 0.019098817691740   5: 0.019096582864994   8: 0.019095763733490   9: 0.019095025485546   7: 0.019094570833440   3: 0.019093784094643 

training_13062    5: 0.500886578219111   0: 0.231404507661291   7: 0.142978724079005   9: 0.017835928590873   3: 0.017818449527549   6: 0.017817023454091   1: 0.017816347522083   8: 0.017814431320995   2: 0.017814019823417   4: 0.017813989801586 

training_13064    5: 0.768894085805942   6: 0.084796023060010   4: 0.018291616896195   8: 0.018288524383794   0: 0.018288467988705   1: 0.018288358333118   9: 0.018288328995120   7: 0.018288213164833   2: 0.018288208324506   3: 0.018288173047775 

training_13067    8: 0.432406714760473   9: 0.155589117067814   6: 0.141043686536016   1: 0.095378294087224   7: 0.080140725235526   5: 0.019102313587949   0: 0.019092775716790   2: 0.019090016430535   3: 0.019078905454691   4: 0.019077451122983 

training_13070    8: 0.415401792704737   6: 0.366894226254635   5: 0.067574692201775   7: 0.021450876030778   0: 0.021448715269636   9: 0.021447386822151   1: 0.021446406116795   4: 0.021445845275899   2: 0.021445103859815   3: 0.021444955463778 

training_13072    6: 0.425143674512542   1: 0.385069788705712   0: 0.097658082337130   7: 0.013163054444335   5: 0.013162475677572   9: 0.013160901319122   4: 0.013160874638227   8: 0.013160733794092   2: 0.013160344165545   3: 0.013160070405723 

training_13077    1: 0.708675000753165   0: 0.107220309688857   2: 0.046844311587822   6: 0.019614650552678   5: 0.019610243990920   4: 0.019607926173419   9: 0.019607550936894   8: 0.019607545075138   7: 0.019606258586615   3: 0.019606202654491 

training_13078    5: 0.785340937119574   6: 0.023858252372997   0: 0.023856511932818   9: 0.023852726360454   1: 0.023851082031057   8: 0.023849647613331   7: 0.023848836579349   4: 0.023847834539730   3: 0.023847094007019   2: 0.023847077443672 

training_1308     6: 0.663250569315137   5: 0.176336978753874   8: 0.020057803014898   4: 0.020052175349249   2: 0.020052157038927   9: 0.020052029558657   0: 0.020051394022913   1: 0.020050020028566   7: 0.020048899844783   3: 0.020047973072997 

training_13080    6: 0.736120377887080   0: 0.098570075961334   7: 0.031942135486552   3: 0.031538849132552   1: 0.026563167839655   5: 0.023983154921417   8: 0.018100966695836   4: 0.011061840878733   9: 0.011060921747181   2: 0.011058509449660 

training_13085    1: 0.802559807984579   6: 0.030642531934739   0: 0.021473049527746   5: 0.021400463812539   4: 0.020654388571820   9: 0.020654375921980   2: 0.020654119398144   8: 0.020653893593599   7: 0.020653773208236   3: 0.020653596046618 

training_13089    1: 0.500698748718714   5: 0.342964170276967   6: 0.019549969392302   0: 0.019541957648207   3: 0.019541757282296   4: 0.019540942360687   7: 0.019540810662962   9: 0.019540723416068   2: 0.019540620970068   8: 0.019540299271729 

training_13090    3: 0.418607599180106   5: 0.391783754781262   6: 0.023770985363048   8: 0.023728249083745   2: 0.023716178211589   9: 0.023702814422106   0: 0.023696578286682   1: 0.023673670747136   4: 0.023660487095188   7: 0.023659682829137 

training_13092    5: 0.732532707947837   4: 0.029721376709906   1: 0.029719484615035   6: 0.029718989380008   0: 0.029718721862281   3: 0.029717942720017   8: 0.029717756849296   7: 0.029717724680502   2: 0.029717685187855   9: 0.029717610047262 

training_13093    4: 0.637942730841871   5: 0.127268310415860   0: 0.029359975170716   3: 0.029354231063233   2: 0.029349284502383   8: 0.029345213407226   6: 0.029345141510384   7: 0.029345048152858   1: 0.029345046795712   9: 0.029345018139757 

training_13094    6: 0.579677643725165   7: 0.202745869539508   1: 0.092674695148521   0: 0.017854235350730   5: 0.017846738181163   9: 0.017841506387551   8: 0.017840819655480   4: 0.017839810132150   2: 0.017839343952376   3: 0.017839337927356 

training_13095    0: 0.541018049999086   6: 0.264648794091425   4: 0.060076660755625   9: 0.033383717391550   1: 0.016817335820759   5: 0.016813176005390   2: 0.016812208533206   7: 0.016810377111739   3: 0.016810113355279   8: 0.016809566935941 

training_13096    6: 0.842586871285106   1: 0.017490836094866   2: 0.017490727565576   3: 0.017490613871852   0: 0.017490443550904   9: 0.017490409216285   5: 0.017490256845143   7: 0.017489985777249   4: 0.017489969409164   8: 0.017489886383856 

training_13097    6: 0.424572669342658   0: 0.322029486735501   1: 0.088579635812354   7: 0.052965423555904   4: 0.018643939227663   5: 0.018643404698647   8: 0.018641737066551   9: 0.018641333378267   2: 0.018641192792282   3: 0.018641177390173 

training_13099    6: 0.488691278524816   8: 0.244009166730473   5: 0.141258715672373   0: 0.018008221626449   7: 0.018005671761283   1: 0.018005645232868   4: 0.018005552004089   3: 0.018005402948370   9: 0.018005261380222   2: 0.018005084119058 

training_13102    6: 0.474143032826803   5: 0.380697558834899   2: 0.018147113046575   4: 0.018146894744754   1: 0.018146300435594   0: 0.018145880356576   9: 0.018144771961456   3: 0.018143862676486   7: 0.018142301134981   8: 0.018142283981875 

training_13103    5: 0.585331970289120   1: 0.183598042088612   7: 0.065104220870183   6: 0.023716375935594   8: 0.023711300969988   0: 0.023710472224091   4: 0.023707376500725   9: 0.023707246801928   2: 0.023707123194910   3: 0.023705871124848 

training_13105    6: 0.335727263208031   5: 0.268609763185895   9: 0.253637468324109   0: 0.020291936802067   1: 0.020291774328827   4: 0.020288765606947   8: 0.020288708046277   2: 0.020288274697565   7: 0.020288145461770   3: 0.020287900338512 

training_1311     5: 0.439081968751642   8: 0.354726907216948   4: 0.025782945750984   9: 0.025772804027858   3: 0.025772744580928   2: 0.025772661813177   0: 0.025772650060245   1: 0.025772584130594   7: 0.025772452677208   6: 0.025772280990415 

training_13110    4: 0.733691674744954   5: 0.029595580073346   1: 0.029589286083477   3: 0.029589178019015   2: 0.029589112036857   8: 0.029589110467598   6: 0.029589087445237   0: 0.029589085124690   7: 0.029588992901671   9: 0.029588893103157 

training_13113    5: 0.723565922116463   6: 0.105718580138474   1: 0.021342399863552   4: 0.021342082974094   0: 0.021340292146053   7: 0.021339656319374   9: 0.021338369427607   8: 0.021338067206597   2: 0.021337454858559   3: 0.021337174949228 

training_13114    5: 0.739306387258890   4: 0.028969742188687   1: 0.028966587959734   6: 0.028966417733837   0: 0.028965829366159   3: 0.028965141914021   7: 0.028965076422018   8: 0.028965055076405   2: 0.028964934288829   9: 0.028964827791420 

training_13115    6: 0.622114048369769   0: 0.205010879149504   1: 0.098558984509159   3: 0.023395995127572   5: 0.008499891501023   4: 0.008491522035895   9: 0.008486346724087   2: 0.008482211865349   8: 0.008480062669397   7: 0.008480058048243 

training_13116    6: 0.739536114309725   7: 0.057081265489578   8: 0.025426874767162   3: 0.025426536306136   5: 0.025423913371154   4: 0.025421524901143   9: 0.025421364434380   2: 0.025421304710700   0: 0.025420552845288   1: 0.025420548864733 

training_13118    5: 0.778399566090785   6: 0.024690890626548   0: 0.024647835100415   3: 0.024614821739146   4: 0.024613290822505   7: 0.024606922414460   8: 0.024606913567212   9: 0.024606638478540   2: 0.024606566039472   1: 0.024606555120917 

training_13119    6: 0.753275892851764   7: 0.056433021815867   8: 0.023790680317300   3: 0.023789144064088   5: 0.023786785426649   9: 0.023785126228271   2: 0.023785104248083   1: 0.023784941389940   4: 0.023784844842553   0: 0.023784458815487 

training_1312     6: 0.811461031848179   0: 0.100933651824155   8: 0.019731597351709   1: 0.012195901064302   3: 0.009296242527802   7: 0.009281303429331   9: 0.009277027767159   2: 0.009276237909063   5: 0.009274392254982   4: 0.009272614023318 

training_13120    0: 0.723940630997104   6: 0.030689313203176   8: 0.030675958255855   7: 0.030672431712170   1: 0.030670915576640   2: 0.030670397549084   9: 0.030670374826053   3: 0.030670272792535   5: 0.030670038358457   4: 0.030669666728927 

training_13122    3: 0.504146909621435   5: 0.241010092789982   4: 0.031866805982473   0: 0.031854996272855   2: 0.031854037226179   8: 0.031853921792631   1: 0.031853786243043   7: 0.031853386937466   9: 0.031853218881461   6: 0.031852844252476 

training_13123    6: 0.816165293736113   5: 0.067152109819255   0: 0.027416624760690   7: 0.020683540256381   9: 0.011479425799565   8: 0.011452233565278   1: 0.011427526133477   2: 0.011409622295248   4: 0.011406983333595   3: 0.011406640300398 

training_13124    0: 0.659847378056199   6: 0.198682790195610   5: 0.029579747201971   1: 0.015986109112473   7: 0.015985344986829   8: 0.015984596676148   9: 0.015983710846292   4: 0.015983681056031   2: 0.015983627259245   3: 0.015983014609203 

training_13126    5: 0.419038170937618   0: 0.382473757650463   6: 0.024812669495758   3: 0.024811656787278   1: 0.024811444836235   4: 0.024811074929234   9: 0.024810452341705   2: 0.024810269492342   7: 0.024810260163195   8: 0.024810243366173 

training_13129    6: 0.472280022226494   0: 0.233807248308212   8: 0.168891870192555   7: 0.017862212486642   5: 0.017862031670437   4: 0.017859768778925   3: 0.017859423619432   9: 0.017859317289320   1: 0.017859226727916   2: 0.017858878700070 

training_1313     5: 0.528492708933265   6: 0.193590410991510   7: 0.134206819403532   1: 0.020537505434648   0: 0.020532531197595   2: 0.020532399786756   8: 0.020528214853902   9: 0.020527397180903   4: 0.020526091087029   3: 0.020525921130861 

training_13130    1: 0.385030853176267   6: 0.311022792789614   7: 0.139701337209600   0: 0.063481202969976   3: 0.032743849391209   5: 0.013636020477935   9: 0.013614913125950   8: 0.013598324814153   2: 0.013585799991192   4: 0.013584906054105 

training_13131    4: 0.745186935675835   5: 0.028316262597862   0: 0.028313528180715   1: 0.028312027113186   3: 0.028311972616987   8: 0.028311932740985   2: 0.028311924096243   6: 0.028311829647152   7: 0.028311815943635   9: 0.028311771387400 

training_13136    6: 0.539923629952335   4: 0.272865800658251   9: 0.047732955834620   8: 0.045681556957517   5: 0.015637331743086   1: 0.015635699422936   0: 0.015633678557178   3: 0.015629990683151   7: 0.015629761410838   2: 0.015629594780086 

training_13138    5: 0.725902808829908   4: 0.030463183854723   0: 0.030454943261696   8: 0.030454353450091   1: 0.030454221487979   2: 0.030454163350104   6: 0.030454125097485   7: 0.030454092466301   3: 0.030454081880545   9: 0.030454026321169 

training_13139    4: 0.663828382191855   0: 0.111895808192167   6: 0.028133868898621   1: 0.028030141017522   5: 0.028025420830038   9: 0.028022704364606   2: 0.028017408601056   8: 0.028017189148511   7: 0.028014604437232   3: 0.028014472318393 

training_1314     5: 0.826896501294346   4: 0.019240855368484   6: 0.019233022495506   1: 0.019233009439322   9: 0.019232972547998   0: 0.019232926388049   8: 0.019232748934069   3: 0.019232688076202   2: 0.019232683083049   7: 0.019232592372974 

training_13141    0: 0.524804834825834   6: 0.307229323038722   1: 0.051004925626072   5: 0.016718014076763   4: 0.016714397308411   9: 0.016706310784130   8: 0.016705765103372   2: 0.016705741308702   7: 0.016705367662799   3: 0.016705320265194 

training_13142    6: 0.611121289333129   9: 0.208296610026854   0: 0.051596749983853   5: 0.018432313006873   2: 0.018427131987274   1: 0.018425798755928   4: 0.018425782413174   7: 0.018425013234117   8: 0.018424874755603   3: 0.018424436503196 

training_13143    8: 0.760557687297662   6: 0.026613665744279   5: 0.026609500093337   9: 0.026605525851073   7: 0.026604258296122   1: 0.026602974013739   0: 0.026602958602186   4: 0.026602322070503   2: 0.026601504972100   3: 0.026599603058998 

training_13144    6: 0.677716314795882   0: 0.203911328976360   1: 0.014799219857303   8: 0.014798267455531   3: 0.014797599498566   2: 0.014795744450463   9: 0.014795606148625   5: 0.014795536843689   7: 0.014795307172068   4: 0.014795074801513 

training_13148    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_13149    6: 0.748806898215061   0: 0.053385945910331   5: 0.044649397063454   9: 0.034916010404960   2: 0.033122558537701   8: 0.017054669897950   1: 0.017034835561699   7: 0.017010541724782   4: 0.017009630846602   3: 0.017009511837458 

training_1315     5: 0.731185094912350   0: 0.100108101424669   8: 0.041589822494632   1: 0.018172906112865   6: 0.018165400677377   9: 0.018156906749957   4: 0.018156737719953   7: 0.018155467343246   2: 0.018155045730887   3: 0.018154516834063 

training_13151    1: 0.457567314150266   5: 0.187815400968585   6: 0.167083093347378   0: 0.055900665533311   4: 0.021941967285967   2: 0.021941553846100   7: 0.021939625330472   3: 0.021937702768528   9: 0.021936837559226   8: 0.021935839210168 

training_13157    0: 0.466755433623419   6: 0.446138632471762   5: 0.013156995855397   3: 0.010881617767939   8: 0.010788516055113   4: 0.010460568803424   1: 0.010456296633293   9: 0.010454110779057   7: 0.010454006360013   2: 0.010453821650583 

training_13158    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_13159    5: 0.626699141130624   6: 0.205644963365614   8: 0.020975244156505   0: 0.020957830800711   9: 0.020954964679523   7: 0.020954547885284   1: 0.020954430193646   4: 0.020953565884392   2: 0.020953398171902   3: 0.020951913731799 

training_1316     5: 0.609077789622686   6: 0.193036224769703   2: 0.074808380988184   8: 0.037656404641830   4: 0.014343848685865   0: 0.014216095635243   1: 0.014216085260432   9: 0.014215777164450   3: 0.014214717677970   7: 0.014214675553637 

training_13162    6: 0.494018962936653   5: 0.164794321695509   8: 0.147092213077563   3: 0.068468793811578   4: 0.020941474109770   9: 0.020940515520589   0: 0.020939547021063   7: 0.020939376118272   1: 0.020932757210531   2: 0.020932038498471 

training_13163    5: 0.788892941420230   6: 0.023468913666812   1: 0.023458331814713   0: 0.023456663626039   8: 0.023455437179091   2: 0.023455081607980   9: 0.023453900091670   7: 0.023453624717998   4: 0.023452594302404   3: 0.023452511573063 

training_13165    5: 0.770386974962099   3: 0.076562350426624   1: 0.019133235016647   4: 0.019133115131463   0: 0.019132870349668   6: 0.019132083655828   8: 0.019130205743213   9: 0.019130012885314   2: 0.019129621218161   7: 0.019129530610984 

training_13168    6: 0.618639147407426   9: 0.170534078803495   8: 0.108003885974834   7: 0.014778037147537   5: 0.014676389295740   0: 0.014675975042818   1: 0.014674978792685   3: 0.014672603908609   4: 0.014672491091271   2: 0.014672412535586 

training_1317     4: 0.767242609048842   5: 0.025871898509856   6: 0.025868705559059   0: 0.025861141682945   7: 0.025860406557778   1: 0.025860320467283   8: 0.025859163226673   9: 0.025859154489968   3: 0.025858606663149   2: 0.025857993794446 

training_13170    6: 0.676025511718691   8: 0.169423159765459   5: 0.019339421215424   7: 0.019317558907354   1: 0.019317221687981   0: 0.019316432108072   4: 0.019315437655559   3: 0.019315391272866   9: 0.019315128871543   2: 0.019314736797052 

training_13172    6: 0.822828861178623   5: 0.019688108201091   0: 0.019686077867855   9: 0.019685724001760   8: 0.019685659994222   7: 0.019685369514139   4: 0.019685260841592   1: 0.019685225468879   2: 0.019684961095519   3: 0.019684751836321 

training_13173    6: 0.619134312807049   5: 0.230887865432153   8: 0.018774007129386   7: 0.018761260477224   0: 0.018742103940086   1: 0.018740760266949   9: 0.018740314627669   3: 0.018739805006110   2: 0.018739800509226   4: 0.018739769804149 

training_13174    5: 0.408960497478062   8: 0.288827889501174   7: 0.162872316617465   0: 0.019914464606097   6: 0.019910243915296   4: 0.019908662895363   9: 0.019906834293240   1: 0.019903607922598   2: 0.019898103204806   3: 0.019897379565900 

training_13175    6: 0.726926497600067   3: 0.065085727315953   9: 0.053719532336246   4: 0.022074790048927   5: 0.022039850153922   1: 0.022036306092058   0: 0.022032016975116   8: 0.022028955843373   7: 0.022028172186824   2: 0.022028151447514 

training_13179    6: 0.630196083167631   0: 0.104929951846650   7: 0.094279911851142   8: 0.077939452162524   3: 0.029131891709115   5: 0.022380025253962   1: 0.010623933310240   2: 0.010256766942993   9: 0.010134679126917   4: 0.010127304628827 

training_13180    5: 0.504244234058549   6: 0.252583409664168   1: 0.070355938018983   0: 0.070000535397947   7: 0.017145935569545   9: 0.017134845446865   4: 0.017134472500689   2: 0.017133971516554   8: 0.017133329840734   3: 0.017133327985965 

training_13182    1: 0.715665897140302   2: 0.144016950078441   6: 0.017543910987744   5: 0.017542761258870   7: 0.017539394116325   4: 0.017539336719278   0: 0.017539247267221   8: 0.017537914302115   9: 0.017537493402720   3: 0.017537094726985 

training_13184    3: 0.371073264370729   9: 0.285734893858020   6: 0.171001644179760   7: 0.086239669875684   4: 0.014333444423820   8: 0.014333036427667   0: 0.014325420007362   5: 0.014322638439278   1: 0.014321223867892   2: 0.014314764549788 

training_13185    6: 0.344101710073867   0: 0.322419708776861   1: 0.150799905673782   5: 0.058161402754246   7: 0.046517918194581   4: 0.015604704340778   9: 0.015601117105654   8: 0.015600139745571   3: 0.015598676160231   2: 0.015594717174428 

training_13186    6: 0.427041592400078   4: 0.405897277476146   5: 0.020887231207007   0: 0.020885236529646   1: 0.020884529992157   9: 0.020882685108862   8: 0.020881338930485   2: 0.020881179109483   7: 0.020879640911706   3: 0.020879288334430 

training_13187    4: 0.499764502116818   6: 0.232124806705636   7: 0.107889577042963   1: 0.064985692795088   0: 0.015879395384064   5: 0.015875636798889   8: 0.015871322071912   3: 0.015870881283836   9: 0.015870142352844   2: 0.015868043447951 

training_13188    7: 0.578542699203200   1: 0.251199209669128   4: 0.021428478398438   6: 0.021293570836973   5: 0.021269910098157   0: 0.021256237191918   9: 0.021253103953018   3: 0.021252522906547   2: 0.021252440498672   8: 0.021251827243950 

training_13189    3: 0.364719368768716   1: 0.334115343299622   0: 0.164176959903894   6: 0.019576265185627   5: 0.019573195364763   9: 0.019569497090201   2: 0.019567732106649   4: 0.019567630877486   7: 0.019567549591643   8: 0.019566457811397 

training_13190    6: 0.639092886453996   7: 0.126619922604755   8: 0.095260997546014   5: 0.019862687934401   1: 0.019862365631414   4: 0.019860817881805   0: 0.019860414110684   9: 0.019860377104435   3: 0.019859790784864   2: 0.019859739947630 

training_13191    5: 0.655046855327230   3: 0.195276358639750   4: 0.018721784828577   0: 0.018708712511064   6: 0.018708404537623   1: 0.018708232171270   8: 0.018707958854994   2: 0.018707241173429   7: 0.018707229563927   9: 0.018707222392136 

training_13192    5: 0.711331095725779   7: 0.133706964305184   6: 0.019429420571493   0: 0.019374509144301   1: 0.019368517169994   4: 0.019359959522969   2: 0.019359427349890   8: 0.019357023427078   9: 0.019356916296620   3: 0.019356166486692 

training_13194    1: 0.685684118291649   4: 0.100392575548804   0: 0.040748144143846   5: 0.035314569857226   6: 0.022986040030451   9: 0.022975422433151   8: 0.022975128998985   2: 0.022974732263289   3: 0.022974645685315   7: 0.022974622747286 

training_13195    5: 0.331616263297944   8: 0.268356917943417   7: 0.224393922820669   4: 0.025111760184592   1: 0.025098414394787   0: 0.025087279080378   2: 0.025086512049988   6: 0.025085613477457   9: 0.025082150588304   3: 0.025081166162463 

training_13196    6: 0.675265041895589   5: 0.065667300884148   7: 0.062213481950357   3: 0.060584786275922   8: 0.022720662171213   0: 0.022715037157929   1: 0.022711299643301   4: 0.022708322816579   9: 0.022707361734040   2: 0.022706705470920 

training_13197    3: 0.641541391979553   6: 0.154735841977941   1: 0.054065244404238   4: 0.021429978360294   0: 0.021378888800485   5: 0.021370379710483   2: 0.021370340185157   7: 0.021369933971582   9: 0.021369581766427   8: 0.021368418843840 

training_13199    5: 0.410186871141019   6: 0.286994789790836   7: 0.161766523940998   4: 0.051332999717702   1: 0.014956713219579   0: 0.014953795388907   8: 0.014953218246592   9: 0.014952780637499   2: 0.014951313298373   3: 0.014950994618495 

training_132      9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_1320     4: 0.790058228568956   5: 0.023336242709449   0: 0.023332880136584   6: 0.023324966617967   1: 0.023324877788508   8: 0.023324708701452   3: 0.023324632445850   9: 0.023324512301751   2: 0.023324476480100   7: 0.023324474249382 

training_13200    6: 0.435649615147075   9: 0.300063877689066   3: 0.121236283859626   1: 0.042204978924548   0: 0.016809833621339   5: 0.016808791931067   2: 0.016808052942943   8: 0.016807762999691   4: 0.016805410646427   7: 0.016805392238218 

training_13201    6: 0.615791254232762   8: 0.225328158299676   0: 0.019862538570011   2: 0.019862108992839   1: 0.019861605456878   3: 0.019860420131606   7: 0.019859871296176   9: 0.019858995902900   5: 0.019858904971109   4: 0.019856142146042 

training_13203    4: 0.743333858562967   5: 0.028522259572367   0: 0.028518172527073   1: 0.028518132204250   8: 0.028518034760602   6: 0.028517970254514   3: 0.028517947826953   2: 0.028517899516846   9: 0.028517886312226   7: 0.028517838462201 

training_13204    5: 0.791025016941497   6: 0.023222816810919   2: 0.023221493539136   9: 0.023219714253118   1: 0.023218771022100   4: 0.023218770015108   3: 0.023218505230251   0: 0.023218324891165   8: 0.023218321379620   7: 0.023218265917084 

training_13205    0: 0.723244709851408   6: 0.058993834934538   9: 0.055874506723076   4: 0.053759486561759   1: 0.018024659530630   5: 0.018021845970927   2: 0.018020369639297   8: 0.018020274801811   3: 0.018020157007823   7: 0.018020154978730 

training_13206    1: 0.754746517413482   2: 0.065890421778120   6: 0.022423337699037   5: 0.022421701898148   0: 0.022421155250659   9: 0.022419764174056   8: 0.022419608409997   4: 0.022419342332230   7: 0.022419229097315   3: 0.022418921946956 

training_13210    1: 0.681696842756661   2: 0.143354242936419   0: 0.070678432146737   6: 0.015008382876652   5: 0.014878879713223   8: 0.014877218671375   7: 0.014876791288298   4: 0.014876697844880   9: 0.014876338441584   3: 0.014876173324171 

training_13211    1: 0.713669459600778   4: 0.103428118022034   6: 0.053657198460127   9: 0.018481025880453   5: 0.018466508826545   0: 0.018462291348350   7: 0.018461051179264   8: 0.018458988921358   2: 0.018458046491084   3: 0.018457311270008 

training_13212    1: 0.725137280994367   4: 0.086067446151230   6: 0.059267672775769   9: 0.018532194286326   0: 0.018502484767746   7: 0.018502086239763   5: 0.018501622015083   8: 0.018496926057774   2: 0.018496482121268   3: 0.018495804590673 

training_13214    4: 0.828598796703575   5: 0.019051156222947   6: 0.019044622782436   1: 0.019043928986777   0: 0.019043707312834   9: 0.019043702386712   8: 0.019043653858339   3: 0.019043540117581   2: 0.019043470426472   7: 0.019043421202327 

training_1322     5: 0.445538884717893   3: 0.361825507859408   4: 0.024080014418667   6: 0.024079508741214   8: 0.024079443364284   0: 0.024079425165251   7: 0.024079383299009   1: 0.024079337338895   2: 0.024079315679480   9: 0.024079179415899 

training_13223    5: 0.654023085085897   2: 0.162138949049389   6: 0.022980301941197   1: 0.022980168461605   3: 0.022980037432593   4: 0.022979867891252   0: 0.022979830628819   9: 0.022979436062426   8: 0.022979218258860   7: 0.022979105187963 

training_13224    5: 0.783641475068762   4: 0.024041103106382   6: 0.024040490465398   3: 0.024040292482766   9: 0.024039671683384   1: 0.024039623543473   2: 0.024039432579905   0: 0.024039413256540   7: 0.024039351665800   8: 0.024039146147589 

training_13225    6: 0.710531419934485   0: 0.139289682969406   1: 0.061705066886287   4: 0.012759228365598   5: 0.012624258740206   2: 0.012619898173938   3: 0.012618100672327   9: 0.012617946345467   8: 0.012617334068829   7: 0.012617063843458 

training_13230    6: 0.406510153675919   3: 0.390029876731658   0: 0.025440678477238   9: 0.025437931002260   5: 0.025431970496529   2: 0.025431781296540   8: 0.025430300110221   1: 0.025429647145524   4: 0.025429198606987   7: 0.025428462457124 

training_13231    6: 0.614329669454063   0: 0.178029112112546   3: 0.090693231445999   8: 0.016712330251107   1: 0.016708949468790   5: 0.016707785996716   2: 0.016705263826738   9: 0.016705209339830   4: 0.016704241288869   7: 0.016704206815342 

training_13232    6: 0.811687154920078   5: 0.020927979355768   4: 0.020924463016489   9: 0.020923894330444   0: 0.020923581714678   8: 0.020922870486988   7: 0.020922768403578   1: 0.020922735947554   2: 0.020922430076981   3: 0.020922121747442 

training_13238    6: 0.814208055687615   0: 0.057795470124368   4: 0.016387868389368   8: 0.016095672850456   3: 0.015962067320026   9: 0.015959280263405   1: 0.015899987275944   5: 0.015897998566759   2: 0.015897046416169   7: 0.015896553105890 

training_1324     4: 0.531313985807450   1: 0.243203155502294   5: 0.028189400308110   0: 0.028189032361019   6: 0.028188258298215   9: 0.028186542752294   2: 0.028185225009901   3: 0.028182166045190   7: 0.028181217784411   8: 0.028181016131115 

training_13242    6: 0.645675618155559   8: 0.175956362616478   1: 0.022303501267772   3: 0.022301704627999   5: 0.022297099642677   9: 0.022297086249246   0: 0.022292714154473   2: 0.022292426411618   7: 0.022291973348140   4: 0.022291513526039 

training_13243    6: 0.782829699642135   0: 0.072421786405439   8: 0.036075318094708   1: 0.033394836644174   5: 0.013173240995108   4: 0.012459858520111   9: 0.012417358998929   7: 0.012412975618861   2: 0.012407632197228   3: 0.012407292883306 

training_13244    6: 0.666681241232044   0: 0.182342667021860   8: 0.042096363479301   1: 0.041769707255106   3: 0.023325800031596   5: 0.009057623422473   7: 0.008684857448346   9: 0.008682603328462   2: 0.008679650812642   4: 0.008679485968170 

training_13245    6: 0.667154024962590   0: 0.204027395644560   8: 0.031850311093299   1: 0.013854490040368   5: 0.013852866397980   7: 0.013852722257438   9: 0.013852529745587   4: 0.013851967344490   3: 0.013851957900945   2: 0.013851734612743 

training_13247    6: 0.512977111723741   1: 0.267943170773908   8: 0.115105571199147   5: 0.032046850693955   3: 0.012035853836588   7: 0.012000698405839   0: 0.011991890083186   2: 0.011969121634456   9: 0.011968241761485   4: 0.011961489887695 

training_13251    6: 0.650088017759923   7: 0.136029051253223   1: 0.060695903830012   3: 0.059654285469724   0: 0.026997850675930   8: 0.013307644767201   5: 0.013307497026885   4: 0.013306717712372   9: 0.013306619191770   2: 0.013306412312959 

training_13255    6: 0.616647210519895   7: 0.167689999536065   1: 0.078694215805027   3: 0.019589842445853   0: 0.019566510383618   5: 0.019563753772011   8: 0.019563708476911   9: 0.019562040555080   4: 0.019561534904015   2: 0.019561183601522 

training_13256    6: 0.772204280181810   8: 0.082032256672993   9: 0.054783288930804   4: 0.013323150966782   0: 0.013017501826785   1: 0.012999005200307   5: 0.012924834882595   2: 0.012907642307320   7: 0.012906058549267   3: 0.012901980481336 

training_13258    6: 0.699252001253315   0: 0.147281377900970   8: 0.052915347807909   3: 0.023665539702732   9: 0.012828954008221   1: 0.012815008641585   4: 0.012813198265452   7: 0.012810544092139   5: 0.012809910237059   2: 0.012808118090619 

training_1326     5: 0.784072561438389   6: 0.023993775751239   1: 0.023993361128640   0: 0.023992487648422   3: 0.023991822437566   4: 0.023991445800125   8: 0.023991223923773   7: 0.023991136978471   2: 0.023991112901679   9: 0.023991071991694 

training_13261    6: 0.458647636669030   0: 0.435730658570755   8: 0.033363692437751   1: 0.025336410316415   4: 0.007890882421189   9: 0.007816008961741   7: 0.007804269376606   5: 0.007803831918942   2: 0.007803322478845   3: 0.007803286848725 

training_13262    6: 0.781251858101728   0: 0.072698458663773   5: 0.018257341411967   9: 0.018256945047911   1: 0.018256522320395   2: 0.018256362525186   8: 0.018256199523547   4: 0.018255683549444   3: 0.018255397752762   7: 0.018255231103286 

training_13263    0: 0.686962248354099   5: 0.190207267548472   6: 0.049042211343175   1: 0.010552278794596   2: 0.010541401622730   8: 0.010539372691812   9: 0.010539056919552   4: 0.010538998360273   3: 0.010538610571386   7: 0.010538553793906 

training_13265    1: 0.618764554285451   6: 0.243434594521061   9: 0.018066618157532   2: 0.017121178781087   3: 0.017115592356051   5: 0.017102555274024   0: 0.017099889636852   4: 0.017099121950329   8: 0.017098247620095   7: 0.017097647417519 

training_13266    6: 0.718055245478461   9: 0.099594196594573   8: 0.094224101245273   4: 0.012861102890469   0: 0.012570934638596   1: 0.012566875842209   5: 0.012536546519356   7: 0.012531270989922   2: 0.012531172696592   3: 0.012528553104550 

training_13269    6: 0.774660295926576   7: 0.091115013977805   8: 0.032547813288479   1: 0.014538829365203   0: 0.014527386629558   5: 0.014523888592043   9: 0.014522103022529   3: 0.014521956369006   4: 0.014521481116058   2: 0.014521231712743 

training_1327     4: 0.798100568363586   5: 0.022440905590917   0: 0.022438589521343   6: 0.022431830344681   1: 0.022431572794378   8: 0.022431452425184   3: 0.022431337218912   7: 0.022431271122447   9: 0.022431249952270   2: 0.022431222666282 

training_13270    6: 0.847190506583861   0: 0.036397886534625   1: 0.014612178181181   2: 0.014543090508574   8: 0.014542803934117   5: 0.014542792568360   7: 0.014542788862903   9: 0.014542718909208   3: 0.014542663376352   4: 0.014542570540818 

training_13271    6: 0.749000392109178   1: 0.141704393341156   8: 0.013666744482372   5: 0.013661999953500   0: 0.013661806764668   9: 0.013661004869142   7: 0.013660953720596   4: 0.013660909019885   2: 0.013660904006549   3: 0.013660891732953 

training_13272    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_13274    6: 0.570726747033883   0: 0.263405469533811   7: 0.048088001819803   5: 0.016826882102056   9: 0.016826636912488   1: 0.016825919799316   8: 0.016825452486442   4: 0.016825308017679   2: 0.016824865691661   3: 0.016824716602862 

training_1328     9: 0.479298766292453   5: 0.288197427955189   4: 0.029073235381432   0: 0.029061840549185   8: 0.029061660062080   6: 0.029061597837687   1: 0.029061432462468   7: 0.029061349101056   3: 0.029061345716718   2: 0.029061344641731 

training_13294    6: 0.650652084553634   7: 0.186869283124507   1: 0.020325644915783   9: 0.020318648218978   0: 0.020317740616501   5: 0.020311688007414   8: 0.020302609931519   4: 0.020301298423617   3: 0.020300559715455   2: 0.020300442492592 

training_133      9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_1331     2: 0.734303369731929   5: 0.029525910586664   9: 0.029522199778517   4: 0.029521817995413   1: 0.029521802189277   6: 0.029521351026397   7: 0.029521345751015   0: 0.029521165706166   8: 0.029520716793576   3: 0.029520320441047 

training_13313    6: 0.687331839428492   8: 0.145537901522611   0: 0.050513471108496   5: 0.036213623043399   9: 0.022897681408223   7: 0.011508445055390   1: 0.011500815671890   2: 0.011498802882048   4: 0.011498745276319   3: 0.011498674603131 

training_13315    6: 0.463752812193923   1: 0.360431076279460   7: 0.053363674585869   8: 0.017497498961498   0: 0.017494613472048   9: 0.017492993180186   5: 0.017491999854427   3: 0.017491792659469   2: 0.017491790702052   4: 0.017491748111068 

training_13317    6: 0.742395833964465   0: 0.028623819896568   1: 0.028623394486031   9: 0.028623131022635   8: 0.028623011849836   2: 0.028622942804111   5: 0.028622110615660   3: 0.028622090743989   7: 0.028621984121467   4: 0.028621680495237 

training_1332     0: 0.613590899126738   9: 0.235473979407915   1: 0.018886540843549   6: 0.018875907826626   7: 0.018866967014111   5: 0.018864988182296   3: 0.018862196333684   8: 0.018859797332746   2: 0.018859435687859   4: 0.018859288244476 

training_13320    6: 0.791230994276247   1: 0.077720364212425   3: 0.031948931443059   8: 0.014167001931485   0: 0.014157397320538   5: 0.014155778205457   7: 0.014155210316391   9: 0.014154880038295   4: 0.014154721843419   2: 0.014154720412684 

training_13321    6: 0.824843868744168   0: 0.042378664644055   9: 0.016612748438244   1: 0.016599524854293   5: 0.016595460581817   8: 0.016594600051633   2: 0.016594225230192   4: 0.016593819799256   3: 0.016593593275894   7: 0.016593494380449 

training_13333    6: 0.773088380401853   0: 0.069816754540147   2: 0.044352113070443   5: 0.016109787714972   1: 0.016108492565680   8: 0.016105832954387   9: 0.016105588711683   7: 0.016104611413598   4: 0.016104431704739   3: 0.016104006922499 

training_13336    0: 0.561542084692810   5: 0.193913902014877   4: 0.030575953753126   6: 0.030569232597808   3: 0.030567690371367   1: 0.030567555253821   8: 0.030566305934073   9: 0.030566261655911   7: 0.030565510658745   2: 0.030565503067462 

training_1335     6: 0.360683378865992   5: 0.249447653079744   4: 0.212174578551357   7: 0.047661606733888   2: 0.044226329363673   1: 0.017166420110155   0: 0.017163071442367   9: 0.017160418635517   8: 0.017158292818311   3: 0.017158250398997 

training_13380    6: 0.598189665211514   0: 0.192747322784417   5: 0.080758155275336   9: 0.018330564964365   1: 0.018330149891232   8: 0.018329319815927   4: 0.018329037085422   7: 0.018328917714621   3: 0.018328569905492   2: 0.018328297351675 

training_13382    6: 0.562155363665127   5: 0.160805974688287   0: 0.148734557221093   9: 0.018330719404812   1: 0.018330094167842   8: 0.018328994911239   7: 0.018328900973296   4: 0.018328841479335   3: 0.018328336984063   2: 0.018328216504906 

training_1339     5: 0.506864088389838   4: 0.220829694883455   6: 0.114374467548134   8: 0.048532175784044   9: 0.018237269052885   0: 0.018236535437451   1: 0.018234416424681   7: 0.018231037616983   2: 0.018230254147885   3: 0.018230060714645 

training_13393    1: 0.648031872670864   6: 0.135045555654111   5: 0.060161800707148   0: 0.022408736628227   3: 0.022394484314868   9: 0.022393278547026   8: 0.022392254023950   4: 0.022391080039543   7: 0.022390767760821   2: 0.022390169653443 

training_13398    0: 0.741195317809569   8: 0.028765616519950   5: 0.028758110406444   6: 0.028757479387758   1: 0.028756557366497   7: 0.028754277909855   9: 0.028753780394811   3: 0.028753507260575   4: 0.028752837667683   2: 0.028752515276858 

training_134      5: 0.817855382734865   1: 0.020247398426013   6: 0.020244514092779   0: 0.020244311299426   3: 0.020237058478834   4: 0.020235293249831   8: 0.020234768787912   9: 0.020234657855429   2: 0.020234243857094   7: 0.020232371217815 

training_1340     0: 0.666959081912614   5: 0.189063387672194   1: 0.018054318650326   6: 0.018015720801727   3: 0.017986864046017   9: 0.017985739371486   4: 0.017984485845010   7: 0.017983523937496   2: 0.017983523900135   8: 0.017983353862994 

training_13404    0: 0.833974742744403   6: 0.018453300453772   8: 0.018450794323442   9: 0.018447999456409   1: 0.018446837402093   5: 0.018446647612907   7: 0.018445116235652   2: 0.018445013431259   4: 0.018444809747928   3: 0.018444738592136 

training_1341     5: 0.786803557008738   2: 0.023689019682443   4: 0.023688943290624   6: 0.023688804747020   3: 0.023688499864689   8: 0.023688379036838   1: 0.023688280059682   9: 0.023688246554237   0: 0.023688178217727   7: 0.023688091538003 

training_1342     5: 0.756383716962011   4: 0.027069004036116   3: 0.027068928075930   1: 0.027068434804137   0: 0.027068401791432   2: 0.027068401072738   6: 0.027068300004801   8: 0.027068282524797   7: 0.027068275568077   9: 0.027068255159961 

training_1343     9: 0.558183943273111   2: 0.185100313925442   6: 0.113493296422446   7: 0.037498729050824   8: 0.017632146483521   5: 0.017622648832974   0: 0.017619527391033   1: 0.017617771845223   4: 0.017617348089416   3: 0.017614274686010 

training_13435    1: 0.746666885775579   5: 0.028174217051995   4: 0.028151179457848   6: 0.028147783831725   0: 0.028146213971480   3: 0.028143665571976   9: 0.028142953254057   8: 0.028142565054879   7: 0.028142312397051   2: 0.028142223633411 

training_1344     5: 0.696957859749733   6: 0.115378644232073   4: 0.023461451184050   0: 0.023458078197492   3: 0.023457577042315   2: 0.023457405200978   1: 0.023457355531402   8: 0.023457280546910   9: 0.023457218172530   7: 0.023457130142517 

training_1345     5: 0.698485983335662   7: 0.099098294531939   0: 0.025338558564325   6: 0.025311887954683   9: 0.025303933325981   8: 0.025293698262393   4: 0.025292289811542   3: 0.025292044635593   2: 0.025291703512678   1: 0.025291606065205 

training_13458    6: 0.791382090489366   0: 0.074787725843527   1: 0.037584988808086   5: 0.025655918889757   4: 0.011806884232438   7: 0.011756890128134   8: 0.011756628805653   9: 0.011756411512512   2: 0.011756230697899   3: 0.011756230592628 

training_13462    6: 0.748367963699941   0: 0.119649238509471   8: 0.044739039052071   1: 0.014157849885420   4: 0.013294103173355   7: 0.012085565664256   2: 0.011939310990494   9: 0.011930671215535   5: 0.011919382301339   3: 0.011916875508117 

training_13468    6: 0.702756606828957   5: 0.103491713266743   0: 0.024233553356587   4: 0.024226341413914   9: 0.024219974813819   8: 0.024216601479665   7: 0.024214631302511   1: 0.024214408306373   2: 0.024213253856728   3: 0.024212915374702 

training_1347     6: 0.442148033164041   5: 0.406969603898766   4: 0.018870671418614   2: 0.018860968994295   0: 0.018859403397256   1: 0.018858875596367   8: 0.018858366611491   7: 0.018858276432059   9: 0.018858080277448   3: 0.018857720209662 

training_13471    0: 0.384021352963042   6: 0.369789086276825   9: 0.108865517917601   5: 0.019630241127485   4: 0.019623082746628   1: 0.019614772910004   7: 0.019614381489804   8: 0.019614159890555   3: 0.019613806688222   2: 0.019613597989833 

training_13482    6: 0.799336473661676   5: 0.022300123168957   0: 0.022296684856344   4: 0.022296137938245   8: 0.022295960277470   9: 0.022295938728810   7: 0.022295256900445   1: 0.022294698702395   2: 0.022294499277239   3: 0.022294226488419 

training_135      1: 0.774050979025679   6: 0.044632222997392   5: 0.033793923195728   4: 0.021200388051196   9: 0.021092951721205   8: 0.021074143498981   0: 0.021040746884620   2: 0.021040355912283   7: 0.021037304415299   3: 0.021036984297618 

training_1350     5: 0.600780339446046   6: 0.198098931499139   2: 0.049712868139908   4: 0.048009907366951   9: 0.017235937949361   0: 0.017233182209981   1: 0.017232419778065   7: 0.017232192662667   8: 0.017232170915338   3: 0.017232050032545 

training_13507    6: 0.402908902126628   0: 0.261924892432140   5: 0.169733195541547   1: 0.063437992177871   3: 0.017003548013081   8: 0.016999520296624   4: 0.016998189047514   9: 0.016998029852766   7: 0.016997877313244   2: 0.016997853198586 

training_1351     5: 0.768554223740183   4: 0.025720788004974   6: 0.025716132404646   0: 0.025715713275077   9: 0.025715649658957   8: 0.025715625376344   3: 0.025715543413334   2: 0.025715478143624   1: 0.025715425597626   7: 0.025715420385235 

training_13512    6: 0.760858377764229   0: 0.026590007384586   1: 0.026571366356716   7: 0.026570884671184   8: 0.026569828032801   9: 0.026568079009944   5: 0.026568038338316   3: 0.026567846514747   2: 0.026567793904603   4: 0.026567778022875 

training_13524    6: 0.724026206819526   7: 0.072228762763567   1: 0.062270282263763   0: 0.020212661872433   8: 0.020211949308706   9: 0.020210899251278   5: 0.020210651225954   2: 0.020209636647063   3: 0.020209485450196   4: 0.020209464397514 

training_13530    6: 0.762779545869190   8: 0.080272870720483   9: 0.050931183398895   1: 0.015147222205755   0: 0.015146696099466   7: 0.015146073239803   5: 0.015145939775621   4: 0.015143717040000   3: 0.015143466078209   2: 0.015143285572579 

training_13531    6: 0.619297542007945   0: 0.246268818965002   9: 0.067925286619992   7: 0.014626143675778   1: 0.008671142803979   8: 0.008643035082678   5: 0.008642246028087   3: 0.008642125359883   4: 0.008641875271598   2: 0.008641784185060 

training_13532    1: 0.585605335166808   2: 0.276420822655546   6: 0.017276173474630   0: 0.017263827418395   5: 0.017253129629421   4: 0.017237261132798   7: 0.017236973891958   3: 0.017235723181571   9: 0.017235557864022   8: 0.017235195584852 

training_13539    6: 0.719771660457488   5: 0.082689694260588   7: 0.066752820384844   0: 0.018684423301383   9: 0.018683795045463   4: 0.018683740807337   1: 0.018683722336683   2: 0.018683537704761   8: 0.018683486436126   3: 0.018683119265326 

training_1354     1: 0.730395954815537   9: 0.121026947925910   0: 0.019009820772522   5: 0.018517937462379   4: 0.018511739655170   8: 0.018509378570552   6: 0.018509317549037   7: 0.018506530555278   2: 0.018506501537625   3: 0.018505871155989 

training_13542    6: 0.791204999617555   1: 0.077717518538367   3: 0.031977769912746   8: 0.014167003288693   0: 0.014157397674267   5: 0.014155778320315   7: 0.014155210369638   9: 0.014154880038690   4: 0.014154721837866   2: 0.014154720401863 

training_13543    6: 0.824867696898100   0: 0.042354512070171   9: 0.016613029543063   1: 0.016599566763898   5: 0.016595462430049   8: 0.016594599811770   2: 0.016594225138249   4: 0.016593819749842   3: 0.016593593233146   7: 0.016593494361710 

training_13544    6: 0.463835603377367   1: 0.360348309648560   7: 0.053363649584160   8: 0.017497499144496   0: 0.017494614001998   9: 0.017492992960712   5: 0.017491999834108   3: 0.017491792646020   2: 0.017491790694828   4: 0.017491748107753 

training_1355     4: 0.738864090972790   5: 0.029021416397230   8: 0.029014512702414   3: 0.029014426036508   0: 0.029014401241741   9: 0.029014349907193   2: 0.029014292588845   1: 0.029014212857108   7: 0.029014154240545   6: 0.029014143055626 

training_13552    9: 0.787227168803157   6: 0.046359573956443   3: 0.020838318686876   8: 0.020800545214175   2: 0.020799627806625   5: 0.020797812801677   0: 0.020794904858453   1: 0.020794631185003   4: 0.020793972376376   7: 0.020793444311215 

training_13559    6: 0.825881240147791   8: 0.042195495363834   5: 0.016491976385783   0: 0.016490912328491   9: 0.016490265591023   1: 0.016490258888816   7: 0.016490146022874   4: 0.016489964642079   3: 0.016489947998911   2: 0.016489792630398 

training_1356     6: 0.747739383717801   0: 0.068841664634613   4: 0.048209212892192   5: 0.043178437763781   1: 0.020419901398505   8: 0.019366944780637   7: 0.019216437435779   3: 0.011725190349412   2: 0.010651853894086   9: 0.010650973133194 

training_1359     5: 0.768375828365154   2: 0.059617096791981   8: 0.049981715949480   1: 0.017433623523680   0: 0.017432930330040   6: 0.017432781485186   9: 0.017431784531443   4: 0.017431451766296   7: 0.017431437540383   3: 0.017431349716357 

training_136      6: 0.414324841242537   8: 0.297319748675600   0: 0.145277904372816   5: 0.031021014017824   7: 0.026392159695568   1: 0.017970692045446   9: 0.017353281616908   3: 0.016802017804553   4: 0.016772993701952   2: 0.016765346826795 

training_1360     5: 0.539669895225078   3: 0.259005643248021   0: 0.065792215211957   1: 0.019372744207227   6: 0.019371346704652   4: 0.019358238859220   2: 0.019357932954908   9: 0.019357522351237   7: 0.019357333782719   8: 0.019357127454981 

training_1361     6: 0.748157002914260   9: 0.136372207283299   5: 0.026161981640665   0: 0.012773782006569   8: 0.012756302375838   1: 0.012756110967404   4: 0.012755961044535   7: 0.012755698723231   2: 0.012755498501635   3: 0.012755454542564 

training_13611    2: 0.374390899070099   6: 0.251460747439102   3: 0.218564948284528   4: 0.052502259627572   1: 0.017189363940630   8: 0.017179806920355   0: 0.017179782104102   5: 0.017178130233422   9: 0.017177382308914   7: 0.017176680071277 

training_13615    4: 0.671308375717737   1: 0.136258348196181   5: 0.024063019276954   8: 0.024053413515343   9: 0.024053042256252   0: 0.024052812683338   7: 0.024052798557317   3: 0.024052777343259   2: 0.024052745605368   6: 0.024052666848251 

training_1363     5: 0.819271053216195   6: 0.020082106744755   0: 0.020081227781160   8: 0.020081102694855   9: 0.020081081262323   1: 0.020080890658395   4: 0.020080890120949   3: 0.020080819049772   7: 0.020080489781792   2: 0.020080338689804 

training_13633    9: 0.561760313231960   6: 0.279478006658159   1: 0.031345387798951   0: 0.028663204941537   8: 0.028014709014102   5: 0.014159442873829   3: 0.014149417480514   4: 0.014143449963066   7: 0.014143305705477   2: 0.014142762332406 

training_1364     4: 0.802136709701712   5: 0.021992669464444   8: 0.021983911207530   3: 0.021983882343161   9: 0.021983870608355   0: 0.021983863217376   6: 0.021983810838332   2: 0.021983803597591   7: 0.021983748775461   1: 0.021983730246037 

training_13649    6: 0.587548239982280   1: 0.192142151200472   2: 0.115194920714223   0: 0.038374559502687   5: 0.011191776303831   7: 0.011112137989643   9: 0.011109460090112   8: 0.011109081072289   4: 0.011108849002180   3: 0.011108824142282 

training_13656    5: 0.509446562426342   0: 0.285746158137144   7: 0.058019205772150   6: 0.036592170322145   8: 0.034973435772980   9: 0.015052228385876   1: 0.015044212263238   4: 0.015043078867415   2: 0.015041746939141   3: 0.015041201113569 

training_1366     5: 0.627683903654241   1: 0.160903108108381   9: 0.053345996921026   0: 0.043075287400122   8: 0.036950748410266   4: 0.015609789169572   6: 0.015609087554182   2: 0.015607399706074   7: 0.015607395792000   3: 0.015607283284136 

training_13660    6: 0.569903096479417   7: 0.149792941180478   2: 0.116090517888989   5: 0.023461674843042   0: 0.023459845382737   9: 0.023459299800014   8: 0.023458730947701   1: 0.023458486059793   3: 0.023458234698673   4: 0.023457172719156 

training_1367     5: 0.842985267966327   4: 0.017448745472529   6: 0.017447504980852   1: 0.017446526209937   0: 0.017446066561902   3: 0.017445382685440   2: 0.017445225815924   9: 0.017445213414680   8: 0.017445036004414   7: 0.017445030887994 

training_13688    6: 0.690661491964675   0: 0.080105470636041   8: 0.054690301296923   1: 0.049491112481248   7: 0.020911510286547   2: 0.020829284299936   5: 0.020828234833768   4: 0.020827611920203   9: 0.020827595056336   3: 0.020827387224322 

training_1369     6: 0.795819582475016   0: 0.078675003963559   9: 0.020971407579513   5: 0.014937409576629   8: 0.014937382788135   1: 0.014934098565089   4: 0.014933189597806   3: 0.014932739769170   7: 0.014930558954765   2: 0.014928626730319 

training_13690    5: 0.408008162527281   6: 0.407783683196367   9: 0.023029894913777   1: 0.023026551143429   0: 0.023026494685211   8: 0.023026279439741   4: 0.023025129978435   7: 0.023025110894313   2: 0.023024358577765   3: 0.023024334643679 

training_13694    7: 0.781164791443947   0: 0.024352098502823   5: 0.024321708580255   2: 0.024319635782325   6: 0.024310454109038   4: 0.024309879838040   1: 0.024308748775092   3: 0.024304408675892   8: 0.024304161417019   9: 0.024304112875570 

training_13695    3: 0.436342534237438   5: 0.253823612613894   4: 0.038746168634660   2: 0.038727507888322   8: 0.038727411157370   7: 0.038726976967114   9: 0.038726622303416   0: 0.038726592779503   1: 0.038726341078984   6: 0.038726232339299 

training_13702    9: 0.457349666191062   1: 0.231248445352926   6: 0.136647123097844   8: 0.072751794994383   4: 0.028660787328826   2: 0.014672199038909   5: 0.014669239137671   0: 0.014669022187074   3: 0.014668925530168   7: 0.014662797141136 

training_13704    3: 0.536446021465183   5: 0.259185811485612   0: 0.025550831689344   1: 0.025550446029930   4: 0.025546598743393   6: 0.025546356499791   2: 0.025545296521687   9: 0.025543480010493   7: 0.025542800920456   8: 0.025542356634111 

training_13708    5: 0.775539320312512   6: 0.024961242460049   9: 0.024943482900716   8: 0.024939517317535   0: 0.024939437362824   7: 0.024938156009047   1: 0.024936067940933   4: 0.024935375663230   2: 0.024933745150047   3: 0.024933654883107 

training_13709    5: 0.467356330444185   2: 0.297409855008279   3: 0.079250493851092   6: 0.022310835788710   0: 0.022286487288747   1: 0.022282402174111   9: 0.022278798113121   8: 0.022276355381333   7: 0.022274592215225   4: 0.022273849735198 

training_13710    5: 0.761490250405942   6: 0.026503759900648   0: 0.026502932685327   4: 0.026502477914945   1: 0.026502000732695   2: 0.026499941977346   3: 0.026499874328131   8: 0.026499708433567   9: 0.026499676128199   7: 0.026499377493200 

training_13711    5: 0.663946014419164   0: 0.137348064532159   7: 0.058830828256297   1: 0.019995321257986   9: 0.019987900109319   6: 0.019984954361230   3: 0.019979611162713   8: 0.019976281973213   2: 0.019975608272134   4: 0.019975415655784 

training_13714    5: 0.792284957133301   9: 0.023087736181706   6: 0.023087237622064   1: 0.023082779333444   0: 0.023079214800462   2: 0.023076648981360   4: 0.023076037082249   7: 0.023075615936132   8: 0.023075211880888   3: 0.023074561048395 

training_13715    5: 0.574247006044891   0: 0.156177644879906   1: 0.140560814459203   6: 0.018432205064768   4: 0.018431896610918   8: 0.018431437592722   7: 0.018430260756606   9: 0.018429953165445   2: 0.018429773560227   3: 0.018429007865314 

training_13717    5: 0.605054646196747   3: 0.229673713250619   4: 0.020660801712125   6: 0.020659443598093   8: 0.020658813362678   0: 0.020658750032934   9: 0.020658652553611   1: 0.020658552201451   7: 0.020658328188995   2: 0.020658298902747 

training_1372     6: 0.605087109354544   0: 0.174281858275764   7: 0.073834777774401   2: 0.043452088541406   9: 0.017226824430916   5: 0.017224731969843   4: 0.017224003750665   1: 0.017223847548442   8: 0.017222710588126   3: 0.017222047765894 

training_13721    6: 0.540731290674349   5: 0.325502555640326   0: 0.016749339572679   8: 0.016734485582921   1: 0.016716131030718   4: 0.016715426502259   7: 0.016713544991779   9: 0.016712942611062   2: 0.016712337015240   3: 0.016711946378665 

training_13729    6: 0.820705768787085   0: 0.054758778877941   5: 0.015572215711925   1: 0.015571447554885   8: 0.015568934331755   2: 0.015565464509383   9: 0.015565346477804   7: 0.015564602132680   3: 0.015563740040244   4: 0.015563701576299 

training_13735    5: 0.730166969033005   8: 0.116311526308728   7: 0.039930672092665   6: 0.016229773854766   1: 0.016227912549197   0: 0.016227586556519   4: 0.016227028284678   9: 0.016226796502693   2: 0.016226084725454   3: 0.016225650092295 

training_13738    6: 0.792406884136926   7: 0.078517927436178   8: 0.026463525728207   1: 0.024478971529655   9: 0.019439886516814   0: 0.011907757359690   3: 0.011714032311333   5: 0.011691802057974   4: 0.011690426264611   2: 0.011688786658613 

training_13739    9: 0.730184373427787   6: 0.101777508816263   8: 0.021022592422230   1: 0.021004949163909   3: 0.021004117319890   5: 0.021002751817072   0: 0.021001653572454   4: 0.021001002454878   2: 0.021000686659280   7: 0.021000364346237 

training_13744    6: 0.379619267841499   7: 0.290900736493713   0: 0.178999025519031   9: 0.021499693638246   5: 0.021498825109264   1: 0.021498064464112   2: 0.021496518804922   3: 0.021496028609445   8: 0.021495922454257   4: 0.021495917065510 

training_1375     4: 0.792954851819141   5: 0.023013391526080   3: 0.023004392991002   8: 0.023004040627519   0: 0.023004027956345   6: 0.023003926112459   9: 0.023003880937185   2: 0.023003836933852   7: 0.023003833744735   1: 0.023003817351682 

training_13753    6: 0.388204993404399   2: 0.386192310436336   1: 0.091311885945070   5: 0.019194509503712   9: 0.019183798065722   0: 0.019183585772656   4: 0.019182568780229   3: 0.019182328117948   7: 0.019182021504623   8: 0.019181998469306 

training_13757    4: 0.384102107725992   6: 0.343955909814978   9: 0.110728320961247   1: 0.040574623705185   8: 0.029294546848707   2: 0.028484972358387   7: 0.015784920654593   0: 0.015734043136264   5: 0.015676504962980   3: 0.015664049831668 

training_1377     6: 0.809220634005681   2: 0.045521135516889   1: 0.044418942808939   7: 0.023352307466079   8: 0.012917878512721   3: 0.012917776060697   5: 0.012915504956707   9: 0.012912394843772   4: 0.012911825560271   0: 0.012911600268245 

training_13775    0: 0.630711607293788   1: 0.158320225574372   6: 0.026383920897382   5: 0.026377401222410   2: 0.026373739077249   8: 0.026373110621875   7: 0.026366205508230   4: 0.026365371032738   9: 0.026364400244059   3: 0.026364018527895 

training_1378     5: 0.621503190290598   6: 0.192364509327083   1: 0.023269536912544   0: 0.023266729325910   3: 0.023266691557934   2: 0.023266427790072   4: 0.023266244659076   9: 0.023265679361294   7: 0.023265593332031   8: 0.023265397443459 

training_13787    1: 0.690562626810080   7: 0.068032231979903   4: 0.058173649718605   6: 0.026184910959219   5: 0.026178986512784   0: 0.026176517276532   9: 0.026174274214030   8: 0.026172817228330   2: 0.026172724157867   3: 0.026171261142650 

training_1379     1: 0.505634458474312   5: 0.314655534656837   6: 0.053524383009106   2: 0.018037959414017   4: 0.018028480984042   8: 0.018026134361639   0: 0.018025017810608   9: 0.018023940445128   3: 0.018022252945420   7: 0.018021837898892 

training_13790    0: 0.830522616196691   5: 0.032205869654837   6: 0.017268927989185   1: 0.017202114020023   2: 0.017172920885115   8: 0.017169690067147   7: 0.017127961649898   4: 0.017110221468424   9: 0.017110088823887   3: 0.017109589244793 

training_13791    6: 0.446970129743954   5: 0.374876292334213   9: 0.022272320457705   1: 0.022269828815846   0: 0.022269827054919   8: 0.022269451678272   4: 0.022268411400894   7: 0.022268365750141   2: 0.022267688667123   3: 0.022267684096932 

training_13795    6: 0.797366515103027   0: 0.022516105805578   1: 0.022515537074729   7: 0.022515534336921   5: 0.022514861010212   8: 0.022514612736793   4: 0.022514311544562   9: 0.022514278298861   2: 0.022514215285932   3: 0.022514028803384 

training_138      4: 0.789261674348848   8: 0.023458192725006   6: 0.023427864937024   7: 0.023421254268878   5: 0.023413069057003   0: 0.023410087053874   1: 0.023405498494583   9: 0.023404187426270   2: 0.023399248506032   3: 0.023398923182483 

training_1381     5: 0.757276253772519   1: 0.026971585085177   4: 0.026971579411561   0: 0.026970644451845   6: 0.026970486488713   2: 0.026967960713314   8: 0.026967947418281   3: 0.026967856265430   9: 0.026967851797285   7: 0.026967834595875 

training_1382     5: 0.777745905895562   6: 0.024696243303434   8: 0.024695565613320   9: 0.024695345868279   0: 0.024694917552818   3: 0.024694746898966   7: 0.024694399859564   4: 0.024694396657091   1: 0.024694373488152   2: 0.024694104862815 

training_13831    6: 0.344124336449549   2: 0.270364177823014   0: 0.158225392600441   1: 0.032475993946020   7: 0.032469106217051   9: 0.032468534648016   5: 0.032468144389699   8: 0.032468133353365   3: 0.032468109522585   4: 0.032468071050260 

training_13834    6: 0.788116061995219   0: 0.062589260092784   4: 0.018677944593513   8: 0.018669112632008   5: 0.018668908600961   3: 0.018656977195556   2: 0.018655527852031   9: 0.018655420763803   1: 0.018655401198370   7: 0.018655385075754 

training_13836    0: 0.443173323115658   6: 0.336155387792098   1: 0.027585965318599   9: 0.027585328390290   7: 0.027583925776585   8: 0.027583666518742   5: 0.027583477171101   2: 0.027583317125182   3: 0.027582862440680   4: 0.027582746351064 

training_1384     5: 0.711455353156515   4: 0.032066938725009   6: 0.032060000997621   1: 0.032059973455608   3: 0.032059830568817   2: 0.032059699984814   7: 0.032059659821212   0: 0.032059583661541   8: 0.032059559786544   9: 0.032059399842319 

training_13842    6: 0.553638458936800   0: 0.229347056019542   1: 0.027129914755781   9: 0.027127851992324   2: 0.027127674894298   5: 0.027126279226085   7: 0.027126037739602   8: 0.027125846861020   3: 0.027125512245564   4: 0.027125367328985 

training_13849    0: 0.729788397722834   6: 0.030036042045492   9: 0.030024802771528   2: 0.030023984128366   1: 0.030023412996227   5: 0.030021127878667   8: 0.030020849674064   7: 0.030020684403824   3: 0.030020391230568   4: 0.030020307148430 

training_1385     6: 0.777565640322366   1: 0.098030210093297   0: 0.015554661390223   7: 0.015551255099525   8: 0.015550013929988   9: 0.015549903839257   5: 0.015549886185287   4: 0.015549617154910   2: 0.015549460853145   3: 0.015549351132003 

training_13852    6: 0.648208529835073   8: 0.168918669050744   1: 0.067366479315425   7: 0.016511112529508   5: 0.016503114886123   9: 0.016501109805652   0: 0.016500242715752   2: 0.016497128133021   3: 0.016496888621384   4: 0.016496725107318 

training_13854    4: 0.487014010865856   5: 0.322235777199956   6: 0.084455156040369   3: 0.015257062075544   9: 0.015183487932666   0: 0.015173726921353   8: 0.015173676875768   7: 0.015172197605484   1: 0.015168111657646   2: 0.015166792825358 

training_13856    8: 0.579956438984889   6: 0.168218500360880   1: 0.132923015052325   5: 0.016992083254638   0: 0.016990767932199   4: 0.016984713190290   7: 0.016984433317860   9: 0.016983771645804   3: 0.016983353023836   2: 0.016982923237278 

training_13869    6: 0.545134067093316   0: 0.323409624059265   9: 0.029447738771145   1: 0.014573484838435   5: 0.014572882631871   7: 0.014572532866120   8: 0.014572484430204   4: 0.014572417713313   3: 0.014572384126081   2: 0.014572383470251 

training_1387     6: 0.796456408262278   9: 0.048672582563291   0: 0.046279049865915   8: 0.027613924789474   4: 0.013506029568802   7: 0.013501469524958   1: 0.013495623269129   5: 0.013493488748450   3: 0.013492661288139   2: 0.013488762119564 

training_13870    9: 0.530904765029985   7: 0.196782059196181   4: 0.104087917210563   5: 0.049432427432997   6: 0.019824918284258   1: 0.019799149764189   0: 0.019796229118806   2: 0.019792955800975   3: 0.019792177887834   8: 0.019787400274213 

training_13874    2: 0.372186116308218   6: 0.285608593358286   1: 0.164708790910171   4: 0.046662810205502   8: 0.046028966646168   0: 0.017014674066634   5: 0.016955758276774   3: 0.016946178141673   9: 0.016944375213706   7: 0.016943736872868 

training_13877    6: 0.578622434974202   1: 0.170883261150781   4: 0.107726043235870   5: 0.020451415101590   7: 0.020389245224282   0: 0.020388377362414   8: 0.020385231014194   2: 0.020384968273836   9: 0.020384520815112   3: 0.020384502847720 

training_1388     6: 0.820825671142273   9: 0.051602433006807   1: 0.028802729945184   5: 0.014132696304336   0: 0.014126798414443   8: 0.014109113527071   3: 0.014101342577642   7: 0.014099897531613   4: 0.014099766536283   2: 0.014099551014347 

training_13889    6: 0.555828375129673   0: 0.235838410557329   1: 0.026044640976166   8: 0.026042218989651   9: 0.026041595582697   2: 0.026041364477112   5: 0.026041359416282   7: 0.026040796843246   3: 0.026040643807935   4: 0.026040594219909 

training_13890    5: 0.830037358089466   4: 0.046289279529135   3: 0.015481023663743   1: 0.015456855752310   6: 0.015456699995728   0: 0.015456616784332   8: 0.015455707574971   2: 0.015455604317240   7: 0.015455559526613   9: 0.015455294766461 

training_139      5: 0.571920825264998   2: 0.226877827513537   6: 0.025151346968326   4: 0.025150739050873   1: 0.025150522329338   0: 0.025150148812786   3: 0.025149898046713   9: 0.025149626374692   8: 0.025149574793097   7: 0.025149490845640 

training_13900    6: 0.374760865842966   5: 0.321717507711451   7: 0.157178687265946   4: 0.020908104536311   1: 0.020906676741917   0: 0.020906638771786   9: 0.020906443486574   2: 0.020905289202663   8: 0.020905181856401   3: 0.020904604583985 

training_13903    6: 0.533172555794045   0: 0.330336493273925   2: 0.040608709371472   7: 0.022977881182607   8: 0.012185179726470   5: 0.012144871510171   1: 0.012144078684856   9: 0.012143770467306   4: 0.012143325814216   3: 0.012143134174931 

training_13904    0: 0.785535777381432   1: 0.076341338438386   5: 0.037029682138034   7: 0.023524667392722   9: 0.012953939419667   6: 0.012930537921274   4: 0.012921712562930   8: 0.012921119138836   2: 0.012920956845283   3: 0.012920268761435 

training_13908    6: 0.730739594308094   0: 0.113736400106839   1: 0.067503578006395   9: 0.024656486169449   7: 0.010570429426931   3: 0.010559529104170   8: 0.010559205412351   5: 0.010558880250880   4: 0.010558005382236   2: 0.010557891832655 

training_1391     5: 0.536967483303692   6: 0.183700220888792   8: 0.159314823682517   4: 0.017155906275434   0: 0.017145189978283   1: 0.017144187550925   9: 0.017143760579634   7: 0.017143063710171   2: 0.017142721861984   3: 0.017142642168569 

training_13915    6: 0.769894285515748   0: 0.087346296602668   1: 0.017850135256700   5: 0.017845872003115   7: 0.017845449667138   9: 0.017844049620688   4: 0.017843885755161   8: 0.017843793299007   2: 0.017843168521404   3: 0.017843063758371 

training_13919    0: 0.768762065593286   5: 0.025700487643131   6: 0.025698379900798   8: 0.025693864638451   9: 0.025693091731115   3: 0.025691705251492   1: 0.025690962776830   7: 0.025690607875707   2: 0.025689571773869   4: 0.025689262815320 

training_1393     6: 0.717351769645799   8: 0.094406950962537   2: 0.043044141056782   5: 0.042337285397446   0: 0.017259516405581   1: 0.017134957662893   9: 0.017124574230300   3: 0.017113619457269   4: 0.017113606391662   7: 0.017113578789732 

training_1394     6: 0.657243700310865   5: 0.157568394495738   0: 0.023154895145661   8: 0.023151554977610   1: 0.023150275856023   7: 0.023146965744875   9: 0.023146439998738   4: 0.023146087294233   2: 0.023145862396401   3: 0.023145823779856 

training_13946    6: 0.536032463397895   0: 0.335422860447821   1: 0.040834942001997   9: 0.012535473696522   5: 0.012530034435205   8: 0.012529449063995   7: 0.012528921406845   2: 0.012528717382790   4: 0.012528571154501   3: 0.012528567012430 

training_13949    0: 0.503574756890186   6: 0.366589604887368   1: 0.043600774431299   7: 0.022325186015653   9: 0.010682703031847   8: 0.010654480636058   5: 0.010643737499081   2: 0.010643038365643   4: 0.010642884752205   3: 0.010642833490661 

training_1395     6: 0.809221053382385   7: 0.021199703862338   0: 0.021199292563047   5: 0.021198320758161   8: 0.021197643344839   1: 0.021197073139955   3: 0.021196864063973   9: 0.021196714015278   4: 0.021196708902529   2: 0.021196625967495 

training_13950    0: 0.472779863130039   6: 0.345331169857985   1: 0.050692039693383   8: 0.018743326443908   5: 0.018743056983381   7: 0.018742216273878   2: 0.018742199293354   9: 0.018742180728837   3: 0.018742008104000   4: 0.018741939491236 

training_13958    6: 0.737946656199427   9: 0.095774223551049   1: 0.048496107735928   0: 0.026791759708061   2: 0.022983894319267   7: 0.013641226580518   5: 0.013604931994257   3: 0.013591618635129   8: 0.013584903575253   4: 0.013584677701110 

training_1396     6: 0.521533089034803   3: 0.283245271327885   8: 0.024408222156351   0: 0.024403015486364   7: 0.024402804233605   2: 0.024402283344678   1: 0.024401708296946   9: 0.024401350776389   4: 0.024401288774530   5: 0.024400966568450 

training_13963    6: 0.743944883081314   8: 0.091749550472050   3: 0.052799204624660   0: 0.039536566916761   1: 0.012002399394865   9: 0.011995125446797   5: 0.011994271783516   7: 0.011993210865839   4: 0.011992431397589   2: 0.011992356016608 

training_13966    6: 0.425965009423366   1: 0.302865072196629   2: 0.120943368893408   9: 0.068908378945888   3: 0.030126893490047   0: 0.010433640574881   5: 0.010192083950658   4: 0.010190210001831   8: 0.010188215310107   7: 0.010187127213183 

training_1398     6: 0.621231787020418   8: 0.128588395958300   0: 0.077281800161463   1: 0.042598003510137   2: 0.039265623992037   5: 0.018236235380509   9: 0.018199828291997   4: 0.018199679590498   7: 0.018199374726519   3: 0.018199271368121 

training_13988    6: 0.479358678674586   0: 0.354225947787775   1: 0.050250344330480   8: 0.016596004471899   5: 0.016595732249634   9: 0.016595611569079   7: 0.016594504475537   2: 0.016594472879428   4: 0.016594407798076   3: 0.016594295763506 

training_1399     6: 0.783248255753375   1: 0.064913835936143   0: 0.042289065227419   9: 0.015687803483343   2: 0.015665640432151   5: 0.015651304303687   8: 0.015642676530686   7: 0.015637293571641   4: 0.015634206316309   3: 0.015629918445246 

training_13994    8: 0.848112591128561   6: 0.016883438312395   9: 0.016879596906802   0: 0.016877524933507   1: 0.016875624927372   5: 0.016875290659555   7: 0.016874823540644   4: 0.016873865106289   2: 0.016873679930943   3: 0.016873564553933 

training_14       5: 0.771381425420675   4: 0.025405339705037   8: 0.025402021679885   6: 0.025401918435113   9: 0.025401706010580   2: 0.025401569062169   0: 0.025401561676991   3: 0.025401518728966   7: 0.025401488579080   1: 0.025401450701505 

training_140      4: 0.547350427265899   1: 0.133163041924215   0: 0.106171878199912   7: 0.080654716194443   6: 0.022128154105218   5: 0.022111275281341   2: 0.022106323077550   9: 0.022105785625668   8: 0.022104515134778   3: 0.022103883190975 

training_14012    6: 0.627359996468923   0: 0.185095743334081   2: 0.061364677844245   1: 0.018027451154882   8: 0.018027353343069   9: 0.018025427145434   5: 0.018025418526816   7: 0.018024796019394   4: 0.018024587368344   3: 0.018024548794813 

training_14028    0: 0.534234122814244   5: 0.248383525368882   8: 0.076779989510654   1: 0.020146655467073   6: 0.020081568104876   2: 0.020075333457779   4: 0.020075001754883   3: 0.020074992430533   9: 0.020074535865487   7: 0.020074275225589 

training_14034    0: 0.503850829590461   1: 0.257636357088916   8: 0.029816426748313   6: 0.029816148246123   5: 0.029814267504629   7: 0.029813855175107   2: 0.029813117740916   4: 0.029813105171722   3: 0.029812959936280   9: 0.029812932797534 

training_1404     5: 0.738853621514009   4: 0.029021383979773   3: 0.029015787994825   8: 0.029015745674430   2: 0.029015708497596   1: 0.029015630717607   7: 0.029015626725204   0: 0.029015572145444   9: 0.029015524233518   6: 0.029015398517594 

training_1405     6: 0.843131582067478   0: 0.038808047268557   1: 0.021668007999374   3: 0.021578385640826   5: 0.012494554030667   7: 0.012471258325460   4: 0.012462519772813   8: 0.012462187315790   9: 0.012461756508871   2: 0.012461701070165 

training_14055    6: 0.346691545052936   1: 0.335498068201415   0: 0.214264965842371   4: 0.014797763456266   8: 0.014792245389759   5: 0.014791897193770   9: 0.014791302160675   2: 0.014790939239024   7: 0.014790711789848   3: 0.014790561673936 

training_1406     6: 0.775358373374318   0: 0.067808590191010   9: 0.054195805476783   1: 0.014672877702179   5: 0.014661012143934   7: 0.014660950197413   8: 0.014660860795455   4: 0.014660565939963   3: 0.014660483623072   2: 0.014660480555873 

training_14069    5: 0.750280813434914   6: 0.027748451027677   0: 0.027747247608196   4: 0.027747102429817   1: 0.027746506999926   2: 0.027746006281888   9: 0.027745994945456   8: 0.027745991478440   7: 0.027745959814676   3: 0.027745925979011 

training_1407     6: 0.722858872906301   5: 0.077032557744419   1: 0.046271791689395   3: 0.044159839411303   9: 0.036998955544539   0: 0.014547252440046   7: 0.014535784035952   8: 0.014532054292167   4: 0.014531649718092   2: 0.014531242217786 

training_1409     1: 0.532344655169940   0: 0.283281105917831   2: 0.043542271274710   6: 0.020133301338203   5: 0.020120116738496   4: 0.020117724910065   9: 0.020116537363607   8: 0.020115084296058   7: 0.020114618258804   3: 0.020114584732288 

training_14091    5: 0.736404789961097   4: 0.029291241262262   8: 0.029288355685082   9: 0.029288056241375   0: 0.029287987725593   1: 0.029287951219688   3: 0.029287951015180   6: 0.029287928777617   2: 0.029287896489896   7: 0.029287841622211 

training_14093    9: 0.473622624831508   5: 0.283551929474903   4: 0.030359744478249   0: 0.030352434598921   3: 0.030352429834715   6: 0.030352369042713   8: 0.030352205343964   2: 0.030352182542674   1: 0.030352097509344   7: 0.030351982343008 

training_14099    1: 0.823880007071933   5: 0.019571533002521   0: 0.019570175033017   6: 0.019569573997839   4: 0.019568522304572   9: 0.019568233652951   8: 0.019568048340799   2: 0.019567979177737   7: 0.019567975042177   3: 0.019567952376456 

training_14103    4: 0.577520146585175   0: 0.212698069973594   5: 0.026232412859072   1: 0.026222583646519   6: 0.026221772373850   3: 0.026221670729881   2: 0.026221218869678   8: 0.026221126710107   9: 0.026220523618036   7: 0.026220474634088 

training_14109    6: 0.848569981508549   0: 0.034510004101734   9: 0.023522638015273   5: 0.013576763326032   7: 0.013520535831069   8: 0.013286310477542   1: 0.013278908697811   4: 0.013247667927557   3: 0.013244061132902   2: 0.013243128981530 

training_1412     1: 0.552263325517975   2: 0.207144932558782   4: 0.101425828819772   6: 0.019895550774024   5: 0.019889379930600   0: 0.019878964793832   8: 0.019876055834628   7: 0.019875555627321   3: 0.019875238073181   9: 0.019875168069885 

training_14126    6: 0.791701588042355   0: 0.092271719143981   1: 0.014715562915805   3: 0.014514584938562   7: 0.014476030786565   9: 0.014471011098465   5: 0.014466908892359   8: 0.014463468225873   4: 0.014459740016994   2: 0.014459385939042 

training_14131    1: 0.746315257494631   6: 0.063185748128098   8: 0.060291124655527   5: 0.018602885936866   0: 0.018602204764809   7: 0.018600826634403   4: 0.018600810152845   9: 0.018600538834303   2: 0.018600524306483   3: 0.018600079092036 

training_1414     1: 0.510514035437386   6: 0.332223998915282   0: 0.065995458008017   5: 0.013048105261469   4: 0.013038488266378   2: 0.013036205554567   7: 0.013036104858073   9: 0.013035936586443   8: 0.013035836680432   3: 0.013035830431951 

training_14146    6: 0.771252676334279   5: 0.025417745114261   0: 0.025416913788475   1: 0.025416703981957   9: 0.025416513357680   7: 0.025416459247000   8: 0.025416044023999   4: 0.025415701846966   2: 0.025415696654742   3: 0.025415545650641 

training_14150    8: 0.704139416128337   6: 0.032879703752068   5: 0.032875944844019   0: 0.032873036610262   1: 0.032872764941083   9: 0.032872467095607   3: 0.032872324611005   4: 0.032871641485242   7: 0.032871522332114   2: 0.032871178200265 

training_14154    1: 0.477321066622984   5: 0.321129921636097   0: 0.062789282111615   6: 0.019825262476481   4: 0.019823567730307   2: 0.019822543871536   7: 0.019822256409656   9: 0.019822250113362   3: 0.019821989482281   8: 0.019821859545682 

training_14156    5: 0.631359847998500   1: 0.127928964208339   4: 0.091257748284666   6: 0.021356454770485   0: 0.021355358269730   8: 0.021349568180818   9: 0.021349097979276   7: 0.021347851410229   2: 0.021347626176217   3: 0.021347482721741 

training_14166    5: 0.394678525341921   3: 0.317527639066158   0: 0.117894355731185   6: 0.024272370505319   4: 0.024272235847157   8: 0.024271100146495   1: 0.024270971001585   2: 0.024270964176675   7: 0.024270952144668   9: 0.024270886038838 

training_14168    5: 0.379290224220056   3: 0.300350215518983   6: 0.148978406102188   4: 0.024485954839087   8: 0.024482725186001   0: 0.024482689668884   1: 0.024482548639680   2: 0.024482464159159   7: 0.024482430398439   9: 0.024482341267524 

training_14177    5: 0.800257676599078   6: 0.022208023135740   1: 0.022199908418482   0: 0.022191611359078   3: 0.022191366963669   2: 0.022191008291311   8: 0.022190556826104   4: 0.022190149897408   7: 0.022189998657240   9: 0.022189699851889 

training_14178    8: 0.805312012727402   0: 0.050328661251495   1: 0.018062015599524   5: 0.018050530170211   6: 0.018046256813550   7: 0.018044016957234   9: 0.018040219531822   3: 0.018038968496180   2: 0.018038770275171   4: 0.018038548177412 

training_14180    5: 0.658519371699700   6: 0.120021484246971   7: 0.068466622719267   8: 0.021857415534546   4: 0.021856922370387   0: 0.021856716857516   1: 0.021855814281740   9: 0.021855472554240   2: 0.021855295980190   3: 0.021854883755444 

training_14182    0: 0.740261865186280   5: 0.028889268941109   6: 0.028861115795597   1: 0.028859689976788   3: 0.028856491573847   4: 0.028854815315010   2: 0.028854684875714   8: 0.028854239154787   9: 0.028854006716073   7: 0.028853822464795 

training_14199    1: 0.393153666072264   6: 0.369023735430875   0: 0.099444548520670   9: 0.076573959782752   5: 0.010302497301734   8: 0.010300579794627   4: 0.010300305939790   7: 0.010300275843322   3: 0.010300239113823   2: 0.010300192200143 

training_142      5: 0.439472386678467   2: 0.352195960611744   4: 0.026045230405290   6: 0.026043859857688   1: 0.026042772050684   9: 0.026041439127983   0: 0.026040490838274   8: 0.026039528663212   7: 0.026039299793487   3: 0.026039031973172 

training_1420     5: 0.777108789685419   3: 0.024766325959634   4: 0.024765944658464   6: 0.024765671755121   8: 0.024765667780549   0: 0.024765606909196   1: 0.024765539854569   2: 0.024765530610945   7: 0.024765504799961   9: 0.024765417986142 

training_14201    0: 0.759838102277506   6: 0.074037184472740   8: 0.047778639828850   1: 0.016913400295853   5: 0.016911350750208   2: 0.016907119543358   4: 0.016904199301501   7: 0.016903667777585   9: 0.016903370636871   3: 0.016902965115528 

training_14207    6: 0.673960446442342   9: 0.201072143942051   7: 0.015622897255209   0: 0.015622537013530   8: 0.015622379242921   5: 0.015621492385879   1: 0.015619950585348   4: 0.015619644615300   3: 0.015619391536065   2: 0.015619116981356 

training_1421     0: 0.395761982471132   6: 0.257871540436291   9: 0.189166354755954   1: 0.061044129135435   4: 0.024843684948510   3: 0.018351885066663   8: 0.017583464369310   5: 0.011806753853484   7: 0.011786361306375   2: 0.011783843656846 

training_14211    6: 0.727918535208199   8: 0.090271040345753   3: 0.069617762232782   0: 0.038433281325419   1: 0.012300721348654   9: 0.012293619513160   5: 0.012292535169084   7: 0.012291424468480   4: 0.012290584249524   2: 0.012290496138945 

training_14212    6: 0.597220465963578   8: 0.226521134317200   0: 0.060205084910510   1: 0.034436261542257   3: 0.013612316414302   5: 0.013605817858464   4: 0.013600852675324   9: 0.013599804873425   7: 0.013599269493269   2: 0.013598991951672 

training_14214    6: 0.472724276630436   0: 0.298726648318508   8: 0.028588229752478   2: 0.028567903703592   1: 0.028566941272322   9: 0.028565739056874   7: 0.028565522732336   3: 0.028565072825629   5: 0.028565050042690   4: 0.028564615665134 

training_14220    6: 0.760196270814929   0: 0.114457888050719   1: 0.028847475221657   9: 0.023243169381833   3: 0.021869214242154   4: 0.010285547391916   7: 0.010276236571644   5: 0.010275210312427   8: 0.010274751434871   2: 0.010274236577850 

training_1425     5: 0.587005108951791   4: 0.252441167778591   1: 0.020073775889299   6: 0.020071435687542   0: 0.020071263632342   8: 0.020068568009180   9: 0.020067827232560   2: 0.020067246493605   3: 0.020066947343634   7: 0.020066658981455 

training_14263    1: 0.553525705456809   9: 0.293759075290628   5: 0.019114289733461   6: 0.019095555274724   4: 0.019089280362941   0: 0.019085403855011   3: 0.019084315980157   8: 0.019082561989407   2: 0.019082145353499   7: 0.019081666703362 

training_1427     0: 0.502199087443963   6: 0.297782244947459   9: 0.083302498731859   3: 0.016758654253875   8: 0.016698490233694   1: 0.016658051294629   5: 0.016656104401766   7: 0.016648926684737   2: 0.016648510265779   4: 0.016647431742238 

training_14270    6: 0.533704007621742   0: 0.319349610241732   8: 0.018376039468184   7: 0.018370998148348   1: 0.018367312545372   2: 0.018366895453794   5: 0.018366713863909   9: 0.018366436204945   3: 0.018366157433241   4: 0.018365829018732 

training_1428     4: 0.495592869749945   5: 0.353611154252099   6: 0.018932099728656   0: 0.018915669275192   7: 0.018869359549318   1: 0.018820154629372   8: 0.018818572811796   3: 0.018814169825710   9: 0.018814067382721   2: 0.018811882795191 

training_14282    5: 0.554651425599028   7: 0.185535123641318   2: 0.075049543595374   8: 0.070210103274163   9: 0.019095287860616   6: 0.019094508276753   1: 0.019092493798706   0: 0.019092070562469   3: 0.019089844487242   4: 0.019089598904332 

training_14285    4: 0.765408265712541   5: 0.026070909093537   0: 0.026069171586858   1: 0.026066289890132   6: 0.026066229716504   9: 0.026064512215710   7: 0.026064001364441   3: 0.026063664592941   8: 0.026063502205687   2: 0.026063453621648 

training_1429     5: 0.433418899039861   2: 0.203396433736134   6: 0.175906171234885   9: 0.062494237375732   1: 0.020800997529828   0: 0.020800808674590   4: 0.020797522252915   8: 0.020795031439797   3: 0.020794972570197   7: 0.020794926146061 

training_14293    6: 0.495685753831717   0: 0.214522073867217   5: 0.135062337906370   3: 0.060872766983938   1: 0.015730635539118   9: 0.015628320432756   8: 0.015625170364227   4: 0.015624560599986   7: 0.015624265042273   2: 0.015624115432398 

training_14297    6: 0.346139462187017   0: 0.303717250984942   7: 0.163791334021021   8: 0.055859440418059   2: 0.053090904754986   5: 0.015481652967266   9: 0.015481214434413   1: 0.015480872904329   4: 0.015479145987292   3: 0.015478721340676 

training_14298    1: 0.539920904519450   4: 0.204987635015376   3: 0.085349444603783   0: 0.046117974754020   6: 0.037544585428699   5: 0.017960176411577   8: 0.017032289510693   2: 0.017029936821660   9: 0.017028770060840   7: 0.017028282873902 

training_143      5: 0.774483705180041   6: 0.025058143767723   4: 0.025057851602425   3: 0.025057491530630   0: 0.025057245721956   9: 0.025057204017301   1: 0.025057186344854   2: 0.025057165966667   8: 0.025057007625469   7: 0.025056998242935 

training_14300    5: 0.790067058760683   4: 0.023330615580343   6: 0.023325650116823   8: 0.023325516615039   3: 0.023325286722343   2: 0.023325210551695   9: 0.023325205233490   7: 0.023325190540379   0: 0.023325185331246   1: 0.023325080547959 

training_14310    0: 0.615784025692394   6: 0.206179565836700   1: 0.094700379144725   3: 0.011996196116904   4: 0.011899436918871   8: 0.011892873673943   5: 0.011889017548477   9: 0.011886909447762   7: 0.011886008439378   2: 0.011885587180846 

training_14313    6: 0.417768559501667   0: 0.386398593913374   1: 0.058627321918466   7: 0.040342023490540   5: 0.016148494738248   8: 0.016146132020264   9: 0.016143392235399   4: 0.016142249574029   3: 0.016141713278503   2: 0.016141519329511 

training_14314    1: 0.427076374571905   0: 0.330957567894210   6: 0.096641433021724   5: 0.020775206165598   9: 0.020766316039147   4: 0.020761409299757   2: 0.020758102344493   3: 0.020754980164513   8: 0.020754751653690   7: 0.020753858844963 

training_14315    2: 0.538262677724403   5: 0.198724347949816   4: 0.105468926194861   6: 0.038848527385584   0: 0.019821893454385   8: 0.019790807980870   1: 0.019775019838549   9: 0.019773875135924   3: 0.019768742159462   7: 0.019765182176146 

training_14316    5: 0.385084244844211   3: 0.307571244529160   6: 0.141395388905013   4: 0.023709543233364   8: 0.023706726629215   0: 0.023706696066688   7: 0.023706619267523   1: 0.023706618824150   2: 0.023706515420826   9: 0.023706402279849 

training_14324    6: 0.458482357128790   5: 0.305162628193361   1: 0.124268406438254   4: 0.029602932600750   0: 0.013792530787776   3: 0.013740482181139   8: 0.013738261417321   9: 0.013737767801440   2: 0.013737510327193   7: 0.013737123123977 

training_1433     5: 0.538541334804703   1: 0.233350688143327   7: 0.088047759241129   4: 0.020011916009348   6: 0.020011546884039   0: 0.020007750116093   9: 0.020007475762936   8: 0.020007424408758   3: 0.020007081222913   2: 0.020007023406754 

training_1434     2: 0.353104505928664   5: 0.326688919616758   6: 0.197296986345712   1: 0.020475279448214   0: 0.017256434273356   8: 0.017209868268611   7: 0.017038000763029   9: 0.016979187678089   4: 0.016975576948920   3: 0.016975240728648 

training_14340    6: 0.726134886748935   0: 0.160632749723609   5: 0.025141186737736   9: 0.012607267994901   2: 0.012593535599461   1: 0.012580913838141   4: 0.012578255357936   7: 0.012577570936624   8: 0.012577321359670   3: 0.012576311702988 

training_1435     4: 0.693003012699672   5: 0.034120216290574   9: 0.034110987784455   3: 0.034109622219952   8: 0.034109585944289   2: 0.034109462792675   7: 0.034109344704727   0: 0.034109340666655   1: 0.034109246111650   6: 0.034109180785351 

training_14354    6: 0.709621984071693   0: 0.117137301058443   1: 0.040886373602481   2: 0.040462715842504   5: 0.015317691155247   9: 0.015315596621414   4: 0.015314652816156   8: 0.015314634120613   3: 0.015314579344774   7: 0.015314471366675 

training_1436     6: 0.531199254463358   0: 0.268422263946809   9: 0.025071288719497   1: 0.025044366081083   7: 0.025044303921856   2: 0.025043846644513   5: 0.025043738775507   4: 0.025043703188829   3: 0.025043634707888   8: 0.025043599550660 

training_14360    8: 0.839775084025006   6: 0.017810353168418   5: 0.017806800870305   0: 0.017803390584882   7: 0.017801337560389   3: 0.017800760936908   1: 0.017800759959758   9: 0.017800669417476   2: 0.017800588633574   4: 0.017800254843286 

training_14376    1: 0.714041452297500   2: 0.031779538955263   0: 0.031775098605808   6: 0.031773504578535   5: 0.031772818081798   4: 0.031772434663785   9: 0.031771631468475   7: 0.031771417625758   8: 0.031771082532349   3: 0.031771021190729 

training_1438     5: 0.721142210971009   0: 0.113697958944573   1: 0.020666732431411   4: 0.020646841684677   6: 0.020644404552653   8: 0.020640594608791   9: 0.020640444914358   2: 0.020640359379204   7: 0.020640231013550   3: 0.020640221499774 

training_14388    5: 0.728749826718184   4: 0.030143701970531   0: 0.030139161921720   6: 0.030138859007613   9: 0.030138347560343   2: 0.030138247643001   8: 0.030138174546413   3: 0.030137941635202   7: 0.030137875236459   1: 0.030137863760534 

training_14389    9: 0.477531794846405   8: 0.252528621377827   6: 0.160418783421016   1: 0.015770347638813   3: 0.015650367070173   0: 0.015620979417061   5: 0.015620673589212   2: 0.015620088465443   7: 0.015619354295079   4: 0.015618989878971 

training_14393    5: 0.763673687714586   8: 0.070645742853197   6: 0.020729590220541   0: 0.020709826208633   9: 0.020708098358760   1: 0.020707578053959   4: 0.020706764418722   2: 0.020706445515373   7: 0.020706260144486   3: 0.020706006511742 

training_14394    0: 0.808616309263247   1: 0.021270552432857   6: 0.021266263357290   2: 0.021265669497301   5: 0.021264747673638   4: 0.021264102834764   8: 0.021263797561703   9: 0.021263078958829   7: 0.021262848335907   3: 0.021262630084463 

training_14395    6: 0.523052390113477   5: 0.184008756125535   9: 0.118772733794788   3: 0.081081658213363   0: 0.015518881878301   7: 0.015518371193295   8: 0.015518328265654   2: 0.015511799311366   1: 0.015511378887595   4: 0.015505702216626 

training_144      6: 0.665199679006508   1: 0.182319820009065   0: 0.063026815071309   8: 0.019267959100068   9: 0.011730857840640   7: 0.011700316403023   4: 0.011689172448884   2: 0.011689018841845   5: 0.011688557711255   3: 0.011687803567403 

training_1440     6: 0.855523252641218   0: 0.022788214672166   5: 0.021482449871205   8: 0.014376510966528   9: 0.014341429645090   1: 0.014298125062902   7: 0.014297632550333   2: 0.014297532573549   4: 0.014297484370538   3: 0.014297367646474 

training_14402    5: 0.579534622861090   1: 0.153271860371173   2: 0.096042309533632   0: 0.024460828449145   3: 0.024451179204729   4: 0.024448169031472   6: 0.024447961679074   8: 0.024447868137111   7: 0.024447667129331   9: 0.024447533603242 

training_14417    5: 0.781295679197999   6: 0.024316856846785   0: 0.024305951135636   9: 0.024303687078505   8: 0.024302363693751   1: 0.024296289070378   4: 0.024295389976770   7: 0.024295366693371   3: 0.024294514409375   2: 0.024293901897430 

training_14418    6: 0.506210742978850   8: 0.301172153326657   7: 0.042341162847206   9: 0.021527363178586   2: 0.021514294841036   3: 0.021463849490616   1: 0.021448252906714   5: 0.021444032475280   0: 0.021439600649985   4: 0.021438547305070 

training_14423    3: 0.525278405683754   0: 0.267412653590349   5: 0.054532712631583   2: 0.021911752397585   9: 0.021838698358810   1: 0.021811705429317   6: 0.021810378056695   4: 0.021803249589664   8: 0.021800667795037   7: 0.021799776467206 

training_14427    5: 0.608734212417693   7: 0.157811408978770   4: 0.094979187808653   6: 0.019786765624661   1: 0.019781846510394   0: 0.019781699961609   2: 0.019781251409702   8: 0.019781226830719   9: 0.019781205135348   3: 0.019781195322451 

training_14434    6: 0.817985716065921   1: 0.040153312345557   8: 0.039224197124631   0: 0.025795809488882   9: 0.016770894616995   2: 0.016147610323856   7: 0.011005454367943   3: 0.010986543761141   5: 0.010966002868652   4: 0.010964459036422 

training_1444     2: 0.423095485989408   6: 0.268908164574912   3: 0.130176855743014   9: 0.047083372385839   1: 0.044940265464444   0: 0.017173695811781   7: 0.017164490564426   5: 0.017154514169849   4: 0.017152080910487   8: 0.017151074385840 

training_14440    6: 0.671578942167422   9: 0.105517524722075   8: 0.068075409181270   0: 0.030027542688011   5: 0.028523309054270   1: 0.027565148524678   7: 0.026423382516793   4: 0.014097206490532   2: 0.014096251865903   3: 0.014095282789045 

training_1445     4: 0.363970694494485   5: 0.335841040911588   1: 0.183900977848977   9: 0.016613610482108   6: 0.016613604865451   7: 0.016612351053197   0: 0.016612332762744   8: 0.016612230222430   3: 0.016611803531058   2: 0.016611353827962 

training_1446     5: 0.754626144284795   4: 0.027272041892640   0: 0.027262885718082   8: 0.027262854799272   6: 0.027262777094492   1: 0.027262774760735   3: 0.027262725366183   7: 0.027262664221970   2: 0.027262646318211   9: 0.027262485543620 

training_14469    1: 0.474023682741862   5: 0.266446327256705   4: 0.032442166958763   8: 0.032441781609546   6: 0.032441634973759   0: 0.032441563192540   7: 0.032440873664476   9: 0.032440833678106   2: 0.032440742927459   3: 0.032440392996784 

training_14476    7: 0.484415743458678   0: 0.322087083228761   5: 0.024198634516815   4: 0.024189415271720   6: 0.024189218895314   2: 0.024188003150228   1: 0.024187166481388   3: 0.024182245889172   8: 0.024181486846531   9: 0.024181002261394 

training_14483    6: 0.774792350788226   0: 0.060398337937448   8: 0.048120607256865   1: 0.016685950946082   5: 0.016672706073869   4: 0.016667231766199   7: 0.016667203059458   9: 0.016665542641502   2: 0.016665070000784   3: 0.016664999529568 

training_14485    1: 0.473618110713948   5: 0.326778742929932   4: 0.052678260981920   0: 0.027351339582847   3: 0.020228322535646   6: 0.019882777646595   8: 0.019865936037142   9: 0.019865770689637   2: 0.019865455456526   7: 0.019865283425806 

training_1449     5: 0.685200902548597   4: 0.107526305693118   1: 0.056886665941341   7: 0.046623442304073   6: 0.017321982556596   0: 0.017308078842407   8: 0.017287618419955   9: 0.017282805048104   3: 0.017281186631945   2: 0.017281012013864 

training_14491    7: 0.448899762410135   6: 0.416587052670787   3: 0.016829051998630   5: 0.016816242535013   1: 0.016813362037951   0: 0.016812955622662   4: 0.016810527960582   8: 0.016810426274195   9: 0.016810364590846   2: 0.016810253899200 

training_14499    7: 0.477319612001857   0: 0.329183563714345   5: 0.024198702678050   4: 0.024189481904320   6: 0.024189053493830   2: 0.024187862758049   1: 0.024187015946559   3: 0.024182244492356   8: 0.024181471973070   9: 0.024180991037564 

training_145      5: 0.527354409978710   1: 0.185213883371960   6: 0.158329877815870   3: 0.038224332462356   2: 0.015151884754561   7: 0.015150181237301   9: 0.015149939440084   4: 0.015142469644655   0: 0.015141737207877   8: 0.015141284086627 

training_14504    1: 0.399739668845755   2: 0.271289439532530   6: 0.166895154328550   0: 0.052969670318628   7: 0.033168837434057   5: 0.015189267142117   4: 0.015187384830690   9: 0.015187157003149   8: 0.015186970541091   3: 0.015186450023432 

training_14506    2: 0.756717685273914   5: 0.027387241366212   1: 0.027088050888262   6: 0.027059386519807   7: 0.027049768917969   0: 0.027047252770347   9: 0.026915922023223   4: 0.026911826397233   3: 0.026911539701303   8: 0.026911326141728 

training_14509    6: 0.655851189392476   0: 0.091574609705154   3: 0.090436114214933   1: 0.065024691857418   8: 0.016188108970953   5: 0.016187742181713   4: 0.016185590141147   2: 0.016184191836023   9: 0.016184067012208   7: 0.016183694687975 

training_14512    0: 0.445793907457941   6: 0.407893514703475   7: 0.018291778515844   5: 0.018291491889890   4: 0.018289237628570   1: 0.018288748264244   8: 0.018288452774508   9: 0.018287866999906   3: 0.018287594868264   2: 0.018287406897358 

training_14515    6: 0.483576551706226   7: 0.336259391943344   5: 0.055943976470035   8: 0.017804413892995   2: 0.017739830627208   0: 0.017738411537976   4: 0.017737546194486   1: 0.017734094034061   9: 0.017733158882089   3: 0.017732624711581 

training_14516    5: 0.753238659735792   6: 0.027419531705882   4: 0.027419369557657   1: 0.027418939413803   8: 0.027418661626619   9: 0.027418238423955   0: 0.027417418496235   7: 0.027416857593481   2: 0.027416255054099   3: 0.027416068392476 

training_14517    5: 0.722951758011571   4: 0.030785681345850   1: 0.030782979777349   8: 0.030782901722560   0: 0.030782894942802   3: 0.030782839651180   2: 0.030782834292238   6: 0.030782722251299   7: 0.030782706241910   9: 0.030782681763241 

training_1452     5: 0.754629753153080   4: 0.027266220649818   6: 0.027263341528528   0: 0.027263173411113   1: 0.027263164834513   3: 0.027262968687759   9: 0.027262898287844   8: 0.027262893177300   2: 0.027262835087466   7: 0.027262751182581 

training_14524    5: 0.680311970576631   0: 0.095733491699884   6: 0.028028754161302   4: 0.027998224505730   8: 0.027988157406001   7: 0.027987990718331   9: 0.027987926479026   2: 0.027987851433719   3: 0.027987842299693   1: 0.027987790719684 

training_14525    5: 0.744924802596181   4: 0.028345036627858   6: 0.028343250759483   1: 0.028342619389576   8: 0.028342231116025   9: 0.028341771663792   0: 0.028340934948184   7: 0.028340298827953   2: 0.028339637279633   3: 0.028339416791316 

training_14537    9: 0.504826919668216   6: 0.304672876996635   2: 0.036782701084544   8: 0.035399428332814   1: 0.031052681219603   0: 0.017534334232447   5: 0.017443137571455   7: 0.017431084383548   4: 0.017428566059718   3: 0.017428270451022 

training_14539    5: 0.726199654523176   6: 0.073405622302895   1: 0.025066399881090   8: 0.025055939623881   0: 0.025047058671049   4: 0.025046584862495   3: 0.025045218569456   9: 0.025044784688122   2: 0.025044637484581   7: 0.025044099393253 

training_14540    5: 0.805365423795988   9: 0.021633640190202   4: 0.021629276110847   0: 0.021628855122041   1: 0.021624503214087   6: 0.021624442748102   8: 0.021623618144871   2: 0.021623495926003   3: 0.021623389462709   7: 0.021623355285150 

training_14542    1: 0.345339342265608   4: 0.336690373030670   5: 0.153746091346716   7: 0.059834480123810   6: 0.017403942981841   0: 0.017401261948663   9: 0.017396795784546   2: 0.017396214002533   8: 0.017396180937796   3: 0.017395317577817 

training_14544    5: 0.470116538635157   6: 0.201893105641244   3: 0.081448463489764   0: 0.077540508230739   1: 0.071597145047664   8: 0.019482502519059   2: 0.019482470134928   9: 0.019480655206422   4: 0.019480125694867   7: 0.019478485400157 

training_14545    5: 0.417127338623104   8: 0.386056369495796   6: 0.024605678961147   0: 0.024602635088632   3: 0.024602494881136   4: 0.024601558095616   1: 0.024601475184521   2: 0.024601002077603   7: 0.024600741933482   9: 0.024600705658963 

training_14547    3: 0.422144166965621   5: 0.350218314300206   4: 0.028461971656843   7: 0.028454666075093   6: 0.028453874932123   1: 0.028453740061235   0: 0.028453627564153   2: 0.028453394565309   8: 0.028453158665869   9: 0.028453085213549 

training_14549    5: 0.783877447766147   2: 0.024014443139320   4: 0.024014256326187   6: 0.024014073335976   3: 0.024013709372026   1: 0.024013449985968   0: 0.024013308682303   8: 0.024013140173729   7: 0.024013115677838   9: 0.024013055540505 

training_14550    5: 0.499661941924507   3: 0.313076672202632   1: 0.023407980996373   0: 0.023407909351044   4: 0.023407725625074   7: 0.023407689532987   6: 0.023407689073997   9: 0.023407649173288   8: 0.023407497969882   2: 0.023407244150216 

training_14551    5: 0.392573665488145   3: 0.392001088640958   4: 0.026934916095675   6: 0.026927528608828   1: 0.026927368071508   0: 0.026927292738670   7: 0.026927160424767   2: 0.026927101577279   8: 0.026926959340450   9: 0.026926919013721 

training_14558    2: 0.793519168852650   5: 0.022950110864774   8: 0.022948219295873   6: 0.022948013003708   1: 0.022940582364414   0: 0.022940025657959   4: 0.022939765481713   7: 0.022938423142651   9: 0.022938390470439   3: 0.022937300865819 

training_1456     5: 0.559882115369726   6: 0.200750772313028   1: 0.122319307137297   4: 0.033400038616928   2: 0.018902533619987   3: 0.017894206880246   0: 0.016169993364229   9: 0.010606638396732   8: 0.010044960871325   7: 0.010029433430503 

training_14563    9: 0.592658665454517   0: 0.150072433672316   3: 0.087901535590417   1: 0.024207714229138   5: 0.024200419076283   6: 0.024195738525566   8: 0.024195297068813   4: 0.024190567675038   2: 0.024189103271700   7: 0.024188525436213 

training_14566    5: 0.434625865484813   6: 0.368471078936560   9: 0.024627731441325   4: 0.024614251490785   8: 0.024611773329453   0: 0.024610738133258   7: 0.024610573940069   1: 0.024609715625143   2: 0.024609142360011   3: 0.024609129258583 

training_14569    4: 0.759400959441067   7: 0.092149255207759   5: 0.018641208910179   8: 0.018549834207550   6: 0.018547304048380   0: 0.018543151247023   1: 0.018542524704052   9: 0.018542227036524   2: 0.018542196566927   3: 0.018541338630540 

training_1457     9: 0.802081707138408   8: 0.021994999785011   6: 0.021993564706729   5: 0.021991232223768   0: 0.021990407052261   1: 0.021990285726507   4: 0.021989684553913   2: 0.021989591642816   7: 0.021989388929022   3: 0.021989138241566 

training_14572    6: 0.571094137794059   7: 0.291520128783804   8: 0.017270611385059   4: 0.017234150648781   0: 0.017150413831613   1: 0.017150255148425   5: 0.017149983149602   9: 0.017144845351003   3: 0.017143557878191   2: 0.017141916029462 

training_14573    6: 0.787276848592365   5: 0.055045767408967   0: 0.019716620434366   2: 0.019712219822646   1: 0.019710683919700   8: 0.019710568586960   4: 0.019709582771129   9: 0.019708659735279   3: 0.019705108465354   7: 0.019703940263234 

training_14582    3: 0.501027819553420   6: 0.293078718285066   2: 0.058936200206511   1: 0.021000687264817   0: 0.020995380643338   5: 0.020993937318886   9: 0.020992557810611   4: 0.020992039531692   8: 0.020991419783849   7: 0.020991239601810 

training_14586    3: 0.494572474672492   5: 0.307798058690506   4: 0.024705301520996   6: 0.024704258080476   1: 0.024703776335748   0: 0.024703686063485   8: 0.024703218765055   9: 0.024703108444003   2: 0.024703065546678   7: 0.024703051880561 

training_14587    1: 0.410746015155347   3: 0.339496896697940   0: 0.117642084436641   5: 0.018878314343427   6: 0.018877098821160   4: 0.018873848890529   9: 0.018872056170646   2: 0.018871479472498   7: 0.018871200438222   8: 0.018871005573590 

training_146      5: 0.687270821894857   0: 0.094510970328893   3: 0.077348172397213   7: 0.020134801099046   1: 0.020123890618474   6: 0.020123761630139   4: 0.020122032855676   2: 0.020122028305536   9: 0.020121836076479   8: 0.020121684793687 

training_1460     5: 0.672272989782678   3: 0.140097773559937   4: 0.023457029659761   1: 0.023453468840114   0: 0.023453364480835   6: 0.023453306012022   8: 0.023453118072572   9: 0.023453089664834   2: 0.023452965443776   7: 0.023452894483471 

training_14603    6: 0.442374148314015   7: 0.206491810543397   3: 0.180769772839897   1: 0.024340388329073   8: 0.024339274723384   5: 0.024338908949597   0: 0.024338339439300   2: 0.024335814450186   4: 0.024335788734975   9: 0.024335753676176 

training_14604    1: 0.717278981028882   6: 0.068780396905587   3: 0.057289891345723   0: 0.022400281134647   7: 0.022387387733230   4: 0.022375206118851   2: 0.022375034673765   5: 0.022373206332501   9: 0.022369887656783   8: 0.022369727070032 

training_1461     5: 0.433267411652789   8: 0.392991280985645   4: 0.021720437369848   6: 0.021717420279871   0: 0.021717417766556   7: 0.021717409416686   9: 0.021717339554711   1: 0.021717244286409   2: 0.021717021256373   3: 0.021717017431112 

training_14612    6: 0.732206343303193   4: 0.076977978834206   0: 0.071235931900617   9: 0.017146452320205   5: 0.017075996254132   8: 0.017075629482599   7: 0.017071839077679   3: 0.017071175342464   1: 0.017069802133485   2: 0.017068851351421 

training_14619    0: 0.807309193189730   1: 0.052025087375138   6: 0.017605633958404   4: 0.017600349518188   5: 0.017587155504282   9: 0.017575527809642   8: 0.017575067036382   2: 0.017574113582226   7: 0.017574009159023   3: 0.017573862866985 

training_14622    5: 0.790360806090593   4: 0.023297667636291   0: 0.023293066502919   1: 0.023293056897526   8: 0.023292703244086   6: 0.023292602579975   2: 0.023292579208736   3: 0.023292539277311   9: 0.023292509946752   7: 0.023292468615811 

training_14623    1: 0.733947388955955   0: 0.085284349625635   8: 0.054976361821322   2: 0.017975015378239   4: 0.017974455027677   5: 0.017970203569649   6: 0.017969825147100   9: 0.017967782594699   7: 0.017967435749045   3: 0.017967182130679 

training_14626    0: 0.792601255051278   6: 0.023141147023908   1: 0.023039389004730   5: 0.023037068795292   2: 0.023036197787367   4: 0.023030743784938   9: 0.023029168028717   8: 0.023029117568561   3: 0.023028040324334   7: 0.023027872630875 

training_14629    1: 0.464632186043226   5: 0.367726441086384   0: 0.042201035484161   6: 0.037735279502241   9: 0.014624377023326   8: 0.014616259791014   2: 0.014616201849589   7: 0.014616172101678   4: 0.014616054917245   3: 0.014615992201135 

training_14630    5: 0.796402495100858   4: 0.022625062287820   6: 0.022623887750866   7: 0.022622378699472   1: 0.022621814881809   0: 0.022621462903566   9: 0.022621114928970   8: 0.022620900583796   3: 0.022620481209351   2: 0.022620401653492 

training_14642    6: 0.740272857366416   9: 0.112058796213392   4: 0.018513336182107   5: 0.018452829797675   0: 0.018451892170843   1: 0.018450936062198   2: 0.018450125997567   3: 0.018449865830116   8: 0.018449803292669   7: 0.018449557087016 

training_14646    4: 0.768833634364148   5: 0.025692566572519   8: 0.025684650477408   6: 0.025684548299482   0: 0.025684186164199   7: 0.025684183095098   2: 0.025684140216593   1: 0.025684104518253   3: 0.025684030746500   9: 0.025683955545800 

training_14655    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_1466     5: 0.437528510523260   1: 0.418204684899324   4: 0.028587506142979   0: 0.025164476430289   6: 0.024934066150187   7: 0.013430022927322   9: 0.013038642810590   2: 0.013037647942678   8: 0.013037613456877   3: 0.013036828716494 

training_14666    3: 0.339574710639096   5: 0.242816059056774   6: 0.242460219108193   0: 0.066502692613104   1: 0.018114180685791   2: 0.018108543106221   4: 0.018106503049778   9: 0.018105909438405   7: 0.018105635543032   8: 0.018105546759606 

training_1467     4: 0.470188210526198   8: 0.319388735118312   5: 0.026349010828547   0: 0.026308561647822   3: 0.026300118410674   6: 0.026295299403718   1: 0.026292843977922   9: 0.026292714640387   2: 0.026292331097327   7: 0.026292174349093 

training_14672    1: 0.565037765469038   6: 0.254127032853749   3: 0.044438635177761   5: 0.019514334512528   9: 0.019490719169377   4: 0.019489540896383   0: 0.019484048989222   2: 0.019473330087359   8: 0.019472609748826   7: 0.019471983095758 

training_14679    5: 0.619880906572522   0: 0.249742980544514   6: 0.016325682065710   1: 0.016295023401533   9: 0.016294025621583   8: 0.016293795843695   4: 0.016292493094287   2: 0.016292097202555   3: 0.016291729504700   7: 0.016291266148901 

training_14682    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_14686    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_14688    0: 0.723940397933916   6: 0.030689545438479   8: 0.030675958679095   7: 0.030672431887907   1: 0.030670915654666   2: 0.030670397594670   9: 0.030670374869957   3: 0.030670272830121   5: 0.030670038381647   4: 0.030669666729542 

training_14689    6: 0.513792131669890   3: 0.282172173424118   7: 0.057475697139580   1: 0.050442347990806   2: 0.031543693426656   5: 0.017739095146295   0: 0.013324436240978   9: 0.011177921684253   4: 0.011169753221116   8: 0.011162750056309 

training_1469     4: 0.750815745005454   5: 0.027695771374412   6: 0.027688857309123   9: 0.027687763305277   8: 0.027687123560494   0: 0.027685471762437   7: 0.027685008561768   2: 0.027684814202278   1: 0.027684785889517   3: 0.027684659029240 

training_14697    5: 0.328745898636753   4: 0.278350887542100   6: 0.262113083949690   2: 0.036700306437689   8: 0.015747494023889   7: 0.015674782740517   1: 0.015668525200311   0: 0.015667562412437   9: 0.015665935915778   3: 0.015665523140837 

training_14698    6: 0.765663906568309   0: 0.080905382173697   8: 0.070764731853303   7: 0.025699145639829   2: 0.015149455488972   1: 0.008449830577418   9: 0.008352250052969   5: 0.008338802865868   3: 0.008338446496784   4: 0.008338048282850 

training_147      5: 0.782659498456195   1: 0.080022943700343   0: 0.017186361372286   8: 0.017168997508043   6: 0.017166221801233   9: 0.017159747830442   7: 0.017159568138884   4: 0.017159143997853   2: 0.017158928028802   3: 0.017158589165919 

training_14701    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_14704    2: 0.738153184016652   5: 0.029100194848143   4: 0.029094921910057   9: 0.029094181212015   1: 0.029093437170416   6: 0.029093153596128   7: 0.029093094266754   0: 0.029092839272618   8: 0.029092826748238   3: 0.029092166958979 

training_14706    6: 0.542769957400135   5: 0.292805844522999   8: 0.051483955740879   1: 0.016156330838960   0: 0.016156230574227   2: 0.016128711504974   3: 0.016125460775241   9: 0.016124872248643   4: 0.016124432884658   7: 0.016124203509284 

training_14709    9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_1471     5: 0.636988975562330   7: 0.164953621072518   3: 0.024757774161093   4: 0.024757607115344   6: 0.024757142183228   8: 0.024757109732617   0: 0.024757052527705   2: 0.024756939533441   1: 0.024756923949471   9: 0.024756854162253 

training_14715    1: 0.521508722979626   0: 0.325768212629291   6: 0.019233677554965   5: 0.019074700071047   4: 0.019070397601833   9: 0.019069318470064   8: 0.019069230966572   2: 0.019068730079427   3: 0.019068523607392   7: 0.019068486039783 

training_14718    6: 0.820514736731734   0: 0.019944355968364   7: 0.019943087292467   1: 0.019943010262703   9: 0.019942601813897   2: 0.019942558029676   8: 0.019942497899701   5: 0.019942459206657   4: 0.019942430991290   3: 0.019942261803512 

training_14719    6: 0.514741544123511   9: 0.326350596462968   0: 0.042955480155220   1: 0.030343846577816   7: 0.014500608868141   5: 0.014227745752837   8: 0.014220780062925   4: 0.014220190063656   3: 0.014219842063119   2: 0.014219365869808 

training_14721    6: 0.820121266921296   0: 0.019988319000140   5: 0.019987234655778   1: 0.019987190114521   9: 0.019986294861515   7: 0.019986258973103   8: 0.019986093902655   4: 0.019986029307124   2: 0.019985750150529   3: 0.019985562113338 

training_14722    6: 0.765397791365314   0: 0.060718916229087   1: 0.021775476005200   2: 0.021733555596864   5: 0.021729909496502   7: 0.021729555616313   8: 0.021729078098236   4: 0.021728622620831   9: 0.021728598966977   3: 0.021728496004677 

training_14729    5: 0.757156252921756   1: 0.026985026915602   0: 0.026983882883121   6: 0.026983310114441   2: 0.026982264822769   4: 0.026982047036334   3: 0.026981967342099   7: 0.026981845299636   9: 0.026981715738851   8: 0.026981686925392 

training_14732    9: 0.479632719932147   6: 0.201286369123435   2: 0.176248458012271   7: 0.038390499971540   8: 0.017416360212322   5: 0.017409821200004   0: 0.017406118603322   4: 0.017404315203310   1: 0.017403976269364   3: 0.017401361472285 

training_14736    1: 0.621525978294548   0: 0.238982663073919   6: 0.040688436964889   2: 0.014146343046548   5: 0.014117938838450   7: 0.014110943744115   3: 0.014107222463311   4: 0.014107166578755   9: 0.014106792307778   8: 0.014106514687687 

training_14739    6: 0.823302770713263   0: 0.069648373591677   1: 0.024079986391168   9: 0.011853841949286   3: 0.011852858834587   8: 0.011852831847773   5: 0.011852740836428   4: 0.011852404450127   2: 0.011852105757832   7: 0.011852085627861 

training_14744    5: 0.736663824027221   0: 0.102387515441528   4: 0.020122479871953   6: 0.020119394232871   9: 0.020118036200898   1: 0.020118035475723   8: 0.020117868640994   7: 0.020117824636614   2: 0.020117524539324   3: 0.020117496932875 

training_14751    5: 0.767281939809929   6: 0.025858058249105   3: 0.025857836777629   0: 0.025857761158176   4: 0.025857705828285   1: 0.025857487714402   2: 0.025857407346500   9: 0.025857332479622   7: 0.025857245844620   8: 0.025857224791733 

training_14752    5: 0.810182016788736   6: 0.021093465074449   4: 0.021091768140165   7: 0.021090982984866   0: 0.021090892076912   8: 0.021090515990170   1: 0.021090352658812   9: 0.021090173245908   2: 0.021089940848481   3: 0.021089892191501 

training_14755    4: 0.433082440694760   6: 0.230535539743590   5: 0.157707995859294   2: 0.025528304379038   1: 0.025526969065337   0: 0.025525335935474   9: 0.025525171787994   7: 0.025523172133392   8: 0.025522547100965   3: 0.025522523300155 

training_14757    6: 0.839060084541117   1: 0.075795971189965   0: 0.010792014031522   5: 0.010622008773202   8: 0.010621839769942   9: 0.010621823111177   3: 0.010621806645403   7: 0.010621547889322   2: 0.010621506534236   4: 0.010621397514113 

training_14761    5: 0.804393879591057   1: 0.021736233890903   0: 0.021734663043960   8: 0.021734209519940   6: 0.021734174654551   3: 0.021733463911872   4: 0.021733361026815   2: 0.021733355365934   9: 0.021733348642485   7: 0.021733310352483 

training_14767    6: 0.537044198636458   0: 0.209298446407160   5: 0.128284456089332   1: 0.040691510590050   9: 0.034027338135337   8: 0.010132187343189   7: 0.010131161701180   3: 0.010130716185148   2: 0.010130012421690   4: 0.010129972490456 

training_1477     1: 0.462253450039070   6: 0.360429600119140   0: 0.059252803047308   2: 0.026903933785254   3: 0.026323149722228   9: 0.012974126834886   5: 0.012968000490287   8: 0.012965124419977   7: 0.012964923508262   4: 0.012964888033586 

training_14770    6: 0.643031043867396   7: 0.146886038000057   0: 0.142231609040506   1: 0.009710676099724   3: 0.009691640022456   8: 0.009691337346686   5: 0.009689983394735   9: 0.009689576451945   4: 0.009689104241833   2: 0.009688991534662 

training_14771    6: 0.666981324835316   7: 0.192204344748921   9: 0.017604523106750   5: 0.017604092621707   0: 0.017602732034699   1: 0.017601285280346   4: 0.017600976235391   8: 0.017600895078917   2: 0.017599991242958   3: 0.017599834814994 

training_14777    6: 0.501726148271501   1: 0.282230444500741   0: 0.027011288154047   8: 0.027008499465188   7: 0.027006303708721   9: 0.027004799619798   5: 0.027004772686533   3: 0.027002714053352   2: 0.027002550055531   4: 0.027002479484588 

training_14779    6: 0.732768321485219   8: 0.100181997451050   7: 0.053433700434724   1: 0.016234181301269   0: 0.016231943918306   5: 0.016230352952977   9: 0.016230270627689   2: 0.016229906293575   4: 0.016229667954488   3: 0.016229657580703 

training_1478     6: 0.811059916329988   5: 0.054199721643407   0: 0.038242129476039   1: 0.027626051949687   7: 0.017149098468466   8: 0.010391583561721   4: 0.010333438688326   9: 0.010332821735831   2: 0.010332690761304   3: 0.010332547385231 

training_14783    6: 0.490921180727358   7: 0.260321845366331   2: 0.086588683987625   5: 0.023177423601749   1: 0.023166938154378   8: 0.023166539182460   4: 0.023165967310892   9: 0.023164728921836   0: 0.023164123769905   3: 0.023162568977465 

training_14785    6: 0.540715916116492   0: 0.268627670385598   5: 0.023832927373060   1: 0.023832373148922   4: 0.023832205225882   8: 0.023832167014825   7: 0.023832134107754   9: 0.023832022749025   3: 0.023831467685247   2: 0.023831116193195 

training_1480     4: 0.441459589363779   0: 0.277720703752912   6: 0.128971496587471   1: 0.021703320814884   5: 0.021693034111841   9: 0.021691770107250   7: 0.021691032967975   8: 0.021690006419242   3: 0.021689982429661   2: 0.021689063444984 

training_14805    1: 0.613352837344705   2: 0.186786047271385   6: 0.025034671458325   7: 0.024993448307793   0: 0.024980863923905   8: 0.024972675666484   5: 0.024970923767324   9: 0.024970705683155   4: 0.024970128801123   3: 0.024967697775800 

training_14818    6: 0.859897215523579   1: 0.042135064332847   8: 0.012249078772562   0: 0.012246914275344   5: 0.012245740553913   9: 0.012245318225253   7: 0.012245202950570   2: 0.012245200275833   4: 0.012245169805701   3: 0.012245095284397 

training_1483     5: 0.577011311926202   4: 0.147700213295022   0: 0.117465603816581   2: 0.022546488263979   3: 0.022546339630026   6: 0.022546200311192   1: 0.022546153740151   9: 0.022545939081690   7: 0.022545935096416   8: 0.022545814838741 

training_1488     5: 0.581719891711652   0: 0.205477134810324   1: 0.056775780717845   4: 0.022305698587410   6: 0.022289191389223   8: 0.022287570000502   3: 0.022286297341537   2: 0.022286253702522   9: 0.022286161866764   7: 0.022286019872222 

training_1492     5: 0.788538401866231   6: 0.023497101473528   4: 0.023496971664290   9: 0.023496523400137   1: 0.023495454105887   0: 0.023495389701293   7: 0.023495350348939   8: 0.023495144121094   2: 0.023494882987761   3: 0.023494780330840 

training_1493     6: 0.708465347944538   4: 0.122169478602770   2: 0.021179594749386   5: 0.021174579913478   8: 0.021169556813575   9: 0.021168899879894   1: 0.021168563426571   0: 0.021168384354787   3: 0.021168055841318   7: 0.021167538473684 

training_1494     5: 0.755863094608959   4: 0.027131665415951   6: 0.027126917454697   9: 0.027125847604367   1: 0.027125605182512   2: 0.027125510005658   0: 0.027125403742494   3: 0.027125401724589   8: 0.027125283442623   7: 0.027125270818150 

training_1496     5: 0.474291904350239   0: 0.326406173988588   3: 0.024913802536114   4: 0.024913327469074   6: 0.024913008110477   1: 0.024912704388673   2: 0.024912290779291   7: 0.024912277298856   8: 0.024912255926881   9: 0.024912255151808 

training_1497     5: 0.416032638944680   1: 0.293584823172443   6: 0.148281803957530   2: 0.020340406136024   0: 0.020323734388552   4: 0.020295792197167   3: 0.020288637565123   7: 0.020284218426862   9: 0.020284047749217   8: 0.020283897462402 

training_1498     5: 0.326767426824678   6: 0.313297784270410   1: 0.276095016113249   0: 0.012147094314516   4: 0.011979331079652   8: 0.011943057259824   9: 0.011942917931283   7: 0.011942645099547   2: 0.011942376282316   3: 0.011942350824525 

training_1499     6: 0.441496830226533   1: 0.325414283732007   0: 0.113248326037193   7: 0.028184081736375   4: 0.026789316559751   9: 0.012975050344790   5: 0.012973624254157   2: 0.012973414128194   8: 0.012972677489251   3: 0.012972395491749 

training_1500     5: 0.782076163806725   1: 0.024219776914556   0: 0.024216573818874   6: 0.024215814342423   4: 0.024212372777596   2: 0.024212102544287   8: 0.024212014180900   3: 0.024211939914520   7: 0.024211655337132   9: 0.024211586362988 

training_1502     1: 0.482859989381491   5: 0.220298578042993   6: 0.184652765339375   0: 0.028081242504726   9: 0.014039872253908   4: 0.014016164471378   3: 0.014013172940397   2: 0.014012797977638   8: 0.014012791224715   7: 0.014012625863379 

training_1503     8: 0.836625216474541   6: 0.018156214919775   0: 0.018154066954893   1: 0.018153597353968   9: 0.018152611269457   5: 0.018152205425553   7: 0.018151818184745   2: 0.018151522277290   4: 0.018151433822069   3: 0.018151313317709 

training_1506     0: 0.620874941512055   5: 0.094553783118065   4: 0.079545982223292   3: 0.045801036423791   7: 0.045176544700308   8: 0.044883667287208   6: 0.017299621886891   1: 0.017289645494614   2: 0.017287555838717   9: 0.017287221515061 

training_1508     5: 0.399013265860544   7: 0.323301249393795   4: 0.034716658862598   0: 0.034711318033817   3: 0.034710690488992   8: 0.034709779620778   2: 0.034709411998995   6: 0.034709410404878   9: 0.034709114231545   1: 0.034709101104057 

training_151      4: 0.755086421112257   5: 0.027217597627232   1: 0.027213694975607   0: 0.027212465239627   6: 0.027212176081974   9: 0.027211621105704   3: 0.027211594708711   2: 0.027211564566297   8: 0.027211441553884   7: 0.027211423028707 

training_1512     0: 0.585260683675702   1: 0.210252225025674   7: 0.059181280864378   2: 0.020763723872950   6: 0.020761798704778   8: 0.020760163361476   9: 0.020756439709483   5: 0.020756399959669   4: 0.020754045261183   3: 0.020753239564707 

training_1514     1: 0.431632262913950   6: 0.348959445255378   0: 0.027430235901792   9: 0.027426820561795   8: 0.027425680035603   7: 0.027425372034256   2: 0.027425369694518   5: 0.027425043188018   3: 0.027424922600121   4: 0.027424847814568 

training_1519     6: 0.726273987372229   2: 0.085262699416319   1: 0.053122063857665   0: 0.019339185803697   3: 0.019335426990192   8: 0.019334498646721   7: 0.019334468847687   5: 0.019333766231039   4: 0.019332021665926   9: 0.019331881168525 

training_152      5: 0.563861945738109   6: 0.140869034087187   9: 0.127336111973696   3: 0.023991462123182   4: 0.023990533553599   0: 0.023990317636435   1: 0.023990269495277   7: 0.023990207115272   8: 0.023990108606947   2: 0.023990009670295 

training_1520     6: 0.665147233459099   9: 0.181321831248760   1: 0.034544174823949   8: 0.017027280050567   7: 0.016997570099223   2: 0.016993766404670   5: 0.016993642658078   3: 0.016992602346958   0: 0.016992137699564   4: 0.016989761209134 

training_1521     2: 0.753008969015408   5: 0.027451246797554   6: 0.027445319369578   0: 0.027444489717586   1: 0.027444399949249   4: 0.027444245737758   8: 0.027440806240888   9: 0.027440789316275   7: 0.027440498972537   3: 0.027439234883165 

training_1524     5: 0.763328554270994   4: 0.026301194496045   8: 0.026296524525212   3: 0.026296444448797   9: 0.026296349694631   2: 0.026296342882683   1: 0.026296183801352   0: 0.026296180795807   7: 0.026296177732410   6: 0.026296047352069 

training_1525     5: 0.800334256150202   6: 0.022187269121348   4: 0.022186150877274   0: 0.022185251858805   9: 0.022185028012493   1: 0.022184846602052   7: 0.022184460189370   8: 0.022184301124246   3: 0.022184250432249   2: 0.022184185631961 

training_1526     5: 0.669653577324230   0: 0.151276861835497   4: 0.022399574550066   2: 0.022385794282895   1: 0.022383811040737   6: 0.022382805392672   7: 0.022379514562566   3: 0.022379467150440   9: 0.022379371823916   8: 0.022379222036979 

training_1527     5: 0.746270142938024   4: 0.028194724709839   6: 0.028192344385468   0: 0.028192036683098   7: 0.028191918991313   3: 0.028191870643381   9: 0.028191785933296   8: 0.028191753200514   2: 0.028191726165117   1: 0.028191696349949 

training_1528     5: 0.759262766464668   2: 0.064580576212780   4: 0.053566542269158   3: 0.017515541173049   6: 0.017512964329262   0: 0.017512767511717   8: 0.017512334755133   1: 0.017512207079843   9: 0.017512179910748   7: 0.017512120293643 

training_1529     5: 0.536120637945745   7: 0.272319575976233   4: 0.023947714005084   6: 0.023945729937258   8: 0.023945012631803   9: 0.023944972896089   0: 0.023944617759653   3: 0.023943978583783   2: 0.023943891230591   1: 0.023943869033760 

training_153      1: 0.516912422363193   0: 0.356060858789214   5: 0.015882553196826   6: 0.015880237244846   4: 0.015877905207234   9: 0.015877626638982   7: 0.015877274164612   8: 0.015877206964626   2: 0.015877077387467   3: 0.015876838043000 

training_1532     5: 0.729601160444942   4: 0.030048453589014   6: 0.030044195756852   1: 0.030044144822927   0: 0.030044118959437   3: 0.030043731569782   7: 0.030043694515690   8: 0.030043590767907   2: 0.030043564532877   9: 0.030043345040573 

training_1533     6: 0.642505512074346   0: 0.230382591597404   1: 0.015896386558356   4: 0.015889190293362   5: 0.015889086598583   9: 0.015887660286749   8: 0.015887619222657   2: 0.015887407392523   7: 0.015887353547405   3: 0.015887192428615 

training_1535     6: 0.543099919596364   7: 0.332905056624807   9: 0.053852243897929   0: 0.012304584018501   1: 0.009865639272527   3: 0.009672966104757   2: 0.009591327134433   8: 0.009571031677725   5: 0.009570185794042   4: 0.009567045878915 

training_1536     4: 0.743029071811573   5: 0.028556825254499   6: 0.028552387688756   9: 0.028551830397641   1: 0.028551814630577   2: 0.028551692981721   3: 0.028551666139943   0: 0.028551665643474   8: 0.028551599515114   7: 0.028551445936701 

training_1537     6: 0.845485267568737   1: 0.017169493376197   0: 0.017168744707807   9: 0.017168408504282   5: 0.017168238185353   7: 0.017168168119700   2: 0.017168064581923   4: 0.017167930035636   8: 0.017167904491115   3: 0.017167780429250 

training_1541     5: 0.754291614865492   1: 0.056657824122248   8: 0.047581049294501   4: 0.045646494515190   6: 0.015978369388652   3: 0.015970688986244   9: 0.015970510531968   0: 0.015969927303310   7: 0.015966818118256   2: 0.015966702874139 

training_1543     5: 0.795554483906695   4: 0.062868147251228   3: 0.017699464148289   0: 0.017697290065800   6: 0.017697189278465   1: 0.017696765170237   8: 0.017696753325058   9: 0.017696691644676   2: 0.017696609019219   7: 0.017696606190334 

training_1545     5: 0.771355400014150   2: 0.025405342165389   3: 0.025405315331987   4: 0.025405222704001   6: 0.025404960610425   1: 0.025404894907098   0: 0.025404824902772   7: 0.025404726167310   9: 0.025404695072640   8: 0.025404618124228 

training_1546     5: 0.775305079855035   3: 0.024966566747961   4: 0.024966414382355   6: 0.024966065794184   8: 0.024966063658295   0: 0.024966057845241   1: 0.024965990297877   2: 0.024965967760121   7: 0.024965928764603   9: 0.024965864894328 

training_1550     6: 0.799193293517742   0: 0.082718763997123   1: 0.014761955438615   5: 0.014761386120309   9: 0.014761335572029   8: 0.014760929941102   7: 0.014760829372839   2: 0.014760614061046   4: 0.014760552862259   3: 0.014760339116937 

training_1553     6: 0.643203005355611   1: 0.177699923114791   0: 0.062197553444837   9: 0.049663161743714   8: 0.018220101567382   7: 0.010032030333789   3: 0.009751047806607   5: 0.009746746579234   4: 0.009744956239888   2: 0.009741473814148 

training_1554     4: 0.662015198106199   8: 0.110617746741951   1: 0.080670515023562   5: 0.020962799496196   6: 0.020957177267127   0: 0.020956504225880   7: 0.020955874760928   9: 0.020955527171531   3: 0.020954340586009   2: 0.020954316620617 

training_1555     5: 0.583994337315923   8: 0.137371951322941   0: 0.111308979686134   2: 0.023909632961144   3: 0.023903537134959   4: 0.023902597774105   6: 0.023902380600179   7: 0.023902324531681   1: 0.023902148343499   9: 0.023902110329436 

training_1556     6: 0.723936372894506   1: 0.090515361076303   2: 0.061863733553264   7: 0.017693586055308   5: 0.017667490431726   4: 0.017665522742424   9: 0.017664851635899   8: 0.017664523811555   0: 0.017664427076477   3: 0.017664130722537 

training_1557     6: 0.824577365419655   5: 0.055101750796817   0: 0.049156665617280   8: 0.010305081266109   9: 0.010157184933941   1: 0.010141333045618   4: 0.010140989034354   2: 0.010140133926152   7: 0.010139812286418   3: 0.010139683673656 

training_1560     6: 0.756806832268306   0: 0.094160969345169   5: 0.076761059741606   1: 0.011044413666509   3: 0.010405259694639   9: 0.010198411636627   8: 0.010168009550769   7: 0.010152257583674   2: 0.010151491524288   4: 0.010151294988414 

training_1562     6: 0.839098667157265   1: 0.036900768512990   0: 0.015517714822544   2: 0.015502330518710   5: 0.015500530512566   4: 0.015496892620105   9: 0.015496557159845   8: 0.015495609196595   7: 0.015495505713564   3: 0.015495423785818 

training_1563     5: 0.441989706571792   6: 0.246973158504077   4: 0.108479904706926   0: 0.060774248505614   7: 0.056445825672631   1: 0.017080472143657   3: 0.017064446069686   2: 0.017064110217151   9: 0.017064075244908   8: 0.017064052363558 

training_1564     5: 0.764901353153073   4: 0.026125035550353   8: 0.026121864759802   9: 0.026121804455053   3: 0.026121753722598   0: 0.026121711517815   2: 0.026121699312333   1: 0.026121604327933   7: 0.026121587406047   6: 0.026121585794993 

training_1566     5: 0.603708656508616   4: 0.199297404132476   6: 0.024626523874605   1: 0.024625462054649   0: 0.024624677752238   9: 0.024623960726039   3: 0.024623753534058   8: 0.024623578315114   7: 0.024623524999054   2: 0.024622458103150 

training_1567     3: 0.371461761855779   5: 0.301928425750266   0: 0.145167292174338   2: 0.025921341842217   4: 0.025920836407097   6: 0.025920521747065   1: 0.025920473749198   7: 0.025919868599761   9: 0.025919768246379   8: 0.025919709627901 

training_1568     5: 0.483258989140259   3: 0.323659888965097   0: 0.024147197094710   6: 0.024140075640485   1: 0.024133664573570   7: 0.024132559707676   4: 0.024132118945458   8: 0.024132082616536   9: 0.024131759007232   2: 0.024131664308979 

training_1569     5: 0.665750789936192   1: 0.141908610835578   4: 0.024045298759838   8: 0.024042362336788   9: 0.024042259238521   6: 0.024042206202985   0: 0.024042189098137   3: 0.024042127888707   2: 0.024042084315756   7: 0.024042071387499 

training_157      1: 0.278003583385849   4: 0.269646270970523   6: 0.173948316184788   3: 0.171898281438129   0: 0.017752815217054   5: 0.017751212555135   2: 0.017750522699808   8: 0.017750313824845   7: 0.017749402657170   9: 0.017749281066699 

training_1570     6: 0.588752495412165   8: 0.251904092919918   1: 0.054410485074370   5: 0.015006416879686   7: 0.015000956033844   0: 0.014986207623313   3: 0.014985219177702   9: 0.014984842476031   2: 0.014984679428224   4: 0.014984604974747 

training_1571     5: 0.765285911986953   1: 0.056903125273167   8: 0.045993046115716   6: 0.018833045383524   0: 0.018832561141467   9: 0.018830963496759   7: 0.018830617355260   2: 0.018830327787643   3: 0.018830208768757   4: 0.018830192690755 

training_1572     1: 0.356786076000015   2: 0.202256282217825   5: 0.196953316344524   8: 0.141868241294976   6: 0.017027360799026   0: 0.017024779109287   4: 0.017022084902052   7: 0.017020878813370   3: 0.017020610737538   9: 0.017020369781387 

training_1575     5: 0.844485011977709   8: 0.028659069019946   0: 0.015866349482314   6: 0.015865542580814   1: 0.015859538546443   9: 0.015855388649349   2: 0.015852581380834   7: 0.015852262516133   4: 0.015852258781650   3: 0.015851997064809 

training_1577     1: 0.399124241441397   6: 0.279252355936566   9: 0.189693679012739   5: 0.018853120388777   0: 0.018847475322599   2: 0.018846896825096   4: 0.018846653104459   8: 0.018846127476830   7: 0.018844759562450   3: 0.018844690929088 

training_1579     6: 0.749639800001907   8: 0.071521888132904   1: 0.063373140832917   0: 0.060428233233711   9: 0.009174426677685   5: 0.009173526424175   3: 0.009172327119336   2: 0.009172262996792   7: 0.009172223152112   4: 0.009172171428460 

training_1581     1: 0.740716667878529   6: 0.077831420259884   5: 0.047763873764012   9: 0.019114587437301   0: 0.019103924338287   3: 0.019095325135144   2: 0.019094989203881   8: 0.019093102999791   4: 0.019093074989968   7: 0.019093033993202 

training_1582     6: 0.645216663254696   7: 0.177966834696000   0: 0.082771751778973   8: 0.013440411128976   9: 0.013438682319347   5: 0.013434523925348   4: 0.013433283791108   1: 0.013432753792581   3: 0.013432618571388   2: 0.013432476741582 

training_1584     5: 0.587590636532070   6: 0.159367729529825   9: 0.099854875709127   0: 0.049237074330723   1: 0.017328668991987   4: 0.017324657499743   2: 0.017324638325953   8: 0.017324493079262   7: 0.017323628299378   3: 0.017323597701932 

training_1585     5: 0.748087086064789   1: 0.060615233291717   9: 0.057277059330713   8: 0.019156363856903   4: 0.019148039077432   0: 0.019143421012061   6: 0.019143360604874   7: 0.019143156490085   2: 0.019143149980300   3: 0.019143130291125 

training_1586     5: 0.788160247021803   2: 0.023538173401631   1: 0.023537949263857   3: 0.023537905110895   4: 0.023537839039982   6: 0.023537686163634   9: 0.023537674607537   0: 0.023537621885897   7: 0.023537494506832   8: 0.023537408997932 

training_1588     6: 0.794164725793389   0: 0.037856260540467   5: 0.035880088648252   1: 0.033865121999871   9: 0.016375022242022   7: 0.016372384416921   4: 0.016371782188059   2: 0.016371629364892   8: 0.016371550540802   3: 0.016371434265324 

training_1590     6: 0.762305877196804   1: 0.059845869832617   0: 0.058419053091459   4: 0.042920614492253   8: 0.012759007183092   5: 0.012754320836894   7: 0.012749379095840   3: 0.012748928563505   9: 0.012748886332494   2: 0.012748063375042 

training_1598     6: 0.714042614347429   7: 0.067034935047604   2: 0.059585120725668   5: 0.046508403468499   0: 0.018823491861923   8: 0.018809196602413   1: 0.018800375212818   9: 0.018799065104018   4: 0.018798608240154   3: 0.018798189389474 

training_160      5: 0.574508249355842   3: 0.219429439056345   6: 0.064898004093693   4: 0.020171546685809   0: 0.020166168793149   8: 0.020166042287892   9: 0.020165258132327   1: 0.020165215871265   7: 0.020165123175224   2: 0.020164952548455 

training_1601     1: 0.676720519137754   0: 0.155686116589325   6: 0.020952788406557   5: 0.020952727623287   9: 0.020948329089151   8: 0.020948103050728   4: 0.020948023134396   2: 0.020947812827702   7: 0.020947799994414   3: 0.020947780146687 

training_1602     5: 0.725118056041467   1: 0.073612783986789   6: 0.051772157478832   2: 0.049549376067505   4: 0.016661212903623   9: 0.016657938737962   0: 0.016657660447523   8: 0.016657160869068   7: 0.016656856654657   3: 0.016656796812575 

training_1606     2: 0.442972115520474   0: 0.309971429593077   4: 0.087256244391677   1: 0.022838010846416   6: 0.022832534941912   5: 0.022828011490668   3: 0.022826079884191   7: 0.022825265111526   9: 0.022825223006996   8: 0.022825085213063 

training_1607     6: 0.786159110981321   7: 0.073933474831204   9: 0.017618521787019   0: 0.017478592494050   1: 0.017471837459750   5: 0.017469771488377   2: 0.017467805875954   4: 0.017467548123530   8: 0.017467115276158   3: 0.017466221682636 

training_1608     5: 0.769657232090459   4: 0.025602189370993   1: 0.025594548397276   3: 0.025592734452432   6: 0.025592444502129   0: 0.025592437632029   8: 0.025592324031876   7: 0.025592058565370   9: 0.025592026238088   2: 0.025592004719347 

training_1610     5: 0.803311765720242   4: 0.021856966509577   6: 0.021855564602596   8: 0.021854465716553   9: 0.021854138360879   1: 0.021854035163239   0: 0.021853721153492   7: 0.021853200192552   3: 0.021853088616204   2: 0.021853053964665 

training_1611     6: 0.529896165017241   0: 0.357303667164419   3: 0.029081317240527   9: 0.021808784649800   5: 0.010354595322262   1: 0.010334967971413   8: 0.010306836680719   7: 0.010304681551295   2: 0.010304546275557   4: 0.010304438126767 

training_1616     6: 0.594174052408752   9: 0.283016652819456   1: 0.035376881103743   8: 0.016640455449020   0: 0.011917419854758   2: 0.011779987880793   5: 0.011776206362239   4: 0.011773465325705   7: 0.011773180919970   3: 0.011771697875564 

training_1619     2: 0.486260890595027   5: 0.279290478590794   4: 0.090343050206306   3: 0.045965765859342   0: 0.016366351983367   9: 0.016362903546646   6: 0.016359316943065   1: 0.016353681527963   7: 0.016348967909359   8: 0.016348592838130 

training_162      0: 0.718533960429227   1: 0.104925820476320   7: 0.022084062195682   8: 0.022075390669872   6: 0.022073746462987   5: 0.022071669808006   4: 0.022059913755067   2: 0.022058732924493   9: 0.022058437055831   3: 0.022058266222516 

training_1620     1: 0.494095697848345   4: 0.337021164229493   8: 0.021123320456591   6: 0.021122534257741   5: 0.021111173997503   0: 0.021110762243088   9: 0.021105857298059   7: 0.021103554692839   2: 0.021103409247950   3: 0.021102525728391 

training_1622     6: 0.439475350443756   5: 0.296496502428621   4: 0.134593789260670   1: 0.018499129434067   0: 0.018491132219750   8: 0.018489131282131   9: 0.018489029388898   2: 0.018488735565450   3: 0.018488730688660   7: 0.018488469287996 

training_1623     6: 0.758118440650003   1: 0.063521225254783   0: 0.049704548999023   9: 0.030340211108644   7: 0.021599638276109   3: 0.016508140493542   8: 0.015055353239898   5: 0.015051168976004   4: 0.015050667093626   2: 0.015050605908368 

training_1626     5: 0.557167624534716   3: 0.139930072210442   1: 0.122970854814800   4: 0.046875994038927   0: 0.044706919394788   6: 0.017675422848440   7: 0.017672240658640   2: 0.017667144766614   9: 0.017666953289928   8: 0.017666773442705 

training_1628     6: 0.693913400536392   5: 0.141924164033605   1: 0.020528524954199   0: 0.020524319928888   4: 0.020519133163180   2: 0.020519126682584   9: 0.020518108234328   3: 0.020517929280893   7: 0.020517853325005   8: 0.020517439860927 

training_163      5: 0.517125744782693   2: 0.262027574847297   0: 0.027606977434762   4: 0.027606288357761   3: 0.027606230577707   6: 0.027606096349471   1: 0.027605790709267   9: 0.027605118283961   7: 0.027605093957432   8: 0.027605084699648 

training_1631     6: 0.783486415424802   0: 0.066514447284818   9: 0.048373592524192   1: 0.014523801795895   5: 0.014518156324242   8: 0.014517259693773   7: 0.014516647603887   3: 0.014516571932451   4: 0.014516561293307   2: 0.014516546122634 

training_1633     5: 0.819167036212614   6: 0.020174774769255   0: 0.020096888940538   1: 0.020089314902357   8: 0.020083130456776   9: 0.020079993871796   4: 0.020079065451137   2: 0.020078900490546   7: 0.020075603893845   3: 0.020075291011137 

training_1634     0: 0.555102867208531   2: 0.206660346923602   6: 0.113883951609049   8: 0.018221730433878   3: 0.017832319022660   7: 0.017787248078339   1: 0.017633896580435   5: 0.017629195397707   4: 0.017624519788187   9: 0.017623924957611 

training_1638     4: 0.719193363785901   5: 0.105586710771170   6: 0.021938902961315   0: 0.021905111235074   9: 0.021901891936849   8: 0.021900437769033   1: 0.021894665131577   7: 0.021893718921532   3: 0.021893127453484   2: 0.021892070034065 

training_1639     5: 0.666941398780692   2: 0.181299193863809   4: 0.018974144396691   6: 0.018970659937667   0: 0.018969836306130   9: 0.018969383705468   8: 0.018969318018494   1: 0.018969185924742   7: 0.018968489531986   3: 0.018968389534321 

training_164      4: 0.804199246373735   5: 0.021768700702187   0: 0.021754137808500   1: 0.021754123143369   7: 0.021754071029467   8: 0.021754025913889   6: 0.021753957868813   9: 0.021753945373308   2: 0.021753925405704   3: 0.021753866381028 

training_1640     6: 0.729201350169977   0: 0.141859927816434   5: 0.016118393136134   7: 0.016117695877920   9: 0.016117371921312   1: 0.016117340185717   4: 0.016117290569351   8: 0.016117230964563   2: 0.016116731255649   3: 0.016116668102943 

training_1642     5: 0.722582839137166   1: 0.103021181908753   4: 0.021802897689755   3: 0.021800032833515   6: 0.021799614089944   0: 0.021798806386714   8: 0.021798786902254   9: 0.021798672343703   2: 0.021798595171392   7: 0.021798573536803 

training_1643     5: 0.833238635251264   4: 0.018533455910329   6: 0.018531586597093   1: 0.018529014146066   0: 0.018528465623138   3: 0.018528323873517   8: 0.018527969927908   9: 0.018527593670908   7: 0.018527514450970   2: 0.018527440548807 

training_1644     3: 0.412647414335191   5: 0.384856749253898   4: 0.025318532697958   8: 0.025311573995620   2: 0.025311144982832   9: 0.025311040938699   7: 0.025310947986593   0: 0.025310900142963   6: 0.025310864453978   1: 0.025310831212268 

training_1648     5: 0.777662481092851   3: 0.024704639870189   4: 0.024704329138228   6: 0.024704212468444   8: 0.024704184665341   0: 0.024704099742551   7: 0.024704044784126   2: 0.024704033800857   1: 0.024704012207420   9: 0.024703962229993 

training_1649     5: 0.702424100006645   6: 0.090022794940639   8: 0.055735855196896   2: 0.021728326744852   1: 0.021704583643880   0: 0.021680047800643   7: 0.021677346046834   4: 0.021676095076783   3: 0.021675599500381   9: 0.021675251042447 

training_165      5: 0.403994655773708   3: 0.316948146358831   4: 0.101258527158388   9: 0.025431938394954   7: 0.025398117465808   0: 0.025397331946946   6: 0.025392896603334   2: 0.025392812358275   1: 0.025392798487272   8: 0.025392775452485 

training_1650     4: 0.780804001169133   7: 0.075708447089527   9: 0.017956085956076   6: 0.017947823169941   0: 0.017946018512036   5: 0.017936456755239   2: 0.017931285837050   8: 0.017925132682675   1: 0.017923885802214   3: 0.017920863026110 

training_1651     5: 0.650006219647142   8: 0.144587105587978   6: 0.025678162515207   4: 0.025677559278628   0: 0.025676915575498   1: 0.025676808007838   7: 0.025674737109873   3: 0.025674548522378   9: 0.025674037416756   2: 0.025673906338702 

training_1652     6: 0.747039230058744   0: 0.111863407452993   3: 0.032040264661863   8: 0.015580065762648   5: 0.015579889910538   1: 0.015579884900136   7: 0.015579788078818   4: 0.015579527888062   9: 0.015579336250341   2: 0.015578605035858 

training_1653     5: 0.792079525693319   6: 0.023104131070744   4: 0.023103615600305   0: 0.023102159138390   3: 0.023102117158419   1: 0.023101979002806   9: 0.023101856451072   2: 0.023101675520261   7: 0.023101553419553   8: 0.023101386945131 

training_1655     5: 0.500883903115413   8: 0.307812289679577   4: 0.023921638306761   0: 0.023911899708075   6: 0.023911800651587   3: 0.023911794369571   9: 0.023911788220207   2: 0.023911688446944   7: 0.023911629700402   1: 0.023911567801463 

training_1656     6: 0.640418777472275   0: 0.215309165495049   1: 0.053862811859637   4: 0.012928050654304   5: 0.012915410598635   9: 0.012913300313933   2: 0.012913243967041   8: 0.012913206407583   3: 0.012913057225624   7: 0.012912976005919 

training_1657     5: 0.561219595426008   4: 0.184361453111512   9: 0.091925910275108   0: 0.059969846403834   6: 0.017090485271149   1: 0.017089956750279   2: 0.017085816662834   8: 0.017085750778031   3: 0.017085607448137   7: 0.017085577873109 

training_1658     4: 0.620333410537911   5: 0.185974478074679   1: 0.067392634938322   6: 0.018052565352071   2: 0.018044619892243   7: 0.018042378841844   0: 0.018041017551462   9: 0.018040576379354   8: 0.018039367008848   3: 0.018038951423266 

training_1659     4: 0.748229627845034   9: 0.065322401255182   1: 0.023327473799195   6: 0.023312032204881   5: 0.023307769730375   0: 0.023306997554049   3: 0.023299714121297   2: 0.023298529899186   7: 0.023297850491727   8: 0.023297603099074 

training_166      5: 0.779691117587513   6: 0.024498627688537   1: 0.024478740884171   0: 0.024476737472194   4: 0.024476154785177   3: 0.024476042936600   8: 0.024475694091542   2: 0.024475685055274   7: 0.024475622191449   9: 0.024475577307543 

training_1660     6: 0.465780768653665   9: 0.264809579487985   8: 0.090026586188898   2: 0.076307498661189   5: 0.017184233993584   4: 0.017179586663173   1: 0.017179306640534   3: 0.017178261009668   0: 0.017177764045568   7: 0.017176414655736 

training_1661     2: 0.344728965774328   6: 0.282468751688571   0: 0.172873053750024   9: 0.106994031817168   1: 0.015527336051108   5: 0.015483399881567   8: 0.015482333267554   4: 0.015480896198824   3: 0.015480737364121   7: 0.015480494206734 

training_1665     0: 0.526809909575319   3: 0.139792744259228   1: 0.105310172781170   6: 0.090924374712605   5: 0.022870620553883   4: 0.022860873409812   7: 0.022857977235113   2: 0.022857855965081   8: 0.022857775497122   9: 0.022857696010668 

training_1666     0: 0.409625618898842   3: 0.279762196911837   1: 0.193587544529413   5: 0.016723493979045   6: 0.016723251782569   4: 0.016718440156214   7: 0.016715368331813   8: 0.016714848277480   9: 0.016714722000484   2: 0.016714515132303 

training_1667     0: 0.840223530993886   6: 0.017755645484942   1: 0.017755494909630   5: 0.017754077909840   4: 0.017752276296374   9: 0.017752202560416   8: 0.017751958864558   2: 0.017751869246659   7: 0.017751517917362   3: 0.017751425816333 

training_167      5: 0.804457855272974   6: 0.021730076598159   4: 0.021728519813464   1: 0.021728449573992   9: 0.021727514486379   0: 0.021726396525825   2: 0.021725611264745   8: 0.021725306763812   3: 0.021725157822275   7: 0.021725111878376 

training_1673     8: 0.431531777693907   1: 0.353050922976342   9: 0.071413830301884   5: 0.041899358179052   0: 0.017058321759292   6: 0.017018173334838   2: 0.017011436399637   4: 0.017006485663123   7: 0.017005087532659   3: 0.017004606159266 

training_1674     6: 0.797740197114028   5: 0.102826106692326   1: 0.012533250936166   0: 0.012419994125693   7: 0.012418458485952   4: 0.012413078855879   8: 0.012412976532744   2: 0.012412280580110   9: 0.012411971103617   3: 0.012411685573484 

training_1675     6: 0.665644980556608   1: 0.124521069272663   9: 0.088516983765123   0: 0.043267248912348   3: 0.023477621723709   7: 0.010916949428877   5: 0.010915447790781   8: 0.010913856951344   2: 0.010913268540485   4: 0.010912573058062 

training_1676     0: 0.455496885651652   5: 0.361914240201245   8: 0.047256876696774   6: 0.019337670010711   1: 0.019334602663148   4: 0.019332869845132   9: 0.019332070634999   7: 0.019331701838100   2: 0.019331701104748   3: 0.019331381353492 

training_1677     5: 0.763206138810141   4: 0.026315976268221   8: 0.026309911150072   3: 0.026309789716178   2: 0.026309767292019   0: 0.026309719951561   6: 0.026309698349253   1: 0.026309680263342   9: 0.026309675966896   7: 0.026309642232317 

training_1678     8: 0.486390054934564   1: 0.315457552078533   4: 0.055716571686754   9: 0.020356187218141   7: 0.020355226143042   0: 0.020347589568293   6: 0.020346594552797   5: 0.020345315733724   2: 0.020342967011921   3: 0.020341941072230 

training_1679     1: 0.537700153432405   0: 0.176117256315264   4: 0.158721665972176   6: 0.018216653386837   5: 0.018214403895975   8: 0.018206592995770   9: 0.018206562477817   2: 0.018206099538436   7: 0.018205563979916   3: 0.018205048005404 

training_168      5: 0.770852897879781   6: 0.025472431377811   1: 0.025465603528724   9: 0.025461842814279   0: 0.025459811740537   2: 0.025458744460620   4: 0.025457944674494   8: 0.025457120209484   7: 0.025457014985414   3: 0.025456588328857 

training_1680     6: 0.791424636456763   9: 0.075676155870393   0: 0.034134220567876   1: 0.014123799722873   3: 0.014113122624598   7: 0.014107280830866   5: 0.014106758129320   2: 0.014106290591918   8: 0.014103970011885   4: 0.014103765193507 

training_1681     6: 0.691303405032774   8: 0.157582613815084   9: 0.018890556127044   0: 0.018889967788740   5: 0.018889376013577   7: 0.018889264248510   1: 0.018888985742169   4: 0.018888736275484   2: 0.018888626468423   3: 0.018888468488194 

training_1682     6: 0.339686667860910   1: 0.292428619403481   5: 0.219921669788055   0: 0.073406994340705   8: 0.012470682719313   9: 0.012421393850381   2: 0.012416348044894   7: 0.012416178804680   3: 0.012415773593087   4: 0.012415671594494 

training_1684     5: 0.391483895788550   1: 0.384874150715695   0: 0.061735347649965   7: 0.023174854788263   6: 0.023124879142454   2: 0.023123766220128   4: 0.023121771608390   9: 0.023120682969372   8: 0.023120572493853   3: 0.023120078623330 

training_1686     6: 0.608968844688827   3: 0.135905818679352   8: 0.132137588157427   0: 0.017571270446978   1: 0.017569854714082   9: 0.017569576016909   4: 0.017569340557160   5: 0.017569301062669   2: 0.017569235791776   7: 0.017569169884819 

training_1688     5: 0.751905651474236   6: 0.027567124020095   8: 0.027566887451221   1: 0.027566666595243   4: 0.027566418205899   9: 0.027566397134848   0: 0.027566328502777   2: 0.027564855672830   3: 0.027564840891780   7: 0.027564830051070 

training_1689     5: 0.722639326255080   4: 0.101511623984441   7: 0.046345528998539   1: 0.018518832055585   9: 0.018501743852666   0: 0.018498654570297   6: 0.018497133055834   2: 0.018495771016498   8: 0.018495759184784   3: 0.018495627026277 

training_169      5: 0.802058117198425   4: 0.021999172867361   6: 0.021993019014010   0: 0.021992857914953   3: 0.021992847650840   8: 0.021992845642170   1: 0.021992826426649   9: 0.021992795289974   2: 0.021992791811690   7: 0.021992726183927 

training_1692     6: 0.609441055877071   9: 0.234429618821557   8: 0.073219876198776   4: 0.011880497953636   1: 0.011840964227460   7: 0.011840934435238   5: 0.011837362958520   2: 0.011837051181115   0: 0.011837009008849   3: 0.011835629337778 

training_1693     6: 0.468655553458325   4: 0.332745807805543   1: 0.062906183454869   0: 0.019399309072963   8: 0.019394040086301   5: 0.019381150706951   9: 0.019380562993628   2: 0.019379483870051   7: 0.019379096688103   3: 0.019378811863267 

training_1694     2: 0.569090227166167   6: 0.228721859496219   0: 0.047938617411260   7: 0.032929331551454   5: 0.020261780374684   1: 0.020231450085965   9: 0.020209988505978   8: 0.020207077317641   4: 0.020205738966554   3: 0.020203929124077 

training_1696     6: 0.401610234628803   5: 0.302704607313398   7: 0.175712185618456   1: 0.028736208011075   0: 0.026190762910800   9: 0.013011630073787   3: 0.013011108335722   2: 0.013008315954071   8: 0.013007735414204   4: 0.013007211739684 

training_1706     5: 0.845411641566333   9: 0.017179208799340   4: 0.017178971192586   8: 0.017177651021273   6: 0.017175836423494   3: 0.017175659986827   1: 0.017175614016569   0: 0.017175474114471   2: 0.017174986020428   7: 0.017174956858679 

training_1708     5: 0.772609876358138   3: 0.025274479122857   4: 0.025264740030393   6: 0.025264530442921   8: 0.025264506039854   0: 0.025264459282881   7: 0.025264372731737   2: 0.025264372244081   1: 0.025264358873275   9: 0.025264304873864 

training_1709     5: 0.636206937957732   2: 0.213085626668542   1: 0.042021218661404   9: 0.015554312594673   6: 0.015536616570183   0: 0.015523525735962   4: 0.015518336898127   7: 0.015518188430389   8: 0.015517864594666   3: 0.015517371888322 

training_1711     6: 0.530229750057845   0: 0.181425541077234   5: 0.121338063074878   1: 0.073369191193406   3: 0.020956406051317   2: 0.018473790119932   8: 0.014079615083955   9: 0.013400911740720   4: 0.013363438015231   7: 0.013363293585480 

training_1714     5: 0.649974172434461   0: 0.162285648638064   3: 0.023467943317972   4: 0.023467828824863   6: 0.023467638712379   1: 0.023467555973576   8: 0.023467534780964   7: 0.023467286823426   2: 0.023467249519064   9: 0.023467140975232 

training_1715     6: 0.734992884267410   8: 0.098494450042108   0: 0.046424941643390   1: 0.031167403959034   7: 0.025168097711276   9: 0.012761230522109   5: 0.012752164722726   3: 0.012747748402299   4: 0.012746304016597   2: 0.012744774713052 

training_1716     5: 0.795297835824349   6: 0.022746775328182   7: 0.022745094470770   1: 0.022744720460444   3: 0.022744676099880   0: 0.022744563543154   4: 0.022744416604697   8: 0.022744052640829   9: 0.022743959674049   2: 0.022743905353646 

training_1718     6: 0.605416595295143   0: 0.166558556208926   5: 0.092637209128353   2: 0.042329531583730   3: 0.022492997110257   1: 0.019091036886384   7: 0.013034509086694   8: 0.012840418742049   9: 0.012801432047211   4: 0.012797713911254 

training_1719     6: 0.754501063423473   1: 0.027290119681360   5: 0.027279328744513   0: 0.027279274883702   4: 0.027276183794857   9: 0.027275728507021   2: 0.027275424579154   8: 0.027274399426965   3: 0.027274352219942   7: 0.027274124739012 

training_1722     5: 0.662081019502404   8: 0.106325780678507   0: 0.095683253764314   4: 0.019418771493337   6: 0.019415434726829   3: 0.019415188236737   1: 0.019415187111304   7: 0.019415127548940   9: 0.019415122250678   2: 0.019415114686950 

training_1723     6: 0.846792762375035   0: 0.031146157165955   5: 0.015267606138545   1: 0.015257432888933   9: 0.015256134518807   4: 0.015256060443487   8: 0.015256039106999   7: 0.015256032857153   2: 0.015255973543326   3: 0.015255800961760 

training_1724     6: 0.422638524320689   0: 0.357447179282542   9: 0.092931321246416   1: 0.051728471795848   4: 0.027414349464422   5: 0.009654083381584   8: 0.009547796507559   7: 0.009546121565289   3: 0.009546081262706   2: 0.009546071172946 

training_1727     5: 0.536453794303558   4: 0.221574715368905   8: 0.088304863830767   0: 0.021953861218771   6: 0.021952904357867   1: 0.021952853029161   3: 0.021951932639997   9: 0.021951830885455   2: 0.021951633349583   7: 0.021951611015936 

training_1729     5: 0.452329162660526   0: 0.218953530686363   6: 0.164656101245890   2: 0.050362552634482   1: 0.042277169572473   7: 0.014344906280434   4: 0.014269570451292   9: 0.014269228677596   8: 0.014269080387317   3: 0.014268697403626 

training_1731     6: 0.818573255407248   5: 0.040979392125759   0: 0.029008643631004   7: 0.015940709205076   9: 0.015935506099309   8: 0.015916860360169   1: 0.015912033970472   4: 0.015911458532984   2: 0.015911127474058   3: 0.015911013193920 

training_1732     5: 0.723599216571528   0: 0.119103549419070   1: 0.019672765144648   6: 0.019666274422173   4: 0.019661062701711   9: 0.019660227747640   2: 0.019659592039034   7: 0.019659383871097   8: 0.019659346958518   3: 0.019658581124581 

training_1734     5: 0.817816130698421   4: 0.020245352548713   0: 0.020242901631554   6: 0.020242457412375   9: 0.020242373180835   8: 0.020242332635019   1: 0.020242294034395   3: 0.020242096550506   2: 0.020242076274669   7: 0.020241985033514 

training_1735     6: 0.682605366284071   0: 0.185756185707921   5: 0.016476498543452   1: 0.016464198820814   4: 0.016452851082816   2: 0.016450453358337   3: 0.016449146771236   9: 0.016448542204867   7: 0.016448393628712   8: 0.016448363597773 

training_1739     5: 0.396380780164323   1: 0.299275208450293   6: 0.164241718658899   0: 0.051528307012413   8: 0.014919333902131   7: 0.014807070265125   4: 0.014712374247395   2: 0.014712363341263   9: 0.014711506479475   3: 0.014711337478684 

training_1740     9: 0.410410924191104   6: 0.277385230300856   5: 0.154908409498582   1: 0.022475507652026   0: 0.022474718064800   4: 0.022470596452037   2: 0.022470030583780   3: 0.022468829072282   7: 0.022467975898335   8: 0.022467778286198 

training_1741     6: 0.739307962658598   0: 0.080960772525780   5: 0.022469030082335   1: 0.022468913242101   4: 0.022466085680669   8: 0.022465692830693   9: 0.022465659816791   2: 0.022465656321335   7: 0.022465290479737   3: 0.022464936361960 

training_1747     5: 0.600951983078573   6: 0.249087643811689   1: 0.018747536443915   7: 0.018745788030977   0: 0.018745056727348   3: 0.018744594072504   2: 0.018744487673522   9: 0.018744373596355   4: 0.018744283880941   8: 0.018744252684176 

training_1751     2: 0.505705826470752   5: 0.347921966207296   6: 0.018825613498153   1: 0.018334175569526   9: 0.018215406262410   4: 0.018209181082074   0: 0.018198001849733   3: 0.018197025829271   8: 0.018196506225304   7: 0.018196297005482 

training_1752     4: 0.548483527278777   8: 0.253943649517136   5: 0.024705168501643   6: 0.024696607433393   1: 0.024695545419372   0: 0.024695329702495   9: 0.024695316981385   3: 0.024695056054137   2: 0.024694904903727   7: 0.024694894207935 

training_1758     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_1759     5: 0.793799538511210   4: 0.022916077302568   8: 0.022910715606053   0: 0.022910599663606   9: 0.022910584309576   1: 0.022910571515616   3: 0.022910550420169   6: 0.022910547349969   2: 0.022910449098150   7: 0.022910366223084 

training_176      0: 0.400125786053021   6: 0.318193658329017   1: 0.094681738788130   3: 0.093279221617688   7: 0.037350924754072   5: 0.011291201662563   9: 0.011276182768432   4: 0.011270864251447   2: 0.011270250917623   8: 0.011260170858007 

training_1760     0: 0.741565249677047   8: 0.071712928499925   5: 0.023348873601694   1: 0.023342818462739   6: 0.023339649387006   4: 0.023339422561768   2: 0.023338206123746   3: 0.023337679217419   7: 0.023337637445339   9: 0.023337535023317 

training_1761     6: 0.491286479158915   9: 0.233475578497343   5: 0.131627579043494   1: 0.020516941511127   0: 0.020516301755963   8: 0.020515719425218   2: 0.020515634449459   7: 0.020515410527584   4: 0.020515251125207   3: 0.020515104505690 

training_1763     3: 0.432813974671349   5: 0.359060578495647   4: 0.026016275232048   6: 0.026015812990328   8: 0.026015759607722   0: 0.026015660135098   7: 0.026015528245896   2: 0.026015517436911   1: 0.026015494611661   9: 0.026015398573340 

training_1764     5: 0.409619895566930   4: 0.357625280350260   6: 0.072369396644483   0: 0.022913983711178   1: 0.022913152141018   9: 0.022912123105800   8: 0.022911764537264   7: 0.022911480443035   3: 0.022911476253616   2: 0.022911447246416 

training_1765     5: 0.824921952475849   4: 0.019454945036477   6: 0.019453979772933   0: 0.019453430312265   8: 0.019452860507322   9: 0.019452853818474   1: 0.019452826177856   3: 0.019452508101509   2: 0.019452324171180   7: 0.019452319626135 

training_1767     3: 0.534582316224229   5: 0.237608640301828   4: 0.028478428323484   6: 0.028476940114924   1: 0.028476178037388   0: 0.028476058960660   8: 0.028475643402493   2: 0.028475289500337   7: 0.028475253119290   9: 0.028475252015368 

training_1768     5: 0.809562498137211   4: 0.021163882531304   6: 0.021159898212510   1: 0.021159260181704   0: 0.021159244194221   8: 0.021159164744926   3: 0.021159082214151   9: 0.021159059013156   2: 0.021158971335676   7: 0.021158939435141 

training_1769     5: 0.779104282698199   9: 0.024627578859510   1: 0.024536315976435   6: 0.024534292995152   0: 0.024533652718830   4: 0.024533448526441   3: 0.024532938285227   2: 0.024532566783337   7: 0.024532488069080   8: 0.024532435087789 

training_1771     6: 0.840173627161704   9: 0.017800420657448   1: 0.017756322504476   5: 0.017755988567165   0: 0.017754583238491   4: 0.017752798163042   2: 0.017751925306698   7: 0.017751499741948   8: 0.017751451001205   3: 0.017751383657823 

training_1772     6: 0.751411444730749   0: 0.131571857676837   1: 0.022251238208264   5: 0.021426395255557   2: 0.012230440385338   9: 0.012222553787490   3: 0.012221885642956   8: 0.012221474995611   4: 0.012221388054336   7: 0.012221321262862 

training_1773     6: 0.669539893916470   5: 0.146107991379656   0: 0.043698832696860   8: 0.041364131076385   1: 0.016569904771452   9: 0.016550717900917   4: 0.016542693379441   7: 0.016542077010754   2: 0.016541905181824   3: 0.016541852686240 

training_1777     6: 0.772349782705146   1: 0.055672091195560   0: 0.050292834482371   9: 0.034754713012362   7: 0.014519589347309   5: 0.014492309988061   8: 0.014480881800048   4: 0.014479500234201   2: 0.014479161078218   3: 0.014479136156723 

training_1783     5: 0.450631160843067   4: 0.351074817525253   6: 0.024795143596517   3: 0.024786575841636   0: 0.024785432625092   2: 0.024785426243990   1: 0.024785418801048   8: 0.024785397877925   7: 0.024785365030891   9: 0.024785261614581 

training_1785     6: 0.753311255412347   0: 0.110324644270528   9: 0.017064093302972   5: 0.017043322087087   8: 0.017043078178626   7: 0.017043048463857   1: 0.017043028066596   3: 0.017042518294494   2: 0.017042506824439   4: 0.017042505099053 

training_1787     1: 0.596312395950739   0: 0.252534561482671   3: 0.047723018263595   5: 0.014780472526578   6: 0.014776792766571   9: 0.014775633071892   8: 0.014774987098678   2: 0.014774911351312   4: 0.014774480026349   7: 0.014772747461615 

training_1789     5: 0.380693445994925   6: 0.312274737624199   4: 0.183325938670795   9: 0.045509202927139   1: 0.013065227454121   0: 0.013028371782088   2: 0.013027290781371   8: 0.013026183539059   7: 0.013025303258922   3: 0.013024297967380 

training_179      6: 0.727631566014637   0: 0.171437709386068   1: 0.039573238011405   7: 0.008781620513176   5: 0.008771451862533   3: 0.008761215692189   4: 0.008761190503917   9: 0.008761185471513   8: 0.008760426569542   2: 0.008760395975020 

training_1790     5: 0.653670160649578   0: 0.148231125287617   7: 0.056508090780556   8: 0.020231861549006   6: 0.020229758993620   1: 0.020229352369510   4: 0.020226335819766   9: 0.020225532107459   2: 0.020224110847406   3: 0.020223671595481 

training_1792     6: 0.707141648866363   5: 0.073741867367064   0: 0.063777488399424   7: 0.054384185705030   1: 0.028477162816140   8: 0.014509326080237   9: 0.014504986056350   3: 0.014489600343940   4: 0.014487248818258   2: 0.014486485547194 

training_1794     5: 0.463228539341682   0: 0.295839934935988   3: 0.083683920876545   7: 0.022477122278387   1: 0.022462163425707   6: 0.022461871501626   2: 0.022461736389747   4: 0.022461582029896   8: 0.022461579912139   9: 0.022461549308282 

training_1797     5: 0.765776869065214   3: 0.026025453067497   4: 0.026025282671129   1: 0.026024703406962   0: 0.026024678179706   2: 0.026024667438566   7: 0.026024598785017   6: 0.026024592208201   8: 0.026024585718169   9: 0.026024569459539 

training_1798     0: 0.335577007075108   4: 0.291321799934948   7: 0.237098698253210   2: 0.019441056388101   1: 0.019431034210566   5: 0.019429733308282   6: 0.019427339023496   9: 0.019425086768016   8: 0.019424616665131   3: 0.019423628373141 

training_1799     2: 0.751967543844519   6: 0.027562964256552   9: 0.027561519556120   5: 0.027559504995181   1: 0.027558984563463   0: 0.027558967161089   8: 0.027558433153377   4: 0.027557903030916   7: 0.027557451090164   3: 0.027556728348619 

training_18       0: 0.504611180056549   6: 0.265944049406941   8: 0.103342771536805   1: 0.026608333664943   5: 0.024173446418907   2: 0.024160061119872   4: 0.012842631493533   7: 0.012783193542812   3: 0.012767210793849   9: 0.012767121965788 

training_180      6: 0.799621240423413   0: 0.051032270081682   8: 0.040742235191936   5: 0.029186197921244   1: 0.026814714388348   7: 0.010599254727371   3: 0.010514717719573   9: 0.010501085801320   4: 0.010494233928155   2: 0.010494049816959 

training_1801     1: 0.631117154617889   2: 0.167573317040567   9: 0.056973288525592   7: 0.020629316756149   6: 0.020621623355643   0: 0.020620282747189   5: 0.020620156498645   8: 0.020616214755707   4: 0.020614708932264   3: 0.020613936770353 

training_1803     5: 0.686217843998822   0: 0.157531954339175   6: 0.019536882035089   4: 0.019531589926343   1: 0.019531102889021   2: 0.019530347424341   7: 0.019530178900631   3: 0.019530095529896   9: 0.019530017539171   8: 0.019529987417511 

training_1808     1: 0.561286229935784   6: 0.270232766851374   0: 0.064408296188568   4: 0.024760491662955   2: 0.013281506255693   5: 0.013212810860026   8: 0.013206245202986   7: 0.013204882418016   9: 0.013203991274972   3: 0.013202779349626 

training_1809     6: 0.812157720008791   1: 0.064252092333221   0: 0.053252668750926   7: 0.010064949168247   3: 0.010049334943436   9: 0.010045916333975   8: 0.010044645465263   5: 0.010044409151694   4: 0.010044136595676   2: 0.010044127248770 

training_1811     6: 0.805333890609835   1: 0.044907966055603   3: 0.041090794546062   0: 0.015524616939016   5: 0.015524279801650   9: 0.015524064968487   7: 0.015523774465187   4: 0.015523599772912   8: 0.015523573284122   2: 0.015523439557126 

training_1814     5: 0.463026877346354   3: 0.318477758788934   6: 0.027312591609569   4: 0.027312487974343   1: 0.027311976654551   0: 0.027311931940574   8: 0.027311764708951   7: 0.027311669454639   2: 0.027311478686583   9: 0.027311462835502 

training_1815     6: 0.679471131591815   0: 0.127922969196247   8: 0.072430974477847   9: 0.017169457982578   5: 0.017168827953123   7: 0.017167616844601   1: 0.017167425557201   4: 0.017167238870935   2: 0.017167193328745   3: 0.017167164196907 

training_1816     5: 0.349733723340246   6: 0.319298511011069   1: 0.093180066393349   4: 0.085398649286636   0: 0.049350076325672   9: 0.040189227156457   3: 0.015784467921523   7: 0.015699204879136   2: 0.015683071530681   8: 0.015683002155230 

training_1820     5: 0.459232804486705   7: 0.330813703248266   3: 0.026245522441565   4: 0.026244602160863   6: 0.026244019896462   0: 0.026243998265844   8: 0.026243990178497   1: 0.026243857821474   2: 0.026243812009084   9: 0.026243689491240 

training_1824     5: 0.619027408569213   8: 0.176853110761091   0: 0.025515691379423   2: 0.025515447276217   4: 0.025515311064037   9: 0.025514877490366   6: 0.025514749633636   3: 0.025514689295762   1: 0.025514536617181   7: 0.025514177913074 

training_183      5: 0.766491473192919   4: 0.025948957266105   8: 0.025945054891670   3: 0.025945027428188   1: 0.025944988757360   2: 0.025944987390328   6: 0.025944934518024   7: 0.025944903630876   9: 0.025944836634275   0: 0.025944836290255 

training_1832     0: 0.484248399351606   2: 0.216758277927883   1: 0.135624332331625   9: 0.053359834116390   6: 0.018391932367262   5: 0.018337194422927   4: 0.018322795343599   8: 0.018321076186838   7: 0.018318216286550   3: 0.018317941665319 

training_1835     1: 0.326214627785658   8: 0.288524840955947   7: 0.246860917012975   6: 0.020063091290762   9: 0.019749241408191   0: 0.019747361783156   5: 0.019713783847034   4: 0.019709541832105   2: 0.019708499891943   3: 0.019708094192228 

training_1836     6: 0.664899175350837   1: 0.134402907672213   0: 0.120026664435858   5: 0.012408344901900   9: 0.011381941468577   7: 0.011381555084955   2: 0.011374975047723   8: 0.011374956708389   3: 0.011374750354672   4: 0.011374728974876 

training_1837     4: 0.641907834206714   8: 0.156270472580364   5: 0.025232303646313   6: 0.025228587032578   7: 0.025228482548855   2: 0.025227635345472   9: 0.025227331401779   1: 0.025225904148020   3: 0.025225753262027   0: 0.025225695827879 

training_1839     6: 0.837423946528334   3: 0.044235654457683   0: 0.014797904280624   1: 0.014792415417422   5: 0.014792378469118   4: 0.014791651796340   8: 0.014791604718446   9: 0.014791505761885   7: 0.014791500544955   2: 0.014791438025195 

training_1842     6: 0.762978922928034   1: 0.051521562561742   8: 0.047397465171637   7: 0.043885221814613   0: 0.015716325825757   5: 0.015703374449645   4: 0.015699603208973   9: 0.015699512762066   3: 0.015699011966536   2: 0.015698999310997 

training_1843     6: 0.568440369941852   7: 0.244788826225121   5: 0.023348054477090   0: 0.023346780919524   8: 0.023346616006059   3: 0.023346426578499   1: 0.023346263915489   9: 0.023345689402501   4: 0.023345556514603   2: 0.023345416019262 

training_1845     6: 0.752706441801221   0: 0.123895521261643   1: 0.031586487869321   8: 0.013149843526799   7: 0.013132659837261   9: 0.013121953037919   5: 0.013102316289814   3: 0.013101692343669   4: 0.013101570143930   2: 0.013101513888424 

training_1846     5: 0.758142390425476   0: 0.093446465126900   4: 0.018553496630350   6: 0.018551511795620   1: 0.018551313735466   2: 0.018551042004235   3: 0.018550991278074   8: 0.018550982292739   9: 0.018550913866821   7: 0.018550892844319 

training_1847     4: 0.380799199405581   7: 0.213000059986292   0: 0.197921386634248   2: 0.096531251865727   1: 0.018629170296210   6: 0.018627356411110   5: 0.018626922176317   9: 0.018621835007252   8: 0.018621708113586   3: 0.018621110103678 

training_1848     6: 0.813703199048854   1: 0.060577526487215   0: 0.039849114941103   9: 0.012271109337288   2: 0.012267249312881   4: 0.012266830101078   5: 0.012266538711565   8: 0.012266432311653   7: 0.012266013461538   3: 0.012265986286825 

training_1849     5: 0.698576922169409   3: 0.129445604101878   4: 0.021500526240846   1: 0.021496951764056   0: 0.021496940722518   6: 0.021496772523125   2: 0.021496709971793   8: 0.021496601844462   9: 0.021496514711577   7: 0.021496455950336 

training_185      2: 0.807438025874148   6: 0.021442202831045   7: 0.021422724791198   4: 0.021411717510914   1: 0.021391303070564   5: 0.021389542558030   0: 0.021381092889121   3: 0.021379225052664   9: 0.021372768177282   8: 0.021371397245034 

training_1851     2: 0.562066852040220   7: 0.204405965696487   5: 0.029197849012613   4: 0.029191620899296   9: 0.029190829438522   1: 0.029190091515662   6: 0.029189743420420   0: 0.029189337894548   8: 0.029189235188123   3: 0.029188474894110 

training_1853     5: 0.547554276527857   9: 0.180673807356976   3: 0.111549016043068   6: 0.022894252490076   4: 0.022891311514289   1: 0.022888383434791   0: 0.022887788630420   7: 0.022887575784765   8: 0.022886978514694   2: 0.022886609703065 

training_1855     6: 0.739564146638108   1: 0.028944472459023   0: 0.028937985685084   5: 0.028937960847181   4: 0.028936616989828   2: 0.028936310896430   9: 0.028935733720001   3: 0.028935691678832   8: 0.028935564810941   7: 0.028935516274573 

training_1856     6: 0.429123121500149   7: 0.425642233265717   2: 0.018161472342995   9: 0.018156810693762   5: 0.018156654883667   4: 0.018153585803374   0: 0.018152421610062   8: 0.018152066944118   1: 0.018151926698749   3: 0.018149706257409 

training_1858     6: 0.637707507783796   0: 0.149265006939931   8: 0.120149399889514   1: 0.013269676101169   5: 0.013269049664690   9: 0.013268173306885   7: 0.013267977936267   4: 0.013267856185420   2: 0.013267704049382   3: 0.013267648142945 

training_186      5: 0.748043183752958   0: 0.028001532933914   1: 0.027996733342690   6: 0.027996123682514   4: 0.027995051593533   8: 0.027994614586976   9: 0.027993510793131   7: 0.027993439474715   2: 0.027993230246146   3: 0.027992579593423 

training_1860     1: 0.517814533297110   6: 0.271088360393022   5: 0.073942581379928   7: 0.051464336721109   0: 0.024929255031204   8: 0.012884158625412   3: 0.011973031882290   4: 0.011968608809561   9: 0.011968008410505   2: 0.011967125449859 

training_1861     5: 0.748328262448273   7: 0.093185809726631   4: 0.019816633874986   1: 0.019810130662062   0: 0.019810049530598   6: 0.019809894658226   8: 0.019809851497683   2: 0.019809796198535   9: 0.019809793612399   3: 0.019809777790606 

training_1862     6: 0.795679705805864   1: 0.040066293208189   0: 0.020634505252244   5: 0.020581647563106   7: 0.020565579481451   3: 0.020503228159124   8: 0.020493777347482   4: 0.020491782913350   9: 0.020491750407784   2: 0.020491729861406 

training_1863     6: 0.748794836230396   0: 0.089621241655821   3: 0.046982454448558   1: 0.016375615982585   5: 0.016372397677455   9: 0.016371150284116   4: 0.016370647280790   8: 0.016370631839444   7: 0.016370602902915   2: 0.016370421697920 

training_187      4: 0.791721288570780   5: 0.023150096258662   1: 0.023142438634980   0: 0.023141932627395   6: 0.023141304760366   9: 0.023140629346294   7: 0.023140599289600   2: 0.023140584661095   8: 0.023140567672313   3: 0.023140558178515 

training_1871     6: 0.676486553876160   0: 0.098964815059982   5: 0.083564487728400   8: 0.020144083915032   1: 0.020140786253175   9: 0.020140775982428   2: 0.020139838220389   7: 0.020139618454425   4: 0.020139581537847   3: 0.020139458972162 

training_1872     4: 0.730876377026384   5: 0.119876660781820   1: 0.018666910744935   6: 0.018658374759966   0: 0.018657282289116   8: 0.018655979096613   2: 0.018652720853712   9: 0.018652068726118   7: 0.018651853066594   3: 0.018651772654742 

training_1873     5: 0.765771863241215   4: 0.026025697819050   6: 0.026025683285632   3: 0.026025630232098   1: 0.026025424291550   0: 0.026025305201907   8: 0.026025120003970   2: 0.026025114650520   7: 0.026025090798340   9: 0.026025070475719 

training_1875     2: 0.847078476271316   6: 0.017023555336628   7: 0.016991956060014   5: 0.016990769873272   1: 0.016988344554279   0: 0.016988034646432   8: 0.016985363977580   9: 0.016984938548578   4: 0.016984806334172   3: 0.016983754397730 

training_1877     5: 0.794162877557875   4: 0.022875500024974   8: 0.022871723575322   6: 0.022871658284799   1: 0.022871011423375   0: 0.022870030995029   9: 0.022869970001801   7: 0.022869157192842   2: 0.022869051634136   3: 0.022869019309849 

training_1878     6: 0.630359736005974   7: 0.243925096451626   5: 0.015716998807880   9: 0.015716597581633   2: 0.015716538140710   4: 0.015715111195455   8: 0.015713230184918   0: 0.015712873451361   1: 0.015712398831869   3: 0.015711419348575 

training_1880     6: 0.695084181539247   8: 0.100978831954574   0: 0.077174045092363   1: 0.037584553883397   4: 0.014866809177366   5: 0.014865904538081   3: 0.014862307009694   7: 0.014861438431166   9: 0.014861061381141   2: 0.014860866992971 

training_1882     6: 0.683794723829436   0: 0.132442997859606   5: 0.063124369521274   8: 0.031578978151869   7: 0.014938590976138   9: 0.014920917114610   4: 0.014829808336000   3: 0.014791956553248   1: 0.014790132365061   2: 0.014787525292758 

training_1885     6: 0.678432507625380   5: 0.134948761819348   0: 0.044387871520225   8: 0.041774000963496   1: 0.016764382558547   9: 0.016746239675611   4: 0.016736888127228   7: 0.016736552845748   2: 0.016736422951242   3: 0.016736371913176 

training_1886     6: 0.485605136407218   2: 0.242421968032837   5: 0.152974243926681   9: 0.017009332850692   1: 0.017003242280865   0: 0.016999388803919   4: 0.016997955460354   3: 0.016996975190813   8: 0.016996130051635   7: 0.016995626994986 

training_1889     6: 0.744327715619279   1: 0.116593125873047   0: 0.042061050185248   4: 0.036580012684173   3: 0.013212022407482   7: 0.009450207331872   5: 0.009447316423103   8: 0.009444548587583   9: 0.009443383684084   2: 0.009440617204128 

training_189      1: 0.756267798121010   6: 0.027095657149676   2: 0.027094679641207   7: 0.027078913596729   9: 0.027078507402108   5: 0.027078494355308   8: 0.027077181822546   0: 0.027076509617231   4: 0.027076168878015   3: 0.027076089416171 

training_1890     6: 0.588528009217448   7: 0.273633740378150   5: 0.017284119787324   9: 0.017238702289318   8: 0.017228941330320   4: 0.017218874323532   0: 0.017217558249423   3: 0.017216831355762   1: 0.017216784928145   2: 0.017216438140578 

training_1897     6: 0.622202090577418   1: 0.272494442894761   0: 0.013286962501679   7: 0.013162867481726   9: 0.013145859940915   5: 0.013142763071615   8: 0.013142264034539   4: 0.013141141860610   3: 0.013140845694903   2: 0.013140761941832 

training_1898     6: 0.528271269577305   8: 0.329199014251036   5: 0.017817857638281   0: 0.017817607806166   1: 0.017816922015351   9: 0.017816630933634   4: 0.017815347756231   3: 0.017815183581621   7: 0.017815107967148   2: 0.017815058473227 

training_19       6: 0.514839596987086   0: 0.345339050576630   5: 0.017480454374134   1: 0.017477849729663   4: 0.017477311652078   2: 0.017477310462491   3: 0.017477206463191   7: 0.017477135382662   8: 0.017477120293917   9: 0.017476964078148 

training_1901     6: 0.670216137790612   8: 0.108627126683061   7: 0.085912907148558   9: 0.060907598108841   0: 0.012426403937604   5: 0.012386973473897   1: 0.012385606095017   4: 0.012379966849832   3: 0.012378711880729   2: 0.012378568031849 

training_1902     6: 0.597061081660472   1: 0.286772655354794   8: 0.020223802987975   5: 0.019420002456594   2: 0.012884721982341   9: 0.012754494845613   4: 0.012732561354287   0: 0.012719371863365   7: 0.012716268408205   3: 0.012715039086353 

training_1904     6: 0.626673506645859   1: 0.203427232428916   3: 0.039465051534473   5: 0.028939222088179   0: 0.027408167261447   9: 0.014874414153678   8: 0.014803566397487   7: 0.014803011245109   2: 0.014802937183031   4: 0.014802891061821 

training_1907     6: 0.826769394313238   5: 0.019249321578852   7: 0.019248325424826   4: 0.019247886485030   8: 0.019247755131584   0: 0.019247752214694   9: 0.019247713228807   1: 0.019247652382408   2: 0.019247114509393   3: 0.019247084731169 

training_1909     6: 0.598531573697180   1: 0.123593599369025   2: 0.095018792780538   0: 0.067512305979457   4: 0.045290453613048   5: 0.014011548138187   8: 0.014011260786268   9: 0.014010440559643   7: 0.014010205603306   3: 0.014009819473347 

training_191      2: 0.359998468670497   6: 0.277620996985036   1: 0.189452536912567   3: 0.062610464884177   5: 0.018393796750891   4: 0.018387025445622   8: 0.018385364483866   9: 0.018384619235141   0: 0.018383596948835   7: 0.018383129683367 

training_1910     6: 0.528912293497631   7: 0.244522621052927   9: 0.028321269039401   5: 0.028321071903389   8: 0.028320984865913   0: 0.028320841011328   4: 0.028320491529772   1: 0.028320253806561   3: 0.028320188135546   2: 0.028319985157531 

training_1912     6: 0.837109272817694   8: 0.018104161420837   9: 0.018101156461593   0: 0.018099906519811   7: 0.018098419102797   5: 0.018098016381998   1: 0.018097496546692   2: 0.018097226299190   4: 0.018097210576566   3: 0.018097133872824 

training_1913     6: 0.647210854382534   3: 0.136127567669206   7: 0.089124376330737   8: 0.018222214669746   9: 0.018220055866614   0: 0.018219845333771   5: 0.018219394782456   1: 0.018219203356082   2: 0.018218270392247   4: 0.018218217216607 

training_1915     6: 0.620832150164875   7: 0.244937309751256   0: 0.029029136771302   4: 0.015527499974979   1: 0.014948011391380   5: 0.014947161089344   9: 0.014946420743720   8: 0.014945249438002   2: 0.014943532405907   3: 0.014943528269233 

training_1917     6: 0.564495266622907   3: 0.211260174081789   1: 0.072891336172904   5: 0.021636699010502   0: 0.021635078469485   4: 0.021625666370586   9: 0.021616877705442   2: 0.021614186721103   8: 0.021614072336057   7: 0.021610642509225 

training_1918     6: 0.730891582593867   1: 0.130241616518750   2: 0.031298585778202   3: 0.015386416915521   0: 0.015366959093486   7: 0.015366193752951   5: 0.015364966360695   4: 0.015362200996103   8: 0.015360876599033   9: 0.015360601391392 

training_1919     6: 0.432763323855422   0: 0.397335359909966   9: 0.046245512124940   8: 0.044245316371490   1: 0.033647792147235   3: 0.009361487314258   4: 0.009215891158571   5: 0.009067914775743   2: 0.009058804463479   7: 0.009058597878897 

training_1920     0: 0.517642534893397   6: 0.201088216309013   5: 0.171697904263073   1: 0.015717502903870   7: 0.015659886841111   3: 0.015641713751343   2: 0.015638083501542   8: 0.015638070629676   4: 0.015638054413732   9: 0.015638032493242 

training_1924     6: 0.562723933253444   9: 0.259240996400942   5: 0.022297577910581   4: 0.022286539659017   3: 0.022244628545961   0: 0.022242656098622   1: 0.022242262539418   8: 0.022241980203503   2: 0.022239946258820   7: 0.022239479129693 

training_1926     6: 0.754582154565705   0: 0.105028071512438   1: 0.054602970768921   9: 0.028854950876255   5: 0.013129507545788   7: 0.008764883354136   4: 0.008759837585614   3: 0.008759528578589   8: 0.008759287540123   2: 0.008758807672432 

training_1929     6: 0.522467871528479   7: 0.324848908067883   9: 0.019092497466039   5: 0.019085419474419   1: 0.019085035145506   0: 0.019084647454150   4: 0.019084528672047   3: 0.019083961558649   8: 0.019083606166154   2: 0.019083524466673 

training_193      6: 0.719563897073944   3: 0.081914467432805   5: 0.074918795096073   0: 0.029413721414616   1: 0.015708888120415   8: 0.015696826685351   2: 0.015695968391583   7: 0.015695853510732   4: 0.015695798522379   9: 0.015695783752103 

training_1931     9: 0.830395197290941   6: 0.046240398774923   1: 0.015423345011009   8: 0.015421016802284   5: 0.015420902541529   0: 0.015420731005415   4: 0.015419956470535   7: 0.015419508232658   2: 0.015419495943981   3: 0.015419447926724 

training_1932     6: 0.802581817327244   1: 0.021942617624035   9: 0.021935228895581   5: 0.021935210605492   0: 0.021934613170587   7: 0.021934592853931   8: 0.021934288242749   4: 0.021933942978307   2: 0.021933855372247   3: 0.021933832929827 

training_1933     6: 0.635799170103569   0: 0.259373442136223   5: 0.022804119806870   9: 0.011719599868668   8: 0.011718187356699   1: 0.011717525232654   7: 0.011717208063450   2: 0.011717010984923   4: 0.011716895544034   3: 0.011716840902911 

training_1934     6: 0.819884739530626   2: 0.041662030133649   8: 0.017312399171183   5: 0.017307376850985   0: 0.017305972876689   1: 0.017305934437523   4: 0.017305604554457   7: 0.017305481344722   3: 0.017305285816383   9: 0.017305175283783 

training_194      2: 0.764591719192797   5: 0.090897570525310   6: 0.018074199662026   0: 0.018066314040865   1: 0.018063495790468   7: 0.018062939600280   4: 0.018061939283597   9: 0.018061425949974   8: 0.018060555087945   3: 0.018059840866737 

training_1940     6: 0.871546045844026   0: 0.025386370246749   9: 0.012892367334705   1: 0.012885177001739   8: 0.012884190631413   5: 0.012882043671985   4: 0.012881018322732   3: 0.012881009798034   7: 0.012880901512565   2: 0.012880875636052 

training_1942     6: 0.772819147204102   1: 0.051360040026116   0: 0.048486047199469   2: 0.027667485622536   5: 0.027353107049221   9: 0.014609950830352   8: 0.014430156814837   3: 0.014427802694778   4: 0.014423181798262   7: 0.014423080760328 

training_1943     9: 0.751498944585889   4: 0.105840941440732   1: 0.017870123342023   6: 0.017868226300249   0: 0.017841643963534   8: 0.017819486440505   5: 0.017818774972065   3: 0.017814154462143   7: 0.017813967893315   2: 0.017813736599544 

training_1946     6: 0.694844078923893   0: 0.149902189510593   8: 0.048977225889081   9: 0.015185350516348   5: 0.015183771762459   1: 0.015182164813744   7: 0.015181814554080   2: 0.015181682522552   4: 0.015181185624469   3: 0.015180535882780 

training_1948     6: 0.815190513191523   1: 0.054886015652467   0: 0.026871292033088   5: 0.014786807847118   2: 0.014753553060493   3: 0.014729412693598   9: 0.014699258204946   4: 0.014695547184525   8: 0.014694009738038   7: 0.014693590394204 

training_1949     6: 0.705182602172898   0: 0.140587733840753   9: 0.056745383202219   7: 0.013930932407155   1: 0.013927312097371   8: 0.013926196769660   5: 0.013925515608128   4: 0.013924925227940   2: 0.013924906492608   3: 0.013924492181270 

training_1951     6: 0.481738012872984   0: 0.212185941188135   1: 0.140132359355343   9: 0.057434629273042   5: 0.050028585912569   3: 0.011696383862040   8: 0.011696304566409   2: 0.011695963592254   7: 0.011695913134265   4: 0.011695906242959 

training_1952     6: 0.663924457510786   5: 0.191045611986928   0: 0.018130508031629   8: 0.018129996295712   1: 0.018129799238693   7: 0.018128320057982   9: 0.018128300574251   4: 0.018127823009902   2: 0.018127766832467   3: 0.018127416461649 

training_1959     6: 0.619207453321923   0: 0.286117403364264   1: 0.023180581447237   7: 0.015765794425726   5: 0.009292602580091   9: 0.009287751721101   3: 0.009287306329510   8: 0.009287128654798   4: 0.009286995798427   2: 0.009286982356925 

training_196      4: 0.735294835966431   5: 0.029417985662999   6: 0.029415121365506   9: 0.029412284981131   8: 0.029412268623615   0: 0.029410251476010   7: 0.029409632547275   1: 0.029409341997566   2: 0.029409309272704   3: 0.029408968106761 

training_1960     6: 0.628501525852389   4: 0.137102737120570   9: 0.082278601636634   3: 0.052501166385648   1: 0.030692526153656   0: 0.013851108482951   5: 0.013777441268796   8: 0.013771712562510   7: 0.013761878679269   2: 0.013761301857577 

training_1961     6: 0.514044905547975   9: 0.274197057243856   5: 0.026532746931746   4: 0.026515884038549   8: 0.026455259121388   7: 0.026451532652230   3: 0.026451386575549   2: 0.026451259645693   0: 0.026451162235461   1: 0.026448806007552 

training_1963     6: 0.748030409279717   0: 0.094498954576171   1: 0.072533893864642   8: 0.027959910820820   3: 0.015018446743708   9: 0.008401804211412   5: 0.008395143431437   4: 0.008387449368377   7: 0.008387143801361   2: 0.008386843902355 

training_1964     6: 0.518244654043776   9: 0.285886081009299   7: 0.078773184405769   0: 0.024449416252406   8: 0.015459129114352   1: 0.015445950521254   5: 0.015436999114015   4: 0.015435218240561   3: 0.015434814673766   2: 0.015434552624803 

training_1965     6: 0.814195953696976   5: 0.020650094421147   4: 0.020648218791608   9: 0.020644351781699   0: 0.020644064546236   7: 0.020643713360082   1: 0.020643650927476   8: 0.020643591699145   2: 0.020643272348683   3: 0.020643088426947 

training_1966     6: 0.417718311034209   8: 0.321349176573765   0: 0.134317878399753   1: 0.018093149209816   7: 0.018089029336395   5: 0.018088189644869   9: 0.018087194214131   4: 0.018086212938753   3: 0.018085533115068   2: 0.018085325533240 

training_1967     6: 0.733137683849813   0: 0.122902173984272   3: 0.065166062140652   1: 0.011295856206736   9: 0.011253583024210   8: 0.011252872713245   5: 0.011248511621966   7: 0.011247929186363   4: 0.011247839243906   2: 0.011247488028836 

training_197      6: 0.712793749013676   7: 0.072773896851699   8: 0.069591980509274   5: 0.047977851517286   9: 0.016310707459433   1: 0.016129256210030   0: 0.016113160217192   3: 0.016107486172528   4: 0.016100981264092   2: 0.016100930784791 

training_1970     6: 0.552362189075602   8: 0.290994762588808   5: 0.042361141288996   0: 0.016333243515355   1: 0.016333039256603   7: 0.016327503002858   9: 0.016324156080887   3: 0.016321959115365   4: 0.016321192840362   2: 0.016320813235164 

training_1971     6: 0.828867653651670   0: 0.019020855615575   5: 0.019016618013247   3: 0.019015064480233   1: 0.019013619204837   7: 0.019013614701623   9: 0.019013498842376   8: 0.019013424434002   4: 0.019013061746157   2: 0.019012589310277 

training_1975     6: 0.470755643240235   0: 0.324632550276400   2: 0.081121493891628   5: 0.017642450638597   1: 0.017641960935366   7: 0.017641428107043   9: 0.017641332404316   4: 0.017641093115631   8: 0.017641079505485   3: 0.017640967885298 

training_1976     6: 0.445351250201679   9: 0.330129856988094   4: 0.107762939644738   7: 0.016867044932198   0: 0.016710619368024   2: 0.016666230411025   5: 0.016643335667007   1: 0.016635462920364   8: 0.016618934266166   3: 0.016614325600704 

training_198      6: 0.654360658798542   9: 0.163812929494463   5: 0.039374254544285   8: 0.033602658170154   7: 0.018761133138153   0: 0.018019033208727   4: 0.018017604267194   1: 0.018017533872958   2: 0.018017135592302   3: 0.018017058913221 

training_1980     6: 0.654828029702289   1: 0.129307653467842   8: 0.060632991914203   7: 0.042202388097175   9: 0.018846305928618   4: 0.018836996189694   0: 0.018836764928327   5: 0.018836457650411   2: 0.018836254451035   3: 0.018836157670405 

training_1982     6: 0.430053398395853   1: 0.408760164307459   0: 0.020161699700866   8: 0.020149241218099   9: 0.020148470130786   5: 0.020147649694969   7: 0.020145393535358   2: 0.020144853644059   4: 0.020144734334694   3: 0.020144395037856 

training_1983     6: 0.693230692876462   2: 0.115751236773144   0: 0.023878721100809   5: 0.023878675093150   9: 0.023878096434687   8: 0.023877871167086   7: 0.023876879442999   1: 0.023876645729014   3: 0.023876076655619   4: 0.023875104727031 

training_1987     0: 0.628716901097174   5: 0.160189653781739   1: 0.026393128624032   6: 0.026389289925849   4: 0.026385989214133   9: 0.026385719872858   2: 0.026385043243185   7: 0.026385005965381   3: 0.026384743180019   8: 0.026384525095629 

training_1989     6: 0.756875764736890   1: 0.027024361862102   0: 0.027016980357945   2: 0.027012475909211   5: 0.027012395989029   4: 0.027011885787899   9: 0.027011822364402   7: 0.027011517507168   3: 0.027011446341244   8: 0.027011349144110 

training_199      4: 0.529167695189695   5: 0.272201010217997   1: 0.024838842080819   6: 0.024831953029058   0: 0.024831366239787   9: 0.024827680079831   8: 0.024826909804908   2: 0.024825015956771   7: 0.024824974043438   3: 0.024824553357695 

training_1990     6: 0.751810243000090   1: 0.104671932903026   9: 0.044941705328157   0: 0.023314078494156   7: 0.012805967033835   8: 0.012511364732119   3: 0.012503744396311   5: 0.012486906812509   4: 0.012477051363608   2: 0.012477005936188 

training_1994     0: 0.598027875526818   6: 0.164021035911062   1: 0.124028494474262   9: 0.016895256297902   4: 0.016188888991664   5: 0.016172083885797   8: 0.016169691370262   2: 0.016165927966509   7: 0.016165689762168   3: 0.016165055813556 

training_1995     6: 0.831775475877092   0: 0.048941039508711   1: 0.034633736489980   4: 0.012098088485062   5: 0.012096147191322   9: 0.012091581454072   8: 0.012091312061377   2: 0.012090959713203   7: 0.012090876235215   3: 0.012090782983966 

training_1996     6: 0.686893041167250   1: 0.152574439019655   8: 0.038269616801107   0: 0.026937655533074   7: 0.019837657696433   3: 0.015243930247262   5: 0.015066997738314   2: 0.015059438709548   4: 0.015058728334738   9: 0.015058494752618 

training_200      6: 0.556730591474074   8: 0.259089793419808   5: 0.077623200586489   0: 0.035986977815090   1: 0.011802651049413   7: 0.011757682549133   9: 0.011752740971226   2: 0.011752282978232   4: 0.011752054635239   3: 0.011752024521296 

training_2000     6: 0.550733504576048   7: 0.312461825132499   5: 0.017120099340381   4: 0.017099978188390   8: 0.017099928047069   3: 0.017098326418678   1: 0.017097618728630   9: 0.017097323978286   0: 0.017096244475049   2: 0.017095151114969 

training_2001     6: 0.820353326889187   1: 0.052552862034572   0: 0.029244937081887   9: 0.014014874193781   5: 0.013978480506149   7: 0.013976969038265   4: 0.013973619005042   8: 0.013970490800986   3: 0.013967873903718   2: 0.013966566546413 

training_2003     6: 0.704820845897120   0: 0.125634592484874   5: 0.046626789867606   8: 0.017569444567843   2: 0.017558724092183   1: 0.017558526310902   4: 0.017557899421496   7: 0.017557808997398   3: 0.017557718149984   9: 0.017557650210595 

training_2004     2: 0.621558441109140   0: 0.174610739679769   5: 0.025483851968048   6: 0.025480888269180   4: 0.025479542080712   1: 0.025478250090294   8: 0.025477850109280   7: 0.025477149580548   9: 0.025477059865021   3: 0.025476227248008 

training_2005     5: 0.707387174542613   4: 0.129288303121981   6: 0.020416079043390   7: 0.020415731192990   8: 0.020415613410871   9: 0.020415549493472   3: 0.020415463608401   1: 0.020415375720327   2: 0.020415356793255   0: 0.020415353072699 

training_2006     6: 0.710063287484547   4: 0.070183726297447   0: 0.057790706859972   2: 0.045699939603740   7: 0.019418672571938   1: 0.019377591638589   5: 0.019371703035813   8: 0.019365554303999   9: 0.019364485457001   3: 0.019364332746955 

training_2007     1: 0.421781447131108   2: 0.402547050160570   6: 0.022103291832589   8: 0.021947592097142   5: 0.021946656974072   0: 0.021937889926899   9: 0.021937509850015   4: 0.021935147375416   7: 0.021932279018400   3: 0.021931135633789 

training_2008     6: 0.783130085181532   5: 0.055237190713660   0: 0.020205678994327   1: 0.020204704918812   4: 0.020203974780824   3: 0.020203832136210   9: 0.020203767839826   2: 0.020203641020879   7: 0.020203602475899   8: 0.020203521938029 

training_201      5: 0.471001622038086   2: 0.218223277923668   8: 0.127728565858076   1: 0.026167796785734   4: 0.026152780841815   9: 0.026145600893228   3: 0.026145279260437   6: 0.026145152647018   7: 0.026145011269971   0: 0.026144912481967 

training_2010     6: 0.426640365817718   3: 0.286154730868845   1: 0.175783668269209   2: 0.042581474175257   4: 0.011661410091927   0: 0.011448418812305   9: 0.011437134848550   5: 0.011433150721780   7: 0.011429846978563   8: 0.011429799415846 

training_2012     6: 0.593018837450150   1: 0.265232158224739   5: 0.032316424010319   9: 0.015646716665666   2: 0.015642887618666   0: 0.015631288167012   8: 0.015629413899679   7: 0.015628673932359   3: 0.015626828443864   4: 0.015626771587547 

training_2013     6: 0.483952883807131   0: 0.399360811224900   1: 0.014627328178091   5: 0.014582427377753   8: 0.014581576500414   3: 0.014581362569707   4: 0.014579400721689   9: 0.014578335477456   2: 0.014578021253910   7: 0.014577852888950 

training_2016     5: 0.563104018066750   6: 0.249160417969097   4: 0.023474768036698   8: 0.023466131323043   3: 0.023465898314716   2: 0.023465772340097   1: 0.023465759444939   9: 0.023465753036788   0: 0.023465749082500   7: 0.023465732385371 

training_202      5: 0.809960838394253   4: 0.021119707680293   8: 0.021115022486088   7: 0.021114993484214   9: 0.021114961092933   6: 0.021114958890836   0: 0.021114917984580   3: 0.021114897677566   1: 0.021114871701805   2: 0.021114830607433 

training_2020     5: 0.691928479976254   1: 0.113747009951670   0: 0.024295452606912   8: 0.024294699049510   9: 0.024290215901212   6: 0.024290173402209   4: 0.024289689680256   3: 0.024288673970950   7: 0.024287985959722   2: 0.024287619501305 

training_2022     9: 0.497301448532147   6: 0.368998530989761   8: 0.016719628243085   5: 0.016713864743244   0: 0.016713256698679   1: 0.016713201756464   4: 0.016710268586552   2: 0.016710013594604   7: 0.016709983363289   3: 0.016709803492175 

training_2024     0: 0.828116908953140   1: 0.040018112902299   6: 0.016485693712593   5: 0.016484890711219   4: 0.016482602844614   8: 0.016482557780560   2: 0.016482429090158   7: 0.016482334102899   9: 0.016482333885124   3: 0.016482136017395 

training_2025     6: 0.787395189270517   0: 0.096242637419837   1: 0.024697889504245   5: 0.013562693009432   4: 0.013062018202388   9: 0.013008269096839   8: 0.013007913171756   7: 0.013007833266531   3: 0.013007782636921   2: 0.013007774421535 

training_2026     4: 0.831946972880039   1: 0.018680204116876   5: 0.018677087791968   0: 0.018675289412578   6: 0.018672666798220   2: 0.018670587348690   3: 0.018669554631172   8: 0.018669469026438   7: 0.018669321137243   9: 0.018668846856776 

training_2027     0: 0.762246279319639   5: 0.026434453035773   6: 0.026422419083187   1: 0.026419135572465   2: 0.026414703248041   9: 0.026412973427529   4: 0.026412905699815   3: 0.026412407495369   7: 0.026412395097188   8: 0.026412328020993 

training_2028     5: 0.811654190052218   0: 0.054877121001213   1: 0.016686890605704   6: 0.016686469126222   4: 0.016685544475251   3: 0.016682584979127   9: 0.016682087220991   8: 0.016682042025161   7: 0.016681623572347   2: 0.016681446941767 

training_2029     5: 0.499814522747813   6: 0.233523333079145   1: 0.116106573759382   7: 0.021509459690273   8: 0.021509154020410   4: 0.021508658157491   0: 0.021507437178998   3: 0.021507249094810   9: 0.021506982523131   2: 0.021506629748545 

training_203      6: 0.346993273283302   8: 0.304328739958377   0: 0.275607253062684   1: 0.016865669907825   4: 0.012762957831517   5: 0.008704963275899   7: 0.008687461846747   9: 0.008683557040301   3: 0.008683240452964   2: 0.008682883340384 

training_2033     4: 0.790162947064894   8: 0.064424410274190   5: 0.018183350833909   0: 0.018178386268891   6: 0.018175951972965   1: 0.018175831002872   9: 0.018175044229903   3: 0.018174857802955   2: 0.018174647319341   7: 0.018174573230081 

training_2035     5: 0.483766314459557   6: 0.238052749239756   4: 0.034774849750552   3: 0.034774575009563   0: 0.034773298412293   1: 0.034772948704819   7: 0.034771587643954   8: 0.034771310165734   2: 0.034771220205982   9: 0.034771146407790 

training_2039     2: 0.596462480218380   5: 0.150755701431752   7: 0.100615845513445   6: 0.021742344735574   0: 0.021741546961685   1: 0.021740374036733   4: 0.021736481744971   8: 0.021735373700609   9: 0.021735055256420   3: 0.021734796400432 

training_2042     5: 0.649965970199690   1: 0.154646481979082   4: 0.024426187254482   0: 0.024423460587243   6: 0.024423139457199   3: 0.024423056231071   2: 0.024423017785655   8: 0.024423013021235   9: 0.024422951390341   7: 0.024422722094002 

training_2044     6: 0.832457166637358   8: 0.018620525220686   1: 0.018615881635658   0: 0.018615807673285   7: 0.018615674520909   9: 0.018615362364351   2: 0.018614932156871   5: 0.018614925004503   4: 0.018614896969213   3: 0.018614827817166 

training_2046     2: 0.646611097379309   0: 0.112033603885886   6: 0.087119286917147   1: 0.048689493202646   7: 0.017654900375120   5: 0.017579652980949   8: 0.017578535681959   4: 0.017578515457857   9: 0.017577964826711   3: 0.017576949292416 

training_2047     5: 0.636813883528733   6: 0.176747026903131   1: 0.023310517856117   4: 0.023306803802176   3: 0.023305012843201   8: 0.023303405270427   0: 0.023303391327673   2: 0.023303341646323   9: 0.023303308612190   7: 0.023303308210030 

training_2048     5: 0.783118989280410   6: 0.076330228623592   4: 0.017571388514150   0: 0.017570886836494   1: 0.017569354360137   7: 0.017568584132722   9: 0.017567982161869   8: 0.017567865824841   3: 0.017567647759693   2: 0.017567072506090 

training_2049     5: 0.780944528011065   3: 0.024340362894505   4: 0.024339710049578   6: 0.024339431005300   8: 0.024339379273882   0: 0.024339374862749   7: 0.024339363117771   1: 0.024339334594221   2: 0.024339303699236   9: 0.024339212491692 

training_2054     0: 0.622134773817164   6: 0.175145868775724   2: 0.061594768112733   5: 0.042412919647444   1: 0.016532026616403   4: 0.016437531590779   8: 0.016436634787035   9: 0.016435559512962   3: 0.016435129730935   7: 0.016434787408820 

training_2055     5: 0.795437917669489   4: 0.022731472124071   1: 0.022729933932742   0: 0.022729875926880   6: 0.022729321178762   9: 0.022728579518563   8: 0.022728363366495   3: 0.022728221644859   7: 0.022728161810166   2: 0.022728152827973 

training_2056     5: 0.477818235498217   0: 0.362146228173716   6: 0.020008560280194   1: 0.020008151833217   8: 0.020003624221710   9: 0.020003443545651   4: 0.020003147136794   2: 0.020003108727985   7: 0.020002790941307   3: 0.020002709641209 

training_2061     6: 0.636364263031343   9: 0.185108067651585   1: 0.093496484171857   2: 0.032195008547318   0: 0.008823574509046   4: 0.008815270067514   5: 0.008812040904391   7: 0.008795765225916   8: 0.008795332455737   3: 0.008794193435293 

training_2064     6: 0.800067849503243   0: 0.109934203020167   1: 0.015419839343514   9: 0.015101851166052   5: 0.014947757966854   3: 0.008909341501690   7: 0.008908162302229   8: 0.008904481934036   2: 0.008903981049172   4: 0.008902532213044 

training_2065     3: 0.547392128379726   5: 0.233228189836147   6: 0.027429239939328   1: 0.027425087807067   0: 0.027423791192736   4: 0.027421086152740   8: 0.027420876827114   9: 0.027420737004454   2: 0.027419439178869   7: 0.027419423681820 

training_2067     6: 0.749067959106544   5: 0.027886287431647   0: 0.027885826984679   1: 0.027885480910699   4: 0.027880160123132   2: 0.027879265348460   7: 0.027879143718313   3: 0.027878785479880   8: 0.027878683175737   9: 0.027878407720909 

training_2073     1: 0.644827243540127   6: 0.215404223484741   7: 0.034094310481738   3: 0.015101024335055   5: 0.015097657488418   0: 0.015096095136099   4: 0.015095181139103   8: 0.015095179246580   9: 0.015094646798271   2: 0.015094438349868 

training_2074     6: 0.807143487498402   1: 0.062928326278949   2: 0.026698200592096   5: 0.026583660091216   0: 0.012783399354595   7: 0.012780827893260   8: 0.012772119818049   4: 0.012770163549550   9: 0.012770008856657   3: 0.012769806067227 

training_2079     5: 0.637362265099311   3: 0.076121857003880   0: 0.071967459023169   2: 0.065540699800388   8: 0.055495116187914   1: 0.018703006314922   6: 0.018702918528688   4: 0.018702405872191   9: 0.018702380867398   7: 0.018701891302139 

training_2080     1: 0.385825257136991   2: 0.375129304722846   7: 0.081945649487845   6: 0.044585348229933   3: 0.018812720824363   8: 0.018752956220915   5: 0.018739166694761   0: 0.018738535815811   9: 0.018736228507612   4: 0.018734832358923 

training_2087     6: 0.820939316764164   5: 0.040309281360514   0: 0.027709079008107   1: 0.026692628602609   8: 0.014073930819024   2: 0.014063068433914   9: 0.014053433662851   4: 0.014053103303374   3: 0.014053092674023   7: 0.014053065371421 

training_2089     5: 0.710670168056543   4: 0.032153723738838   8: 0.032147282456200   6: 0.032147122432058   3: 0.032147046742195   9: 0.032147014960327   2: 0.032146968649372   0: 0.032146944860968   7: 0.032146886960850   1: 0.032146841142647 

training_209      6: 0.787540688978473   0: 0.095619310278268   3: 0.046614691061291   1: 0.023471846183719   7: 0.007831544982796   9: 0.007786184538320   5: 0.007784848466098   4: 0.007784657243828   8: 0.007783208060297   2: 0.007783020206910 

training_2092     5: 0.793213927219952   4: 0.022980243714461   0: 0.022975904190278   8: 0.022975872883613   3: 0.022975732526059   7: 0.022975732424874   1: 0.022975688426209   9: 0.022975650181871   2: 0.022975624428488   6: 0.022975624004194 

training_2095     6: 0.760016016732621   5: 0.076462895078463   1: 0.047260495344502   0: 0.031357290171248   3: 0.014212841479305   8: 0.014145039005572   7: 0.014140711564287   9: 0.014138180472390   2: 0.014133270258407   4: 0.014133259893205 

training_2097     6: 0.740784294024164   9: 0.076268330940414   5: 0.075824206111604   0: 0.015312059701193   1: 0.015309101213401   4: 0.015301752057489   2: 0.015300788930902   3: 0.015300705439138   8: 0.015299581095275   7: 0.015299180486420 

training_2098     6: 0.474161109383226   5: 0.315436917165891   1: 0.026303504623921   8: 0.026302763668341   9: 0.026301275018225   7: 0.026300566830697   4: 0.026299821516194   0: 0.026299180274425   2: 0.026297535213767   3: 0.026297326305314 

training_2099     5: 0.697212959074584   4: 0.084057378411134   6: 0.080062429564035   2: 0.019828129649539   9: 0.019816434909078   1: 0.019815023389605   0: 0.019802868705897   8: 0.019801960667860   7: 0.019801433862585   3: 0.019801381765683 

training_210      4: 0.687304273974269   1: 0.131735099421286   5: 0.022626756795878   0: 0.022619365822003   8: 0.022619203000251   6: 0.022619176825208   9: 0.022619067987976   3: 0.022619064605662   2: 0.022619036887696   7: 0.022618954679771 

training_2101     5: 0.757338684321744   4: 0.026965869703291   8: 0.026962102284228   3: 0.026961984453607   2: 0.026961962508200   0: 0.026961914647225   6: 0.026961892565845   1: 0.026961876065283   9: 0.026961872971382   7: 0.026961840479195 

training_2102     3: 0.591373200756208   5: 0.205782696668638   6: 0.025454226792115   1: 0.025434190341763   9: 0.025339482595739   0: 0.025330916886139   2: 0.025323272833151   4: 0.025321938786849   7: 0.025320425420201   8: 0.025319648919198 

training_2107     6: 0.705033732403808   5: 0.137066253958253   9: 0.019755766208824   0: 0.019745567187546   1: 0.019737542877344   2: 0.019734103766005   4: 0.019732950906023   3: 0.019731498921347   7: 0.019731469427450   8: 0.019731114343400 

training_2108     6: 0.391201081493914   5: 0.246997378116613   1: 0.232222118949144   7: 0.028613056274113   8: 0.027919562502844   4: 0.014736569430419   0: 0.014598395485352   9: 0.014571233697636   2: 0.014570372919381   3: 0.014570231130585 

training_2109     5: 0.482425510976662   3: 0.294125788668368   6: 0.027938345068371   4: 0.027932209113684   1: 0.027932030546923   0: 0.027931695451857   9: 0.027929042265862   7: 0.027928767772342   8: 0.027928523927425   2: 0.027928086208506 

training_211      6: 0.398373301528972   5: 0.274885665371391   0: 0.173260869386060   4: 0.052763927136821   1: 0.016788934277478   8: 0.016787811445726   9: 0.016786444012463   2: 0.016786385787442   3: 0.016783378080284   7: 0.016783282973362 

training_2110     6: 0.694884080751603   0: 0.088186373945931   1: 0.075700961993254   5: 0.048074678519028   8: 0.024295144283078   9: 0.013780572321168   7: 0.013771849622002   4: 0.013769680647137   3: 0.013768348570179   2: 0.013768309346619 

training_2112     5: 0.807155748780332   4: 0.021431519830892   0: 0.021426885645013   1: 0.021426850116437   6: 0.021426752745013   9: 0.021426671084662   3: 0.021426668400404   2: 0.021426449896398   7: 0.021426233187206   8: 0.021426220313644 

training_2114     6: 0.437087427213095   5: 0.249173268666720   2: 0.167230198770300   1: 0.020934357575462   0: 0.020931701102170   3: 0.020929453316942   4: 0.020929436540156   9: 0.020928622797754   7: 0.020927813111551   8: 0.020927720905850 

training_2115     6: 0.774403216061219   1: 0.057369726351048   8: 0.056399444651907   7: 0.043626821146099   9: 0.011382935329378   0: 0.011376809588427   5: 0.011363189929142   4: 0.011361000237396   3: 0.011358670157511   2: 0.011358186547873 

training_2116     1: 0.411110281679682   6: 0.222520888597575   5: 0.164583063540207   3: 0.064403354297709   9: 0.045069081854863   4: 0.018469450918827   0: 0.018462945743365   8: 0.018460672891643   7: 0.018460387967438   2: 0.018459872508691 

training_2118     1: 0.539725032144879   6: 0.330276937183178   0: 0.049700039244539   8: 0.020204878654174   9: 0.010072822528243   3: 0.010024867999925   7: 0.010003652049389   5: 0.010000768244739   4: 0.009996676374349   2: 0.009994325576586 

training_212      4: 0.656559440867704   9: 0.121470425274158   7: 0.070746651430806   8: 0.021609926531413   5: 0.021608111131185   6: 0.021603090708030   0: 0.021601984883870   2: 0.021600521814970   3: 0.021599934325654   1: 0.021599913032209 

training_2121     6: 0.707705425220299   1: 0.165550309341751   0: 0.039325619359293   5: 0.022764136318177   9: 0.010869677705248   7: 0.010791042842604   8: 0.010749091597942   3: 0.010748458420763   2: 0.010748155190788   4: 0.010748084003136 

training_2122     1: 0.619468064539526   5: 0.157229728738259   4: 0.027921256044656   0: 0.027914950718737   6: 0.027912009999831   8: 0.027911979994749   7: 0.027911677896728   9: 0.027910983228568   3: 0.027910167186928   2: 0.027909181652017 

training_2126     2: 0.532477370054229   4: 0.226883424882538   6: 0.120673487561348   5: 0.017164127920599   0: 0.017139090438535   1: 0.017137107574142   8: 0.017131682920579   9: 0.017131617933113   7: 0.017131434730281   3: 0.017130655984634 

training_2128     6: 0.785949156755189   1: 0.090605554352591   5: 0.029500939913879   2: 0.021249039279436   3: 0.012135523989426   0: 0.012131503364659   7: 0.012108476027791   8: 0.012106821231375   4: 0.012106776037716   9: 0.012106209047938 

training_213      6: 0.760939474842428   8: 0.088755549354209   3: 0.046621326735128   5: 0.014850325685315   0: 0.014818143498471   7: 0.014815096850214   2: 0.014804524335055   9: 0.014799107955226   1: 0.014798564691128   4: 0.014797886052826 

training_2130     6: 0.449779331801071   9: 0.301596178176603   2: 0.092097925624283   0: 0.058689374614741   1: 0.016344703475046   4: 0.016303855219822   5: 0.016303670076314   7: 0.016295568823751   8: 0.016295372562655   3: 0.016294019625714 

training_2133     4: 0.420394890045844   5: 0.415542320472481   6: 0.020509237386967   0: 0.020508579448068   1: 0.020508446690528   9: 0.020508127132824   2: 0.020507526334016   8: 0.020507150180621   7: 0.020506878858630   3: 0.020506843450022 

training_2136     6: 0.365992903769835   5: 0.343576323006253   4: 0.036319369677602   3: 0.036302196325561   2: 0.036301989524502   1: 0.036301781112526   0: 0.036301602374832   8: 0.036301582906561   7: 0.036301254341604   9: 0.036300996960724 

training_2137     3: 0.637329348925131   5: 0.187484472388224   6: 0.021907069137611   4: 0.021902317243162   8: 0.021898026498678   1: 0.021896521229441   0: 0.021896340774112   9: 0.021896206428540   2: 0.021895235284467   7: 0.021894462090634 

training_214      1: 0.555098104407172   5: 0.280866964800668   6: 0.041270188307442   0: 0.017598466622820   8: 0.017528637342729   2: 0.017528053038742   4: 0.017527671518822   7: 0.017527361943257   9: 0.017527284754046   3: 0.017527267264301 

training_2148     4: 0.732359967395513   5: 0.029746745474601   8: 0.029737149532507   9: 0.029737031270624   3: 0.029736814063668   2: 0.029736652692932   7: 0.029736463030165   0: 0.029736416424305   1: 0.029736400873447   6: 0.029736359242237 

training_2149     5: 0.735963870947701   1: 0.099448653607116   7: 0.020581082727354   6: 0.020575837288281   4: 0.020572828290785   8: 0.020572653410361   9: 0.020572368183541   0: 0.020571531125787   2: 0.020570623619928   3: 0.020570550799147 

training_2151     1: 0.598050643533449   5: 0.166730407612753   4: 0.059283240737721   8: 0.056515929883749   3: 0.019938696285650   0: 0.019901741172367   6: 0.019898724530271   2: 0.019894786686947   9: 0.019893062776838   7: 0.019892766780254 

training_2153     5: 0.768731268912046   3: 0.025697024117787   4: 0.025696744368491   6: 0.025696537280168   8: 0.025696513248169   0: 0.025696467021473   7: 0.025696381576859   2: 0.025696381099304   1: 0.025696367840790   9: 0.025696314534913 

training_2154     5: 0.437299427671683   3: 0.372769324895280   8: 0.023741744591167   4: 0.023741665623279   1: 0.023741644005098   6: 0.023741591248214   9: 0.023741414756267   0: 0.023741367567135   7: 0.023740967993402   2: 0.023740851648474 

training_2155     6: 0.389604728153004   8: 0.386986589733513   0: 0.104012161564804   3: 0.017121277916060   9: 0.017056978355822   5: 0.017049623676334   1: 0.017044671624264   7: 0.017041641974992   4: 0.017041171516966   2: 0.017041155484241 

training_2157     5: 0.698585971038131   1: 0.033513975501854   4: 0.033490185140017   7: 0.033489986305427   0: 0.033488427507047   6: 0.033487002061152   3: 0.033486266355175   2: 0.033486239270426   9: 0.033486181433366   8: 0.033485765387405 

training_2159     1: 0.551887347915220   2: 0.200368041670835   6: 0.078204542478112   3: 0.052225368766590   5: 0.019561889024631   0: 0.019555902480943   4: 0.019550080029476   8: 0.019549398612828   9: 0.019548863328786   7: 0.019548565692580 

training_216      9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_2163     5: 0.658137017882430   7: 0.095193726225744   4: 0.091273624846300   6: 0.022218586305624   0: 0.022198918881863   2: 0.022195886603098   3: 0.022195859747171   1: 0.022195608902521   9: 0.022195413056430   8: 0.022195357548821 

training_2166     5: 0.695491227574248   0: 0.033843687598280   2: 0.033838452967794   6: 0.033836601671308   4: 0.033833968842671   1: 0.033832275687985   3: 0.033831211428136   8: 0.033831206815208   7: 0.033830698452027   9: 0.033830668962343 

training_2167     4: 0.746867776221959   5: 0.028131889826735   3: 0.028125421837200   1: 0.028125309837146   8: 0.028125088233074   0: 0.028125082025270   2: 0.028124902347262   6: 0.028124861536732   7: 0.028124846972552   9: 0.028124821162068 

training_2168     6: 0.577267881320827   0: 0.169412711182432   1: 0.128432108961856   8: 0.055903500277000   4: 0.011501068423397   9: 0.011499037924614   5: 0.011496258066690   7: 0.011496181388393   2: 0.011495628723898   3: 0.011495623730891 

training_2169     6: 0.664492164249909   7: 0.138825567460645   8: 0.024590867954707   0: 0.024590832208083   9: 0.024587104587680   1: 0.024584827766835   4: 0.024582495340333   2: 0.024582186545223   5: 0.024582169887860   3: 0.024581783998725 

training_2171     6: 0.760432967824828   7: 0.026619410033328   0: 0.026618701017819   8: 0.026618540987543   9: 0.026618478339582   1: 0.026618435410473   2: 0.026618426862855   5: 0.026618372530113   3: 0.026618335606600   4: 0.026618331386859 

training_2172     6: 0.707449029591882   7: 0.068977607697743   5: 0.065284631327800   0: 0.049523409835499   8: 0.018135550923284   2: 0.018133030678382   9: 0.018124469320853   1: 0.018124141777398   3: 0.018124089482905   4: 0.018124039364256 

training_2173     6: 0.336458128150157   5: 0.290200266918058   3: 0.153055654041440   0: 0.116950826340514   2: 0.017232888559014   9: 0.017224929139558   4: 0.017220254117189   1: 0.017219496358038   7: 0.017218977428322   8: 0.017218578947710 

training_2174     2: 0.767524880881257   5: 0.025834999848425   6: 0.025832158331481   4: 0.025831743010337   9: 0.025830982239585   0: 0.025829569700420   1: 0.025829544521347   8: 0.025829208756851   7: 0.025828463893474   3: 0.025828448816822 

training_2175     6: 0.452908687664857   0: 0.413408520642199   9: 0.016815733564154   7: 0.016732832725640   1: 0.016692382682015   5: 0.016689876369241   8: 0.016689104030560   4: 0.016687786614645   2: 0.016687596032424   3: 0.016687479674264 

training_2176     5: 0.397008532030784   8: 0.371862188758287   2: 0.028893147399699   1: 0.028892337605327   0: 0.028891383525087   6: 0.028891346749609   7: 0.028890848234694   3: 0.028890442549123   9: 0.028890223072697   4: 0.028889550074693 

training_2178     1: 0.731020865051173   4: 0.029891733474704   6: 0.029889190141311   9: 0.029886410912468   0: 0.029886186888571   8: 0.029885685274880   7: 0.029885545285768   5: 0.029885365047556   2: 0.029884542451160   3: 0.029884475472410 

training_2181     1: 0.756867401526059   6: 0.027024329408095   0: 0.027016195502843   7: 0.027013822665164   9: 0.027013551240840   8: 0.027013329704043   5: 0.027013235222743   2: 0.027012980419599   3: 0.027012635180834   4: 0.027012519129781 

training_2182     5: 0.711042067403696   7: 0.091581966919965   4: 0.076896970613613   0: 0.017215501372959   6: 0.017212813254830   1: 0.017212604030158   9: 0.017210052222752   8: 0.017209551233185   2: 0.017209245133648   3: 0.017209227815195 

training_2183     6: 0.750173646129712   7: 0.027758775485688   0: 0.027758674568281   8: 0.027758557687369   9: 0.027758466990756   1: 0.027758465432900   5: 0.027758390494768   3: 0.027758347700822   2: 0.027758341605557   4: 0.027758333904146 

training_2186     0: 0.569266833502966   6: 0.297131675612102   4: 0.016706510029380   5: 0.016706476195661   7: 0.016698902970456   9: 0.016698480871859   8: 0.016698472356833   1: 0.016698035909383   2: 0.016697340411336   3: 0.016697272140025 

training_2187     6: 0.605053599124659   0: 0.232676163236907   1: 0.041510584033341   8: 0.017293057080462   7: 0.017251203856438   9: 0.017245028365650   5: 0.017244193520113   2: 0.017243595712778   4: 0.017242238722756   3: 0.017240336346895 

training_2188     5: 0.585324520013941   6: 0.247823710329990   4: 0.020862637043621   7: 0.020855841819639   8: 0.020855696310241   0: 0.020855637361041   1: 0.020855614360784   9: 0.020855501188030   3: 0.020855463089750   2: 0.020855378482963 

training_2190     6: 0.465481536756510   1: 0.339018555976541   0: 0.091077992741469   4: 0.014918763689935   5: 0.014917922273451   9: 0.014917287150680   8: 0.014917274099148   7: 0.014916964772269   3: 0.014916904342473   2: 0.014916798197525 

training_2191     6: 0.768991057208247   8: 0.090154942404982   7: 0.017617870525605   0: 0.017609927665640   9: 0.017607110704602   1: 0.017605058831914   4: 0.017603937030861   5: 0.017603497133860   2: 0.017603351764282   3: 0.017603246730007 

training_2193     3: 0.350283231246364   1: 0.249824578441269   6: 0.194410598835958   8: 0.066326916280516   4: 0.048878274626982   7: 0.018059914125553   5: 0.018059133625671   0: 0.018055767816110   2: 0.018050853730717   9: 0.018050731270860 

training_2194     5: 0.692196233883907   6: 0.176355670369188   9: 0.016437721623427   3: 0.016434341178054   8: 0.016432302796774   4: 0.016429918926129   0: 0.016429354398905   2: 0.016428369672869   1: 0.016428315168601   7: 0.016427771982146 

training_2195     6: 0.495964913631125   7: 0.151488854408488   1: 0.104744735951726   2: 0.069394392016353   4: 0.069197856361597   0: 0.054569204377498   8: 0.013992609414557   5: 0.013662103195253   9: 0.013504846645673   3: 0.013480483997731 

training_2196     6: 0.457678390789521   5: 0.343923361226592   9: 0.071009690359714   7: 0.018208055652806   0: 0.018202866161284   8: 0.018197496944180   1: 0.018196375199374   4: 0.018195196508580   3: 0.018194285025090   2: 0.018194282132860 

training_2197     6: 0.556403117194353   0: 0.353358275536314   8: 0.018309356856576   7: 0.016595520103041   9: 0.009227264606350   1: 0.009222173918373   5: 0.009221456931243   2: 0.009221282975956   4: 0.009220917178328   3: 0.009220634699467 

training_2198     5: 0.488847644828347   8: 0.188828524898302   6: 0.165071995286952   0: 0.040370504449040   2: 0.036884726767285   1: 0.016001254867845   9: 0.015999330704946   7: 0.015999030439268   4: 0.015998596115754   3: 0.015998391642262 

training_22       7: 0.521067128075804   0: 0.283042781953115   5: 0.024494428731828   6: 0.024490551814396   2: 0.024488805417814   1: 0.024486390984678   4: 0.024485416917861   3: 0.024481970422598   8: 0.024481343289346   9: 0.024481182392559 

training_220      6: 0.780355898758335   0: 0.072004608588075   1: 0.041353215843123   7: 0.027774089663070   8: 0.013125529183834   9: 0.013078822638628   5: 0.013078049298084   4: 0.013076780675844   2: 0.013076743175512   3: 0.013076262175495 

training_2202     6: 0.807207528850076   0: 0.053038480546422   9: 0.033486369262130   1: 0.015192351078870   5: 0.015185181965200   4: 0.015178835055025   2: 0.015178570089556   8: 0.015177722815865   3: 0.015177494687171   7: 0.015177465649687 

training_2203     6: 0.385817079128172   5: 0.385668590043862   8: 0.110212406474983   1: 0.045934960522619   0: 0.012095420206563   7: 0.012057926655793   9: 0.012054875360387   4: 0.012053644050960   3: 0.012052670694478   2: 0.012052426862185 

training_2205     5: 0.793474530662691   4: 0.022949604753731   0: 0.022948354114417   6: 0.022947788480586   2: 0.022947515590725   8: 0.022946761642564   9: 0.022946574925589   1: 0.022946399566892   3: 0.022946255941975   7: 0.022946214320829 

training_2206     6: 0.816911759033550   2: 0.040939270463154   8: 0.017772971398712   1: 0.017769199906942   5: 0.017768574980622   0: 0.017768549942740   7: 0.017767730176678   4: 0.017767640474814   9: 0.017767413928621   3: 0.017766889694167 

training_2207     0: 0.725493808665956   7: 0.030516822402123   4: 0.030507257555364   1: 0.030501874754223   5: 0.030500234825506   6: 0.030497064792089   2: 0.030497046389428   8: 0.030495345546246   9: 0.030495286964900   3: 0.030495258104165 

training_221      6: 0.353435838723201   2: 0.327764802068690   8: 0.157105394004130   5: 0.023247145955635   0: 0.023201869736379   1: 0.023087316583610   9: 0.023041496917505   3: 0.023040311281581   7: 0.023038123585110   4: 0.023037701144159 

training_2211     5: 0.787860289750694   1: 0.023576867750337   0: 0.023570928713829   3: 0.023570713352442   6: 0.023570479755854   8: 0.023570473810553   4: 0.023570309746115   9: 0.023570156902575   2: 0.023569930782072   7: 0.023569849435529 

training_2212     4: 0.792498831262156   6: 0.023080557951655   0: 0.023061567762620   9: 0.023060506829000   5: 0.023057793316596   7: 0.023053716419963   8: 0.023051118273078   1: 0.023047047419703   2: 0.023046154146113   3: 0.023042706619117 

training_2213     5: 0.796770573993729   6: 0.022590669616029   2: 0.022581798823881   9: 0.022580394810766   1: 0.022580267017303   0: 0.022580015714609   4: 0.022579191819533   3: 0.022579123122569   8: 0.022578989927244   7: 0.022578975154336 

training_2216     5: 0.720879305935003   2: 0.031014807582230   1: 0.031014019326888   0: 0.031013744088313   6: 0.031013512557395   3: 0.031013094687034   8: 0.031012892955816   4: 0.031012892257832   9: 0.031012873658502   7: 0.031012856950988 

training_2217     6: 0.835862606208760   7: 0.035658298062433   8: 0.016082990459986   0: 0.016077802844897   9: 0.016067311269039   1: 0.016050969986999   5: 0.016050128173618   4: 0.016050067902241   2: 0.016049985391112   3: 0.016049839700916 

training_2219     1: 0.535785520043588   0: 0.210211341097073   2: 0.100791536453871   6: 0.069194478570307   7: 0.014008206375709   9: 0.014008170594523   4: 0.014003601344692   5: 0.014001049786999   8: 0.013998238372419   3: 0.013997857360818 

training_2220     1: 0.610842391981148   5: 0.160896166134363   0: 0.028544491047048   6: 0.028536484882512   4: 0.028530595731888   7: 0.028530493612783   2: 0.028530025924508   3: 0.028529886352479   9: 0.028529777174352   8: 0.028529687158919 

training_2221     5: 0.575690852173107   9: 0.154549060535968   6: 0.141365152336629   1: 0.039988370373195   3: 0.015611227015923   0: 0.014560936524544   4: 0.014559136950804   8: 0.014558582936295   7: 0.014558385457025   2: 0.014558295696511 

training_2223     6: 0.755595998623814   8: 0.066870757364709   2: 0.059015559580121   7: 0.032708493489549   0: 0.014303028124368   5: 0.014301632684773   1: 0.014301548804747   9: 0.014301056185362   4: 0.014301042625310   3: 0.014300882517246 

training_2224     0: 0.443882809271823   8: 0.205368770073881   1: 0.200232925853664   2: 0.045787824759742   6: 0.017476286963646   5: 0.017453967116488   4: 0.017450637174744   9: 0.017449544508936   7: 0.017449009702725   3: 0.017448224574352 

training_2225     1: 0.759618085735287   5: 0.055644280531640   9: 0.023114694667919   6: 0.023091036251327   0: 0.023089296071861   4: 0.023088933303759   8: 0.023088723015067   2: 0.023088421576643   7: 0.023088275821834   3: 0.023088253024664 

training_2226     6: 0.717427856803052   8: 0.103000086721987   0: 0.062634584842257   2: 0.031898022606244   1: 0.014331064577367   5: 0.014158152963032   9: 0.014138384586869   7: 0.014137708763058   4: 0.014137574183273   3: 0.014136563952861 

training_2227     5: 0.749075106987412   4: 0.068841712875844   6: 0.054532753791247   7: 0.018226825287935   2: 0.018220851829385   1: 0.018220800728727   9: 0.018220720458172   0: 0.018220591319859   8: 0.018220411061670   3: 0.018220225659748 

training_2228     6: 0.717474632345888   0: 0.185606081474328   1: 0.038236407026506   5: 0.012268590489486   2: 0.007865459319244   8: 0.007734602492357   7: 0.007723312827453   9: 0.007714887174536   4: 0.007688213385858   3: 0.007687813464343 

training_2230     5: 0.751133602656475   8: 0.069906931378257   6: 0.022460886437233   1: 0.022357513701177   9: 0.022357282422737   0: 0.022357048287417   2: 0.022356924833618   4: 0.022356710605595   3: 0.022356587516281   7: 0.022356512161210 

training_2231     6: 0.738359569553892   2: 0.079564279712809   0: 0.043509018006483   9: 0.039604980169874   5: 0.016494374188585   1: 0.016493910850407   4: 0.016493811936701   7: 0.016493498145746   8: 0.016493298595539   3: 0.016493258839964 

training_2232     6: 0.803549486076893   0: 0.021830484343935   7: 0.021828437961635   1: 0.021827943164481   9: 0.021827348672076   4: 0.021827324548676   8: 0.021827317723244   2: 0.021827281931007   5: 0.021827215240410   3: 0.021827160337645 

training_2234     5: 0.755708032703000   7: 0.074165685921304   4: 0.021269206568316   6: 0.021266901058856   2: 0.021265533767654   9: 0.021265296393125   0: 0.021265257000083   1: 0.021265239503341   8: 0.021264426133355   3: 0.021264420950966 

training_2236     5: 0.760151465495069   4: 0.026653838699365   0: 0.026649639282121   1: 0.026649592967002   6: 0.026649453095266   8: 0.026649291876356   7: 0.026649253365628   2: 0.026649212797716   3: 0.026649154595823   9: 0.026649097825654 

training_2237     0: 0.736390044700333   2: 0.074713181974825   5: 0.023617247169007   4: 0.023615180399370   1: 0.023612914911650   6: 0.023612225811153   8: 0.023610034263634   9: 0.023609782483701   3: 0.023609739262427   7: 0.023609649023898 

training_2238     5: 0.797069740359896   6: 0.022549094504607   4: 0.022548056023534   0: 0.022547881266404   3: 0.022547826663356   1: 0.022547748201063   8: 0.022547482910392   9: 0.022547441602601   2: 0.022547374159341   7: 0.022547354308807 

training_2239     6: 0.638740147174717   2: 0.183438888618835   5: 0.022228305741011   0: 0.022228218497282   1: 0.022228138912973   7: 0.022227629385687   4: 0.022227450640020   9: 0.022227225992475   8: 0.022227207898521   3: 0.022226787138479 

training_2240     5: 0.483076470384651   6: 0.234435276344681   4: 0.129197018813083   1: 0.021902446217906   0: 0.021902016008197   8: 0.021898906265361   9: 0.021898435416444   2: 0.021897134509962   7: 0.021896256507168   3: 0.021896039532545 

training_2244     8: 0.710400516587970   0: 0.032182954090763   1: 0.032181625887950   6: 0.032180262090922   5: 0.032179827071837   4: 0.032175452339604   2: 0.032175273505493   3: 0.032175228924277   9: 0.032174887977381   7: 0.032173971523802 

training_2246     6: 0.630285810423144   0: 0.230949411382672   2: 0.032074326909396   5: 0.015242333037741   1: 0.015242120160442   8: 0.015241520309165   7: 0.015241286310039   9: 0.015241275909647   4: 0.015241094366458   3: 0.015240821191296 

training_2247     6: 0.383834390584024   1: 0.378953777248206   9: 0.112025792199315   8: 0.027913253488296   0: 0.016275446599872   5: 0.016200736882103   4: 0.016199734645032   2: 0.016199335550459   3: 0.016198790153311   7: 0.016198742649382 

training_2249     5: 0.527864938150668   6: 0.301157768675316   4: 0.021378268436985   9: 0.021372385245606   0: 0.021371681390940   8: 0.021371181101305   1: 0.021371092615190   3: 0.021370938168254   7: 0.021370883102956   2: 0.021370863112780 

training_225      6: 0.672542339198124   0: 0.180970946226452   7: 0.063485996627025   9: 0.012181187116762   2: 0.011941770866962   1: 0.011916898293756   5: 0.011751393788854   3: 0.011736746219271   8: 0.011736485917442   4: 0.011736235745353 

training_2251     0: 0.460870143210920   6: 0.279294787545765   1: 0.163053280433325   3: 0.017135359264439   2: 0.016185708155514   9: 0.012938227043188   7: 0.012784361997286   5: 0.012604396706742   4: 0.012581347940029   8: 0.012552387702792 

training_2252     5: 0.784846859393695   4: 0.023910433022033   6: 0.023906782119002   0: 0.023905412636900   9: 0.023905280818839   7: 0.023905259992275   8: 0.023905109495437   3: 0.023905105293148   2: 0.023904892966089   1: 0.023904864262582 

training_2253     5: 0.803534480065796   0: 0.064386330323345   1: 0.016513321988611   8: 0.016512081010136   6: 0.016511746939744   4: 0.016509573359363   2: 0.016508960764369   9: 0.016508877164882   7: 0.016507387669066   3: 0.016507240714688 

training_2257     6: 0.754656492425422   1: 0.131148769453772   2: 0.024783597280461   3: 0.022864271283311   0: 0.011093784186815   4: 0.011092267372391   5: 0.011090900694043   8: 0.011090503366299   7: 0.011089830752190   9: 0.011089583185297 

training_2259     5: 0.702040211836910   2: 0.149925487131243   0: 0.018507286591911   7: 0.018505094955908   1: 0.018504318938913   6: 0.018504179750416   9: 0.018504076915330   8: 0.018503274523261   3: 0.018503079777134   4: 0.018502989578974 

training_2260     5: 0.523230354205841   9: 0.309071772825748   1: 0.051495414699355   6: 0.016646463248434   7: 0.016598550030889   0: 0.016598111260799   2: 0.016590406974729   4: 0.016590281002290   8: 0.016589707051242   3: 0.016588938700672 

training_2264     6: 0.803470319567618   7: 0.055115676666229   5: 0.017678434893037   1: 0.017677363245107   0: 0.017676871177610   8: 0.017676442239504   9: 0.017676356016351   3: 0.017676331963097   2: 0.017676192916348   4: 0.017676011315099 

training_2265     5: 0.748295078683658   3: 0.057943634101744   6: 0.051155453528903   0: 0.042404699007827   9: 0.016728870332812   1: 0.016696739070115   4: 0.016694498596518   8: 0.016693746364543   7: 0.016693650522435   2: 0.016693629791445 

training_2266     5: 0.790348043195470   6: 0.023304892420644   4: 0.023296124873040   0: 0.023295149106191   1: 0.023293041522145   8: 0.023292641024873   3: 0.023292612876868   9: 0.023292565020448   2: 0.023292498939775   7: 0.023292431020546 

training_2268     1: 0.644995800649513   0: 0.193149208937184   4: 0.020242237285912   8: 0.020236000511754   6: 0.020231490911055   2: 0.020230614346123   3: 0.020229723715130   9: 0.020229390164364   5: 0.020228863082439   7: 0.020226670396525 

training_2269     0: 0.392290657864936   6: 0.272071301012740   7: 0.235366594124233   9: 0.027465858082567   8: 0.023902276367847   1: 0.012307392022126   5: 0.009188557974289   2: 0.009143474004817   4: 0.009134595361209   3: 0.009129293185237 

training_227      6: 0.799210614356616   0: 0.090109270070756   1: 0.023346840077198   5: 0.018045986333293   3: 0.011636133620107   9: 0.011543726169437   7: 0.011531263156274   4: 0.011526762260132   8: 0.011525872013166   2: 0.011523531943021 

training_2270     5: 0.686550276239234   4: 0.113627350873762   8: 0.024990432271014   9: 0.024979503971204   6: 0.024979021685030   3: 0.024976676273819   0: 0.024975599808000   1: 0.024975563212242   7: 0.024972837051100   2: 0.024972738614594 

training_2271     8: 0.549324233881102   6: 0.271429702317850   2: 0.049079992166019   0: 0.036659217081140   3: 0.025018494157916   4: 0.013733190653436   5: 0.013707027918575   1: 0.013689592047262   9: 0.013679793003732   7: 0.013678756772967 

training_2273     0: 0.395237191932557   5: 0.274260740958867   7: 0.180319523229208   3: 0.067063701396823   4: 0.013880614072960   1: 0.013854770248487   8: 0.013850393899247   6: 0.013846160679055   9: 0.013844186481189   2: 0.013842717101607 

training_2275     4: 0.812489876964429   5: 0.020840154656968   6: 0.020834927419220   0: 0.020833705804964   1: 0.020833697148977   9: 0.020833688668249   8: 0.020833555437809   2: 0.020833485039950   3: 0.020833478142966   7: 0.020833430716467 

training_2276     5: 0.701824783714205   0: 0.100531297483884   4: 0.024712042413495   8: 0.024704972261668   6: 0.024704757801155   1: 0.024704672301084   9: 0.024704612406523   3: 0.024704382070443   2: 0.024704284083135   7: 0.024704195464408 

training_2278     6: 0.588533193687275   0: 0.247844750125724   5: 0.090001946951477   1: 0.010518352872956   8: 0.010517894844044   7: 0.010517184028085   9: 0.010516839746174   2: 0.010516664015889   3: 0.010516591496675   4: 0.010516582231701 

training_2279     5: 0.706449666834295   6: 0.139375920901685   9: 0.019292542763812   3: 0.019282554764020   8: 0.019279136545256   0: 0.019265247452136   1: 0.019264294293178   4: 0.019264225357825   2: 0.019264135720344   7: 0.019262275367450 

training_228      6: 0.666244971573332   7: 0.181433136137490   1: 0.019055019535404   0: 0.019047835581964   9: 0.019047553650905   5: 0.019041568011419   8: 0.019033661551426   4: 0.019032463778011   3: 0.019031946014337   2: 0.019031844165712 

training_2281     1: 0.622738160512047   6: 0.211521595734769   5: 0.020739838608577   4: 0.020716905973703   0: 0.020715480221940   8: 0.020714344359225   2: 0.020713843047414   7: 0.020713535399120   9: 0.020713160948426   3: 0.020713135194778 

training_2286     6: 0.521978260694470   1: 0.356277161445624   0: 0.015246075390215   4: 0.015215810250971   8: 0.015214459588687   7: 0.015214107408979   9: 0.015213752004263   5: 0.015213632398270   3: 0.015213406422016   2: 0.015213334396507 

training_229      6: 0.637756948908729   7: 0.223199133233892   1: 0.017389799598598   8: 0.017383660622621   0: 0.017383317864664   5: 0.017381027757021   2: 0.017376829443126   9: 0.017376652490029   4: 0.017376436668153   3: 0.017376193413167 

training_2290     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_2291     6: 0.492144429424193   1: 0.323773495802832   5: 0.023066848126244   4: 0.023037284473150   0: 0.022999403073989   3: 0.022998939604460   2: 0.022997002452579   8: 0.022994987789911   7: 0.022994430220857   9: 0.022993179031784 

training_2297     5: 0.647159281972842   6: 0.100551958814106   0: 0.096028838878904   1: 0.022329409632643   2: 0.022322686206484   9: 0.022322408521835   4: 0.022322366290370   3: 0.022321517728238   7: 0.022320964627271   8: 0.022320567327306 

training_2298     2: 0.505129060184450   5: 0.310038666405188   4: 0.023110375115724   8: 0.023103354814553   3: 0.023103319970235   1: 0.023103166035257   0: 0.023103093013061   7: 0.023103079103534   9: 0.023103005855203   6: 0.023102879502794 

training_23       5: 0.843026333235500   8: 0.029211865103245   6: 0.016675351013933   0: 0.015983237338613   1: 0.015913531218552   9: 0.015840407338890   2: 0.015838204230614   4: 0.015837600462978   7: 0.015836888164800   3: 0.015836581892875 

training_2301     2: 0.435112310879106   0: 0.344918796130734   9: 0.069350869252687   6: 0.021520782815591   5: 0.021519777181258   1: 0.021519744134934   8: 0.021518029593606   4: 0.021516055201883   3: 0.021512121154603   7: 0.021511513655599 

training_2303     6: 0.352207267750125   5: 0.266227207882606   1: 0.118615738564477   2: 0.114159011149300   0: 0.064011199365591   3: 0.032705980287827   4: 0.013020596843441   8: 0.013017794249470   9: 0.013017724638779   7: 0.013017479268385 

training_2304     5: 0.749060965913438   8: 0.081144076481116   4: 0.021226175954751   9: 0.021224762290999   6: 0.021224623788562   1: 0.021224011273030   7: 0.021224010199875   0: 0.021223870615501   2: 0.021223752074478   3: 0.021223751408251 

training_2307     6: 0.411498935569319   9: 0.321690403210487   1: 0.124234542249064   2: 0.035514499573181   3: 0.026090141423093   0: 0.024746793995912   5: 0.014069809902207   4: 0.014054603338330   8: 0.014050809694017   7: 0.014049461044389 

training_2308     5: 0.708840887349950   0: 0.094059425321148   8: 0.055613820960959   6: 0.020217338729458   2: 0.020211800357394   1: 0.020211750236678   9: 0.020211745458388   3: 0.020211178581154   7: 0.020211034684433   4: 0.020211018320437 

training_2309     4: 0.813827852327665   5: 0.020691387648114   6: 0.020686233859018   0: 0.020685540974740   8: 0.020685013225379   9: 0.020684988256993   1: 0.020684807545270   7: 0.020684745056570   3: 0.020684739174554   2: 0.020684691931698 

training_2310     6: 0.522062211759374   1: 0.376034033058496   4: 0.012744088546500   5: 0.012740976082552   9: 0.012737853671881   0: 0.012736441271735   7: 0.012736290424701   3: 0.012736195362596   8: 0.012736164597232   2: 0.012735745224933 

training_2312     0: 0.789620255996118   1: 0.062715788080805   4: 0.018678176276503   9: 0.018523719471408   7: 0.018441360822592   5: 0.018409220119263   6: 0.018405688038189   2: 0.018402425057791   8: 0.018401838370905   3: 0.018401527766426 

training_2316     5: 0.834712897418119   4: 0.018368809225007   0: 0.018368053294365   2: 0.018365316079704   6: 0.018364374198662   8: 0.018364190358290   1: 0.018364171019538   3: 0.018364127888076   9: 0.018364096066339   7: 0.018363964451899 

training_232      6: 0.739178506138609   1: 0.120395291998586   0: 0.043943415316777   5: 0.025561132669102   8: 0.019752227995990   4: 0.010254405554431   9: 0.010231449643299   7: 0.010229196416463   3: 0.010227714982376   2: 0.010226659284365 

training_2320     5: 0.737405274457542   4: 0.029181222618671   6: 0.029177017715720   1: 0.029176916257339   9: 0.029176734609734   0: 0.029176708446766   8: 0.029176678144128   3: 0.029176649050320   2: 0.029176445852061   7: 0.029176352847719 

training_2322     0: 0.540074262344970   5: 0.287656443762908   1: 0.021537175730785   6: 0.021534202352633   4: 0.021534071868007   9: 0.021533928818857   2: 0.021533036400912   3: 0.021532730257434   8: 0.021532505778288   7: 0.021531642685207 

training_2323     5: 0.771612879589218   6: 0.025392970597247   1: 0.025377963323362   0: 0.025376291433784   7: 0.025375576307887   9: 0.025373239794344   4: 0.025373131434304   8: 0.025373105051052   2: 0.025372505556272   3: 0.025372336912529 

training_2325     3: 0.397874383648724   5: 0.366782383778373   2: 0.094881380153073   6: 0.020073038626456   8: 0.020071386655066   9: 0.020069649954673   0: 0.020069184620885   1: 0.020061861999443   4: 0.020058823487207   7: 0.020057907076100 

training_2326     6: 0.832184060497188   8: 0.064371778566603   3: 0.029821443114656   0: 0.010519064105691   5: 0.010518043745023   7: 0.010517417547814   1: 0.010517381755873   9: 0.010516987271467   2: 0.010516952809494   4: 0.010516870586191 

training_2327     6: 0.551417827923967   5: 0.220551421444327   8: 0.028545238479362   0: 0.028505426656198   1: 0.028499302219839   7: 0.028498654237367   2: 0.028496171106611   9: 0.028496027292731   3: 0.028495030358532   4: 0.028494900281066 

training_233      6: 0.570027974981653   5: 0.275198309532355   9: 0.019373493865756   0: 0.019349454869156   8: 0.019347910960147   1: 0.019343493292535   2: 0.019340032856912   7: 0.019339928115318   3: 0.019339836692063   4: 0.019339564834104 

training_2332     5: 0.655711738094573   7: 0.166111956212896   1: 0.022276382148742   3: 0.022272135285553   4: 0.022271651657557   0: 0.022271650276101   6: 0.022271540401639   2: 0.022271042448989   9: 0.022270985356585   8: 0.022270918117366 

training_2333     4: 0.774603164940178   7: 0.072457878141086   9: 0.019120687520731   2: 0.019119590237741   5: 0.019119579660342   6: 0.019116627822309   0: 0.019116115075054   1: 0.019115702911324   8: 0.019115404784135   3: 0.019115248907100 

training_2335     5: 0.805533225214271   4: 0.021611970311828   6: 0.021607169684843   0: 0.021607101373907   8: 0.021606924788508   9: 0.021606796388937   3: 0.021606734088991   2: 0.021606699577567   7: 0.021606691559908   1: 0.021606687011239 

training_2336     6: 0.752970959117527   0: 0.027449456146601   9: 0.027448527814540   1: 0.027447640208750   7: 0.027447597864227   8: 0.027447376852366   5: 0.027447285967778   2: 0.027447238813382   3: 0.027446996778055   4: 0.027446920436774 

training_2337     5: 0.818219389100066   4: 0.020199873162119   6: 0.020198854307610   9: 0.020197921115296   0: 0.020197490276200   1: 0.020197473892106   7: 0.020197323619902   8: 0.020197317001430   2: 0.020197180189682   3: 0.020197177335591 

training_2338     4: 0.739473278813899   5: 0.028951767278037   3: 0.028947929612550   8: 0.028947447172061   1: 0.028946641545931   0: 0.028946633119079   9: 0.028946622777876   2: 0.028946619345821   6: 0.028946602990643   7: 0.028946457344103 

training_2339     5: 0.509352703049655   0: 0.169567045669202   7: 0.148063828942161   3: 0.024717350032850   4: 0.024716922944475   6: 0.024716695072549   8: 0.024716636176960   2: 0.024716335756940   1: 0.024716293112903   9: 0.024716189242304 

training_2340     5: 0.483777844523428   7: 0.313787411795254   3: 0.025305339022293   4: 0.025304763874347   6: 0.025304226603200   0: 0.025304207528624   8: 0.025304192346799   1: 0.025304034143102   2: 0.025304034099657   9: 0.025303946063296 

training_2342     5: 0.731503623413174   2: 0.078266987835312   4: 0.023784219580274   1: 0.023778235879952   0: 0.023778012985716   7: 0.023777979234993   8: 0.023777952473624   6: 0.023777705365216   9: 0.023777665031933   3: 0.023777618199806 

training_2344     9: 0.567287313327494   0: 0.163806170448457   4: 0.096809254353108   6: 0.063066604937218   1: 0.018186035419024   3: 0.018182337492122   5: 0.018168783992497   2: 0.018164555566454   8: 0.018164523913006   7: 0.018164420550621 

training_2346     5: 0.450623625044359   8: 0.273759510433078   7: 0.114229793975685   4: 0.023058402973766   1: 0.023055345115843   3: 0.023055313632375   0: 0.023055302028625   6: 0.023054470554912   2: 0.023054215635629   9: 0.023054020605728 

training_2347     5: 0.609699408420368   6: 0.115422957546302   9: 0.114802593022759   7: 0.022883565885194   0: 0.022869398698703   3: 0.022864765094904   4: 0.022864496826768   1: 0.022864384656517   8: 0.022864297938807   2: 0.022864131909678 

training_2348     5: 0.593816465471380   7: 0.197877136869441   3: 0.026039046935146   4: 0.026038659256891   8: 0.026038203094616   0: 0.026038194089387   6: 0.026038188320033   2: 0.026038063534982   1: 0.026038054972750   9: 0.026037987455374 

training_235      6: 0.780981435381679   0: 0.082208524611752   8: 0.047611680419307   7: 0.019543708521485   9: 0.017008338722232   5: 0.010767663326415   1: 0.010479328967110   2: 0.010467438010922   4: 0.010466888750467   3: 0.010464993288631 

training_2350     5: 0.821313584721940   4: 0.019861458162268   1: 0.019853364477794   0: 0.019853297789627   6: 0.019853195055048   8: 0.019853103201904   7: 0.019853056390585   9: 0.019853008574950   2: 0.019852970357263   3: 0.019852961268621 

training_2352     6: 0.749563664074118   1: 0.146506870727141   0: 0.029467897275273   7: 0.010642655249510   4: 0.010636808718315   5: 0.010636716082140   9: 0.010636525786163   8: 0.010636353557613   2: 0.010636270010390   3: 0.010636238519336 

training_2353     5: 0.668786725808108   6: 0.190150049553664   1: 0.017637426154557   4: 0.017635220519953   9: 0.017632580167049   0: 0.017631946295329   7: 0.017631640959782   8: 0.017631636353716   2: 0.017631413604913   3: 0.017631360582929 

training_2354     6: 0.755662870835579   0: 0.104446894799874   1: 0.054391539883232   9: 0.028744078345220   5: 0.013083554727133   7: 0.008738606541869   4: 0.008733565548071   3: 0.008733333511731   8: 0.008733017544547   2: 0.008732538262744 

training_2357     6: 0.450285974631793   9: 0.427964443414395   0: 0.015365843687551   1: 0.015290164672198   7: 0.015199581533692   5: 0.015187426010880   8: 0.015186643897116   4: 0.015177567476725   2: 0.015172223656609   3: 0.015170131019041 

training_2358     6: 0.390342654817245   5: 0.270846076489223   8: 0.134894921935854   0: 0.029137345040490   1: 0.029131236536744   7: 0.029131068134712   9: 0.029129846478395   2: 0.029129553082169   3: 0.029128886169517   4: 0.029128411315651 

training_2359     6: 0.733148327023225   1: 0.096277218935514   0: 0.069887997744025   5: 0.027451633119052   9: 0.017327958294579   2: 0.011315432048588   3: 0.011157227840478   8: 0.011145323896653   4: 0.011144454279434   7: 0.011144426818451 

training_236      6: 0.724450445576340   0: 0.120871476428259   3: 0.058502419201733   1: 0.031285589648761   2: 0.010826456382325   7: 0.010814703247223   5: 0.010814647419805   9: 0.010813178455698   8: 0.010810641243375   4: 0.010810442396481 

training_2365     5: 0.728539618891618   4: 0.072797193044744   7: 0.068501957371090   6: 0.018610242057094   1: 0.018594487936018   0: 0.018593836850758   8: 0.018591270781239   9: 0.018590666574029   2: 0.018590438585082   3: 0.018590287908329 

training_2366     5: 0.398250497715688   9: 0.287157243351995   6: 0.180700867181827   1: 0.019186365121008   0: 0.019152671904148   7: 0.019128216420460   4: 0.019108913305084   2: 0.019105396061215   8: 0.019105315031655   3: 0.019104513906919 

training_2367     6: 0.833810743886424   1: 0.058893468323618   3: 0.038278367913741   0: 0.010055376381920   7: 0.009849153480594   8: 0.009841033571448   5: 0.009820031650202   9: 0.009817339004888   4: 0.009817299958638   2: 0.009817185828526 

training_237      6: 0.819892678308692   0: 0.100175680519581   5: 0.014661538101264   1: 0.009328004657644   9: 0.009323869922968   4: 0.009323829935661   3: 0.009323722506880   7: 0.009323661568662   2: 0.009323531311404   8: 0.009323483167243 

training_2370     6: 0.678530562451690   0: 0.199646068447895   7: 0.015525185786661   1: 0.015300713112111   5: 0.015183867518800   4: 0.015174881474416   8: 0.015166013049840   3: 0.015159595935062   2: 0.015157124061097   9: 0.015155988162428 

training_2371     2: 0.532322011124209   6: 0.297166131388872   0: 0.045087523256976   4: 0.017928223640762   5: 0.017920906029430   8: 0.017920098154648   3: 0.017916758445165   1: 0.017913603284860   7: 0.017913118230512   9: 0.017911626444566 

training_2374     0: 0.594213997701123   6: 0.267613521081232   1: 0.017276325049502   5: 0.017275992504340   7: 0.017270216472628   9: 0.017270203988467   2: 0.017270015105829   4: 0.017269939730226   8: 0.017269915098208   3: 0.017269873268444 

training_2375     6: 0.778980382706918   1: 0.110186797079521   0: 0.015757336069490   8: 0.013657748006351   5: 0.013626161416367   9: 0.013612705121651   7: 0.013549991803850   2: 0.013544143083509   3: 0.013542414084451   4: 0.013542320627892 

training_2376     0: 0.572776823196023   6: 0.289753293334321   4: 0.029702885818127   3: 0.022187965563434   2: 0.014625244504378   9: 0.014423748664746   7: 0.014244931602931   5: 0.014123772109918   1: 0.014082096035035   8: 0.014079239171088 

training_2377     5: 0.720590036225847   0: 0.031046086115955   4: 0.031045784829856   1: 0.031045703337765   3: 0.031045685498277   6: 0.031045386143228   2: 0.031045380526093   8: 0.031045356188364   7: 0.031045303119517   9: 0.031045278015098 

training_2379     5: 0.553789824848469   2: 0.231068710855043   0: 0.066439339868649   6: 0.021277992553216   4: 0.021243771784090   1: 0.021239597083039   3: 0.021236598146536   7: 0.021235612560601   8: 0.021234310916572   9: 0.021234241383784 

training_2380     5: 0.789061266426506   4: 0.023443161751605   1: 0.023438228297549   0: 0.023437469748934   8: 0.023437248919629   6: 0.023436706713993   2: 0.023436506159403   9: 0.023436505750939   3: 0.023436497585441   7: 0.023436408646000 

training_2382     6: 0.818622041169740   1: 0.020154269812708   5: 0.020154156097228   0: 0.020153906219749   8: 0.020153209301719   7: 0.020152774813829   9: 0.020152745281373   4: 0.020152459701670   2: 0.020152341424407   3: 0.020152096177578 

training_2383     6: 0.741948740222454   1: 0.161951132142365   0: 0.022731614134057   2: 0.010496268496212   8: 0.010481490048684   5: 0.010480803436892   7: 0.010479962987720   9: 0.010477939896178   3: 0.010476141436257   4: 0.010475907199181 

training_2385     5: 0.640974716068478   9: 0.109660523341173   3: 0.101742630171039   4: 0.021090063502703   8: 0.021089086423569   0: 0.021088793454214   6: 0.021088687304479   2: 0.021088509313986   1: 0.021088497602848   7: 0.021088492817510 

training_2386     5: 0.668738790337162   6: 0.190197978069878   1: 0.017637418634850   4: 0.017635236909334   9: 0.017632578820484   0: 0.017631945948317   7: 0.017631640832246   8: 0.017631636295597   2: 0.017631413574615   3: 0.017631360577516 

training_2389     6: 0.498463672191883   0: 0.315811882045165   9: 0.058837070339475   8: 0.052624644579124   1: 0.012381118898332   7: 0.012377152413876   5: 0.012376810460167   4: 0.012375927785668   3: 0.012375894893622   2: 0.012375826392690 

training_2390     6: 0.447214374946832   5: 0.302168088139819   1: 0.122814924703345   8: 0.043396506579332   2: 0.014095676249303   0: 0.014063999465391   9: 0.014063090393369   7: 0.014061337992897   3: 0.014061004364598   4: 0.014060997165114 

training_2391     5: 0.626866828682991   6: 0.171290024716606   3: 0.025230846788344   4: 0.025230677243063   2: 0.025230311683980   0: 0.025230287431441   1: 0.025230280252484   8: 0.025230273942020   7: 0.025230266098177   9: 0.025230203160894 

training_2393     5: 0.808940860994736   4: 0.021230984337625   0: 0.021229395199070   1: 0.021228809399597   9: 0.021228516123752   8: 0.021228417085752   6: 0.021228358457339   3: 0.021228325828479   2: 0.021228199594836   7: 0.021228132978814 

training_2394     0: 0.418887685511795   8: 0.183152974471428   5: 0.151354864799833   3: 0.118187044760343   2: 0.040563525516304   6: 0.017584169218434   9: 0.017577788151340   4: 0.017566915124352   1: 0.017563871430916   7: 0.017561161015255 

training_2396     5: 0.792642835681338   3: 0.023040073967579   0: 0.023040033010697   4: 0.023039758702478   6: 0.023039751781905   7: 0.023039739601271   1: 0.023039558782531   8: 0.023039470496602   2: 0.023039399367033   9: 0.023039378608566 

training_2397     5: 0.470089623238542   2: 0.328481291946640   3: 0.025198059538396   4: 0.025176457740747   6: 0.025176025671791   1: 0.025176003751523   0: 0.025175925128175   7: 0.025175669225546   8: 0.025175556302889   9: 0.025175387455751 

training_2398     5: 0.748490876894750   6: 0.076593994038943   1: 0.021865186118121   8: 0.021865007327180   0: 0.021864994565424   9: 0.021864246874040   4: 0.021864004772729   2: 0.021863956185444   3: 0.021863920424195   7: 0.021863812799173 

training_24       5: 0.780207918609052   7: 0.063099922261749   9: 0.019611273446118   6: 0.019593335820864   4: 0.019584052766411   1: 0.019581041312853   3: 0.019580866263137   0: 0.019580794301869   8: 0.019580453207779   2: 0.019580342010168 

training_2402     5: 0.738851316026061   0: 0.029048661294572   6: 0.029018969452677   4: 0.029015715177542   1: 0.029011600261141   9: 0.029011374697154   8: 0.029011281692068   2: 0.029010491159488   3: 0.029010398864950   7: 0.029010191374345 

training_2403     8: 0.772974162466933   5: 0.025233399422025   6: 0.025229404612392   9: 0.025226111804114   4: 0.025225230425377   0: 0.025224548915046   1: 0.025224349187117   7: 0.025221719914466   2: 0.025221021628644   3: 0.025220051623886 

training_2405     1: 0.583694420556623   0: 0.269059214246943   4: 0.036632791458737   6: 0.015812818061842   5: 0.015803195709829   9: 0.015800587058219   8: 0.015799465387256   2: 0.015799421517792   7: 0.015799394519190   3: 0.015798691483569 

training_2406     6: 0.801653961983807   0: 0.073672383756719   1: 0.032802464741242   5: 0.013144355492045   4: 0.013137150698934   8: 0.013118956282150   3: 0.013118364915178   9: 0.013117953219203   2: 0.013117448645554   7: 0.013116960265167 

training_2409     5: 0.756390747579931   4: 0.027070912134202   1: 0.027067815568808   0: 0.027067397376338   6: 0.027067347803634   3: 0.027067244276753   8: 0.027067174957710   2: 0.027067154791187   9: 0.027067146067738   7: 0.027067059443698 

training_241      6: 0.538589933268890   0: 0.196911508209490   8: 0.158682764389440   9: 0.015117328885703   1: 0.015116743900561   7: 0.015116688319040   5: 0.015116679791846   4: 0.015116304781583   3: 0.015116042395380   2: 0.015116006058067 

training_2410     2: 0.634720416467486   1: 0.146518912163596   0: 0.027353469619675   6: 0.027351522639459   5: 0.027345916253627   9: 0.027345437800067   4: 0.027342109959786   8: 0.027340822235571   3: 0.027340738657400   7: 0.027340654203333 

training_2411     6: 0.391644923011657   4: 0.360002274718843   2: 0.103223761929580   1: 0.044525382323180   5: 0.016789031043182   0: 0.016780303950221   8: 0.016764063937422   9: 0.016757615136069   7: 0.016756373226997   3: 0.016756270722849 

training_2417     6: 0.697673345752357   0: 0.175078635819571   5: 0.053293219126663   2: 0.017000619072470   1: 0.009634183109715   8: 0.009628171971335   7: 0.009518230989926   9: 0.009407832556583   3: 0.009385031261787   4: 0.009380730339593 

training_2419     5: 0.777182565626758   9: 0.043647166562214   6: 0.022442913429269   0: 0.022405415404821   1: 0.022402667687923   8: 0.022384512814116   4: 0.022384022606702   2: 0.022383613372383   7: 0.022383582022738   3: 0.022383540473077 

training_242      6: 0.777546513120601   7: 0.117692888185073   1: 0.013114237809678   8: 0.013093588198920   0: 0.013092623034467   9: 0.013092184187143   5: 0.013092122516081   3: 0.013091976875100   2: 0.013091965142521   4: 0.013091900930415 

training_2420     5: 0.448144997248869   6: 0.369587925829489   7: 0.022784420332219   0: 0.022783858543102   3: 0.022783644315898   1: 0.022783541429825   8: 0.022783184442273   4: 0.022783034899182   2: 0.022782747013999   9: 0.022782645945145 

training_2421     5: 0.721016270816273   7: 0.077028139274443   8: 0.070289166759012   2: 0.018811561372518   4: 0.018810357629322   6: 0.018809928845280   0: 0.018809003449192   1: 0.018808688522295   9: 0.018808486821148   3: 0.018808396510516 

training_2425     6: 0.765826885377670   8: 0.112586553137796   0: 0.015209591583124   1: 0.015198327471412   5: 0.015198016278117   9: 0.015196700152631   4: 0.015196123512901   3: 0.015195970764863   7: 0.015195941211030   2: 0.015195890510456 

training_2428     5: 0.477632444393127   0: 0.167336117951358   6: 0.165548616988841   9: 0.088552819550514   1: 0.045832977008574   8: 0.011020595984793   3: 0.011020041323304   4: 0.011019866477791   2: 0.011019050320142   7: 0.011017470001556 

training_2429     5: 0.636715415996598   7: 0.114934638182837   1: 0.099206960694463   6: 0.021315695917811   3: 0.021308314709471   4: 0.021307450965972   9: 0.021303595290126   0: 0.021302952091674   2: 0.021302641189496   8: 0.021302334961551 

training_2433     5: 0.458011501916902   3: 0.296422092343749   0: 0.132484246069596   6: 0.016323037476710   9: 0.016145187865544   1: 0.016127249084973   4: 0.016123401382591   2: 0.016121220260198   8: 0.016121122160998   7: 0.016120941438740 

training_2434     1: 0.737960566242587   0: 0.089422019739534   6: 0.021579183969417   5: 0.021578220500348   9: 0.021577897983921   4: 0.021576970859252   8: 0.021576617001452   7: 0.021576274405615   2: 0.021576130123445   3: 0.021576119174428 

training_2435     6: 0.394786736436170   5: 0.392712380306555   1: 0.106150589842023   9: 0.015204698729512   2: 0.015192915723149   0: 0.015192226984586   4: 0.015191928049399   7: 0.015189594269230   8: 0.015189536763239   3: 0.015189392896136 

training_2436     6: 0.818558433431255   8: 0.038187582431042   0: 0.017912492938104   7: 0.017909285342410   5: 0.017906768765899   3: 0.017905695910343   1: 0.017905271601489   9: 0.017904980595657   4: 0.017904915546220   2: 0.017904573437583 

training_2437     4: 0.739278137959695   2: 0.028982017094982   5: 0.028977179547501   6: 0.028967667392172   1: 0.028967013713726   0: 0.028966006353399   3: 0.028965696735403   8: 0.028965495855304   9: 0.028965419529753   7: 0.028965365818066 

training_2440     5: 0.511685090162024   0: 0.292792543929703   3: 0.024441684397153   4: 0.024441021135118   7: 0.024440095564613   6: 0.024439993477764   2: 0.024439935737970   1: 0.024439911646748   9: 0.024439862606045   8: 0.024439861342861 

training_2441     6: 0.487961295317622   8: 0.300564898783947   5: 0.026443685432075   4: 0.026436047072291   9: 0.026434329239272   7: 0.026433738497575   1: 0.026432608914207   0: 0.026431913576168   3: 0.026430785353554   2: 0.026430697813289 

training_2442     8: 0.431209144947117   6: 0.350034496174727   5: 0.027352509688290   4: 0.027346715309490   1: 0.027346460984852   0: 0.027343631830469   9: 0.027342951110276   7: 0.027342216749663   2: 0.027341463580057   3: 0.027340409625059 

training_2447     4: 0.428305737644878   6: 0.351447055862878   3: 0.104030920771683   1: 0.016647081282607   9: 0.016625713474443   0: 0.016614013875397   5: 0.016590837893361   8: 0.016580913840836   2: 0.016579227588953   7: 0.016578497764963 

training_2448     6: 0.744897157498404   0: 0.087868089343906   8: 0.046464975206404   9: 0.028158649723627   1: 0.023722657863606   4: 0.013804379846117   5: 0.013802872308286   3: 0.013765718972830   2: 0.013757786794561   7: 0.013757712442260 

training_2449     6: 0.535772540581932   0: 0.211498238124088   9: 0.091259518189874   2: 0.089878147812627   5: 0.011937741494176   3: 0.011933547455845   4: 0.011932347163896   1: 0.011931202216435   8: 0.011928552016457   7: 0.011928164944669 

training_2452     6: 0.630014497878074   1: 0.243174698625214   7: 0.015945198963481   0: 0.015840644819395   4: 0.015839285083743   5: 0.015837431377125   9: 0.015837325106828   8: 0.015837278354438   2: 0.015836994060887   3: 0.015836645730817 

training_2456     6: 0.789273527005776   7: 0.104431815326347   5: 0.023031376334698   9: 0.011913648130694   1: 0.011904702604196   4: 0.011895940026367   0: 0.011894788150543   8: 0.011885389234626   3: 0.011884824932302   2: 0.011883988254451 

training_2458     5: 0.443142720970035   6: 0.225164956825190   9: 0.090943988568494   2: 0.080042708156315   4: 0.073263752703735   7: 0.017489623542209   3: 0.017488636282802   0: 0.017488437711703   1: 0.017487651514568   8: 0.017487523724948 

training_2459     5: 0.749618680168859   4: 0.027823194824380   0: 0.027819876989107   3: 0.027819860969640   8: 0.027819779327794   2: 0.027819776374787   1: 0.027819756411657   6: 0.027819720623508   9: 0.027819711586076   7: 0.027819642724193 

training_246      6: 0.766338911016632   1: 0.078539304695817   3: 0.071521348966452   0: 0.011960518221149   7: 0.011943918632405   8: 0.011941352779366   5: 0.011940292666686   9: 0.011938601426174   4: 0.011937915375579   2: 0.011937836219739 

training_2460     2: 0.461665154574154   5: 0.264798901236641   4: 0.034203286227294   9: 0.034191288733293   0: 0.034190921738676   1: 0.034190711797503   3: 0.034190406998204   6: 0.034189950515367   8: 0.034189839274397   7: 0.034189538904471 

training_2462     5: 0.592045209140933   0: 0.201361581802816   6: 0.064877715470741   1: 0.020250053941346   9: 0.020244679789441   8: 0.020244605469617   7: 0.020244148255695   2: 0.020244146328773   4: 0.020244016289116   3: 0.020243843511522 

training_2465     8: 0.768588150421089   6: 0.025716934388186   9: 0.025714522226796   5: 0.025714277444331   4: 0.025712008599730   0: 0.025711755980675   7: 0.025711675572769   1: 0.025710619440021   2: 0.025710110479989   3: 0.025709945446415 

training_2466     8: 0.775167281079193   6: 0.024985723975615   9: 0.024983635133412   5: 0.024983438645908   0: 0.024980527522726   2: 0.024980380289321   1: 0.024980209170476   4: 0.024979985471339   7: 0.024979919103084   3: 0.024978899608928 

training_2467     6: 0.731315781023833   8: 0.087050193540171   0: 0.051668328830075   1: 0.031784411587088   5: 0.029667197980243   4: 0.013706076157967   3: 0.013702820115570   7: 0.013702024307694   9: 0.013701681478699   2: 0.013701484978660 

training_2468     8: 0.378817781255591   6: 0.356687993955296   7: 0.114374716673090   9: 0.021450484671263   5: 0.021447699270343   0: 0.021445581345768   4: 0.021444925408216   1: 0.021444113457125   2: 0.021443546833972   3: 0.021443157129336 

training_247      6: 0.547972161446793   0: 0.317063147354028   3: 0.028845424370364   4: 0.024700648794041   1: 0.021790649081763   2: 0.018889846432331   9: 0.010236832980577   5: 0.010207597663448   7: 0.010148808739861   8: 0.010144883136793 

training_2470     0: 0.368199722778699   6: 0.319202845380067   5: 0.208916271658937   1: 0.014815487031651   2: 0.014813123879693   3: 0.014810856297767   4: 0.014810538519277   9: 0.014810511479590   8: 0.014810454054673   7: 0.014810188919646 

training_2471     4: 0.815210305141907   5: 0.020539159305988   6: 0.020532165587023   1: 0.020531993603174   0: 0.020531652531310   2: 0.020531138924409   9: 0.020531041970332   8: 0.020530990084099   3: 0.020530812698629   7: 0.020530740153130 

training_2474     8: 0.421494336451532   5: 0.411176282615575   6: 0.043100939156183   7: 0.018014787388677   1: 0.017721792155098   9: 0.017701294015631   0: 0.017700575424729   2: 0.017697130172109   3: 0.017696616047137   4: 0.017696246573330 

training_2475     0: 0.616634946512219   1: 0.177848354975388   6: 0.097403671036842   4: 0.029331190130483   5: 0.013142581653552   3: 0.013133092246375   9: 0.013127162213096   8: 0.013126591552800   7: 0.013126282681349   2: 0.013126126997895 

training_2476     2: 0.482486989503389   6: 0.310196915118685   0: 0.083424866401443   7: 0.018076596764174   5: 0.017642798389910   9: 0.017638548135788   1: 0.017637697581157   8: 0.017633056977164   4: 0.017632015449677   3: 0.017630515678615 

training_2478     4: 0.739949796707038   5: 0.028900034815580   8: 0.028894001666512   3: 0.028893874270586   9: 0.028893774828370   2: 0.028893760873634   7: 0.028893721977543   0: 0.028893721548807   6: 0.028893699393845   1: 0.028893613918085 

training_2479     4: 0.798676280383939   5: 0.022373479814934   6: 0.022370388361476   2: 0.022370233551191   9: 0.022369452403880   1: 0.022368442741051   0: 0.022368314917193   3: 0.022367892260604   7: 0.022367833822422   8: 0.022367681743311 

training_248      6: 0.743926825254797   1: 0.111811330698922   0: 0.043418461608566   3: 0.035819724713682   4: 0.010842567369311   9: 0.010836333370466   5: 0.010836318974356   8: 0.010836168667718   7: 0.010836136483347   2: 0.010836132858834 

training_2480     6: 0.435525811770547   0: 0.272956591550164   4: 0.143521864099582   5: 0.071728347763626   1: 0.012785076404399   2: 0.012696557198678   7: 0.012696552999175   9: 0.012696492536400   8: 0.012696433952208   3: 0.012696271725222 

training_2482     5: 0.611908931501321   1: 0.183218502503629   6: 0.025611407075275   0: 0.025609896888778   8: 0.025608879768161   7: 0.025608814811441   3: 0.025608786431287   4: 0.025608693887220   2: 0.025608055015714   9: 0.025608032117174 

training_2483     5: 0.616185890069979   4: 0.213427935094144   3: 0.056999955810580   2: 0.016252082756238   9: 0.016196157957784   0: 0.016191096921314   1: 0.016190840854720   6: 0.016187469764733   8: 0.016184541521751   7: 0.016184029248757 

training_2484     5: 0.793794936450846   4: 0.022918081822821   1: 0.022912733542620   6: 0.022910817244292   2: 0.022910816409739   9: 0.022910678019848   7: 0.022910650939702   8: 0.022910580872959   0: 0.022910356772740   3: 0.022910347924432 

training_2488     5: 0.599055577144932   1: 0.121573831349057   7: 0.111273308590589   4: 0.024019427487055   6: 0.024014337873455   8: 0.024012855271886   3: 0.024012690867377   0: 0.024012679948924   2: 0.024012678662925   9: 0.024012612803801 

training_249      6: 0.788646908312936   1: 0.066906969477810   3: 0.032766066872092   8: 0.031468230785211   0: 0.013389720522671   9: 0.013364989299836   7: 0.013364941920307   5: 0.013364155878969   2: 0.013364021628076   4: 0.013363995302092 

training_2490     4: 0.403202298991133   1: 0.391545571750701   5: 0.025664687240236   0: 0.025661390324256   3: 0.025654708668439   7: 0.025654554495748   8: 0.025654461913658   6: 0.025654190435007   2: 0.025654120201859   9: 0.025654015978962 

training_2491     1: 0.503341406385976   0: 0.168654187148635   6: 0.132341279020027   3: 0.097491348282210   5: 0.016368730861445   2: 0.016363659225957   4: 0.016360664587640   9: 0.016359806952469   7: 0.016359719992651   8: 0.016359197542990 

training_2492     0: 0.487781372098104   6: 0.389240989416763   7: 0.031210033045243   4: 0.013119787001830   5: 0.013119592937047   1: 0.013108107172402   8: 0.013106632453789   9: 0.013105176302588   3: 0.013104184490181   2: 0.013104125082053 

training_2494     5: 0.780227090298274   3: 0.024429081303157   2: 0.024419222486486   4: 0.024418044898064   1: 0.024418002177327   6: 0.024417982576357   7: 0.024417710318824   0: 0.024417640448295   8: 0.024417627809121   9: 0.024417597684094 

training_2495     6: 0.646101392390436   5: 0.114183423483794   8: 0.102816900212798   3: 0.058648920251570   7: 0.013061763602619   1: 0.013047910605112   9: 0.013039400332973   0: 0.013037683659728   4: 0.013031426479954   2: 0.013031178981014 

training_2496     5: 0.765029545103754   1: 0.026115418942439   6: 0.026112630019314   4: 0.026106914913259   0: 0.026106742833678   9: 0.026106313153874   8: 0.026106143101416   7: 0.026106004888713   2: 0.026105267568225   3: 0.026105019475329 

training_2497     4: 0.744325086841839   6: 0.028423204061605   1: 0.028418735669475   0: 0.028413544361259   5: 0.028406545069428   7: 0.028405148757039   9: 0.028403099714589   2: 0.028402158841336   8: 0.028401356992803   3: 0.028401119690628 

training_2499     6: 0.694930654164310   3: 0.163264843377042   0: 0.035768695001317   1: 0.015163550638332   7: 0.015151030927146   2: 0.015145059285352   5: 0.015144469309862   9: 0.015143944460910   4: 0.015143931445150   8: 0.015143821390578 

training_2500     1: 0.340769219393273   6: 0.286778576767979   4: 0.265635243367557   3: 0.027289526423898   2: 0.013728886646165   0: 0.013187960108629   7: 0.013170630500170   5: 0.013160970096421   8: 0.013140707908712   9: 0.013138278787198 

training_2504     4: 0.491872383627257   5: 0.261896670176311   7: 0.030779354838728   8: 0.030779078642403   3: 0.030779014098028   2: 0.030778906926201   9: 0.030778702728654   1: 0.030778691801606   0: 0.030778626168435   6: 0.030778570992377 

training_2505     6: 0.610383828080264   0: 0.252923092350281   5: 0.017093340741649   1: 0.017087785392084   4: 0.017087314621021   2: 0.017086278056680   8: 0.017085307904224   9: 0.017085036273124   3: 0.017084041351896   7: 0.017083975228776 

training_2508     6: 0.815414327180305   1: 0.064939191913836   0: 0.031228882151464   5: 0.027830335441603   8: 0.010098916090398   7: 0.010097983049825   9: 0.010097836681130   2: 0.010097607651462   4: 0.010097601550758   3: 0.010097318289218 

training_2511     6: 0.654814467758157   3: 0.121475192781756   1: 0.113691144049229   0: 0.028363908227035   7: 0.013615466166221   9: 0.013612664059813   8: 0.013608849189734   5: 0.013606150634135   2: 0.013606126406901   4: 0.013606030727018 

training_2512     0: 0.671318487275485   6: 0.119766238245946   3: 0.044631402431740   1: 0.040672335904350   4: 0.021097531883839   2: 0.020547702632735   5: 0.020499283671922   9: 0.020489195031985   8: 0.020489107540975   7: 0.020488715381023 

training_2513     1: 0.708734877129465   0: 0.106736203868502   6: 0.103787965119951   5: 0.011537648719707   8: 0.011536510829864   4: 0.011534490232157   3: 0.011533664157102   2: 0.011533249194889   7: 0.011533055050227   9: 0.011532335698137 

training_2515     9: 0.433683201608268   6: 0.356063410821479   0: 0.085447832372598   4: 0.037859295530766   7: 0.014643956188147   1: 0.014468864448568   3: 0.014461886268523   8: 0.014458322492332   5: 0.014456907102699   2: 0.014456323166620 

training_2517     0: 0.476839568886725   6: 0.283193754268211   2: 0.105445873249106   8: 0.040021094233513   1: 0.015753331064109   4: 0.015750787290415   9: 0.015750493224571   7: 0.015749155817342   5: 0.015748233816746   3: 0.015747708149263 

training_2518     5: 0.739441805349804   4: 0.028962692917909   8: 0.028949670493220   0: 0.028949519882058   2: 0.028949448779013   3: 0.028949430995645   7: 0.028949390139428   1: 0.028949371101691   9: 0.028949344105637   6: 0.028949326235595 

training_2519     5: 0.781142420778366   4: 0.024323315641691   0: 0.024316874758128   8: 0.024316865716128   7: 0.024316830303581   3: 0.024316782833719   2: 0.024316748619476   1: 0.024316746536985   9: 0.024316730254622   6: 0.024316684557302 

training_2520     6: 0.312215807594472   5: 0.300442882463963   9: 0.165884289897167   1: 0.094929129261393   3: 0.038160171810938   0: 0.026835805110920   4: 0.015390435339405   7: 0.015384831058717   8: 0.015378359261713   2: 0.015378288201312 

training_2521     6: 0.771759616033490   0: 0.089613802783973   1: 0.078429914384968   8: 0.014713117484904   7: 0.007679732248296   9: 0.007598873481089   5: 0.007564515419799   4: 0.007553443265716   3: 0.007544156534493   2: 0.007542828363273 

training_2522     6: 0.730570445359911   1: 0.104549042560584   8: 0.069066157358840   0: 0.018068106685038   2: 0.017611517684238   5: 0.012032579588610   7: 0.012030761839887   4: 0.012027855817005   9: 0.012025016008434   3: 0.012018517097454 

training_2524     6: 0.748260946236656   4: 0.086059812897945   1: 0.048189021014702   8: 0.016790284602659   0: 0.016784628144554   5: 0.016783632945775   3: 0.016783075737111   9: 0.016782990046880   7: 0.016782825018839   2: 0.016782783354879 

training_2526     1: 0.587877885511353   5: 0.163201764788658   8: 0.111966689181512   2: 0.038425174918967   7: 0.016448875865176   6: 0.016444735029191   0: 0.016416752109518   9: 0.016411276770141   4: 0.016403975917983   3: 0.016402869907500 

training_2528     5: 0.643292386188916   1: 0.106235073069086   4: 0.060298927552199   0: 0.029967967185116   6: 0.027531142185314   7: 0.027319691766460   3: 0.026897570222058   2: 0.026310094674216   8: 0.026076038164662   9: 0.026071108991974 

training_2529     6: 0.761449988519231   8: 0.080850855022145   7: 0.019718498671329   5: 0.019713324996553   0: 0.019712376724128   9: 0.019711741295392   1: 0.019711041756833   4: 0.019710830662242   2: 0.019710693841213   3: 0.019710648510933 

training_253      6: 0.777556571034691   2: 0.050669904994032   1: 0.046741424281732   0: 0.017863522209799   5: 0.017861749917942   8: 0.017861709134508   7: 0.017861501872256   9: 0.017861286408287   3: 0.017861194917694   4: 0.017861135229060 

training_2530     2: 0.479578640040251   6: 0.269387930421392   5: 0.114970319219838   8: 0.019449316263449   1: 0.019441198866751   0: 0.019436644471632   4: 0.019434342695414   9: 0.019434316136378   7: 0.019433998676991   3: 0.019433293207903 

training_2531     6: 0.577843043387669   5: 0.284636880305253   9: 0.017199472200750   0: 0.017197882022593   1: 0.017187941577499   7: 0.017187518643748   4: 0.017187336904746   8: 0.017186946730684   3: 0.017186836627830   2: 0.017186141599227 

training_2532     1: 0.712510011165449   3: 0.110907364284668   6: 0.022107886716012   5: 0.022085877601792   0: 0.022068644458315   4: 0.022064975043861   9: 0.022064548864636   8: 0.022063883080977   2: 0.022063522785655   7: 0.022063285998635 

training_2534     1: 0.292300717386089   2: 0.278799609135976   6: 0.188829045807784   4: 0.152395111428029   5: 0.014788435297934   0: 0.014606511751353   3: 0.014571575209520   8: 0.014570221258430   7: 0.014569876943492   9: 0.014568895781394 

training_2535     6: 0.715010673948018   5: 0.155498291672315   8: 0.016199568125258   7: 0.016195186630719   0: 0.016184488887483   9: 0.016182826765479   1: 0.016182496603279   4: 0.016182320858144   3: 0.016182159955667   2: 0.016181986553639 

training_2538     6: 0.321764405226589   5: 0.283348124339457   9: 0.167094300980633   1: 0.132792690664485   4: 0.015848017038026   7: 0.015833966286196   0: 0.015832905063058   3: 0.015829254907922   2: 0.015828212750351   8: 0.015828122743283 

training_2539     4: 0.592325110046241   9: 0.255149993879559   6: 0.019128339568713   1: 0.019102512016139   0: 0.019073662452892   5: 0.019048679887640   8: 0.019044834197787   7: 0.019042425422975   3: 0.019042234017075   2: 0.019042208510978 

training_254      6: 0.763116652359416   0: 0.106763477286466   7: 0.016271111290960   5: 0.016265259246517   9: 0.016264309445202   1: 0.016264302681177   8: 0.016263964248239   2: 0.016263959032954   4: 0.016263678911300   3: 0.016263285497769 

training_2540     1: 0.617856113673109   5: 0.187022782014401   8: 0.048832276686508   0: 0.045995027561626   7: 0.016757660859141   6: 0.016709088441556   3: 0.016707642360487   4: 0.016706520043036   2: 0.016706493868590   9: 0.016706394491547 

training_2542     6: 0.842475391700925   8: 0.071355252386838   7: 0.010796310774539   1: 0.010779492156534   0: 0.010766326982575   5: 0.010766000704544   2: 0.010765393629753   9: 0.010765370492228   3: 0.010765269871393   4: 0.010765191300671 

training_2543     0: 0.466261233946034   1: 0.386453453612307   7: 0.018412593125617   5: 0.018412282201441   6: 0.018411334377986   4: 0.018410169364760   2: 0.018410106720855   8: 0.018409813844875   9: 0.018409671799121   3: 0.018409341007004 

training_2544     9: 0.437209267159500   1: 0.290306085445811   5: 0.123717573266112   4: 0.039501977354398   6: 0.018281877468122   8: 0.018229957768411   0: 0.018211727450599   3: 0.018186227799830   7: 0.018177718027017   2: 0.018177588260199 

training_2546     6: 0.821061000732818   0: 0.043060943402653   1: 0.035294439955226   5: 0.014395859441277   2: 0.014368349455273   3: 0.014366310664376   9: 0.014364785700950   4: 0.014364456509018   7: 0.014362610971530   8: 0.014361243166880 

training_2548     5: 0.792034678375868   6: 0.023122152404116   0: 0.023115525136404   4: 0.023109182705220   2: 0.023106367724585   7: 0.023103590060229   8: 0.023102336034405   3: 0.023102115320089   9: 0.023102059468160   1: 0.023101992770924 

training_2549     5: 0.684989870898146   8: 0.114238966469566   6: 0.025119418506223   1: 0.025093680449366   4: 0.025093433107166   2: 0.025093297987781   0: 0.025093257514746   9: 0.025092749522077   3: 0.025092742907111   7: 0.025092582637817 

training_2550     6: 0.715950601403170   8: 0.062867677863949   0: 0.048730174305897   5: 0.046295111204103   4: 0.045242140435284   1: 0.016193254117076   7: 0.016188400002321   9: 0.016177625739214   3: 0.016177620367362   2: 0.016177394561623 

training_2551     6: 0.851798576811505   0: 0.016500205438356   1: 0.016477480128119   5: 0.016468493215561   4: 0.016460715747697   8: 0.016460333933217   2: 0.016458812127784   9: 0.016458799075961   7: 0.016458322574072   3: 0.016458260947728 

training_2552     6: 0.534441087932482   0: 0.181725049069119   5: 0.158921839145388   9: 0.017890110343492   7: 0.017843514559226   2: 0.017842276785705   1: 0.017838942597831   8: 0.017838412577096   4: 0.017829908538506   3: 0.017828858451156 

training_2553     6: 0.826166744760280   0: 0.052762532505427   1: 0.024582451933833   5: 0.013795073168906   7: 0.013782515528008   3: 0.013782332284698   8: 0.013782259187024   9: 0.013782131697323   4: 0.013782024432229   2: 0.013781934502271 

training_2554     0: 0.477144665200171   6: 0.342059743115187   8: 0.118512794557331   1: 0.009166560862077   3: 0.008893107025305   5: 0.008887669334662   9: 0.008873330328315   7: 0.008821429020620   4: 0.008820490797101   2: 0.008820209759233 

training_2555     6: 0.731721185584565   5: 0.068889655504591   9: 0.059225490230871   1: 0.020069949731711   0: 0.020024031399550   7: 0.020015073360453   8: 0.020014076584364   4: 0.020013911383183   2: 0.020013399308336   3: 0.020013226912376 

training_2557     6: 0.830079863225326   0: 0.033733612204804   7: 0.017039847634754   3: 0.017028508602058   5: 0.017023948084921   4: 0.017021621255420   8: 0.017018287103313   1: 0.017018251827236   9: 0.017018148310336   2: 0.017017911751832 

training_2558     5: 0.756329357845642   2: 0.091430626878761   6: 0.019032607425800   4: 0.019032474916410   0: 0.019029853798344   1: 0.019029157547729   9: 0.019029087174683   7: 0.019029012400406   8: 0.019028925463985   3: 0.019028896548239 

training_2559     6: 0.678230625801764   8: 0.124275747092657   5: 0.024690261812156   0: 0.024688058352586   4: 0.024687595842863   1: 0.024687494738441   7: 0.024685301807249   2: 0.024685123755002   3: 0.024684946264415   9: 0.024684844532867 

training_256      6: 0.705925961268923   0: 0.165514584650464   1: 0.025111664559934   8: 0.014796793624558   7: 0.014777832818479   9: 0.014776225311536   5: 0.014774901675922   3: 0.014774086876239   2: 0.014773976969616   4: 0.014773972244329 

training_2560     0: 0.800466940701281   5: 0.022192179804037   4: 0.022176482707809   6: 0.022168726860466   9: 0.022167148563616   1: 0.022166762454595   8: 0.022165867125981   3: 0.022165747863591   2: 0.022165168291135   7: 0.022164975627490 

training_2561     5: 0.407620641927311   8: 0.249256730599398   6: 0.167125466090886   0: 0.025147066007221   4: 0.025146893656188   7: 0.025143471033997   1: 0.025141760916420   3: 0.025139701833838   2: 0.025139282497951   9: 0.025138985436792 

training_2562     5: 0.718057987583427   9: 0.092599358230810   4: 0.023671208398366   8: 0.023667427900584   6: 0.023667423316279   0: 0.023667370099118   1: 0.023667365642300   3: 0.023667363970711   2: 0.023667254743329   7: 0.023667240115077 

training_2564     1: 0.715373508398007   0: 0.031636358824717   5: 0.031627025418700   4: 0.031624671813024   6: 0.031623657364570   2: 0.031623201095673   8: 0.031623091126666   7: 0.031623073549259   9: 0.031622946889986   3: 0.031622465519398 

training_2565     9: 0.467296901232307   6: 0.395073444184943   8: 0.017207041805431   5: 0.017206862785356   0: 0.017203938946703   1: 0.017203901058265   4: 0.017202350936686   2: 0.017201935181258   7: 0.017201855618791   3: 0.017201768250261 

training_2566     4: 0.759766995509425   5: 0.026707217612087   6: 0.026695084838472   1: 0.026694330230290   0: 0.026693789100124   9: 0.026689338312262   2: 0.026689331041617   7: 0.026688768333952   3: 0.026687827524590   8: 0.026687317497181 

training_2567     5: 0.540972993639341   7: 0.297422054471568   4: 0.020206739381243   0: 0.020202854854710   6: 0.020200477613380   1: 0.020199436566150   2: 0.020199384489158   8: 0.020199151279440   9: 0.020198639576289   3: 0.020198268128721 

training_2568     5: 0.692927589051469   4: 0.156829695897609   9: 0.018782067033074   2: 0.018781643654197   1: 0.018781514431925   0: 0.018780677620576   6: 0.018780192567174   8: 0.018778950312045   7: 0.018778855165398   3: 0.018778814266533 

training_2569     5: 0.728115436517897   3: 0.090833706852906   4: 0.022642843145568   6: 0.022633971242359   0: 0.022631060114909   9: 0.022630130677252   1: 0.022629032988783   8: 0.022628740066097   2: 0.022627637232930   7: 0.022627441161299 

training_2570     1: 0.802684657865319   6: 0.040216047678212   3: 0.019662091961292   0: 0.019644633695106   4: 0.019643058084598   5: 0.019642511533725   8: 0.019627044599770   2: 0.019626769741594   9: 0.019626656330168   7: 0.019626528510217 

training_2572     0: 0.784095087909830   6: 0.024008687814713   8: 0.023987708512082   5: 0.023987680789604   1: 0.023987535136433   9: 0.023987094104329   7: 0.023986858519534   4: 0.023986587133643   2: 0.023986475652821   3: 0.023986284427011 

training_2574     9: 0.529195958905217   6: 0.218799155250997   4: 0.100828712405839   5: 0.021605142136327   8: 0.021601947980374   0: 0.021596063703468   1: 0.021596055790795   3: 0.021592712717424   2: 0.021592604691284   7: 0.021591646418275 

training_2576     9: 0.704304579969942   6: 0.120630243451856   8: 0.025790393182278   1: 0.021330570681566   3: 0.021325637444534   5: 0.021324951000114   0: 0.021324515409082   4: 0.021323287071915   2: 0.021323044981950   7: 0.021322776806762 

training_2577     6: 0.699127425957726   5: 0.072797672240038   1: 0.028534225918018   0: 0.028526654461876   4: 0.028504073012558   9: 0.028502578845341   3: 0.028502552781762   2: 0.028502089939744   7: 0.028501389184457   8: 0.028501337658480 

training_2578     3: 0.735396876153397   5: 0.084325860115166   4: 0.039777551163355   9: 0.020103726097403   6: 0.020082350232379   0: 0.020081915160840   1: 0.020066395999082   7: 0.020065124204321   2: 0.020050578245561   8: 0.020049622628495 

training_2579     5: 0.775450855086702   3: 0.024950289753200   4: 0.024950193036536   6: 0.024950154626571   1: 0.024949926844592   0: 0.024949904859681   8: 0.024949755645434   7: 0.024949641796670   2: 0.024949639689183   9: 0.024949638661432 

training_2580     5: 0.810436233149436   4: 0.021064425852154   6: 0.021062652237598   1: 0.021062536677471   8: 0.021062536395402   0: 0.021062528396196   3: 0.021062301627198   7: 0.021062300120930   2: 0.021062257529440   9: 0.021062228014175 

training_2582     4: 0.408024844262439   6: 0.351563087702005   1: 0.030063384043355   0: 0.030053848655925   5: 0.030050878214725   2: 0.030050752929220   9: 0.030048893808465   8: 0.030048409033914   3: 0.030048027658669   7: 0.030047873691281 

training_2583     8: 0.584960465879586   6: 0.234203566916781   5: 0.022620992255098   0: 0.022610356403439   4: 0.022608870201072   9: 0.022603882317033   1: 0.022603173376761   2: 0.022596241513934   3: 0.022596231706961   7: 0.022596219429334 

training_2584     5: 0.627973475881872   8: 0.158725944977052   2: 0.026663166174802   0: 0.026662860730532   3: 0.026662752502865   6: 0.026662559497828   4: 0.026662552680291   1: 0.026662494899708   7: 0.026662107266714   9: 0.026662085388337 

training_2585     2: 0.787026196444149   5: 0.052320767255747   4: 0.020115954572876   6: 0.020084187961556   7: 0.020082133614302   0: 0.020076238257211   8: 0.020074797819072   1: 0.020074041201927   9: 0.020073572277504   3: 0.020072110595656 

training_2587     5: 0.707628826877282   4: 0.032489391462041   0: 0.032487161319123   1: 0.032485594364268   6: 0.032485519555611   8: 0.032485340146757   3: 0.032485080845035   7: 0.032484486473513   2: 0.032484319285891   9: 0.032484279670480 

training_259      6: 0.781888821980164   5: 0.096229679141284   0: 0.015336715867212   8: 0.015262058109541   9: 0.015214580750042   3: 0.015213786770735   7: 0.015213749644084   1: 0.015213640075715   4: 0.015213520399869   2: 0.015213447261355 

training_2590     4: 0.791169771452488   6: 0.023220001682678   0: 0.023211073721032   9: 0.023207040251004   8: 0.023205124846247   5: 0.023201942251758   1: 0.023197628872880   7: 0.023196819291233   3: 0.023195931665655   2: 0.023194665965025 

training_2591     5: 0.783995157338566   6: 0.024005845063314   2: 0.024001695591064   0: 0.024001356439756   1: 0.024000575092593   3: 0.023999337965965   4: 0.023999328566178   9: 0.023999153918805   7: 0.023998970483148   8: 0.023998579540612 

training_2593     5: 0.763057449380183   6: 0.026333719667908   4: 0.026332316479378   2: 0.026327456624806   0: 0.026327100531103   1: 0.026325702794631   9: 0.026324226579616   3: 0.026324133692857   7: 0.026324094638870   8: 0.026323799610647 

training_2594     6: 0.505333816186743   0: 0.292941271072339   1: 0.069670572816063   8: 0.042407502556749   5: 0.014942194589681   9: 0.014942076574646   7: 0.014940761371701   4: 0.014940724025459   2: 0.014940553239256   3: 0.014940527567364 

training_2595     6: 0.489329917594878   4: 0.166976280487020   8: 0.159717937205686   1: 0.026283277410747   7: 0.026282739428620   5: 0.026282307759848   3: 0.026282036637949   9: 0.026281924100064   2: 0.026281852018064   0: 0.026281727357124 

training_2596     0: 0.339356128945590   4: 0.291157726455376   6: 0.228321280630174   2: 0.027813410504327   1: 0.018897782253080   5: 0.018892631579497   9: 0.018890533115214   8: 0.018890459981407   7: 0.018890284131951   3: 0.018889762403383 

training_2599     6: 0.489321472921034   4: 0.166979202084539   8: 0.159723459687069   1: 0.026283277571376   7: 0.026282739542242   5: 0.026282307857348   3: 0.026282036702202   9: 0.026281924165461   2: 0.026281852065747   0: 0.026281727402983 

training_260      9: 0.559349490012461   6: 0.283014590719513   4: 0.019722552649690   5: 0.019714005544227   1: 0.019706574471403   0: 0.019700690788146   8: 0.019698739834499   7: 0.019697977264849   2: 0.019697923509305   3: 0.019697455205906 

training_2601     6: 0.566875663835001   9: 0.228766084330808   3: 0.071210051970518   7: 0.042078562801509   0: 0.015180625302866   5: 0.015178912816469   8: 0.015178716929966   1: 0.015178108145163   4: 0.015176655982548   2: 0.015176617885151 

training_2602     4: 0.780772966920890   5: 0.024366383973213   3: 0.024358581687394   9: 0.024357860743598   0: 0.024357828096345   1: 0.024357709573412   8: 0.024357532077153   6: 0.024357187469971   2: 0.024357019937384   7: 0.024356929520638 

training_2604     0: 0.621263530515660   1: 0.174731926115388   7: 0.059030070649204   4: 0.020727767352401   6: 0.020715574591078   5: 0.020712972748148   9: 0.020705339718021   8: 0.020704565449431   3: 0.020704327742848   2: 0.020703925117820 

training_2606     6: 0.695046474759896   8: 0.107540054016571   0: 0.089245823085125   7: 0.015453598339634   1: 0.015453329105877   4: 0.015453258053787   5: 0.015452012905525   9: 0.015451997939408   3: 0.015451802288086   2: 0.015451649506092 

training_2608     5: 0.679822966329641   6: 0.128616412840304   4: 0.023945575924456   3: 0.023945512020051   1: 0.023945327802191   0: 0.023945076833412   9: 0.023945039448698   2: 0.023944721235207   8: 0.023944691755272   7: 0.023944675810769 

training_2609     0: 0.522671496481249   6: 0.307338447704996   4: 0.046480766512039   7: 0.017713647503691   1: 0.017640581335461   5: 0.017633096440020   9: 0.017631528699291   8: 0.017631432371213   3: 0.017630263603215   2: 0.017628739348823 

training_2611     5: 0.704028801623321   2: 0.113178110921660   1: 0.022862550677982   6: 0.022855160812154   0: 0.022853700808842   4: 0.022850492280948   9: 0.022843347094916   8: 0.022842985662791   3: 0.022842538922258   7: 0.022842311195129 

training_2613     4: 0.669485860950964   7: 0.132074947309631   5: 0.024808863476279   3: 0.024806325571198   6: 0.024804995375135   1: 0.024804936978887   0: 0.024803720596056   8: 0.024803550364517   2: 0.024803442620012   9: 0.024803356757321 

training_2617     6: 0.790317795065738   1: 0.060819028059560   8: 0.041276999770798   4: 0.015413641489840   5: 0.015380786993829   0: 0.015362540865185   3: 0.015358163453878   9: 0.015357397969465   2: 0.015356839335983   7: 0.015356806995724 

training_2618     6: 0.564866887347480   0: 0.344659826339855   5: 0.023717938357053   7: 0.013739846241196   1: 0.008866700970103   8: 0.008849211334768   3: 0.008847567719027   4: 0.008817852731740   9: 0.008817376281780   2: 0.008816792676999 

training_2619     5: 0.671759355901332   7: 0.113437393029497   0: 0.079383669185927   6: 0.019347868364163   8: 0.019346710027692   4: 0.019346325144585   1: 0.019345160210684   9: 0.019344741061432   2: 0.019344508182434   3: 0.019344268892254 

training_2620     6: 0.598125228267792   0: 0.227916110653321   1: 0.089735660001489   4: 0.012032357846224   9: 0.012032258884931   5: 0.012031829486865   8: 0.012031751180706   7: 0.012031708245241   3: 0.012031560347559   2: 0.012031535085871 

training_2622     6: 0.756764428725853   0: 0.027035543489892   9: 0.027028243667083   1: 0.027026086663310   5: 0.027024873483290   7: 0.027024467900791   8: 0.027024310940684   4: 0.027024223898724   2: 0.027024099432102   3: 0.027023721798272 

training_2623     6: 0.732740663692059   0: 0.029707731022597   1: 0.029696268997688   5: 0.029695186146423   9: 0.029694010077864   7: 0.029693908587526   8: 0.029693524232564   2: 0.029693232016220   3: 0.029692765582746   4: 0.029692709644314 

training_2626     8: 0.676776240611103   6: 0.111203463282512   7: 0.087144500588411   1: 0.017841187993730   0: 0.017841067534978   5: 0.017840174440064   9: 0.017839988487520   4: 0.017838011883327   2: 0.017837729834791   3: 0.017837635343564 

training_2630     5: 0.646183281743937   1: 0.155154068593304   7: 0.024834395937234   0: 0.024833461577511   6: 0.024832712913055   4: 0.024832540473067   8: 0.024832456950936   3: 0.024832440508157   2: 0.024832382938173   9: 0.024832258364627 

training_2633     6: 0.714080434023847   1: 0.172829360267125   4: 0.014140333132769   0: 0.014138642232679   5: 0.014135764434207   9: 0.014135447958184   3: 0.014135246272154   7: 0.014135031555049   8: 0.014134917932373   2: 0.014134822191612 

training_2634     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_2635     6: 0.828185661947720   0: 0.047478262036619   4: 0.015546599576823   1: 0.015545853515651   3: 0.015543861943572   8: 0.015540334201166   5: 0.015540269153300   9: 0.015539981706991   7: 0.015539628527459   2: 0.015539547390699 

training_2637     0: 0.819992238901499   1: 0.020007652153799   6: 0.020005262937634   5: 0.020000966378614   9: 0.019999236031195   8: 0.019999092932387   4: 0.019999070412407   7: 0.019999031160335   3: 0.019998760429929   2: 0.019998688662200 

training_2638     1: 0.448912357972061   9: 0.361938556299000   0: 0.063306019087836   7: 0.026691633394479   4: 0.016600191983288   5: 0.016517139449201   6: 0.016513793090909   2: 0.016507007317593   8: 0.016506870549971   3: 0.016506430855663 

training_2645     5: 0.623335258846924   7: 0.214355398831255   4: 0.020296437772099   0: 0.020291123155505   6: 0.020289200608184   2: 0.020287010835750   1: 0.020286948113820   8: 0.020286704840481   9: 0.020286243882281   3: 0.020285673113701 

training_2647     6: 0.378600756564741   5: 0.243941377447921   9: 0.198669485036603   1: 0.066851372440649   3: 0.034039568656604   4: 0.015585252233476   0: 0.015580886093008   7: 0.015577619148456   2: 0.015576876815899   8: 0.015576805562645 

training_2648     6: 0.734003863043091   0: 0.073379702170085   1: 0.065188867060024   8: 0.018204830577596   5: 0.018204468781985   9: 0.018204149117126   7: 0.018203707684637   4: 0.018203611335417   2: 0.018203433730825   3: 0.018203366499214 

training_2649     4: 0.619840548708773   1: 0.141123572441971   0: 0.029905938335705   3: 0.029879092330053   5: 0.029878541278595   7: 0.029877459603796   6: 0.029873788262070   2: 0.029873762397913   8: 0.029873728260222   9: 0.029873568380900 

training_2650     6: 0.717760759720959   5: 0.087550472896511   4: 0.051668243595657   0: 0.020447826571493   1: 0.020433373918287   9: 0.020432496307664   2: 0.020429200814478   8: 0.020426130152242   7: 0.020425808377209   3: 0.020425687645502 

training_2652     6: 0.671582222899165   3: 0.197556539315540   1: 0.021964242380667   0: 0.015753920567646   5: 0.015549307133845   4: 0.015520483167052   8: 0.015519125997589   9: 0.015519112598654   2: 0.015517738442283   7: 0.015517307497559 

training_2658     5: 0.760857381561889   4: 0.075633183613459   1: 0.055504658177294   6: 0.015432462888141   0: 0.015429899551396   3: 0.015428930793803   7: 0.015428483818507   8: 0.015428479499811   9: 0.015428411971992   2: 0.015428108123707 

training_2659     4: 0.470379635886970   5: 0.247220176756695   1: 0.123195374115073   7: 0.053599440506725   0: 0.017606344540946   6: 0.017603279596907   3: 0.017599603738881   8: 0.017599069833427   2: 0.017598567801112   9: 0.017598507223263 

training_2660     1: 0.552437574846188   6: 0.180015227366637   7: 0.098330895536486   8: 0.052104871145628   0: 0.019560064521316   5: 0.019511905726979   4: 0.019510725465537   9: 0.019509755493696   2: 0.019509629372062   3: 0.019509350525471 

training_2663     5: 0.694748516779555   0: 0.115320563971726   8: 0.050279137323162   6: 0.043202358678669   1: 0.016086124428852   2: 0.016078759568332   9: 0.016072814494188   4: 0.016072326622311   7: 0.016069805530645   3: 0.016069592602559 

training_2664     5: 0.824582709634751   6: 0.019502744149500   3: 0.019490635380807   0: 0.019490166071196   7: 0.019490163061125   8: 0.019489468282985   1: 0.019489147790014   4: 0.019488633243964   9: 0.019488185367540   2: 0.019488147018119 

training_2666     9: 0.420517325672534   5: 0.278943540734693   6: 0.121038976184258   1: 0.025657873964727   0: 0.025648928695048   4: 0.025640838281947   3: 0.025639572505360   8: 0.025638464733107   7: 0.025637276317958   2: 0.025637202910368 

training_2667     5: 0.441448807125788   4: 0.399953792409782   1: 0.019825714471716   0: 0.019825479980537   6: 0.019825283072735   8: 0.019824799711186   9: 0.019824284009326   7: 0.019823989889415   2: 0.019823927289830   3: 0.019823922039685 

training_267      6: 0.754829994792878   9: 0.056916955076443   0: 0.023533176620470   5: 0.023532068670018   1: 0.023532027863324   7: 0.023531295148708   4: 0.023531231853834   8: 0.023531176841367   2: 0.023531136474348   3: 0.023530936658610 

training_2671     6: 0.383217903862574   7: 0.277850986270664   0: 0.141844545679351   1: 0.093470515857703   9: 0.017271950805982   8: 0.017270661187832   5: 0.017270440181868   4: 0.017269114046507   2: 0.017266948963437   3: 0.017266933144081 

training_2672     1: 0.600277938727461   6: 0.185893271619824   7: 0.094569771569749   0: 0.017038755446660   5: 0.017038550721456   4: 0.017037275822814   8: 0.017036239848106   9: 0.017036114786758   2: 0.017036085323026   3: 0.017035996134147 

training_2674     5: 0.753080255743689   4: 0.027439016055027   8: 0.027435313684297   2: 0.027435116669023   0: 0.027435098800694   6: 0.027435089874436   3: 0.027435060622434   1: 0.027435045849994   9: 0.027435024618656   7: 0.027434978081751 

training_2677     6: 0.586043731954703   1: 0.191517013663003   8: 0.074286014319141   9: 0.046336332363342   5: 0.016974269425100   0: 0.016973135140759   4: 0.016967521241395   3: 0.016967444567253   2: 0.016967320723114   7: 0.016967216602190 

training_2678     8: 0.715383535854416   5: 0.031632528025679   4: 0.031624792753756   6: 0.031624747178611   0: 0.031623631062884   9: 0.031622401952410   3: 0.031622216021022   1: 0.031622178630780   7: 0.031622102098201   2: 0.031621866422242 

training_2681     6: 0.360442532864322   8: 0.320844066430710   1: 0.192435674804397   5: 0.034525356420919   7: 0.015482244299431   2: 0.015283858147749   0: 0.015254401200920   9: 0.015245047105241   3: 0.015244486284197   4: 0.015242332442116 

training_2683     8: 0.793487792590281   2: 0.064248861382829   0: 0.017786004077714   6: 0.017785376789485   1: 0.017783018593817   5: 0.017782917938248   9: 0.017781712255931   4: 0.017781626290314   7: 0.017781577086014   3: 0.017781112995369 

training_2686     6: 0.839864697924210   9: 0.039447220591112   1: 0.015146926269276   5: 0.015098847874127   3: 0.015090556787368   0: 0.015080860086166   4: 0.015071563935635   8: 0.015067786692875   7: 0.015065928446857   2: 0.015065611392374 

training_2687     5: 0.824338852223376   4: 0.019521328175638   2: 0.019519371137018   6: 0.019517686849963   0: 0.019517524958861   8: 0.019517106069572   7: 0.019517093979604   9: 0.019517081012539   3: 0.019517017104514   1: 0.019516938488916 

training_2688     6: 0.504461454727151   9: 0.254337452417824   4: 0.075058081998465   0: 0.049560331098093   8: 0.033931838677256   7: 0.024697875525136   1: 0.022852569256235   5: 0.011707190967510   3: 0.011698154266086   2: 0.011695051066244 

training_2691     4: 0.782241102806319   1: 0.051622520684877   0: 0.046452649747141   8: 0.017114580837616   9: 0.017106064817718   5: 0.017099305665816   6: 0.017092743757394   3: 0.017090621689748   7: 0.017090265916602   2: 0.017090144076768 

training_2693     5: 0.726849826436583   4: 0.030355425739839   8: 0.030349567122991   9: 0.030349454263657   0: 0.030349379867000   3: 0.030349364444140   2: 0.030349346415649   1: 0.030349280584555   6: 0.030349186880557   7: 0.030349168245029 

training_2695     5: 0.577349743469578   0: 0.275351731217115   6: 0.027487355432968   1: 0.017138736844233   2: 0.017117543119769   7: 0.017112740936874   4: 0.017111132767039   8: 0.017110920953545   9: 0.017110475462232   3: 0.017109619796646 

training_2696     2: 0.606990073173047   6: 0.235771557917407   5: 0.019660748707542   8: 0.019660465465469   1: 0.019654626172011   0: 0.019653704775407   4: 0.019652940597383   7: 0.019652172018788   3: 0.019651871451586   9: 0.019651839721359 

training_2697     6: 0.521116328020622   0: 0.273315615798726   1: 0.117634539010577   7: 0.027350648096963   3: 0.015877277970017   9: 0.008942550896389   5: 0.008941818056779   8: 0.008941028224906   4: 0.008940215295037   2: 0.008939978629984 

training_2699     0: 0.793012119624142   1: 0.023004993547454   5: 0.023001493859524   6: 0.023000078824514   9: 0.022997759805623   8: 0.022997244069142   4: 0.022997101310864   7: 0.022996929775378   2: 0.022996495163533   3: 0.022995784019825 

training_27       5: 0.830026088353824   0: 0.018894705134453   6: 0.018886926424362   4: 0.018885806474117   1: 0.018885804153194   9: 0.018885672476378   8: 0.018884590905506   7: 0.018883718016166   2: 0.018883347716442   3: 0.018883340345559 

training_2700     5: 0.646336349705685   1: 0.155146604056265   4: 0.024822419461185   6: 0.024814760039185   9: 0.024813729985654   0: 0.024813475350766   8: 0.024813397200868   7: 0.024813174655181   3: 0.024813050584330   2: 0.024813038960879 

training_2708     4: 0.768566057233540   2: 0.070034811831028   5: 0.020180298318298   1: 0.020178674317542   0: 0.020174158744064   6: 0.020173681781513   9: 0.020173226727779   3: 0.020173105408103   8: 0.020173074092831   7: 0.020172911545304 

training_2709     6: 0.757740245208300   0: 0.106839430713694   1: 0.058145008337399   8: 0.016768981032482   9: 0.010089211160669   5: 0.010085184735182   4: 0.010083942890340   7: 0.010083355899022   2: 0.010082405147997   3: 0.010082234874916 

training_271      6: 0.836255696085210   5: 0.018195365229686   9: 0.018194186610338   7: 0.018193959073076   8: 0.018193795456950   0: 0.018193688020372   4: 0.018193647367639   1: 0.018193439849989   2: 0.018193307179645   3: 0.018192915127095 

training_2711     5: 0.317660866992887   0: 0.299422664130233   9: 0.137115774163139   6: 0.105423152815789   8: 0.050594365216443   4: 0.017957779968897   1: 0.017956944941933   7: 0.017956773171790   3: 0.017955913402299   2: 0.017955765196591 

training_2714     5: 0.588836521129302   1: 0.202857426865409   9: 0.053287451591532   7: 0.022164675198716   6: 0.022145901914027   8: 0.022143090014572   0: 0.022142736023855   2: 0.022140913221425   4: 0.022140777798311   3: 0.022140506242852 

training_2718     5: 0.808749511358375   6: 0.062960781209183   8: 0.016629874150367   0: 0.015983571877443   2: 0.015956623409434   4: 0.015946022317865   1: 0.015944161877135   3: 0.015943837051676   7: 0.015942823871716   9: 0.015942792876805 

training_272      6: 0.489900265186447   9: 0.188795554202507   0: 0.128262281045919   7: 0.070941780240308   5: 0.042995122545004   2: 0.015824605785533   1: 0.015823362459249   3: 0.015819310471476   4: 0.015819043020028   8: 0.015818675043529 

training_2720     5: 0.551149137832623   1: 0.167729279815631   7: 0.117193037647955   8: 0.047097712913405   6: 0.019486498629182   0: 0.019474798257970   2: 0.019470456893791   9: 0.019466739984695   3: 0.019466409948477   4: 0.019465928076272 

training_2722     6: 0.510601781418378   5: 0.325174107868595   1: 0.020532904348832   3: 0.020529377826029   4: 0.020528112960419   0: 0.020527264911965   9: 0.020526782104073   8: 0.020526693809046   7: 0.020526663095276   2: 0.020526311657387 

training_2723     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_2725     6: 0.767651137547105   0: 0.132979680674248   1: 0.023595484199949   3: 0.016255538040309   7: 0.013520159414322   2: 0.013505490838639   8: 0.008168287717001   9: 0.008108780714499   5: 0.008107931794767   4: 0.008107509059160 

training_2727     6: 0.664546943125360   5: 0.098668573474245   1: 0.065939275820380   8: 0.057464167115817   2: 0.033830878417543   7: 0.015925655144957   0: 0.015909067329418   9: 0.015905271729570   4: 0.015905089751872   3: 0.015905078090836 

training_2728     9: 0.363236597113145   6: 0.272915874724393   5: 0.222208190437914   7: 0.041527213956646   0: 0.016708098747933   1: 0.016687848475994   8: 0.016680565974417   4: 0.016678698579026   2: 0.016678561091883   3: 0.016678350898649 

training_2729     7: 0.385584811307106   6: 0.344218172155783   4: 0.091771731723992   1: 0.061841244422371   5: 0.019437905383404   0: 0.019432940975090   8: 0.019429076099443   9: 0.019428659098894   2: 0.019427847864814   3: 0.019427610969103 

training_273      6: 0.715848797402061   1: 0.115993697128454   9: 0.084883720541825   7: 0.018415216205678   8: 0.010813458613118   2: 0.010812390522329   0: 0.010810678846275   5: 0.010808078984316   4: 0.010807185618108   3: 0.010806776137835 

training_2737     2: 0.563407170271090   6: 0.236589941392743   1: 0.048092539287409   5: 0.021707831479888   4: 0.021705180662400   0: 0.021703957951032   7: 0.021699155969510   9: 0.021698730855558   8: 0.021697899922420   3: 0.021697592207949 

training_274      6: 0.746803471740462   7: 0.101939306920660   9: 0.038605514096949   0: 0.016094774261460   5: 0.016093789715041   8: 0.016093519400351   4: 0.016092715906421   1: 0.016092584168206   2: 0.016092429177168   3: 0.016091894613281 

training_2741     6: 0.740551376079474   8: 0.111118276508195   5: 0.032846466344673   1: 0.016499342233847   0: 0.016498749215588   9: 0.016497273982181   7: 0.016497214709834   4: 0.016497148184044   2: 0.016497103680890   3: 0.016497049061274 

training_2742     6: 0.473077792062712   0: 0.329781930252902   1: 0.087950398670135   5: 0.037842513960509   2: 0.011961476921481   9: 0.011880794198244   4: 0.011877281340025   7: 0.011876539563164   3: 0.011875661524513   8: 0.011875611506315 

training_2743     8: 0.765829354659567   6: 0.026032045094951   9: 0.026020643935446   5: 0.026018343736240   1: 0.026017922996023   7: 0.026017619322446   0: 0.026016816077983   4: 0.026016042952110   3: 0.026015709755089   2: 0.026015501470144 

training_2744     6: 0.872130544817953   5: 0.014212204384687   8: 0.014209030160066   4: 0.014208973183416   9: 0.014208631353198   1: 0.014207230650076   0: 0.014206962572773   7: 0.014205815425231   2: 0.014205461926577   3: 0.014205145526024 

training_2746     6: 0.694828699660838   7: 0.184970982477774   2: 0.030704973236505   3: 0.013215548027303   9: 0.012835632581109   1: 0.012808699354937   0: 0.012660574839448   5: 0.012658933105292   8: 0.012658278684445   4: 0.012657678032349 

training_2747     6: 0.749925629512755   0: 0.070789739082618   2: 0.056731362771210   3: 0.031749469056949   5: 0.015158127006413   1: 0.015134607552519   7: 0.015129157155603   4: 0.015127354832353   8: 0.015127334668393   9: 0.015127218361188 

training_2748     5: 0.779054027882866   7: 0.066465279572669   4: 0.019316569127616   2: 0.019310564018686   0: 0.019309185001037   6: 0.019308942428556   8: 0.019308916986968   9: 0.019308849488471   3: 0.019308846405654   1: 0.019308819087477 

training_2749     6: 0.733180945963794   0: 0.081617817084547   8: 0.061413643860355   5: 0.030592721244992   2: 0.015561535154801   1: 0.015545003767067   4: 0.015522954403198   7: 0.015522603679756   9: 0.015521420860015   3: 0.015521353981475 

training_275      6: 0.682507728006715   0: 0.122467410859074   1: 0.070244578246602   8: 0.031206100816208   5: 0.020639268801458   9: 0.014621356466025   7: 0.014607198172482   2: 0.014602959014489   4: 0.014560243500640   3: 0.014543156116308 

training_2750     5: 0.820184831358544   4: 0.019984995847595   6: 0.019979557616206   0: 0.019978854673098   1: 0.019978764344032   7: 0.019978673457661   9: 0.019978624879516   8: 0.019978595894922   3: 0.019978554634535   2: 0.019978547293891 

training_2751     5: 0.789376599771342   4: 0.023405942731122   0: 0.023402313761886   1: 0.023402273137537   6: 0.023402243147344   8: 0.023402214074838   3: 0.023402168766168   9: 0.023402105302986   2: 0.023402097484543   7: 0.023402041822234 

training_2752     5: 0.762765818964026   4: 0.026363173137305   8: 0.026359076827527   3: 0.026359016660638   9: 0.026358939284205   2: 0.026358921345819   7: 0.026358816684421   0: 0.026358775278859   1: 0.026358750817792   6: 0.026358710999408 

training_2754     4: 0.771110057171528   5: 0.025437313584041   8: 0.025431782608410   3: 0.025431681434761   2: 0.025431582502735   0: 0.025431573304243   9: 0.025431561917517   1: 0.025431522881227   7: 0.025431467530939   6: 0.025431457064600 

training_2756     5: 0.576107499290212   0: 0.236985611559809   9: 0.023379336140512   4: 0.023364292729452   1: 0.023360733259902   3: 0.023360720862721   2: 0.023360517857756   6: 0.023360482757316   8: 0.023360417293781   7: 0.023360388248539 

training_2757     5: 0.822796527430258   4: 0.019690803787700   6: 0.019690120165511   8: 0.019689479828821   9: 0.019689337450467   0: 0.019689232288025   1: 0.019689130520227   7: 0.019688561119649   2: 0.019688431971849   3: 0.019688375437493 

training_2760     6: 0.832067432197928   1: 0.018660871958212   0: 0.018660204537160   2: 0.018659278885774   7: 0.018659130353884   5: 0.018659081902904   9: 0.018658672137997   4: 0.018658644663732   8: 0.018658562711770   3: 0.018658120650638 

training_2761     4: 0.696492488806248   5: 0.082663110208907   7: 0.027608154353678   8: 0.027606850935505   1: 0.027605297347552   2: 0.027605055074741   3: 0.027604904174635   0: 0.027604819436528   6: 0.027604673552293   9: 0.027604646109915 

training_2762     1: 0.328814237194334   6: 0.297558454729105   7: 0.233183818409373   5: 0.047719768911073   2: 0.015484040813125   9: 0.015459292217141   8: 0.015451399572797   0: 0.015445728716771   4: 0.015441933253921   3: 0.015441326182359 

training_2763     2: 0.568801892721903   1: 0.254119637872107   4: 0.043071401382402   6: 0.019191403496748   0: 0.019144756089215   5: 0.019142512367277   8: 0.019136938620136   9: 0.019133900135745   3: 0.019129073397968   7: 0.019128483916499 

training_2764     6: 0.469107880931226   1: 0.260799405559686   0: 0.127931809494931   7: 0.059607715699423   5: 0.013759905824125   8: 0.013759162335372   9: 0.013758991988974   4: 0.013758413071458   3: 0.013758379131376   2: 0.013758335963430 

training_2765     6: 0.435055636053422   1: 0.434779772577317   3: 0.016279904801119   5: 0.016272559420259   0: 0.016269561431945   8: 0.016269043169994   7: 0.016268523622149   9: 0.016268490667618   2: 0.016268261665867   4: 0.016268246590310 

training_2767     6: 0.562505040455039   8: 0.212252166141087   4: 0.064923965751750   3: 0.043611633154261   0: 0.040016923493315   5: 0.015350735061941   1: 0.015335419250811   2: 0.015335158151564   9: 0.015334804532852   7: 0.015334154007379 

training_2768     0: 0.748441311202859   2: 0.079122552317043   5: 0.058644313733131   6: 0.016262649493776   1: 0.016260376135266   8: 0.016254337266093   7: 0.016254143444667   4: 0.016253444314905   9: 0.016253441586237   3: 0.016253430506023 

training_2769     1: 0.527311129546157   5: 0.287372255234859   6: 0.023175453564364   0: 0.023172444618887   4: 0.023162547574084   9: 0.023162121817574   8: 0.023161637800487   2: 0.023160969613593   7: 0.023160831194678   3: 0.023160609035319 

training_2771     3: 0.465212041628350   5: 0.335295625017529   4: 0.024937293868962   8: 0.024936587108655   0: 0.024936547041066   6: 0.024936537363375   2: 0.024936382960154   1: 0.024936367820828   7: 0.024936345007570   9: 0.024936272183512 

training_2772     5: 0.499556589309259   9: 0.305714233134972   0: 0.024341919639426   3: 0.024341633561048   1: 0.024341594549093   4: 0.024341304831475   6: 0.024340991725348   8: 0.024340752994040   7: 0.024340495020634   2: 0.024340485234705 

training_2773     5: 0.783209511787117   3: 0.024088615346469   4: 0.024088178512594   6: 0.024087748253586   8: 0.024087744350532   0: 0.024087742101619   1: 0.024087668237302   2: 0.024087645852799   7: 0.024087605309862   9: 0.024087540248121 

training_2775     6: 0.752591718088537   0: 0.101843329276746   9: 0.069976237871331   8: 0.018473265421817   2: 0.013522596654597   1: 0.008919553053864   7: 0.008686194854652   5: 0.008675030156101   3: 0.008656048122997   4: 0.008656026499358 

training_2777     6: 0.557972653826546   1: 0.162917417566610   5: 0.141087024303726   9: 0.049836554790212   0: 0.021850196681724   7: 0.020157196878580   8: 0.011551056213139   4: 0.011543865434215   2: 0.011543276648647   3: 0.011540757656599 

training_2779     5: 0.476972371057973   2: 0.326689474729790   8: 0.024545081216065   6: 0.024544101625921   4: 0.024542413272669   0: 0.024541846064338   3: 0.024541538403516   1: 0.024541135408566   9: 0.024541066549268   7: 0.024540971671895 

training_2781     5: 0.553146859590194   8: 0.256923868471254   0: 0.023766308415152   3: 0.023738557271337   4: 0.023738234023601   6: 0.023737873578611   7: 0.023737447580275   9: 0.023736978525908   2: 0.023736961967990   1: 0.023736910575679 

training_2782     9: 0.346761893943092   6: 0.260129786701451   5: 0.213940381963274   0: 0.044947399874488   8: 0.042214812038305   7: 0.018405320631439   2: 0.018401678157053   1: 0.018400315692832   4: 0.018399604739618   3: 0.018398806258448 

training_2783     5: 0.480772735425216   6: 0.232673519278123   3: 0.133751247814175   4: 0.041744469465175   0: 0.025821938430044   7: 0.017210520089248   1: 0.017090230882231   9: 0.016978820206567   8: 0.016978589397361   2: 0.016977929011860 

training_2784     5: 0.495081182457897   0: 0.275244346137472   6: 0.028717416899192   1: 0.028715575274348   8: 0.028708424207795   2: 0.028707006549551   4: 0.028706986367555   3: 0.028706421065944   9: 0.028706344312321   7: 0.028706296727925 

training_2785     1: 0.363083306498456   6: 0.281273935845668   7: 0.210278127264246   5: 0.048563152077198   2: 0.016171767121555   9: 0.016138290590909   8: 0.016130970962049   0: 0.016123045790377   4: 0.016119029256053   3: 0.016118374593490 

training_2787     5: 0.624252248345382   3: 0.179660302305290   4: 0.024511502243739   6: 0.024511225326548   1: 0.024511147530632   0: 0.024511105332836   2: 0.024510687800566   7: 0.024510672686111   8: 0.024510614594352   9: 0.024510493834545 

training_2789     5: 0.707165129310917   8: 0.069943327939569   7: 0.056066040873755   4: 0.055830464482982   6: 0.018508810453030   3: 0.018499063601385   2: 0.018497596036778   9: 0.018497103389483   1: 0.018496326676456   0: 0.018496137235645 

training_279      6: 0.760375426191478   1: 0.097963907726270   5: 0.017715314382444   2: 0.017714520094226   4: 0.017709620558079   0: 0.017706744996918   9: 0.017705676590252   8: 0.017703760116455   7: 0.017702574432681   3: 0.017702454911197 

training_2791     5: 0.474447956013833   6: 0.222853034281190   1: 0.181547708335151   0: 0.032145146334253   7: 0.015200353465073   8: 0.014765819985150   9: 0.014761589006419   2: 0.014759614085546   4: 0.014759513597185   3: 0.014759264896200 

training_2792     6: 0.409515431545255   1: 0.186488521025506   5: 0.156081265226044   9: 0.118231525408644   2: 0.078300661185438   0: 0.010937940680788   4: 0.010115701923541   3: 0.010109809405857   8: 0.010109621839736   7: 0.010109521759189 

training_2793     6: 0.586350063516335   5: 0.151407195690790   4: 0.114052103547115   9: 0.055642703667452   1: 0.015434148767031   2: 0.015427179296252   0: 0.015424732677645   8: 0.015421028380869   3: 0.015420461912486   7: 0.015420382544023 

training_2794     6: 0.582782479814375   1: 0.181682606465132   0: 0.029504858259149   5: 0.029444851664344   2: 0.029432983048175   4: 0.029431063369929   9: 0.029430711384970   7: 0.029430271469491   8: 0.029430198577290   3: 0.029429975947145 

training_2797     5: 0.841485659989296   6: 0.017624648469751   1: 0.017620197026507   0: 0.017612835606668   8: 0.017610514567911   2: 0.017610263811737   9: 0.017609533329450   4: 0.017609470453406   7: 0.017608573400588   3: 0.017608303344685 

training_2798     1: 0.459841255756988   0: 0.295193773312480   6: 0.030623231002599   5: 0.030621513009296   4: 0.030621024825426   9: 0.030620549171272   8: 0.030620288214183   7: 0.030619663034854   2: 0.030619374401601   3: 0.030619327271302 

training_2799     6: 0.734101025233065   0: 0.145739905848522   8: 0.015262102798915   1: 0.015031634571083   9: 0.014994277090787   7: 0.014979994194412   5: 0.014975977303045   2: 0.014972032872050   3: 0.014971680883942   4: 0.014971369204180 

training_2800     6: 0.628242259275050   8: 0.128532374788995   9: 0.092820580834297   5: 0.021513108231365   4: 0.021500180667786   0: 0.021480874361814   1: 0.021478580212966   3: 0.021477489716452   2: 0.021477406620878   7: 0.021477145290397 

training_2801     4: 0.703915873773659   5: 0.032904209039448   8: 0.032897681365669   1: 0.032897649142407   2: 0.032897626333419   0: 0.032897622168773   3: 0.032897556900577   9: 0.032897306033710   7: 0.032897293883312   6: 0.032897181359026 

training_2802     1: 0.470814867852109   0: 0.290792040916136   6: 0.144255237151962   9: 0.013451138326478   8: 0.013448494710442   5: 0.013448482054263   7: 0.013447714988855   2: 0.013447648432265   4: 0.013447583719660   3: 0.013446791847830 

training_2803     0: 0.715074438299898   1: 0.141342964878964   9: 0.046648876315331   7: 0.013874771535719   6: 0.013847498454185   5: 0.013847498022135   4: 0.013844297865570   3: 0.013841536413049   8: 0.013839310786130   2: 0.013838807429018 

training_2806     5: 0.703553923579833   4: 0.102448776796088   8: 0.066596385356875   3: 0.036169536634383   9: 0.015212030863908   1: 0.015206871034682   6: 0.015206653098434   0: 0.015203266208205   2: 0.015201579448801   7: 0.015200976978792 

training_2807     5: 0.718019423268892   2: 0.098774876675584   4: 0.022905198849940   1: 0.022900654779139   6: 0.022900547396063   0: 0.022900076165785   8: 0.022899847359837   7: 0.022899843435684   3: 0.022899790589468   9: 0.022899741479608 

training_2809     5: 0.580761795538630   3: 0.210117785792430   4: 0.026140551072050   8: 0.026140084042442   6: 0.026140083212501   0: 0.026140064250253   1: 0.026139980080598   2: 0.026139943182561   7: 0.026139898432584   9: 0.026139814395952 

training_281      6: 0.758211980981567   2: 0.071593234056609   3: 0.039470257778745   0: 0.034790732503015   1: 0.016030088979550   7: 0.015995536115637   4: 0.015978391584189   5: 0.015977002626556   9: 0.015976807123718   8: 0.015975968250414 

training_2810     5: 0.677375809511215   4: 0.133409263158291   0: 0.053166060990914   6: 0.019439421977046   8: 0.019438574311509   1: 0.019436323842621   9: 0.019435768444313   3: 0.019432958511011   2: 0.019432955707278   7: 0.019432863545801 

training_2811     3: 0.429318107376047   9: 0.353711898231037   6: 0.027148437897607   1: 0.027126835808298   5: 0.027122339756713   0: 0.027117722346482   4: 0.027115509411899   2: 0.027114707622999   8: 0.027112329970129   7: 0.027112111578789 

training_2813     0: 0.622751305689899   1: 0.139795835136391   5: 0.072405083713680   6: 0.045663845228682   8: 0.019986690043721   7: 0.019881361461682   4: 0.019879231336346   9: 0.019879202574889   2: 0.019878893650536   3: 0.019878551164173 

training_2815     1: 0.666211567307962   3: 0.095289802531424   6: 0.094453680232884   9: 0.041253504451861   7: 0.017140671524440   5: 0.017133753611679   0: 0.017129941459410   4: 0.017129233024023   2: 0.017129007186338   8: 0.017128838669978 

training_2818     3: 0.430321399082628   5: 0.226788689707047   6: 0.149497167611608   1: 0.045051752093616   0: 0.042533249995517   9: 0.021278766838011   8: 0.021133475106396   4: 0.021133226817934   2: 0.021131216747029   7: 0.021131056000214 

training_2819     6: 0.781088509196255   1: 0.085678841572592   8: 0.037154446516349   9: 0.022850827199689   4: 0.012247357274134   5: 0.012198062673558   7: 0.012196273102808   0: 0.012195584690738   2: 0.012195114107878   3: 0.012194983665998 

training_2820     4: 0.809017636135257   5: 0.021225279244610   6: 0.021221044844782   0: 0.021219811860057   9: 0.021219502792194   1: 0.021219447218596   2: 0.021219438899004   8: 0.021219416505925   7: 0.021219247250610   3: 0.021219175248963 

training_2825     5: 0.736294815895357   4: 0.029306219521085   0: 0.029299967286848   8: 0.029299961825640   7: 0.029299910884632   3: 0.029299882800661   2: 0.029299867642781   1: 0.029299829965989   9: 0.029299810612579   6: 0.029299733564426 

training_2826     5: 0.740474865812064   4: 0.028846395270147   8: 0.028835041048425   3: 0.028834902023596   0: 0.028834895721059   2: 0.028834854644224   7: 0.028834854482213   1: 0.028834764887175   9: 0.028834735128978   6: 0.028834690982119 

training_2827     6: 0.548887672018447   7: 0.196124760201930   5: 0.131124048435142   4: 0.017699682375267   1: 0.017696042458844   9: 0.017694514219761   0: 0.017694464760329   8: 0.017693960674535   3: 0.017692560611309   2: 0.017692294244435 

training_2828     6: 0.823195440599248   3: 0.060586428653846   0: 0.039632655107787   1: 0.014353281684285   8: 0.013477546986820   5: 0.009754074759301   9: 0.009751892950540   2: 0.009751443284842   4: 0.009749148270419   7: 0.009748087702911 

training_283      6: 0.753417704993311   5: 0.027409684587276   8: 0.027399915554965   0: 0.027397484290107   3: 0.027396333595608   9: 0.027396176942111   4: 0.027396111579186   7: 0.027395982348479   1: 0.027395549083785   2: 0.027395057025172 

training_2833     4: 0.325298327789147   0: 0.295493110100495   6: 0.270916896800273   1: 0.016500997490936   7: 0.015936698040752   9: 0.015358883687239   8: 0.015289405586800   2: 0.015169472754824   5: 0.015020051094551   3: 0.015016156654983 

training_2834     4: 0.800517931684341   5: 0.022169080384801   8: 0.022164454294166   2: 0.022164289086921   6: 0.022164161698880   9: 0.022164137356073   3: 0.022164044606888   0: 0.022163973837103   1: 0.022163969668309   7: 0.022163957382518 

training_2836     4: 0.771856929686598   5: 0.025353565864995   9: 0.025352647570704   6: 0.025348682075244   1: 0.025348315649318   0: 0.025348186776268   8: 0.025348067214720   3: 0.025347914559057   2: 0.025347854638681   7: 0.025347835964415 

training_2838     6: 0.580709607438531   3: 0.214274724669821   8: 0.101156499304155   0: 0.014838767630034   7: 0.014837693711834   9: 0.014837631335828   2: 0.014836801612942   4: 0.014836126748835   5: 0.014836089181438   1: 0.014836058366582 

training_2839     5: 0.818835169346952   4: 0.020131201739467   6: 0.020130723940874   7: 0.020129173543326   0: 0.020129162029247   1: 0.020128967733627   9: 0.020128955166121   8: 0.020128933306451   3: 0.020128861034255   2: 0.020128852159680 

training_284      6: 0.759312015363688   9: 0.113502522889525   8: 0.015908504327524   3: 0.015903374930167   1: 0.015903292084523   5: 0.015896972120048   0: 0.015893930015419   4: 0.015893294991201   7: 0.015893256605971   2: 0.015892836671933 

training_2843     6: 0.802299030685310   0: 0.058748166151173   7: 0.017385009246375   8: 0.017376027845632   1: 0.017367750057522   5: 0.017366732101346   9: 0.017366625829843   4: 0.017364572550538   2: 0.017363232542469   3: 0.017362852989792 

training_2847     6: 0.444857154885776   4: 0.365121595786156   5: 0.023773184143312   1: 0.023751205950624   0: 0.023751205726712   3: 0.023749813469036   9: 0.023749298550633   2: 0.023749283691596   8: 0.023748674215606   7: 0.023748583580548 

training_2848     6: 0.715144115460739   0: 0.159188149371523   8: 0.031954386237945   1: 0.013389708610437   4: 0.013388505944419   5: 0.013387991133281   7: 0.013386897422188   9: 0.013386791151361   3: 0.013386770148238   2: 0.013386684519867 

training_2849     5: 0.428639399678368   3: 0.339381171397496   6: 0.070899922887082   7: 0.023012389760658   0: 0.023012178240106   4: 0.023011409499525   8: 0.023011124654779   2: 0.023010993726346   1: 0.023010792032156   9: 0.023010618123485 

training_2850     4: 0.692446411224140   2: 0.140095709989196   6: 0.020978206945085   0: 0.020941061966853   9: 0.020931571489477   1: 0.020929331117743   8: 0.020926410741301   5: 0.020925311202001   7: 0.020914488091059   3: 0.020911497233146 

training_2851     8: 0.428114053986084   6: 0.352709344710665   1: 0.060208394574402   5: 0.058843206743855   0: 0.016696331434943   9: 0.016693624648906   7: 0.016685261364567   2: 0.016684277939223   3: 0.016683074089104   4: 0.016682430508252 

training_2853     6: 0.560413476870094   1: 0.154691127155195   3: 0.080712226069150   5: 0.066891822167326   8: 0.039961021682849   0: 0.031487796283434   7: 0.016460975770412   2: 0.016460573670866   9: 0.016460539058916   4: 0.016460441271759 

training_2856     4: 0.807793943208802   5: 0.021362949165549   1: 0.021357918297349   0: 0.021356005053123   8: 0.021355018026115   6: 0.021354958555630   3: 0.021354940417904   9: 0.021354807478140   2: 0.021354782226531   7: 0.021354677570856 

training_2857     6: 0.693328360854400   5: 0.170328551721691   0: 0.017076122954684   1: 0.017039842292227   9: 0.017038026709465   8: 0.017037954833253   3: 0.017037801289874   7: 0.017037798879112   2: 0.017037776059216   4: 0.017037764406079 

training_2858     6: 0.790727498387315   5: 0.049592998258818   0: 0.019970981615685   2: 0.019963716369302   1: 0.019962196261741   4: 0.019959918213198   8: 0.019958937730359   9: 0.019958354616491   3: 0.019953247257164   7: 0.019952151289926 

training_2862     6: 0.430968308616521   1: 0.154406982399734   8: 0.120528052385789   3: 0.101809674082813   7: 0.045897911651971   4: 0.045885627344940   0: 0.045494732695429   5: 0.018337043636998   9: 0.018335868893304   2: 0.018335798292501 

training_2864     6: 0.723178395242224   1: 0.107155580256508   0: 0.046407007551236   3: 0.036060636660744   8: 0.026505947972207   4: 0.012140987888647   5: 0.012139040842200   9: 0.012138288448574   7: 0.012137584178790   2: 0.012136530958870 

training_2866     4: 0.790494460923221   5: 0.023283794680089   8: 0.023277979840603   9: 0.023277791847419   3: 0.023277790674659   2: 0.023277724933299   0: 0.023277650365050   7: 0.023277649443819   1: 0.023277605518311   6: 0.023277551773529 

training_2867     5: 0.394683478474630   2: 0.279625398185917   7: 0.109444945962741   9: 0.098710595680766   4: 0.019601310730472   1: 0.019599366029448   6: 0.019593160124795   0: 0.019582757454526   3: 0.019579837722520   8: 0.019579149634186 

training_2870     8: 0.760642403684194   5: 0.026600636613060   6: 0.026599378589780   4: 0.026596123231699   0: 0.026594947564566   9: 0.026594572211332   1: 0.026594197107904   7: 0.026593636550060   2: 0.026592473952984   3: 0.026591630494421 

training_2872     5: 0.542834952898585   6: 0.294677753842251   8: 0.020325516492194   0: 0.020312043605802   1: 0.020308931566145   9: 0.020308866936714   7: 0.020308819338946   4: 0.020308480370368   2: 0.020307915320419   3: 0.020306719628576 

training_2873     5: 0.724805561490901   4: 0.030580245719115   8: 0.030576879101726   3: 0.030576807339936   0: 0.030576801592927   2: 0.030576790594619   1: 0.030576780711387   6: 0.030576780637269   9: 0.030576693559607   7: 0.030576659252514 

training_2877     5: 0.777445982776671   4: 0.024734054672645   6: 0.024727888074267   0: 0.024727570552427   7: 0.024727537236311   8: 0.024727528907072   3: 0.024727473563729   9: 0.024727353597935   2: 0.024727336910141   1: 0.024727273708801 

training_2880     9: 0.346040202219682   6: 0.273757277080458   5: 0.202343006227707   0: 0.044544929914907   8: 0.041744548886856   7: 0.018318505718251   2: 0.018314295694364   1: 0.018313099390721   4: 0.018312252678804   3: 0.018311882188249 

training_2881     6: 0.719716362017375   0: 0.095305712270527   2: 0.073394782873187   3: 0.015952226127088   4: 0.015941249543855   5: 0.015939002870880   1: 0.015938274608534   8: 0.015937646774323   7: 0.015937591563743   9: 0.015937151350489 

training_2884     1: 0.749846986466698   4: 0.050032425839841   6: 0.039475905125207   2: 0.030642753707777   9: 0.021672899754658   0: 0.021667515092586   3: 0.021667365363105   5: 0.021666421878601   7: 0.021663914580905   8: 0.021663812190622 

training_2886     5: 0.555536489707238   6: 0.251922602772474   3: 0.024068258106120   1: 0.024068098856239   4: 0.024067810288168   0: 0.024067377338815   2: 0.024067367264672   7: 0.024067358416395   8: 0.024067352942620   9: 0.024067284307261 

training_2887     5: 0.810711777352971   0: 0.058978577745549   4: 0.016290423961016   6: 0.016289213804061   1: 0.016288962301470   9: 0.016288374313927   8: 0.016288219035813   7: 0.016288217038988   2: 0.016288196406408   3: 0.016288038039796 

training_2890     0: 0.463936274516442   5: 0.215201467752899   1: 0.189083643537936   8: 0.033808164052740   6: 0.016330077083417   4: 0.016328976702733   9: 0.016328460998816   2: 0.016328158755284   3: 0.016327530027300   7: 0.016327246572435 

training_2896     0: 0.747105704383314   1: 0.062967462040083   3: 0.023897399266663   6: 0.023736175988686   5: 0.023725422766587   8: 0.023717738102947   9: 0.023714377520852   4: 0.023713094005208   7: 0.023712224228680   2: 0.023710401696980 

training_2897     1: 0.420795121226864   6: 0.373982415045813   0: 0.060443161649179   7: 0.050406629882661   5: 0.015732217879557   4: 0.015729622574230   2: 0.015728970550033   9: 0.015727764737328   3: 0.015727184323742   8: 0.015726912130593 

training_2898     9: 0.583386175685739   1: 0.232401348485980   0: 0.039918988815013   6: 0.038982025853741   4: 0.017554821043296   5: 0.017553319225551   8: 0.017551815574166   2: 0.017551072392308   7: 0.017550279922241   3: 0.017550153001964 

training_29       6: 0.588839226833375   5: 0.140974257191774   9: 0.125183149837900   0: 0.052775689562410   1: 0.015373495970848   4: 0.015371304260871   3: 0.015371007009655   8: 0.015370918228586   7: 0.015370741622626   2: 0.015370209481954 

training_290      6: 0.796865670069110   8: 0.059720156897084   1: 0.037358240528686   3: 0.015153267651764   7: 0.015152395363854   5: 0.015150295079970   0: 0.015150293514475   9: 0.015150061219202   4: 0.015149861639555   2: 0.015149758036300 

training_2902     0: 0.407903768483758   7: 0.398757047992690   4: 0.058079281976522   1: 0.019326945120378   5: 0.019326894541449   6: 0.019324790483399   9: 0.019321025752461   8: 0.019320511420575   2: 0.019320409535596   3: 0.019319324693173 

training_2907     2: 0.522784903623384   6: 0.313951335791343   0: 0.020713990249480   9: 0.020468246552781   5: 0.020353670961725   1: 0.020351376265180   4: 0.020348151857892   8: 0.020343248080982   7: 0.020342694236389   3: 0.020342382380843 

training_2908     5: 0.770744879286557   6: 0.025473306637195   0: 0.025472984194975   4: 0.025472964167920   3: 0.025472935609314   1: 0.025472734990663   2: 0.025472648755210   8: 0.025472539890029   9: 0.025472510155525   7: 0.025472496312611 

training_2909     6: 0.649874602748966   3: 0.143208473281690   1: 0.025874743087338   0: 0.025868271047783   5: 0.025863444036896   2: 0.025862447837465   4: 0.025862395276877   9: 0.025862055721554   7: 0.025861913490139   8: 0.025861653471293 

training_2912     1: 0.425028258507357   6: 0.377338788794857   0: 0.057807421307778   3: 0.047275688813435   5: 0.015432598111145   4: 0.015432139108033   9: 0.015421616316561   8: 0.015421240808893   2: 0.015421132956818   7: 0.015421115275123 

training_2913     6: 0.776648202428394   7: 0.077959552161170   0: 0.049499925582261   1: 0.013865946154877   8: 0.013698820571726   5: 0.013669761836146   4: 0.013666897833584   9: 0.013664404199607   3: 0.013663493040276   2: 0.013662996191958 

training_2915     5: 0.779168948724230   6: 0.024562954016137   1: 0.024548672041400   0: 0.024543835250140   7: 0.024534682814239   9: 0.024529638931307   3: 0.024528185787180   8: 0.024527815603785   4: 0.024527778713263   2: 0.024527488118318 

training_2916     0: 0.483948378862695   6: 0.375442845630705   4: 0.031802584855237   1: 0.030677951322399   7: 0.013081417532384   5: 0.013013630115107   8: 0.013008631156069   9: 0.013008442700961   3: 0.013008111736462   2: 0.013008006087980 

training_2917     6: 0.796247355144435   1: 0.067087243707502   0: 0.017090566271326   5: 0.017084040533553   2: 0.017082324632512   4: 0.017082103936275   8: 0.017081765296297   9: 0.017081667587027   7: 0.017081553280556   3: 0.017081379610517 

training_2918     4: 0.723940827410723   7: 0.125348023799503   5: 0.018846158486360   6: 0.018839256810515   1: 0.018838657864063   0: 0.018838424134705   8: 0.018837387224623   3: 0.018837121742311   9: 0.018837096079170   2: 0.018837046448028 

training_2919     5: 0.795698775422073   4: 0.022707170258318   6: 0.022700232203833   8: 0.022699663587403   0: 0.022699319273629   9: 0.022699251593940   1: 0.022699065634273   7: 0.022698876739923   3: 0.022698856171469   2: 0.022698789115140 

training_2920     5: 0.812941765443713   6: 0.020785647708349   1: 0.020785506423084   0: 0.020784705040902   3: 0.020783919034251   9: 0.020783868456964   2: 0.020783730983475   4: 0.020783649578067   8: 0.020783633843141   7: 0.020783573488054 

training_2922     6: 0.743777810943227   8: 0.100493151775853   0: 0.034196808547388   2: 0.032014630600099   7: 0.014962704798592   1: 0.014913375784100   3: 0.014912148185421   5: 0.014910620485766   4: 0.014909420894764   9: 0.014909327984789 

training_2923     6: 0.755533503473379   0: 0.067291266437641   1: 0.062035371544945   2: 0.016449669318165   5: 0.016448997049688   9: 0.016448862715569   4: 0.016448665422437   7: 0.016448129420142   8: 0.016447787477254   3: 0.016447747140780 

training_2924     1: 0.436284511275135   9: 0.280755323606768   0: 0.144838671872730   4: 0.071056229055350   6: 0.011200702315114   5: 0.011180309995321   2: 0.011171728792450   8: 0.011171157897375   7: 0.011170809408687   3: 0.011170555781068 

training_2925     6: 0.431223658719342   0: 0.373374926314418   1: 0.113886751710814   9: 0.024127412212569   2: 0.009651897570317   7: 0.009564494724216   5: 0.009543162283412   4: 0.009542972227629   8: 0.009542900373505   3: 0.009541823863778 

training_2926     2: 0.651293392826011   7: 0.130958264428618   0: 0.027226013720386   1: 0.027223438289409   6: 0.027218505064768   5: 0.027217481723434   8: 0.027216422639373   4: 0.027215898869120   9: 0.027215292866358   3: 0.027215289572522 

training_2927     1: 0.694934393486991   3: 0.116440667969388   5: 0.023655621572194   6: 0.023622033109869   9: 0.023581182820656   0: 0.023579996444186   4: 0.023567544192424   8: 0.023551559962478   2: 0.023534561897815   7: 0.023532438543999 

training_2928     5: 0.778642336196415   3: 0.024605492977053   4: 0.024594682621149   6: 0.024594308080006   1: 0.024594036185427   2: 0.024593886500491   7: 0.024593860500590   0: 0.024593830963329   8: 0.024593817660287   9: 0.024593748315252 

training_2929     5: 0.493695684742424   6: 0.304827788103032   4: 0.025189775210189   8: 0.025184049609988   3: 0.025183928117653   2: 0.025183838310684   7: 0.025183771240130   9: 0.025183745816536   0: 0.025183718905538   1: 0.025183699943827 

training_293      6: 0.732139380261542   2: 0.085580380312869   5: 0.047135434754362   7: 0.019613911314281   0: 0.019283822481621   8: 0.019269372926896   9: 0.019263588783322   1: 0.019245608797552   4: 0.019235060895288   3: 0.019233439472265 

training_2930     6: 0.460421204923951   5: 0.235529671655119   0: 0.135554350236145   1: 0.060709912707389   8: 0.017993490419795   2: 0.017960256355709   9: 0.017958341340010   4: 0.017958034485590   3: 0.017957560253373   7: 0.017957177622920 

training_2933     4: 0.784487657116734   1: 0.023993504699415   5: 0.023968127665327   0: 0.023947123789969   6: 0.023944324328245   2: 0.023937029426028   8: 0.023931797850255   7: 0.023930628989427   9: 0.023930041031898   3: 0.023929765102702 

training_2936     6: 0.592548521096987   0: 0.144129197289498   9: 0.119686237052262   8: 0.043854113118385   1: 0.035847228894852   3: 0.012794864360053   5: 0.012787130468151   2: 0.012784731037826   7: 0.012784256744440   4: 0.012783719937547 

training_2938     4: 0.799347745889414   5: 0.022300790433868   8: 0.022294162402999   6: 0.022294074773699   9: 0.022294030606751   0: 0.022293927832060   3: 0.022293866613390   2: 0.022293838151549   7: 0.022293789203123   1: 0.022293774093146 

training_2939     1: 0.346761686822227   6: 0.337111644718152   0: 0.128865687110021   5: 0.026752890800117   7: 0.026752442876292   2: 0.026751207982650   4: 0.026751120127401   3: 0.026751119205730   9: 0.026751105952374   8: 0.026751094405035 

training_2940     6: 0.748038196050995   1: 0.027998325299281   0: 0.027996676247982   5: 0.027995835916876   7: 0.027995590030044   4: 0.027995252329080   2: 0.027995090827012   9: 0.027995074940371   8: 0.027995019127033   3: 0.027994939231325 

training_2942     6: 0.598960800926553   9: 0.131742847935069   0: 0.120000082761865   1: 0.045289018390730   8: 0.034869327881965   3: 0.013838907834921   2: 0.013825446155529   5: 0.013824942995282   7: 0.013824691195097   4: 0.013823933922989 

training_2944     6: 0.575298099280933   5: 0.157592763123863   8: 0.095448759057349   3: 0.071466637348523   1: 0.016705474848093   4: 0.016697947576467   0: 0.016697942937956   7: 0.016697663128436   9: 0.016697543389091   2: 0.016697169309291 

training_2945     5: 0.522234061629248   6: 0.343724922039848   1: 0.016805488256145   0: 0.016750806539412   8: 0.016747951545857   4: 0.016747651568700   7: 0.016747552052078   9: 0.016747490196223   2: 0.016747478460062   3: 0.016746597712426 

training_2946     1: 0.585446555840179   4: 0.154908217149260   5: 0.082258570911632   0: 0.025350417419459   6: 0.025341111728402   9: 0.025340856108790   2: 0.025338851301242   8: 0.025338640606007   7: 0.025338476274767   3: 0.025338302660262 

training_2947     6: 0.767767729565792   8: 0.066316288751429   7: 0.034411254357910   0: 0.033124792702515   5: 0.016397554187756   9: 0.016397011187524   1: 0.016396820119232   4: 0.016396257150297   2: 0.016396197271922   3: 0.016396094705622 

training_2948     6: 0.758879173807808   1: 0.062006375816538   0: 0.056340260990301   5: 0.017556596418426   2: 0.017541540794919   8: 0.017536819481166   7: 0.017536818672255   3: 0.017534513519906   4: 0.017534338824742   9: 0.017533561673938 

training_2950     6: 0.765425463733021   1: 0.071330664003506   7: 0.042251298309080   5: 0.017285448392523   0: 0.017285358500417   8: 0.017284943044068   4: 0.017284336705783   3: 0.017284271738418   2: 0.017284178305329   9: 0.017284037267855 

training_2951     6: 0.607311239572636   0: 0.226695686161781   1: 0.048553273702223   5: 0.016778172912035   4: 0.016777149124161   7: 0.016776979111565   9: 0.016776951800838   2: 0.016776947545020   3: 0.016776827526481   8: 0.016776772543260 

training_2952     6: 0.376525714797803   8: 0.352141229744828   7: 0.061792633885058   3: 0.060470232894146   2: 0.060182006134522   5: 0.017781079021211   0: 0.017777939460865   1: 0.017777435818364   9: 0.017776392402310   4: 0.017775335840893 

training_2953     6: 0.407137575363756   9: 0.243835474596582   4: 0.224338437482958   5: 0.017819003121606   1: 0.017812806855395   0: 0.017812591678840   8: 0.017811908173631   2: 0.017811190603874   7: 0.017810515751900   3: 0.017810496371459 

training_2954     6: 0.656351138403164   8: 0.092883460683930   7: 0.069095064633979   0: 0.067968191398292   1: 0.018953561833287   5: 0.018950286130584   9: 0.018949840611024   3: 0.018949682429749   2: 0.018949405671896   4: 0.018949368204095 

training_2955     6: 0.732165661288163   1: 0.093991872610232   8: 0.061557774541274   3: 0.016257785147149   9: 0.016006225755637   2: 0.016004692816718   0: 0.016004385163428   5: 0.016004261760699   4: 0.016003689393966   7: 0.016003651522734 

training_2956     6: 0.700031076301286   3: 0.098429473778390   1: 0.052471288622422   7: 0.039814738588474   2: 0.031617059543166   8: 0.023635561436120   0: 0.013506006582000   5: 0.013499922228590   4: 0.013499667458544   9: 0.013495205461008 

training_2957     6: 0.670436533008667   4: 0.107809010603014   3: 0.083867489844384   0: 0.057342385543538   5: 0.023805926314569   1: 0.011795130144792   8: 0.011266038944349   9: 0.011232611572674   7: 0.011227754676066   2: 0.011217119347948 

training_2958     6: 0.512395925594076   1: 0.309200814423457   5: 0.045739818558606   8: 0.043741759041932   9: 0.030392575423892   3: 0.011889622015302   4: 0.011661680342707   0: 0.011659690109931   2: 0.011659275933256   7: 0.011658838556841 

training_2959     6: 0.770137064636469   3: 0.056720341625453   0: 0.053649233606436   9: 0.017100619969402   8: 0.017070714534106   1: 0.017067675080026   5: 0.017064142835438   4: 0.017063536160450   7: 0.017063515444528   2: 0.017063156107691 

training_296      9: 0.563052703929800   1: 0.259389893080308   3: 0.049728262609882   6: 0.018268310054619   5: 0.018263755672202   0: 0.018262931015628   8: 0.018260409581933   4: 0.018258681168626   7: 0.018258130599447   2: 0.018256922287555 

training_2960     5: 0.344862570234048   3: 0.324264527913775   6: 0.186848932537103   9: 0.020575843057050   8: 0.020575380289238   0: 0.020575045532872   4: 0.020574700063638   1: 0.020574663584135   7: 0.020574622629144   2: 0.020573714158997 

training_2961     5: 0.444646247952643   6: 0.291561202839317   3: 0.120127712572785   9: 0.020526793804366   8: 0.020524362671805   1: 0.020523290559097   0: 0.020523038612405   4: 0.020522762268845   7: 0.020522504804845   2: 0.020522083913892 

training_2962     5: 0.391065551934015   6: 0.261994552516091   3: 0.127377104979354   0: 0.104178689625708   9: 0.019233153786308   8: 0.019231602093174   4: 0.019231295891674   1: 0.019230125746016   7: 0.019229277564257   2: 0.019228645863404 

training_2963     5: 0.373124607815198   6: 0.282136908088447   3: 0.207974221995690   7: 0.019540185405818   9: 0.019538698003377   4: 0.019537527892481   8: 0.019537523982542   1: 0.019537142468364   0: 0.019537059671280   2: 0.019536124676804 

training_2964     6: 0.714678532431564   3: 0.126842751933985   5: 0.019811942361457   8: 0.019811231783071   0: 0.019810040321058   1: 0.019809712446249   4: 0.019809506852146   7: 0.019808956716867   9: 0.019808688900527   2: 0.019808636253077 

training_2965     6: 0.843021662794166   0: 0.042751629907603   3: 0.028357885865753   8: 0.020211295191277   5: 0.010951438732538   7: 0.010943944545295   4: 0.010941675823772   9: 0.010940755665859   1: 0.010940077935085   2: 0.010939633538651 

training_2966     6: 0.647893290905788   7: 0.186035512076941   0: 0.020760996904880   1: 0.020759992789735   8: 0.020759606395945   9: 0.020759300541166   5: 0.020758663058476   4: 0.020758038109390   2: 0.020757378758431   3: 0.020757220459249 

training_2968     6: 0.657975138877865   1: 0.141825379688601   8: 0.089486789663580   5: 0.031094708958789   4: 0.022080094912518   3: 0.016210944240022   0: 0.010357963149897   2: 0.010333647939613   7: 0.010317703662439   9: 0.010317628906676 

training_297      6: 0.570455876229526   7: 0.238233641104586   8: 0.068341810358110   3: 0.032277311255346   0: 0.015122714299883   1: 0.015117982909159   5: 0.015115432812255   2: 0.015111800873542   4: 0.015111716879780   9: 0.015111713277813 

training_2970     0: 0.447705742010046   6: 0.335741828210382   3: 0.046853756013390   9: 0.046739659351707   8: 0.039783234965660   7: 0.016643240666621   5: 0.016634138562750   1: 0.016633066190100   4: 0.016633000090485   2: 0.016632333938859 

training_2971     6: 0.755931625467127   8: 0.088698528866462   3: 0.055993959744185   9: 0.025812016706393   0: 0.012287743342363   1: 0.012265684370721   5: 0.012253376674079   2: 0.012252609466672   7: 0.012252321126409   4: 0.012252134235590 

training_2973     6: 0.696467567985291   5: 0.132983993745021   1: 0.076979617583015   8: 0.023032007113306   2: 0.017133902728271   4: 0.010690922631829   0: 0.010687160227590   7: 0.010676525980068   3: 0.010676353808003   9: 0.010671948197606 

training_2974     6: 0.555763440397651   7: 0.321006756772220   9: 0.015592260656251   1: 0.015379758811775   0: 0.015377507463156   8: 0.015376808464218   5: 0.015376304860554   2: 0.015375780005910   4: 0.015375769798437   3: 0.015375612769826 

training_2975     6: 0.772703728414497   3: 0.059927721538357   0: 0.042032190591412   5: 0.027823199520249   7: 0.025636533861333   8: 0.020766436716787   9: 0.012778485977471   2: 0.012778034327744   4: 0.012777742843566   1: 0.012775926208584 

training_2976     6: 0.681102785023818   0: 0.130985558646558   8: 0.072759938656494   4: 0.016451458415579   5: 0.016450609132708   7: 0.016450328959113   1: 0.016450157997333   9: 0.016449849328276   2: 0.016449779260076   3: 0.016449534580045 

training_2977     6: 0.539781503574670   7: 0.255530154440816   2: 0.062338498562037   0: 0.020337378420622   1: 0.020336562981142   5: 0.020335834487159   9: 0.020335523761335   8: 0.020335053037662   4: 0.020334845141189   3: 0.020334645593367 

training_2978     6: 0.587902951013783   0: 0.202726230446389   7: 0.074571034704722   5: 0.019260274271809   9: 0.019257568397045   3: 0.019257364065441   8: 0.019257122248491   4: 0.019256126619964   1: 0.019256044800902   2: 0.019255283431454 

training_2979     6: 0.702352205466321   0: 0.209653336049932   1: 0.019657117406527   5: 0.009764457200399   8: 0.009763208503421   4: 0.009762747547597   9: 0.009762454385700   7: 0.009761547408313   2: 0.009761529875715   3: 0.009761396156075 

training_298      0: 0.729924224341449   5: 0.030013017180145   4: 0.030009558774222   1: 0.030009230878799   6: 0.030009208715168   2: 0.030008775621382   9: 0.030008401758720   7: 0.030006724854134   8: 0.030005671088016   3: 0.030005186787965 

training_2982     6: 0.775432200439893   9: 0.066005638966082   3: 0.045450669832575   7: 0.016206140166633   5: 0.016162048322502   0: 0.016156090700989   8: 0.016151972730990   1: 0.016147372855515   4: 0.016144236969697   2: 0.016143629015125 

training_2983     6: 0.737738880125268   7: 0.110552695430014   0: 0.034638901452644   5: 0.016797374041886   1: 0.016712883542597   4: 0.016712425308043   2: 0.016712043788853   8: 0.016711803287658   9: 0.016711715177396   3: 0.016711277845641 

training_2985     6: 0.697381328624055   3: 0.098403193403828   9: 0.025531061267858   8: 0.025530722623393   5: 0.025526716659363   0: 0.025525984486697   1: 0.025525629934569   7: 0.025525456353763   2: 0.025524972249179   4: 0.025524934397295 

training_299      5: 0.669671165896652   8: 0.127047484912689   3: 0.083898892818407   0: 0.017107935943059   1: 0.017047700970101   6: 0.017047399739275   4: 0.017045832993803   7: 0.017044715179320   9: 0.017044638465946   2: 0.017044233080748 

training_2990     6: 0.696481132386718   5: 0.175521877600791   0: 0.016015411740337   4: 0.015998945098207   1: 0.015998239745593   9: 0.015997451225074   8: 0.015997210761097   7: 0.015996781667409   3: 0.015996491861012   2: 0.015996457913763 

training_2993     6: 0.592442995757425   1: 0.222248507830770   9: 0.042646681904174   8: 0.020401436081068   7: 0.020387130494305   0: 0.020380644319181   5: 0.020377712343488   4: 0.020372331337268   2: 0.020371812966762   3: 0.020370746965560 

training_2994     6: 0.571070831295026   9: 0.216683709824359   1: 0.075583793725649   8: 0.034963434161174   7: 0.017500980990553   0: 0.016842735673359   5: 0.016840163115646   4: 0.016838542450248   2: 0.016837994769068   3: 0.016837813994919 

training_2995     6: 0.730946835950760   0: 0.165494425703848   5: 0.012945402150796   1: 0.012945328298035   8: 0.012944970600119   9: 0.012944827188163   7: 0.012944784629261   4: 0.012944650358339   3: 0.012944390763063   2: 0.012944384357615 

training_2996     9: 0.527054576820456   6: 0.188396905400518   1: 0.118813718567139   3: 0.054472482220088   0: 0.018546471819383   5: 0.018546452584686   8: 0.018542960995372   4: 0.018542770087512   7: 0.018542134190587   2: 0.018541527314259 

training_2998     6: 0.766247581321064   1: 0.118191283018667   9: 0.029709286938746   3: 0.012613026419060   0: 0.012239694482684   8: 0.012209853778017   7: 0.012199652308179   2: 0.012197624083967   5: 0.012197081915551   4: 0.012194915734067 

training_2999     9: 0.548030656561468   6: 0.250675458748993   1: 0.054824385282551   7: 0.020949211260056   5: 0.020923199061557   2: 0.020922963547550   0: 0.020920558134299   4: 0.020918168321553   3: 0.020918031243112   8: 0.020917367838862 

training_30       8: 0.544149443522437   5: 0.248109800450451   6: 0.025972859984896   9: 0.025970847838573   1: 0.025970448666411   0: 0.025968432057079   4: 0.025965622206815   7: 0.025965252456529   2: 0.025963890961807   3: 0.025963401855002 

training_3001     9: 0.804446842869179   6: 0.059139665221691   0: 0.017113668268698   5: 0.017046298381743   4: 0.017043605401052   8: 0.017043335121100   7: 0.017042169748439   1: 0.017041731555154   2: 0.017041362225259   3: 0.017041321207685 

training_3002     6: 0.797789240694839   0: 0.046690187175762   1: 0.045040384376681   9: 0.015784711515791   8: 0.015783921122350   5: 0.015783043166614   7: 0.015782599666610   2: 0.015782033083894   4: 0.015781970884661   3: 0.015781908312798 

training_3003     6: 0.443366794574743   2: 0.307526055204197   0: 0.088722193684322   5: 0.054282483532584   9: 0.017698889887515   3: 0.017689660328136   1: 0.017681824219616   7: 0.017677827782107   8: 0.017677168262834   4: 0.017677102523945 

training_3006     6: 0.537864489201744   8: 0.240694391055350   9: 0.027682685260911   0: 0.027681839832183   5: 0.027680645195808   1: 0.027680103631360   2: 0.027679172406238   7: 0.027679071923086   4: 0.027678826729811   3: 0.027678774763508 

training_3007     6: 0.592703464799182   8: 0.144815047094188   0: 0.141886423099052   9: 0.017230012842585   5: 0.017229340529446   1: 0.017228339225563   4: 0.017227583835970   7: 0.017226715221569   3: 0.017226665271649   2: 0.017226408080796 

training_3008     5: 0.656217098780396   8: 0.167386618371248   6: 0.022052606821469   0: 0.022052099349260   1: 0.022049731504074   9: 0.022049168101730   4: 0.022048359292462   2: 0.022048326811541   3: 0.022048028644871   7: 0.022047962322948 

training_3009     6: 0.466984323119199   4: 0.331127688001374   0: 0.050137873832525   2: 0.040994245700731   8: 0.033749204448661   3: 0.015450419129152   1: 0.015409675891208   5: 0.015390618812211   9: 0.015379404672501   7: 0.015376546392439 

training_3010     6: 0.604026445709416   9: 0.112444128746382   0: 0.105745150142498   1: 0.089997826563051   3: 0.014641276704652   5: 0.014630338864189   8: 0.014630171591670   4: 0.014628318448783   7: 0.014628285830300   2: 0.014628057399059 

training_3013     6: 0.779700755320754   1: 0.062279666983195   5: 0.034548014496009   0: 0.032400658076562   4: 0.015195510242783   2: 0.015179366043221   3: 0.015177389217307   7: 0.015173845664207   9: 0.015172499523832   8: 0.015172294432129 

training_3015     6: 0.445777503735298   2: 0.398967922086174   9: 0.019409811504366   0: 0.019408476960464   5: 0.019408174616981   4: 0.019407802333012   1: 0.019406197542634   7: 0.019405714084581   8: 0.019404382273861   3: 0.019404014862629 

training_3016     6: 0.513667786503303   9: 0.215342322926283   0: 0.163486765793312   5: 0.015359307347751   1: 0.015358745014696   8: 0.015357912009708   4: 0.015357260323017   7: 0.015357177774866   3: 0.015356375193493   2: 0.015356347113570 

training_3017     6: 0.842804653933909   8: 0.039256010632704   5: 0.014743344410791   0: 0.014743121193662   1: 0.014742556440182   2: 0.014742316561740   9: 0.014742036012291   3: 0.014742010496662   4: 0.014742005874748   7: 0.014741944443311 

training_3019     6: 0.824233366465583   0: 0.084361491917513   1: 0.027038549255018   7: 0.009246469550130   8: 0.009187461672579   4: 0.009187121415867   5: 0.009186887339822   9: 0.009186500987303   2: 0.009186234391835   3: 0.009185917004350 

training_302      5: 0.616858959818970   6: 0.261241246551151   3: 0.030139564153837   9: 0.018015287950982   8: 0.012776333167409   1: 0.012215275415862   4: 0.012212956938689   0: 0.012189495449611   2: 0.012175595871370   7: 0.012175284682118 

training_3020     6: 0.675593227177737   0: 0.172716595106166   7: 0.069953417017084   1: 0.020537745062007   5: 0.010203722982121   9: 0.010201159756660   8: 0.010198913740961   3: 0.010198480814356   2: 0.010198403966944   4: 0.010198334375964 

training_3023     0: 0.641119066882263   1: 0.183219071886170   5: 0.064783500756164   2: 0.045739316084902   6: 0.011281690068936   9: 0.010805226665725   7: 0.010763997839643   4: 0.010763256747126   8: 0.010762506135032   3: 0.010762366934038 

training_3024     6: 0.562543595301407   0: 0.331002908429071   7: 0.013496994820364   9: 0.013281898421504   5: 0.013280594638559   8: 0.013280496062440   1: 0.013279301699791   4: 0.013278919919145   2: 0.013277668984396   3: 0.013277621723323 

training_3025     5: 0.413768411735038   0: 0.404459270373426   1: 0.043142221436138   7: 0.019823287589681   3: 0.019815307963915   9: 0.019807760410311   2: 0.019801160348675   6: 0.019798262640171   8: 0.019792261435889   4: 0.019792056066757 

training_3026     1: 0.427871163475651   6: 0.202454780706444   0: 0.181444329947786   4: 0.072077670464323   3: 0.045955626531809   2: 0.020122731862892   9: 0.012673275398759   5: 0.012474465907112   7: 0.012463019218938   8: 0.012462936486287 

training_3028     6: 0.755485638363767   8: 0.088764094737433   3: 0.056099784084461   9: 0.025870940146463   0: 0.012323847406965   1: 0.012301643847364   5: 0.012289282843295   2: 0.012288512770153   7: 0.012288218847060   4: 0.012288036953040 

training_303      6: 0.682442245174901   0: 0.124216343559680   8: 0.101317282233989   5: 0.013149889823447   7: 0.013149829626283   1: 0.013145777159237   9: 0.013145641292098   4: 0.013144739606058   2: 0.013144148536502   3: 0.013144102987805 

training_3031     6: 0.742910554815924   0: 0.092896124769998   1: 0.088972227763603   3: 0.010754732686957   9: 0.010747683932923   5: 0.010744428969939   7: 0.010743871057832   4: 0.010743565340622   8: 0.010743459431111   2: 0.010743351231089 

training_3034     6: 0.743213174696998   7: 0.086862477000863   1: 0.038918666732299   0: 0.032167039590293   8: 0.030465500903717   3: 0.020790103955517   5: 0.011916548046139   4: 0.011903083246881   2: 0.011884702499144   9: 0.011878703328149 

training_3035     7: 0.687139875605183   1: 0.034795391939395   8: 0.034773624234452   5: 0.034766036377515   0: 0.034764817198508   6: 0.034756075389486   4: 0.034752069380888   2: 0.034751703140852   3: 0.034750274967528   9: 0.034750131766194 

training_3036     6: 0.688189162764951   3: 0.113408483195649   1: 0.073831856795393   0: 0.017800769061864   8: 0.017797777314754   5: 0.017797740723773   4: 0.017794999649143   9: 0.017793251608082   2: 0.017793076904107   7: 0.017792881982285 

training_3037     5: 0.736347634702385   6: 0.029313010313933   9: 0.029298340998907   0: 0.029294784912180   8: 0.029293652602729   7: 0.029292517629326   1: 0.029290725713037   4: 0.029290476270575   2: 0.029289574933688   3: 0.029289281923238 

training_3038     6: 0.492262133125218   4: 0.341808679920784   1: 0.049360374927700   9: 0.016969124923725   8: 0.016619643446373   0: 0.016606773278176   5: 0.016597967793041   2: 0.016592156786461   3: 0.016591908147415   7: 0.016591237651107 

training_3039     6: 0.698073684981389   5: 0.121374590525130   8: 0.037191214519037   1: 0.031746852902087   0: 0.018790511386745   2: 0.018585800154043   4: 0.018564443651936   7: 0.018557921080677   9: 0.018557749713877   3: 0.018557231085078 

training_304      0: 0.641793470064506   1: 0.164097797744454   9: 0.057354270642389   5: 0.019567307112272   6: 0.019534081800221   3: 0.019532387034739   8: 0.019531292111818   2: 0.019530281701208   4: 0.019529984809167   7: 0.019529126979225 

training_3040     6: 0.695453403234015   0: 0.151131881520342   4: 0.019188291756983   5: 0.019182317833175   8: 0.019181976753435   3: 0.019172948720646   2: 0.019172359214368   1: 0.019172289588827   7: 0.019172279669577   9: 0.019172251708633 

training_3041     0: 0.414868575679515   2: 0.251854143178967   3: 0.145727687711906   1: 0.026831464306607   6: 0.026802033404601   9: 0.026789422775397   8: 0.026781941268043   7: 0.026781595567839   5: 0.026781575715541   4: 0.026781560391584 

training_3042     2: 0.547713477482973   1: 0.201357991673158   0: 0.064724931706191   7: 0.058594068011571   6: 0.021273628613544   5: 0.021271746666281   4: 0.021268135542705   9: 0.021267020698169   3: 0.021266152193445   8: 0.021262847411962 

training_3043     6: 0.592377277978379   8: 0.144834231660647   0: 0.142193426840850   9: 0.017230013483458   5: 0.017229339166029   1: 0.017228339518854   4: 0.017227582842223   7: 0.017226715494179   3: 0.017226664835682   2: 0.017226408179701 

training_3044     9: 0.824725846717519   6: 0.019530199989227   8: 0.019489040023965   0: 0.019469654770747   1: 0.019468555948708   4: 0.019464594478318   5: 0.019464001091221   7: 0.019462984085453   3: 0.019462604801252   2: 0.019462518093590 

training_3046     1: 0.502358478968133   6: 0.308617814470345   5: 0.052683418303161   4: 0.019527564524760   8: 0.019498357157752   3: 0.019471130769987   9: 0.019466924358434   0: 0.019461052699259   7: 0.019457716984031   2: 0.019457541764138 

training_3047     6: 0.590054952620727   1: 0.236903287066361   9: 0.052303856661992   8: 0.035055633195715   5: 0.014308409770164   2: 0.014278678580943   7: 0.014276932979719   0: 0.014274197361451   3: 0.014272302481847   4: 0.014271749281081 

training_3048     6: 0.696462952845649   5: 0.132990441480954   1: 0.076996732255503   8: 0.023013035656503   2: 0.017133874045648   4: 0.010690924561502   0: 0.010687189625419   7: 0.010676543870246   3: 0.010676357456011   9: 0.010671948202567 

training_3049     9: 0.688780073223920   5: 0.117710859849488   6: 0.024193396189205   7: 0.024190565165722   8: 0.024190092043011   0: 0.024189562591449   4: 0.024187156722773   1: 0.024186639128482   3: 0.024185830722531   2: 0.024185824363420 

training_3051     6: 0.739982367725309   7: 0.106995946642772   5: 0.052444158660182   1: 0.014419610054970   4: 0.014364306230737   0: 0.014361008715696   8: 0.014359397602490   3: 0.014358061914450   2: 0.014357736139439   9: 0.014357406313956 

training_3053     0: 0.770291953848462   4: 0.025801361369647   9: 0.025511550313846   5: 0.025489183260859   1: 0.025487428920235   6: 0.025486291695753   2: 0.025483902934244   8: 0.025483229711556   7: 0.025482623561882   3: 0.025482474383514 

training_3056     7: 0.415933164239559   6: 0.317077803403064   0: 0.131336187566023   2: 0.025666551402261   8: 0.018338376770752   1: 0.018336137323486   5: 0.018335877379917   4: 0.018326810204013   9: 0.018324722792977   3: 0.018324368917947 

training_3057     0: 0.795045881027816   6: 0.022779640726482   8: 0.022772714732315   5: 0.022772714262756   1: 0.022772441338016   9: 0.022771929530071   7: 0.022771604000627   4: 0.022771252133226   2: 0.022771102607879   3: 0.022770719640812 

training_3060     6: 0.758693989636405   9: 0.026821300726694   8: 0.026814639051965   0: 0.026812021348834   1: 0.026810247576179   7: 0.026809950122827   3: 0.026809666917542   5: 0.026809585543590   2: 0.026809531644545   4: 0.026809067431418 

training_3061     1: 0.692232688111109   5: 0.034198232169335   0: 0.034197716800482   4: 0.034196734320858   9: 0.034195979723911   7: 0.034195878544556   2: 0.034195853670163   6: 0.034195697464904   3: 0.034195648973550   8: 0.034195570221132 

training_3062     5: 0.412170350563116   6: 0.273568745698525   1: 0.189479097347970   0: 0.031183347629485   8: 0.025267215821085   3: 0.019093779860828   9: 0.012311341550498   7: 0.012309149694336   2: 0.012308502345643   4: 0.012308469488515 

training_3063     3: 0.419821424207527   6: 0.293026486093667   0: 0.105970187482805   7: 0.063064310880451   1: 0.030627364676787   9: 0.017535993418480   5: 0.017533994974647   4: 0.017480577466378   8: 0.017480293570956   2: 0.017459367228301 

training_3065     6: 0.823804566075794   0: 0.086019941464681   1: 0.025029282561569   7: 0.009373008966493   8: 0.009296253828139   4: 0.009295905443988   5: 0.009295746661602   9: 0.009295382353904   2: 0.009295100244190   3: 0.009294812399640 

training_3067     9: 0.811037218931725   8: 0.020998260475073   6: 0.020998079727446   5: 0.020996064399535   1: 0.020995625303226   0: 0.020995489285097   4: 0.020995280196801   7: 0.020994804622226   3: 0.020994611859960   2: 0.020994565198911 

training_3068     6: 0.805795353923330   3: 0.049573034145584   0: 0.032145459758286   1: 0.030479891480336   9: 0.013670540343095   8: 0.013667883341197   5: 0.013667537079541   7: 0.013666940644847   2: 0.013666845796859   4: 0.013666513486925 

training_3069     2: 0.375622097918927   6: 0.268746599646903   1: 0.225021648048914   4: 0.034554622781315   0: 0.016046794847039   9: 0.016038841513571   7: 0.016003474445491   5: 0.015990534185247   3: 0.015988294637318   8: 0.015987091975275 

training_307      9: 0.853046526829252   6: 0.016331757531901   8: 0.016328605394890   5: 0.016328555015077   0: 0.016328063317484   1: 0.016327977917758   4: 0.016327483919454   2: 0.016327050896419   3: 0.016327012460659   7: 0.016326966717106 

training_3071     3: 0.386357339545814   6: 0.311223317683076   0: 0.113436776249167   7: 0.065769789781322   1: 0.032914583303764   9: 0.018086437672364   5: 0.018085188934181   4: 0.018048556471278   8: 0.018046395818051   2: 0.018031614540983 

training_3072     1: 0.844254709720045   5: 0.036975915635769   7: 0.014930447721837   0: 0.014857573122235   6: 0.014839150080365   9: 0.014831429158343   3: 0.014829255874217   2: 0.014828189985898   8: 0.014828073575204   4: 0.014825255126086 

training_3073     6: 0.614117121350659   0: 0.116959540018364   9: 0.116487873869446   7: 0.046134384835245   1: 0.034475121700976   8: 0.014368395849772   5: 0.014365892523515   4: 0.014365460414841   3: 0.014363189231571   2: 0.014363020205612 

training_3074     1: 0.474711552995065   8: 0.289640775416215   5: 0.029463960274424   6: 0.029457338340613   0: 0.029456497236144   7: 0.029455922956770   9: 0.029454757677174   2: 0.029453827110506   4: 0.029453494683344   3: 0.029451873309744 

training_3076     0: 0.768813286641294   6: 0.025694981750498   5: 0.025691346594009   8: 0.025688734329196   9: 0.025687590301681   3: 0.025685488171206   1: 0.025685473670348   7: 0.025685218560273   2: 0.025684172131907   4: 0.025683707849588 

training_3077     5: 0.522648473547367   1: 0.362120127942690   6: 0.014420166536941   0: 0.014407984248220   7: 0.014407221591591   9: 0.014400041573212   8: 0.014400030483411   2: 0.014399323251763   3: 0.014398377496424   4: 0.014398253328382 

training_3078     6: 0.813588972683363   0: 0.088342883378687   8: 0.024755910536982   1: 0.010506087289346   5: 0.010470803161662   9: 0.010467346617303   7: 0.010467134124916   4: 0.010467042802849   2: 0.010466921829320   3: 0.010466897575573 

training_3080     1: 0.497192392338431   5: 0.286832407875081   4: 0.082213820173443   6: 0.019112299924263   9: 0.019110927928085   8: 0.019108930813769   0: 0.019108265208857   2: 0.019107501754342   3: 0.019107035917213   7: 0.019106418066516 

training_3082     6: 0.828634335026494   8: 0.019042504295521   9: 0.019040621733392   7: 0.019040580904577   0: 0.019040491250282   5: 0.019040489922487   1: 0.019040460621174   2: 0.019040301020624   3: 0.019040146009544   4: 0.019040069215904 

training_3083     0: 0.554669986018591   5: 0.223201932977373   6: 0.027767757144687   1: 0.027767380796055   4: 0.027766325750663   2: 0.027765585578258   8: 0.027765411631990   7: 0.027765288693181   9: 0.027765239355422   3: 0.027765092053779 

training_3084     1: 0.473288086420076   6: 0.335381645733317   8: 0.095508307818151   0: 0.019174014443449   5: 0.018617086529110   7: 0.011606890679432   9: 0.011606198329105   4: 0.011606120137305   2: 0.011605891491629   3: 0.011605758418427 

training_3085     0: 0.515974749309518   1: 0.231378175222958   8: 0.105229028791316   6: 0.021064775576647   5: 0.021063349807224   4: 0.021059114704650   9: 0.021058435468595   2: 0.021057999712952   7: 0.021057391519837   3: 0.021056979886304 

training_3086     1: 0.573004950773705   6: 0.120956101676256   0: 0.094995139207899   9: 0.088478895485425   3: 0.039377401979582   4: 0.030338781702573   2: 0.017210901776033   5: 0.011912632088601   8: 0.011863665886440   7: 0.011861529423486 

training_3087     6: 0.472702724575456   9: 0.292355817276522   0: 0.029369683978798   8: 0.029368987091837   1: 0.029368098318086   5: 0.029367453846984   2: 0.029367178358780   7: 0.029366875081023   3: 0.029366676328445   4: 0.029366505144070 

training_3088     6: 0.488479475951025   2: 0.267183445443723   0: 0.030551232517166   9: 0.030545857822525   8: 0.030541700562553   1: 0.030541098603095   5: 0.030540210286448   7: 0.030539365183634   3: 0.030539003553316   4: 0.030538610076514 

training_3089     4: 0.413058667911628   5: 0.209328103218463   6: 0.179262438200792   9: 0.063743560186463   8: 0.042709366675820   1: 0.018393183611953   0: 0.018378547759692   7: 0.018375949637937   2: 0.018375348577887   3: 0.018374834219364 

training_309      6: 0.703756392369194   1: 0.134760198750266   5: 0.079294129299826   9: 0.011751790417436   0: 0.011748556220661   7: 0.011738874702812   8: 0.011738032066844   2: 0.011737714970560   4: 0.011737169852052   3: 0.011737141350349 

training_3091     1: 0.349432041787287   6: 0.240179397179758   9: 0.234456825427744   7: 0.047455455266843   8: 0.043235225358231   5: 0.017055080945763   4: 0.017053313017136   0: 0.017046298214605   2: 0.017043369346743   3: 0.017042993455889 

training_3092     0: 0.311517255612542   9: 0.311293478115546   6: 0.230270451988990   8: 0.020998344032795   2: 0.020988590619881   1: 0.020987846054042   5: 0.020987202232532   3: 0.020986246626671   4: 0.020985443836005   7: 0.020985140880996 

training_3093     0: 0.444671365852565   5: 0.186114636080309   4: 0.134784597414261   1: 0.121758275664039   7: 0.033347803483901   9: 0.015871177175197   6: 0.015871054437773   3: 0.015869303143762   2: 0.015860843483854   8: 0.015850943264339 

training_3094     0: 0.453518081344445   5: 0.397830789481919   1: 0.018590143920710   6: 0.018590074599457   3: 0.018583801242906   9: 0.018583722726695   2: 0.018578251532334   7: 0.018575120344707   4: 0.018575027831757   8: 0.018574986975072 

training_3095     6: 0.807036320326541   7: 0.044666671750069   1: 0.018541335416405   0: 0.018539299021858   5: 0.018538848340815   8: 0.018536520099463   4: 0.018536209994643   9: 0.018535110468606   2: 0.018534975918109   3: 0.018534708663491 

training_3096     8: 0.428277761545841   1: 0.281191465333725   2: 0.129549080664935   6: 0.023003849905226   0: 0.023000117683541   5: 0.022999058510141   4: 0.022995400699209   9: 0.022994829691354   7: 0.022994388263240   3: 0.022994047702787 

training_3098     6: 0.632054249081662   9: 0.150234736782761   4: 0.094528243825469   1: 0.017639266468433   5: 0.017596545825105   0: 0.017593570212144   7: 0.017588932732928   8: 0.017588694376332   3: 0.017588273873279   2: 0.017587486821888 

training_310      6: 0.608214981741278   7: 0.210693756241329   5: 0.044665079007156   1: 0.019498442289153   0: 0.019493333401309   9: 0.019491079061477   4: 0.019487710244859   8: 0.019486041326342   3: 0.019484864316092   2: 0.019484712371005 

training_3100     1: 0.496253129163713   7: 0.328852241789346   8: 0.021875586925137   6: 0.021866413837432   5: 0.021862699208777   0: 0.021860642694403   4: 0.021857551990724   2: 0.021857511862360   9: 0.021857385451542   3: 0.021856837076567 

training_3103     6: 0.578531696081335   0: 0.204806343633902   9: 0.117489011541610   8: 0.014179557447800   2: 0.014166434599056   1: 0.014166274813797   5: 0.014165935569924   3: 0.014165051790002   4: 0.014164893675564   7: 0.014164800847008 

training_3104     6: 0.599567643128932   5: 0.158080659272582   7: 0.116499418108473   8: 0.035429676867409   1: 0.015083659976764   0: 0.015071313771955   4: 0.015068901209463   9: 0.015067942610574   2: 0.015065489116688   3: 0.015065295937162 

training_3105     6: 0.827207044890181   5: 0.019201756203307   1: 0.019200124217713   9: 0.019199478211395   3: 0.019199288455105   0: 0.019199143457314   7: 0.019198844600188   4: 0.019198533360611   8: 0.019198004496389   2: 0.019197782107796 

training_3107     0: 0.703870269110115   8: 0.077038522962887   5: 0.047616992666678   4: 0.024501542108753   1: 0.024498489035509   6: 0.024496968013996   9: 0.024494942442176   7: 0.024494305462239   2: 0.024494164956672   3: 0.024493803240975 

training_3109     6: 0.505444048213103   5: 0.240987816150026   4: 0.121660078430863   1: 0.018870957658669   9: 0.018843334898766   0: 0.018842668277296   7: 0.018838758202614   8: 0.018838176729647   3: 0.018837446077484   2: 0.018836715361531 

training_311      6: 0.771470056548602   7: 0.076825785352258   1: 0.059008342991263   0: 0.027926879490936   2: 0.013792890652841   5: 0.010214197529358   8: 0.010192094398546   3: 0.010190465253788   9: 0.010189758635406   4: 0.010189529147003 

training_3110     6: 0.618600919661499   5: 0.132109011690759   8: 0.066280608336049   0: 0.059300318562076   1: 0.035377534385780   9: 0.024502320776227   3: 0.024382322444038   4: 0.013155745080735   2: 0.013153353520823   7: 0.013137865542014 

training_3111     6: 0.764123369351277   0: 0.088412931051290   1: 0.075012269025063   8: 0.016268059647047   5: 0.009388726109150   9: 0.009360108042331   3: 0.009359338829511   7: 0.009358610144433   4: 0.009358356409890   2: 0.009358231390007 

training_3114     1: 0.732681824519371   8: 0.029746266400284   7: 0.029702639331395   0: 0.029700506167835   6: 0.029697629968561   5: 0.029694479256570   9: 0.029694390581219   2: 0.029694346527192   4: 0.029693980807109   3: 0.029693936440464 

training_3115     1: 0.332959533429671   6: 0.283483100593084   2: 0.184154673528377   5: 0.108456508950825   9: 0.019312285222834   0: 0.014419101318806   4: 0.014312107261615   8: 0.014305147096430   3: 0.014299402212566   7: 0.014298140385791 

training_3117     8: 0.425549377659280   6: 0.242571550597020   0: 0.152046307711320   7: 0.066569517649107   9: 0.047828098116094   1: 0.013099999159225   4: 0.013094853639197   5: 0.013082162520990   2: 0.013081057732170   3: 0.013077075215598 

training_3118     5: 0.786320463579166   4: 0.059245556317804   9: 0.019328088936167   2: 0.019320478760362   1: 0.019315833508770   6: 0.019300994057085   8: 0.019295970869340   0: 0.019293649213858   7: 0.019290039531495   3: 0.019288925225952 

training_312      6: 0.718616488115212   0: 0.147032252172070   5: 0.016795420931662   1: 0.016794367918465   9: 0.016794112804884   4: 0.016793903042785   8: 0.016793629807267   7: 0.016793416221759   2: 0.016793285009495   3: 0.016793123976400 

training_3120     5: 0.485106548629154   0: 0.347006896530803   9: 0.021013204308127   6: 0.020984243038675   1: 0.020983275416652   2: 0.020981784850392   8: 0.020981574869375   4: 0.020981329155380   7: 0.020980582765179   3: 0.020980560436262 

training_3121     8: 0.662897749243818   6: 0.097102241966129   0: 0.053842775849118   2: 0.050390675560903   3: 0.047079768601191   1: 0.017739674423407   9: 0.017737066924635   5: 0.017737040897881   7: 0.017736949054230   4: 0.017736057478688 

training_3122     6: 0.578332003326554   0: 0.204963906101244   9: 0.117531166466060   8: 0.014179536587788   2: 0.014166431637504   1: 0.014166274410251   5: 0.014165935554325   3: 0.014165051496447   4: 0.014164893555558   7: 0.014164800864268 

training_3125     6: 0.403583083354057   3: 0.364262767299927   1: 0.029028905541021   0: 0.029028886711176   5: 0.029019702164977   4: 0.029017168901107   2: 0.029015912283045   9: 0.029014761636162   8: 0.029014473529283   7: 0.029014338579244 

training_3128     6: 0.714628154516789   7: 0.081208863665916   0: 0.070548284801190   8: 0.043773585408018   5: 0.014977756760757   1: 0.014976548688596   9: 0.014975589373551   3: 0.014970568787049   2: 0.014970494348921   4: 0.014970153649213 

training_3129     1: 0.598914487155082   3: 0.232970049928997   6: 0.021061817116093   0: 0.021038044189488   5: 0.021006870613277   8: 0.021006331528315   4: 0.021002033772083   9: 0.021000429526336   7: 0.021000287889933   2: 0.020999648280395 

training_313      6: 0.758742728678856   3: 0.058205893912689   7: 0.040271950864823   2: 0.030585582038707   9: 0.026260698128733   0: 0.017281305930547   5: 0.017181122363767   4: 0.017162964239328   1: 0.017156235483927   8: 0.017151518358623 

training_3131     6: 0.714578828340882   7: 0.081211830894719   0: 0.070596814682709   8: 0.043771457557353   5: 0.014977730015940   1: 0.014976531703065   9: 0.014975590683696   3: 0.014970568672555   2: 0.014970493899160   4: 0.014970153549920 

training_3132     6: 0.749200529076514   0: 0.098543616156054   8: 0.019037003877830   4: 0.019036495822597   5: 0.019034998010168   7: 0.019029805533058   1: 0.019029619870713   2: 0.019029440343477   3: 0.019029279571920   9: 0.019029211737668 

training_3133     6: 0.714201910469583   7: 0.081391517752835   0: 0.070198434625789   8: 0.043965395791903   5: 0.015044433344841   1: 0.015043641333099   9: 0.015042696673933   3: 0.015037578968578   2: 0.015037509331319   4: 0.015036881708120 

training_3134     9: 0.733299203368487   6: 0.029648793890684   8: 0.029634676333405   7: 0.029634260991107   0: 0.029633769867956   1: 0.029631094392738   2: 0.029629693648400   3: 0.029629677071848   5: 0.029629670369004   4: 0.029629160066372 

training_3135     6: 0.708770721155791   0: 0.150576783109312   3: 0.051776294531080   8: 0.012701792645928   5: 0.012698603185644   1: 0.012696281750760   2: 0.012695135442272   7: 0.012694896530460   4: 0.012694804761934   9: 0.012694686886818 

training_3137     6: 0.768243870637444   0: 0.121599834057312   8: 0.031232478806424   9: 0.011279373086826   1: 0.011278396718885   5: 0.011273547505152   2: 0.011273296370957   7: 0.011273195828921   3: 0.011273067551227   4: 0.011272939436850 

training_3138     8: 0.448282479501952   6: 0.354654165575774   0: 0.057202669518455   5: 0.019984649975538   4: 0.019980491279839   1: 0.019979804075538   9: 0.019979372201907   7: 0.019978958123563   3: 0.019978807547967   2: 0.019978602199468 

training_3139     1: 0.465888022872204   8: 0.274299733680881   7: 0.071719556014642   0: 0.058753794723961   5: 0.021571565092875   4: 0.021562103311819   6: 0.021554536887409   9: 0.021551305256027   2: 0.021549784408343   3: 0.021549597751838 

training_314      6: 0.807755566414418   4: 0.041163680253031   0: 0.018904011333216   9: 0.018882808419025   5: 0.018882693126911   1: 0.018882598399838   8: 0.018882492745861   7: 0.018882265081134   3: 0.018881949879846   2: 0.018881934346722 

training_3142     6: 0.424303471175946   1: 0.390888271359210   7: 0.084144419124562   0: 0.014386208758343   9: 0.014385654800986   5: 0.014380190371206   2: 0.014378447365215   4: 0.014377962266962   8: 0.014377766378450   3: 0.014377608399121 

training_3145     2: 0.568253926092436   6: 0.270095779538193   5: 0.020272326349607   4: 0.020199684404893   1: 0.020199516138836   0: 0.020198002702330   9: 0.020196428538209   3: 0.020195462517137   8: 0.020194440190938   7: 0.020194433527421 

training_3146     2: 0.570879068156171   6: 0.222995041280100   1: 0.025768597418363   9: 0.025766985382106   0: 0.025766613606210   5: 0.025766101274833   7: 0.025765082493643   8: 0.025764201285692   4: 0.025764182490650   3: 0.025764126612233 

training_3149     6: 0.462305228311043   0: 0.204608141434578   1: 0.177041082036229   9: 0.041261410069256   4: 0.040255109597972   7: 0.023877730973673   2: 0.012879754971154   5: 0.012591853677207   8: 0.012591828687061   3: 0.012587860241828 

training_315      5: 0.690697935048558   1: 0.125699362659862   4: 0.057062463405003   6: 0.018081974924570   0: 0.018078302944138   9: 0.018077076081868   2: 0.018076812082379   3: 0.018075558094072   8: 0.018075317512973   7: 0.018075197246578 

training_3152     1: 0.357735416304386   8: 0.195616782609103   6: 0.187517494128179   0: 0.119804952144534   7: 0.047457886574816   4: 0.032293360361905   5: 0.014894906782611   3: 0.014893296145596   9: 0.014893076047175   2: 0.014892828901694 

training_3153     6: 0.684635077985673   1: 0.140107786720836   7: 0.046812496342859   0: 0.018351238932413   5: 0.018349979522239   9: 0.018349336875689   2: 0.018348800190127   4: 0.018348710137001   8: 0.018348422910532   3: 0.018348150382631 

training_3154     6: 0.605460711549101   1: 0.255616924736420   5: 0.017367174465762   0: 0.017366394760521   8: 0.017365295558794   4: 0.017365087981080   2: 0.017364704658219   9: 0.017364687408755   7: 0.017364548408163   3: 0.017364470473185 

training_3155     6: 0.756328136352379   1: 0.145425666767779   7: 0.022805803163425   0: 0.010815158092673   2: 0.010813481721363   8: 0.010766684285399   5: 0.010765669313202   9: 0.010761611936787   4: 0.010759137273160   3: 0.010758651093832 

training_3157     6: 0.618784674497906   1: 0.228726103882506   7: 0.028852293423081   9: 0.026145406301814   0: 0.016262953763991   5: 0.016247457689327   4: 0.016245597798147   8: 0.016245321326757   3: 0.016245140184671   2: 0.016245051131801 

training_3159     8: 0.715385519436021   5: 0.031630553442236   4: 0.031624788891340   6: 0.031624744871281   0: 0.031623634858650   9: 0.031622400362277   3: 0.031622214638115   1: 0.031622177276366   7: 0.031622100825841   2: 0.031621865397872 

training_3161     0: 0.738526130965629   9: 0.050898085986193   5: 0.047031533511904   6: 0.044280114683091   7: 0.020162781524921   8: 0.019866594646170   1: 0.019833984589231   4: 0.019829847729768   3: 0.019788095283797   2: 0.019782831079295 

training_3162     2: 0.468899001746814   9: 0.321497990266979   5: 0.026209401767889   6: 0.026207014835833   4: 0.026201848965617   1: 0.026200376874893   7: 0.026197283005032   8: 0.026196755945259   3: 0.026196024264833   0: 0.026194302326851 

training_3163     6: 0.433032040740952   7: 0.301252380022185   8: 0.059556675360697   0: 0.059450240009311   4: 0.053980783837274   5: 0.018556367544397   9: 0.018555752176985   2: 0.018541018686426   1: 0.018538469638235   3: 0.018536271983538 

training_3164     8: 0.790110646866749   2: 0.064572718845294   0: 0.018168086830329   6: 0.018167524497717   1: 0.018164502734746   5: 0.018163869173119   9: 0.018163667752520   7: 0.018163166410212   4: 0.018163036394453   3: 0.018162780494862 

training_3166     6: 0.512011750451061   2: 0.301921386615154   5: 0.064379543116371   1: 0.031634943297396   8: 0.015032469208195   0: 0.015005616583382   4: 0.015004787005347   3: 0.015003669959119   9: 0.015003298192724   7: 0.015002535571251 

training_3168     6: 0.373684452555680   1: 0.338937784461535   0: 0.107140299221807   4: 0.097965020959890   3: 0.013734794989417   7: 0.013711364943650   5: 0.013708027595196   8: 0.013706237408579   9: 0.013706202451765   2: 0.013705815412481 

training_3169     2: 0.784872516171952   6: 0.023912543831644   8: 0.023906460945200   5: 0.023906183754615   9: 0.023905798126774   0: 0.023901986564729   4: 0.023901045039870   7: 0.023899455723461   1: 0.023897965958526   3: 0.023896043883230 

training_317      6: 0.775672944495785   0: 0.131769628115771   5: 0.011572419510883   4: 0.011571633489609   1: 0.011570418697631   9: 0.011570120818995   7: 0.011568995634988   8: 0.011568511645283   2: 0.011567665815873   3: 0.011567661775181 

training_3174     1: 0.537056043244518   5: 0.189881157736794   0: 0.156119564908106   6: 0.036343414731880   8: 0.013451612939875   3: 0.013430809940920   2: 0.013430015654654   4: 0.013429705529375   9: 0.013429449130745   7: 0.013428226183134 

training_3176     6: 0.604582759294845   8: 0.195182891069192   0: 0.086453449423575   5: 0.016262324622336   1: 0.016257808688060   4: 0.016254646366510   9: 0.016253870702130   2: 0.016251076469238   3: 0.016250606890463   7: 0.016250566473652 

training_3180     5: 0.467608503968705   2: 0.338748769044082   6: 0.024254830065209   0: 0.024225061285831   1: 0.024219040662696   4: 0.024189733187059   9: 0.024189081869325   8: 0.024188817878609   7: 0.024188083582571   3: 0.024188078455914 

training_3181     2: 0.642985375466615   6: 0.209273346482584   8: 0.018471959874929   5: 0.018471192845324   9: 0.018468143280925   1: 0.018467501294941   0: 0.018466757123884   4: 0.018466071824848   3: 0.018464991962410   7: 0.018464659843541 

training_3183     6: 0.394047480216347   7: 0.312118628123404   4: 0.080595006073374   0: 0.063217028212014   8: 0.061467113486113   5: 0.017724538727397   9: 0.017715993852135   2: 0.017707168502378   1: 0.017704491637172   3: 0.017702551169666 

training_3184     6: 0.812408089831429   5: 0.020857436349117   4: 0.020847820773760   1: 0.020844574625821   3: 0.020844108717304   0: 0.020843829754160   9: 0.020841690460408   8: 0.020837679202406   2: 0.020837414695876   7: 0.020837355589719 

training_3186     1: 0.711688152605895   0: 0.032039670913392   5: 0.032038874110000   6: 0.032034817563113   2: 0.032033479325930   9: 0.032033466203205   4: 0.032033409240979   8: 0.032032812200654   7: 0.032032668285608   3: 0.032032649551224 

training_3187     6: 0.775121792820662   7: 0.094237678833064   0: 0.016467729284503   1: 0.016356585195808   5: 0.016318374991139   9: 0.016300952096445   8: 0.016299891123903   2: 0.016299561338832   3: 0.016298816940794   4: 0.016298617374851 

training_3189     2: 0.624844439119963   5: 0.230119779058630   6: 0.018146787747062   9: 0.018135350288086   0: 0.018129382626697   1: 0.018128010397015   7: 0.018124849090547   8: 0.018124805734887   3: 0.018123479353474   4: 0.018123116583640 

training_3190     6: 0.486452594760429   8: 0.294686156980970   1: 0.027361344759543   5: 0.027358599080350   7: 0.027357937519276   9: 0.027357837933991   0: 0.027357670688228   2: 0.027356146498797   3: 0.027355862940890   4: 0.027355848837528 

training_3191     6: 0.685870935771185   5: 0.207022571096881   0: 0.013456689009579   1: 0.013421837967383   7: 0.013373724422986   8: 0.013372194714500   2: 0.013371043333786   9: 0.013370489348499   4: 0.013370477071525   3: 0.013370037263676 

training_3192     6: 0.583513852423648   0: 0.243513330741956   8: 0.069078100265935   1: 0.025399708473804   7: 0.013105746638442   5: 0.013097992197807   9: 0.013083611314181   2: 0.013079784443418   4: 0.013064687182090   3: 0.013063186318720 

training_3194     5: 0.756456213449528   1: 0.062995441921926   6: 0.022571219964492   0: 0.022569434610713   4: 0.022568280324625   2: 0.022568071512886   3: 0.022567943633008   9: 0.022567879592996   8: 0.022567866343551   7: 0.022567648646275 

training_3198     0: 0.564093963303131   8: 0.156128056089223   7: 0.100224285253767   6: 0.075088934077624   5: 0.029117203538152   1: 0.015074765643932   4: 0.015069508930297   9: 0.015068139701084   2: 0.015067789275029   3: 0.015067354187761 

training_3199     6: 0.849723014418436   1: 0.016698286192068   0: 0.016698027835785   8: 0.016697995559661   5: 0.016697827516041   4: 0.016697249348414   9: 0.016697139446733   7: 0.016696924523523   2: 0.016696824679865   3: 0.016696710479474 

training_320      6: 0.584995611105080   7: 0.224831789724475   4: 0.041712154545990   2: 0.036111560971572   8: 0.035488275282849   3: 0.015385357032159   1: 0.015377626258003   5: 0.015366730350245   0: 0.015366187079966   9: 0.015364707649662 

training_3204     6: 0.650315447512694   0: 0.198246227337985   3: 0.018940950838301   2: 0.018930143082166   5: 0.018929672899519   9: 0.018928503656919   4: 0.018928168585764   1: 0.018927627635017   7: 0.018926655074599   8: 0.018926603377036 

training_3205     1: 0.434381994550927   5: 0.375562713604783   3: 0.044295631429862   8: 0.039044399692557   0: 0.017789992398139   6: 0.017788535333158   9: 0.017784997954484   4: 0.017784316733917   2: 0.017784173263791   7: 0.017783245038383 

training_3206     6: 0.511502337916131   3: 0.125110874710092   7: 0.117828407157266   1: 0.092313389734640   0: 0.057497129974499   5: 0.019164690210626   8: 0.019149073590515   9: 0.019146681151183   2: 0.019144590004174   4: 0.019142825550875 

training_3207     6: 0.723160570515239   0: 0.080793397668443   7: 0.044835437596304   3: 0.021616124820056   8: 0.021603404180717   5: 0.021600271961216   9: 0.021599537652941   4: 0.021597474361736   1: 0.021597304421494   2: 0.021596476821853 

training_3210     2: 0.423207487273017   0: 0.362340348673980   9: 0.090831656931814   6: 0.017668632444182   4: 0.017660726637816   1: 0.017659786256645   5: 0.017659609437314   7: 0.017658007940841   3: 0.017657003679815   8: 0.017656740724578 

training_3211     6: 0.788791579007589   7: 0.044389694581322   3: 0.020859015330630   8: 0.020855034841217   5: 0.020852816034588   9: 0.020851514525982   0: 0.020851465373457   1: 0.020849980447089   4: 0.020849831753507   2: 0.020849068104618 

training_3216     0: 0.680699283365944   6: 0.160531747694732   5: 0.019858877351858   1: 0.019854766942415   9: 0.019846189739964   8: 0.019842831846393   4: 0.019842701252016   2: 0.019841439118572   7: 0.019841291824787   3: 0.019840870863320 

training_3217     6: 0.620348962261821   1: 0.173659492029301   8: 0.089539845722818   2: 0.029053074985465   9: 0.020768304482968   0: 0.020018424257426   5: 0.011655553501700   3: 0.011654396684041   4: 0.011652609416478   7: 0.011649336657982 

training_3219     6: 0.781251221766629   8: 0.053819091761936   4: 0.052617204330801   9: 0.016048635217728   0: 0.016044899245974   1: 0.016044800709859   5: 0.016044106960009   3: 0.016043681476984   7: 0.016043275803834   2: 0.016043082726246 

training_322      6: 0.480504312609500   0: 0.378778715243083   8: 0.029414777566969   1: 0.015945026476021   2: 0.015894204299911   5: 0.015893658564501   9: 0.015893368141782   3: 0.015892076034427   4: 0.015891933407116   7: 0.015891927656691 

training_3222     6: 0.696177567077820   0: 0.177914989309269   5: 0.015739965272544   1: 0.015739724100424   8: 0.015739374803008   9: 0.015739062221991   7: 0.015738238833317   3: 0.015737232854924   2: 0.015736991099427   4: 0.015736854427277 

training_3223     1: 0.723718597466531   5: 0.114704753039376   6: 0.020199557661293   0: 0.020197886248240   8: 0.020196908084824   9: 0.020196735976460   7: 0.020196554150807   4: 0.020196541072296   2: 0.020196329912114   3: 0.020196136388060 

training_3225     6: 0.701053664749074   8: 0.118625011209634   1: 0.022542923135913   5: 0.022541729526925   0: 0.022540683869383   7: 0.022540016495608   9: 0.022539574733061   2: 0.022538945404661   4: 0.022538887117005   3: 0.022538563758735 

training_3228     6: 0.757215840430319   5: 0.073089165435414   0: 0.021234843550185   8: 0.021215971346157   9: 0.021212101014765   1: 0.021206863018083   2: 0.021206818942252   7: 0.021206208580284   4: 0.021206155402365   3: 0.021206032280175 

training_3229     1: 0.697659940454908   6: 0.142539954278604   0: 0.019981291032418   5: 0.019978497292386   2: 0.019975958529187   4: 0.019974897428055   8: 0.019972587102538   9: 0.019972401761380   7: 0.019972363617024   3: 0.019972108503500 

training_323      6: 0.788628447027475   0: 0.072652345818941   1: 0.017342398826136   5: 0.017342379015830   9: 0.017340942862767   2: 0.017340190069744   7: 0.017339888370778   8: 0.017339330855886   4: 0.017337137297895   3: 0.017336939854547 

training_3235     0: 0.414476341786730   5: 0.343126197406735   6: 0.030309642428320   1: 0.030305401179892   4: 0.030297980832665   2: 0.030297972721986   9: 0.030296901553837   7: 0.030296762376346   3: 0.030296499958935   8: 0.030296299754552 

training_3239     1: 0.350836397449473   6: 0.333117140438397   7: 0.163131289706584   5: 0.035832582264671   4: 0.019577350764535   9: 0.019519911160368   8: 0.019509418837501   0: 0.019493531940974   2: 0.019492183652509   3: 0.019490193784987 

training_3241     1: 0.295024995667106   5: 0.248540855432383   7: 0.202425486220279   8: 0.147118279848367   6: 0.017821089858652   0: 0.017817693235572   4: 0.017814316526552   9: 0.017813265693336   2: 0.017812244273318   3: 0.017811773244435 

training_3242     0: 0.613940089497957   6: 0.121206659757846   1: 0.060246078558526   2: 0.059175463570225   8: 0.055894893918170   3: 0.027680220907072   5: 0.022043253205331   9: 0.013290591239670   4: 0.013262435485933   7: 0.013260313859271 

training_3243     0: 0.777529088124581   5: 0.024746632913792   4: 0.024738770298017   6: 0.024714766867109   8: 0.024712515849703   1: 0.024711974545361   7: 0.024711826020328   2: 0.024711507298899   3: 0.024711491059440   9: 0.024711427022769 

training_3246     0: 0.592304679510178   6: 0.294763940196655   1: 0.028828658101509   9: 0.012020657209394   8: 0.012019894356634   5: 0.012013278984734   7: 0.012012802077706   4: 0.012012110367230   3: 0.012012039951714   2: 0.012011939244245 

training_3247     5: 0.726583469287275   4: 0.030385009463705   6: 0.030384017790494   1: 0.030382497904555   7: 0.030380126624879   8: 0.030379213173436   3: 0.030378099299665   2: 0.030377965138111   0: 0.030375019308697   9: 0.030374582009181 

training_3249     6: 0.792512928411750   0: 0.050796481437797   7: 0.032906191525557   9: 0.032307937067046   5: 0.015249511027122   4: 0.015246774349809   1: 0.015245637070206   8: 0.015245471998691   2: 0.015244820552191   3: 0.015244246559832 

training_3251     1: 0.549114968731007   7: 0.299020792583954   4: 0.035626915060398   2: 0.016652149892962   9: 0.016602537180180   5: 0.016601964108164   6: 0.016599262101888   0: 0.016598244311401   8: 0.016592666349733   3: 0.016590499680313 

training_3252     1: 0.406283566123296   5: 0.235212860766205   4: 0.224317881282105   0: 0.019193562092683   6: 0.019178751825962   2: 0.019166885894013   8: 0.019166701084706   9: 0.019160439638504   3: 0.019160107433124   7: 0.019159243859402 

training_3253     6: 0.465308186287874   8: 0.241370801128122   0: 0.139167275620577   7: 0.022025708249538   1: 0.022024579254231   9: 0.022023428173050   5: 0.022021340584704   2: 0.022019781373986   4: 0.022019520122061   3: 0.022019379205855 

training_3254     5: 0.802273188755845   6: 0.021989137036260   0: 0.021977649622259   1: 0.021968589511648   3: 0.021966018008135   4: 0.021965523739057   9: 0.021965066889902   2: 0.021965017365937   7: 0.021964907968302   8: 0.021964901102653 

training_3256     2: 0.639370007946388   6: 0.177073408484210   1: 0.072173367610645   5: 0.015926184212324   8: 0.015915177725869   0: 0.015913933992657   9: 0.015913328886402   7: 0.015907153091004   3: 0.015903783890614   4: 0.015903654159886 

training_3258     5: 0.778303264826252   1: 0.024634297692753   6: 0.024633931338868   0: 0.024633619050823   9: 0.024632760590001   2: 0.024632668023311   4: 0.024632406236531   8: 0.024632395130210   7: 0.024632354320615   3: 0.024632302790636 

training_3259     9: 0.460285673468224   6: 0.331440338823859   0: 0.055371260735195   2: 0.048534291245984   4: 0.017463083261946   7: 0.017386982687613   1: 0.017385809174058   5: 0.017380744508347   3: 0.017376101706676   8: 0.017375714388098 

training_3261     0: 0.693849808346417   6: 0.097504650792024   5: 0.088137541036576   2: 0.038725297443274   1: 0.013731805123160   3: 0.013631092897897   4: 0.013613295838278   9: 0.013602404987088   7: 0.013602271371257   8: 0.013601832164030 

training_3263     1: 0.778007818031440   0: 0.078802863113988   6: 0.017901464112500   5: 0.017899356783992   9: 0.017898843911602   8: 0.017898649138512   4: 0.017898201806244   7: 0.017897851155292   2: 0.017897669098502   3: 0.017897282847928 

training_3264     1: 0.481392710744715   0: 0.260229437962559   5: 0.116371009191683   3: 0.038903048874245   9: 0.017206811557729   6: 0.017184300488838   2: 0.017178450281556   4: 0.017178240536261   8: 0.017178070626450   7: 0.017177919735965 

training_3266     0: 0.842934597447909   5: 0.017457959350189   4: 0.017453981391456   6: 0.017453256987611   1: 0.017452948799232   9: 0.017449844209595   2: 0.017449597961118   8: 0.017449499232280   7: 0.017449192948221   3: 0.017449121672391 

training_3267     6: 0.565102701803087   1: 0.266291590012311   0: 0.094141126672330   5: 0.010642517960482   7: 0.010637702792326   9: 0.010637586476783   4: 0.010636952176825   8: 0.010636835843540   2: 0.010636551953608   3: 0.010636434308707 

training_3269     5: 0.411576038672709   6: 0.347324602535994   7: 0.125252453706300   2: 0.031331503711885   0: 0.023957923209356   3: 0.012125638272445   1: 0.012117482724045   8: 0.012106136608547   4: 0.012104537029138   9: 0.012103683529580 

training_327      6: 0.472530655460868   7: 0.354125734057176   5: 0.042915069464777   9: 0.018635463407745   8: 0.018634314847144   0: 0.018632402933048   4: 0.018631913632573   1: 0.018631659440768   3: 0.018631395580825   2: 0.018631391175076 

training_3271     5: 0.497829629496424   6: 0.353067211338437   7: 0.042980062569588   8: 0.015356765276060   1: 0.015134276778325   0: 0.015128267241738   9: 0.015126459272477   4: 0.015125901978387   2: 0.015125872048163   3: 0.015125554000401 

training_3272     6: 0.790042458587223   8: 0.056105734109906   1: 0.042164693034271   0: 0.015979193344698   7: 0.015964428835889   5: 0.015949456537849   9: 0.015949311980191   4: 0.015948484650925   2: 0.015948217692705   3: 0.015948021226343 

training_3273     6: 0.514093063503849   9: 0.342048320362762   4: 0.017991003419069   5: 0.017990868553677   0: 0.017983491041563   3: 0.017979311750033   1: 0.017979140075427   8: 0.017978758688661   7: 0.017978540964369   2: 0.017977501640590 

training_3275     6: 0.555102664697221   2: 0.200989972082768   0: 0.102237372637186   8: 0.043310024876026   1: 0.016397881353383   5: 0.016395349789701   3: 0.016392034989164   4: 0.016391662464737   9: 0.016391661564316   7: 0.016391375545498 

training_3276     1: 0.516846351894368   6: 0.208747022064499   0: 0.116011580056283   2: 0.060072666456096   9: 0.016414500665724   3: 0.016390485542859   5: 0.016389097487741   4: 0.016377124681914   8: 0.016375971784267   7: 0.016375199366249 

training_3277     7: 0.384916919069792   6: 0.314052488685829   0: 0.111651555499144   4: 0.086698272606451   9: 0.027357965832691   1: 0.015079729880164   5: 0.015067466397451   2: 0.015058778172373   3: 0.015058448887124   8: 0.015058374968981 

training_3278     1: 0.410860898384126   6: 0.360379746529061   8: 0.084654391247657   0: 0.054283520802288   5: 0.014974055742165   7: 0.014970795578440   4: 0.014969566871813   9: 0.014969450180714   2: 0.014968926253037   3: 0.014968648410699 

training_3282     6: 0.418135442276006   8: 0.369209294310159   1: 0.071431691230499   5: 0.020182071174202   0: 0.020177421692155   7: 0.020173758710613   4: 0.020173391375255   9: 0.020173198150477   3: 0.020171877708094   2: 0.020171853372540 

training_3283     6: 0.459036297387318   0: 0.358256374575151   8: 0.052291868125184   2: 0.047306795261456   1: 0.017965619106718   3: 0.016460784656474   5: 0.014941733979014   4: 0.011256148987503   9: 0.011242840819559   7: 0.011241537101624 

training_3285     6: 0.764299138479504   4: 0.082744081394523   3: 0.031200691970273   2: 0.028945627165144   0: 0.021368840027657   7: 0.014808474510967   8: 0.014287867165162   9: 0.014215057451919   5: 0.014067529644126   1: 0.014062692190726 

training_3287     1: 0.740803389228762   0: 0.156127804287860   3: 0.012945697090145   8: 0.012929474986117   6: 0.012928127358177   9: 0.012905090477294   5: 0.012866738468900   4: 0.012832472727642   7: 0.012830772616952   2: 0.012830432758151 

training_3290     5: 0.732344790756012   8: 0.070760122986561   3: 0.064936038563272   6: 0.018857193652503   0: 0.018852647565220   1: 0.018852073322123   9: 0.018851531625969   4: 0.018849185881093   2: 0.018848485344121   7: 0.018847930303126 

training_3292     6: 0.810812785175233   3: 0.073906234325372   9: 0.028677207004959   0: 0.012372960657358   1: 0.012372687642273   5: 0.012372105042190   8: 0.012371797249374   7: 0.012371447147813   4: 0.012371414467608   2: 0.012371361287820 

training_3295     5: 0.423163790554499   4: 0.163384327816821   0: 0.142938628558298   8: 0.083235196045001   2: 0.059714065639487   9: 0.051269310064423   6: 0.019078509419904   1: 0.019072854157245   7: 0.019072687601138   3: 0.019070630143183 

training_3298     6: 0.649632436602017   0: 0.167612762383908   2: 0.048102381936195   3: 0.032998979525824   7: 0.030060027601061   4: 0.022488652691710   1: 0.012279705449821   5: 0.012277948235814   8: 0.012273680012471   9: 0.012273425561180 

training_3299     8: 0.595965509216001   1: 0.183393905260513   6: 0.027597310928998   7: 0.027579341757678   0: 0.027578538996351   9: 0.027577237781408   5: 0.027577235037001   2: 0.027577036609985   3: 0.027576980803703   4: 0.027576903608363 

training_330      6: 0.675006840075828   8: 0.187377778823067   1: 0.049084726994493   0: 0.012670387013828   9: 0.012648585294493   5: 0.012648181591281   7: 0.012644780484655   3: 0.012639814872833   4: 0.012639728315825   2: 0.012639176533697 

training_3302     7: 0.496526626512200   6: 0.309606511646004   0: 0.024265008758649   1: 0.024243488343236   5: 0.024232258393244   8: 0.024231343474820   4: 0.024225920689256   9: 0.024223318329475   2: 0.024223083490652   3: 0.024222440362466 

training_3303     2: 0.613007245376778   1: 0.190029168588992   6: 0.076025938939440   5: 0.017284405735025   9: 0.017278090231558   7: 0.017275518858633   8: 0.017275115689150   0: 0.017275073475813   3: 0.017274861757062   4: 0.017274581347548 

training_3305     0: 0.720186733099666   1: 0.031102628631338   5: 0.031096322341950   6: 0.031090804676801   8: 0.031087741241337   2: 0.031087521228411   4: 0.031087407511298   7: 0.031087381426377   9: 0.031087129468615   3: 0.031086330374208 

training_3306     6: 0.711090012835921   8: 0.165069817071994   1: 0.021865683909082   0: 0.014729350204107   5: 0.014554125132560   3: 0.014540219008326   9: 0.014537770977238   7: 0.014537724248352   4: 0.014537671985529   2: 0.014537624626890 

training_3309     1: 0.683484242523062   5: 0.083446075454728   2: 0.080516726887165   7: 0.049798979630796   8: 0.017158076141897   4: 0.017129209392684   6: 0.017122138884328   0: 0.017117789708041   9: 0.017114754570971   3: 0.017112006806328 

training_331      1: 0.746254874539113   0: 0.134870532063129   6: 0.015052451288696   7: 0.014866095590908   5: 0.014845726602531   4: 0.014823741358593   8: 0.014822380095917   2: 0.014822339565259   9: 0.014821211667467   3: 0.014820647228388 

training_3310     1: 0.470380804978689   6: 0.384286926948986   0: 0.032712326158337   8: 0.016097517716330   3: 0.016091149556700   5: 0.016087803790198   9: 0.016086223429239   2: 0.016085892022607   4: 0.016085737422149   7: 0.016085617976765 

training_3311     6: 0.753568841284435   5: 0.027408079957467   4: 0.027389762560168   8: 0.027387418498025   9: 0.027380082834838   7: 0.027375281931385   1: 0.027372872483971   0: 0.027372685099861   3: 0.027372511694531   2: 0.027372463655319 

training_3312     6: 0.766706125131985   5: 0.025943647658386   4: 0.025930638867048   8: 0.025926121574189   9: 0.025920136579899   7: 0.025916170666570   1: 0.025914434126054   0: 0.025914412834273   3: 0.025914173538121   2: 0.025914139023474 

training_3313     0: 0.503895015442617   1: 0.295728109195417   5: 0.067975489311910   6: 0.018917198782681   9: 0.018915504676451   4: 0.018914729884039   8: 0.018914164218003   2: 0.018913406870344   7: 0.018913390971737   3: 0.018912990646801 

training_3314     6: 0.792342048772377   5: 0.023076430924475   4: 0.023073942234313   9: 0.023073401185542   8: 0.023073196807558   7: 0.023072753195347   0: 0.023072542125046   3: 0.023071954126529   2: 0.023071871432936   1: 0.023071859195877 

training_3315     8: 0.343294984835462   5: 0.271458480927037   6: 0.211398901156685   9: 0.059544097767217   0: 0.019056691737289   1: 0.019052806301586   2: 0.019052405269558   7: 0.019048775649579   4: 0.019046498459329   3: 0.019046357896258 

training_3317     6: 0.493912646269899   8: 0.309620229171814   0: 0.024564950406703   5: 0.024560942426838   7: 0.024560460621120   9: 0.024556513261900   1: 0.024556312917449   2: 0.024556306848393   4: 0.024556033220684   3: 0.024555604855200 

training_3318     6: 0.775224390288904   0: 0.073539621731607   9: 0.033733443608344   8: 0.016811367082321   4: 0.016793665979304   3: 0.016785280030339   5: 0.016779580612878   1: 0.016778246345197   2: 0.016777219285599   7: 0.016777185035509 

training_332      7: 0.492525848166044   6: 0.219109054242851   3: 0.133928819102668   5: 0.022064212531264   0: 0.022063718933094   1: 0.022062237607534   9: 0.022061829561866   2: 0.022061731893618   4: 0.022061357368192   8: 0.022061190592869 

training_3320     0: 0.673982616025560   1: 0.200611285940271   6: 0.015684721771961   2: 0.015677361743080   5: 0.015676265220249   4: 0.015675391715431   9: 0.015675031525799   8: 0.015674472872112   7: 0.015671880712636   3: 0.015670972472902 

training_3322     6: 0.403675555012090   8: 0.336593438710980   7: 0.093370741336036   1: 0.046805639351028   5: 0.019933157050232   0: 0.019931174400155   9: 0.019924812539359   2: 0.019924022047932   4: 0.019921251795792   3: 0.019920207756396 

training_3323     6: 0.573083850540384   0: 0.282262956378537   5: 0.018083453248654   4: 0.018082265312531   1: 0.018082016520698   2: 0.018081687931651   8: 0.018081252534086   9: 0.018080974393833   7: 0.018080836325498   3: 0.018080706814128 

training_3324     6: 0.558139476878846   5: 0.210552474009678   1: 0.089888839766306   0: 0.020204616645579   7: 0.020202653860912   4: 0.020202591676483   9: 0.020202405948527   8: 0.020202355720147   2: 0.020202293023819   3: 0.020202292469704 

training_3327     6: 0.380145300792713   8: 0.364689435515657   7: 0.092055874444396   1: 0.045769947991105   5: 0.019563414460218   0: 0.019561501470458   9: 0.019555645620470   2: 0.019554772971367   4: 0.019552617756417   3: 0.019551488977200 

training_3329     6: 0.770359131537830   8: 0.066125860128978   9: 0.035854616543252   1: 0.033873429484498   4: 0.015636863451621   5: 0.015634337775349   0: 0.015630223211223   2: 0.015629133171109   7: 0.015628247047039   3: 0.015628157649100 

training_3330     6: 0.821115826321647   0: 0.074871803426992   8: 0.013007699586128   7: 0.013003445269061   9: 0.013002885581880   5: 0.013001495211640   1: 0.013000119669374   2: 0.012998966981916   4: 0.012998935300911   3: 0.012998822650452 

training_3332     6: 0.686579176877848   4: 0.115575522654573   1: 0.093700473357729   9: 0.038754948091153   0: 0.010941360060031   5: 0.010911266994996   8: 0.010895355599442   3: 0.010888474636993   7: 0.010876869879913   2: 0.010876551847324 

training_3333     0: 0.500040470252880   6: 0.182411131194102   9: 0.125449575403647   1: 0.027458111732798   5: 0.027442198220884   4: 0.027441073608170   8: 0.027439795312845   7: 0.027439436451007   2: 0.027439402370060   3: 0.027438805453607 

training_3334     6: 0.798962506727690   5: 0.022342089977574   4: 0.022338094119120   9: 0.022337911491455   8: 0.022337706955262   7: 0.022337005035779   0: 0.022336412742617   1: 0.022336280652532   3: 0.022336053141631   2: 0.022335939156339 

training_3335     6: 0.795321657298785   5: 0.022745513724985   9: 0.022743465976420   4: 0.022742667833138   8: 0.022742146085216   7: 0.022741410999644   0: 0.022741381030864   3: 0.022740647833151   2: 0.022740588683993   1: 0.022740520533805 

training_3336     0: 0.584845320283488   1: 0.226902567885270   6: 0.067001045111175   3: 0.030344496857520   7: 0.015173413230174   4: 0.015147780810653   9: 0.015147554845504   5: 0.015147438368960   8: 0.015145701666765   2: 0.015144680940492 

training_3337     6: 0.773380119189633   0: 0.078586044080892   8: 0.018507046442288   5: 0.018506235003378   1: 0.018504908260319   4: 0.018504536653170   7: 0.018503151729098   9: 0.018502925618642   3: 0.018502553437002   2: 0.018502479585577 

training_3338     1: 0.393962638709384   6: 0.376213010281832   0: 0.103313850085949   8: 0.048400754539560   3: 0.013022596659661   5: 0.013020090327038   4: 0.013019674120229   9: 0.013016480129504   7: 0.013015539909752   2: 0.013015365237090 

training_3339     6: 0.815930285973294   1: 0.038673138339756   5: 0.018191498109513   7: 0.018184414670691   0: 0.018175386140129   3: 0.018169438257966   4: 0.018169390790850   2: 0.018168958527410   8: 0.018168779756426   9: 0.018168709433965 

training_334      1: 0.818590415005033   6: 0.020180444271214   9: 0.020165479952129   5: 0.020157605126937   8: 0.020156635682875   0: 0.020153496376436   4: 0.020152135998986   7: 0.020149403720677   3: 0.020147853664810   2: 0.020146530200901 

training_3340     6: 0.832598072002766   5: 0.018602321879386   0: 0.018602090607460   1: 0.018600120567547   4: 0.018599812113794   3: 0.018599611303166   8: 0.018599564206913   2: 0.018599489701176   7: 0.018599461939437   9: 0.018599455678354 

training_3341     5: 0.602988112830977   6: 0.162086393314800   9: 0.029367292920037   0: 0.029366850463775   4: 0.029366628155145   8: 0.029366481797783   7: 0.029365442892945   1: 0.029365104779004   3: 0.029363896021392   2: 0.029363796824143 

training_3342     2: 0.527855666467826   1: 0.194865475266325   8: 0.151945989950199   5: 0.017968552684232   9: 0.017908907772602   4: 0.017903889967839   6: 0.017903822773220   0: 0.017887831760458   7: 0.017881738416449   3: 0.017878124940851 

training_3343     5: 0.735025864081905   4: 0.029450314107677   6: 0.029444429038983   1: 0.029441190074216   7: 0.029440504513087   0: 0.029439949006436   3: 0.029439672352678   8: 0.029439662643053   9: 0.029439219128264   2: 0.029439195053702 

training_3344     5: 0.731663066645472   6: 0.143012046562045   1: 0.015668034746139   0: 0.015667800993911   9: 0.015666887552982   2: 0.015664701822329   4: 0.015664637731736   8: 0.015664394735530   7: 0.015664334183144   3: 0.015664095026712 

training_3345     1: 0.780584932717554   4: 0.024398612938578   5: 0.024396117822822   7: 0.024375718616654   0: 0.024375319855850   6: 0.024374787754412   2: 0.024373875046036   9: 0.024373767311768   8: 0.024373461548392   3: 0.024373406387934 

training_3347     6: 0.712539698575499   2: 0.098690588072887   1: 0.069978781934391   7: 0.016993049455952   0: 0.016970554087809   5: 0.016969574128164   8: 0.016965437517926   4: 0.016964496169409   3: 0.016963939001631   9: 0.016963881056332 

training_3348     6: 0.715286077177524   2: 0.130304229693076   5: 0.019317957044206   0: 0.019302716692819   8: 0.019301952217301   1: 0.019299127974437   4: 0.019298900446942   9: 0.019298645129368   7: 0.019295254455878   3: 0.019295139168448 

training_3349     6: 0.330180023841337   1: 0.304057584744939   9: 0.177537884266334   0: 0.054484397971603   5: 0.048627438323351   7: 0.017023033517284   3: 0.017022627175604   8: 0.017022401345711   4: 0.017022355314704   2: 0.017022253499133 

training_3351     6: 0.821616310901162   0: 0.071841351023315   1: 0.026388972971743   9: 0.011453363308843   5: 0.011451268414014   4: 0.011450476211711   8: 0.011449634684794   7: 0.011449605477167   2: 0.011449552055528   3: 0.011449464951723 

training_3352     6: 0.872473301607017   0: 0.030709846993998   3: 0.020709507003334   1: 0.010889710064659   9: 0.010869924498205   5: 0.010869859242683   7: 0.010869645444328   8: 0.010869444935570   2: 0.010869382502360   4: 0.010869377707846 

training_3353     6: 0.722201559611453   4: 0.090480590490495   0: 0.069741680352477   9: 0.016862121407546   5: 0.016790999290957   8: 0.016788600060156   7: 0.016784854546596   3: 0.016784365883901   1: 0.016783096905571   2: 0.016782131450848 

training_3354     2: 0.753996069874336   5: 0.027338183724284   4: 0.027336642890467   6: 0.027336290382862   9: 0.027332722043570   1: 0.027332656348331   0: 0.027332544494747   8: 0.027332517621525   7: 0.027331798890148   3: 0.027330573729729 

training_3356     6: 0.487578317042164   1: 0.350462645981197   0: 0.020250130957560   5: 0.020247834116086   4: 0.020243880668625   8: 0.020243814420932   9: 0.020243458062766   2: 0.020243411580133   7: 0.020243355436322   3: 0.020243151734215 

training_3358     6: 0.477296108063720   5: 0.318414462138098   7: 0.055605508585159   0: 0.021262936187176   2: 0.021239820184946   1: 0.021237030218266   4: 0.021236389409543   8: 0.021236340574259   9: 0.021235790830619   3: 0.021235613808215 

training_3359     5: 0.722575014176724   4: 0.030834758228512   1: 0.030825397675927   0: 0.030824222292286   6: 0.030824094935775   2: 0.030823838530724   3: 0.030823338936858   8: 0.030823165985744   7: 0.030823089284920   9: 0.030823079952529 

training_336      9: 0.782311907372527   6: 0.024190796026714   1: 0.024190144716121   8: 0.024188422236440   0: 0.024187859590531   5: 0.024187046101158   4: 0.024186295692469   7: 0.024185948031218   3: 0.024185847625926   2: 0.024185732606894 

training_3360     6: 0.823632411711251   0: 0.029809024753967   8: 0.019148313414663   9: 0.018592608633427   5: 0.018139441246200   1: 0.018136791685026   4: 0.018136063159957   2: 0.018135676554560   7: 0.018135091440547   3: 0.018134577400402 

training_3363     1: 0.400835353210493   7: 0.352296683299587   6: 0.030863476664563   4: 0.030859606902683   5: 0.030859431229637   0: 0.030859320201056   3: 0.030856700127071   9: 0.030856688711217   2: 0.030856469517545   8: 0.030856270136148 

training_3364     6: 0.550710241311507   0: 0.209508105790818   9: 0.103818623781209   4: 0.045617322780392   5: 0.015068522353128   2: 0.015063284770947   8: 0.015055666528490   1: 0.015054109707064   3: 0.015053250963947   7: 0.015050872012498 

training_3365     6: 0.693156560203261   9: 0.034097295491484   8: 0.034095986993292   0: 0.034095073105879   1: 0.034094790600738   5: 0.034092493716509   7: 0.034092322275805   2: 0.034092261027219   4: 0.034091705639458   3: 0.034091510946354 

training_3367     4: 0.571885838608914   6: 0.219874150657333   0: 0.087482574586164   5: 0.017256894289952   3: 0.017250918876790   2: 0.017250901659557   8: 0.017250143411826   7: 0.017249987854439   1: 0.017249907968065   9: 0.017248682086962 

training_3370     0: 0.751285270495021   1: 0.027638894708449   6: 0.027635480915233   9: 0.027634602978059   7: 0.027634377552578   4: 0.027634345937860   5: 0.027634341915644   8: 0.027634282344842   2: 0.027634225375342   3: 0.027634177776973 

training_3371     6: 0.522009272387940   8: 0.155969059185487   0: 0.111878465128923   2: 0.108476865401302   7: 0.016945964449477   5: 0.016945674006327   1: 0.016944769744830   9: 0.016944606086422   4: 0.016943695007891   3: 0.016941628601400 

training_3372     6: 0.381786653264837   1: 0.273597342836106   0: 0.232951237151315   2: 0.027415855745115   5: 0.014042299467638   4: 0.014041467048055   7: 0.014041412596726   9: 0.014041359696650   8: 0.014041267571441   3: 0.014041104622117 

training_3377     0: 0.507119678722207   6: 0.329508909389605   8: 0.020424896555101   5: 0.020424814329274   2: 0.020423793846316   1: 0.020423758590963   9: 0.020419150586923   7: 0.020418600805323   4: 0.020418575759804   3: 0.020417821414484 

training_3378     6: 0.709447251612458   5: 0.077436597526476   1: 0.060315378334871   0: 0.021838743477106   4: 0.021832655688307   2: 0.021826056878193   3: 0.021826028951039   9: 0.021825877930078   8: 0.021825862113898   7: 0.021825547487574 

training_338      6: 0.843577033580341   1: 0.033261518648698   9: 0.016248889724067   5: 0.015485267955250   4: 0.015276157423415   8: 0.015248988466435   0: 0.015226903813323   2: 0.015225136489008   3: 0.015225118681959   7: 0.015224985217504 

training_3380     5: 0.433682629281105   6: 0.280514483705736   1: 0.178458668812501   4: 0.026265455236052   0: 0.021407882084638   8: 0.011956563163322   7: 0.011941878379244   3: 0.011924819866549   9: 0.011924101244739   2: 0.011923518226113 

training_3381     0: 0.745802348589541   6: 0.124384433997572   5: 0.016232103453400   1: 0.016229367725727   4: 0.016226175121707   8: 0.016226161451691   2: 0.016225269182593   3: 0.016225054246218   7: 0.016224633792258   9: 0.016224452439292 

training_3382     4: 0.421083966167418   5: 0.279825399222444   3: 0.140717904129241   1: 0.022626557911073   0: 0.022625738210870   6: 0.022625312754600   2: 0.022624542124393   7: 0.022623582658872   9: 0.022623519610283   8: 0.022623477210806 

training_3384     1: 0.736897725192450   3: 0.090760489888079   8: 0.054106716597913   5: 0.016919700960833   6: 0.016906352651664   7: 0.016887547113304   0: 0.016883487188119   4: 0.016881919626419   2: 0.016878064055020   9: 0.016877996726199 

training_3386     0: 0.723939938525486   6: 0.030690003283172   8: 0.030675959466856   7: 0.030672432222063   1: 0.030670915804789   2: 0.030670397682740   9: 0.030670374954784   3: 0.030670272902801   5: 0.030670038426572   4: 0.030669666730737 

training_3387     4: 0.588962835852410   0: 0.223548254670904   8: 0.075117148006936   1: 0.016100780723617   6: 0.016076170716805   7: 0.016043282399774   9: 0.016042686392944   5: 0.016037062407291   2: 0.016036572095217   3: 0.016035206734103 

training_3389     2: 0.503864360276999   6: 0.366866917635509   0: 0.016171588754665   5: 0.016159881931890   1: 0.016157817520695   4: 0.016157558200827   9: 0.016155813193258   8: 0.016155797195800   7: 0.016155216901785   3: 0.016155048388572 

training_3390     1: 0.402259983709153   6: 0.365176561660640   0: 0.152295206323546   8: 0.011471103655877   4: 0.011468052470067   9: 0.011466667636704   7: 0.011466151836331   5: 0.011465967252766   3: 0.011465393887019   2: 0.011464911567896 

training_3394     1: 0.526750179293120   6: 0.200353088874496   0: 0.177736211986730   5: 0.013598916920775   2: 0.013594313761111   3: 0.013594297300228   9: 0.013593331889385   4: 0.013593327817000   8: 0.013593276634249   7: 0.013593055522906 

training_3395     4: 0.515590772691361   2: 0.318279055303103   1: 0.020790430799625   6: 0.020773718645330   0: 0.020772049351246   3: 0.020767451567721   8: 0.020760727084272   5: 0.020758730506707   9: 0.020755469129855   7: 0.020751594920780 

training_3396     1: 0.496063409455929   6: 0.227734113969131   8: 0.096054156812234   7: 0.085746702622585   0: 0.024029107349324   4: 0.018299616477689   5: 0.013097607907874   3: 0.013014349309022   9: 0.012981378966797   2: 0.012979557129415 

training_3399     0: 0.430530596419577   5: 0.404258133082632   6: 0.020657913966001   1: 0.020657003853812   9: 0.020649978025563   8: 0.020649692426133   4: 0.020649568754110   7: 0.020649360353581   2: 0.020648970795702   3: 0.020648782322888 

training_3400     0: 0.550235488268448   6: 0.241725862704424   4: 0.047940299716322   5: 0.022882706685578   1: 0.022873124576146   2: 0.022869011567601   3: 0.022868865669939   9: 0.022868328412865   7: 0.022868237001633   8: 0.022868075397044 

training_3401     6: 0.780641231273586   0: 0.064452367174408   9: 0.045722032448718   1: 0.015600510410268   5: 0.015597945877373   8: 0.015597908681513   7: 0.015597400015752   4: 0.015597039039269   2: 0.015596878012291   3: 0.015596687066822 

training_3405     5: 0.402160171257923   2: 0.336935602416518   1: 0.103724240900516   6: 0.022542135349971   3: 0.022450782321331   9: 0.022446795380742   0: 0.022442739595519   4: 0.022435689122250   8: 0.022431089747140   7: 0.022430753908089 

training_3406     1: 0.313671931697544   6: 0.299040141195423   9: 0.181344419840768   0: 0.029423317011448   5: 0.029420841704767   4: 0.029420016815428   3: 0.029419982241374   2: 0.029419964940033   7: 0.029419789949355   8: 0.029419594603862 

training_3409     9: 0.349472468598418   1: 0.344194741454106   0: 0.069797579258590   5: 0.064998135707268   7: 0.061665110168452   2: 0.045968575937136   6: 0.015979267861141   4: 0.015977333448947   8: 0.015973954072099   3: 0.015972833493844 

training_341      9: 0.554599425151843   6: 0.187962944638339   8: 0.127971741422164   0: 0.018496533733623   5: 0.018495709864206   1: 0.018495410087940   3: 0.018494979890833   2: 0.018494778901997   4: 0.018494363940863   7: 0.018494112368191 

training_3411     6: 0.792082944938487   0: 0.117809916204983   1: 0.023986690633983   9: 0.009456363733120   5: 0.009445556671392   4: 0.009444923215440   7: 0.009443522819066   8: 0.009443462904633   2: 0.009443376496913   3: 0.009443242381983 

training_3413     6: 0.437577641136874   1: 0.267436695313678   9: 0.164990806825523   4: 0.027529737231627   0: 0.017263947187055   5: 0.017042022411973   8: 0.017040405392567   2: 0.017040190446326   7: 0.017039279564837   3: 0.017039274489540 

training_3415     6: 0.553959400150585   0: 0.319203792981983   8: 0.015861393065426   4: 0.015858854960036   5: 0.015857752432543   1: 0.015855252982062   2: 0.015851877353852   3: 0.015851815817368   9: 0.015850152715045   7: 0.015849707541101 

training_3416     0: 0.548418818511785   1: 0.298883533625715   6: 0.019088708095290   5: 0.019088132489197   2: 0.019087091431478   4: 0.019086978464316   8: 0.019086932077249   9: 0.019086871227030   7: 0.019086604918936   3: 0.019086329159004 

training_3417     1: 0.573245232433392   4: 0.112519891196717   9: 0.068560215946242   8: 0.067176380111135   0: 0.056540067164780   6: 0.051883982095215   7: 0.017518986237369   2: 0.017518884743739   5: 0.017518843680972   3: 0.017517516390439 

training_3418     1: 0.676697031337853   8: 0.172753532758744   5: 0.018827028342430   4: 0.018820327043664   6: 0.018818811881829   0: 0.018817468926390   9: 0.018817439631321   3: 0.018816600876283   2: 0.018816267332491   7: 0.018815491868995 

training_3419     6: 0.597101911831929   8: 0.175617091515239   5: 0.028413657415511   7: 0.028411717247708   1: 0.028411371170120   4: 0.028411037532283   0: 0.028409144343334   9: 0.028409011870148   2: 0.028407703068793   3: 0.028407354004935 

training_342      6: 0.731543100429088   0: 0.091292890236348   1: 0.087580900543216   5: 0.032117792156719   3: 0.017501775638282   8: 0.008186998503546   9: 0.007945071054102   7: 0.007943989215212   2: 0.007943787649508   4: 0.007943694573980 

training_3420     5: 0.721146862073275   1: 0.137968726336483   6: 0.017614625154054   0: 0.017613295889055   4: 0.017610406423588   8: 0.017609553716390   9: 0.017609358950920   7: 0.017609236288525   2: 0.017609161094919   3: 0.017608774072790 

training_3421     6: 0.795029915932247   1: 0.074954163166219   0: 0.040167430068028   3: 0.018639553260564   5: 0.017713605564729   8: 0.010704363560090   9: 0.010698389444459   7: 0.010697732556156   4: 0.010697503779757   2: 0.010697342667752 

training_3422     1: 0.721528668004339   0: 0.078150676123681   5: 0.045241345145514   6: 0.022174184586465   8: 0.022161489505960   7: 0.022150109479692   2: 0.022148791138153   4: 0.022148459116896   9: 0.022148425065962   3: 0.022147851833338 

training_3425     5: 0.749597731021861   6: 0.027828896995874   1: 0.027823496777355   0: 0.027822722227951   8: 0.027821978025634   9: 0.027821749101800   4: 0.027821565320567   7: 0.027820998185409   2: 0.027820442818995   3: 0.027820419524555 

training_3429     6: 0.791296806824516   1: 0.078313895253069   0: 0.038733624472227   8: 0.020423144419292   7: 0.011873513381777   5: 0.011872964927874   2: 0.011872333718691   9: 0.011871583085419   4: 0.011871112932953   3: 0.011871020984182 

training_343      6: 0.777886245615966   8: 0.024680461444806   0: 0.024680149206297   1: 0.024680121104461   2: 0.024679864097227   7: 0.024679708465881   5: 0.024678810718030   9: 0.024678330097178   4: 0.024678269390259   3: 0.024678039859895 

training_3430     6: 0.599728218777354   7: 0.178560603794538   2: 0.064979113307175   8: 0.054169881342715   0: 0.017143238342351   5: 0.017102714993718   1: 0.017081963710591   9: 0.017079747011784   4: 0.017078597396290   3: 0.017075921323484 

training_3433     6: 0.794635497030266   1: 0.082741774400807   0: 0.015333396961553   7: 0.015328230501884   9: 0.015327152527158   8: 0.015327058505114   5: 0.015326839445673   2: 0.015326721110584   3: 0.015326708844519   4: 0.015326620672443 

training_3435     6: 0.793086834128327   7: 0.079880706367140   8: 0.015986545548386   0: 0.015880841662908   9: 0.015864085426383   5: 0.015862813547162   1: 0.015860797509884   4: 0.015859786104722   2: 0.015859282968337   3: 0.015858306736751 

training_3438     7: 0.508135575143813   6: 0.304860531480552   9: 0.086815833399673   5: 0.014413959143276   4: 0.014336329834095   8: 0.014294691003411   0: 0.014292293626995   1: 0.014284121292665   3: 0.014283505244900   2: 0.014283159830620 

training_3440     6: 0.642036491636442   1: 0.161422132960286   0: 0.116988042765795   8: 0.022679355466095   4: 0.009480625413178   5: 0.009479053013933   3: 0.009478744454934   9: 0.009478601895884   7: 0.009478519956839   2: 0.009478432436614 

training_3441     6: 0.834383989991624   7: 0.036503529314442   8: 0.032947683976308   5: 0.013739227846741   4: 0.013738924944965   0: 0.013738116962610   9: 0.013737860211703   1: 0.013737831788683   3: 0.013736424263103   2: 0.013736410699818 

training_3442     6: 0.754508102102748   1: 0.085541109791332   5: 0.032143730065621   0: 0.031838904693442   9: 0.026757488967982   7: 0.013851869871817   8: 0.013843291011778   2: 0.013840076722304   3: 0.013837720241468   4: 0.013837706531508 

training_3445     6: 0.584564516410339   8: 0.227789158067464   5: 0.042732500375800   7: 0.027903652714502   9: 0.026286134392963   0: 0.024552054907736   1: 0.024490705590908   3: 0.013908360528851   4: 0.013886587254286   2: 0.013886329757151 

training_3446     6: 0.413283950146457   1: 0.247806068122783   0: 0.211430069075146   9: 0.074484786994535   5: 0.011352013389713   2: 0.008473369756741   7: 0.008308934431456   8: 0.008287100178682   4: 0.008287078737969   3: 0.008286629166517 

training_3448     6: 0.558525954684542   1: 0.212748098077721   0: 0.028593651125198   5: 0.028592047782635   4: 0.028591548081540   8: 0.028590831568532   9: 0.028590265825422   7: 0.028589343491879   3: 0.028589211088047   2: 0.028589048274484 

training_3449     6: 0.663123566263700   1: 0.224069610820936   3: 0.030166095595971   9: 0.011810047755153   0: 0.011808234169937   5: 0.011804781244527   8: 0.011804607310089   7: 0.011804401403865   4: 0.011804364287936   2: 0.011804291147885 

training_345      6: 0.741898318212938   0: 0.085464849367246   3: 0.055324059071712   1: 0.016764499488395   5: 0.016761381430771   4: 0.016759568647545   9: 0.016757107983939   8: 0.016756792561623   7: 0.016756767151880   2: 0.016756656083951 

training_3452     6: 0.657488008609756   8: 0.177671291871753   1: 0.053702119213320   3: 0.035167955073722   0: 0.012788696046802   7: 0.012636610684383   9: 0.012636445326889   2: 0.012636415064366   5: 0.012636295204199   4: 0.012636162904811 

training_3453     6: 0.735719266712882   3: 0.127122005290142   7: 0.017196786290039   8: 0.017179062120871   4: 0.017146944437252   5: 0.017127917106678   1: 0.017127693139366   0: 0.017127350755345   2: 0.017126564080729   9: 0.017126410066695 

training_3454     6: 0.784361373636569   2: 0.062719927674367   0: 0.042708342380758   1: 0.029170322080155   7: 0.013511826652939   5: 0.013508729443676   4: 0.013507832393011   3: 0.013504088867245   9: 0.013503829651766   8: 0.013503727219515 

training_3455     6: 0.699404419501638   2: 0.141580507941983   0: 0.060912355913252   1: 0.021135004018928   3: 0.012837894502688   5: 0.012826483796832   9: 0.012826294855002   8: 0.012826128934383   7: 0.012825566081186   4: 0.012825344454109 

training_3456     5: 0.457279539324572   6: 0.227843810762601   3: 0.101156566610699   8: 0.063081208680800   7: 0.054088669015440   1: 0.040379762005697   4: 0.014045331411470   0: 0.014043515153443   9: 0.014042676244377   2: 0.014038920790901 

training_3458     6: 0.677154706949973   3: 0.127549916281715   8: 0.074917110945778   7: 0.017207057880161   5: 0.017198311668432   4: 0.017197207780254   1: 0.017194346705757   0: 0.017194263846850   9: 0.017193853144272   2: 0.017193224796806 

training_3459     0: 0.736605010729621   6: 0.114396484817021   1: 0.018628486170465   5: 0.018628354844157   9: 0.018624396602533   2: 0.018624272779997   8: 0.018623906514229   4: 0.018623267714795   7: 0.018622945537252   3: 0.018622874289930 

training_346      6: 0.612759301685572   0: 0.147181919579774   2: 0.104352298957690   7: 0.047691483617595   4: 0.014673014614495   5: 0.014671357277017   9: 0.014668663380762   3: 0.014668263651835   1: 0.014668116133990   8: 0.014665581101270 

training_3460     6: 0.701206753793068   2: 0.081415148934997   7: 0.077770221070080   0: 0.034879798053230   4: 0.017484888139936   1: 0.017471010470923   5: 0.017446958862694   3: 0.017442316887031   9: 0.017441888533396   8: 0.017441015254644 

training_3461     6: 0.402696603630782   1: 0.281216261895765   4: 0.157781725784386   0: 0.022616199038598   9: 0.022615496311112   8: 0.022615270953646   5: 0.022615258884712   2: 0.022614859604027   7: 0.022614229645885   3: 0.022614094251087 

training_3463     6: 0.650043717555875   0: 0.151343975670039   3: 0.104848207373064   5: 0.013398525314991   4: 0.013396396057816   9: 0.013395575043488   1: 0.013395324592765   8: 0.013394791478155   2: 0.013391871557511   7: 0.013391615356296 

training_3466     6: 0.513824811067917   9: 0.351240918075273   5: 0.016941796567734   1: 0.016861904823534   4: 0.016861527968065   3: 0.016857116512101   0: 0.016854735914416   2: 0.016853516782056   8: 0.016852200065199   7: 0.016851472223704 

training_3467     6: 0.785026890139137   9: 0.050197554945111   0: 0.020601266760516   5: 0.020599291328542   8: 0.020596607417637   7: 0.020596062333717   4: 0.020595929757458   1: 0.020595610706037   3: 0.020595553113111   2: 0.020595233498733 

training_3468     0: 0.637389055828807   5: 0.210924508582816   6: 0.018965323987969   9: 0.018965220273230   3: 0.018962524570469   8: 0.018960818862797   4: 0.018960053068819   1: 0.018959256234027   7: 0.018956954651670   2: 0.018956283939396 

training_3469     9: 0.400357151513379   6: 0.399701087303646   8: 0.047932445526088   0: 0.021720400276892   1: 0.021720116305589   5: 0.021717208439684   4: 0.021714434550463   7: 0.021712409977216   2: 0.021712381751980   3: 0.021712364355063 

training_3472     6: 0.595596702789432   0: 0.192510122625005   7: 0.066398681920922   1: 0.056889548421051   8: 0.014803796669690   5: 0.014762568127355   4: 0.014762529107378   9: 0.014759349671332   3: 0.014758582751259   2: 0.014758117916576 

training_3473     6: 0.647411535229298   8: 0.149413132933097   1: 0.062826192655187   3: 0.020065650069976   5: 0.020048726966864   0: 0.020047370655295   9: 0.020047136304670   2: 0.020046814649529   7: 0.020046770268073   4: 0.020046670268010 

training_3474     1: 0.561898656282511   2: 0.152950195243959   5: 0.129269958856117   6: 0.022272100198013   4: 0.022270248301676   9: 0.022270225169069   8: 0.022269139825014   0: 0.022267106146160   3: 0.022266969880907   7: 0.022265400096573 

training_3476     8: 0.545041247332331   4: 0.188205697219216   5: 0.033361035642516   9: 0.033346409009325   3: 0.033341719965863   0: 0.033340964567820   1: 0.033340852246420   6: 0.033340797693987   2: 0.033340725690673   7: 0.033340550631849 

training_3477     1: 0.708831239285431   5: 0.110925052238907   9: 0.022654273686996   8: 0.022543118643707   6: 0.022526101151938   0: 0.022513700197299   4: 0.022503131632954   3: 0.022502386386528   7: 0.022500738199442   2: 0.022500258576800 

training_3480     5: 0.506879742602619   3: 0.283523051295460   0: 0.054663934619323   8: 0.048375663003431   6: 0.017767011718377   1: 0.017763080918665   4: 0.017758473442565   9: 0.017758159126069   7: 0.017755591723078   2: 0.017755291550413 

training_3481     1: 0.691682073062742   5: 0.034286575440019   4: 0.034278742753149   9: 0.034275274825862   8: 0.034264323430245   3: 0.034249895426284   0: 0.034242413012668   6: 0.034241898688567   2: 0.034239756692273   7: 0.034239046668192 

training_3482     9: 0.848206441855041   6: 0.016868582229063   8: 0.016866694607448   5: 0.016866488957336   0: 0.016865841243976   4: 0.016865542767792   1: 0.016865446363297   2: 0.016865071487281   7: 0.016865001775821   3: 0.016864888712947 

training_3483     6: 0.817912886806741   0: 0.048840479602545   9: 0.016663028449642   7: 0.016658759661149   1: 0.016655416145478   5: 0.016654895081291   8: 0.016654717589976   4: 0.016653554396204   2: 0.016653183441466   3: 0.016653078825507 

training_3486     5: 0.375679942182232   6: 0.242071356453361   3: 0.158635273701024   9: 0.137475402519830   2: 0.014369979612365   1: 0.014369966333458   8: 0.014365027835699   0: 0.014345356167669   4: 0.014345270653009   7: 0.014342424541354 

training_3488     6: 0.736655814686539   0: 0.155378828037777   1: 0.027334890719033   8: 0.018433722125078   9: 0.010399596902064   5: 0.010367748680775   2: 0.010357725395486   7: 0.010357638343703   4: 0.010357478628929   3: 0.010356556480616 

training_349      6: 0.785417992955098   4: 0.056879579677768   1: 0.054906725740965   7: 0.014686369383794   8: 0.014685882517967   2: 0.014685084318719   0: 0.014684818820627   9: 0.014684721124498   3: 0.014684477352726   5: 0.014684348107838 

training_3490     6: 0.663981234540737   5: 0.107231200038812   8: 0.100361962570139   3: 0.055908780978231   0: 0.018572703843243   1: 0.010891235755485   2: 0.010766792720593   9: 0.010762944681246   7: 0.010761588543968   4: 0.010761556327547 

training_3491     1: 0.574761287864199   6: 0.227551267170051   0: 0.092128287591098   7: 0.015083370954290   8: 0.015081613665666   9: 0.015080144067640   5: 0.015079376651582   4: 0.015078484500303   2: 0.015078187849833   3: 0.015077979685337 

training_3492     6: 0.840790854315196   1: 0.039081272171055   5: 0.015018248514075   0: 0.015017334487584   3: 0.015015495752094   7: 0.015015429415898   8: 0.015015415572849   4: 0.015015374185432   2: 0.015015302366365   9: 0.015015273219451 

training_3493     6: 0.809358509734505   9: 0.074528125886887   0: 0.038900754877344   7: 0.011045387973967   1: 0.011035472412837   5: 0.011031008446425   8: 0.011025573899448   2: 0.011025295893183   4: 0.011024973581907   3: 0.011024897293499 

training_3497     6: 0.474935756528186   9: 0.367014284239026   7: 0.047143542384544   1: 0.015948928601733   5: 0.015832435486458   4: 0.015828077851978   0: 0.015825838605519   3: 0.015823727924652   2: 0.015823716324383   8: 0.015823692053522 

training_3499     7: 0.571404560288308   6: 0.265837422003094   5: 0.020346957143305   1: 0.020345552781217   8: 0.020344827535769   0: 0.020344619337590   2: 0.020344311445366   4: 0.020344044417315   9: 0.020343904044754   3: 0.020343801003282 

training_3504     6: 0.721494942442000   8: 0.030950622513799   9: 0.030948301831035   0: 0.030946273277157   1: 0.030943868728376   7: 0.030943384725316   2: 0.030943360697319   5: 0.030943308639587   3: 0.030943117269198   4: 0.030942819876213 

training_3505     6: 0.468068248021575   5: 0.369478500829374   0: 0.044894612630850   1: 0.037820288516276   8: 0.013294074246683   9: 0.013290893148824   4: 0.013289385472303   7: 0.013289002517459   2: 0.013287626825810   3: 0.013287367790846 

training_3507     6: 0.677498630023448   1: 0.107072628803756   3: 0.080689551023205   2: 0.037217961503010   9: 0.016266607818580   7: 0.016265964018678   0: 0.016254024152194   5: 0.016246205359988   4: 0.016244436325669   8: 0.016243990971472 

training_3509     6: 0.593763793951959   3: 0.176219624605613   1: 0.115720336758755   8: 0.027216327863525   5: 0.014517525373437   0: 0.014515543619290   9: 0.014512233950677   2: 0.014511748087428   4: 0.014511614239979   7: 0.014511251549337 

training_3511     6: 0.871495306390045   0: 0.014278815082707   1: 0.014278794337726   9: 0.014278480636337   5: 0.014278385975763   7: 0.014278262467971   4: 0.014278085561182   8: 0.014278056831714   2: 0.014277954064366   3: 0.014277858652186 

training_3512     6: 0.655751964152636   0: 0.251516061415050   3: 0.016249360193187   1: 0.010959720104799   8: 0.010932294380219   7: 0.010920441802853   5: 0.010917971821348   4: 0.010917873397347   9: 0.010917309845126   2: 0.010917002887435 

training_3514     6: 0.607785000946933   0: 0.263151640371504   8: 0.037503283615125   1: 0.021119485347836   9: 0.011768169388155   5: 0.011742181238242   4: 0.011733233578356   2: 0.011732687661903   7: 0.011732276305608   3: 0.011732041546341 

training_3517     5: 0.596790150852740   3: 0.246092648516642   9: 0.019643051164867   8: 0.019640775711214   4: 0.019640166588935   6: 0.019639715414884   1: 0.019639435732978   0: 0.019639277082095   2: 0.019637426376434   7: 0.019637352559210 

training_352      6: 0.710367116804591   1: 0.146447483242654   0: 0.032759879078812   4: 0.015793208083374   8: 0.015773540078799   9: 0.015772078433529   7: 0.015772017246774   2: 0.015771810184528   5: 0.015771499103752   3: 0.015771367743187 

training_3520     6: 0.595510506044748   0: 0.192686574480984   7: 0.066321672297352   1: 0.056876214442249   8: 0.014803891368917   5: 0.014762565571160   4: 0.014762524340557   9: 0.014759350364366   3: 0.014758583225463   2: 0.014758117864204 

training_3524     6: 0.692074201039099   0: 0.130046578003509   5: 0.102278728484501   1: 0.010808462158991   9: 0.010800841006092   8: 0.010799323450224   3: 0.010798872284392   2: 0.010797811385238   7: 0.010797666808021   4: 0.010797515379933 

training_3526     6: 0.402586881686852   1: 0.281328267927457   4: 0.157779437893187   0: 0.022616200257107   9: 0.022615497162044   8: 0.022615271792452   5: 0.022615259312989   2: 0.022614859826469   7: 0.022614229937524   3: 0.022614094203918 

training_3528     6: 0.663160503181662   1: 0.224032666828305   3: 0.030166096541676   9: 0.011810051689229   0: 0.011808236527647   5: 0.011804781168871   8: 0.011804607258704   7: 0.011804401394275   4: 0.011804364265949   2: 0.011804291143680 

training_353      6: 0.686255485289460   3: 0.112582336472879   0: 0.089424664799040   2: 0.015963075962647   9: 0.015962962195553   1: 0.015962924826641   5: 0.015962904626649   7: 0.015962051255083   8: 0.015961912213245   4: 0.015961682358803 

training_3531     6: 0.674890372580903   9: 0.104020422736020   0: 0.079856974893940   5: 0.043665593494370   3: 0.032390739575939   1: 0.013036939302773   8: 0.013034871328500   2: 0.013034807930515   7: 0.013034678011275   4: 0.013034600145765 

training_3532     6: 0.743729060802012   1: 0.090289934060794   0: 0.073636184432205   3: 0.013192383822585   5: 0.013192311770275   9: 0.013192241260176   8: 0.013192016820703   7: 0.013192005967182   4: 0.013191942356980   2: 0.013191918707087 

training_3533     6: 0.782562000106157   0: 0.079398114114741   8: 0.017280554280566   9: 0.017261649458185   5: 0.017250326309954   1: 0.017250088629251   7: 0.017249668833021   3: 0.017249281007783   4: 0.017249266733827   2: 0.017249050526515 

training_3534     6: 0.687244363741648   0: 0.124761581320898   1: 0.111926182898003   9: 0.017424192699016   8: 0.015569107987567   7: 0.008622171436932   5: 0.008615682403880   3: 0.008612498146661   4: 0.008612196175490   2: 0.008612023189904 

training_3535     6: 0.664811085976451   0: 0.126977939938230   1: 0.067807331462685   5: 0.066870288252527   9: 0.027888829306016   2: 0.009132146240115   3: 0.009130646871482   7: 0.009129591766654   8: 0.009126208289332   4: 0.009125931896508 

training_3538     9: 0.548770406395770   1: 0.224071148625426   6: 0.028406865630467   5: 0.028402925974099   4: 0.028400981426976   0: 0.028399428258113   7: 0.028387334344728   8: 0.028387034222045   2: 0.028387017817054   3: 0.028386857305321 

training_3539     6: 0.786461197270498   0: 0.087710199069685   5: 0.039116107436907   2: 0.012461736609198   4: 0.012423331260047   1: 0.012373879343455   3: 0.012363871955133   8: 0.012363415408841   9: 0.012363228812708   7: 0.012363032833529 

training_354      6: 0.797698089189532   1: 0.085416966382642   0: 0.028232532120690   3: 0.012690309336127   4: 0.012665397826402   8: 0.012661555205407   9: 0.012659880698051   5: 0.012659028166367   7: 0.012658126536785   2: 0.012658114537997 

training_3540     6: 0.784189456952957   0: 0.079885228394149   5: 0.025934267992057   8: 0.022531928557118   3: 0.022427509930035   7: 0.017541743419257   1: 0.011893839377114   2: 0.011866887047819   9: 0.011864678488773   4: 0.011864459840722 

training_3541     6: 0.802744017423443   5: 0.021918329022469   9: 0.021917885651694   0: 0.021917664539652   1: 0.021917559909785   8: 0.021917316316087   7: 0.021917099798822   4: 0.021916716205837   2: 0.021916705904806   3: 0.021916705227406 

training_3542     6: 0.782654800317927   1: 0.057599046357067   0: 0.054145779885650   8: 0.035929995669538   7: 0.011629439627422   5: 0.011610452615664   9: 0.011608138928566   3: 0.011607665274738   4: 0.011607438507525   2: 0.011607242815902 

training_3543     5: 0.766745197842033   1: 0.090670570244083   3: 0.017841180724006   4: 0.017825215488288   6: 0.017823737484558   9: 0.017822217509067   0: 0.017818832054166   8: 0.017817750873960   2: 0.017817665918078   7: 0.017817631861761 

training_3545     5: 0.840679122847329   4: 0.017706554337402   6: 0.017702068292587   0: 0.017701969263828   1: 0.017701852808827   8: 0.017701795435380   2: 0.017701773351481   9: 0.017701740406874   3: 0.017701577601628   7: 0.017701545654662 

training_3547     9: 0.419807182232942   1: 0.289275341350676   4: 0.102868490421337   6: 0.084507938745971   0: 0.017266246854616   2: 0.017257701453716   5: 0.017257047589149   7: 0.017254426468029   8: 0.017253182632459   3: 0.017252442251105 

training_3553     6: 0.834375984185603   7: 0.036511715767461   8: 0.032947504464154   5: 0.013739227892118   4: 0.013738923674379   0: 0.013738116994338   9: 0.013737860239623   1: 0.013737831815039   3: 0.013736424264502   2: 0.013736410702783 

training_3554     6: 0.550924345459510   9: 0.258520189744672   5: 0.075590910939838   1: 0.016448382399688   0: 0.016422886486820   8: 0.016419830476434   4: 0.016418514705055   2: 0.016418462273129   7: 0.016418407935270   3: 0.016418069579583 

training_3556     6: 0.658058372273836   4: 0.122403349668921   1: 0.092034469611882   5: 0.047465040085879   8: 0.023374857977817   3: 0.011349419858118   7: 0.011332533889721   0: 0.011332077288476   9: 0.011325421683825   2: 0.011324457661524 

training_3557     5: 0.810272029919154   4: 0.021085723190812   1: 0.021081005479053   0: 0.021080786585522   6: 0.021080735764682   8: 0.021079987523610   2: 0.021079951081927   9: 0.021079944917409   3: 0.021079924970845   7: 0.021079910566986 

training_3559     6: 0.588687541191201   0: 0.141800996751880   1: 0.095761426196999   4: 0.055588322791424   3: 0.035964221209732   7: 0.016463129071721   8: 0.016446237825714   9: 0.016429585735623   5: 0.016429526222661   2: 0.016429013003045 

training_356      0: 0.463950954046468   1: 0.339565520348144   7: 0.051282990307030   3: 0.048787407725358   6: 0.020924384492430   4: 0.019565417332993   2: 0.019539105669643   5: 0.012136501049094   9: 0.012124130944623   8: 0.012123588084217 

training_3563     0: 0.508804227452711   6: 0.249269378900301   1: 0.101503368359667   2: 0.060054501512186   7: 0.032901845683265   5: 0.013003132566317   9: 0.008620520091268   4: 0.008620459586179   3: 0.008611466731874   8: 0.008611099116231 

training_3564     6: 0.620006868322671   1: 0.149739289134409   2: 0.115242731588077   0: 0.036469926682049   8: 0.019660457789270   5: 0.011787471566675   4: 0.011776527567700   9: 0.011772487287986   3: 0.011772438085731   7: 0.011771801975431 

training_3565     6: 0.361752378689666   4: 0.291632793754764   7: 0.197294470549357   0: 0.021344124321452   1: 0.021341942307277   5: 0.021333104670177   2: 0.021326481224250   9: 0.021325374718961   3: 0.021325231680195   8: 0.021324098083901 

training_3569     5: 0.832860201781280   1: 0.018579894367972   6: 0.018576455785410   0: 0.018574965191954   4: 0.018570371347723   3: 0.018568742536697   2: 0.018567949139722   7: 0.018567269226836   8: 0.018567102863439   9: 0.018567047758967 

training_3570     0: 0.453578364904448   5: 0.252019553328428   9: 0.104910309251858   6: 0.027077518326632   1: 0.027075924588851   7: 0.027068588743582   4: 0.027068151667336   2: 0.027067596196196   3: 0.027067177378159   8: 0.027066815614510 

training_3571     6: 0.786673476155380   1: 0.098278409375159   0: 0.036883373014612   7: 0.011201223505661   5: 0.011163000875108   9: 0.011161279692865   4: 0.011161266694267   8: 0.011161242909911   2: 0.011158818738998   3: 0.011157909038039 

training_3572     6: 0.687247356202650   1: 0.186633403758954   7: 0.015765788366798   0: 0.015765597797912   9: 0.015765098184179   5: 0.015764814391618   8: 0.015764785504958   2: 0.015764527147793   4: 0.015764349530551   3: 0.015764279114586 

training_3573     6: 0.445506584264078   4: 0.265400409795546   2: 0.132739034726907   5: 0.049584675762759   8: 0.017816321586193   1: 0.017797595101001   0: 0.017792778167421   9: 0.017787724470388   7: 0.017787711225401   3: 0.017787164900305 

training_3574     6: 0.558363410370477   5: 0.287128108806881   2: 0.032204338079401   7: 0.023671097450855   3: 0.023645259420889   0: 0.022381302907754   8: 0.013431857558160   1: 0.013085945551535   9: 0.013050938713103   4: 0.013037741140944 

training_3575     5: 0.774512080423800   0: 0.071775450403843   1: 0.019216212798177   7: 0.019215230747603   6: 0.019215069248731   9: 0.019213252169324   8: 0.019213220428748   4: 0.019213184756236   2: 0.019213176914661   3: 0.019213122108876 

training_3577     6: 0.724418424449843   5: 0.117218052015791   8: 0.044433721335806   1: 0.016276346218558   0: 0.016276322583344   4: 0.016275791390827   7: 0.016275776672960   9: 0.016275198499415   3: 0.016275185757087   2: 0.016275181076370 

training_3578     5: 0.722583607618964   6: 0.128571111691380   1: 0.018606761022832   8: 0.018606272749671   0: 0.018606256916919   2: 0.018605377684799   4: 0.018605363071130   3: 0.018605136642458   9: 0.018605122972707   7: 0.018604989629140 

training_3579     3: 0.585198542186589   5: 0.211060929963745   6: 0.025472845275830   0: 0.025468185943492   9: 0.025468149584619   4: 0.025467864920922   7: 0.025466888759942   8: 0.025466513941084   1: 0.025465646939449   2: 0.025464432484327 

training_3580     5: 0.778724858718124   3: 0.024586790824145   4: 0.024586562203558   6: 0.024586049012182   7: 0.024586034414946   8: 0.024585966595550   1: 0.024585962459330   2: 0.024585962276721   0: 0.024585954533650   9: 0.024585858961793 

training_3582     5: 0.723387098494194   8: 0.122512612488410   4: 0.019263982597365   0: 0.019263133786113   6: 0.019262818459443   2: 0.019262554687584   1: 0.019262233802345   7: 0.019261932028823   9: 0.019261832130863   3: 0.019261801524860 

training_3584     9: 0.533612488637289   6: 0.320368195872580   8: 0.018262286439559   1: 0.018253465936227   5: 0.018251467269554   0: 0.018251236686413   7: 0.018250813298317   4: 0.018250370126582   3: 0.018249922510526   2: 0.018249753222952 

training_3585     5: 0.722040391333909   8: 0.097384447059982   4: 0.022574115607025   9: 0.022571827661651   7: 0.022571669576437   6: 0.022571609889010   0: 0.022571572838604   1: 0.022571526510099   3: 0.022571468681953   2: 0.022571370841331 

training_3586     2: 0.458160535632180   3: 0.176246343509633   1: 0.144498580750655   5: 0.031589887649092   4: 0.031588132665921   0: 0.031586556698940   6: 0.031583449175988   8: 0.031582707025680   7: 0.031581946285550   9: 0.031581860606360 

training_3587     0: 0.561835580560107   5: 0.209381864972314   6: 0.133112598312867   1: 0.013695388690047   8: 0.013674717493079   2: 0.013670286818606   7: 0.013660820642632   9: 0.013658742948043   3: 0.013657558268201   4: 0.013652441294104 

training_3589     6: 0.519032994409630   4: 0.199085654855880   5: 0.143942036653792   1: 0.042294968558171   8: 0.021077347753369   3: 0.019620525129569   2: 0.013746041975452   9: 0.013736214579126   0: 0.013733494839488   7: 0.013730721245524 

training_3591     3: 0.231989663808878   2: 0.217774011740661   6: 0.201225599553872   9: 0.195072704017340   5: 0.025663591310866   1: 0.025659769404392   0: 0.025657646984668   4: 0.025655404281649   7: 0.025651022447818   8: 0.025650586449855 

training_3592     2: 0.281147371658064   0: 0.181098988743433   6: 0.159341500657893   3: 0.108901040899285   9: 0.100455136406478   5: 0.088985598123925   4: 0.041429281973561   1: 0.012883409630023   8: 0.012879281891289   7: 0.012878390016050 

training_3593     6: 0.616181565450789   0: 0.167633572106383   1: 0.134415447539864   8: 0.012036369808495   9: 0.011672043227055   4: 0.011637071631992   5: 0.011607418509012   2: 0.011605538919037   7: 0.011605531216886   3: 0.011605441590487 

training_3594     6: 0.759080329246842   1: 0.069094769073960   4: 0.050980776380135   3: 0.033514707204573   7: 0.028365003869580   0: 0.011805824897283   8: 0.011800664723721   5: 0.011790522859101   9: 0.011783818099070   2: 0.011783583645734 

training_3595     0: 0.795045828354026   6: 0.022779693195169   8: 0.022772714775623   5: 0.022772714306110   1: 0.022772441375690   9: 0.022771929557760   7: 0.022771604022124   4: 0.022771252148049   2: 0.022771102619866   3: 0.022770719645581 

training_3596     2: 0.352635159977364   1: 0.298522016735784   3: 0.194087573342352   0: 0.022142799985810   6: 0.022117112687946   5: 0.022116287005429   4: 0.022099005453748   7: 0.022095383174248   9: 0.022093427139439   8: 0.022091234497880 

training_3597     0: 0.812285560567356   4: 0.054249842983739   6: 0.016696472007699   5: 0.016684452145548   1: 0.016682014626741   9: 0.016681675292924   3: 0.016680155003195   7: 0.016680094190966   2: 0.016680068463283   8: 0.016679664718550 

training_3598     5: 0.483368826414981   3: 0.298181184533114   1: 0.074424417278128   2: 0.020596920815446   0: 0.020580324972336   6: 0.020579073264851   7: 0.020571374346718   4: 0.020566764775112   8: 0.020565582922851   9: 0.020565530676462 

training_3599     1: 0.664074161867241   4: 0.173056823235816   5: 0.020368588736914   6: 0.020365052942700   0: 0.020358289762447   9: 0.020355940979229   3: 0.020355883151154   8: 0.020355760068756   7: 0.020354916450237   2: 0.020354582805508 

training_36       5: 0.454460816834398   4: 0.349650090115870   6: 0.024487266802097   2: 0.024486617755175   3: 0.024486444285307   1: 0.024486032219333   0: 0.024485841039514   7: 0.024485700636656   9: 0.024485618638772   8: 0.024485571672878 

training_3601     5: 0.787013760438690   0: 0.023667941032704   3: 0.023665445784999   1: 0.023665297928897   8: 0.023664958585516   6: 0.023664795459309   4: 0.023664747661698   9: 0.023664428826009   7: 0.023664312952443   2: 0.023664311329735 

training_3602     5: 0.822040522600041   8: 0.039658452068472   4: 0.017290496656474   1: 0.017287576447337   6: 0.017287527212512   0: 0.017287421934474   7: 0.017287119766812   9: 0.017286999675965   2: 0.017286967032181   3: 0.017286916605731 

training_3603     5: 0.780513704403683   1: 0.059806093652260   6: 0.019962662292852   8: 0.019960602039697   9: 0.019960437066266   0: 0.019959957661209   7: 0.019959268398793   2: 0.019959102541597   4: 0.019959094102197   3: 0.019959077841445 

training_3604     9: 0.410844512737536   5: 0.392455317535359   3: 0.024611741682111   4: 0.024604613555436   0: 0.024590708119230   6: 0.024585704005501   1: 0.024578211496833   8: 0.024576665685302   2: 0.024576300200731   7: 0.024576224981962 

training_3605     5: 0.685802364093633   4: 0.130262634218608   0: 0.049157755091795   6: 0.019294982908504   9: 0.019291277308208   2: 0.019243273761732   1: 0.019241925166356   8: 0.019235668512444   3: 0.019235092730707   7: 0.019235026208012 

training_3607     1: 0.214225696486453   2: 0.205600677340409   3: 0.197687913123536   6: 0.153396161492864   9: 0.139150395252160   8: 0.018050593356998   5: 0.017975491975673   0: 0.017972201407915   4: 0.017971817379811   7: 0.017969052184181 

training_3609     6: 0.753001971178737   0: 0.082863833739766   4: 0.041971468416682   1: 0.038387062516596   3: 0.013967384902028   5: 0.013965440807004   8: 0.013961983090575   9: 0.013960664931799   7: 0.013960175816042   2: 0.013960014600770 

training_361      0: 0.631796757909987   8: 0.100720887908397   6: 0.089869051391285   7: 0.067008944152744   4: 0.018451302875667   5: 0.018441311333284   1: 0.018430542564612   9: 0.018428975233610   2: 0.018426285243477   3: 0.018425941386939 

training_3610     6: 0.629192597155003   5: 0.161193794526115   4: 0.026206901017317   9: 0.026202489686635   0: 0.026201031241263   1: 0.026200907655719   8: 0.026200746114095   2: 0.026200690451783   3: 0.026200541844629   7: 0.026200300307441 

training_3611     6: 0.545815923070128   8: 0.222837009604657   0: 0.028920392053809   1: 0.028919844033624   7: 0.028919696270617   2: 0.028917839557703   9: 0.028917729797325   4: 0.028917709571582   5: 0.028917127516582   3: 0.028916728523971 

training_3612     9: 0.496552789527846   6: 0.358497482346034   8: 0.018122741115336   0: 0.018120371047056   5: 0.018118649653133   7: 0.018118514934961   1: 0.018118205807144   4: 0.018117454530691   2: 0.018116947786286   3: 0.018116843251511 

training_3613     7: 0.420152100147720   5: 0.226755187616385   6: 0.182412312817435   0: 0.050354832216987   3: 0.036252149805826   1: 0.016957590941561   4: 0.016780920446463   2: 0.016778967304776   9: 0.016777979213523   8: 0.016777959489325 

training_3615     6: 0.768287570585607   0: 0.091500299039422   8: 0.028989183418107   9: 0.028976227166276   4: 0.017473801825559   5: 0.013199460450835   1: 0.012896197747016   7: 0.012895774378958   3: 0.012890791954738   2: 0.012890693433481 

training_3616     6: 0.521251805552190   0: 0.279201248937377   9: 0.024965059795577   5: 0.024941943971312   7: 0.024940422626982   8: 0.024940229671392   3: 0.024940182072007   1: 0.024939874793218   4: 0.024939672292543   2: 0.024939560287403 

training_3619     9: 0.554525610057130   5: 0.252665379800186   0: 0.040198957705878   1: 0.035231013801532   8: 0.035067460321540   4: 0.016469543295456   6: 0.016461209211101   2: 0.016461041224699   3: 0.016460392415283   7: 0.016459392167194 

training_362      1: 0.456613572763711   6: 0.243471519999001   0: 0.153758010027016   7: 0.075451396546839   4: 0.012120877236537   9: 0.011723992894605   2: 0.011717789264422   5: 0.011715250232964   8: 0.011714739157037   3: 0.011712851877868 

training_3620     5: 0.816065838341345   6: 0.020439222107522   2: 0.020437267885570   0: 0.020437221523724   1: 0.020437210826642   8: 0.020436799462376   9: 0.020436748475755   3: 0.020436601241726   4: 0.020436550637224   7: 0.020436539498116 

training_3621     9: 0.757975545716705   6: 0.026900842582136   5: 0.026896509573040   1: 0.026893124817757   4: 0.026891669044161   0: 0.026891440380319   7: 0.026888176785903   8: 0.026887808904532   3: 0.026887709609115   2: 0.026887172586331 

training_3622     0: 0.752906895675973   8: 0.080788843873356   2: 0.045896123931508   5: 0.017218882636735   4: 0.017207837905833   6: 0.017202885730944   9: 0.017201505754913   1: 0.017196006360821   7: 0.017190676037241   3: 0.017190342092677 

training_3623     5: 0.726460396509596   2: 0.114906938086781   0: 0.019831367512816   1: 0.019829733533290   6: 0.019829226367824   8: 0.019829033235228   7: 0.019828571430695   4: 0.019828362695830   3: 0.019828294556499   9: 0.019828076071442 

training_3624     5: 0.776941001019142   4: 0.024788134200303   8: 0.024784191712707   9: 0.024783926101138   6: 0.024783901940388   0: 0.024783845350361   3: 0.024783805918118   2: 0.024783771550454   1: 0.024783721348360   7: 0.024783700859030 

training_3625     6: 0.654627069503567   1: 0.147016479745563   0: 0.045567763061249   4: 0.042406828480441   5: 0.018413952276269   2: 0.018396778251499   9: 0.018395219981519   7: 0.018392350503104   8: 0.018391872453800   3: 0.018391685742990 

training_3626     5: 0.640471466820990   9: 0.196198107460550   6: 0.020426811464016   4: 0.020418067068637   0: 0.020416589810435   7: 0.020414941597373   8: 0.020414406999991   1: 0.020414153891014   3: 0.020413320020196   2: 0.020412134866799 

training_3629     5: 0.610807529542266   7: 0.117784966535291   6: 0.112142404168277   4: 0.022755040027500   1: 0.022754589309699   9: 0.022753050985557   8: 0.022750773764834   3: 0.022750553908118   0: 0.022750552656518   2: 0.022750539101940 

training_3630     6: 0.446499407095069   3: 0.410062006642466   9: 0.029293117924352   1: 0.016313605133854   8: 0.016312519219169   0: 0.016307927182425   5: 0.016306592465739   4: 0.016303428300371   7: 0.016300880272591   2: 0.016300515763964 

training_3631     5: 0.764143767664024   4: 0.026215177924305   8: 0.026205489646447   0: 0.026205134813978   2: 0.026205123763590   9: 0.026205120428084   3: 0.026205080728991   7: 0.026205079617364   6: 0.026205023834014   1: 0.026205001579202 

training_3632     1: 0.637154237216870   4: 0.194565990054067   6: 0.039761003936522   2: 0.018402286693541   5: 0.018400110739976   9: 0.018379207832908   0: 0.018335663813331   8: 0.018334382555358   7: 0.018333562349328   3: 0.018333554808098 

training_3633     5: 0.644109441059785   3: 0.191629477518518   4: 0.020534047442587   1: 0.020532992349727   6: 0.020532960918559   0: 0.020532573909180   7: 0.020532287003168   8: 0.020532169672149   2: 0.020532026355752   9: 0.020532023770575 

training_3634     4: 0.829471413320608   5: 0.018952703751203   6: 0.018948295937317   7: 0.018947299901649   1: 0.018946895312107   0: 0.018946863672199   8: 0.018946700934510   9: 0.018946635249411   3: 0.018946609208761   2: 0.018946582712234 

training_3637     4: 0.800303225204166   5: 0.022193859554539   6: 0.022188234118077   1: 0.022188063135268   0: 0.022188027653102   8: 0.022187804961637   9: 0.022187777113210   3: 0.022187737526710   2: 0.022187654681801   7: 0.022187616051490 

training_3639     6: 0.702570409453946   7: 0.143516544666242   0: 0.040340784696391   1: 0.016243139654476   5: 0.016237601384591   9: 0.016220832874821   4: 0.016218391176078   8: 0.016217692644482   2: 0.016217375276087   3: 0.016217228172886 

training_3640     9: 0.423520106328434   6: 0.406387226239742   0: 0.051557308383765   1: 0.016939818553817   5: 0.016934136008911   8: 0.016932754639619   4: 0.016932491553203   2: 0.016932294091314   7: 0.016932105250047   3: 0.016931758951149 

training_3643     7: 0.531715753488000   5: 0.310354210049061   0: 0.019856753440071   8: 0.019746570962907   6: 0.019732407556245   1: 0.019732320836821   3: 0.019722885720221   9: 0.019716030985686   4: 0.019711778444035   2: 0.019711288516953 

training_3645     6: 0.424525357135341   0: 0.235800622081586   7: 0.178817274830145   5: 0.081408127456749   1: 0.026224900479172   2: 0.010721429416703   8: 0.010633370618624   9: 0.010623038238627   3: 0.010623028418553   4: 0.010622851324500 

training_3646     6: 0.562189935493731   5: 0.282394697414780   2: 0.032128213858473   3: 0.023981692100623   7: 0.023850618094339   0: 0.022525785661653   8: 0.013490921352568   1: 0.013174208252053   9: 0.013138660316452   4: 0.013125267455328 

training_3647     5: 0.767959271474990   2: 0.025782760959270   3: 0.025782595110303   4: 0.025782556498411   1: 0.025782313293240   6: 0.025782275620034   0: 0.025782206787683   7: 0.025782047022752   9: 0.025782020994590   8: 0.025781952238728 

training_3649     5: 0.451301828903041   3: 0.258266850658754   2: 0.106689738410755   6: 0.026254162856702   4: 0.026249876144299   9: 0.026248523643020   7: 0.026247894670334   1: 0.026247133252918   0: 0.026247064385547   8: 0.026246927074629 

training_3651     5: 0.537384501972142   1: 0.174887395156806   7: 0.124762159632149   9: 0.023282140074631   6: 0.023281066301506   3: 0.023280927780249   4: 0.023280808249333   0: 0.023280567153301   8: 0.023280395345826   2: 0.023280038334055 

training_3652     4: 0.504611701999361   1: 0.264634412756693   5: 0.091659410361021   0: 0.019872095947346   6: 0.019871351240867   9: 0.019870866863004   8: 0.019870502696998   2: 0.019870130729099   3: 0.019869951222864   7: 0.019869576182746 

training_366      1: 0.460254366805749   4: 0.362517697011521   5: 0.033891378124232   6: 0.029762727183590   0: 0.019555596201933   8: 0.019122660593699   2: 0.018724677075546   9: 0.018723830693743   3: 0.018723623795548   7: 0.018723442514440 

training_3660     6: 0.615440854764631   5: 0.224637690249462   0: 0.043676553775565   1: 0.016609574293626   8: 0.016607914427464   9: 0.016606883215951   2: 0.016605306077598   7: 0.016605142633808   4: 0.016605105801410   3: 0.016604974760485 

training_3661     6: 0.740031416827358   0: 0.114023879236793   9: 0.018245188955664   8: 0.018244780966108   5: 0.018243997767000   1: 0.018242660023265   4: 0.018242440230829   7: 0.018242123282206   2: 0.018241812944320   3: 0.018241699766458 

training_3666     6: 0.758959176469120   8: 0.122768040815449   0: 0.014804872969233   2: 0.014786846666770   7: 0.014782525345357   9: 0.014781228949479   1: 0.014780093455725   5: 0.014780040837140   4: 0.014778600759450   3: 0.014778573732278 

training_3667     5: 0.777247888959358   6: 0.024791613339292   1: 0.024750489350141   0: 0.024747655167296   4: 0.024745062217742   2: 0.024744387517708   3: 0.024743576123957   8: 0.024743318653951   7: 0.024743102972383   9: 0.024742905698172 

training_3668     5: 0.663531835029310   4: 0.149023356345189   7: 0.023443897278386   0: 0.023432187278967   1: 0.023429886902017   2: 0.023428597761007   8: 0.023428069905150   3: 0.023427510977800   9: 0.023427357824487   6: 0.023427300697687 

training_3669     5: 0.812265116089580   4: 0.020864938971796   6: 0.020859178640968   0: 0.020859027829927   8: 0.020858805962904   9: 0.020858684445377   3: 0.020858591919698   1: 0.020858581634419   2: 0.020858552515141   7: 0.020858521990190 

training_3672     4: 0.474779576837858   5: 0.350500868931101   0: 0.021840520911744   6: 0.021840404400940   8: 0.021839898061793   9: 0.021839788357460   1: 0.021839757917556   2: 0.021839752985268   3: 0.021839746179224   7: 0.021839685417055 

training_3673     0: 0.780328682657773   8: 0.047308685275410   6: 0.021563324622644   1: 0.021545072681173   5: 0.021544967967870   4: 0.021542216846662   3: 0.021542152388866   9: 0.021541816452737   2: 0.021541637814071   7: 0.021541443292794 

training_3674     3: 0.443589668201910   5: 0.312935680995009   7: 0.030435353289993   4: 0.030435256982949   6: 0.030434216520419   2: 0.030434047959855   8: 0.030434019913897   0: 0.030434006006232   1: 0.030433933796436   9: 0.030433816333300 

training_3676     4: 0.814626469111353   5: 0.020605562185795   2: 0.020598715897965   6: 0.020598538044169   0: 0.020597025987997   1: 0.020595704186558   9: 0.020594693306709   3: 0.020594661004756   7: 0.020594377428256   8: 0.020594252846442 

training_368      6: 0.554987461058778   1: 0.204457014710555   8: 0.049654722251248   0: 0.049175316629532   7: 0.048666441532730   2: 0.037243549070397   9: 0.013969672553002   5: 0.013950200216214   3: 0.013948265464203   4: 0.013947356513340 

training_3680     5: 0.770837375206862   4: 0.025468866164006   6: 0.025464588472199   0: 0.025461891779023   1: 0.025461680279055   3: 0.025461571998012   8: 0.025461151652444   9: 0.025461049926187   7: 0.025460932149789   2: 0.025460892372423 

training_3681     5: 0.809926964708968   6: 0.021123140224983   4: 0.021119589233185   1: 0.021119525785390   0: 0.021118921517759   9: 0.021118906913166   7: 0.021118880861288   8: 0.021118732306566   2: 0.021117723177946   3: 0.021117615270749 

training_3684     6: 0.728608592265567   0: 0.124646755529663   2: 0.036465835490664   5: 0.015761025911184   1: 0.015754922081282   4: 0.015754727196900   9: 0.015754270689853   3: 0.015753164929512   8: 0.015751013022059   7: 0.015749692883318 

training_3688     9: 0.572783571466002   3: 0.142647806413564   6: 0.114875094712750   1: 0.067825109786311   2: 0.017030817539366   0: 0.016978207278559   5: 0.016966994480706   7: 0.016966554192138   8: 0.016963008144357   4: 0.016962835986248 

training_369      1: 0.584675773360455   0: 0.197214116208533   7: 0.061673763906470   3: 0.039603839186526   6: 0.034429326388168   2: 0.016694485380605   5: 0.016432389951077   9: 0.016427362705159   4: 0.016424930981672   8: 0.016424011931335 

training_3690     6: 0.560582002960677   0: 0.281675903156639   9: 0.019726040207364   5: 0.019718772742330   4: 0.019717057649036   8: 0.019716517440210   7: 0.019716372137420   1: 0.019715996972170   2: 0.019715719760520   3: 0.019715616973635 

training_3694     8: 0.811568763176634   3: 0.048284260704980   6: 0.017522170267181   0: 0.017519301076692   1: 0.017518931634470   9: 0.017517733429624   7: 0.017517619440089   5: 0.017517472309726   2: 0.017516894778808   4: 0.017516853181795 

training_3695     5: 0.702760194080685   3: 0.106087331818764   0: 0.023904812033512   4: 0.023895336274932   6: 0.023892159718949   8: 0.023892110484326   2: 0.023892048694894   9: 0.023892010556446   7: 0.023892003351340   1: 0.023891992986153 

training_3697     5: 0.791716258173106   4: 0.023146586220502   8: 0.023142317991895   6: 0.023142228153220   3: 0.023142177444326   2: 0.023142152103808   9: 0.023142125890843   1: 0.023142062639739   7: 0.023142058653938   0: 0.023142032728623 

training_3699     1: 0.417265752361654   6: 0.332544795069867   7: 0.139160139421973   0: 0.028026055806460   3: 0.014079654833228   5: 0.013796998809691   4: 0.013782316113859   2: 0.013781727224254   9: 0.013781629280134   8: 0.013780931078880 

training_37       5: 0.766790452758888   2: 0.077681259653624   6: 0.019452840870131   4: 0.019442297300849   7: 0.019439844524251   1: 0.019439827667515   3: 0.019438540409064   0: 0.019438536186882   8: 0.019438274385183   9: 0.019438126243613 

training_3701     6: 0.833518959119742   0: 0.037536274710831   9: 0.016141520425963   1: 0.016122249557151   5: 0.016116743768335   7: 0.016113029672331   4: 0.016112887521328   8: 0.016112859120467   2: 0.016112818309278   3: 0.016112657794574 

training_3702     6: 0.421882711547228   1: 0.343192691285921   2: 0.066715956893449   0: 0.024066567872757   7: 0.024036223303539   5: 0.024030124377760   8: 0.024023532552901   9: 0.024019336315925   4: 0.024016622008539   3: 0.024016233841982 

training_3704     6: 0.665785969060665   1: 0.150345019063182   4: 0.043232412016188   0: 0.028647261075354   5: 0.018724015661694   9: 0.018692760614829   2: 0.018646299406101   7: 0.018645376504185   8: 0.018641129641169   3: 0.018639756956632 

training_3707     7: 0.411540278175170   1: 0.209189903471746   2: 0.155552744428271   4: 0.097158386436995   0: 0.041593684447075   8: 0.017024468841621   6: 0.017018831602154   5: 0.016976968167865   9: 0.016972629070916   3: 0.016972105358187 

training_3708     9: 0.480250543606612   6: 0.359381286625105   5: 0.020048198864568   7: 0.020048071180824   0: 0.020047470250068   1: 0.020046277821567   4: 0.020045119814712   8: 0.020044637813074   2: 0.020044472720685   3: 0.020043921302784 

training_371      1: 0.511255396884314   6: 0.302312894258810   0: 0.023306315652184   5: 0.023305460970611   4: 0.023305011509277   9: 0.023304366003438   2: 0.023302984398525   7: 0.023302785084956   8: 0.023302585173588   3: 0.023302200064297 

training_3711     6: 0.750049106502425   0: 0.103861566810285   1: 0.050930489017405   2: 0.021051541597343   5: 0.012355147112422   4: 0.012352486472980   8: 0.012350775277333   7: 0.012350216779067   3: 0.012349538825967   9: 0.012349131604773 

training_3713     5: 0.781839955735191   0: 0.024245353985618   4: 0.024244936040668   7: 0.024238768189389   8: 0.024238682635783   3: 0.024238532346949   2: 0.024238511318785   9: 0.024238489745370   1: 0.024238411448845   6: 0.024238358553402 

training_3717     6: 0.596808848852869   7: 0.245463467966139   9: 0.019717347891790   5: 0.019716979496915   0: 0.019716153429919   8: 0.019716126583306   1: 0.019715651235722   4: 0.019715405468909   3: 0.019715025196735   2: 0.019714993877695 

training_372      0: 0.680060650321198   6: 0.126602617222648   1: 0.102368558632212   4: 0.016920582769020   7: 0.012453120333353   5: 0.012333504870173   9: 0.012330357236156   3: 0.012313212888076   8: 0.012308756846567   2: 0.012308638880596 

training_3720     6: 0.421738015386234   9: 0.419302130035830   5: 0.019873556945340   0: 0.019871304811825   7: 0.019871152527603   1: 0.019870107036347   4: 0.019869690431255   8: 0.019868327031527   2: 0.019868154449824   3: 0.019867561344215 

training_3721     5: 0.801507015319580   4: 0.022060391768550   6: 0.022055392200507   0: 0.022054088922243   9: 0.022054075838590   1: 0.022053942831127   8: 0.022053850949386   2: 0.022053816201349   3: 0.022053720184705   7: 0.022053705783964 

training_3723     6: 0.482649711813436   9: 0.356099009660472   5: 0.020158978439411   0: 0.020158304532257   7: 0.020157543417440   1: 0.020157088148964   4: 0.020155559490807   2: 0.020154820445141   8: 0.020154759377147   3: 0.020154224674927 

training_3729     8: 0.715385874461262   5: 0.031630206428512   4: 0.031624788643178   6: 0.031624745739525   0: 0.031623627608917   9: 0.031622400049390   3: 0.031622214349127   1: 0.031622176998837   7: 0.031622100536255   2: 0.031621865184998 

training_3730     5: 0.785337142549398   4: 0.023856031981566   0: 0.023851239499140   1: 0.023851238386518   8: 0.023850846598572   9: 0.023850746665999   2: 0.023850735706164   3: 0.023850715384234   6: 0.023850694401528   7: 0.023850608826881 

training_3734     5: 0.777864558743777   3: 0.024682270056595   4: 0.024682006285760   6: 0.024681952339930   0: 0.024681777244221   1: 0.024681762335579   7: 0.024681482059041   2: 0.024681437164352   8: 0.024681425513653   9: 0.024681328257092 

training_3735     8: 0.790108816446574   2: 0.064574989492061   0: 0.018168008390298   6: 0.018167163488285   1: 0.018164502435311   5: 0.018163868992938   9: 0.018163667606887   7: 0.018163166337893   4: 0.018163036336424   3: 0.018162780473329 

training_3737     6: 0.799372930796819   8: 0.054131342751189   0: 0.018313603767926   5: 0.018312169116612   7: 0.018312100927614   1: 0.018311917415270   2: 0.018311762921412   9: 0.018311545479037   4: 0.018311339285150   3: 0.018311287538971 

training_3738     4: 0.714881853745456   8: 0.118781990944667   5: 0.020799460264176   1: 0.020791982547482   0: 0.020791587306978   6: 0.020791545487023   3: 0.020790845651031   2: 0.020790378879814   7: 0.020790326671321   9: 0.020790028502053 

training_374      6: 0.717287410773128   3: 0.085679858520421   8: 0.061878922988453   5: 0.019312307153585   0: 0.019307824957527   4: 0.019307414881489   1: 0.019306773844774   9: 0.019306667489038   7: 0.019306574363068   2: 0.019306245028518 

training_3740     5: 0.760544557970953   9: 0.100109949819215   4: 0.017420773805620   0: 0.017419775549385   6: 0.017417885940653   8: 0.017417559025713   3: 0.017417436867542   1: 0.017417422341245   7: 0.017417322155396   2: 0.017417316524278 

training_3741     6: 0.374577742556728   4: 0.357310940840445   1: 0.033519200249372   0: 0.033517249418311   5: 0.033517172853277   2: 0.033512524365190   3: 0.033512174750901   8: 0.033511116300784   9: 0.033511085467755   7: 0.033510793197235 

training_3742     5: 0.731084510578430   9: 0.125494439483172   8: 0.017937941060567   0: 0.017932192855676   6: 0.017931360749711   1: 0.017926288335142   4: 0.017923815187286   7: 0.017923686179724   2: 0.017923032738300   3: 0.017922732831991 

training_3743     0: 0.681417450825681   6: 0.206249406588970   5: 0.014049855247050   1: 0.014046069611523   2: 0.014040939351336   4: 0.014040699329860   9: 0.014039385181479   7: 0.014039190917697   3: 0.014038548341179   8: 0.014038454605224 

training_3744     4: 0.473593180425476   6: 0.257710212392352   0: 0.122591679350662   1: 0.020877687158130   5: 0.020873244526971   8: 0.020870918628129   9: 0.020870887008100   7: 0.020870828422603   2: 0.020870711886654   3: 0.020870650200923 

training_3747     0: 0.752598836793516   1: 0.089270714102361   9: 0.019827873282535   6: 0.019766591691133   5: 0.019761947416361   7: 0.019756028817895   8: 0.019755646217584   4: 0.019754482416545   2: 0.019754194399140   3: 0.019753684862932 

training_3748     6: 0.648331108652911   0: 0.139339388319754   1: 0.127397517854135   7: 0.012164056369475   9: 0.012129069973464   2: 0.012128402265184   5: 0.012128085320930   8: 0.012127886557518   4: 0.012127273585113   3: 0.012127211101517 

training_3750     5: 0.392890255192017   4: 0.292125137602600   6: 0.129938723886986   3: 0.048041686434009   8: 0.034826621786471   7: 0.020447970161929   1: 0.020433330859197   0: 0.020432723274160   2: 0.020432446944964   9: 0.020431103857668 

training_3751     5: 0.720583200046520   3: 0.126474655837634   6: 0.019121848028409   1: 0.019119185812244   4: 0.019118124446362   0: 0.019117934678646   8: 0.019116944036996   9: 0.019116171957675   2: 0.019116035970181   7: 0.019115899185331 

training_3755     4: 0.712448114615007   9: 0.113479999224959   5: 0.021762955783380   6: 0.021762771457444   1: 0.021758207787641   8: 0.021758180717141   3: 0.021757915413606   7: 0.021757890320006   0: 0.021757675504372   2: 0.021756289176444 

training_3757     5: 0.456441135961200   3: 0.234831164080409   0: 0.132075698997412   7: 0.025238203158115   4: 0.025236259689007   6: 0.025235647645392   2: 0.025235533330298   8: 0.025235526167561   1: 0.025235511586738   9: 0.025235319383868 

training_3758     6: 0.486243336844123   5: 0.327204052648350   0: 0.081224390543537   2: 0.015056648842868   9: 0.015056551170222   8: 0.015048079484375   1: 0.015042741126192   4: 0.015042336722872   7: 0.015041605204022   3: 0.015040257413437 

training_3759     1: 0.543018137943643   6: 0.210428397031318   5: 0.103633290320432   0: 0.059228685548154   7: 0.013950589897153   3: 0.013950132321126   8: 0.013948979518796   9: 0.013947857432510   4: 0.013947275619267   2: 0.013946654367601 

training_376      4: 0.566592412657995   5: 0.265093453579795   6: 0.021055570633139   0: 0.021041022873918   8: 0.021040598281713   9: 0.021039544364367   1: 0.021037305521766   2: 0.021033794152139   7: 0.021033463565447   3: 0.021032834369722 

training_3760     5: 0.799970646395473   9: 0.022231894901164   1: 0.022231073869304   6: 0.022226816819537   4: 0.022224398404286   0: 0.022223914779886   7: 0.022223289177233   8: 0.022222872246682   2: 0.022222548688003   3: 0.022222544718432 

training_3762     6: 0.704197692517312   0: 0.160024315051654   1: 0.075013515928831   5: 0.008683177209765   8: 0.008683054304473   9: 0.008681120985032   4: 0.008680199592789   2: 0.008679431537989   7: 0.008678764235958   3: 0.008678728636195 

training_3763     5: 0.778437573652917   3: 0.024618585528710   2: 0.024618514711572   4: 0.024618227237125   6: 0.024618174193901   0: 0.024618030932605   1: 0.024617991687416   9: 0.024617957988611   7: 0.024617515960478   8: 0.024617428106665 

training_3764     5: 0.768730959156891   3: 0.025697313858330   4: 0.025696769856466   6: 0.025696539876105   8: 0.025696512706488   0: 0.025696467290732   7: 0.025696379345984   2: 0.025696378767760   1: 0.025696366747933   9: 0.025696312393311 

training_3765     5: 0.509826030246792   3: 0.290040987212083   4: 0.025017303108652   0: 0.025016655866686   6: 0.025016644430510   8: 0.025016625210060   1: 0.025016579504851   2: 0.025016526270748   7: 0.025016359802748   9: 0.025016288346870 

training_3766     6: 0.505972753175069   4: 0.228004601287399   5: 0.033258590727827   1: 0.033255690724922   0: 0.033254094906044   2: 0.033251419693173   7: 0.033251013945201   9: 0.033250793661789   8: 0.033250541863191   3: 0.033250500015384 

training_3768     5: 0.852070842776843   4: 0.016440648803793   6: 0.016437251436188   1: 0.016436742612455   0: 0.016436225653836   9: 0.016435778516737   3: 0.016435716049706   8: 0.016435660554849   2: 0.016435613643502   7: 0.016435519952092 

training_377      6: 0.409567209490443   9: 0.341856968518356   0: 0.126165498663367   1: 0.017490450282357   5: 0.017488613280916   3: 0.017487930633255   2: 0.017485984127311   4: 0.017485968656908   8: 0.017485842203868   7: 0.017485534143219 

training_3770     6: 0.818059155574879   0: 0.067467596852677   1: 0.014314826997780   2: 0.014310621050820   7: 0.014309012077249   5: 0.014308749048370   8: 0.014308189920576   9: 0.014308036795948   3: 0.014307077152457   4: 0.014306734529243 

training_3771     4: 0.710377196623635   9: 0.128106293544854   0: 0.020198176881256   6: 0.020197317430970   8: 0.020192035148551   5: 0.020189732291029   1: 0.020185773924832   2: 0.020184530760500   7: 0.020184521816821   3: 0.020184421577552 

training_3772     5: 0.414145614065201   1: 0.319233314377591   8: 0.083031377600301   6: 0.026227768399914   0: 0.026227682727998   4: 0.026227057882844   9: 0.026227057820432   3: 0.026227003582024   2: 0.026226604743307   7: 0.026226518800388 

training_3774     5: 0.439691147442923   7: 0.232328407933886   6: 0.143283068576297   3: 0.026386854950935   4: 0.026385638563417   1: 0.026385347433289   0: 0.026385133302936   2: 0.026385062797471   9: 0.026384688547825   8: 0.026384650451023 

training_3775     6: 0.660515138815031   4: 0.160760652775972   1: 0.033682959178541   5: 0.020735909057116   0: 0.020733055888080   2: 0.020718302772317   9: 0.020715357048975   8: 0.020712915808243   7: 0.020712860811393   3: 0.020712847844333 

training_3777     0: 0.682739356255936   6: 0.153579960743771   2: 0.020568292701373   5: 0.020448688478957   1: 0.020445467356745   9: 0.020444465688913   4: 0.020444302400810   8: 0.020443911008527   7: 0.020443076046173   3: 0.020442479318794 

training_3779     6: 0.765616134337803   5: 0.055125862387418   0: 0.049927329105833   2: 0.036057590871357   7: 0.023144687491221   3: 0.021914595893886   9: 0.012265453738335   1: 0.011985744202549   8: 0.011981995013128   4: 0.011980606958470 

training_378      5: 0.465874124059988   1: 0.356128235136289   6: 0.022252938003488   0: 0.022250616534501   3: 0.022249416461102   9: 0.022249243385283   4: 0.022249087030511   8: 0.022249060175717   7: 0.022248820873310   2: 0.022248458339811 

training_3782     5: 0.739632127606598   4: 0.028933326393631   7: 0.028929963708863   3: 0.028929303327678   0: 0.028929248077362   2: 0.028929247691967   1: 0.028929239676786   8: 0.028929233772554   6: 0.028929198070660   9: 0.028929111673900 

training_3784     5: 0.726342997452357   3: 0.099665511129574   0: 0.021759195034710   6: 0.021753269290102   4: 0.021747603644501   1: 0.021746782766667   9: 0.021746264834522   8: 0.021746237299186   2: 0.021746087432061   7: 0.021746051116319 

training_3785     5: 0.690973685423764   7: 0.089261965625719   4: 0.082880769469890   8: 0.019561640057763   3: 0.019555738138929   9: 0.019554735288835   0: 0.019553382069910   6: 0.019553130921291   1: 0.019552507376373   2: 0.019552445627526 

training_3786     5: 0.817693744637780   4: 0.020261683435593   6: 0.020255707175416   8: 0.020255638319980   0: 0.020255634687784   1: 0.020255586554267   3: 0.020255531549641   2: 0.020255510408947   9: 0.020255499646192   7: 0.020255463584401 

training_3787     5: 0.784669219382480   2: 0.023928126639056   6: 0.023926731560883   1: 0.023925901761695   9: 0.023925530480517   4: 0.023925329918481   3: 0.023925221951655   0: 0.023925052689568   7: 0.023924459981205   8: 0.023924425634461 

training_3788     5: 0.567237061256645   0: 0.236516369882877   4: 0.024534716927519   2: 0.024534648046269   3: 0.024529985038879   6: 0.024529916139043   8: 0.024529561801274   7: 0.024529277391076   9: 0.024529233049124   1: 0.024529230467295 

training_379      0: 0.619902893374631   4: 0.185952510672132   2: 0.053510137899942   6: 0.020285815513987   1: 0.020283069313868   3: 0.020044768783620   5: 0.020009960983146   7: 0.020005410256600   9: 0.020004625494793   8: 0.020000807707282 

training_3790     6: 0.383035977290245   4: 0.301832383074780   3: 0.162978968606924   7: 0.047242036719229   5: 0.017487882673467   0: 0.017486317600862   1: 0.017486161425414   2: 0.017484150119986   9: 0.017483082533011   8: 0.017483039956081 

training_3792     6: 0.536953736785881   0: 0.256293041023040   1: 0.064582708367922   2: 0.058757043505760   7: 0.020433041744240   3: 0.012695513190548   5: 0.012571979780509   9: 0.012571216386811   8: 0.012570919921784   4: 0.012570799293506 

training_3793     6: 0.814499790045146   5: 0.020611581047162   3: 0.020611566784123   0: 0.020611449321796   1: 0.020611343059102   4: 0.020611035675615   9: 0.020610949655473   8: 0.020610776562143   7: 0.020610768782831   2: 0.020610739066608 

training_3795     1: 0.471227678667968   6: 0.282116813099989   7: 0.079050334420884   0: 0.041896537351768   3: 0.035073482781285   8: 0.031343631177934   5: 0.014824925559434   9: 0.014822692708227   4: 0.014822374555758   2: 0.014821529676754 

training_3796     6: 0.592709517325775   1: 0.288337974530444   9: 0.014869833056511   7: 0.014869702435663   0: 0.014869406639871   5: 0.014868973888154   2: 0.014868726922792   8: 0.014868689852403   4: 0.014868612393721   3: 0.014868562954666 

training_3797     0: 0.797075409184671   1: 0.057116096151428   8: 0.018278182379856   9: 0.018243533347111   3: 0.018241733930162   6: 0.018223855771317   5: 0.018207591130615   7: 0.018205235588996   4: 0.018204608270455   2: 0.018203754245389 

training_3798     6: 0.495299203661064   1: 0.333271905553820   5: 0.083004590207142   0: 0.040060955871930   9: 0.010010976887083   2: 0.007714213753234   3: 0.007670418343793   4: 0.007660398990453   7: 0.007655182004745   8: 0.007652154726737 

training_38       5: 0.770019000454998   4: 0.025557667684135   8: 0.025553124782928   0: 0.025552944701210   9: 0.025552927515298   6: 0.025552923094621   3: 0.025552905592353   2: 0.025552884227013   7: 0.025552819471448   1: 0.025552802475997 

training_3800     6: 0.756702576423420   0: 0.104518455783768   2: 0.047213811828539   7: 0.013105136307448   9: 0.013078361653876   1: 0.013076856140883   5: 0.013076470505623   8: 0.013076416623435   4: 0.013076016727054   3: 0.013075898005955 

training_3801     5: 0.753706038057580   0: 0.069252428615226   4: 0.022136516760383   6: 0.022129566464603   8: 0.022129441420920   7: 0.022129387786882   9: 0.022129276712642   3: 0.022129201826439   1: 0.022129092870574   2: 0.022129049484751 

training_3806     4: 0.824547392707985   5: 0.019503916133509   6: 0.019496118586512   3: 0.019493589860118   0: 0.019493458192987   1: 0.019493364640126   9: 0.019493316031727   7: 0.019493200653084   8: 0.019493037589482   2: 0.019492605604470 

training_3807     5: 0.616632615749583   9: 0.188025011033930   2: 0.024422531230985   1: 0.024421864226787   6: 0.024419400057756   0: 0.024418571649713   4: 0.024416892205703   3: 0.024415020105280   8: 0.024414065146420   7: 0.024414028593843 

training_3808     5: 0.533909325572616   9: 0.167832327073900   7: 0.132007319826511   8: 0.023759137938142   4: 0.023750159964486   6: 0.023749560322897   3: 0.023748564092386   1: 0.023748028642865   0: 0.023747871619872   2: 0.023747704946323 

training_381      1: 0.535293871102164   5: 0.341933283224001   6: 0.015351188941805   0: 0.015347161393842   3: 0.015346280791933   8: 0.015345857865759   4: 0.015345741589492   2: 0.015345632466780   7: 0.015345510865261   9: 0.015345471758962 

training_3817     4: 0.635345239388514   0: 0.218383724303813   6: 0.018291381130269   5: 0.018287606194301   2: 0.018284200235283   1: 0.018283714650480   9: 0.018283481303775   8: 0.018280975430374   7: 0.018280481177077   3: 0.018279196186116 

training_3821     4: 0.542177461024783   0: 0.285070192895691   6: 0.021600963781652   5: 0.021598429054744   1: 0.021596662926716   2: 0.021591845710676   9: 0.021591415851654   8: 0.021591102680628   7: 0.021590985145536   3: 0.021590940927920 

training_3825     6: 0.595571858694940   9: 0.222777344388751   1: 0.083056543877966   7: 0.014121686213611   0: 0.014085344539381   2: 0.014080152183968   5: 0.014078746208063   4: 0.014077011079185   8: 0.014075928996037   3: 0.014075383818097 

training_3828     0: 0.456229412947250   9: 0.257132697982196   5: 0.117871854908165   7: 0.059616240220614   6: 0.018235497452814   1: 0.018184444952480   8: 0.018183453720982   3: 0.018183265956097   4: 0.018182105626362   2: 0.018181026233041 

training_383      6: 0.726161360583202   1: 0.030438116638218   0: 0.030433080639518   5: 0.030428687413837   9: 0.030425235549340   4: 0.030424114749853   3: 0.030423411291081   8: 0.030422148383150   2: 0.030421949518614   7: 0.030421895233186 

training_3830     6: 0.626587923295338   0: 0.237825068237333   5: 0.016950371406529   1: 0.016949951278390   3: 0.016949035469636   9: 0.016948305013910   4: 0.016947387679497   8: 0.016947339738116   2: 0.016947313435403   7: 0.016947304445848 

training_3831     5: 0.754891299460869   1: 0.027234775026808   0: 0.027234640051005   6: 0.027234395702703   2: 0.027234242217415   3: 0.027234237761415   8: 0.027234140324889   7: 0.027234117757563   4: 0.027234092450929   9: 0.027234059246403 

training_3833     1: 0.733697839467188   0: 0.087718919739165   5: 0.034320766996798   4: 0.020701182786222   9: 0.020620974152926   8: 0.020606323019070   6: 0.020595859270662   2: 0.020581202952305   7: 0.020578595544598   3: 0.020578336071068 

training_3838     6: 0.736151056411588   0: 0.082276181327817   2: 0.069749811020571   9: 0.015976025784491   1: 0.015974701336658   5: 0.015974668177395   7: 0.015974484544670   8: 0.015974465890905   4: 0.015974333218643   3: 0.015974272287263 

training_3839     1: 0.686930280886143   8: 0.090844360153323   6: 0.050922957998309   7: 0.050922161864272   4: 0.020085879477795   5: 0.020064426683957   0: 0.020058740440648   3: 0.020057389163126   9: 0.020057144499587   2: 0.020056658832841 

training_3840     5: 0.686744932042103   6: 0.175230538386497   2: 0.017258899596701   9: 0.017254258677928   0: 0.017253651687021   4: 0.017253356307051   1: 0.017251549846398   8: 0.017251304937441   7: 0.017251239476865   3: 0.017250269041995 

training_3841     5: 0.652945959614711   1: 0.146520352158948   0: 0.026232768953401   6: 0.024916780076953   9: 0.024901476609830   2: 0.024897801284584   3: 0.024896365124665   4: 0.024896358917618   7: 0.024896161349177   8: 0.024895975910113 

training_3843     6: 0.697923123795475   0: 0.116792433561851   1: 0.062125934028146   7: 0.017596693069607   9: 0.017596029907739   8: 0.017595679306625   3: 0.017592893733705   5: 0.017592572148803   4: 0.017592531414959   2: 0.017592109033090 

training_3846     0: 0.768452937789635   9: 0.074574711744821   8: 0.019633633491930   2: 0.019633479349056   1: 0.019629270296331   6: 0.019624520679580   5: 0.019618799284341   7: 0.019612570977993   4: 0.019611037130759   3: 0.019609039255556 

training_3847     6: 0.858433081625312   8: 0.021433636297106   0: 0.020164912903552   1: 0.014281913317576   3: 0.014281719260956   9: 0.014281176439379   5: 0.014281136129032   7: 0.014281035946095   4: 0.014280714090082   2: 0.014280673990910 

training_3850     1: 0.376851812650566   5: 0.321312991157630   4: 0.037743232424098   3: 0.037728227112704   2: 0.037727738337648   8: 0.037727706931071   7: 0.037727365786941   9: 0.037727082223043   0: 0.037727063145824   6: 0.037726780230473 

training_3851     1: 0.358915936295159   5: 0.358733642736263   2: 0.035296917459081   4: 0.035295557080556   6: 0.035293733414231   0: 0.035293421832567   3: 0.035293075344383   9: 0.035292900279664   7: 0.035292749722816   8: 0.035292065835279 

training_3853     4: 0.577310191386202   5: 0.260857513398297   6: 0.020230758579891   2: 0.020229410935499   1: 0.020229231554667   9: 0.020229111131555   0: 0.020228551580484   3: 0.020228546835160   7: 0.020228383521981   8: 0.020228301076265 

training_3855     6: 0.743790879118419   0: 0.106539032603140   1: 0.035799469657134   3: 0.016780439579732   2: 0.016207101523697   8: 0.016196523552362   7: 0.016183262125222   5: 0.016177054948590   9: 0.016163756757766   4: 0.016162480133939 

training_3856     5: 0.644006520600462   4: 0.135778955647246   8: 0.055622275155497   6: 0.043430313516167   7: 0.020209576495809   1: 0.020195173626346   3: 0.020192448387993   0: 0.020190991282690   2: 0.020187406335039   9: 0.020186338952751 

training_3857     5: 0.609628095323009   1: 0.167205876901442   3: 0.074456675774380   7: 0.021256842264805   6: 0.021243144833782   9: 0.021242369897415   0: 0.021242204568560   8: 0.021242128618283   4: 0.021241747477011   2: 0.021240914341312 

training_3858     5: 0.779094318815649   3: 0.024545560844275   2: 0.024545384811149   4: 0.024545158265044   6: 0.024545049766760   1: 0.024545046242931   0: 0.024544984423082   9: 0.024544875066430   7: 0.024544871559927   8: 0.024544750204752 

training_3860     5: 0.752922063694752   1: 0.093654033559304   4: 0.019179491528978   6: 0.019178177396464   8: 0.019177938957954   9: 0.019177864998035   3: 0.019177700928672   0: 0.019177684348589   2: 0.019177548138054   7: 0.019177496449198 

training_3862     6: 0.647360682479408   0: 0.176038706707630   9: 0.070607139437658   1: 0.031180233358647   7: 0.012505859360259   3: 0.012481737925424   5: 0.012457019417040   4: 0.012456232566443   8: 0.012456227822426   2: 0.012456160925064 

training_3864     6: 0.307940898014958   2: 0.305530092568252   0: 0.293205564413040   9: 0.023464461949938   4: 0.011664078732913   1: 0.011658616449052   5: 0.011638468108653   7: 0.011636796114930   8: 0.011630603604172   3: 0.011630420044092 

training_3865     5: 0.450771047177633   0: 0.295804699265473   1: 0.107076770876561   8: 0.020975236221462   6: 0.020958695987111   4: 0.020884511607505   9: 0.020883094337995   7: 0.020882436053014   2: 0.020881851430287   3: 0.020881657042959 

training_3867     5: 0.655793728471838   9: 0.184774091557081   6: 0.020023575377838   0: 0.019964488005118   1: 0.019920726666165   3: 0.019905879822566   8: 0.019904784468157   2: 0.019904352785203   4: 0.019904233498079   7: 0.019904139347954 

training_3868     5: 0.382609417248280   6: 0.342944628504109   7: 0.128957733932836   1: 0.036621497700732   8: 0.018152940798748   0: 0.018147736483578   3: 0.018142861256789   2: 0.018142331513475   4: 0.018141104884100   9: 0.018139747677353 

training_3869     6: 0.834528406217269   8: 0.061264163123791   1: 0.035754738007607   9: 0.013413231909439   2: 0.009199871761383   7: 0.009188927598580   5: 0.009174654174749   3: 0.009161973012350   0: 0.009161122630828   4: 0.009152911564003 

training_387      1: 0.630614778384610   6: 0.169557616160698   5: 0.055720270344266   9: 0.020594563959902   0: 0.020593078282749   3: 0.020586646829650   4: 0.020584259637927   7: 0.020583177964365   2: 0.020582936227652   8: 0.020582672208181 

training_3870     5: 0.832456702263955   4: 0.018620158595783   6: 0.018615809865719   0: 0.018615658456112   1: 0.018615489334911   8: 0.018615409409214   9: 0.018615321353634   3: 0.018615164522263   2: 0.018615148710761   7: 0.018615137487648 

training_3872     4: 0.702336529664421   5: 0.124758337528918   6: 0.021617522418889   2: 0.021613874354082   9: 0.021613260733341   1: 0.021612418864822   0: 0.021612324810211   3: 0.021611997877892   7: 0.021611934759391   8: 0.021611798988033 

training_3873     5: 0.618323876466713   7: 0.124556493206511   8: 0.085657908231400   6: 0.056733702273549   3: 0.019149282302311   4: 0.019132554737528   0: 0.019129292084940   1: 0.019110239958055   9: 0.019105285308004   2: 0.019101365430988 

training_3874     4: 0.771203724582057   5: 0.025426603223894   1: 0.025422055021564   0: 0.025421937514101   8: 0.025421487201098   9: 0.025421199910421   6: 0.025421029959206   3: 0.025420728595277   2: 0.025420639325776   7: 0.025420594666606 

training_3875     5: 0.782517308304714   1: 0.024165617630035   6: 0.024165181806562   3: 0.024165087298660   4: 0.024164930903405   0: 0.024164581684591   2: 0.024164423745497   8: 0.024164347322300   7: 0.024164305353980   9: 0.024164215950256 

training_3879     1: 0.676961874794595   6: 0.079477016635198   8: 0.074012001162367   5: 0.024222168195496   0: 0.024221855049710   4: 0.024221246716655   9: 0.024221077175592   3: 0.024221020769054   2: 0.024220911838455   7: 0.024220827662879 

training_388      5: 0.757886755931693   6: 0.081975291751794   4: 0.020021902565549   0: 0.020017119396357   9: 0.020016786945170   8: 0.020016534900996   1: 0.020016529324766   7: 0.020016397456212   3: 0.020016355339729   2: 0.020016326387733 

training_3881     6: 0.602526437151789   5: 0.229458240358370   9: 0.036175769177408   8: 0.033611575903360   2: 0.016382892035359   7: 0.016371208745078   0: 0.016370911182617   1: 0.016369021834812   4: 0.016367175564020   3: 0.016366768047186 

training_3884     5: 0.714030218398309   6: 0.106500450934389   0: 0.074178731775286   2: 0.015049967243787   1: 0.015049504261107   4: 0.015042731653049   8: 0.015037857576261   9: 0.015037727034017   7: 0.015036431662877   3: 0.015036379460918 

training_3886     0: 0.379701840615156   6: 0.276204224653438   4: 0.156119256666629   1: 0.057124445960154   3: 0.042467276004092   5: 0.017679967847870   9: 0.017676121246113   8: 0.017676098934163   7: 0.017675394416054   2: 0.017675373656330 

training_3888     6: 0.777128293204874   7: 0.066427172788211   3: 0.035586299417339   1: 0.033490310481596   5: 0.014561991842448   8: 0.014561866288984   0: 0.014561113558899   4: 0.014561086021096   9: 0.014560965768320   2: 0.014560900628233 

training_389      6: 0.443388414921661   5: 0.272216594700047   4: 0.182579492544109   2: 0.014564629568084   0: 0.014547512357858   1: 0.014545147023920   9: 0.014543420483607   8: 0.014543095808835   3: 0.014536250677750   7: 0.014535441914128 

training_3890     5: 0.435899355527913   1: 0.224756065179467   6: 0.205167035720426   8: 0.042061396534805   0: 0.015357079985176   4: 0.015353040156013   2: 0.015351888289616   9: 0.015351814940146   7: 0.015351345741866   3: 0.015350977924572 

training_3892     6: 0.569153598371025   9: 0.300592554897707   5: 0.026089552534635   1: 0.014883816841026   0: 0.014882722058502   2: 0.014881852693838   7: 0.014879958753802   8: 0.014879489770414   3: 0.014878236515344   4: 0.014878217563706 

training_3893     0: 0.615757793949598   3: 0.215789661092031   6: 0.021074484660391   5: 0.021061013808087   8: 0.021059763608004   1: 0.021055387892017   4: 0.021055069587853   9: 0.021050221267328   7: 0.021048367553027   2: 0.021048236581664 

training_3894     4: 0.778976206517602   5: 0.024564570289051   0: 0.024557819261425   1: 0.024557698727830   8: 0.024557643092864   2: 0.024557320763171   3: 0.024557282034795   9: 0.024557215328036   6: 0.024557140969458   7: 0.024557103015767 

training_3895     4: 0.748703944877732   5: 0.027929121526366   6: 0.027921624163390   9: 0.027920986204186   8: 0.027920797927692   1: 0.027920763190411   2: 0.027920749782760   3: 0.027920740433169   0: 0.027920672550934   7: 0.027920599343360 

training_3897     6: 0.749008006359817   0: 0.027890665103425   1: 0.027889435904157   7: 0.027888102035489   5: 0.027887750541031   8: 0.027887651875453   9: 0.027887304293747   4: 0.027887174528158   2: 0.027887050033598   3: 0.027886859325124 

training_3898     6: 0.789406488893009   5: 0.023402413593205   9: 0.023400201582681   4: 0.023400077275827   7: 0.023399712760936   0: 0.023398926338913   1: 0.023398426018188   8: 0.023398080812945   2: 0.023397866785177   3: 0.023397805939118 

training_3899     0: 0.670783683804230   4: 0.184910664241190   6: 0.018122535807008   1: 0.018046452763413   9: 0.018029567444175   5: 0.018026467587721   2: 0.018021037546189   7: 0.018019991281733   8: 0.018019924306890   3: 0.018019675217451 

training_390      6: 0.333223467801348   8: 0.200191858060551   0: 0.163081748442662   3: 0.119374449379083   5: 0.103529171706678   2: 0.025476922524415   1: 0.013784221110241   4: 0.013780692162470   7: 0.013778742026830   9: 0.013778726785722 

training_3900     5: 0.833129572822195   6: 0.018554936805444   4: 0.018542936548295   9: 0.018542924865557   1: 0.018539844426545   0: 0.018538387597296   3: 0.018538162881257   8: 0.018538025502556   7: 0.018537619303898   2: 0.018537589246957 

training_3901     6: 0.587866457120282   5: 0.260924798174633   7: 0.032076848073483   3: 0.017042322501944   9: 0.017034213454330   8: 0.017015632752795   0: 0.017014879741114   1: 0.017009897910743   2: 0.017007818268161   4: 0.017007132002515 

training_3902     6: 0.659690518882911   0: 0.224198017391536   2: 0.024604383488759   1: 0.013367856048364   7: 0.013030483769294   4: 0.013022345799383   5: 0.013022195111736   9: 0.013021862845096   8: 0.013021545344452   3: 0.013020791318468 

training_3903     5: 0.802607545275292   2: 0.063004181805061   8: 0.016803039993274   6: 0.016801410824980   0: 0.016798410163943   4: 0.016798000593074   9: 0.016797854823386   7: 0.016797393969561   1: 0.016796717957103   3: 0.016795444594324 

training_3904     6: 0.789249255958075   8: 0.085409103989490   5: 0.015688712992697   4: 0.015669210076109   9: 0.015668587133021   0: 0.015666285709997   1: 0.015664874093312   7: 0.015662257591462   2: 0.015661026201199   3: 0.015660686254638 

training_3905     5: 0.644125714678395   0: 0.119929892882623   3: 0.085272501491678   9: 0.021547837070684   7: 0.021529179439197   8: 0.021524788618631   6: 0.021519859362282   1: 0.021517195217089   4: 0.021516697837991   2: 0.021516333401430 

training_3906     6: 0.513101949767509   7: 0.178196307364531   2: 0.173003546954081   0: 0.060109163644656   5: 0.012600499214083   1: 0.012600025685449   9: 0.012598117540406   4: 0.012597620242462   8: 0.012596507400471   3: 0.012596262186352 

training_3908     5: 0.713022338473332   3: 0.122902971701954   4: 0.054241582875009   6: 0.015692521360010   1: 0.015691444384648   0: 0.015690219178818   9: 0.015690014511655   8: 0.015689889899610   7: 0.015689709824155   2: 0.015689307790809 

training_3909     4: 0.815716457931332   5: 0.020480980853721   6: 0.020475808106836   0: 0.020475632076781   9: 0.020475459687861   8: 0.020475257188422   1: 0.020475152566350   3: 0.020475129855890   2: 0.020475071632501   7: 0.020475050100307 

training_3910     6: 0.347237114015378   4: 0.321788059338932   3: 0.106131531069477   7: 0.075325629098922   5: 0.042573143158620   9: 0.039676104898405   1: 0.016818881844236   0: 0.016818394764502   2: 0.016815921689832   8: 0.016815220121697 

training_3912     0: 0.695026447149621   6: 0.106503940379206   1: 0.047080877435615   3: 0.045185121674976   5: 0.028196304406444   9: 0.022912935007128   7: 0.013775557352811   4: 0.013773262823455   2: 0.013773007434409   8: 0.013772546336335 

training_3913     6: 0.744805710590717   1: 0.028356156308829   0: 0.028356092888034   7: 0.028355954743178   5: 0.028354711988696   8: 0.028354624327724   2: 0.028354374682125   9: 0.028354340202224   4: 0.028354181638594   3: 0.028353852629878 

training_3916     1: 0.515193714395531   8: 0.208575753239139   6: 0.107472579125921   7: 0.064007501651170   5: 0.017462821355789   0: 0.017459940525840   9: 0.017457284637725   4: 0.017457067945220   2: 0.017456743693027   3: 0.017456593430637 

training_3917     3: 0.523391643479683   5: 0.271561781017868   4: 0.025631607633540   6: 0.025630982597685   8: 0.025630893256712   0: 0.025630787083861   1: 0.025630656085023   2: 0.025630643365326   7: 0.025630574113858   9: 0.025630431366445 

training_3918     9: 0.371691315318778   5: 0.201353299330282   6: 0.176575189826709   1: 0.131914267531186   2: 0.036393504005253   0: 0.016425464405088   4: 0.016412135269420   7: 0.016411787268603   3: 0.016411615691029   8: 0.016411421353652 

training_392      4: 0.394113676710471   3: 0.338471792199807   5: 0.033439716761850   2: 0.033425441777027   1: 0.033425297944941   0: 0.033425153638982   8: 0.033425077521295   7: 0.033424807607149   9: 0.033424662593545   6: 0.033424373244931 

training_3920     1: 0.438437496102971   4: 0.264698408027262   3: 0.151836812719803   9: 0.041744485920931   6: 0.017232244358867   0: 0.017215179736215   5: 0.017213845745993   8: 0.017207771184855   2: 0.017206892896683   7: 0.017206863306420 

training_3922     3: 0.458821342796895   5: 0.333429604588155   0: 0.025987570086822   4: 0.025971120220283   6: 0.025965931098045   1: 0.025965385887415   8: 0.025965381437007   9: 0.025965157802078   2: 0.025964317032679   7: 0.025964189050622 

training_3926     1: 0.704309312232590   4: 0.154038791907395   5: 0.017711359154755   6: 0.017708054512808   0: 0.017707951503004   2: 0.017706608737408   7: 0.017704796101931   9: 0.017704707447550   3: 0.017704285052000   8: 0.017704133350559 

training_3928     6: 0.846414145995744   1: 0.030912590944440   3: 0.015342505758182   0: 0.015333906565517   5: 0.015333165304672   9: 0.015332950626875   7: 0.015332842107730   4: 0.015332740723119   2: 0.015332649591907   8: 0.015332502381813 

training_393      6: 0.460227737888700   1: 0.383325659703817   9: 0.028323866858364   0: 0.018323053121322   5: 0.018303864360211   4: 0.018299921674995   2: 0.018299311918267   7: 0.018298957166269   8: 0.018298826991186   3: 0.018298800316870 

training_3930     6: 0.790720968028733   5: 0.049599615154694   0: 0.019970950427491   2: 0.019963700074477   1: 0.019962179559730   4: 0.019959907068706   8: 0.019958937528256   9: 0.019958347069990   3: 0.019953243778268   7: 0.019952151309655 

training_3931     6: 0.698603582965077   0: 0.210781834327998   8: 0.016232576443692   2: 0.011416661023450   1: 0.010575562327197   7: 0.010481664434870   4: 0.010477633317571   5: 0.010477463650460   9: 0.010476804190699   3: 0.010476217318986 

training_3933     1: 0.842491009687464   5: 0.017509811481140   6: 0.017503043065113   8: 0.017501480771360   4: 0.017500260474086   0: 0.017499603017032   9: 0.017499559275606   7: 0.017498654073492   2: 0.017498604052127   3: 0.017497974102581 

training_3934     5: 0.610104010550566   7: 0.198911315609241   3: 0.038896047471183   4: 0.021803356391954   0: 0.021768445220244   6: 0.021756417536884   1: 0.021707018986237   9: 0.021692943436465   8: 0.021681727828007   2: 0.021678716969219 

training_3937     5: 0.583657374798567   6: 0.163009648916152   1: 0.139274099113822   9: 0.016297315858312   0: 0.016296049861520   4: 0.016294337144586   8: 0.016293883824806   2: 0.016292621527144   7: 0.016292393785586   3: 0.016292275169506 

training_3939     4: 0.434176924417228   1: 0.154253165163022   5: 0.149104752249546   9: 0.071449547186768   7: 0.070789571777150   8: 0.024067344952882   2: 0.024045176048600   6: 0.024042881743553   0: 0.024038382865147   3: 0.024032253596103 

training_3942     6: 0.535430635116973   9: 0.294582734270990   8: 0.064996515203667   0: 0.023789910798478   5: 0.020519532061159   3: 0.012179336045797   4: 0.012159716288416   1: 0.012114440468076   7: 0.012113780011226   2: 0.012113399735217 

training_3944     5: 0.519556604996207   8: 0.285756074196739   1: 0.024336754167012   6: 0.024336309551236   3: 0.024336177293261   0: 0.024336128425701   4: 0.024336043473284   2: 0.024335512927763   7: 0.024335272299352   9: 0.024335122669445 

training_3946     5: 0.703988637578546   1: 0.131021209002732   4: 0.020632008584404   9: 0.020623313286964   0: 0.020622857568563   6: 0.020622770465117   8: 0.020622472681821   7: 0.020622314506674   2: 0.020622270645701   3: 0.020622145679477 

training_3948     1: 0.745057666114716   2: 0.097307692906926   5: 0.019709029726731   4: 0.019707028822984   8: 0.019704053957968   6: 0.019703647516449   0: 0.019703291571298   9: 0.019703098249874   7: 0.019702490240892   3: 0.019702000892162 

training_3949     6: 0.707173762791880   0: 0.098058745269947   7: 0.063414554321829   9: 0.034388802677519   5: 0.016178682990376   8: 0.016175649887909   1: 0.016158034459280   4: 0.016154773625791   3: 0.016148502211575   2: 0.016148491763894 

training_395      6: 0.734754225875060   0: 0.101801059140081   5: 0.020431853876145   9: 0.020431514333242   7: 0.020431166398112   8: 0.020430475561551   4: 0.020430414771604   1: 0.020429973115756   3: 0.020429749927429   2: 0.020429567001019 

training_3950     6: 0.575981893625920   7: 0.205804746668946   3: 0.080903923980086   1: 0.046903026384200   5: 0.015195931807686   0: 0.015049021520062   2: 0.015042364235347   9: 0.015041308424360   4: 0.015038964204493   8: 0.015038819148900 

training_3951     6: 0.361422241639903   2: 0.292096851448483   5: 0.208533694587606   8: 0.019722939522251   1: 0.019717380345735   0: 0.019704537562455   4: 0.019704228228380   9: 0.019699879890245   7: 0.019699382541457   3: 0.019698864233486 

training_3952     5: 0.605615668890310   2: 0.175396935097167   6: 0.074180804559807   4: 0.020690033465145   0: 0.020686995291393   1: 0.020686737494286   9: 0.020686163681677   8: 0.020685628140876   7: 0.020685580649850   3: 0.020685452729489 

training_3954     4: 0.772225338654060   5: 0.025314240490494   8: 0.025307798877153   6: 0.025307675651667   1: 0.025307623966308   2: 0.025307564044426   3: 0.025307486805455   0: 0.025307452905242   7: 0.025307438095883   9: 0.025307380509311 

training_3955     6: 0.782475325164834   1: 0.061838039464318   0: 0.056902899040711   8: 0.014132310351731   7: 0.014117885153283   2: 0.014110180931078   5: 0.014107305828886   9: 0.014105507672150   3: 0.014105358060489   4: 0.014105188332520 

training_3957     0: 0.498640019759512   6: 0.345180014414685   3: 0.028236430989801   1: 0.027323293760674   9: 0.025812506308742   5: 0.014977962598958   8: 0.014974263356654   2: 0.014953805573116   7: 0.014950916263833   4: 0.014950786974025 

training_3958     5: 0.769398465807648   4: 0.025631071543864   8: 0.025621549642875   0: 0.025621390604113   2: 0.025621294908126   1: 0.025621269860214   3: 0.025621266351065   9: 0.025621261013192   7: 0.025621236788422   6: 0.025621193480479 

training_3959     2: 0.597114998567616   6: 0.164622093676332   5: 0.029784582868081   0: 0.029783922632016   9: 0.029783040363287   1: 0.029782722386324   4: 0.029782667990859   8: 0.029782111155468   7: 0.029782063882367   3: 0.029781796477650 

training_396      5: 0.596456307970686   4: 0.200296829084623   6: 0.025413159249142   1: 0.025411549523386   0: 0.025407712990206   9: 0.025403121588610   3: 0.025403039224427   2: 0.025402934223199   7: 0.025402706629209   8: 0.025402639516512 

training_3960     5: 0.749483966322978   7: 0.058617062054286   4: 0.052101752457787   9: 0.019985002452720   6: 0.019983327155888   1: 0.019972024544092   0: 0.019970383206915   3: 0.019962525523198   2: 0.019962504038507   8: 0.019961452243629 

training_3961     5: 0.816297106435662   1: 0.020416410900678   6: 0.020415996836130   0: 0.020413207993637   7: 0.020409763960984   4: 0.020409591279281   8: 0.020409560139821   9: 0.020409527664970   2: 0.020409510037119   3: 0.020409324751717 

training_3964     0: 0.464499275911296   5: 0.307397507459205   1: 0.028522278486092   6: 0.028515089363114   4: 0.028511823916736   2: 0.028511586842139   3: 0.028510868929575   7: 0.028510700167287   9: 0.028510465699739   8: 0.028510403224817 

training_3968     5: 0.733029314395266   6: 0.029665941690936   4: 0.029665533784255   1: 0.029665470551730   7: 0.029663948910972   8: 0.029663533027154   3: 0.029662583986582   2: 0.029662494845703   0: 0.029660708519556   9: 0.029660470287847 

training_3970     6: 0.669143334255770   7: 0.126505875355914   2: 0.049595651479810   5: 0.045093605762871   1: 0.018280160356873   0: 0.018277701119883   8: 0.018277004904166   4: 0.018275996412340   3: 0.018275393238307   9: 0.018275277114067 

training_3971     5: 0.748923882074654   4: 0.027901046219043   8: 0.027897036342883   3: 0.027897021529392   2: 0.027896902600923   9: 0.027896857969698   6: 0.027896853930067   7: 0.027896835619972   0: 0.027896811697110   1: 0.027896752016259 

training_3973     6: 0.777091875979327   8: 0.080983790310624   1: 0.017749863051524   5: 0.017741358123157   7: 0.017740044583094   0: 0.017739680251835   3: 0.017738630566831   4: 0.017738372822214   9: 0.017738270146980   2: 0.017738114164413 

training_3976     2: 0.489132135999218   7: 0.262239124082698   5: 0.031088340826562   4: 0.031079491425103   9: 0.031078521326472   1: 0.031077542345611   6: 0.031077053598520   0: 0.031076434337691   8: 0.031076205807644   3: 0.031075150250483 

training_3977     5: 0.680632256440398   1: 0.151204065393013   6: 0.021041559262781   0: 0.021028378122001   4: 0.021017856465949   9: 0.021015569595082   7: 0.021015218147673   2: 0.021015171810556   8: 0.021015069324753   3: 0.021014855437792 

training_3979     6: 0.784570650402752   5: 0.082999830480371   0: 0.022934786758932   7: 0.022815738581739   2: 0.014540130427145   8: 0.014499888377132   4: 0.014450487677019   3: 0.014401542202794   1: 0.014395642618718   9: 0.014391302473397 

training_398      2: 0.721537488024857   1: 0.030967487580831   6: 0.030959670976234   0: 0.030953660231771   5: 0.030945965529474   4: 0.030931289327657   7: 0.030928338217734   3: 0.030926223303519   8: 0.030925724562524   9: 0.030924152245399 

training_3980     6: 0.446169848112004   7: 0.408060138577390   2: 0.018230223610320   9: 0.018223717671817   5: 0.018222337837812   4: 0.018219796773083   0: 0.018219545742250   1: 0.018219013954742   8: 0.018218555707679   3: 0.018216822012904 

training_3981     6: 0.580941260297027   7: 0.214576618136300   0: 0.123322559041657   1: 0.011713826798411   3: 0.011600473713569   8: 0.011570967003656   9: 0.011570795267884   5: 0.011568161420974   4: 0.011567889919787   2: 0.011567448400735 

training_3982     6: 0.627839190239980   0: 0.193093162168387   1: 0.095595531121064   5: 0.011928316658366   9: 0.011924754927428   3: 0.011924504769171   4: 0.011923778132385   8: 0.011923729395946   2: 0.011923556011561   7: 0.011923476575710 

training_3983     0: 0.625436063009267   9: 0.139213252196944   1: 0.029436093364294   3: 0.029416923687851   6: 0.029416678136123   4: 0.029416466880657   2: 0.029416181258718   8: 0.029416141688493   7: 0.029416107717629   5: 0.029416092060024 

training_3984     0: 0.575428862893279   6: 0.296391942977112   9: 0.043992473569553   1: 0.012041870247091   2: 0.012039004391964   7: 0.012026204862886   5: 0.012021743934183   3: 0.012021128075366   4: 0.012018882156278   8: 0.012017886892290 

training_3985     2: 0.653935224000062   1: 0.143811232107691   5: 0.079142716313768   6: 0.017674872821543   0: 0.017581008035465   4: 0.017573755011393   9: 0.017572508632094   3: 0.017569993435286   8: 0.017569544931153   7: 0.017569144711543 

training_3989     5: 0.771011284253154   6: 0.025478475227702   1: 0.025456418630136   0: 0.025452284612268   7: 0.025440161250652   4: 0.025435125623582   9: 0.025433483019139   8: 0.025431135275989   3: 0.025431089163442   2: 0.025430542943936 

training_399      5: 0.656944508527712   8: 0.152309532847905   6: 0.023847985375777   4: 0.023846275303232   9: 0.023845519283803   1: 0.023842842902436   0: 0.023841264131358   7: 0.023840857543478   2: 0.023840623646239   3: 0.023840590438061 

training_3990     9: 0.585518574656742   0: 0.219001090214579   6: 0.024446510113810   1: 0.024436921429823   5: 0.024436493223129   4: 0.024433684122883   8: 0.024431975629690   2: 0.024431837987124   7: 0.024431506623387   3: 0.024431405998832 

training_3991     0: 0.612991792072230   1: 0.254488948225486   3: 0.031107188945349   5: 0.014560692343600   6: 0.014503017225476   8: 0.014477460694451   7: 0.014474582160072   9: 0.014467214781327   4: 0.014464609896327   2: 0.014464493655681 

training_3993     0: 0.670860043915852   5: 0.103776089963018   1: 0.092085175478923   6: 0.019065578666432   2: 0.019037076538804   9: 0.019036083743526   8: 0.019035725798427   7: 0.019035225679491   4: 0.019034715536133   3: 0.019034284679393 

training_3994     4: 0.829255933925928   5: 0.018980981180689   6: 0.018973699843267   7: 0.018970372747425   9: 0.018970368557953   0: 0.018970159588527   3: 0.018969926138779   1: 0.018969607446479   8: 0.018969541044882   2: 0.018969409526072 

training_3995     6: 0.627865104932699   7: 0.248896866094039   9: 0.015408244359455   5: 0.015407300638111   2: 0.015406631042968   4: 0.015405278858345   8: 0.015403393250864   0: 0.015403045912311   1: 0.015402540842227   3: 0.015401594068983 

training_3996     5: 0.793052545877775   6: 0.023009148186546   0: 0.022994773318317   9: 0.022994165488435   8: 0.022992809921229   4: 0.022992190208734   1: 0.022991587816321   7: 0.022991292373920   2: 0.022990779694728   3: 0.022990707113994 

training_3997     6: 0.293697430124405   2: 0.288053343560417   0: 0.175202852990267   4: 0.124150656849735   8: 0.035850559935609   7: 0.016613097183491   5: 0.016609584406570   1: 0.016608075763702   3: 0.016607768655656   9: 0.016606630530147 

training_3999     5: 0.666274071176649   6: 0.148536926898201   2: 0.068281171237296   1: 0.016707794657302   4: 0.016704214453458   0: 0.016700992725449   8: 0.016699059112175   9: 0.016698928308785   7: 0.016698637782585   3: 0.016698203648100 

training_40       5: 0.408729404086712   6: 0.387362514827369   0: 0.066687843199277   9: 0.019607357876090   1: 0.019604728140749   4: 0.019602363726506   7: 0.019601795383451   8: 0.019601746206694   2: 0.019601343003226   3: 0.019600903549926 

training_400      1: 0.716520806117018   5: 0.031510745976466   4: 0.031503858424854   6: 0.031497813735962   0: 0.031497175561049   8: 0.031496723606345   9: 0.031494483053332   2: 0.031493408615039   7: 0.031492560328234   3: 0.031492424581700 

training_4000     5: 0.800736522460180   4: 0.022145234896309   8: 0.022139906789208   6: 0.022139877155827   0: 0.022139840190001   1: 0.022139800570888   3: 0.022139756754036   9: 0.022139755618854   2: 0.022139667105350   7: 0.022139638459347 

training_4005     6: 0.417548440771427   0: 0.390982195816748   1: 0.077483104055669   5: 0.041650266787198   4: 0.023906269982075   9: 0.009693709121533   2: 0.009686457984051   8: 0.009684062213811   7: 0.009682808956577   3: 0.009682684310912 

training_401      1: 0.555676195950751   6: 0.196877253504402   7: 0.076277234823703   8: 0.037488126129158   0: 0.033976694794916   2: 0.020005719553142   5: 0.019926717396074   9: 0.019924359848405   4: 0.019924165844998   3: 0.019923532154450 

training_4012     5: 0.563598230942408   0: 0.198138224626520   8: 0.080010250281464   3: 0.056906854265760   7: 0.032142695014754   4: 0.013843011814541   1: 0.013842223587944   6: 0.013842159351623   9: 0.013838866520055   2: 0.013837483594931 

training_4014     5: 0.712790040689015   7: 0.090777823606480   9: 0.071111990434864   6: 0.017904389755084   4: 0.017904145827068   0: 0.017903187256989   1: 0.017902944728757   8: 0.017901872291652   3: 0.017901816210600   2: 0.017901789199491 

training_4015     4: 0.793244983079496   5: 0.022980077655254   1: 0.022973402800852   6: 0.022972780129051   0: 0.022972461958291   2: 0.022971720537632   8: 0.022971510703068   9: 0.022971134523898   3: 0.022970966481727   7: 0.022970962130733 

training_4016     6: 0.511277331113749   9: 0.192088568964240   1: 0.153218575460758   8: 0.037774499612385   0: 0.037609921645803   4: 0.016987568883520   2: 0.016448091478100   5: 0.011538568604924   7: 0.011530246623044   3: 0.011526627613477 

training_4019     6: 0.373029166896784   5: 0.249036686694940   0: 0.230139408946040   8: 0.071272222030211   1: 0.012861608720997   4: 0.012736034020278   9: 0.012732691322238   2: 0.012730834526107   7: 0.012730729060089   3: 0.012730617782317 

training_402      6: 0.793404681791383   8: 0.080531944635680   2: 0.015759757462695   1: 0.015759265753819   5: 0.015758505747403   0: 0.015757822876752   9: 0.015757386571551   3: 0.015757283455550   7: 0.015756740520889   4: 0.015756611184277 

training_4021     5: 0.449891358163698   6: 0.344595037606356   4: 0.025696921577606   8: 0.025688386842946   1: 0.025688354295135   3: 0.025688211395658   0: 0.025688178851995   2: 0.025687947216255   7: 0.025687829800418   9: 0.025687774249932 

training_4022     6: 0.609146695233333   5: 0.241413132545977   7: 0.031326294581432   3: 0.016901107314121   9: 0.016888814469844   8: 0.016872975578183   0: 0.016868353715963   1: 0.016862500752495   2: 0.016860427779130   4: 0.016859698029522 

training_4023     6: 0.359272494490614   5: 0.287324286649358   0: 0.210347503615735   3: 0.020441420504752   1: 0.020438635076544   2: 0.020436205755422   4: 0.020435210165111   8: 0.020434798901364   7: 0.020434724545170   9: 0.020434720295930 

training_4025     5: 0.484360901905445   7: 0.217705034542187   9: 0.135188242968302   1: 0.023256463399773   3: 0.023248904817299   4: 0.023248571147488   8: 0.023248003210408   0: 0.023248000798906   6: 0.023247999166160   2: 0.023247878044031 

training_4026     6: 0.789062696993780   0: 0.068289793143893   1: 0.056632617281217   8: 0.024632675728623   3: 0.013690007335421   9: 0.013673373124562   5: 0.008505429715348   4: 0.008504563356901   2: 0.008504447784604   7: 0.008504395535650 

training_4027     6: 0.804426563522632   0: 0.068985170513003   1: 0.051519958563547   5: 0.010728062185375   9: 0.010726311309309   4: 0.010723477695175   2: 0.010722995384996   7: 0.010722674815290   8: 0.010722523349646   3: 0.010722262661027 

training_4028     6: 0.729949324481039   7: 0.156838928749300   2: 0.014165592793277   3: 0.014159113760803   0: 0.014153306240570   5: 0.014149422510143   4: 0.014148482906674   1: 0.014146589187848   9: 0.014144803410119   8: 0.014144435960227 

training_4029     5: 0.744411071818439   9: 0.065045292316686   1: 0.063653345211405   0: 0.018134024696687   6: 0.018128836708232   4: 0.018128139433353   8: 0.018124971537232   7: 0.018124848669063   2: 0.018124799494959   3: 0.018124670113946 

training_4031     6: 0.804292031036160   5: 0.070992740947029   1: 0.039779924197057   0: 0.012153270552604   9: 0.012130530711861   7: 0.012130509801307   8: 0.012130377135929   4: 0.012130342742541   3: 0.012130162991712   2: 0.012130109883799 

training_4032     9: 0.428391364752690   0: 0.353544001699417   1: 0.027266085737258   5: 0.027262918365039   6: 0.027262646566318   4: 0.027259657533864   2: 0.027254522002509   8: 0.027253653589148   7: 0.027252930462992   3: 0.027252219290765 

training_4033     6: 0.363829447269858   9: 0.288919775513057   0: 0.235595909687296   1: 0.015958688359027   5: 0.015952244478277   4: 0.015949870635759   2: 0.015948611332035   7: 0.015948557401258   8: 0.015948477191025   3: 0.015948418132407 

training_4035     6: 0.656317026423908   4: 0.082230757435777   1: 0.056726327830539   5: 0.049587951540434   0: 0.047413253051665   9: 0.043141481813898   7: 0.016148197829291   2: 0.016145353189744   3: 0.016145169736663   8: 0.016144481148080 

training_4036     6: 0.436647099046147   7: 0.414940997622642   9: 0.018552220910137   0: 0.018552144321421   1: 0.018551690899399   8: 0.018551647380260   5: 0.018551604309686   4: 0.018551021270962   2: 0.018550816240017   3: 0.018550757999329 

training_4038     6: 0.817150520862135   2: 0.051323465746222   0: 0.016444387387071   1: 0.016441337302679   5: 0.016440368144071   8: 0.016440077489779   9: 0.016440057382008   7: 0.016440052978812   3: 0.016439947353658   4: 0.016439785353566 

training_4039     6: 0.757475477266087   4: 0.065577690648229   0: 0.059666124445884   7: 0.032638456433563   1: 0.021881235826648   3: 0.012681508835547   9: 0.012565796283540   2: 0.012513511435534   5: 0.012504026456031   8: 0.012496172368937 

training_404      5: 0.603847957331238   4: 0.233506907506113   1: 0.020333233913339   6: 0.020332983645796   0: 0.020331388099933   3: 0.020329661330584   8: 0.020329525363225   2: 0.020329509229068   9: 0.020329446173026   7: 0.020329387407679 

training_4040     6: 0.623642357282704   8: 0.205150882678153   2: 0.064316168343516   7: 0.015295711863709   5: 0.015266452245834   9: 0.015266040037803   1: 0.015265831635549   3: 0.015265661576375   0: 0.015265601659725   4: 0.015265292676631 

training_4041     6: 0.510862104340417   9: 0.198274295355758   0: 0.191381516842962   1: 0.014214001729623   2: 0.014212484218241   5: 0.014212033449834   8: 0.014211234679752   7: 0.014211021709055   3: 0.014210880057662   4: 0.014210427616696 

training_4043     6: 0.502293890405333   8: 0.233320201356677   5: 0.093814398564291   7: 0.065083411047943   4: 0.040945066788294   1: 0.012920830878513   0: 0.012916565273720   3: 0.012902047510628   2: 0.012901812888494   9: 0.012901775286108 

training_4045     6: 0.519746783355236   5: 0.213378740727253   0: 0.157692264785030   8: 0.017290188929426   7: 0.015370451382041   9: 0.015338250060552   3: 0.015297978094616   1: 0.015295994687279   4: 0.015295524155273   2: 0.015293823823294 

training_4047     6: 0.821332540409341   5: 0.019853534686566   0: 0.019852382640669   8: 0.019852003588171   9: 0.019851938693652   4: 0.019851845840569   7: 0.019851594471997   1: 0.019851559921462   3: 0.019851405747344   2: 0.019851194000229 

training_4048     6: 0.783392512220936   5: 0.057967033494267   0: 0.047354532478829   4: 0.028411103741613   7: 0.013819711365937   1: 0.013811771200018   9: 0.013811713624002   8: 0.013810855394540   2: 0.013810520760935   3: 0.013810245718923 

training_4049     6: 0.526540047846269   2: 0.154493413182949   1: 0.143559791283430   0: 0.098400684035937   8: 0.024292419797563   5: 0.012455317193549   9: 0.010209149147267   4: 0.010016616504217   7: 0.010016441441647   3: 0.010016119567171 

training_405      5: 0.605998518262417   8: 0.204742276291578   4: 0.023660098937812   1: 0.023658235190608   0: 0.023658122797063   6: 0.023657198793643   3: 0.023656546311626   2: 0.023656505818281   9: 0.023656286874891   7: 0.023656210722081 

training_4051     6: 0.594571586136133   8: 0.244676801469077   0: 0.040360243904742   1: 0.017229155829321   3: 0.017202110231373   5: 0.017193564611340   9: 0.017191754400610   2: 0.017191753084193   4: 0.017191611066570   7: 0.017191419266640 

training_4052     6: 0.431163683610725   1: 0.230697277501544   5: 0.148175749101643   0: 0.117442081417736   7: 0.024819431913168   8: 0.009566618799115   9: 0.009540996804147   3: 0.009531933425211   2: 0.009531186621584   4: 0.009531040805127 

training_4054     9: 0.533203445957249   6: 0.308393772523356   7: 0.031763206778491   0: 0.023006221534003   5: 0.021059412803569   3: 0.016661451904548   2: 0.016547953740775   4: 0.016458112615814   1: 0.016454745872866   8: 0.016451676269328 

training_4055     6: 0.423685021964644   1: 0.339224232025471   0: 0.110179898790483   5: 0.047128314027979   7: 0.025268123929854   4: 0.010903341006415   9: 0.010902953781349   8: 0.010902832109020   2: 0.010902675343557   3: 0.010902607021228 

training_4056     6: 0.790747614963847   0: 0.055922807546706   9: 0.019168408889174   5: 0.019167151623526   1: 0.019166962857890   8: 0.019165724546683   7: 0.019165546365882   4: 0.019165416014422   2: 0.019165184553175   3: 0.019165182638697 

training_4057     6: 0.690064631107302   2: 0.160787707475917   1: 0.027940969249469   7: 0.022875906696997   0: 0.022727505401084   5: 0.015365863296239   4: 0.015080967316117   8: 0.015060599545437   3: 0.015054883698318   9: 0.015040966213120 

training_4058     1: 0.504347779745064   6: 0.331570499065236   2: 0.029531793683243   3: 0.027381021400393   0: 0.018076374352611   9: 0.017846689309459   5: 0.017828047108043   8: 0.017806110756153   7: 0.017805885239736   4: 0.017805799340063 

training_406      5: 0.386929652401241   0: 0.321945567066697   3: 0.081980635967903   4: 0.069148115452542   7: 0.023346648324673   1: 0.023332676447394   6: 0.023332652638048   8: 0.023328250995660   9: 0.023327903826365   2: 0.023327896879477 

training_4061     6: 0.765288595271285   1: 0.089537788751159   8: 0.052321777832382   0: 0.013274759331209   9: 0.013266734177790   5: 0.013263253831867   3: 0.013262024233368   2: 0.013261781240895   7: 0.013261721818203   4: 0.013261563511843 

training_4062     0: 0.759680907734634   5: 0.026715266072687   4: 0.026708572319416   6: 0.026707921826559   8: 0.026703830230352   9: 0.026699212732576   7: 0.026696660173017   1: 0.026696069262733   2: 0.026695848630052   3: 0.026695711017976 

training_4063     6: 0.788141328775427   8: 0.056975228596816   7: 0.056279808182486   0: 0.014108034447966   4: 0.014083000251155   5: 0.014082959583230   1: 0.014082608068812   9: 0.014082597910453   2: 0.014082240123720   3: 0.014082194059935 

training_4064     1: 0.599143916472420   0: 0.182697780331941   7: 0.069535499409512   8: 0.028908719893097   6: 0.023498908130178   3: 0.019601815776760   2: 0.019187028342069   5: 0.019159492155882   4: 0.019134312153041   9: 0.019132527335100 

training_4065     5: 0.533880070443665   6: 0.177900702594159   3: 0.147911509293436   0: 0.020044900418010   1: 0.020044700390426   4: 0.020044520818064   8: 0.020043571457338   9: 0.020043490152714   7: 0.020043276300452   2: 0.020043258131735 

training_4066     6: 0.814499790073405   5: 0.020611581015280   3: 0.020611566788304   0: 0.020611449320460   1: 0.020611343057104   4: 0.020611035678787   9: 0.020610949655115   8: 0.020610776562082   7: 0.020610768782867   2: 0.020610739066597 

training_4067     6: 0.735417300330592   0: 0.105308524237133   1: 0.060447031457558   4: 0.022439826360063   3: 0.020381638485442   7: 0.016624713598763   2: 0.010751741096896   5: 0.009551134108934   8: 0.009539808186189   9: 0.009538282138429 

training_4069     1: 0.381099305969086   0: 0.208603808838330   6: 0.146889808072894   8: 0.089866664459138   4: 0.062141168071080   9: 0.043541888669655   3: 0.027147356491337   5: 0.013571211105913   7: 0.013569452262075   2: 0.013569336060492 

training_407      5: 0.420715228038168   8: 0.386022261713841   0: 0.024158570546171   1: 0.024158399694492   6: 0.024158378699429   3: 0.024157846705012   4: 0.024157492728738   2: 0.024157434513483   7: 0.024157193938098   9: 0.024157193422567 

training_4071     6: 0.851041294837836   0: 0.036616141143400   8: 0.033940067306660   7: 0.015773875269413   1: 0.010661135716374   5: 0.010398464553574   3: 0.010392465172970   4: 0.010392223919510   9: 0.010392193455376   2: 0.010392138624886 

training_4074     6: 0.797157230724076   0: 0.097773804072910   1: 0.013145670857194   5: 0.013134765871696   4: 0.013133664651423   7: 0.013131611878324   8: 0.013131498558756   9: 0.013131343045230   3: 0.013130239739876   2: 0.013130170600516 

training_4075     6: 0.583276100163218   0: 0.161023536739965   5: 0.104088726875121   3: 0.065196324947563   1: 0.014411653592282   4: 0.014404701232363   7: 0.014401423370133   9: 0.014399890241107   8: 0.014398969480833   2: 0.014398673357414 

training_4076     6: 0.743308340905811   0: 0.111488420992006   5: 0.018161056133084   7: 0.018151867720879   8: 0.018151212067063   1: 0.018149931926796   4: 0.018147378129453   9: 0.018147306785579   3: 0.018147269758780   2: 0.018147215580549 

training_4077     6: 0.769248563947932   7: 0.062784233597912   8: 0.021007229951615   0: 0.021006712782345   9: 0.021000380174087   5: 0.020990944552999   1: 0.020990865045190   4: 0.020990500235026   2: 0.020990437548429   3: 0.020990132164466 

training_4078     6: 0.808698012232531   7: 0.068408237160638   0: 0.015385948010928   9: 0.015371809047124   5: 0.015371360271693   1: 0.015366137971237   4: 0.015353234282385   8: 0.015350133904992   3: 0.015347582214075   2: 0.015347544904397 

training_408      2: 0.533053942941238   6: 0.310022949624908   0: 0.019884780831649   5: 0.019635881701101   1: 0.019606729889542   4: 0.019595134740506   9: 0.019557054184330   7: 0.019550103150351   8: 0.019547116548728   3: 0.019546306387645 

training_4080     6: 0.821142245532954   0: 0.051689255805647   5: 0.015939599680407   1: 0.015894829879930   3: 0.015889606279113   9: 0.015889134964608   8: 0.015889118441571   7: 0.015888894180770   2: 0.015888713093365   4: 0.015888602141634 

training_4081     6: 0.522904696997609   1: 0.296420310542003   9: 0.074653847380045   3: 0.032382605847501   7: 0.018432659303452   0: 0.011052957954002   5: 0.011042526611273   4: 0.011040359487847   8: 0.011035967644897   2: 0.011034068231372 

training_4083     6: 0.603630461469294   7: 0.142862112664538   2: 0.102348309578179   8: 0.021596420133422   4: 0.021594393098790   0: 0.021594319976347   9: 0.021594264625964   5: 0.021593373140798   1: 0.021593291364016   3: 0.021593053948653 

training_4084     6: 0.764345783786312   7: 0.064068519024217   8: 0.021459409379659   0: 0.021458133112974   9: 0.021453324329145   5: 0.021444778147355   4: 0.021443098588334   1: 0.021442820157331   2: 0.021442314259937   3: 0.021441819214736 

training_4085     1: 0.426310742389250   0: 0.414329084993992   5: 0.019932733485272   6: 0.019926759012151   4: 0.019921637445220   9: 0.019918135303582   8: 0.019916356785384   7: 0.019915632045447   3: 0.019914794026731   2: 0.019914124512972 

training_4087     9: 0.394428486227580   5: 0.373966828441130   1: 0.028958714401980   6: 0.028958708443715   4: 0.028950344219093   8: 0.028949808889055   3: 0.028948448786957   0: 0.028947570359413   7: 0.028945803491921   2: 0.028945286739158 

training_4088     9: 0.837806598169761   6: 0.047101862433498   8: 0.014389539867608   1: 0.014389015754103   0: 0.014388626463465   5: 0.014385825327572   4: 0.014385031187072   7: 0.014384600361366   2: 0.014384555841387   3: 0.014384344594168 

training_4089     5: 0.715490835401066   3: 0.129243005834331   6: 0.019441925028469   1: 0.019439932996424   9: 0.019418527360623   8: 0.019400565156593   0: 0.019395391423344   4: 0.019392381301176   7: 0.019389824330861   2: 0.019387611167114 

training_409      5: 0.403803757877450   6: 0.388833535335306   8: 0.085808074974578   1: 0.017374281024962   0: 0.017364991912982   4: 0.017364262340797   9: 0.017363192732267   2: 0.017362751386424   7: 0.017362693761708   3: 0.017362458653525 

training_4090     9: 0.762822588083071   4: 0.089243103039545   6: 0.018495671074662   8: 0.018493171999503   0: 0.018492220539374   5: 0.018492064151492   1: 0.018491838910935   7: 0.018490050909444   2: 0.018489647047993   3: 0.018489644243981 

training_4091     6: 0.477815562741428   7: 0.292770731750936   3: 0.078662824293912   9: 0.021537235601994   5: 0.021536708734660   0: 0.021536060826779   1: 0.021535729348238   8: 0.021535524013078   2: 0.021534814082645   4: 0.021534808606329 

training_4092     5: 0.480024690879543   6: 0.366547322332351   9: 0.019186203355339   8: 0.019180811631889   1: 0.019179358928319   3: 0.019178028480212   0: 0.019176948109202   4: 0.019176748094844   7: 0.019175108711702   2: 0.019174779476598 

training_4093     6: 0.814916759868640   0: 0.107709400149914   5: 0.012001771484246   9: 0.009378815597800   1: 0.009369272371857   8: 0.009356646513979   2: 0.009350707155036   7: 0.009305685443798   4: 0.009305638676468   3: 0.009305302738261 

training_4094     5: 0.466887016791254   3: 0.203820239185066   4: 0.136663099509322   8: 0.069870945744697   6: 0.020464811874949   9: 0.020462991345166   0: 0.020459442398946   1: 0.020459233626519   7: 0.020456169451262   2: 0.020456050072819 

training_4096     6: 0.760910398709631   1: 0.065495702183761   9: 0.062724402885699   7: 0.015852431224371   0: 0.015841430479183   8: 0.015840379332541   3: 0.015835046042602   5: 0.015833533725690   2: 0.015833357077959   4: 0.015833318338563 

training_4097     6: 0.467401521087812   4: 0.266684992537015   0: 0.085161920517078   3: 0.083910193257638   9: 0.016149175710358   1: 0.016143812852099   5: 0.016142494787786   8: 0.016138935125534   2: 0.016133482098251   7: 0.016133472026429 

training_4098     6: 0.625678919144381   5: 0.170601836764981   1: 0.096764090171932   0: 0.030712192138608   9: 0.012729276217415   8: 0.012710820886683   3: 0.012701385159933   4: 0.012700727481314   2: 0.012700691987924   7: 0.012700060046829 

training_4099     6: 0.643609678073460   7: 0.173911145947904   2: 0.061232986216478   5: 0.017447362904303   0: 0.017367512140124   8: 0.017290030680590   1: 0.017286885296489   9: 0.017285024557154   4: 0.017284855030211   3: 0.017284519153287 

training_41       5: 0.811323807670234   4: 0.020969424991949   6: 0.020963789211346   0: 0.020963668873640   1: 0.020963522618174   8: 0.020963267975361   9: 0.020963174503694   3: 0.020963156008076   2: 0.020963114561038   7: 0.020963073586487 

training_410      5: 0.672591578339025   3: 0.134845028639946   2: 0.024076027006968   4: 0.024072313418117   6: 0.024070703320467   9: 0.024069418250354   0: 0.024069084916363   1: 0.024068964876771   7: 0.024068460330065   8: 0.024068420901925 

training_4100     5: 0.848182478876904   9: 0.016879407167679   8: 0.016872541510385   6: 0.016872389615110   1: 0.016871805843129   3: 0.016866368330392   0: 0.016865991873524   4: 0.016863526735188   7: 0.016862863162915   2: 0.016862626884773 

training_4101     6: 0.789163386658986   0: 0.064551808668566   3: 0.037295826460514   1: 0.031341898691454   9: 0.019244622491920   7: 0.011713273776959   4: 0.011678183036125   5: 0.011671740247173   8: 0.011670871405444   2: 0.011668388562860 

training_4103     6: 0.741739540985484   0: 0.066478247318753   7: 0.024046540357538   1: 0.023988860957345   5: 0.023970233766659   2: 0.023960889688988   9: 0.023955074277889   8: 0.023953768845017   4: 0.023953453651194   3: 0.023953390151133 

training_4105     1: 0.527005227637418   5: 0.215741374733740   6: 0.101366307369724   4: 0.022274086937410   8: 0.022270308937903   9: 0.022268657474943   0: 0.022268632457392   7: 0.022268598922533   3: 0.022268422698503   2: 0.022268382830434 

training_4106     1: 0.511735232861477   6: 0.290376720584385   9: 0.066747709325963   7: 0.041774277666434   2: 0.029889049881112   0: 0.011897567025611   5: 0.011895893486192   3: 0.011895717976010   4: 0.011894628559573   8: 0.011893202633243 

training_4107     1: 0.753936795542545   0: 0.085192147529923   6: 0.020130179037925   5: 0.020126884105850   9: 0.020109995677127   8: 0.020104760098005   3: 0.020100741154771   4: 0.020100294246092   7: 0.020099616560485   2: 0.020098586047277 

training_411      6: 0.487882797285091   8: 0.332486413545825   0: 0.075781258693369   9: 0.014840639824757   1: 0.014835791699962   5: 0.014835351032721   3: 0.014834519257855   4: 0.014834513969983   7: 0.014834390394746   2: 0.014834324295691 

training_4111     5: 0.508133046043422   0: 0.333673560156883   2: 0.053215772165851   6: 0.015006021803047   7: 0.014996795744067   1: 0.014996764251075   4: 0.014995502698239   9: 0.014994762304342   8: 0.014994738986387   3: 0.014993035846688 

training_4113     6: 0.484814786989620   0: 0.344611326413814   9: 0.070088204385672   5: 0.014370273521750   1: 0.014361426960591   3: 0.014353531669905   4: 0.014352901398040   8: 0.014350525864605   7: 0.014348788611515   2: 0.014348234184487 

training_4114     6: 0.727288478334538   5: 0.030309144919895   4: 0.030304029111542   9: 0.030301989712535   8: 0.030300374516316   0: 0.030299731708545   7: 0.030299425511853   1: 0.030299180232062   2: 0.030298933150725   3: 0.030298712801989 

training_4115     6: 0.796301696930211   5: 0.022636763809635   9: 0.022635774233192   4: 0.022633469032977   7: 0.022633381119453   8: 0.022632485500964   0: 0.022632079148396   1: 0.022631755971590   2: 0.022631385351945   3: 0.022631208901638 

training_4117     6: 0.524596650428211   1: 0.158019018766522   0: 0.155493631035333   7: 0.059408549227258   3: 0.017088781543022   5: 0.017079942525897   9: 0.017079095783397   8: 0.017078230793694   4: 0.017078149658524   2: 0.017077950238143 

training_4120     6: 0.686407422894041   4: 0.105470716529284   7: 0.093302635012808   5: 0.016407243255110   9: 0.016403574785075   0: 0.016402244658610   8: 0.016401962863249   1: 0.016401769998963   2: 0.016401350038151   3: 0.016401079964710 

training_4122     6: 0.735728117378845   0: 0.140253642194379   7: 0.015511095950420   5: 0.015507037569922   1: 0.015503791638878   9: 0.015500055517299   3: 0.015499225081398   8: 0.015499052900738   2: 0.015499005156825   4: 0.015498976611294 

training_4123     5: 0.714217655977955   3: 0.082401953233929   7: 0.070376902316078   6: 0.019008661503987   4: 0.019002224316322   1: 0.018999725510360   0: 0.018999231909786   8: 0.018998281477993   9: 0.018997839498122   2: 0.018997524255468 

training_4125     6: 0.510892373077494   9: 0.198207522335439   0: 0.191418021012265   1: 0.014214000854289   2: 0.014212485840427   5: 0.014212032760401   8: 0.014211234695814   7: 0.014211022590429   3: 0.014210879388556   4: 0.014210427444885 

training_4127     6: 0.431243655369935   1: 0.230793862097198   5: 0.148197789582940   0: 0.117243443100142   7: 0.024819476549861   8: 0.009566618483865   9: 0.009540994227582   3: 0.009531933175416   2: 0.009531186521783   4: 0.009531040891278 

training_4129     6: 0.757488597053772   4: 0.065473986698946   0: 0.059762926565536   7: 0.032590143613209   1: 0.021913411869167   3: 0.012675283406040   9: 0.012580907194474   2: 0.012514330330482   5: 0.012504250512254   8: 0.012496162756121 

training_4131     9: 0.764966843202730   4: 0.053357602299146   6: 0.051155085400571   8: 0.018649056740487   5: 0.018646928246124   3: 0.018646243954708   1: 0.018645428728341   0: 0.018645315809002   7: 0.018643878950029   2: 0.018643616668863 

training_4132     6: 0.753627537413033   1: 0.126646311606539   8: 0.024428298060788   4: 0.022642652865973   5: 0.012118016583606   0: 0.012110463985066   9: 0.012106889970082   3: 0.012106857818447   7: 0.012106496874165   2: 0.012106474822302 

training_4133     6: 0.644855184702085   5: 0.132889666770136   1: 0.109706104051885   8: 0.035603292396343   0: 0.012826297820118   9: 0.012824731724931   4: 0.012824203540608   7: 0.012823920876980   2: 0.012823322208702   3: 0.012823275908214 

training_4135     6: 0.280088757597114   9: 0.273241418806463   1: 0.273064187612968   0: 0.079406439836699   5: 0.015702160275566   4: 0.015700042394674   2: 0.015699958115469   8: 0.015699044333969   7: 0.015698997664510   3: 0.015698993362568 

training_4138     6: 0.439766003210569   7: 0.210736585490873   3: 0.126597378251261   2: 0.087581201548549   5: 0.045228783153044   0: 0.018018631607728   1: 0.018018165106285   8: 0.018018010242964   9: 0.018017730841354   4: 0.018017510547373 

training_4139     6: 0.817150551999190   2: 0.051323462347265   0: 0.016444359696475   1: 0.016441337280840   5: 0.016440368135461   8: 0.016440077485110   9: 0.016440057377609   7: 0.016440052974487   3: 0.016439947350744   4: 0.016439785352820 

training_4141     9: 0.437111012226516   5: 0.346229573621008   4: 0.027088773001359   3: 0.027081731018384   0: 0.027081656095604   8: 0.027081589981067   2: 0.027081507267319   6: 0.027081487506273   1: 0.027081347430020   7: 0.027081321852450 

training_4142     5: 0.690155400377133   0: 0.121421912957853   6: 0.023560511459241   4: 0.023556085685126   2: 0.023552308329201   1: 0.023552202092925   3: 0.023550760999143   8: 0.023550388057349   9: 0.023550340916079   7: 0.023550089125951 

training_4143     6: 0.572881661785874   5: 0.278402149876598   0: 0.032738512616339   3: 0.026457784048812   1: 0.023701531020248   8: 0.013383607501367   7: 0.013116601263516   9: 0.013107312375055   4: 0.013105877159067   2: 0.013104962353125 

training_4144     5: 0.673163467225801   2: 0.132518009350669   3: 0.024290484555679   4: 0.024289966157695   8: 0.024289947345084   6: 0.024289749074847   0: 0.024289674655134   7: 0.024289593312204   1: 0.024289579586334   9: 0.024289528736555 

training_4145     7: 0.317367042544678   5: 0.207534806454355   1: 0.203235670422801   4: 0.162272205254869   8: 0.018360127350974   6: 0.018271067536339   0: 0.018248461416473   9: 0.018239767769139   2: 0.018235853901522   3: 0.018234997348850 

training_4146     1: 0.635970338478464   6: 0.133400781759300   5: 0.091611810539825   8: 0.019891400868806   0: 0.019858089422576   7: 0.019855208326910   9: 0.019854137935740   4: 0.019853243145910   3: 0.019852729957219   2: 0.019852259565250 

training_4147     6: 0.816807949153305   0: 0.060520158025648   8: 0.025399482019367   9: 0.014235837992154   7: 0.013880594087601   1: 0.013833177124329   5: 0.013831697610343   3: 0.013831274969965   2: 0.013830060881043   4: 0.013829768136246 

training_4148     9: 0.623230323858963   1: 0.140633448564118   0: 0.029529730824634   6: 0.029517866047586   5: 0.029517274009984   4: 0.029514695170659   2: 0.029514380109127   7: 0.029514183663706   8: 0.029514124361985   3: 0.029513973389238 

training_4149     5: 0.646130411292715   6: 0.179183668065345   9: 0.021857061586536   3: 0.021846628781270   8: 0.021839824045197   0: 0.021831953771725   1: 0.021827976940306   2: 0.021827657632156   7: 0.021827522063844   4: 0.021827295820905 

training_4150     9: 0.733721232625931   5: 0.029596351724721   6: 0.029590861533861   4: 0.029588726625338   8: 0.029586582259306   0: 0.029586395114402   1: 0.029583775306026   7: 0.029582809249463   3: 0.029581660205653   2: 0.029581605355299 

training_4152     6: 0.624155139684650   0: 0.240313705617214   7: 0.025846887142747   9: 0.015675672885049   5: 0.015672296819593   4: 0.015668315984886   1: 0.015667394248652   2: 0.015667073636109   3: 0.015666877786130   8: 0.015666636194970 

training_4153     9: 0.451438369010540   0: 0.328697885201141   1: 0.059017108722015   7: 0.036251899363108   6: 0.020775860191942   5: 0.020766260435274   2: 0.020763744876281   4: 0.020763600931650   8: 0.020762792448784   3: 0.020762478819267 

training_4155     5: 0.708670669713172   4: 0.098202248286986   8: 0.063537128700402   0: 0.018588343182035   9: 0.018500752304097   1: 0.018500402955065   6: 0.018500254893218   7: 0.018500175559796   2: 0.018500028790599   3: 0.018499995614631 

training_4156     6: 0.693912995739509   0: 0.123486212217472   1: 0.093103344956203   7: 0.017437862231815   5: 0.016548391216105   3: 0.015862709157233   9: 0.009918449726717   8: 0.009913104041678   2: 0.009912339943783   4: 0.009904590769486 

training_4157     5: 0.671077310662358   0: 0.131076907325407   4: 0.024736886147769   8: 0.024730178713806   3: 0.024729905009053   2: 0.024729825590194   1: 0.024729789909058   9: 0.024729783462962   7: 0.024729723984200   6: 0.024729689195193 

training_4158     6: 0.379790719944590   0: 0.271330724950043   1: 0.238455372157856   7: 0.026115752166157   5: 0.025443733587285   4: 0.011773402772104   9: 0.011772632291556   8: 0.011772615837131   3: 0.011772523796330   2: 0.011772522496949 

training_4159     5: 0.683059738983632   4: 0.101393891181050   6: 0.074619085972554   9: 0.020143780245634   0: 0.020137641950994   1: 0.020132519042607   2: 0.020128729620054   8: 0.020128699770143   7: 0.020128041092637   3: 0.020127872140695 

training_416      6: 0.640380555313243   9: 0.210338143829095   1: 0.018663912408349   5: 0.018663552040640   8: 0.018660710283581   0: 0.018659661142782   7: 0.018658784153319   4: 0.018658366152456   2: 0.018658216046349   3: 0.018658098630186 

training_4160     1: 0.379030163118069   6: 0.273194932384503   2: 0.115763220848179   5: 0.098968346664782   0: 0.043080655354449   9: 0.026530561881936   4: 0.019230976803955   7: 0.018944431387612   3: 0.012681008487261   8: 0.012575703069253 

training_4161     5: 0.417332266692575   9: 0.415957667687817   1: 0.020845268712378   0: 0.020842532653447   6: 0.020840458385491   4: 0.020837961552582   2: 0.020836316488928   7: 0.020836101409059   8: 0.020835965133282   3: 0.020835461284441 

training_4162     9: 0.625524865911462   4: 0.171995631211330   6: 0.053893929000366   5: 0.037549121949469   7: 0.018508949446749   2: 0.018508089643527   8: 0.018506870063329   1: 0.018505755890203   0: 0.018505728831098   3: 0.018501058052467 

training_4164     4: 0.505429218818165   6: 0.248730496365588   0: 0.030736139144597   5: 0.030735987256036   1: 0.030735906569475   2: 0.030727570844034   8: 0.030727452195341   7: 0.030726446732487   9: 0.030725887646212   3: 0.030724894428065 

training_4165     6: 0.793594251908001   0: 0.106078936934552   1: 0.024457684986178   7: 0.024256322054959   5: 0.008603828036955   8: 0.008603290068810   4: 0.008603268617626   9: 0.008601116411691   3: 0.008600748064005   2: 0.008600552917224 

training_4167     6: 0.441749151588443   4: 0.221249313437347   2: 0.174284832136785   5: 0.048433388881994   8: 0.019079044991883   1: 0.019047989209724   0: 0.019043709030933   7: 0.019037772673204   9: 0.019037715669570   3: 0.019037082380118 

training_4169     4: 0.704154442345002   9: 0.084343483695872   1: 0.069305268178198   0: 0.020334295330059   6: 0.020316130967224   5: 0.020314785419574   8: 0.020310669225337   7: 0.020307743863668   3: 0.020307511997005   2: 0.020305668978060 

training_417      9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_4170     6: 0.729952134453934   0: 0.076989263055609   9: 0.062248600372544   1: 0.035002028903090   8: 0.016012566165551   5: 0.015961160253676   4: 0.015958800496779   7: 0.015958771336312   2: 0.015958378011170   3: 0.015958296951334 

training_4171     6: 0.599452112097576   9: 0.146328851792899   7: 0.116595511895263   0: 0.038318500535066   8: 0.016560223695218   2: 0.016559426529707   1: 0.016552547501035   5: 0.016545257178864   3: 0.016544009665810   4: 0.016543559108562 

training_4172     6: 0.736362618867896   5: 0.108062362650569   0: 0.035359358921104   9: 0.017183461533000   1: 0.017176852510820   8: 0.017173390114018   2: 0.017170706722015   4: 0.017170561375245   3: 0.017170481514718   7: 0.017170205790614 

training_4173     6: 0.681858397344153   9: 0.066860252197160   5: 0.059251878282140   4: 0.054237892693260   7: 0.048111855869502   3: 0.032619289576492   1: 0.014341024362363   0: 0.014244299009196   8: 0.014237817641645   2: 0.014237293024090 

training_4174     6: 0.800003625484380   1: 0.102046361702845   5: 0.017293288949831   0: 0.016040036379569   9: 0.010959513897087   7: 0.010958934464989   8: 0.010696760595660   2: 0.010690348330560   3: 0.010656252470171   4: 0.010654877724909 

training_4175     5: 0.788838016598883   8: 0.023488163238014   1: 0.023481004711973   6: 0.023467259819111   0: 0.023460882131416   9: 0.023453238947218   2: 0.023453014277279   7: 0.023452861037254   4: 0.023452837911572   3: 0.023452721327279 

training_4176     8: 0.439893868959838   5: 0.321942531040664   4: 0.029778377720276   9: 0.029769722690007   3: 0.029769511481196   0: 0.029769430887705   2: 0.029769361101457   1: 0.029769170644438   7: 0.029769071697434   6: 0.029768953776983 

training_4177     5: 0.510344973371156   2: 0.278370344977569   6: 0.026412459282573   3: 0.026411892552374   4: 0.026410595815666   7: 0.026410079232463   1: 0.026410047669378   0: 0.026409962246837   8: 0.026409848138146   9: 0.026409796713838 

training_4178     0: 0.488057193002923   2: 0.335982223200798   5: 0.022017672248728   1: 0.021998243638171   6: 0.021994940865936   3: 0.021991234735993   9: 0.021989929921901   8: 0.021989720222865   4: 0.021989538501970   7: 0.021989303660714 

training_418      6: 0.405589318470191   9: 0.208344484248168   5: 0.201588205232557   1: 0.026368921083876   0: 0.026362132322085   4: 0.026349966465228   8: 0.026349662897104   2: 0.026349399260281   7: 0.026349368063305   3: 0.026348541957205 

training_4182     1: 0.526334556296077   4: 0.328755729932302   8: 0.034718803375679   0: 0.015811287375159   3: 0.015790207506158   6: 0.015723330904434   5: 0.015719407798022   9: 0.015716117273940   7: 0.015715387458704   2: 0.015715172079525 

training_4184     5: 0.774996295812473   4: 0.025003083221465   6: 0.025001698907471   0: 0.025000750337575   8: 0.025000563128020   1: 0.024999918903380   9: 0.024999578059304   7: 0.024999448385938   3: 0.024999408760628   2: 0.024999254483746 

training_4185     0: 0.527675754274905   5: 0.208820969701076   4: 0.032952015809814   2: 0.032936420831352   3: 0.032936372412398   8: 0.032936368667057   1: 0.032935943332138   7: 0.032935615064161   9: 0.032935388601875   6: 0.032935151305224 

training_4188     9: 0.827090709144526   8: 0.019237507852919   1: 0.019214773944272   6: 0.019214618661828   0: 0.019208335371018   5: 0.019208052864691   7: 0.019206730808378   4: 0.019206611550105   3: 0.019206362319924   2: 0.019206297482338 

training_4189     5: 0.658454118943080   0: 0.148449565949267   4: 0.024139418688895   1: 0.024137549051541   8: 0.024136972472640   9: 0.024136920079785   6: 0.024136525582938   3: 0.024136416478714   2: 0.024136315819860   7: 0.024136196933280 

training_4192     6: 0.681533503137906   5: 0.174146687860515   0: 0.018041383649601   4: 0.018041131613554   1: 0.018040673382181   9: 0.018040549328157   7: 0.018039293486421   8: 0.018039037464943   2: 0.018038950419792   3: 0.018038789656930 

training_4193     3: 0.498644100083910   5: 0.287621244354131   4: 0.026717870401014   8: 0.026716859641207   6: 0.026716850725247   0: 0.026716823273271   2: 0.026716619734821   1: 0.026716609715681   7: 0.026716541356468   9: 0.026716480714249 

training_4194     5: 0.765877564890849   4: 0.026017045019325   8: 0.026013342721504   3: 0.026013256567285   9: 0.026013207402134   2: 0.026013186605018   6: 0.026013138874046   7: 0.026013132459133   0: 0.026013083356100   1: 0.026013042104607 

training_4199     6: 0.426473445576533   0: 0.227249765398884   1: 0.175508491975047   3: 0.052864808599887   8: 0.040659373228103   5: 0.015452046013565   4: 0.015449400699326   9: 0.015447841182137   2: 0.015447469376375   7: 0.015447357950144 

training_42       6: 0.693619251826907   1: 0.121918255049412   7: 0.048595451736535   0: 0.039260577156072   8: 0.016109403038895   5: 0.016107423947841   9: 0.016098555399045   2: 0.016097337575374   4: 0.016096919630017   3: 0.016096824639900 

training_420      5: 0.740331457124799   3: 0.129332243343481   4: 0.016293498233835   0: 0.016293153301996   6: 0.016292933819231   1: 0.016292405647299   9: 0.016291443685373   2: 0.016291021601584   8: 0.016290925169036   7: 0.016290918073365 

training_4201     4: 0.346925569898745   6: 0.286228880145385   1: 0.155735489348303   8: 0.082695229929484   2: 0.056936958528368   3: 0.014355914900954   5: 0.014294006838427   9: 0.014279850680401   0: 0.014276169591805   7: 0.014271930138128 

training_4203     7: 0.535455070013703   6: 0.266437466720295   2: 0.080433195865860   0: 0.016936735663563   1: 0.016796037566006   5: 0.016789311304816   9: 0.016789220059446   8: 0.016789133360508   3: 0.016788193041557   4: 0.016785636404247 

training_4204     1: 0.822613528576653   0: 0.024179958099368   9: 0.020334252864491   5: 0.019158746850067   6: 0.019110364467612   7: 0.018975858379894   4: 0.018911487120942   2: 0.018905468485097   8: 0.018905231035308   3: 0.018905104120568 

training_4205     5: 0.763792671941394   0: 0.105954995723886   6: 0.016282894077008   4: 0.016282779759486   8: 0.016281702861007   9: 0.016281544642572   1: 0.016281462218396   7: 0.016280766824881   2: 0.016280686898237   3: 0.016280495053133 

training_4206     0: 0.795046141213988   6: 0.022779381578555   8: 0.022772714512421   5: 0.022772714042629   1: 0.022772441147007   9: 0.022771929390113   7: 0.022771603892184   4: 0.022771252058614   2: 0.022771102547601   3: 0.022770719616888 

training_4209     6: 0.714695733766311   3: 0.119831698742061   9: 0.034022959234902   7: 0.018791726745723   1: 0.018780908432965   0: 0.018778296192990   5: 0.018777670039649   2: 0.018775508399368   4: 0.018772981007299   8: 0.018772517438731 

training_4210     5: 0.775517313584487   3: 0.024942922812809   2: 0.024942813462102   4: 0.024942573466586   6: 0.024942541809066   1: 0.024942486992757   0: 0.024942424317442   7: 0.024942344362564   9: 0.024942322777972   8: 0.024942256414214 

training_4212     0: 0.691324461443025   6: 0.159378009530839   9: 0.047404603245510   3: 0.014567267692649   5: 0.014562730616428   2: 0.014556703587851   4: 0.014553081886764   1: 0.014552073742549   8: 0.014551499305970   7: 0.014549568948414 

training_4215     6: 0.700610979877047   1: 0.115380435037155   9: 0.045881267174911   8: 0.043926506886942   3: 0.015777357815380   5: 0.015692277468104   0: 0.015686666190553   7: 0.015682382574504   4: 0.015681171874403   2: 0.015680955101001 

training_4216     5: 0.770810927552715   4: 0.079616724414696   9: 0.018700557019568   6: 0.018697257019284   1: 0.018696240170317   0: 0.018696074292117   8: 0.018695668634360   3: 0.018695533321689   2: 0.018695513023652   7: 0.018695504551602 

training_4218     5: 0.608732114997705   8: 0.189776110619964   0: 0.077822075497716   6: 0.017672084013878   9: 0.017668417083619   3: 0.017667022731490   4: 0.017666352526695   1: 0.017665682927420   7: 0.017665082359951   2: 0.017665057241560 

training_4219     4: 0.791796360154318   5: 0.023139219584011   6: 0.023133247827478   0: 0.023133212657568   8: 0.023133125308435   9: 0.023133043763619   1: 0.023132963387082   2: 0.023132946787297   3: 0.023132940550029   7: 0.023132939980162 

training_422      5: 0.858262200719073   6: 0.015752037040101   4: 0.015749781963302   0: 0.015748699450365   8: 0.015748368785092   9: 0.015748349536370   1: 0.015748119717709   7: 0.015747642414781   2: 0.015747421936861   3: 0.015747378436345 

training_4220     5: 0.631786410651492   7: 0.129168434946070   4: 0.086418547665605   3: 0.021837118978812   0: 0.021810108965297   6: 0.021803797167027   1: 0.021795092969378   9: 0.021795045139609   8: 0.021792746088791   2: 0.021792697427919 

training_4223     0: 0.728778707223913   6: 0.098944096026435   9: 0.068291726751004   5: 0.020639245653929   1: 0.013942364281725   4: 0.013908882634617   7: 0.013878523904359   8: 0.013875046115791   2: 0.013874794672594   3: 0.013866612735632 

training_4227     7: 0.622547247730008   5: 0.123443835107739   1: 0.073015857048143   9: 0.068205899746852   6: 0.018863487812784   0: 0.018809332534733   4: 0.018781831488933   2: 0.018778838597586   3: 0.018777120024849   8: 0.018776549908374 

training_4228     5: 0.702723921963244   4: 0.111989088938862   3: 0.023161341754031   6: 0.023161066946875   0: 0.023160966604238   1: 0.023160924175120   8: 0.023160805383930   2: 0.023160651420556   7: 0.023160644054604   9: 0.023160588758540 

training_4229     4: 0.324595490311456   6: 0.293927927591080   0: 0.210982257480868   1: 0.049177616522226   8: 0.031050832055649   7: 0.018087390061937   5: 0.018052701017475   2: 0.018042544669865   9: 0.018041740641575   3: 0.018041499647871 

training_423      5: 0.497275387871681   9: 0.234642473216126   8: 0.111573300151614   0: 0.022364836135801   3: 0.022358284172632   4: 0.022357909450565   7: 0.022357003954117   6: 0.022356972762752   1: 0.022356924281228   2: 0.022356908003484 

training_4231     0: 0.409023021896495   6: 0.337176358973507   4: 0.080280518591831   2: 0.068549693962416   5: 0.033314515132601   1: 0.014443354345372   7: 0.014305333421415   8: 0.014302946352289   9: 0.014302533410216   3: 0.014301723913859 

training_4232     6: 0.507510798298859   2: 0.342594703338509   1: 0.045260343392463   9: 0.019514456393571   8: 0.014631072075136   0: 0.014115516370481   5: 0.014102809617230   4: 0.014090921734933   7: 0.014089796563695   3: 0.014089582215122 

training_4233     1: 0.405556696942920   6: 0.289264166057034   0: 0.147524158726045   4: 0.049542699519573   7: 0.043231370480224   5: 0.012978183575355   3: 0.012977419202101   8: 0.012975448365751   9: 0.012975418354094   2: 0.012974438776903 

training_4235     0: 0.434079572704313   5: 0.320318062798473   7: 0.111636355851823   6: 0.019143806679481   1: 0.019139676829850   4: 0.019137339150210   2: 0.019136691285850   9: 0.019136410407917   3: 0.019136082219567   8: 0.019136002072517 

training_4237     0: 0.407455609903296   6: 0.329707775268739   3: 0.117617931094390   9: 0.020766810574028   1: 0.020755104233275   4: 0.020745733487922   5: 0.020741546754439   7: 0.020737503551171   8: 0.020736049733176   2: 0.020735935399564 

training_4238     6: 0.612505656884559   7: 0.155548671458029   3: 0.081224853546659   5: 0.021532705107290   8: 0.021532475128157   9: 0.021532024846301   0: 0.021532010899072   1: 0.021530744691527   2: 0.021530437022440   4: 0.021530420415966 

training_4239     4: 0.775180279724160   9: 0.072160950115129   5: 0.019089966672686   6: 0.019083913720380   0: 0.019082330227006   1: 0.019081183134174   3: 0.019080558769112   8: 0.019080389003719   7: 0.019080380104752   2: 0.019080048528881 

training_424      1: 0.729394976717992   6: 0.054934155150588   0: 0.052870936721512   9: 0.046743342130620   5: 0.019356031824726   3: 0.019345416640729   2: 0.019342191171682   8: 0.019340873360363   4: 0.019337036665651   7: 0.019335039616137 

training_4240     5: 0.766035449621636   3: 0.026006543475841   4: 0.025995107752478   8: 0.025994771970433   0: 0.025994766917442   6: 0.025994764031332   2: 0.025994668407883   1: 0.025994664518053   7: 0.025994650001548   9: 0.025994613303354 

training_4241     5: 0.643946603231185   7: 0.161652042914604   2: 0.024300539640587   3: 0.024300427431872   4: 0.024300378309753   6: 0.024300173148739   1: 0.024300100512140   0: 0.024300071101389   9: 0.024299878034531   8: 0.024299785675199 

training_4245     3: 0.320220794909541   4: 0.259496015150043   5: 0.250238795456324   6: 0.024292358905352   8: 0.024292261697130   0: 0.024292261006868   7: 0.024291942891243   2: 0.024291908556379   1: 0.024291890995488   9: 0.024291770431632 

training_4246     6: 0.725522251065388   1: 0.121867703187415   0: 0.049285717685060   9: 0.027500311411302   7: 0.019078414272606   2: 0.011447289575494   5: 0.011325018559402   8: 0.011324568848691   4: 0.011324405222300   3: 0.011324320172342 

training_4249     1: 0.486678751790274   2: 0.349693754611022   6: 0.020477389403848   5: 0.020477202566118   0: 0.020470018764060   4: 0.020446954898039   7: 0.020441276814411   9: 0.020438983410561   3: 0.020438057478468   8: 0.020437610263199 

training_425      6: 0.754141261828541   7: 0.103731030784425   5: 0.017767705732478   0: 0.017767261365575   1: 0.017766938414548   9: 0.017765545544426   8: 0.017765238561675   2: 0.017765166574076   3: 0.017764948988423   4: 0.017764902205832 

training_4253     5: 0.615102196579655   3: 0.199695657672681   8: 0.023151236131475   1: 0.023150772811388   0: 0.023150472005308   4: 0.023150466204805   6: 0.023150109117525   2: 0.023149927249972   9: 0.023149595608831   7: 0.023149566618360 

training_4255     6: 0.548652340213209   0: 0.317044373217265   5: 0.016789985334500   9: 0.016789303778914   1: 0.016788498772864   4: 0.016787558864077   7: 0.016787273630854   8: 0.016786980378534   3: 0.016786893576316   2: 0.016786792233466 

training_4257     4: 0.754245097734236   5: 0.027310683365754   8: 0.027306031177967   6: 0.027305608963789   9: 0.027305578897210   7: 0.027305494148540   3: 0.027305411447717   2: 0.027305391764825   0: 0.027305360781478   1: 0.027305341718485 

training_4258     5: 0.764537101760513   4: 0.026168183330461   2: 0.026165256946530   8: 0.026161898861525   9: 0.026161597360737   1: 0.026161557649703   0: 0.026161290521104   6: 0.026161177525371   3: 0.026161060576219   7: 0.026160875467838 

training_4259     6: 0.768188248077443   0: 0.060953824011643   1: 0.060555715779141   3: 0.030229856783682   9: 0.013361044731041   2: 0.013359420436285   5: 0.013348586443110   4: 0.013335527402971   8: 0.013334455376699   7: 0.013333320957984 

training_4261     4: 0.796293429742373   5: 0.022644168148949   6: 0.022635488533832   1: 0.022635205135366   0: 0.022634393314879   8: 0.022632026154983   9: 0.022631876486134   7: 0.022631275143282   3: 0.022631138323681   2: 0.022630999016522 

training_4266     6: 0.461288714246027   1: 0.347584268091847   5: 0.080516347190164   2: 0.027388090438213   0: 0.026412368027486   8: 0.016636126482132   9: 0.010059734763368   4: 0.010044741119835   3: 0.010035147062038   7: 0.010034462578890 

training_4267     6: 0.838218845480227   1: 0.061963260460841   7: 0.024438820087227   8: 0.014554313291693   0: 0.010153862684904   2: 0.010145967702455   9: 0.010135353134025   5: 0.010134858043099   4: 0.010127451523545   3: 0.010127267591983 

training_4273     4: 0.761526059691387   5: 0.026501989736386   8: 0.026497100319018   3: 0.026496794586773   9: 0.026496464430433   2: 0.026496457217459   7: 0.026496334127294   0: 0.026496314112781   1: 0.026496269570816   6: 0.026496216207652 

training_4275     8: 0.625659125414189   6: 0.155882899430517   0: 0.061724379014311   3: 0.053816017285477   7: 0.017155330725028   9: 0.017153915456311   1: 0.017152885436941   5: 0.017152119984466   2: 0.017151735656698   4: 0.017151591596064 

training_4276     5: 0.622789220142144   6: 0.166100133491424   1: 0.026391662874750   4: 0.026391551024283   0: 0.026390471753844   2: 0.026387572880919   3: 0.026387397532995   8: 0.026387375417972   9: 0.026387374097950   7: 0.026387240783719 

training_4277     1: 0.764970345986420   0: 0.041675316288252   2: 0.035258289295258   9: 0.032801546388190   8: 0.020919861396309   3: 0.020899612138841   6: 0.020877126563313   5: 0.020873230660192   4: 0.020863138475213   7: 0.020861532808013 

training_4278     6: 0.782919807589823   1: 0.024120489325908   7: 0.024120302308441   0: 0.024120289322503   8: 0.024120072376311   9: 0.024119834115151   5: 0.024119823888779   2: 0.024119810912866   4: 0.024119785387696   3: 0.024119784772523 

training_4279     0: 0.463117902515682   4: 0.288912568442410   5: 0.031007947209692   7: 0.030995508030201   8: 0.030994825563921   2: 0.030994633351415   1: 0.030994521882811   3: 0.030994200064902   6: 0.030993958516726   9: 0.030993934422239 

training_4280     6: 0.768023704604907   1: 0.025775856515990   7: 0.025775325344235   0: 0.025775075341002   8: 0.025775074214787   9: 0.025775025167607   5: 0.025775000043542   2: 0.025774984457048   4: 0.025774977828793   3: 0.025774976482088 

training_4281     6: 0.448110464439601   2: 0.354510881763111   5: 0.024678997905695   9: 0.024677019524920   0: 0.024671618194480   4: 0.024671095042464   7: 0.024670797772361   1: 0.024670212750585   8: 0.024669522215173   3: 0.024669390391611 

training_4282     7: 0.493331965309873   1: 0.255480293350482   0: 0.031404122822001   2: 0.031403042885591   5: 0.031402727214579   6: 0.031397766012084   4: 0.031396739198697   9: 0.031395931464724   8: 0.031393947655879   3: 0.031393464086090 

training_4284     4: 0.529997976772795   0: 0.239846720628743   1: 0.028772679640119   8: 0.028772536775210   5: 0.028772365890910   6: 0.028770656478787   7: 0.028769742779722   9: 0.028766297448385   2: 0.028765773082229   3: 0.028765250503098 

training_4285     5: 0.494846301179054   3: 0.316944887954827   4: 0.023526686004692   0: 0.023526319604945   6: 0.023526057569197   7: 0.023526011007573   1: 0.023525999529283   2: 0.023525964592585   8: 0.023525913088593   9: 0.023525859469250 

training_4286     1: 0.389717448709558   9: 0.330297204751624   5: 0.153404399200301   2: 0.018121700407853   6: 0.018084776225826   0: 0.018076714487669   8: 0.018075606666709   4: 0.018075459090600   7: 0.018073351398905   3: 0.018073339060955 

training_4288     4: 0.756546859581228   5: 0.027055989649878   6: 0.027050068917841   1: 0.027049918572746   0: 0.027049684430762   3: 0.027049615200661   8: 0.027049592479362   9: 0.027049534935036   2: 0.027049394720297   7: 0.027049341512191 

training_4289     6: 0.780907027099251   1: 0.082918419053196   0: 0.044540312086465   2: 0.019609312425741   5: 0.012005962622262   9: 0.012005589963089   7: 0.012005168865585   8: 0.012003404077159   3: 0.012002779496255   4: 0.012002024310999 

training_4290     0: 0.471516491463409   6: 0.421273972400743   8: 0.027798088041655   1: 0.026429183038300   3: 0.008947027201822   9: 0.008808866076060   5: 0.008807528928459   7: 0.008806865047633   4: 0.008806566733717   2: 0.008805411068202 

training_4291     0: 0.500768538024684   7: 0.196030119711138   5: 0.174012255448934   6: 0.018509459676797   4: 0.018449762032440   9: 0.018447144349272   8: 0.018446712201780   1: 0.018446534241976   3: 0.018445650581215   2: 0.018443823731765 

training_4292     5: 0.815485390672819   4: 0.020507163117784   6: 0.020501739765595   0: 0.020501289482384   1: 0.020500858745938   3: 0.020500762390818   8: 0.020500753345195   9: 0.020500721055855   7: 0.020500694051620   2: 0.020500627371992 

training_4293     8: 0.750805168926477   5: 0.027695899780122   6: 0.027689414554354   0: 0.027688350852850   4: 0.027687361785016   1: 0.027687085579039   9: 0.027686965446952   3: 0.027686869007791   2: 0.027686524148531   7: 0.027686359918866 

training_4296     6: 0.798647794879589   8: 0.057461128600352   0: 0.018010410211871   1: 0.017991496991116   5: 0.017987132282997   7: 0.017980557133336   4: 0.017980556653043   9: 0.017980475892356   2: 0.017980256151882   3: 0.017980191203457 

training_4297     6: 0.764025478963211   0: 0.151836662133298   5: 0.010517867149428   9: 0.010517440349297   8: 0.010517388453127   1: 0.010517374650451   7: 0.010517238601621   3: 0.010516923978635   4: 0.010516920831510   2: 0.010516704889423 

training_4298     8: 0.730561576237309   0: 0.125760467174346   2: 0.017992645568487   6: 0.017957319138726   1: 0.017957294987581   5: 0.017955511692924   9: 0.017954186978952   7: 0.017954150937835   4: 0.017953533637500   3: 0.017953313646340 

training_4301     4: 0.492884487367056   0: 0.319391556427579   5: 0.051175669213637   1: 0.019520673319945   6: 0.019511731065805   7: 0.019504828520570   8: 0.019503688736676   9: 0.019502864094827   2: 0.019502591596393   3: 0.019501909657512 

training_4302     5: 0.450153925463718   6: 0.308407977246460   4: 0.030185691131534   8: 0.030179771401721   1: 0.030179325765861   0: 0.030179053853686   9: 0.030178775873568   2: 0.030178670845982   7: 0.030178443302068   3: 0.030178365115402 

training_4303     7: 0.340822113228016   0: 0.294851201062401   6: 0.233171293049910   5: 0.041393361861875   1: 0.018923551211572   9: 0.014536342347122   2: 0.014101615299884   4: 0.014068587214169   8: 0.014067009534271   3: 0.014064925190781 

training_4304     5: 0.671843084876377   0: 0.104244636604512   8: 0.080991806817963   2: 0.044332573218489   4: 0.016433392513868   6: 0.016431668813998   7: 0.016431402708103   1: 0.016430711109149   9: 0.016430503677642   3: 0.016430219659900 

training_4305     7: 0.454396701604410   6: 0.323312623893377   8: 0.064534704208155   2: 0.048891340059585   5: 0.018157857993846   1: 0.018142067631134   0: 0.018141637549720   9: 0.018141247954388   4: 0.018141246784263   3: 0.018140572321122 

training_4306     6: 0.516317704078210   7: 0.310938117954377   5: 0.021595041775385   0: 0.021593133391466   1: 0.021593056375227   8: 0.021593008267093   9: 0.021592993112470   4: 0.021592627161729   2: 0.021592243380606   3: 0.021592074503437 

training_4307     4: 0.803679180332374   5: 0.021819691707966   1: 0.021813462565707   0: 0.021813196470554   2: 0.021812778107424   6: 0.021812620165234   9: 0.021812391364089   3: 0.021812340438625   8: 0.021812269344747   7: 0.021812069503279 

training_4310     5: 0.473580350554429   0: 0.369599646931495   2: 0.040179945808359   6: 0.016679194985352   1: 0.016663313921318   8: 0.016660981883368   7: 0.016659866842192   9: 0.016659217967695   4: 0.016658959476219   3: 0.016658521629573 

training_4313     5: 0.745972120858775   8: 0.109244051850240   3: 0.018100196355678   4: 0.018098848149421   0: 0.018097986791803   1: 0.018097663338451   6: 0.018097522207456   2: 0.018097267418721   9: 0.018097178588923   7: 0.018097164440532 

training_4314     6: 0.660044675494006   5: 0.172991866082606   1: 0.055695109237669   0: 0.028941012393785   9: 0.013722157890995   2: 0.013721255483476   4: 0.013721068732204   8: 0.013720991186075   7: 0.013720936552989   3: 0.013720926946194 

training_4315     6: 0.484925588378207   2: 0.315152997872693   7: 0.105112884241886   3: 0.020725572789498   1: 0.012383761886525   0: 0.012376625406256   5: 0.012332375278688   9: 0.012331502283001   4: 0.012329533299442   8: 0.012329158563804 

training_4318     5: 0.680042967283943   0: 0.186426527193245   6: 0.016693497939611   1: 0.016692177090015   4: 0.016691532602348   7: 0.016691431538425   9: 0.016690770245676   2: 0.016690436070928   3: 0.016690333881267   8: 0.016690326154543 

training_4323     9: 0.316069091684902   1: 0.302950122870187   0: 0.248971196735752   6: 0.018863507742683   5: 0.018859198907014   8: 0.018857585371223   4: 0.018857579777216   7: 0.018857566807074   2: 0.018857113481855   3: 0.018857036622093 

training_4327     5: 0.803783885974116   8: 0.021803432015723   6: 0.021802736705914   7: 0.021802346450611   4: 0.021802071223376   0: 0.021801601671277   1: 0.021801380009673   9: 0.021800999909974   3: 0.021800773552756   2: 0.021800772486579 

training_4328     7: 0.338649608614831   6: 0.243016355522946   0: 0.111184641095313   5: 0.103197340688953   9: 0.069316657942600   8: 0.044771264757513   1: 0.042583030630851   2: 0.015761825298012   3: 0.015759828962607   4: 0.015759446486373 

training_4330     5: 0.602104565584419   3: 0.233926321973177   6: 0.020515018060319   1: 0.020498829326648   0: 0.020494188337370   4: 0.020493878085943   7: 0.020492421054291   9: 0.020492201000937   8: 0.020491577932249   2: 0.020490998644647 

training_4331     5: 0.538002265978953   7: 0.274450176203014   3: 0.023444955938598   4: 0.023443691066502   6: 0.023443402514936   1: 0.023443367296258   0: 0.023443290105204   2: 0.023443094268694   8: 0.023442931339356   9: 0.023442825288485 

training_4333     2: 0.317657065826492   1: 0.308865400367778   6: 0.251868581259362   5: 0.017385508004508   7: 0.017374812850366   0: 0.017373539696477   4: 0.017370652363888   9: 0.017369921471142   8: 0.017367836974217   3: 0.017366681185770 

training_4337     5: 0.810004420882218   4: 0.021116191481562   6: 0.021112802416165   9: 0.021110693177532   2: 0.021110093588484   1: 0.021109747602412   0: 0.021109360964872   7: 0.021109028023270   8: 0.021108920426588   3: 0.021108741436897 

training_4338     6: 0.559747185673606   5: 0.255833667422438   0: 0.071601983008619   1: 0.016123110135265   7: 0.016117829466454   4: 0.016116867639081   9: 0.016115036712384   8: 0.016114999105028   2: 0.016114677162157   3: 0.016114643674968 

training_4339     3: 0.555586535340232   1: 0.250017993303576   0: 0.024310398278916   6: 0.024304804611566   5: 0.024300746356868   4: 0.024298264013823   7: 0.024296271751037   9: 0.024296077378667   8: 0.024294571791986   2: 0.024294337173329 

training_4340     6: 0.623908463636695   9: 0.205319522180295   0: 0.055411151922416   1: 0.040106547747579   3: 0.017671347125121   8: 0.011575010922727   7: 0.011517429276202   5: 0.011497410571577   4: 0.011497189509267   2: 0.011495927108122 

training_4341     5: 0.775924440639040   4: 0.024901836318638   6: 0.024900150384781   7: 0.024896709434469   9: 0.024896624155607   0: 0.024896229932176   8: 0.024896160599978   3: 0.024895987821950   1: 0.024895971767168   2: 0.024895888946194 

training_4343     1: 0.830350328410724   0: 0.038485452681766   5: 0.016451310396225   6: 0.016390961462114   9: 0.016387669963705   8: 0.016387188474596   7: 0.016386922908143   4: 0.016386793198223   2: 0.016386771280396   3: 0.016386601224107 

training_4344     5: 0.789417964789861   4: 0.023398447520045   6: 0.023398373954894   3: 0.023398179129367   0: 0.023398107048985   1: 0.023398034627230   8: 0.023397763071759   9: 0.023397738422823   2: 0.023397709450810   7: 0.023397681984226 

training_4345     6: 0.599147293439206   5: 0.129362012311180   1: 0.125790281032070   9: 0.040460978864049   3: 0.017544017167564   8: 0.017540083798352   7: 0.017539646355910   2: 0.017539374032768   0: 0.017538894451011   4: 0.017537418547890 

training_4346     4: 0.766712545800085   2: 0.054802812744264   1: 0.050852448328129   5: 0.018239868644252   8: 0.018235608565957   0: 0.018231851250301   6: 0.018231767689102   3: 0.018231101641148   9: 0.018231023475522   7: 0.018230971861241 

training_4347     1: 0.636816940041143   0: 0.202480314161379   8: 0.056901043629115   5: 0.014834066872273   3: 0.014832006523870   4: 0.014830247038506   6: 0.014829732878937   9: 0.014829409905968   7: 0.014823302467748   2: 0.014822936481061 

training_4349     6: 0.799587493228628   0: 0.048289014437004   2: 0.019017673568555   5: 0.019016877932246   1: 0.019016310376638   8: 0.019015143934460   3: 0.019014911115094   7: 0.019014529468038   4: 0.019014087716348   9: 0.019013958222988 

training_435      5: 0.395237277403378   3: 0.320987068925623   0: 0.167169948694884   9: 0.043842838016745   6: 0.012132197712244   1: 0.012129216709482   8: 0.012126796029035   4: 0.012125324097583   2: 0.012124717501839   7: 0.012124614909186 

training_4351     5: 0.556437454250244   4: 0.174333231725466   6: 0.108937937690146   0: 0.022899195662770   1: 0.022899143317542   9: 0.022898678441455   8: 0.022898662054103   3: 0.022898660262340   2: 0.022898561595470   7: 0.022898475000465 

training_4353     5: 0.725175245917837   7: 0.078624586560915   4: 0.061653828054459   2: 0.019275294843392   1: 0.019249960631015   0: 0.019218697643141   6: 0.019204802359052   9: 0.019200339963772   8: 0.019198689815009   3: 0.019198554211407 

training_4356     6: 0.639965748529818   5: 0.102067891893555   0: 0.068892178842803   1: 0.057044385324047   8: 0.056671730915239   3: 0.015075677585571   7: 0.015070766621988   9: 0.015070638596319   4: 0.015070494136343   2: 0.015070487554315 

training_4357     5: 0.554041952832511   9: 0.149529974889337   1: 0.133872443041118   4: 0.023228332194469   3: 0.023221608043591   6: 0.023221333440530   0: 0.023221179047337   8: 0.023221172872457   2: 0.023221065646520   7: 0.023220937992129 

training_4358     4: 0.669563809414907   6: 0.138959559889619   5: 0.023942288942068   8: 0.023934118637921   0: 0.023933874873730   9: 0.023933540180282   3: 0.023933283112034   2: 0.023933213838422   1: 0.023933186777234   7: 0.023933124333783 

training_436      0: 0.607777180826581   6: 0.270140673292976   3: 0.015264641239060   1: 0.015262269922655   5: 0.015261252198669   4: 0.015260974240802   8: 0.015259604661276   2: 0.015258168577228   9: 0.015257740948831   7: 0.015257494091920 

training_4360     3: 0.450876736875545   6: 0.326199220727175   8: 0.084365924049307   7: 0.019825942168863   1: 0.019806151744337   5: 0.019803009954455   0: 0.019797537821846   4: 0.019787391726129   2: 0.019771851759913   9: 0.019766233172430 

training_4361     5: 0.775527930306762   4: 0.024948353785079   8: 0.024940643084172   0: 0.024940552765948   3: 0.024940503263034   2: 0.024940473807679   7: 0.024940436659349   1: 0.024940423661353   9: 0.024940398850804   6: 0.024940283815820 

training_4363     5: 0.774321138064351   6: 0.079543882123448   1: 0.018274907917395   4: 0.018268755660681   0: 0.018266315555561   7: 0.018265232751711   9: 0.018265078900825   8: 0.018264983080366   2: 0.018264979212893   3: 0.018264726732770 

training_4364     1: 0.752847060581445   4: 0.108178778177090   0: 0.032096159017120   6: 0.015320157449638   9: 0.015271788627303   5: 0.015262076870075   8: 0.015256921281870   3: 0.015255973827879   7: 0.015255932661757   2: 0.015255151505822 

training_4365     2: 0.410726781415974   6: 0.252519171354549   5: 0.122804661305085   0: 0.101085272114892   1: 0.037444351351001   9: 0.015093098558346   8: 0.015085371711792   3: 0.015084281248647   7: 0.015078865458403   4: 0.015078145481312 

training_4366     6: 0.794587703976891   5: 0.022827684409517   4: 0.022825009067134   9: 0.022824252191577   8: 0.022823140466574   0: 0.022822983118510   7: 0.022822715054195   1: 0.022822466507651   2: 0.022822150937064   3: 0.022821894270888 

training_4367     6: 0.606038347510158   2: 0.125126806082194   0: 0.078493147670802   7: 0.076150223922988   5: 0.048690644980169   8: 0.013105456219061   1: 0.013101289038514   9: 0.013101184417614   4: 0.013096759095412   3: 0.013096141063089 

training_4369     0: 0.615853614080736   6: 0.265112809998509   7: 0.024005890327813   5: 0.013581897719120   1: 0.013579857476134   2: 0.013576040452672   4: 0.013572765628573   8: 0.013572451945954   3: 0.013572438157745   9: 0.013572234212745 

training_4370     4: 0.767684587333605   5: 0.025818714372221   6: 0.025812410416549   0: 0.025812295803914   1: 0.025812263088978   8: 0.025812114942626   9: 0.025812042391511   3: 0.025811988212843   2: 0.025811848842399   7: 0.025811734595354 

training_4371     6: 0.430882943879722   4: 0.306420312368532   8: 0.124853290680433   5: 0.019729163837216   0: 0.019696056208617   2: 0.019693522910804   1: 0.019693014601157   9: 0.019681107363396   3: 0.019675502076459   7: 0.019675086073664 

training_4372     5: 0.765312002116828   3: 0.094256696199717   6: 0.017561920888635   9: 0.017557768233935   8: 0.017553699273319   1: 0.017553031678614   4: 0.017551826667753   0: 0.017551710661056   7: 0.017550936572836   2: 0.017550407707307 

training_4374     5: 0.655177529555942   6: 0.192415793579742   1: 0.019052416433065   8: 0.019052334879136   0: 0.019051250622877   4: 0.019050424081846   9: 0.019050242652582   7: 0.019050068817570   2: 0.019050025814263   3: 0.019049913562978 

training_4376     5: 0.675531788111964   2: 0.134850797043463   4: 0.023707344380257   6: 0.023703030924241   9: 0.023701758129400   1: 0.023701288259638   8: 0.023701189502554   0: 0.023701168022347   3: 0.023700889527412   7: 0.023700746098724 

training_4378     5: 0.817497806424571   4: 0.020282681016637   1: 0.020278174413894   6: 0.020278143536231   0: 0.020278119738421   8: 0.020277422553238   3: 0.020276984945720   9: 0.020276926417837   7: 0.020276880628761   2: 0.020276860324690 

training_438      6: 0.413667841302542   4: 0.378426748163361   5: 0.026030753010963   3: 0.025989482931900   0: 0.025987880892922   8: 0.025980500720128   9: 0.025980397977577   1: 0.025979303975524   7: 0.025978650685797   2: 0.025978440339286 

training_4380     5: 0.666175170097891   1: 0.148722856608866   3: 0.023138127597375   4: 0.023138028881768   6: 0.023137957934348   0: 0.023137916276706   2: 0.023137642181161   8: 0.023137552808541   7: 0.023137403390262   9: 0.023137344223082 

training_4382     6: 0.730015572321183   5: 0.121778323245100   0: 0.033815283323609   1: 0.016342428037347   4: 0.016341919508439   8: 0.016341678848264   2: 0.016341644746868   7: 0.016341226538498   9: 0.016341101384278   3: 0.016340822046413 

training_4384     5: 0.778854745199990   6: 0.024635994712784   0: 0.024597413629655   1: 0.024563261739570   9: 0.024559925022218   3: 0.024558393045097   4: 0.024557867755041   7: 0.024557486946396   2: 0.024557464361186   8: 0.024557447588063 

training_4385     5: 0.754932569575403   4: 0.027238201123136   8: 0.027228826465320   0: 0.027228791454197   3: 0.027228713128467   2: 0.027228661175752   1: 0.027228618781973   7: 0.027228602830761   9: 0.027228582241839   6: 0.027228433223152 

training_4386     6: 0.403134923812491   9: 0.366470268998301   5: 0.073807209714174   1: 0.022418529083246   2: 0.022384359979166   0: 0.022360044794899   4: 0.022357088109055   7: 0.022357018828662   8: 0.022355686818015   3: 0.022354869861990 

training_4387     5: 0.778358723440527   3: 0.024627268279296   4: 0.024627136424742   6: 0.024627013048582   1: 0.024626839306493   0: 0.024626812502294   8: 0.024626607936744   9: 0.024626547011059   2: 0.024626530796068   7: 0.024626521254195 

training_4388     5: 0.546691422883281   0: 0.161794831425063   7: 0.127358764720426   1: 0.023457726322435   3: 0.023450110226122   4: 0.023449942721185   6: 0.023449437713779   8: 0.023449401166515   2: 0.023449228432480   9: 0.023449134388714 

training_4389     5: 0.490578392099796   4: 0.313374701434204   0: 0.024507009905798   3: 0.024506663836911   1: 0.024505871417869   6: 0.024505835987650   8: 0.024505572491733   2: 0.024505459771379   7: 0.024505269712673   9: 0.024505223341986 

training_439      4: 0.469822671032525   6: 0.206060649080021   3: 0.134808920390907   5: 0.027064828039778   0: 0.027042701977645   9: 0.027041721550182   8: 0.027041501054683   1: 0.027039612371791   7: 0.027038980068148   2: 0.027038414434319 

training_4392     6: 0.649571406491571   0: 0.135943224622988   5: 0.091838176677404   3: 0.017535036696116   1: 0.017529646591492   9: 0.017523183074780   8: 0.017515543942914   7: 0.017514673717013   4: 0.017514592832645   2: 0.017514515353078 

training_4397     5: 0.612721222590576   6: 0.177338402796061   3: 0.026243037022665   1: 0.026242999678994   4: 0.026242678038327   0: 0.026242615587507   8: 0.026242457913926   2: 0.026242258036043   7: 0.026242179935180   9: 0.026242148400721 

training_4398     5: 0.783909688889087   6: 0.024010395548301   3: 0.024010360769446   4: 0.024010311897614   0: 0.024010119098478   8: 0.024009959062133   1: 0.024009863534683   9: 0.024009806488752   2: 0.024009749280599   7: 0.024009745430905 

training_4399     5: 0.689958395497111   4: 0.124771549284877   3: 0.023183492593520   6: 0.023155494020907   0: 0.023155440893857   8: 0.023155212413648   1: 0.023155161791091   2: 0.023155123497517   7: 0.023155080303491   9: 0.023155049703980 

training_44       1: 0.670769479102142   6: 0.129957025113934   2: 0.082650972592121   8: 0.016789045717566   0: 0.016666685507479   5: 0.016639149512533   9: 0.016632610507134   4: 0.016631951054573   3: 0.016631566544284   7: 0.016631514348233 

training_440      6: 0.712317282391600   5: 0.031974658332883   1: 0.031971795120697   0: 0.031967415884536   4: 0.031964463481119   8: 0.031961584948794   2: 0.031961295061681   9: 0.031961226644127   7: 0.031961091022265   3: 0.031959187112296 

training_4401     0: 0.629077329276582   2: 0.121906584903604   1: 0.071856749370068   3: 0.057458001878175   5: 0.019958014980542   6: 0.019952923836226   4: 0.019949653849504   9: 0.019947910871531   8: 0.019946496261241   7: 0.019946334772528 

training_4404     5: 0.652123390201597   3: 0.142671893461519   7: 0.073018531576177   1: 0.018888919123502   6: 0.018888548362572   0: 0.018884279868517   4: 0.018884136881220   8: 0.018881289327966   9: 0.018880549828336   2: 0.018878461368593 

training_4405     6: 0.572352448257208   0: 0.246244272216844   1: 0.105646935931161   7: 0.010830013040838   9: 0.010822564922086   5: 0.010821141089800   2: 0.010820972888362   8: 0.010820913700273   4: 0.010820378075598   3: 0.010820359877830 

training_4407     6: 0.743805105725495   0: 0.088168109740216   5: 0.037207400491305   7: 0.027634154766720   8: 0.017257735669837   9: 0.017252039636466   3: 0.017190324998742   1: 0.017164052214995   4: 0.017161152789546   2: 0.017159923966678 

training_4408     4: 0.646403907498600   6: 0.150330366474213   8: 0.048355454230324   1: 0.022152024973778   5: 0.022136717916221   0: 0.022127756849080   9: 0.022123902080856   2: 0.022123519027655   7: 0.022123483635449   3: 0.022122867313825 

training_4409     9: 0.728821042796244   6: 0.030142920327147   0: 0.030134360755728   8: 0.030133624887458   1: 0.030131551645014   5: 0.030129182018772   7: 0.030127413172235   3: 0.030126921709165   2: 0.030126915427908   4: 0.030126067260329 

training_441      1: 0.736590937359223   2: 0.062628429167779   5: 0.039163221480610   6: 0.023113744974677   0: 0.023093204603942   9: 0.023089612537212   8: 0.023084046783084   4: 0.023082907922869   3: 0.023076980691116   7: 0.023076914479489 

training_4410     5: 0.825247621832718   0: 0.019421774720442   6: 0.019418819450030   1: 0.019418021533136   4: 0.019416750039913   9: 0.019415834316363   7: 0.019415554910762   8: 0.019415455611009   3: 0.019415172862398   2: 0.019414994723227 

training_4411     0: 0.590380898900584   1: 0.221188291670478   6: 0.053417162469870   3: 0.019334069410589   8: 0.019290490441816   5: 0.019281221832811   4: 0.019277622870359   9: 0.019277570358720   2: 0.019276566926223   7: 0.019276105118551 

training_4412     5: 0.518900955724515   7: 0.290663098057782   3: 0.023804986933505   2: 0.023804890612271   0: 0.023804634404697   6: 0.023804511329690   4: 0.023804511236963   1: 0.023804353404428   9: 0.023804053480964   8: 0.023804004815185 

training_4419     5: 0.693772800675289   6: 0.133871538107852   8: 0.021548466713965   9: 0.021547277045954   0: 0.021544502855242   4: 0.021544111239294   7: 0.021544028854144   1: 0.021543408833324   2: 0.021541940163968   3: 0.021541925510969 

training_442      6: 0.645305036124822   5: 0.091419231459092   3: 0.079620220040108   2: 0.056302136282622   1: 0.021231291866668   0: 0.021228873331359   4: 0.021226112643865   8: 0.021222530179331   7: 0.021222451407984   9: 0.021222116664148 

training_4420     5: 0.771101911827839   4: 0.025441266642958   0: 0.025433347976719   6: 0.025433007071923   1: 0.025432992355537   7: 0.025431723191221   9: 0.025431607716471   3: 0.025431420141056   8: 0.025431409195106   2: 0.025431313881170 

training_4425     9: 0.470348585867244   6: 0.241617981946026   3: 0.070166600887830   7: 0.062342878060316   0: 0.045338778012866   5: 0.043883715343651   2: 0.029853492616340   1: 0.012182057868204   8: 0.012144573156074   4: 0.012121336241449 

training_4429     6: 0.580850736434439   3: 0.189651537370254   0: 0.086070728118926   8: 0.053267656199484   4: 0.023888108910313   1: 0.021366777640688   5: 0.011228947258175   9: 0.011225914523283   2: 0.011224799012832   7: 0.011224794531607 

training_443      6: 0.550483981813868   8: 0.327915243107966   3: 0.015254434703377   0: 0.015202459740051   5: 0.015192120667684   1: 0.015190660895256   9: 0.015190615462530   2: 0.015190205590086   7: 0.015190189409447   4: 0.015190088609736 

training_4431     6: 0.513592483881777   0: 0.348780515812194   3: 0.037575705465656   9: 0.014495160655160   8: 0.014292745351410   5: 0.014257146627690   1: 0.014252454534483   7: 0.014251752891297   2: 0.014251095687417   4: 0.014250939092915 

training_4433     7: 0.354157477417226   8: 0.220705852276724   5: 0.199822092069136   2: 0.032201465181453   9: 0.032190031103689   3: 0.032185208541913   1: 0.032184733812746   0: 0.032184583464075   4: 0.032184368195592   6: 0.032184187937446 

training_4434     8: 0.464300829525934   5: 0.291493234853885   1: 0.030535135181918   0: 0.030530492113769   6: 0.030528031278155   4: 0.030524099839431   2: 0.030523419879882   9: 0.030521676304871   3: 0.030521621130428   7: 0.030521459891727 

training_4436     6: 0.402481404367055   8: 0.224936135839413   5: 0.165276386178942   7: 0.078046765103415   1: 0.032248679745617   9: 0.029747198195795   3: 0.016827165640596   4: 0.016813671709573   0: 0.016812237276166   2: 0.016810355943429 

training_4437     7: 0.355911831021968   5: 0.353285128740350   8: 0.142097913846923   6: 0.021296092697374   1: 0.021239379243947   2: 0.021237930039654   0: 0.021234372370743   9: 0.021234025596787   4: 0.021231816891990   3: 0.021231509550263 

training_4438     5: 0.731556326582816   4: 0.106485475747100   6: 0.020246897214482   1: 0.020246117158251   0: 0.020245473111677   3: 0.020244974923569   9: 0.020243886068231   7: 0.020243681403270   8: 0.020243613496830   2: 0.020243554293773 

training_4439     5: 0.627618472656073   8: 0.174880607897482   3: 0.024688609978806   4: 0.024687858480481   1: 0.024687618008843   6: 0.024687591093672   0: 0.024687511059749   2: 0.024687353557733   7: 0.024687287349515   9: 0.024687089917647 

training_444      6: 0.627862273110467   0: 0.195089295201915   3: 0.022143283609187   9: 0.022134113916155   5: 0.022129365212729   7: 0.022128980307075   1: 0.022128767852501   8: 0.022128241860695   4: 0.022127861172013   2: 0.022127817757261 

training_4440     5: 0.708398621651818   3: 0.108781305427486   1: 0.022855227045865   0: 0.022853604170066   6: 0.022852439078508   4: 0.022852116123625   8: 0.022851755510730   7: 0.022851690791700   2: 0.022851632025107   9: 0.022851608175094 

training_4445     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_4446     5: 0.343610846201822   3: 0.334257700629987   2: 0.151480602961116   4: 0.024379568159963   0: 0.024378653851870   6: 0.024378627887001   8: 0.024378598818710   7: 0.024378546719679   1: 0.024378535204230   9: 0.024378319565622 

training_4447     8: 0.484161674818551   5: 0.351153960083334   3: 0.020925595504232   0: 0.020628896641654   6: 0.020586116590027   1: 0.020565554448575   2: 0.020496325604555   9: 0.020494432420234   4: 0.020494099693122   7: 0.020493344195715 

training_4449     6: 0.449270319995077   1: 0.339854153430689   0: 0.026361537091577   7: 0.026361396808018   9: 0.026360323540100   2: 0.026359393039169   8: 0.026359327150250   5: 0.026358781599302   3: 0.026357870423910   4: 0.026356896921908 

training_4451     5: 0.774187988831348   4: 0.025093438437386   8: 0.025089916996319   3: 0.025089901908347   0: 0.025089864083471   2: 0.025089855069746   9: 0.025089845217242   1: 0.025089799383013   7: 0.025089725185357   6: 0.025089664887771 

training_4452     5: 0.788845993553964   3: 0.023467015697973   4: 0.023461605907979   1: 0.023461208851679   2: 0.023461015811936   0: 0.023460903127053   6: 0.023460829923017   9: 0.023460513234118   7: 0.023460471983361   8: 0.023460441908921 

training_4453     2: 0.779274233602806   5: 0.056050829045068   4: 0.020614940958639   7: 0.020585826289436   6: 0.020582754604984   0: 0.020579771675617   1: 0.020578891563790   9: 0.020578109296312   3: 0.020577339078887   8: 0.020577303884463 

training_4454     5: 0.681230144544517   7: 0.143047216647737   4: 0.021968275175798   6: 0.021968181433201   2: 0.021965765317304   9: 0.021965231458705   1: 0.021964337329193   0: 0.021964226560732   3: 0.021963458873900   8: 0.021963162658912 

training_4455     6: 0.530843104975789   9: 0.237679683463665   5: 0.028947849421275   0: 0.028936075935647   8: 0.028934623166175   1: 0.028933960640377   2: 0.028932780666114   3: 0.028931029891586   7: 0.028930792359326   4: 0.028930099480047 

training_4457     5: 0.779828561385539   4: 0.024468435484378   6: 0.024463923592367   1: 0.024463453323356   0: 0.024463350979119   9: 0.024462632089293   8: 0.024462569939934   3: 0.024462438295226   2: 0.024462355592416   7: 0.024462279318371 

training_4458     6: 0.655899731052675   9: 0.161548961540902   1: 0.041231914433688   2: 0.040577183964864   7: 0.016813309394762   0: 0.016787064737893   5: 0.016786991460938   8: 0.016785181874416   4: 0.016785063998827   3: 0.016784597541036 

training_4459     5: 0.410213681236910   2: 0.393029051821913   3: 0.024596090131558   4: 0.024595591140944   7: 0.024594402219400   1: 0.024594312922956   0: 0.024594285956265   6: 0.024594248438975   8: 0.024594182222015   9: 0.024594153909065 

training_4460     4: 0.440369657909992   3: 0.304942784694020   5: 0.031845190255962   6: 0.031834923660737   8: 0.031834807366905   0: 0.031834663845180   2: 0.031834580426857   9: 0.031834525705033   7: 0.031834476864656   1: 0.031834389270657 

training_4462     2: 0.550834951775974   0: 0.212005257147924   9: 0.029647733631891   6: 0.029646864189380   5: 0.029646137028929   8: 0.029644913879407   1: 0.029644260756040   4: 0.029644085106503   7: 0.029643175460637   3: 0.029642621023316 

training_4465     1: 0.517947116490900   6: 0.248041777377165   7: 0.101265106644733   0: 0.032747887562397   9: 0.016685636000502   5: 0.016682599694252   8: 0.016658058757387   4: 0.016657630554638   3: 0.016657273157747   2: 0.016656913760279 

training_4466     2: 0.749108558904440   5: 0.027883730575921   4: 0.027878942599520   9: 0.027877445679506   6: 0.027876789808007   8: 0.027875486518899   0: 0.027875276597581   1: 0.027875002036676   3: 0.027874501257759   7: 0.027874266021691 

training_4467     6: 0.682581398746289   4: 0.150709036203641   7: 0.041353392545068   0: 0.017988908054587   1: 0.017896862844500   9: 0.017894535114199   5: 0.017894500763718   2: 0.017894363097473   8: 0.017893672888906   3: 0.017893329741620 

training_4468     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_447      5: 0.642235714049212   6: 0.183110817512090   0: 0.021847305342970   1: 0.021837089110823   3: 0.021830002378978   2: 0.021828963101913   9: 0.021828305260905   4: 0.021827751995112   7: 0.021827146892164   8: 0.021826904355833 

training_4470     6: 0.670168006582053   4: 0.095655971493421   0: 0.085929898622434   7: 0.069871779128543   1: 0.022758359343147   8: 0.011129407353699   5: 0.011124315870763   3: 0.011123545678530   9: 0.011120800599977   2: 0.011117915327434 

training_4472     5: 0.782027080386186   6: 0.024225258275886   9: 0.024221205794973   4: 0.024220079106835   8: 0.024218978500829   0: 0.024218523341625   7: 0.024218208635848   1: 0.024217025528087   3: 0.024216844136423   2: 0.024216796293309 

training_4473     6: 0.752785824918537   1: 0.027469855915736   0: 0.027469145429015   7: 0.027468586072199   8: 0.027468439239542   5: 0.027468094867010   9: 0.027467787287738   2: 0.027467553106486   4: 0.027467402289927   3: 0.027467310873811 

training_4474     2: 0.724994810504750   1: 0.089711386421675   4: 0.071451860543220   6: 0.016270405389833   5: 0.016269684631675   0: 0.016263473979729   9: 0.016260728289349   7: 0.016259970212341   8: 0.016259840167627   3: 0.016257839859801 

training_4475     5: 0.684873968689810   3: 0.124170298801658   4: 0.076824424138340   6: 0.016305874468468   9: 0.016305682845488   2: 0.016304667671337   1: 0.016304263318644   0: 0.016303794599709   7: 0.016303700769414   8: 0.016303324697132 

training_4476     4: 0.816941871362930   5: 0.020346194198850   6: 0.020340184447781   0: 0.020339624704865   1: 0.020339593313721   9: 0.020339192909294   8: 0.020338978206097   2: 0.020338162442648   7: 0.020338145912834   3: 0.020338052500980 

training_4477     0: 0.487789737739326   6: 0.384181485634941   1: 0.037158475350432   5: 0.020706139803542   4: 0.012412699345980   9: 0.011581015925251   2: 0.011547424978625   8: 0.011541571278042   3: 0.011540786476071   7: 0.011540663467790 

training_4478     6: 0.810876277705379   7: 0.048559303972567   0: 0.017572155557024   1: 0.017571347203132   5: 0.017570859692635   9: 0.017570292048879   8: 0.017570198768220   2: 0.017569937074160   4: 0.017569895481534   3: 0.017569732496471 

training_448      6: 0.570656733032096   9: 0.283717671608280   5: 0.039622843304558   8: 0.015321781166255   1: 0.015127724452051   0: 0.015117254809238   2: 0.015112890199316   3: 0.015109119137907   7: 0.015108128233880   4: 0.015105854056419 

training_4480     1: 0.736259427538099   6: 0.029316286205091   0: 0.029311567451383   8: 0.029302706396086   2: 0.029302023810906   7: 0.029301819004102   9: 0.029301732897272   5: 0.029301563532092   3: 0.029301529033824   4: 0.029301344131146 

training_4481     2: 0.595399299697168   0: 0.162987370080896   6: 0.061893216309393   5: 0.057785320043153   4: 0.020350655317569   7: 0.020322964334128   1: 0.020316058386021   9: 0.020315674659943   8: 0.020314761762011   3: 0.020314679409719 

training_4483     6: 0.427963429191722   2: 0.211446933185968   4: 0.167296047200079   0: 0.027623880637786   5: 0.027614275385805   8: 0.027612271628720   9: 0.027612266584506   1: 0.027610823673533   7: 0.027610041754974   3: 0.027610030756907 

training_4484     6: 0.544983653753657   5: 0.234562094355730   9: 0.027561066289117   2: 0.027560773580889   0: 0.027557298263229   1: 0.027556740713177   8: 0.027556410665027   3: 0.027554208225688   7: 0.027554116334603   4: 0.027553637818884 

training_4486     0: 0.749670299807762   6: 0.027823386562697   8: 0.027821709147086   1: 0.027816499161227   9: 0.027811934405025   7: 0.027811595365091   2: 0.027811429898298   5: 0.027811181286062   4: 0.027811007886401   3: 0.027810956480352 

training_4487     8: 0.530365162292224   5: 0.270261909265632   6: 0.024929395811682   9: 0.024926308969456   1: 0.024923035581661   0: 0.024920549568492   7: 0.024920499730786   4: 0.024918527536167   2: 0.024917877313039   3: 0.024916733930861 

training_4488     1: 0.423449909768681   6: 0.396741648067631   7: 0.045216733726206   0: 0.039178250317202   2: 0.027951752500770   4: 0.013494614283224   5: 0.013494400271333   8: 0.013491267123547   3: 0.013490934519709   9: 0.013490489421697 

training_449      5: 0.673538857074884   1: 0.125806454857222   6: 0.078271735913502   0: 0.017486199499955   4: 0.017486177937121   8: 0.017483148643801   9: 0.017482120647897   7: 0.017481883434330   3: 0.017481778980398   2: 0.017481643010891 

training_4490     6: 0.800208849826014   1: 0.088242973531500   5: 0.025857370776609   0: 0.020197986424984   8: 0.014520736168449   9: 0.010246435343205   7: 0.010227746020665   2: 0.010167592788678   3: 0.010165209495517   4: 0.010165099624378 

training_4493     5: 0.619118087556278   3: 0.189942799443245   8: 0.052361698807920   6: 0.019809138215751   1: 0.019801244188595   0: 0.019798769048692   4: 0.019792997915766   9: 0.019791980898724   2: 0.019791673582275   7: 0.019791610342753 

training_4494     5: 0.678665695259526   4: 0.126164412521395   0: 0.064288357470385   7: 0.018712755331044   6: 0.018705744079569   9: 0.018699474820645   8: 0.018691800255558   1: 0.018691032907633   2: 0.018690378996361   3: 0.018690348357883 

training_4498     5: 0.561540026051623   0: 0.210298569845745   8: 0.077467732426702   2: 0.021533888030662   1: 0.021532866743333   6: 0.021528702743862   7: 0.021525523870586   4: 0.021524884984056   9: 0.021524174608682   3: 0.021523630694751 

training_4499     2: 0.456322253971258   6: 0.330353492430541   0: 0.026667244323652   4: 0.026666697182521   9: 0.026666565589817   8: 0.026666130397917   1: 0.026665126934134   5: 0.026664549881479   3: 0.026664008892732   7: 0.026663930395949 

training_45       4: 0.414251306012981   0: 0.251397799139587   6: 0.242048554357025   1: 0.019987337517371   8: 0.012227844781221   5: 0.012046152718489   9: 0.012010683969778   3: 0.012010263194056   2: 0.012010055075356   7: 0.012010003234134 

training_450      6: 0.736843231310579   9: 0.133985248491067   0: 0.016159997277581   5: 0.016148837079875   4: 0.016144448115543   8: 0.016144112654856   1: 0.016143780283164   7: 0.016143740157924   3: 0.016143379971742   2: 0.016143224657671 

training_4503     6: 0.583280482625661   9: 0.140266111578906   5: 0.099184909099080   3: 0.064275562607562   1: 0.030126576160462   0: 0.029347298568666   7: 0.013436348031400   8: 0.013368115030278   2: 0.013358982665507   4: 0.013355613632478 

training_4504     4: 0.771500372059877   5: 0.025393958541838   8: 0.025388405202189   3: 0.025388379963156   2: 0.025388271414330   0: 0.025388185816905   1: 0.025388179079403   9: 0.025388159105100   7: 0.025388099272636   6: 0.025387989544566 

training_4505     5: 0.737811478961913   3: 0.084075400922919   7: 0.022276704072419   1: 0.022267283184917   6: 0.022262429698155   2: 0.022262000674101   9: 0.022261533563567   0: 0.022261401784539   4: 0.022260971693683   8: 0.022260795443786 

training_4507     6: 0.622500156367923   9: 0.211255417090327   0: 0.045152397157931   8: 0.017384821528668   1: 0.017288822785451   5: 0.017284945350264   2: 0.017284262981031   4: 0.017283876992186   3: 0.017282704415454   7: 0.017282595330765 

training_4509     6: 0.768664379045752   1: 0.025705890786544   8: 0.025704720590856   9: 0.025704578734378   0: 0.025704509954205   5: 0.025704118558466   7: 0.025702988906981   2: 0.025702946933748   4: 0.025702938553451   3: 0.025702927935620 

training_4510     1: 0.622733157976194   5: 0.233504656125205   0: 0.033538842288706   6: 0.015781004511758   7: 0.015741386963879   8: 0.015740992002260   4: 0.015740511211167   2: 0.015740201810779   9: 0.015740003135558   3: 0.015739243974493 

training_4512     6: 0.402264264387323   7: 0.229448771596895   3: 0.192164593836904   1: 0.025163448069612   5: 0.025162417758929   8: 0.025161064707544   0: 0.025161054875458   2: 0.025158353648293   4: 0.025158277779601   9: 0.025157753339440 

training_4513     6: 0.493346056218947   0: 0.389282479037088   8: 0.026581653978517   1: 0.012979752739323   5: 0.012969870235734   4: 0.012968758100578   9: 0.012968268020620   2: 0.012967848046655   7: 0.012967680848217   3: 0.012967632774322 

training_4514     6: 0.570645961289566   9: 0.161084352069772   5: 0.129645192686728   1: 0.044546885250172   7: 0.015705386457120   8: 0.015682198080225   0: 0.015675023301413   2: 0.015674230987314   3: 0.015671455573026   4: 0.015669314304666 

training_4515     6: 0.579170595344243   8: 0.201399573067376   5: 0.027435647355175   1: 0.027429936269055   0: 0.027429137847057   4: 0.027429087370377   7: 0.027427536914212   9: 0.027426613342517   2: 0.027426566910171   3: 0.027425305579819 

training_4516     8: 0.753426879441010   5: 0.027399938998554   6: 0.027398646307736   1: 0.027397520638431   4: 0.027397171032241   0: 0.027396608884108   9: 0.027396395919956   7: 0.027395946377155   2: 0.027395714337653   3: 0.027395178063156 

training_4517     4: 0.686807687430117   5: 0.139400358685169   0: 0.021736856217425   9: 0.021736577799060   8: 0.021720043925392   1: 0.021719796241610   3: 0.021719734832562   6: 0.021719671964488   2: 0.021719670875464   7: 0.021719602028711 

training_4518     4: 0.434891530508229   6: 0.379417186290445   0: 0.061623776138401   9: 0.030525170796768   3: 0.015873889215889   1: 0.015579142111811   5: 0.015525295782099   2: 0.015522916152449   8: 0.015520660435865   7: 0.015520432568043 

training_4519     5: 0.553049015050298   6: 0.307811256797023   8: 0.017394522565666   1: 0.017393565970070   0: 0.017393450748453   9: 0.017392286264427   7: 0.017391858596267   4: 0.017391808887276   2: 0.017391404572005   3: 0.017390830548514 

training_4521     5: 0.757838989232531   4: 0.026909383987940   8: 0.026906570379987   9: 0.026906495694268   3: 0.026906493156085   2: 0.026906488439173   1: 0.026906444829649   0: 0.026906431425714   7: 0.026906394226170   6: 0.026906308628483 

training_4523     5: 0.589802261414952   6: 0.261621272916872   1: 0.018575413798437   7: 0.018574297928405   0: 0.018574260446547   2: 0.018571206678801   3: 0.018570866651122   4: 0.018570551204924   8: 0.018569954208503   9: 0.018569914751436 

training_4524     6: 0.557212850058757   8: 0.225217045949544   5: 0.125028178887649   4: 0.013265466236393   1: 0.013221763563478   0: 0.013217372271237   7: 0.013210211104174   9: 0.013209556853560   2: 0.013208858449423   3: 0.013208696625784 

training_4525     6: 0.717083112538933   9: 0.115157082255647   1: 0.037256085212248   0: 0.036054187201892   8: 0.015843082314647   7: 0.015771334078677   2: 0.015710219068933   5: 0.015708605161024   4: 0.015708316546462   3: 0.015707975621537 

training_4532     8: 0.775164142565615   6: 0.024988833534059   9: 0.024983642661339   5: 0.024983445917180   0: 0.024980530630083   2: 0.024980383179618   1: 0.024980211828540   4: 0.024979987833579   7: 0.024979921369125   3: 0.024978900480863 

training_4533     8: 0.765240619430928   5: 0.026093909652803   4: 0.026088009497438   6: 0.026086325198589   0: 0.026082384106158   9: 0.026082123370258   7: 0.026081990844780   1: 0.026081953276463   2: 0.026081419079700   3: 0.026081265542883 

training_4534     9: 0.486879482901002   6: 0.300540535197118   5: 0.026581005679029   8: 0.026576411613491   4: 0.026573677391257   7: 0.026571009944088   0: 0.026570150535551   1: 0.026569757321069   2: 0.026569143069178   3: 0.026568826348216 

training_4536     4: 0.341877359223838   6: 0.302792872049280   2: 0.196623196914427   1: 0.022691641912720   5: 0.022673736083204   0: 0.022672228982586   9: 0.022667851156667   3: 0.022667230059148   8: 0.022667135299717   7: 0.022666748318413 

training_4537     0: 0.497586134124670   5: 0.313287418222642   6: 0.023642791611402   1: 0.023642592454739   4: 0.023641076894468   8: 0.023640886557729   9: 0.023640080611005   2: 0.023639891964499   7: 0.023639754113226   3: 0.023639373445620 

training_4541     5: 0.546143664330756   6: 0.292952316871534   9: 0.020203706791234   1: 0.020104154795472   2: 0.020101760758073   0: 0.020101379853686   8: 0.020100333576027   7: 0.020099306571587   4: 0.020097005023483   3: 0.020096371428149 

training_4544     6: 0.540284992041062   8: 0.253291510199077   7: 0.084958434150426   0: 0.017440415423825   9: 0.017340473805397   5: 0.017338980055119   4: 0.017337031050595   1: 0.017336306342645   2: 0.017336049251288   3: 0.017335807680566 

training_4548     6: 0.737661460975952   0: 0.088933715374135   1: 0.073132773999531   9: 0.023016739474150   8: 0.016351597188369   7: 0.014007000578712   5: 0.011729007988217   4: 0.011723984737471   3: 0.011722052818620   2: 0.011721666864842 

training_4549     6: 0.756007262211671   3: 0.069325887521695   1: 0.060361499896077   0: 0.016339285954066   5: 0.016328240287506   8: 0.016328229758324   9: 0.016327679734337   4: 0.016327399242625   2: 0.016327301676608   7: 0.016327213717091 

training_455      2: 0.387048736160145   5: 0.325532571393615   4: 0.035938628239839   3: 0.035926510588208   1: 0.035925988570219   8: 0.035925910500169   0: 0.035925854000031   7: 0.035925539391635   9: 0.035925321575560   6: 0.035924939580578 

training_4551     5: 0.828419477081193   1: 0.019066398402490   6: 0.019065641474454   0: 0.019065112880044   2: 0.019063978899027   9: 0.019063978157254   4: 0.019063951967189   3: 0.019063920148850   8: 0.019063814657902   7: 0.019063726331597 

training_4552     6: 0.809611161835446   1: 0.071920046199677   8: 0.032232527005411   0: 0.018273318379596   3: 0.017952581752932   5: 0.010002748082387   9: 0.010002260426426   4: 0.010002041917646   2: 0.010001700898656   7: 0.010001613501823 

training_4554     4: 0.757003982482688   1: 0.082533618962426   5: 0.020069135367520   9: 0.020057747009067   3: 0.020056382312159   6: 0.020056243095991   0: 0.020055864195918   8: 0.020055711530564   7: 0.020055686296565   2: 0.020055628747102 

training_4555     6: 0.411229678129155   0: 0.350267811191838   1: 0.141450972452926   8: 0.025562770681200   9: 0.011915539054953   5: 0.011915149219532   4: 0.011914811265599   7: 0.011914507843353   2: 0.011914484247440   3: 0.011914275914003 

training_4558     2: 0.733639039631423   5: 0.029605377804357   4: 0.029599172701453   6: 0.029597005323313   9: 0.029596072586622   8: 0.029593537446200   1: 0.029593057900116   0: 0.029592991418436   7: 0.029591896521631   3: 0.029591848666449 

training_456      4: 0.781244840442689   6: 0.024312188980002   5: 0.024310873765801   8: 0.024305522062571   0: 0.024304962046453   3: 0.024304469119368   9: 0.024304373428520   2: 0.024304302398213   7: 0.024304240876601   1: 0.024304226879782 

training_4560     4: 0.438613658486708   5: 0.365584423495290   3: 0.024476296063236   6: 0.024475272397237   8: 0.024475240396848   0: 0.024475202996858   1: 0.024475081685677   2: 0.024475017934020   7: 0.024474963065538   9: 0.024474843478587 

training_4562     5: 0.698843200491477   6: 0.085672068972817   2: 0.080521498791615   9: 0.019313374131921   3: 0.019297247186008   8: 0.019288997569485   0: 0.019268834414891   1: 0.019266750662927   4: 0.019264383566137   7: 0.019263644212722 

training_4564     6: 0.808748008659166   0: 0.083556539835978   8: 0.042574549561765   3: 0.013696075590505   7: 0.008944383486139   5: 0.008538129234677   9: 0.008489098137665   1: 0.008488151330368   4: 0.008483752068616   2: 0.008481312095123 

training_4569     2: 0.299947875345670   6: 0.256086634148704   5: 0.168091785330232   4: 0.116159522976281   9: 0.069887477212336   0: 0.017988155864163   1: 0.017961992605029   8: 0.017961956722787   7: 0.017957535220473   3: 0.017957064574324 

training_4573     6: 0.796930550267863   0: 0.089058932813243   7: 0.025758158081805   4: 0.012617128252333   5: 0.012607167586642   9: 0.012606718481893   1: 0.012606486972367   2: 0.012605010074794   3: 0.012604938739312   8: 0.012604908729748 

training_4574     5: 0.698904347783353   6: 0.085425699185620   2: 0.080708382045413   9: 0.019312258440249   3: 0.019296650161654   8: 0.019289018037241   0: 0.019268855235152   1: 0.019266759544355   4: 0.019264383839995   7: 0.019263645726969 

training_4576     2: 0.561616318527890   6: 0.277102249042117   1: 0.041080312233037   0: 0.026196122521546   5: 0.024835517561492   4: 0.013918347456833   7: 0.013829979625315   8: 0.013807558237421   9: 0.013807212557643   3: 0.013806382236705 

training_4577     6: 0.596020397385796   5: 0.127238044311125   3: 0.079779852700912   1: 0.065265257983660   9: 0.060636299200055   7: 0.014218123696352   0: 0.014213871971887   8: 0.014212461271879   4: 0.014207953851119   2: 0.014207737627215 

training_4578     2: 0.733083640527895   5: 0.029664344177589   4: 0.029660175746394   9: 0.029658354257557   6: 0.029657289061992   8: 0.029655982373341   1: 0.029655312744849   0: 0.029655296398297   3: 0.029654949591180   7: 0.029654655120904 

training_4579     1: 0.723563008192329   5: 0.080954830867697   9: 0.042497968994096   8: 0.022097551125257   6: 0.021849612951630   0: 0.021815230484556   7: 0.021806532605425   4: 0.021806463560191   3: 0.021805166387530   2: 0.021803634831289 

training_4581     5: 0.832307805556872   4: 0.018636730695687   6: 0.018632296666548   0: 0.018632050247852   1: 0.018631927102084   9: 0.018631914252349   8: 0.018631884084572   3: 0.018631818803114   7: 0.018631802461982   2: 0.018631770128940 

training_4583     5: 0.442477616394720   6: 0.298086194893928   8: 0.118004346458117   4: 0.020206218314835   1: 0.020206083611960   0: 0.020206011555270   3: 0.020203685414988   9: 0.020203401363475   2: 0.020203368884451   7: 0.020203073108257 

training_4584     2: 0.821214481209947   5: 0.042923824721886   4: 0.017011108384855   7: 0.016983232378118   6: 0.016983030017511   0: 0.016979107380543   1: 0.016977723659285   9: 0.016976706302857   3: 0.016975498310562   8: 0.016975287634437 

training_4585     5: 0.321218173255177   1: 0.235411763620731   6: 0.155244355357401   8: 0.129235326761645   9: 0.069516284312662   0: 0.017889864203734   4: 0.017871998903300   7: 0.017870969719091   2: 0.017870727695086   3: 0.017870536171172 

training_4586     0: 0.717287312687348   2: 0.082783331115760   6: 0.024996106370621   1: 0.024994424182752   4: 0.024992388973449   5: 0.024991476316623   9: 0.024989025426598   3: 0.024988884742315   7: 0.024988557462045   8: 0.024988492722488 

training_459      6: 0.595904577850590   9: 0.196931677544453   2: 0.025904811994239   5: 0.025897156276727   1: 0.025896236239960   7: 0.025894067167283   8: 0.025893538264882   0: 0.025893298951317   3: 0.025892692645368   4: 0.025891943065181 

training_4590     4: 0.304028200358742   6: 0.303452635137958   9: 0.276646477111804   5: 0.016599441245785   2: 0.016549485760860   8: 0.016545993161296   0: 0.016545493313687   1: 0.016544479694335   7: 0.016544129778110   3: 0.016543664437423 

training_4591     1: 0.383537960737433   9: 0.364639411131200   2: 0.102151124174148   7: 0.021656501592133   5: 0.021354593786748   6: 0.021334544115408   0: 0.021333100638085   8: 0.021331919644526   4: 0.021331304856498   3: 0.021329539323821 

training_4592     8: 0.415512841843194   0: 0.374775011784096   4: 0.066034389668430   1: 0.020558511744559   6: 0.020531369195217   5: 0.020525724513765   9: 0.020516780883125   2: 0.020516302453420   3: 0.020514652194507   7: 0.020514415719687 

training_4593     6: 0.825181085529981   0: 0.048696036582718   3: 0.024427827520258   4: 0.014641338884259   1: 0.014518269116882   5: 0.014508300378449   9: 0.014506844343653   8: 0.014506841254892   2: 0.014506750172511   7: 0.014506706216397 

training_4595     6: 0.815081312369339   1: 0.059545574393864   8: 0.038607416844240   0: 0.012395661244746   5: 0.012395403787952   9: 0.012395132024682   4: 0.012394937662403   7: 0.012394867217256   3: 0.012394850081354   2: 0.012394844374165 

training_4599     6: 0.834409872468456   8: 0.018400526088089   5: 0.018399984146004   7: 0.018399060372848   0: 0.018398875513064   4: 0.018398651881983   9: 0.018398565925166   1: 0.018398462316554   2: 0.018398049661775   3: 0.018397951626061 

training_46       6: 0.805989749072155   0: 0.053747868797603   7: 0.017564693915365   5: 0.017548689846646   8: 0.017543597610128   9: 0.017532614560686   1: 0.017519099773493   4: 0.017518264753968   2: 0.017517730635218   3: 0.017517691034736 

training_4600     6: 0.562436724686275   2: 0.182962591809338   0: 0.081007666340974   1: 0.050540383978966   3: 0.042394102966608   8: 0.016133808687987   5: 0.016132781012983   9: 0.016131317784968   4: 0.016130973862210   7: 0.016129648869691 

training_4602     6: 0.433161155461236   0: 0.282295431838761   8: 0.194632310784148   1: 0.031407474869469   9: 0.009757559974018   5: 0.009751138044208   4: 0.009748978919375   2: 0.009748677397565   7: 0.009748675857089   3: 0.009748596854132 

training_4603     6: 0.709371874432862   8: 0.123040092693054   0: 0.069244799099042   1: 0.038398585602231   7: 0.009992260145103   5: 0.009991073180496   2: 0.009990413492744   9: 0.009990368464931   3: 0.009990343385245   4: 0.009990189504292 

training_4604     6: 0.562224344783840   2: 0.183172143437971   0: 0.081010020074691   1: 0.050540824433260   3: 0.042394140686429   8: 0.016133805008921   5: 0.016132782233266   9: 0.016131316934910   4: 0.016130974342520   7: 0.016129648064191 

training_4605     4: 0.458446843009282   6: 0.255581605687876   5: 0.106434293593033   2: 0.056245138704851   0: 0.020562463607989   1: 0.020558607854286   7: 0.020545177267774   8: 0.020542782301227   9: 0.020541795017202   3: 0.020541292956480 

training_4606     2: 0.431636402357613   6: 0.331560650992156   8: 0.056292569232565   1: 0.026032625876798   9: 0.025768675986344   0: 0.025750441750972   5: 0.025744030310299   4: 0.025741892889380   3: 0.025738276276519   7: 0.025734434327352 

training_4609     6: 0.761419208166490   7: 0.081681747706080   4: 0.050955326003818   1: 0.021336402846995   3: 0.014397947670966   0: 0.014086570381934   8: 0.014059034655903   5: 0.014042257298384   9: 0.014012843747687   2: 0.014008661521743 

training_461      5: 0.684217028876772   3: 0.113404151001014   7: 0.025309255805250   4: 0.025295980218616   6: 0.025295672648490   2: 0.025295611416840   0: 0.025295601870964   1: 0.025295595432758   8: 0.025295580088032   9: 0.025295522641263 

training_4610     5: 0.566050599658144   3: 0.259010521026636   7: 0.066632354838809   0: 0.015482921584770   1: 0.015474241499085   6: 0.015471648608955   4: 0.015469991012651   9: 0.015469640178328   8: 0.015469332719790   2: 0.015468748872833 

training_4613     5: 0.791371007535834   6: 0.023183185775756   1: 0.023182088048082   0: 0.023181816058043   9: 0.023180660382331   8: 0.023180329238094   4: 0.023180325278489   7: 0.023180236450125   3: 0.023180222907779   2: 0.023180128325467 

training_4615     8: 0.781658368100637   1: 0.024272010371962   5: 0.024270907479689   6: 0.024270616811998   0: 0.024267572385433   9: 0.024260170099287   2: 0.024253733395005   4: 0.024251480871379   3: 0.024247665301990   7: 0.024247475182620 

training_4616     6: 0.759237863712406   0: 0.082501604634767   3: 0.050028332911174   1: 0.015468045204996   7: 0.015461303900970   9: 0.015460790682751   8: 0.015460615640484   5: 0.015460613664231   2: 0.015460478075907   4: 0.015460351572313 

training_4617     6: 0.790408058052929   8: 0.090376540401329   5: 0.014903474644549   1: 0.014902803048959   0: 0.014902350262281   3: 0.014901567277202   4: 0.014901369261336   2: 0.014901307324410   7: 0.014901272450286   9: 0.014901257276720 

training_4620     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_4621     6: 0.512192245433253   3: 0.336780268434242   1: 0.034963032239089   8: 0.024969754344469   0: 0.015198270030453   5: 0.015192823123698   9: 0.015188573287607   4: 0.015174114648718   2: 0.015170470010022   7: 0.015170448448448 

training_4622     6: 0.324618389734876   5: 0.320240013664045   4: 0.159301417129268   9: 0.079429577727897   8: 0.028606607094068   3: 0.026804417885938   0: 0.015283143050788   1: 0.015240435922524   2: 0.015238571767164   7: 0.015237426023433 

training_4623     1: 0.702333436816518   6: 0.072707762128121   5: 0.043563846440852   7: 0.039238515523165   8: 0.023843404854719   0: 0.023732923087502   2: 0.023665361855151   3: 0.023640737140401   4: 0.023637541510075   9: 0.023636470643496 

training_4625     6: 0.632645317549075   0: 0.217509740863334   9: 0.063480687631028   1: 0.028494333175024   5: 0.009647308196978   4: 0.009646240671096   8: 0.009645536284365   3: 0.009644105075353   7: 0.009643656154749   2: 0.009643074398998 

training_4629     6: 0.731631450943428   7: 0.081823750741910   0: 0.056248187570033   5: 0.018618501090651   4: 0.018614388475337   9: 0.018613586873526   8: 0.018613195754366   3: 0.018612823374824   1: 0.018612317943268   2: 0.018611797232658 

training_4630     6: 0.724482650216825   8: 0.084569547189849   0: 0.074467308363776   5: 0.050819726520878   2: 0.015179586979646   9: 0.011858419252257   7: 0.009699375742118   1: 0.009642560197501   3: 0.009640569719948   4: 0.009640255817202 

training_4631     6: 0.672090224147287   5: 0.165615465008030   0: 0.020300294897571   9: 0.020290436263518   8: 0.020284427606256   1: 0.020284141626670   3: 0.020283898683360   4: 0.020283848834864   7: 0.020283845119621   2: 0.020283417812822 

training_4632     6: 0.804858653941697   0: 0.064071104957984   9: 0.041560239174596   7: 0.012804199521598   1: 0.012794374948706   5: 0.012788900647248   8: 0.012780754862349   3: 0.012780644927849   2: 0.012780568667614   4: 0.012780558350357 

training_4633     6: 0.732243845259773   5: 0.082468829698755   8: 0.049020253836840   1: 0.040683917307460   0: 0.015963669438015   3: 0.015924179358746   9: 0.015923945818806   4: 0.015923906542468   7: 0.015923898767657   2: 0.015923553971481 

training_4634     6: 0.766248779610340   2: 0.066598170197214   0: 0.044525330606975   8: 0.017617214159439   1: 0.017503548583160   5: 0.017501970973147   7: 0.017501640041264   9: 0.017501638093066   4: 0.017500859698246   3: 0.017500848037149 

training_4635     6: 0.552119519671427   5: 0.225275679557484   1: 0.027835474486895   4: 0.027828889010977   9: 0.027827026695817   8: 0.027825085028532   7: 0.027823254094782   0: 0.027822404817334   3: 0.027821335145517   2: 0.027821331491238 

training_4636     6: 0.708348423048160   0: 0.168454200792706   3: 0.026664352257570   5: 0.013791388694999   9: 0.013791382275455   1: 0.013790733438671   8: 0.013790005337357   4: 0.013789934413303   7: 0.013789837601494   2: 0.013789742140286 

training_4637     6: 0.755837317259215   0: 0.059292185711333   8: 0.054317029927371   5: 0.018653904797594   9: 0.018651876415930   7: 0.018650073327450   1: 0.018649640483656   4: 0.018649390507711   3: 0.018649295827299   2: 0.018649285742441 

training_4638     6: 0.751708923445817   8: 0.049311095382149   1: 0.047546427571833   9: 0.044867923844312   5: 0.017768014110785   0: 0.017763782841919   2: 0.017758741238253   7: 0.017758712640073   4: 0.017758465644767   3: 0.017757913280093 

training_464      5: 0.825223937994646   0: 0.019425063320640   6: 0.019423515454380   1: 0.019420506313672   8: 0.019418258714117   7: 0.019418156202701   4: 0.019418045198512   9: 0.019417915060750   3: 0.019417471894865   2: 0.019417129845717 

training_4640     6: 0.760838589861412   0: 0.095605738032491   3: 0.029390644317748   1: 0.027997194275495   5: 0.014362440652077   4: 0.014361284249403   9: 0.014361283476572   7: 0.014360958547834   8: 0.014360944258264   2: 0.014360922328703 

training_4641     6: 0.806980812369663   1: 0.055778982249028   0: 0.017155518623031   5: 0.017155421796654   9: 0.017155274492532   8: 0.017155191914485   7: 0.017155087984288   4: 0.017154693318293   2: 0.017154599249041   3: 0.017154418002985 

training_4644     5: 0.771243937015909   6: 0.025435176197345   1: 0.025427870294780   9: 0.025417390146510   7: 0.025415033682376   4: 0.025413606343623   0: 0.025412468089357   8: 0.025412451709582   3: 0.025411102356912   2: 0.025410964163606 

training_4648     6: 0.811900806365540   5: 0.020901043743185   1: 0.020900935997972   9: 0.020900149558141   0: 0.020900081043554   8: 0.020900078719379   3: 0.020899357476339   7: 0.020899256263749   4: 0.020899151288365   2: 0.020899139543776 

training_4649     1: 0.682506333078223   6: 0.111367516372958   0: 0.025790692111803   5: 0.025786614428070   4: 0.025773417705561   8: 0.025756935586182   9: 0.025755269185446   3: 0.025755131699645   2: 0.025754448817571   7: 0.025753641014542 

training_4650     6: 0.716746596907077   7: 0.082157129716264   2: 0.060667850585131   3: 0.040785549581129   4: 0.016640693339237   0: 0.016609328565753   8: 0.016598895716890   5: 0.016598094197970   9: 0.016598007620173   1: 0.016597853770377 

training_4652     1: 0.556011452005776   5: 0.203154331186975   4: 0.030125581805982   6: 0.030102414258092   8: 0.030101529971645   0: 0.030101309395262   9: 0.030101219534453   7: 0.030100893128424   3: 0.030100680075585   2: 0.030100588637805 

training_4654     6: 0.847140777753896   0: 0.034944278115460   5: 0.014744334191447   1: 0.014739926823881   9: 0.014739632069902   8: 0.014738527962814   3: 0.014738490996081   4: 0.014738291413221   7: 0.014738034118641   2: 0.014737706554656 

training_4656     6: 0.446758638169087   1: 0.345103568005450   5: 0.026027911191951   4: 0.026020939057794   0: 0.026018318075108   8: 0.026016782310629   9: 0.026014467216234   7: 0.026013358737444   3: 0.026013143245518   2: 0.026012873990786 

training_4657     5: 0.592866990366740   1: 0.271662847708696   6: 0.016936627008228   0: 0.016935631256870   9: 0.016935337974523   4: 0.016933440982614   8: 0.016933108026174   2: 0.016932055800477   7: 0.016932030655184   3: 0.016931930220492 

training_4658     6: 0.411863688593022   2: 0.221436105474184   1: 0.169494743687761   0: 0.028182120330365   5: 0.028172117624462   9: 0.028171475519001   4: 0.028170692278924   7: 0.028169934768870   8: 0.028169699184150   3: 0.028169422539261 

training_4659     1: 0.641916804648303   5: 0.160752548732699   6: 0.047527432352084   0: 0.021404108524994   9: 0.021401854668346   8: 0.021400318159768   4: 0.021399893409524   3: 0.021399671395016   7: 0.021398829347610   2: 0.021398538761654 

training_466      5: 0.747598388803353   4: 0.028049478334447   8: 0.028044252067551   3: 0.028044142008333   2: 0.028044036651367   6: 0.028044002716256   9: 0.028043977236273   7: 0.028043938399490   0: 0.028043936406061   1: 0.028043847376870 

training_4660     6: 0.770251486570679   9: 0.085003256406010   5: 0.018097701399223   1: 0.018093924278933   4: 0.018093515479976   0: 0.018092572294582   8: 0.018092332742604   7: 0.018091903010016   3: 0.018091745697270   2: 0.018091562120708 

training_4662     6: 0.632629141973017   0: 0.140596345315312   2: 0.109095286217731   1: 0.016812951543785   7: 0.016811582732523   5: 0.016811528846295   9: 0.016811214176151   4: 0.016811069387535   8: 0.016810703332029   3: 0.016810176475622 

training_4664     6: 0.709066990189558   1: 0.080470989158364   2: 0.066222110167974   0: 0.039301415419167   8: 0.017504431988066   5: 0.017492245219394   9: 0.017487662162898   4: 0.017485199797705   7: 0.017484558950746   3: 0.017484396946127 

training_4665     6: 0.351663813055946   0: 0.282629631898648   1: 0.234556498422290   7: 0.047788625826695   9: 0.028444136903401   4: 0.014917013794185   5: 0.010002465158022   2: 0.009999361031465   3: 0.009999333938704   8: 0.009999119970643 

training_4666     9: 0.693681448096800   6: 0.181871948787589   5: 0.015557428649968   1: 0.015557036289797   0: 0.015556597360848   4: 0.015556385497072   8: 0.015556124730372   7: 0.015554750448230   2: 0.015554189948628   3: 0.015554090190696 

training_467      4: 0.530068232974411   6: 0.148410273262543   5: 0.112818038310807   1: 0.067814271002839   9: 0.023484882591974   0: 0.023484830947369   2: 0.023481445415428   7: 0.023480299420783   8: 0.023480062435145   3: 0.023477663638701 

training_4671     6: 0.587691187472913   5: 0.135958241765734   2: 0.105457964098594   8: 0.059895652212361   7: 0.018508802401499   0: 0.018500346503855   4: 0.018497835291523   9: 0.018496865508039   1: 0.018496809526077   3: 0.018496295219405 

training_4675     6: 0.709466049352801   1: 0.032285372228198   0: 0.032282248249748   5: 0.032281774890994   9: 0.032281046238423   4: 0.032280832033844   8: 0.032280753317948   7: 0.032280749733408   2: 0.032280601690974   3: 0.032280572263662 

training_4678     6: 0.811348669378453   5: 0.020962902846423   4: 0.020961563501607   0: 0.020961320403316   9: 0.020961154019177   7: 0.020961116672182   8: 0.020961030814683   1: 0.020960972174818   3: 0.020960668828330   2: 0.020960601361011 

training_4679     6: 0.766182080410218   8: 0.068430354776477   0: 0.035977192936527   1: 0.029779433102059   5: 0.028579200213221   9: 0.014212363644955   3: 0.014209994446519   2: 0.014209953943061   7: 0.014209769398388   4: 0.014209657128574 

training_4680     6: 0.809188160030594   1: 0.067791140290177   0: 0.015378136026712   8: 0.015377835813577   5: 0.015377808619206   9: 0.015377502478190   7: 0.015377465130805   4: 0.015377332216510   3: 0.015377312371809   2: 0.015377307022420 

training_4681     6: 0.551237686720389   7: 0.208306579799709   2: 0.079545265657126   8: 0.053126530737935   1: 0.017964851269184   0: 0.017964650670355   5: 0.017964472787753   9: 0.017963540784893   4: 0.017963458088879   3: 0.017962963483778 

training_4682     9: 0.547900275371979   6: 0.220233450630989   4: 0.096399784549375   8: 0.019356137086808   5: 0.019354460741757   1: 0.019353624225111   0: 0.019352273985308   3: 0.019350195657719   7: 0.019350135360740   2: 0.019349662390214 

training_4686     6: 0.742803579239167   5: 0.118297893636788   1: 0.017367826786436   0: 0.017365161759914   4: 0.017362168093635   2: 0.017361322494308   3: 0.017361302393323   8: 0.017360598150096   9: 0.017360409688009   7: 0.017359737758324 

training_4687     1: 0.799577192801830   9: 0.047895693988883   6: 0.019073403767253   8: 0.019072144395585   5: 0.019070709559367   0: 0.019067058681540   3: 0.019061554567349   2: 0.019060813791309   7: 0.019060775151248   4: 0.019060653295636 

training_4689     6: 0.793366963230939   0: 0.084542393078747   7: 0.015273984825300   1: 0.015262536586946   5: 0.015259809000871   9: 0.015259132953427   2: 0.015258911936558   4: 0.015258837277602   8: 0.015258811114893   3: 0.015258619994717 

training_4690     0: 0.464185092776471   6: 0.239605409600755   2: 0.163972687896798   5: 0.029342200044444   1: 0.017154233103848   8: 0.017148440900101   7: 0.017148044556815   9: 0.017148037404202   4: 0.017147956092563   3: 0.017147897624002 

training_4691     6: 0.593157733234543   1: 0.244053801211396   8: 0.037708024184641   4: 0.031013748650709   0: 0.030547811016315   7: 0.012709644003786   9: 0.012708024330454   5: 0.012704395954057   2: 0.012698415832737   3: 0.012698401581362 

training_4692     1: 0.496615228764788   6: 0.261767072261933   0: 0.084139819319887   5: 0.082514170790871   8: 0.021853077269587   7: 0.010748227428564   9: 0.010594016027405   4: 0.010591970750602   3: 0.010588662428269   2: 0.010587754958094 

training_4695     6: 0.803581951486691   0: 0.088943834153690   5: 0.013439649995640   4: 0.013438028282589   7: 0.013434574037681   1: 0.013433215978423   9: 0.013432658710019   8: 0.013432373823862   3: 0.013431858117966   2: 0.013431855413438 

training_4696     6: 0.754917887859901   0: 0.083046881310821   1: 0.020339060411994   2: 0.020273013962016   9: 0.020265885458936   5: 0.020248782390165   3: 0.020230430525782   4: 0.020226727071248   8: 0.020226115778332   7: 0.020225215230807 

training_4697     6: 0.315796150798357   1: 0.311469624166183   9: 0.133609568560069   0: 0.085135409776442   7: 0.070026849260287   3: 0.016797358374422   2: 0.016795772686849   5: 0.016791213191384   8: 0.016789045955668   4: 0.016789007230339 

training_4698     6: 0.585977209597102   7: 0.182749637347552   9: 0.028911953755297   0: 0.028909781925225   8: 0.028909312230943   1: 0.028909027960145   5: 0.028909023627496   3: 0.028908180722188   2: 0.028908088130533   4: 0.028907784703518 

training_47       6: 0.820366478562416   0: 0.082049541387595   5: 0.012205060668357   9: 0.012198879706308   1: 0.012197866740743   8: 0.012196974046711   4: 0.012196491966150   7: 0.012196279252073   2: 0.012196276401958   3: 0.012196151267690 

training_470      5: 0.725370132113714   8: 0.105606255722968   6: 0.021179174284180   0: 0.021132090127333   1: 0.021121821189578   9: 0.021119812262137   7: 0.021118484623179   3: 0.021117792949495   4: 0.021117307877725   2: 0.021117128849691 

training_4700     7: 0.451777952337829   6: 0.364516629725394   0: 0.022968414025213   9: 0.022965366821304   5: 0.022964000849372   8: 0.022962374027572   1: 0.022961742113764   2: 0.022961196910008   4: 0.022961190039809   3: 0.022961133149735 

training_4703     6: 0.809192997845251   1: 0.067786301990761   0: 0.015378135996661   8: 0.015377836298257   5: 0.015377808599884   9: 0.015377502483507   7: 0.015377465182200   4: 0.015377332213201   3: 0.015377312369223   2: 0.015377307021053 

training_4708     6: 0.811900825526762   5: 0.020901043187039   1: 0.020900917725724   9: 0.020900149721169   0: 0.020900080930575   8: 0.020900078358312   3: 0.020899357467033   7: 0.020899256257413   4: 0.020899151285106   2: 0.020899139540868 

training_4709     6: 0.732188234806833   5: 0.082477557104846   8: 0.049020617505780   1: 0.040732099489539   0: 0.015962004806517   3: 0.015924179968212   9: 0.015923946218877   4: 0.015923906914739   7: 0.015923899124951   2: 0.015923554059706 

training_4711     6: 0.790391674042232   8: 0.090392923491430   5: 0.014903474928055   1: 0.014902803996518   0: 0.014902349819826   3: 0.014901567320521   4: 0.014901369292719   2: 0.014901307346985   7: 0.014901272469152   9: 0.014901257292563 

training_4712     6: 0.758984231777356   0: 0.082755335226982   3: 0.050028419334175   1: 0.015467876430500   7: 0.015461286657761   9: 0.015460790896278   8: 0.015460615905272   5: 0.015460613934693   2: 0.015460478220531   4: 0.015460351616452 

training_4713     6: 0.632562202485053   0: 0.140661203594005   2: 0.109097371986806   1: 0.016812948296035   7: 0.016811580799804   5: 0.016811528987953   9: 0.016811214391928   4: 0.016811069520562   8: 0.016810703438716   3: 0.016810176499137 

training_4714     6: 0.709223544370754   1: 0.080182131297926   2: 0.066226325637345   0: 0.039430163958769   8: 0.017504031325582   5: 0.017492058191940   9: 0.017487589932695   4: 0.017485199689756   7: 0.017484558739582   3: 0.017484396855650 

training_4717     6: 0.847125007975100   0: 0.034960255998213   5: 0.014744208993551   1: 0.014739904956395   9: 0.014739603537651   8: 0.014738521230047   3: 0.014738474689815   4: 0.014738285261077   7: 0.014738030813253   2: 0.014737706544898 

training_4719     6: 0.683234654394575   0: 0.136374431014958   2: 0.048647470730359   3: 0.018823019967139   1: 0.018822706319686   5: 0.018820637311255   7: 0.018819461672738   8: 0.018819397884054   4: 0.018819206679502   9: 0.018819014025735 

training_4720     9: 0.411441837974307   8: 0.299137073155330   4: 0.068587544566771   1: 0.066875431186687   5: 0.046417026193015   6: 0.041694541757791   7: 0.016476727106987   0: 0.016457671290367   3: 0.016457394892137   2: 0.016454751876607 

training_4729     5: 0.455112333761607   8: 0.335096750181807   4: 0.026229109810563   6: 0.026223476498747   1: 0.026223378723096   0: 0.026223232968523   9: 0.026223152504789   3: 0.026223020619886   2: 0.026222823295355   7: 0.026222721635627 

training_473      2: 0.449990229240755   5: 0.381946364001172   3: 0.021025780658815   6: 0.021018642286415   0: 0.021008160565558   1: 0.021007193344613   9: 0.021002625909121   4: 0.021000625711858   8: 0.021000490082355   7: 0.020999888199337 

training_4732     5: 0.800965138874100   2: 0.062927429001859   4: 0.017014900272876   6: 0.017014208376801   9: 0.017013321403643   8: 0.017013171086928   1: 0.017013150993699   0: 0.017013147430570   7: 0.017012882869842   3: 0.017012649689680 

training_4733     1: 0.336063456697366   5: 0.270700411620631   0: 0.270186869163543   7: 0.033579106257932   4: 0.014933154362365   6: 0.014911838992738   9: 0.014907004807061   3: 0.014906237121726   2: 0.014906026445870   8: 0.014905894530770 

training_4735     6: 0.518436791211560   1: 0.372020378539758   8: 0.013693405213838   0: 0.013693340455756   5: 0.013693175882424   9: 0.013692851050323   4: 0.013692528840301   7: 0.013692522272355   3: 0.013692507233366   2: 0.013692499300320 

training_4739     6: 0.789382196017151   8: 0.039295386280680   7: 0.038763213717087   0: 0.036426173352929   4: 0.016244484398105   5: 0.015983244516948   3: 0.015981882719989   1: 0.015974907060512   9: 0.015974591674919   2: 0.015973920261679 

training_474      0: 0.787928908011252   9: 0.041684294825462   6: 0.021320432146740   5: 0.021313661476191   7: 0.021299892816282   8: 0.021293333236523   1: 0.021290965403769   2: 0.021289692045079   3: 0.021289476730864   4: 0.021289343307838 

training_4740     6: 0.800023247587971   8: 0.087073022479696   5: 0.014114454297235   1: 0.014113766458924   0: 0.014113342429429   3: 0.014112579431206   2: 0.014112476822789   4: 0.014112388562167   9: 0.014112371952035   7: 0.014112349978547 

training_4741     6: 0.830980227348809   9: 0.018781256240415   0: 0.018781058432111   8: 0.018780142358170   5: 0.018779999937464   7: 0.018779918332750   1: 0.018779727406026   2: 0.018779314679353   4: 0.018779208345615   3: 0.018779146919286 

training_4742     6: 0.697415322736590   8: 0.101916271941650   1: 0.082516105315185   0: 0.016890495914726   5: 0.016882593076600   4: 0.016880141898453   2: 0.016876166858872   9: 0.016875551446347   3: 0.016875340083378   7: 0.016872010728200 

training_4743     6: 0.501905013579286   5: 0.271986521995670   4: 0.028267727435573   9: 0.028266368914135   8: 0.028265942659598   0: 0.028262360294049   1: 0.028262059646946   7: 0.028262053967734   2: 0.028261255258371   3: 0.028260696248638 

training_4744     6: 0.733506604638613   0: 0.115950449937485   9: 0.028334325809788   2: 0.028264716362997   8: 0.025438127030011   3: 0.019417001580752   7: 0.012347508147448   1: 0.012282355237443   5: 0.012229960396406   4: 0.012228950859056 

training_4745     4: 0.725129763518528   8: 0.070012339547243   1: 0.068815657251021   0: 0.019455496281939   5: 0.019436041313894   6: 0.019432121284709   2: 0.019431289309878   9: 0.019429407423124   7: 0.019428984051262   3: 0.019428900018401 

training_4747     5: 0.794475312696937   4: 0.022839021540724   6: 0.022836373161830   0: 0.022836091757825   8: 0.022835639002292   9: 0.022835585856920   1: 0.022835553444542   3: 0.022835511741367   2: 0.022835484477133   7: 0.022835426320430 

training_4748     0: 0.717756174943912   6: 0.127277715955972   5: 0.019378168741841   1: 0.019376960739367   9: 0.019370083710077   4: 0.019368999119100   2: 0.019368494825445   7: 0.019368124965466   8: 0.019367686027171   3: 0.019367590971648 

training_475      8: 0.514759458230539   6: 0.332143032612329   0: 0.048450409545718   1: 0.014955297701926   5: 0.014951091731295   9: 0.014949166736968   4: 0.014948620969312   2: 0.014947869224328   7: 0.014947643622469   3: 0.014947409625116 

training_4751     5: 0.389609984195301   3: 0.291833576433188   6: 0.128223187108905   0: 0.083536029353331   1: 0.017807066907679   2: 0.017799823023191   4: 0.017798275736783   9: 0.017797439154487   8: 0.017797389588865   7: 0.017797228498271 

training_4755     4: 0.412944191712082   5: 0.384628925599922   7: 0.067747092921575   6: 0.019247581012242   9: 0.019242398170282   2: 0.019238575370979   0: 0.019237989631132   8: 0.019237928366668   1: 0.019237916420204   3: 0.019237400794915 

training_4756     0: 0.356795975660813   6: 0.230535433253664   5: 0.216502389371832   7: 0.094067008332981   3: 0.017017728184210   1: 0.017017601406538   4: 0.017016772781369   9: 0.017015842833361   2: 0.017015642569411   8: 0.017015605605819 

training_4758     6: 0.737419293292887   5: 0.029190539267313   1: 0.029189467752845   4: 0.029184533052923   0: 0.029175164966208   8: 0.029169160945350   2: 0.029169022090023   3: 0.029167867271552   9: 0.029167501076079   7: 0.029167450284821 

training_4759     5: 0.705582936870948   7: 0.032729959043168   0: 0.032713263000511   4: 0.032712563411857   1: 0.032712268349120   8: 0.032710665543575   9: 0.032710273954081   6: 0.032710081723824   2: 0.032709356764768   3: 0.032708631338147 

training_4761     0: 0.742911082869154   6: 0.028573276935463   1: 0.028567368142268   5: 0.028565414759723   7: 0.028564557936094   4: 0.028564157570795   9: 0.028563888614784   2: 0.028563671121930   3: 0.028563292402237   8: 0.028563289647552 

training_4763     6: 0.757178265482332   9: 0.026987366758349   8: 0.026984516616892   0: 0.026980323979499   7: 0.026979107401362   1: 0.026979048213209   4: 0.026978013854146   2: 0.026977908473760   5: 0.026977800170460   3: 0.026977649049990 

training_4765     4: 0.747372751933254   2: 0.079122111092192   5: 0.021692920651560   9: 0.021690605724825   1: 0.021687804976803   6: 0.021687668031199   0: 0.021687498417557   7: 0.021686287343577   3: 0.021686233500448   8: 0.021686118328584 

training_4768     9: 0.725212309033427   8: 0.096314955744881   6: 0.022325227942222   5: 0.022307558828959   0: 0.022307515089953   7: 0.022306740610418   1: 0.022306612091727   4: 0.022306392313275   3: 0.022306349131702   2: 0.022306339213435 

training_4769     6: 0.374916701874251   7: 0.258237775106056   0: 0.187321102999195   3: 0.083213206504823   9: 0.016057197028228   1: 0.016055627186099   5: 0.016052346871338   8: 0.016049977207836   2: 0.016048713937967   4: 0.016047351284206 

training_4770     6: 0.461081034583728   5: 0.334582151013939   9: 0.025555909000621   4: 0.025543543194134   8: 0.025541339520851   0: 0.025540045376345   7: 0.025539795349650   1: 0.025539466340286   2: 0.025538419621022   3: 0.025538295999424 

training_4771     6: 0.823804147216457   0: 0.050783422946031   7: 0.028018231707010   9: 0.013960518350710   1: 0.013914949370829   8: 0.013905978664953   3: 0.013904548833024   5: 0.013904180107193   4: 0.013902943583220   2: 0.013901079220571 

training_4772     0: 0.755176607926968   1: 0.089540757690733   6: 0.033305751333638   5: 0.017428332833665   8: 0.017425120260812   4: 0.017424857044435   9: 0.017424758472790   2: 0.017424651976383   7: 0.017424643664090   3: 0.017424518796486 

training_4773     5: 0.489536754056095   3: 0.298252398721222   6: 0.026532486084317   0: 0.026528924540411   9: 0.026528544805969   4: 0.026525897338879   1: 0.026525323617427   8: 0.026525144004302   7: 0.026522711152165   2: 0.026521815679213 

training_4774     6: 0.447034294047801   5: 0.434798702497885   1: 0.014774171711602   0: 0.014772439517145   4: 0.014770889827800   2: 0.014770341038536   8: 0.014769881493579   9: 0.014769825581513   7: 0.014769807389697   3: 0.014769646894442 

training_4775     5: 0.799385276996720   4: 0.022295534728505   6: 0.022290511204021   8: 0.022290319660252   0: 0.022290158938270   1: 0.022290028449573   9: 0.022289620384763   2: 0.022289542594059   7: 0.022289523668803   3: 0.022289483375035 

training_4776     9: 0.350860757674853   3: 0.298407562867073   5: 0.180460450680105   6: 0.024336634889599   1: 0.024330934343317   0: 0.024328655845500   4: 0.024321657735423   2: 0.024317918106739   8: 0.024317847313397   7: 0.024317580543992 

training_4777     5: 0.781465717339119   0: 0.056047989971800   7: 0.054947418311173   1: 0.015365870882498   9: 0.015364100199815   6: 0.015362905795010   4: 0.015362776282528   8: 0.015361405900367   2: 0.015360927621115   3: 0.015360887696576 

training_4778     6: 0.780777656979276   1: 0.096729873931415   5: 0.015312538151721   8: 0.015312402726671   0: 0.015312052609349   9: 0.015311192470417   3: 0.015311166837244   2: 0.015311081715682   7: 0.015311075509656   4: 0.015310959068568 

training_4779     5: 0.646494567161997   6: 0.190227518770181   1: 0.020418046750668   2: 0.020413966779162   0: 0.020413798257431   7: 0.020407529606366   9: 0.020406553920876   8: 0.020406210198291   3: 0.020405979348117   4: 0.020405829206911 

training_478      0: 0.675640571246561   4: 0.163297747403754   2: 0.039379402203070   6: 0.017532458488985   1: 0.017374302874125   5: 0.017360496577610   3: 0.017354986320624   8: 0.017353935538558   9: 0.017353388447797   7: 0.017352710898916 

training_4780     5: 0.550530329058798   0: 0.262788186883498   1: 0.023336315326277   6: 0.023335557489662   3: 0.023335510842664   4: 0.023335429057072   2: 0.023334913939916   8: 0.023334658771765   9: 0.023334577250960   7: 0.023334521379388 

training_4781     1: 0.444365362135864   6: 0.442314915936764   0: 0.014217414649608   5: 0.014158342514827   9: 0.014157624059756   4: 0.014157507436845   8: 0.014157410447628   2: 0.014157232704470   7: 0.014157170718154   3: 0.014157019396085 

training_4782     4: 0.535852207672795   3: 0.221424509324327   5: 0.030346069206016   2: 0.030344022981064   7: 0.030339433413868   0: 0.030338982139174   1: 0.030338907534916   8: 0.030338903602419   9: 0.030338524922476   6: 0.030338439202946 

training_4783     9: 0.716893473901088   4: 0.094735082959891   6: 0.051947307722243   8: 0.019502623492380   1: 0.019498071097373   5: 0.019493344140232   0: 0.019484835131640   2: 0.019482931475383   3: 0.019482721290947   7: 0.019479608788823 

training_4785     6: 0.522272495612724   7: 0.341039568126895   0: 0.029789226814467   8: 0.023096652292876   2: 0.014029413363792   5: 0.014004162841153   1: 0.014001401752789   9: 0.013923432369298   4: 0.013921828756772   3: 0.013921818069233 

training_4787     6: 0.750270935808592   7: 0.070142671708069   8: 0.022450008495412   3: 0.022449587732300   5: 0.022448797158796   9: 0.022448219785766   0: 0.022447988921966   1: 0.022447435275002   4: 0.022447340719352   2: 0.022447014394745 

training_4788     5: 0.840445357811904   4: 0.017731530808365   6: 0.017728298187917   0: 0.017728241827889   1: 0.017728032712906   8: 0.017727803654947   9: 0.017727718376104   7: 0.017727699095046   2: 0.017727681776245   3: 0.017727635748678 

training_4791     5: 0.620963281085496   6: 0.097077687294960   9: 0.084466532607686   2: 0.084150797869498   4: 0.018892496529858   0: 0.018890585118316   1: 0.018890085092634   8: 0.018889617622034   3: 0.018889483612264   7: 0.018889433167253 

training_4792     5: 0.606872794374632   3: 0.112904339627773   7: 0.089311575373838   8: 0.054812662715746   9: 0.051624453968309   2: 0.016911581911511   1: 0.016903027164640   0: 0.016890149519825   6: 0.016888858419198   4: 0.016880556924528 

training_4794     5: 0.831667703364048   4: 0.018706085282885   6: 0.018704541822732   1: 0.018703925634590   0: 0.018703320119337   7: 0.018702964958512   8: 0.018702913522069   2: 0.018702867114222   9: 0.018702858699949   3: 0.018702819481657 

training_4795     1: 0.616244198371711   6: 0.175444827493948   5: 0.108872320478095   9: 0.014237942642070   0: 0.014208514022766   4: 0.014200886362300   3: 0.014198994509102   8: 0.014198748861818   2: 0.014197043467945   7: 0.014196523790247 

training_4796     5: 0.477097166797839   0: 0.285966910855519   2: 0.103929063296765   4: 0.019062423624468   6: 0.018993757339725   1: 0.018991767844059   7: 0.018990013655344   9: 0.018989865308262   8: 0.018989717935822   3: 0.018989313342196 

training_4797     4: 0.713401938754943   3: 0.098026281007166   5: 0.023577663275295   2: 0.023571590591783   6: 0.023571575508982   8: 0.023570761758359   7: 0.023570623238688   9: 0.023570576747037   0: 0.023569704977167   1: 0.023569284140579 

training_4798     0: 0.759029285515131   9: 0.093531297528482   6: 0.018486595789048   2: 0.018466315993917   1: 0.018427951536132   5: 0.018417881200816   8: 0.018410949686114   4: 0.018410421392386   7: 0.018409715767267   3: 0.018409585590708 

training_48       6: 0.687847580331292   7: 0.147743151632125   8: 0.020556281441350   9: 0.020552407294931   0: 0.020552146984618   5: 0.020551678855433   4: 0.020549845939182   1: 0.020549253738266   2: 0.020548995876571   3: 0.020548657906234 

training_480      5: 0.579378207531523   0: 0.166143113279499   2: 0.068637633476354   1: 0.064154620295968   6: 0.020290139497332   4: 0.020279405653766   3: 0.020279340504349   9: 0.020279302526161   8: 0.020279160221903   7: 0.020279077013145 

training_4801     5: 0.784076023134186   6: 0.023992688412108   0: 0.023991802184599   9: 0.023991719757559   4: 0.023991495101522   1: 0.023991401170151   3: 0.023991397154472   8: 0.023991224186448   2: 0.023991173133323   7: 0.023991075765631 

training_4803     5: 0.722641369707156   4: 0.116076073594010   0: 0.020163036386161   6: 0.020160842759762   8: 0.020160000841107   9: 0.020159815654164   3: 0.020159747255629   1: 0.020159737075745   2: 0.020159696207943   7: 0.020159680518323 

training_4804     0: 0.835966811031199   5: 0.018236804190461   4: 0.018227035198063   7: 0.018226971106012   6: 0.018225355513941   1: 0.018224135239848   2: 0.018223594120339   9: 0.018223409146823   8: 0.018223254725463   3: 0.018222629727851 

training_4805     5: 0.722316684889202   4: 0.030858207103563   6: 0.030853392460714   1: 0.030853332446140   3: 0.030853239367824   2: 0.030853105785053   7: 0.030853075086843   8: 0.030853065471755   0: 0.030852988352486   9: 0.030852909036419 

training_4806     1: 0.773651886730948   4: 0.063677617788998   0: 0.038747418110265   2: 0.031525791176850   5: 0.015637455374924   6: 0.015356271989425   7: 0.015355771461605   8: 0.015352729966102   3: 0.015352149906437   9: 0.015342907494447 

training_4807     1: 0.698180321953026   0: 0.162067967998454   9: 0.017481554316606   6: 0.017480924905434   5: 0.017474147733930   8: 0.017465725100432   3: 0.017462893353348   7: 0.017462385324684   4: 0.017462301667818   2: 0.017461777646270 

training_4809     6: 0.654785162900133   0: 0.169740798315433   1: 0.088690062429931   8: 0.032641030940931   3: 0.015665575188146   4: 0.007695721701936   7: 0.007695683391969   9: 0.007695516927358   5: 0.007695419096293   2: 0.007695029107870 

training_4810     5: 0.479866901324028   6: 0.345597848060286   7: 0.082483217132773   4: 0.013581307221140   0: 0.013164125496157   9: 0.013074411644035   1: 0.013058850372809   8: 0.013058149338626   2: 0.013057770371846   3: 0.013057419038299 

training_4812     0: 0.778317163393881   1: 0.056403980676009   9: 0.020672971576849   5: 0.020670816866582   8: 0.020659349093944   6: 0.020657786201087   4: 0.020657761793103   2: 0.020653857378457   7: 0.020653171868169   3: 0.020653141151921 

training_4814     5: 0.821134086447230   6: 0.019876217798069   4: 0.019875713183346   0: 0.019874185246710   1: 0.019873937292314   3: 0.019873895751515   9: 0.019873222306575   8: 0.019873129786263   7: 0.019872825446834   2: 0.019872786741145 

training_4816     6: 0.675812904559649   3: 0.099771485594513   8: 0.084961400325911   7: 0.048144343449205   9: 0.024424008340192   2: 0.013442456783589   5: 0.013394468950231   0: 0.013356741474631   1: 0.013352220645937   4: 0.013339969876144 

training_4818     0: 0.603029660471010   1: 0.180673860014962   8: 0.080244009048326   5: 0.019439517064158   4: 0.019438275024778   6: 0.019436179340508   7: 0.019436021785366   9: 0.019434288187492   2: 0.019434143713487   3: 0.019434045349912 

training_4819     5: 0.799766883187132   6: 0.022260558717426   4: 0.022248802444333   0: 0.022247888968912   1: 0.022246993937697   8: 0.022245970098237   7: 0.022245820788988   9: 0.022245782427079   3: 0.022245771538904   2: 0.022245527891291 

training_4820     5: 0.676964405847023   8: 0.118535879518190   0: 0.025586661163867   6: 0.025580096454297   9: 0.025565321379505   4: 0.025555511684723   2: 0.025553765550600   1: 0.025552951630985   3: 0.025552756971697   7: 0.025552649799113 

training_4821     5: 0.755191310979678   3: 0.027201737536681   4: 0.027201279199963   8: 0.027200900724398   0: 0.027200880817151   6: 0.027200862351071   2: 0.027200781118127   1: 0.027200772475805   7: 0.027200755468009   9: 0.027200719329118 

training_4822     9: 0.396864054964835   6: 0.390695205993471   8: 0.060653413669023   3: 0.052109382297463   1: 0.016634910652478   0: 0.016610397093852   5: 0.016608787316860   7: 0.016608691442796   4: 0.016607789176424   2: 0.016607367392798 

training_4824     6: 0.550312485233253   0: 0.246905780081318   1: 0.124228106239538   7: 0.011229735929782   9: 0.011221206667648   5: 0.011220994561491   2: 0.011220677582578   8: 0.011220673832972   3: 0.011220195829642   4: 0.011220144041778 

training_4825     6: 0.788143845051121   9: 0.041905555216011   1: 0.039614249125759   8: 0.038464808724798   2: 0.015344026747518   0: 0.015306945805272   4: 0.015306574095355   5: 0.015305275498114   7: 0.015304624773815   3: 0.015304094962237 

training_4827     5: 0.654729352387675   6: 0.164003005488785   8: 0.062651897536439   4: 0.016946626238103   1: 0.016945174489827   0: 0.016944967011748   7: 0.016944914298844   2: 0.016944877148075   9: 0.016944628184054   3: 0.016944557216449 

training_4829     6: 0.832274568593531   9: 0.037001149648520   8: 0.016350481952897   0: 0.016343173410484   1: 0.016340412708184   5: 0.016339185482984   7: 0.016338056599597   4: 0.016337708614643   3: 0.016337670884435   2: 0.016337592104726 

training_483      4: 0.765763576355171   5: 0.026034221278158   6: 0.026026977837494   8: 0.026025385584279   9: 0.026025193500053   0: 0.026025154860909   3: 0.026024989573621   7: 0.026024914596892   2: 0.026024836694442   1: 0.026024749718981 

training_4831     1: 0.562015892255190   9: 0.214699102851441   2: 0.027925269317767   6: 0.027918213534992   7: 0.027908659591696   5: 0.027908465597533   8: 0.027907001897583   0: 0.027906873139076   3: 0.027905896677045   4: 0.027904625137677 

training_4832     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_4833     6: 0.432781957412528   8: 0.380550145676602   5: 0.051498410060306   0: 0.034783195771011   3: 0.016738440363833   9: 0.016737628852334   2: 0.016731027878278   1: 0.016727143116373   4: 0.016726167153073   7: 0.016725883715663 

training_4835     6: 0.721117441772292   0: 0.105119596111099   1: 0.062864760438460   4: 0.031178817444094   5: 0.013287119223347   8: 0.013286716741681   2: 0.013286614191275   9: 0.013286551389835   7: 0.013286235340124   3: 0.013286147347792 

training_484      5: 0.807451105913773   4: 0.021398003354146   8: 0.021394296670368   0: 0.021393922573172   3: 0.021393838137933   6: 0.021393816106734   1: 0.021393797232173   9: 0.021393770725784   2: 0.021393766038180   7: 0.021393683247736 

training_4841     9: 0.512449055608545   5: 0.306211359507463   0: 0.022673142186276   1: 0.022672305837451   6: 0.022671210368586   7: 0.022665806895044   4: 0.022664857069934   8: 0.022664667178223   2: 0.022664508521827   3: 0.022663086826651 

training_4843     6: 0.475916746390575   4: 0.320793062307664   5: 0.025419011141981   0: 0.025414191297721   1: 0.025413311611426   8: 0.025409771166630   9: 0.025409302742089   2: 0.025408964222904   7: 0.025407877924951   3: 0.025407761194058 

training_4845     6: 0.784631258384610   9: 0.057513326738509   1: 0.035749179999972   8: 0.017575487723880   0: 0.017461376702964   7: 0.017419662502580   5: 0.017413440503947   4: 0.017412869076110   2: 0.017411713937924   3: 0.017411684429502 

training_4848     1: 0.679793964786675   7: 0.133837241972499   4: 0.054050327812288   2: 0.046193687813329   6: 0.014384297207425   3: 0.014363597698728   5: 0.014353639764555   0: 0.014348055554717   8: 0.014339671223103   9: 0.014335516166681 

training_4850     0: 0.526330203957274   8: 0.232034717855565   6: 0.081840087140875   5: 0.022833608320023   1: 0.022829615573240   4: 0.022829025494695   7: 0.022826038476791   2: 0.022825800560280   9: 0.022825766986549   3: 0.022825135634707 

training_486      6: 0.588584823746255   8: 0.272596018832313   0: 0.017357583960208   7: 0.017355135810801   5: 0.017352752282545   9: 0.017351676188978   1: 0.017351439300739   4: 0.017350644080082   2: 0.017350019213600   3: 0.017349906584479 

training_4867     6: 0.762807327632815   8: 0.076273259149991   0: 0.028176257072401   1: 0.027865004555362   9: 0.026166797911770   3: 0.015886362152066   2: 0.015727769712237   7: 0.015715188874417   5: 0.015706957872613   4: 0.015675075066328 

training_488      6: 0.774328106912644   2: 0.061369267496173   4: 0.040251647205158   1: 0.017772346677139   0: 0.017728773439852   5: 0.017723869162877   9: 0.017711944371295   7: 0.017707680226326   8: 0.017706009811357   3: 0.017700354697178 

training_4881     6: 0.737051497565032   9: 0.110377559954239   5: 0.019072558064618   8: 0.019072190386196   0: 0.019071830397077   2: 0.019071106687275   1: 0.019071100982321   7: 0.019071012122996   3: 0.019070766731965   4: 0.019070377108282 

training_4882     6: 0.653566001695944   0: 0.172413231666004   1: 0.059742889249165   8: 0.034984923346078   5: 0.013216177030505   9: 0.013215550712375   7: 0.013215518363056   4: 0.013215379231197   3: 0.013215215662148   2: 0.013215113043529 

training_4884     6: 0.618779499773604   1: 0.215230291793928   2: 0.031767257651987   5: 0.019179417978130   0: 0.019176658506598   9: 0.019176309391528   4: 0.019174617005994   8: 0.019172233280919   7: 0.019171945191491   3: 0.019171769425820 

training_4887     6: 0.763759201782984   7: 0.061514007123290   1: 0.021850563384225   5: 0.021843574790198   0: 0.021841240059679   4: 0.021839859568511   9: 0.021838161071503   2: 0.021838034237142   8: 0.021837859689192   3: 0.021837498293275 

training_4889     3: 0.585744522794999   9: 0.176036504094353   0: 0.029792720117322   5: 0.029780950299575   6: 0.029780915003930   1: 0.029774881932403   4: 0.029774777293784   2: 0.029771697742458   8: 0.029771556263228   7: 0.029771474457949 

training_489      6: 0.722207579910122   1: 0.105578526173717   8: 0.076433130194820   5: 0.013691132699343   0: 0.013684637999455   9: 0.013681754146774   2: 0.013681413245149   4: 0.013680914869552   7: 0.013680654077156   3: 0.013680256683912 

training_4890     6: 0.766759611881726   7: 0.061309703979483   5: 0.033228604646357   3: 0.019841679625223   9: 0.019813444085250   4: 0.019813301420558   1: 0.019811793321505   0: 0.019811684999668   2: 0.019805260952162   8: 0.019804915088069 

training_4892     5: 0.736886882473246   8: 0.100178843233742   9: 0.020370852391142   0: 0.020370483715215   4: 0.020369012559708   2: 0.020366304771091   6: 0.020364969421589   3: 0.020364271001590   1: 0.020364228240945   7: 0.020364152191732 

training_4893     0: 0.393856123879851   5: 0.223556447611035   6: 0.134265378237984   1: 0.095360798538855   3: 0.087685355081858   8: 0.013160615188898   9: 0.013045759425296   4: 0.013025449956790   2: 0.013022212813281   7: 0.013021859266151 

training_4894     5: 0.794096412663330   6: 0.022889892159901   0: 0.022887191701676   1: 0.022876216259581   4: 0.022876086585447   7: 0.022875606393320   8: 0.022875213387935   9: 0.022875087180024   2: 0.022874187489397   3: 0.022874106179389 

training_4898     6: 0.693023614296378   9: 0.130491947210190   1: 0.053601587176356   0: 0.030709849781634   5: 0.015400295330932   8: 0.015357957097703   3: 0.015355637166781   7: 0.015353806456559   4: 0.015352972943816   2: 0.015352332539651 

training_49       7: 0.415907340317219   6: 0.296011837202254   5: 0.154807856217750   8: 0.019042544022873   0: 0.019040540266178   4: 0.019039517344521   1: 0.019039215737661   9: 0.019037437619594   3: 0.019037164367778   2: 0.019036546904173 

training_490      4: 0.785933806881068   5: 0.049187167445507   1: 0.048002734203953   6: 0.016715550150686   0: 0.016711917073777   9: 0.016690320902738   3: 0.016689909392450   8: 0.016689770625284   2: 0.016689422366237   7: 0.016689400958298 

training_4900     5: 0.760179436658813   6: 0.026647221756091   3: 0.026646975431554   0: 0.026646894436564   4: 0.026646817473144   1: 0.026646667886008   2: 0.026646568275979   9: 0.026646506343009   8: 0.026646477965707   7: 0.026646433773131 

training_4901     5: 0.727873403960530   3: 0.073439295529534   6: 0.073202557788352   4: 0.017929440477907   0: 0.017926206511125   9: 0.017926042457704   1: 0.017925881011741   8: 0.017925799105032   7: 0.017925732095440   2: 0.017925641062634 

training_4903     6: 0.653002848759664   0: 0.160962738221429   3: 0.056054571274980   1: 0.018572516549448   9: 0.018568899968285   8: 0.018568460769092   5: 0.018567722567615   7: 0.018567466575388   2: 0.018567413220195   4: 0.018567362093903 

training_4904     1: 0.720771413277377   6: 0.031029591489506   0: 0.031028001236580   7: 0.031025811741160   5: 0.031025802501971   4: 0.031024794621445   8: 0.031024006695263   9: 0.031023743109316   2: 0.031023689367056   3: 0.031023145960326 

training_4905     6: 0.795508073817623   7: 0.038764388823165   1: 0.036882141337720   0: 0.031305866698898   8: 0.016261188025792   5: 0.016257066589624   3: 0.016256038942470   4: 0.016255236104473   9: 0.016255122795656   2: 0.016254876864579 

training_4908     1: 0.552000740721489   6: 0.189785007815162   2: 0.123119953887058   0: 0.019311740497941   5: 0.019301116843638   9: 0.019297034554568   4: 0.019296414025279   7: 0.019296200987208   8: 0.019295997325089   3: 0.019295793342567 

training_4910     1: 0.662287201416522   5: 0.215593996610371   7: 0.015271924906424   6: 0.015269897850814   0: 0.015266579593333   2: 0.015262372475022   4: 0.015262151709339   8: 0.015262117880168   3: 0.015261992265472   9: 0.015261765292536 

training_4911     5: 0.760744053151203   4: 0.026587822033930   0: 0.026584774809821   1: 0.026584540042053   3: 0.026583364730638   6: 0.026583363833224   9: 0.026583290055645   8: 0.026582999643294   2: 0.026582938525547   7: 0.026582853174646 

training_4914     4: 0.734056368859736   2: 0.065811185985701   0: 0.064235613642622   5: 0.019422762621115   6: 0.019413790373221   1: 0.019412295944672   8: 0.019412141879805   3: 0.019412051026886   9: 0.019411946292827   7: 0.019411843373416 

training_4918     1: 0.618491029386537   7: 0.224257012296962   6: 0.019659736617477   5: 0.019658384142766   0: 0.019657430843883   4: 0.019655429821939   9: 0.019655411028143   8: 0.019655406710637   2: 0.019655317823542   3: 0.019654841328114 

training_4920     4: 0.794789195781881   5: 0.022805827331298   6: 0.022800974919966   1: 0.022800880864163   0: 0.022800796763901   8: 0.022800564997052   2: 0.022800557378121   3: 0.022800497223640   9: 0.022800432141423   7: 0.022800272598555 

training_4922     5: 0.832756316220392   9: 0.018597807234667   6: 0.018595207604705   0: 0.018582617699204   1: 0.018579758324912   8: 0.018579102813029   7: 0.018578014037382   4: 0.018577861839167   2: 0.018576757380969   3: 0.018576556845572 

training_4925     6: 0.753678164990197   4: 0.027374146606660   0: 0.027369603531692   2: 0.027368687071675   9: 0.027368681052991   1: 0.027368271744407   8: 0.027368266837839   5: 0.027368172497118   3: 0.027368007024596   7: 0.027367998642825 

training_4929     8: 0.765834195108703   6: 0.026027242269787   9: 0.026020634954530   5: 0.026018337720040   1: 0.026017917543149   7: 0.026017614253574   0: 0.026016812042899   4: 0.026016039883136   3: 0.026015707124435   2: 0.026015499099746 

training_4930     5: 0.666852025993778   4: 0.126582153469425   6: 0.057932854865420   3: 0.056440506676105   0: 0.015373560208387   2: 0.015364392218162   9: 0.015364122682024   1: 0.015363648286126   8: 0.015363372636465   7: 0.015363362964109 

training_4933     1: 0.449089073922559   7: 0.343498024134785   0: 0.063249417664762   6: 0.037076963935523   5: 0.023987257332521   2: 0.017266222988158   9: 0.016608966646844   4: 0.016439302244310   3: 0.016397650042849   8: 0.016387121087690 

training_4934     4: 0.761509610294495   6: 0.071423973134481   0: 0.020925727025414   7: 0.020912820359082   9: 0.020884985416057   5: 0.020872078187332   8: 0.020870211455206   2: 0.020866942819904   3: 0.020866876365789   1: 0.020866774942241 

training_4937     5: 0.629609940473411   1: 0.204387253070147   6: 0.020757604333537   0: 0.020753253155832   9: 0.020749069629799   2: 0.020748979277164   8: 0.020748859886083   7: 0.020748577633366   3: 0.020748268631320   4: 0.020748193909340 

training_4938     6: 0.870207808235151   5: 0.014426617055231   8: 0.014422651080419   4: 0.014422537379446   9: 0.014422182349419   1: 0.014420770954780   0: 0.014420512980454   7: 0.014419306776123   2: 0.014418970227137   3: 0.014418642961840 

training_4939     6: 0.606705144580558   3: 0.134064774387567   7: 0.126817433238479   8: 0.030327503339020   2: 0.017126798204821   1: 0.016993039766708   5: 0.016993017764134   0: 0.016991902938281   9: 0.016990238402973   4: 0.016990147377459 

training_494      5: 0.799179690751177   0: 0.022320436414799   4: 0.022314413306693   1: 0.022313804281371   3: 0.022312257560492   6: 0.022312202508502   2: 0.022311876774664   9: 0.022311848924708   8: 0.022311807992323   7: 0.022311661485271 

training_4941     6: 0.610045340050007   0: 0.255653768431709   9: 0.051370991173999   7: 0.011863926690562   1: 0.011847079160255   2: 0.011844837094287   5: 0.011843852670063   8: 0.011843541553850   3: 0.011843391898963   4: 0.011843271276305 

training_4944     6: 0.539677288565217   0: 0.348274402876240   5: 0.029673041743709   1: 0.026349563496924   8: 0.014538327353582   7: 0.008302505195946   9: 0.008297768119187   2: 0.008296347817495   4: 0.008295644157982   3: 0.008295110673717 

training_4951     6: 0.531330086746066   2: 0.182167983623226   5: 0.165904636928361   0: 0.040057728730989   1: 0.017517017927198   4: 0.013367444179696   3: 0.012445339310126   7: 0.012408270834258   9: 0.012402045581749   8: 0.012399446138330 

training_4952     9: 0.485548020537747   2: 0.187348214324368   1: 0.145905211968154   6: 0.025896348373595   0: 0.025892442647166   5: 0.025886878461080   4: 0.025882507148115   8: 0.025880847845046   7: 0.025880271943753   3: 0.025879256750976 

training_4953     6: 0.807030601511010   8: 0.046534790470446   1: 0.035242904350937   0: 0.034074570458679   9: 0.020512779645422   3: 0.017130626987215   2: 0.009875222823925   7: 0.009871677569756   5: 0.009865946219682   4: 0.009860879962929 

training_4954     4: 0.657165472716914   5: 0.150448867430038   0: 0.024080038306607   8: 0.024055261161411   3: 0.024041876040568   9: 0.024041857007345   2: 0.024041743347312   1: 0.024041683729217   7: 0.024041614210019   6: 0.024041586050570 

training_4955     3: 0.521852213455370   0: 0.280735783638036   9: 0.056994830988529   6: 0.020076850579472   5: 0.020059729727843   4: 0.020057845591648   1: 0.020056810980077   8: 0.020056641255016   7: 0.020054687784762   2: 0.020054605999247 

training_4956     5: 0.755577528798031   3: 0.027158600010717   4: 0.027158301920665   6: 0.027158064279904   8: 0.027158035393497   0: 0.027157989393283   1: 0.027157930880188   2: 0.027157899841990   7: 0.027157855780591   9: 0.027157793701135 

training_4959     0: 0.728486230718355   5: 0.030177123568882   1: 0.030169586163104   6: 0.030168959751455   4: 0.030168512185146   9: 0.030166367539093   3: 0.030166051120804   2: 0.030165907867157   7: 0.030165686236134   8: 0.030165574849870 

training_496      1: 0.682303519956874   6: 0.182930617575933   0: 0.034951494914167   5: 0.014346752269415   9: 0.014346601217350   3: 0.014326790339328   8: 0.014198911455682   4: 0.014198852477945   2: 0.014198260473980   7: 0.014198199319327 

training_4960     4: 0.734007098649967   0: 0.029581477437865   5: 0.029557174185973   6: 0.029551667018305   1: 0.029551365198693   3: 0.029550520925591   9: 0.029550297035731   2: 0.029550154819105   8: 0.029550152582255   7: 0.029550092146515 

training_4962     6: 0.651358046487850   2: 0.141348346187618   0: 0.082193600112775   4: 0.033079208650781   5: 0.015347704733754   9: 0.015337493842148   8: 0.015334981814624   1: 0.015333769523316   7: 0.015333618571720   3: 0.015333230075412 

training_4963     7: 0.498482176160658   0: 0.321795337743638   5: 0.059015023528749   6: 0.017254623074755   2: 0.017245873065055   1: 0.017243224729410   3: 0.017242259471044   4: 0.017241749898501   9: 0.017241273823354   8: 0.017238458504837 

training_4964     0: 0.605541714096399   1: 0.262256292466106   6: 0.016527923933096   5: 0.016526785405131   4: 0.016525204514058   8: 0.016524658399664   2: 0.016524444141024   7: 0.016524385684432   9: 0.016524357346572   3: 0.016524234013519 

training_4965     6: 0.684360239560813   7: 0.196225461119110   0: 0.014929088275414   5: 0.014927891454464   8: 0.014927305156621   1: 0.014926409327004   9: 0.014926192054333   2: 0.014926083987221   3: 0.014925737630407   4: 0.014925591434613 

training_497      6: 0.469172268234853   7: 0.327206672515964   0: 0.047164233242480   9: 0.042107418132193   8: 0.019069282456490   1: 0.019067429725045   5: 0.019057533894496   4: 0.019051936677584   2: 0.019051671798859   3: 0.019051553322035 

training_4970     4: 0.382979918037536   6: 0.268981134714571   1: 0.179072070287377   0: 0.060523975474406   2: 0.018075484603282   5: 0.018074683620570   8: 0.018073667469005   3: 0.018073339081891   7: 0.018072894806029   9: 0.018072831905332 

training_4972     4: 0.466877046559454   5: 0.365153528152288   6: 0.020999841786468   8: 0.020998583968126   0: 0.020996816606618   9: 0.020995766339785   7: 0.020994848117797   2: 0.020994829166960   1: 0.020994474404066   3: 0.020994264898438 

training_4974     5: 0.745478227267557   1: 0.075767846497389   4: 0.047239685798362   0: 0.019329846521176   6: 0.018698716607407   8: 0.018698086349070   3: 0.018697182800219   9: 0.018696921539262   2: 0.018696752362834   7: 0.018696734256725 

training_4976     0: 0.753288061401802   2: 0.070537286237508   6: 0.022031318583481   1: 0.022024053955657   8: 0.022023284093405   5: 0.022022556782988   4: 0.022019138306092   7: 0.022018286302647   9: 0.022018158275850   3: 0.022017856060571 

training_498      5: 0.294721387137483   2: 0.282307768602284   3: 0.139154943286625   6: 0.119151524998058   8: 0.063540868911747   1: 0.020228913497028   0: 0.020226523889238   9: 0.020223921182216   4: 0.020223311691477   7: 0.020220836803845 

training_4981     7: 0.476510718682819   0: 0.345363419815348   5: 0.058837339716322   6: 0.017047285708182   2: 0.017043763409667   1: 0.017041118138797   3: 0.017040180689851   4: 0.017039995907546   9: 0.017039442244549   8: 0.017036735686919 

training_4983     6: 0.385736051900136   4: 0.234230292045341   5: 0.204606899054017   8: 0.089340683928257   1: 0.014577497490621   3: 0.014570344036289   9: 0.014256497058747   0: 0.014241919608621   7: 0.014227191282788   2: 0.014212623595183 

training_4987     6: 0.836040805075299   9: 0.018223811293315   5: 0.018218141473993   1: 0.018217206327099   0: 0.018217191817386   7: 0.018216790844864   8: 0.018216765214348   4: 0.018216500477584   2: 0.018216395412113   3: 0.018216392064000 

training_4988     6: 0.831728858476163   8: 0.043394825737671   7: 0.028550988306714   5: 0.018081626561961   0: 0.015558286097488   2: 0.012543556152563   1: 0.012540404321619   3: 0.012538312640651   9: 0.012531704259891   4: 0.012531437445280 

training_4990     5: 0.604223269716730   0: 0.202079813312117   2: 0.024214037354159   3: 0.024212875103329   6: 0.024211946546378   4: 0.024211919053274   1: 0.024211765915385   7: 0.024211570288306   8: 0.024211473162921   9: 0.024211329547400 

training_4991     5: 0.624760453290991   3: 0.194191033473582   4: 0.022632632932798   1: 0.022631729103146   0: 0.022630886745698   2: 0.022630816500451   6: 0.022630687102978   7: 0.022630648925926   8: 0.022630573970973   9: 0.022630537953455 

training_4993     6: 0.810925987551831   9: 0.046077927988417   8: 0.017877322370700   1: 0.017877285208899   0: 0.017875964552895   5: 0.017873730142177   7: 0.017873132112955   4: 0.017872975018891   2: 0.017872842605771   3: 0.017872832447464 

training_4998     5: 0.788739807069251   4: 0.023474650402076   1: 0.023474138155494   0: 0.023473370191707   3: 0.023473232266160   2: 0.023473192099798   6: 0.023473189356240   7: 0.023472870689897   9: 0.023472776398466   8: 0.023472773370912 

training_4999     1: 0.434381185374991   5: 0.309652645911917   4: 0.032005819632160   3: 0.031994666552639   8: 0.031994504845531   6: 0.031994454041010   2: 0.031994331808562   0: 0.031994237978738   7: 0.031994132716992   9: 0.031994021137460 

training_5        8: 0.599134688408026   6: 0.267177956572354   1: 0.016720795970782   0: 0.016714837370376   7: 0.016712623659003   9: 0.016710510956113   5: 0.016709033278025   2: 0.016706610499706   4: 0.016706550149503   3: 0.016706393136113 

training_50       5: 0.754543330091121   6: 0.077985725686246   0: 0.020953724585177   1: 0.020935928935132   8: 0.020933214981515   9: 0.020930517887447   4: 0.020930162449764   3: 0.020929230395912   2: 0.020929102552152   7: 0.020929062435535 

training_5001     1: 0.729955080712705   0: 0.071488742681494   4: 0.053557078602673   6: 0.020726593838760   5: 0.020715491547143   9: 0.020711743841593   8: 0.020711694623001   7: 0.020711461236132   2: 0.020711203422401   3: 0.020710909494097 

training_5002     6: 0.615568553227965   8: 0.212098695032367   1: 0.055691320282623   5: 0.016664270054309   0: 0.016663501597318   3: 0.016662906312580   7: 0.016662867972271   9: 0.016662857445051   4: 0.016662533965894   2: 0.016662494109622 

training_5003     6: 0.711068721987953   5: 0.086381099123732   8: 0.039656748938605   3: 0.033384179611770   9: 0.029160408883054   1: 0.025738331593936   0: 0.024226417437077   7: 0.016796054182057   2: 0.016794191745038   4: 0.016793846496778 

training_5009     6: 0.814376130370787   0: 0.043849698941580   1: 0.030840920220682   5: 0.015885215795097   2: 0.015865234939156   9: 0.015845479272767   8: 0.015842297561930   3: 0.015831819140780   4: 0.015831634202049   7: 0.015831569555171 

training_501      6: 0.775900171917723   2: 0.044857618690784   7: 0.040137136918467   0: 0.036876944633555   1: 0.031959366359872   8: 0.014062831727341   5: 0.014060324716718   9: 0.014049779727340   4: 0.014047926346810   3: 0.014047898961391 

training_5012     3: 0.534567322420337   5: 0.259972469716090   4: 0.025683945557774   1: 0.025682508861407   0: 0.025682444437407   2: 0.025682438485035   6: 0.025682357779642   7: 0.025682332640852   8: 0.025682101777488   9: 0.025682078323968 

training_5013     4: 0.738432652565537   5: 0.029068068807041   8: 0.029062662944072   9: 0.029062600422308   3: 0.029062440975837   2: 0.029062395977842   0: 0.029062346364436   7: 0.029062328501761   1: 0.029062285614482   6: 0.029062217826684 

training_5015     5: 0.814447566944032   0: 0.020623742234497   6: 0.020622789251421   4: 0.020618931513102   1: 0.020615799139841   9: 0.020614849564886   8: 0.020614219826060   7: 0.020614117280801   3: 0.020614018708300   2: 0.020613965537060 

training_5017     6: 0.741758873769870   1: 0.028694569120153   7: 0.028694532966938   0: 0.028694159631699   8: 0.028693493309638   5: 0.028693259978442   2: 0.028693084716019   9: 0.028692880448780   4: 0.028692728562199   3: 0.028692417496263 

training_5018     4: 0.768166004416065   5: 0.025767164761439   1: 0.025759571083390   0: 0.025758859570097   2: 0.025758215940646   9: 0.025758112477629   8: 0.025758060610438   6: 0.025758052339260   3: 0.025758051783343   7: 0.025757907017694 

training_502      6: 0.730393518585669   1: 0.130973105792379   8: 0.053025962266450   5: 0.012236855302579   0: 0.012230645138410   4: 0.012228633456573   9: 0.012228464605222   2: 0.012227944439666   7: 0.012227577869710   3: 0.012227292543343 

training_5020     6: 0.475904476901512   7: 0.345251179902548   5: 0.022661409226749   1: 0.022462868377579   0: 0.022375433378532   2: 0.022274752705212   4: 0.022272582704472   3: 0.022268417065073   9: 0.022267916688571   8: 0.022260963049752 

training_5021     5: 0.792909951848329   3: 0.023010598140298   0: 0.023010388085917   1: 0.023010153651073   4: 0.023010125557996   8: 0.023010002120760   6: 0.023009862436791   9: 0.023009793921536   2: 0.023009659189232   7: 0.023009465048067 

training_5029     4: 0.761985776621287   5: 0.026452230084975   0: 0.026445368275323   3: 0.026445341233982   8: 0.026445313147649   2: 0.026445228280958   6: 0.026445225654644   9: 0.026445225474949   1: 0.026445164176741   7: 0.026445127049492 

training_5031     6: 0.819053498470462   1: 0.034089590801749   0: 0.032129217246254   5: 0.016435902661868   9: 0.016407377713766   2: 0.016396352642472   8: 0.016381382869884   3: 0.016369402454265   4: 0.016368702516921   7: 0.016368572622358 

training_5033     6: 0.705323037887644   5: 0.085276011015631   0: 0.051721083916550   7: 0.047436586442591   8: 0.027931925368597   3: 0.026200922914166   1: 0.014033151223339   9: 0.014029342911091   4: 0.014024052117304   2: 0.014023886203087 

training_5034     5: 0.774941083434312   8: 0.063476026162657   4: 0.020200757255480   6: 0.020198552691506   9: 0.020197837734328   0: 0.020197451925037   7: 0.020197451069531   1: 0.020197024310200   3: 0.020196912607389   2: 0.020196902809559 

training_5037     6: 0.720993221012623   0: 0.073191050945659   2: 0.046290074959046   7: 0.043715736817139   1: 0.019336094739759   8: 0.019305464318821   9: 0.019293645898178   5: 0.019293488316985   4: 0.019290979806834   3: 0.019290243184955 

training_504      0: 0.667546270601367   6: 0.124138394866985   5: 0.066141489898173   7: 0.051707552218550   1: 0.015103532144912   2: 0.015082076683967   9: 0.015072962131680   4: 0.015070148220490   8: 0.015068924455048   3: 0.015068648778827 

training_5040     5: 0.508390956791449   6: 0.303103349708294   1: 0.048024430522988   3: 0.020076991737476   0: 0.020073383215072   8: 0.020070661778173   9: 0.020070322732149   4: 0.020064031312411   7: 0.020063193506967   2: 0.020062678695021 

training_5042     6: 0.728739201780821   5: 0.086254120706058   1: 0.056854888519676   4: 0.018311209555175   9: 0.018308261843224   0: 0.018307562170252   8: 0.018306731273527   3: 0.018306129558485   2: 0.018306047142214   7: 0.018305847450568 

training_5043     5: 0.770427742616726   8: 0.067529083344320   4: 0.020258772496174   1: 0.020256986581055   6: 0.020255625707241   0: 0.020254829572533   9: 0.020254612806904   7: 0.020254171318435   2: 0.020254094461454   3: 0.020254081095157 

training_5044     1: 0.575449988737322   6: 0.151841529346945   2: 0.110730102315272   4: 0.046205719456618   5: 0.019296921721299   9: 0.019296473757400   0: 0.019296158501995   8: 0.019294473298597   7: 0.019294396789700   3: 0.019294236074852 

training_5046     4: 0.709527831809539   5: 0.032279506982108   6: 0.032278015285649   1: 0.032277291240613   0: 0.032273842169403   9: 0.032273649095217   3: 0.032272852771636   7: 0.032272452306893   2: 0.032272284023817   8: 0.032272274315125 

training_5048     5: 0.577193144246402   9: 0.239636518086601   1: 0.022938283453742   0: 0.022895940338211   4: 0.022894072369936   6: 0.022888667782987   8: 0.022888485003077   3: 0.022888337031713   7: 0.022888293388448   2: 0.022888258298885 

training_505      6: 0.710648890219363   5: 0.129315882939533   9: 0.034731134022620   0: 0.033971072555540   1: 0.015280478366577   7: 0.015216136238359   4: 0.015210646247591   8: 0.015209163442343   2: 0.015208444269775   3: 0.015208151698299 

training_5050     5: 0.783948768595992   4: 0.024012185635456   3: 0.024009629365496   0: 0.024004825762011   8: 0.024004346876134   1: 0.024004218068082   6: 0.024004074080643   2: 0.024004014425757   9: 0.024003993491275   7: 0.024003943699154 

training_5051     5: 0.776057415975022   4: 0.024888149345110   8: 0.024881931534579   0: 0.024881892565432   7: 0.024881874335936   3: 0.024881794806352   9: 0.024881792030393   6: 0.024881742100476   2: 0.024881737217516   1: 0.024881670089183 

training_5052     6: 0.804953576920878   9: 0.049478710477486   1: 0.018198475446359   8: 0.018198447793064   0: 0.018197032693751   5: 0.018195447899669   7: 0.018194781215267   4: 0.018194619084292   2: 0.018194455697455   3: 0.018194452771780 

training_5053     5: 0.593138885043120   6: 0.235454738136844   2: 0.021426183715707   1: 0.021426066907760   3: 0.021425821440956   4: 0.021425800004063   0: 0.021425759810775   8: 0.021425726629521   9: 0.021425588738653   7: 0.021425429572601 

training_5054     5: 0.780208373886970   4: 0.024422491502379   1: 0.024421873432453   3: 0.024421385730104   2: 0.024421251714071   0: 0.024421146998772   6: 0.024421125413900   7: 0.024420788427406   9: 0.024420782730379   8: 0.024420780163565 

training_5055     5: 0.679504914171713   4: 0.137605108996792   6: 0.022862671222288   1: 0.022861799039985   9: 0.022861332549222   8: 0.022861093292714   0: 0.022861081915434   7: 0.022860724214847   3: 0.022860676514390   2: 0.022860598082616 

training_5056     6: 0.676053275015699   0: 0.142732299543468   8: 0.052250673734014   5: 0.018426553101604   2: 0.018423825276300   1: 0.018423122532807   4: 0.018422915610891   9: 0.018422663629122   7: 0.018422645655738   3: 0.018422025900357 

training_5057     6: 0.820143985710127   1: 0.053017629819475   8: 0.034579536292456   5: 0.027990543683544   0: 0.010745860350721   9: 0.010716345172250   3: 0.010701788398911   7: 0.010701463645851   4: 0.010701445547031   2: 0.010701401379634 

training_5058     5: 0.837249349369883   6: 0.018088486345221   1: 0.018085325087791   0: 0.018084188259056   8: 0.018083354025118   9: 0.018082162516225   7: 0.018082005818787   4: 0.018081736004767   3: 0.018081709344819   2: 0.018081683228333 

training_5059     8: 0.760301623565643   6: 0.026638972673129   5: 0.026638928765769   0: 0.026633306456129   9: 0.026632087211677   4: 0.026632038119382   1: 0.026632006051760   7: 0.026631498976849   2: 0.026630339558563   3: 0.026629198621098 

training_506      5: 0.623748160911840   3: 0.184610223673851   6: 0.023968126491948   1: 0.023954546323784   0: 0.023954260127031   8: 0.023953827382016   4: 0.023953521855636   2: 0.023953096177385   9: 0.023952342981137   7: 0.023951894075372 

training_5060     5: 0.815747240558789   8: 0.020499072739377   6: 0.020480775825895   0: 0.020472782895653   9: 0.020469453181226   7: 0.020467660082125   1: 0.020467305293571   2: 0.020465709915049   4: 0.020465643611540   3: 0.020464355896776 

training_5061     6: 0.708204075474360   2: 0.083036603114116   7: 0.053914524257425   0: 0.052969725934648   9: 0.016984348096823   1: 0.016983742599115   5: 0.016978160606701   8: 0.016977278207376   4: 0.016976073453609   3: 0.016975468255827 

training_5062     0: 0.671559466255640   5: 0.036497608620004   6: 0.036495568878361   1: 0.036494760794501   4: 0.036492636539288   9: 0.036492486006649   2: 0.036492236897603   7: 0.036491939393064   8: 0.036491662632247   3: 0.036491633982642 

training_5068     5: 0.703544125177414   6: 0.032942803462604   0: 0.032941318820384   4: 0.032940770480434   1: 0.032939433637191   8: 0.032938954117122   7: 0.032938831285270   9: 0.032938440397374   2: 0.032937689581351   3: 0.032937633040856 

training_5070     6: 0.701140283348471   0: 0.216147775262299   1: 0.018273699720039   4: 0.015573517882514   2: 0.010297641999139   7: 0.008275959259671   8: 0.007575544056268   9: 0.007572306869161   5: 0.007571760033901   3: 0.007571511568538 

training_5071     0: 0.620225453491571   1: 0.230971936180230   9: 0.044418928142479   6: 0.014916976563457   5: 0.014913013459611   3: 0.014911414153663   2: 0.014911154149702   4: 0.014910557544614   7: 0.014910335050914   8: 0.014910231263761 

training_5072     4: 0.776478930820848   5: 0.024844957430245   8: 0.024834818332905   9: 0.024834631867666   3: 0.024834618401203   2: 0.024834519777016   0: 0.024834453129112   1: 0.024834430269706   7: 0.024834362147821   6: 0.024834277823478 

training_5076     5: 0.666897977333210   1: 0.111469414965137   0: 0.096192320054632   3: 0.017927504327639   4: 0.017926697209947   6: 0.017920656186407   9: 0.017916655704671   8: 0.017916409972630   2: 0.017916184618334   7: 0.017916179627394 

training_5077     9: 0.448191527241174   0: 0.390995242716785   6: 0.020119519219791   8: 0.020113824475895   1: 0.020103177418124   4: 0.020099047913025   5: 0.020098733901620   2: 0.020095943777501   7: 0.020091589286935   3: 0.020091394049150 

training_5078     5: 0.755204046389369   4: 0.027206039000863   8: 0.027198870620553   7: 0.027198785565487   0: 0.027198766205690   3: 0.027198741893063   2: 0.027198723160329   6: 0.027198698992453   1: 0.027198667818467   9: 0.027198660353726 

training_508      5: 0.797147062444386   4: 0.022540840427404   8: 0.022539768392226   6: 0.022539350591245   3: 0.022539122430090   0: 0.022539042495956   1: 0.022538881303922   9: 0.022538715733229   2: 0.022538613178268   7: 0.022538603003274 

training_5080     1: 0.726504553698502   4: 0.102264979676429   5: 0.044776246579944   0: 0.018224765243545   6: 0.018046122209931   3: 0.018045768664989   2: 0.018035475673653   9: 0.018034381997153   8: 0.018034046459806   7: 0.018033659796047 

training_5081     5: 0.783938345755242   1: 0.024046950625026   6: 0.024043600565506   0: 0.024029841588297   4: 0.023992839175147   9: 0.023990619882361   8: 0.023989871159994   2: 0.023989625581409   3: 0.023989445198321   7: 0.023988860468697 

training_5082     1: 0.803915422793010   5: 0.021789284186810   6: 0.021789142662388   0: 0.021787756354968   2: 0.021787087872189   4: 0.021786607817783   9: 0.021786328724652   3: 0.021786223049461   8: 0.021786116064769   7: 0.021786030473970 

training_5083     5: 0.778742097474983   3: 0.024585101984552   4: 0.024584294603881   6: 0.024584231944887   8: 0.024584150645294   7: 0.024584118834716   0: 0.024584070126526   2: 0.024584006990924   1: 0.024583982690711   9: 0.024583944703526 

training_5084     5: 0.776570250576190   4: 0.024831668903891   8: 0.024825531760466   3: 0.024824801409961   2: 0.024824686320763   0: 0.024824678746707   9: 0.024824677301520   1: 0.024824630508366   7: 0.024824550108763   6: 0.024824524363371 

training_5085     5: 0.408165955936474   3: 0.393971733491372   4: 0.024733192525054   6: 0.024733187657972   1: 0.024732980642103   0: 0.024732869191267   2: 0.024732664433054   7: 0.024732598679067   8: 0.024732504798036   9: 0.024732312645602 

training_5086     5: 0.418271720785642   3: 0.391938667071192   6: 0.023726178522649   1: 0.023724085701533   4: 0.023723876120736   0: 0.023723676475142   9: 0.023723342868553   2: 0.023723176080605   8: 0.023723067981526   7: 0.023722208392424 

training_5089     5: 0.761118716910029   0: 0.056972591378164   7: 0.022779872488805   6: 0.022760331171485   9: 0.022745041711439   4: 0.022728952754242   8: 0.022726241268952   1: 0.022722842786663   2: 0.022722823848480   3: 0.022722585681742 

training_509      5: 0.676614768055457   6: 0.145675167829619   8: 0.022214661372913   0: 0.022214438247852   3: 0.022213799128478   4: 0.022213782248335   1: 0.022213674102439   7: 0.022213366621666   9: 0.022213257357289   2: 0.022213085035952 

training_5090     4: 0.759002475153504   5: 0.026783693898075   8: 0.026777018240262   9: 0.026776837670267   3: 0.026776835944834   2: 0.026776750152010   7: 0.026776665214895   0: 0.026776595054798   1: 0.026776573326310   6: 0.026776555345045 

training_5091     1: 0.638915726698020   4: 0.123972953303113   6: 0.116264651989079   7: 0.017270072272599   5: 0.017267873380877   0: 0.017265364472185   9: 0.017262330771799   2: 0.017260459169405   8: 0.017260364754859   3: 0.017260203188065 

training_5092     5: 0.567484319963435   6: 0.221752318769706   0: 0.111707847321739   1: 0.014152822536179   9: 0.014151256899403   4: 0.014150655955282   7: 0.014150324933966   8: 0.014150216965454   2: 0.014150189792154   3: 0.014150046862682 

training_5094     1: 0.478281259988663   5: 0.157295542028493   6: 0.151532092977994   0: 0.064947871647118   4: 0.041524827095035   2: 0.039984499875298   8: 0.016609031880109   9: 0.016608614069601   7: 0.016608169176473   3: 0.016608091261216 

training_5095     5: 0.812247699276899   4: 0.020866329860803   0: 0.020861737362166   6: 0.020861310001342   1: 0.020861134728022   8: 0.020860475745034   9: 0.020860466147653   3: 0.020860358375444   2: 0.020860277638835   7: 0.020860210863801 

training_5097     4: 0.432310291845055   6: 0.344243303427736   2: 0.062173808935162   3: 0.058972779214568   8: 0.017066027045435   1: 0.017049709126607   0: 0.017048929824043   5: 0.017048319163883   9: 0.017043777063251   7: 0.017043054354261 

training_5100     5: 0.725500832792392   6: 0.030504382440497   4: 0.030503588805239   7: 0.030500249434316   9: 0.030499514932938   0: 0.030498434041466   8: 0.030498362286881   1: 0.030498298671539   3: 0.030498197512462   2: 0.030498139082270 

training_5102     3: 0.430402931035675   6: 0.278603705850904   9: 0.080373098781790   1: 0.056967151461040   0: 0.046150177120971   5: 0.021507471311454   4: 0.021500944534534   2: 0.021499832729082   7: 0.021497460756156   8: 0.021497226418393 

training_5105     4: 0.781755520527323   5: 0.024256172368849   8: 0.024248739919110   3: 0.024248612540703   2: 0.024248550975771   0: 0.024248522347812   9: 0.024248500962328   1: 0.024248476541804   7: 0.024248476261955   6: 0.024248427554344 

training_5109     6: 0.716171279683129   0: 0.157092103782891   7: 0.044106625429155   8: 0.015503276295169   3: 0.011586609772766   1: 0.011240806768866   9: 0.011083854098661   2: 0.011077548782531   5: 0.011069827692430   4: 0.011068067694402 

training_511      1: 0.733854078271259   2: 0.029594580473789   6: 0.029580517114768   5: 0.029572330733815   7: 0.029568629056704   9: 0.029567449355434   0: 0.029567130282248   8: 0.029566315008355   3: 0.029565079455592   4: 0.029563890248036 

training_5112     5: 0.469661840881210   4: 0.346256073569673   6: 0.063556492180364   8: 0.017231722429781   0: 0.017219304521510   1: 0.017219147037158   9: 0.017215301487447   7: 0.017214629075024   3: 0.017213333854181   2: 0.017212154963652 

training_5113     5: 0.291136716898974   0: 0.233201914282487   8: 0.120328014993147   7: 0.106814653996981   2: 0.106688176556105   9: 0.056291480363616   4: 0.029324104227339   6: 0.023332339786948   1: 0.016446221569139   3: 0.016436377325264 

training_5114     5: 0.371118596940195   9: 0.353430108075558   1: 0.122487976025108   6: 0.021856873209598   0: 0.021853487839383   4: 0.021851822541756   7: 0.021850747298289   2: 0.021850385801225   8: 0.021850187629672   3: 0.021849814639217 

training_5115     6: 0.355457849021908   1: 0.300006544701563   0: 0.134166040029337   9: 0.125385603298972   5: 0.014169136220750   3: 0.014163413173424   8: 0.014162998170587   4: 0.014162984710918   7: 0.014162810601843   2: 0.014162620070699 

training_5116     6: 0.632468916489216   7: 0.163082541855922   2: 0.100920162981282   3: 0.023051031309262   1: 0.013443061007691   5: 0.013409426773782   9: 0.013408932485487   0: 0.013405972033391   4: 0.013405083699267   8: 0.013404871364699 

training_5117     0: 0.637813107771641   6: 0.133634603434910   1: 0.103238798160989   5: 0.017903401782559   4: 0.017902630765160   7: 0.017901610934010   2: 0.017901555160615   9: 0.017901504901721   8: 0.017901447921805   3: 0.017901339166591 

training_5118     6: 0.672502231885622   4: 0.132454876727679   1: 0.064383018266859   5: 0.039339063194935   0: 0.015417122999609   2: 0.015185428337063   9: 0.015184094413348   3: 0.015183952883406   7: 0.015175440340869   8: 0.015174770950610 

training_5119     6: 0.585406437112187   7: 0.183720759393915   2: 0.121432649380528   1: 0.025855405621146   3: 0.014370398064773   5: 0.013848001665730   9: 0.013843501271523   0: 0.013841731078004   4: 0.013840759504690   8: 0.013840356907504 

training_512      5: 0.796774102415583   8: 0.022582506806991   4: 0.022580772119450   6: 0.022580745434673   0: 0.022580698122058   3: 0.022580551638700   1: 0.022580417023284   2: 0.022580115980683   7: 0.022580046170546   9: 0.022580044288033 

training_5121     0: 0.495009119811872   5: 0.213564360625940   2: 0.178295595502243   6: 0.016180389458795   1: 0.016172338935178   9: 0.016157734998011   3: 0.016156306815911   7: 0.016155441621625   8: 0.016154437674166   4: 0.016154274556258 

training_5123     6: 0.818485509044842   0: 0.046124348596218   1: 0.016927858174391   5: 0.016927476868609   4: 0.016926409332562   2: 0.016921989013519   9: 0.016921786492098   8: 0.016921730572866   7: 0.016921632263748   3: 0.016921259641148 

training_5125     6: 0.816665952126639   0: 0.055366094500959   5: 0.015998635171511   1: 0.015998628905737   4: 0.015997440625750   2: 0.015994914596860   8: 0.015994766374389   9: 0.015994762596263   7: 0.015994561830214   3: 0.015994243271677 

training_5126     5: 0.627469705488448   9: 0.212034231606539   1: 0.020080745030905   4: 0.020062665227716   6: 0.020061008069601   0: 0.020060062224956   8: 0.020058368517739   2: 0.020057777119236   7: 0.020057771150274   3: 0.020057665564587 

training_5127     0: 0.500949557975997   6: 0.368741308093257   1: 0.054295443428497   7: 0.018694180202918   2: 0.009607713452024   5: 0.009568849880314   9: 0.009538703038909   8: 0.009534917549092   4: 0.009534795131855   3: 0.009534531247137 

training_5128     4: 0.772788259887002   0: 0.081856989675580   5: 0.018182488698203   6: 0.018170709133054   1: 0.018170462097421   7: 0.018170032020907   8: 0.018165865864761   9: 0.018165801374092   2: 0.018164721977314   3: 0.018164669271666 

training_513      5: 0.797123707616632   8: 0.022542850040390   1: 0.022542425224363   6: 0.022542059512806   0: 0.022541917315037   4: 0.022541758150012   3: 0.022541628732627   2: 0.022541341544032   7: 0.022541251216168   9: 0.022541060647931 

training_5132     6: 0.327314775824232   1: 0.305919267615527   0: 0.149670021932715   9: 0.129863156893654   5: 0.014544196468082   3: 0.014538178272348   8: 0.014537788471553   4: 0.014537722962775   7: 0.014537581893434   2: 0.014537309665680 

training_5134     6: 0.604647284237880   8: 0.233924789336897   0: 0.053624633148072   7: 0.033527105194278   1: 0.012383949412504   5: 0.012379874127950   9: 0.012379437766674   4: 0.012377736242332   3: 0.012377662320708   2: 0.012377528212705 

training_5138     6: 0.377459988545055   1: 0.277521378047996   7: 0.171858894468433   0: 0.024742253632095   2: 0.024736838464459   5: 0.024736602071106   3: 0.024736478644151   9: 0.024735881546167   4: 0.024735855135120   8: 0.024735829445418 

training_5139     6: 0.708125239377396   1: 0.141304485049238   0: 0.084697582366344   4: 0.009550896211511   5: 0.009389724908688   7: 0.009387579705577   9: 0.009387322868289   3: 0.009385899329536   2: 0.009385661245560   8: 0.009385608937861 

training_514      5: 0.795144936242927   6: 0.022770251319630   8: 0.022765689275813   0: 0.022762497626918   1: 0.022762297903499   3: 0.022759120816665   4: 0.022759104710295   7: 0.022758841194056   9: 0.022758818577421   2: 0.022758442332775 

training_5141     5: 0.419286718122227   6: 0.339110788967071   9: 0.080721574859824   8: 0.049510048163006   4: 0.018562763646442   1: 0.018562422969973   0: 0.018562382327412   2: 0.018561379748237   7: 0.018561042258195   3: 0.018560878937613 

training_5142     6: 0.573043842521074   3: 0.248821258808855   1: 0.022308631205604   0: 0.022270808549248   8: 0.022269517960481   5: 0.022258719844084   7: 0.022258035357624   9: 0.022256557012134   4: 0.022256378599681   2: 0.022256250141215 

training_5145     6: 0.610108980250683   7: 0.088619326011903   3: 0.086484628636515   5: 0.065033923639855   1: 0.045887140454792   0: 0.044638299066425   9: 0.022974029221184   8: 0.012177390328179   4: 0.012038973318697   2: 0.012037309071766 

training_5146     6: 0.647765331243674   3: 0.176606262997754   7: 0.021996972238006   8: 0.021949649662928   5: 0.021948671738069   9: 0.021947540550667   0: 0.021946954432551   4: 0.021946495609673   1: 0.021946177527488   2: 0.021945943999191 

training_5148     6: 0.743341038542242   3: 0.100248501937105   0: 0.033320884838216   5: 0.017589153662068   1: 0.017584059372412   9: 0.017583633645047   4: 0.017583486535894   8: 0.017583472429072   7: 0.017582903166567   2: 0.017582865871377 

training_5149     6: 0.575890021467596   0: 0.267257262394317   9: 0.053775965443305   4: 0.014743683588425   5: 0.014724163308653   8: 0.014723127713453   1: 0.014722505599275   3: 0.014721241352159   2: 0.014721021248635   7: 0.014721007884182 

training_5150     6: 0.615396610762370   7: 0.112329742412445   3: 0.077645425624162   9: 0.068274855098945   1: 0.064032639399916   0: 0.012539821093117   2: 0.012503714865627   4: 0.012475535694821   5: 0.012402528950018   8: 0.012399126098579 

training_5152     6: 0.836498244210439   7: 0.018169153717318   9: 0.018168563277131   5: 0.018166656510710   1: 0.018166568106595   0: 0.018166509213794   8: 0.018166502612509   2: 0.018166028071943   3: 0.018165926379145   4: 0.018165847900414 

training_5153     6: 0.728847466019467   0: 0.118945793162615   2: 0.041240673525906   5: 0.024127354029720   4: 0.014490957839510   8: 0.014481316021226   9: 0.014470087487069   3: 0.014467732181659   1: 0.014467097029972   7: 0.014461522702855 

training_5154     6: 0.727455455899013   8: 0.073849150896260   1: 0.056374281704199   5: 0.031169871412976   3: 0.028667053808620   7: 0.016555895126048   9: 0.016507543210685   0: 0.016493834998346   2: 0.016463644203626   4: 0.016463268740227 

training_5156     6: 0.780827110628564   8: 0.064855282861409   0: 0.061662671859123   9: 0.027252487215918   2: 0.010904663402220   7: 0.010902537080232   5: 0.010900846948394   1: 0.010900538500226   3: 0.010897832384876   4: 0.010896029119038 

training_516      6: 0.752510068634996   7: 0.085035014034805   8: 0.056542911638905   5: 0.015136833731022   4: 0.015133063479677   0: 0.015131178767351   1: 0.015128014806345   3: 0.015127938634025   9: 0.015127539227054   2: 0.015127437045819 

training_5160     6: 0.629051088562675   1: 0.256612352523849   0: 0.014296662702134   9: 0.014291787977530   8: 0.014291635452058   5: 0.014291480726595   7: 0.014291359726462   3: 0.014291230950479   4: 0.014291203749484   2: 0.014291197628733 

training_5162     6: 0.529390461206034   3: 0.235337448183617   0: 0.116170287916718   1: 0.043210444205244   5: 0.012657204128321   9: 0.012656932154451   4: 0.012645292462868   2: 0.012644281834903   7: 0.012643861831030   8: 0.012643786076814 

training_5166     6: 0.745154379890029   5: 0.028319805059960   1: 0.028316769781269   3: 0.028315956053018   0: 0.028315654067070   9: 0.028315652658152   2: 0.028315564886638   7: 0.028315446162437   8: 0.028315419056888   4: 0.028315352384539 

training_5167     6: 0.639195059607305   1: 0.239128112899693   0: 0.034665198899700   9: 0.012431991462525   2: 0.012430875620802   5: 0.012430655680285   7: 0.012430152758060   4: 0.012429443264690   8: 0.012429258727581   3: 0.012429251079360 

training_5168     6: 0.799612593146220   1: 0.071931300763151   3: 0.040162149855685   8: 0.012631173102349   9: 0.012617615700289   5: 0.012610980919719   0: 0.012610810534396   7: 0.012609865507453   4: 0.012607245791189   2: 0.012606264679550 

training_5169     6: 0.844994319518566   9: 0.054754875643645   5: 0.021876618046719   1: 0.020540295953858   0: 0.009835377272150   7: 0.009601500425788   3: 0.009599427260785   2: 0.009599222982561   8: 0.009599210413383   4: 0.009599152482545 

training_517      5: 0.665291223651049   8: 0.139305379851948   3: 0.024426250081886   4: 0.024425781824225   6: 0.024425332255821   0: 0.024425320160421   1: 0.024425240687468   2: 0.024425212892567   7: 0.024425167372666   9: 0.024425091221949 

training_5171     6: 0.814643400578425   0: 0.089200972833227   1: 0.041808492680698   4: 0.008406446015073   9: 0.007658346582060   2: 0.007657142067614   7: 0.007656809955071   5: 0.007656566826577   3: 0.007655928752885   8: 0.007655893708370 

training_5172     6: 0.486736804737521   9: 0.351643150443077   0: 0.047671752168511   7: 0.033832922556320   5: 0.013354584420348   1: 0.013354530738957   4: 0.013354356202301   3: 0.013350749553924   8: 0.013350718141090   2: 0.013350431037951 

training_5175     6: 0.801631121548355   7: 0.049941469636276   5: 0.018554287654307   0: 0.018553715289861   4: 0.018553599759093   1: 0.018553570103567   8: 0.018553203150112   9: 0.018553195226294   2: 0.018552945447361   3: 0.018552892184773 

training_5176     6: 0.815680810055637   0: 0.124921552256702   1: 0.007426065153107   7: 0.007425073659872   8: 0.007424775511041   5: 0.007424649835559   9: 0.007424413529684   3: 0.007424240107617   4: 0.007424229089171   2: 0.007424190801610 

training_5177     1: 0.521535738992206   0: 0.381978277918043   3: 0.017288974508998   7: 0.011357032769293   6: 0.011317594044106   5: 0.011312682387820   4: 0.011304409848543   2: 0.011302314394710   9: 0.011302288756706   8: 0.011300686379574 

training_5178     6: 0.777976934962489   7: 0.082529549035433   0: 0.062682307647509   1: 0.010981267192094   8: 0.010974400250922   9: 0.010972766028554   3: 0.010971894363501   5: 0.010971008266940   4: 0.010970226532595   2: 0.010969645719964 

training_518      6: 0.601319993220895   1: 0.202124193537142   0: 0.053407319374850   8: 0.030604227081889   3: 0.030452500080937   7: 0.029863873798763   2: 0.013058663858034   5: 0.013057069135179   9: 0.013056990855153   4: 0.013055169057157 

training_5181     6: 0.821480122248269   0: 0.069691602448852   1: 0.025478891474922   9: 0.011913513927056   7: 0.011912384001526   5: 0.011907345778226   8: 0.011905673556354   4: 0.011904446215176   2: 0.011903145157980   3: 0.011902875191639 

training_5183     6: 0.846904611176230   0: 0.028716501374565   1: 0.015610862239167   5: 0.015539018430581   7: 0.015538393742222   8: 0.015538286240338   9: 0.015538282133974   3: 0.015538102318233   4: 0.015538005519388   2: 0.015537936825303 

training_5185     6: 0.683159852516530   7: 0.136301221543672   3: 0.079520652734831   0: 0.014434139340183   5: 0.014433404530496   4: 0.014431671183385   1: 0.014430051316475   9: 0.014429939569285   8: 0.014429805192164   2: 0.014429262072980 

training_5188     6: 0.389782131163286   5: 0.251115165867649   7: 0.228804332798409   9: 0.018621360624233   3: 0.018616101846651   8: 0.018614383494181   1: 0.018613659827456   4: 0.018612792606863   0: 0.018611045310124   2: 0.018609026461148 

training_5189     6: 0.772488252802561   0: 0.055027274368834   1: 0.051259513877722   7: 0.045258179232381   5: 0.012681473881741   8: 0.012657816569027   9: 0.012657032195015   2: 0.012656942614817   3: 0.012656814997172   4: 0.012656699460729 

training_519      8: 0.715386416427848   5: 0.031629666772624   4: 0.031624787065625   6: 0.031624745653233   0: 0.031623629036413   9: 0.031622399539112   3: 0.031622213916561   1: 0.031622176574775   7: 0.031622100149715   2: 0.031621864864095 

training_5190     6: 0.736881699022745   0: 0.168150049666236   1: 0.012307825980576   9: 0.012192445368598   8: 0.011815790786412   3: 0.011772519418730   5: 0.011720909378359   7: 0.011719974252911   2: 0.011719437151956   4: 0.011719348973476 

training_5191     1: 0.760125104778240   5: 0.081507687013373   0: 0.020013287828119   2: 0.019843888028412   6: 0.019763613628205   7: 0.019753793532460   4: 0.019749993734793   8: 0.019748268355978   3: 0.019747888424493   9: 0.019746474675927 

training_5192     6: 0.811991754402147   1: 0.061411748539532   3: 0.040297284850541   8: 0.012343709427983   9: 0.012336571952174   5: 0.012327046381157   0: 0.012325042032233   7: 0.012324053803778   4: 0.012322055122433   2: 0.012320733488021 

training_5193     6: 0.752597978130649   0: 0.087598815509691   7: 0.078556163083640   1: 0.011616596849980   8: 0.011608958548052   3: 0.011607464894586   5: 0.011604411712797   2: 0.011603409399520   9: 0.011603206746209   4: 0.011602995124877 

training_5194     6: 0.613033198479318   9: 0.210410311661589   0: 0.022071085740013   5: 0.022070633691441   1: 0.022070397849573   7: 0.022069563360171   8: 0.022068873481322   4: 0.022068725282541   2: 0.022068703060090   3: 0.022068507393942 

training_5195     6: 0.722522956868056   1: 0.133971594839289   0: 0.036256412893513   4: 0.030733847509725   7: 0.012767844043964   5: 0.012752898978479   9: 0.012751029313943   2: 0.012748472299304   8: 0.012747498180344   3: 0.012747445073383 

training_5196     6: 0.666685165298790   7: 0.153768710422643   0: 0.035783825762772   9: 0.032386878922507   5: 0.018570451763061   8: 0.018563013422662   1: 0.018561565182692   2: 0.018560154266364   4: 0.018560146476743   3: 0.018560088481765 

training_5201     6: 0.586091657283733   0: 0.142695769749612   1: 0.130071118516337   9: 0.060531918061876   8: 0.038076001648551   3: 0.008512338041570   7: 0.008506155430557   5: 0.008505678253093   4: 0.008504701275300   2: 0.008504661739370 

training_5203     6: 0.799783843772317   5: 0.041008605557976   7: 0.038143304561497   3: 0.022980011843577   2: 0.022653629272939   8: 0.015516298080110   0: 0.015147036607601   1: 0.014931137897589   4: 0.014918964095224   9: 0.014917168311170 

training_5204     6: 0.759359779669915   1: 0.026743901859648   0: 0.026738435509975   9: 0.026737892537179   8: 0.026737873010968   5: 0.026737173514812   7: 0.026736664504833   4: 0.026736185079830   3: 0.026736092409753   2: 0.026736001903086 

training_5205     6: 0.645876258510298   0: 0.181169492667344   1: 0.052907056412243   9: 0.017155686785490   5: 0.017150550159749   3: 0.017149225606639   8: 0.017148198225623   4: 0.017148175448582   7: 0.017147734769633   2: 0.017147621414399 

training_5206     6: 0.812349118693015   0: 0.109060374113365   7: 0.015962020392686   1: 0.008962527969514   2: 0.008949076592261   9: 0.008943677380486   5: 0.008943568483313   8: 0.008943457799115   4: 0.008943094511315   3: 0.008943084064929 

training_5207     9: 0.723881789318051   3: 0.076605182516323   0: 0.053014064408180   6: 0.020934762853860   8: 0.020931780761072   5: 0.020929653441645   1: 0.020926858442534   4: 0.020925889419923   7: 0.020925478236733   2: 0.020924540601679 

training_5209     6: 0.721582035889297   5: 0.105263582023493   8: 0.041376407294729   7: 0.018873812366699   0: 0.018845682510434   1: 0.018820854979236   2: 0.018810551730020   9: 0.018810043015112   4: 0.018808672661615   3: 0.018808357529365 

training_521      5: 0.468595728029945   9: 0.250471594489681   8: 0.119728828354392   0: 0.023036512771651   3: 0.023028892460957   4: 0.023028292271836   6: 0.023027661842293   1: 0.023027540328835   2: 0.023027504398698   7: 0.023027445051712 

training_5210     6: 0.755632405888088   0: 0.123152533932604   8: 0.028373433680700   5: 0.013275011879460   1: 0.013263836447079   4: 0.013261233573623   7: 0.013261128313979   2: 0.013260227749830   9: 0.013260158333344   3: 0.013260030201295 

training_5212     1: 0.747552708259707   0: 0.060707556704254   6: 0.056429903117376   5: 0.019368333080223   9: 0.019329505590528   8: 0.019325863003902   4: 0.019324647683896   3: 0.019321452924270   7: 0.019320224945510   2: 0.019319804690333 

training_5214     6: 0.685638546260054   0: 0.170862258447724   2: 0.038350758011218   1: 0.030196161336709   5: 0.028936179331245   8: 0.009209454990492   9: 0.009203179143928   3: 0.009202213043553   7: 0.009201079596751   4: 0.009200169838325 

training_5215     6: 0.625592708557993   7: 0.198419849520576   0: 0.052153647721549   9: 0.017692325223785   1: 0.017691963624598   8: 0.017690628315923   5: 0.017690598209062   4: 0.017689482020860   2: 0.017689440798097   3: 0.017689356007556 

training_5216     6: 0.741997051551491   8: 0.108687196263765   9: 0.018673166494825   5: 0.018664981085261   1: 0.018663811606917   0: 0.018663772916766   4: 0.018662995147400   7: 0.018662841437334   3: 0.018662116959297   2: 0.018662066536944 

training_5218     6: 0.501116078331887   7: 0.258080383995311   5: 0.054959492348839   9: 0.044160870770088   8: 0.041377257093713   0: 0.020102430110528   1: 0.020082059172810   2: 0.020041465878693   3: 0.020040461539320   4: 0.020039500758810 

training_5219     5: 0.552081572912614   3: 0.250637404064117   1: 0.058888063650310   7: 0.042895524562919   0: 0.015932890538421   9: 0.015922882773267   6: 0.015912809030758   8: 0.015911224613775   4: 0.015909802691884   2: 0.015907825161936 

training_522      8: 0.790108893080946   2: 0.064574907325954   0: 0.018168009969877   6: 0.018167167440856   1: 0.018164502435242   5: 0.018163868992903   9: 0.018163667606723   7: 0.018163166337724   4: 0.018163036336414   3: 0.018162780473360 

training_5220     6: 0.710910498866620   7: 0.103032427504831   9: 0.057092781925055   3: 0.018443907833312   5: 0.018421772220948   8: 0.018420351587910   4: 0.018420065030488   0: 0.018419893722196   1: 0.018419532198231   2: 0.018418769110409 

training_5222     1: 0.651519498097766   0: 0.086464109892628   2: 0.078775837758558   6: 0.049592306865555   5: 0.022283830804694   7: 0.022277541183978   9: 0.022272051597384   4: 0.022271932151747   8: 0.022271707140867   3: 0.022271184506822 

training_5223     9: 0.836328909944985   6: 0.043132115935263   1: 0.015070197076674   8: 0.015067978878828   0: 0.015067501127727   5: 0.015067409914328   4: 0.015066761469956   7: 0.015066412168474   2: 0.015066383978494   3: 0.015066329505271 

training_5226     0: 0.571950230320843   4: 0.191215876263384   6: 0.139736458816778   5: 0.013920663085721   1: 0.013892120996672   3: 0.013860966202203   8: 0.013857223753064   9: 0.013855702106943   2: 0.013855403477130   7: 0.013855354977264 

training_5228     6: 0.428583250330064   3: 0.248583215063177   5: 0.175870997656085   0: 0.021022026579528   1: 0.020994195410580   8: 0.020990000468111   4: 0.020989339589397   2: 0.020989033210442   7: 0.020988992114350   9: 0.020988949578267 

training_5231     6: 0.753458201054714   7: 0.078796083104800   3: 0.050672066894293   4: 0.016730845505127   0: 0.016729217925511   5: 0.016725264688423   1: 0.016722905494444   8: 0.016722277051179   9: 0.016721820351052   2: 0.016721317930457 

training_5232     9: 0.772460066888758   4: 0.094124985438685   1: 0.016714180578165   6: 0.016713044959877   0: 0.016685158985016   5: 0.016663918350231   8: 0.016663663135396   7: 0.016658559378860   3: 0.016658382717240   2: 0.016658039567773 

training_5234     0: 0.430939612990389   1: 0.361272562979136   6: 0.110381963191725   4: 0.022239176300503   8: 0.012591115539513   5: 0.012517639629629   3: 0.012514677302831   9: 0.012514660618295   7: 0.012514425138017   2: 0.012514166309961 

training_5235     0: 0.484739128804770   6: 0.402266993197733   7: 0.019811228673138   4: 0.019128895280553   8: 0.018582246714466   9: 0.011115764621514   5: 0.011092677112143   1: 0.011088452782569   2: 0.011087547768041   3: 0.011087065045073 

training_5236     6: 0.626892999945995   3: 0.201186354789079   7: 0.021518532057820   5: 0.021487184949060   8: 0.021486603263510   2: 0.021486213575948   0: 0.021486150552268   9: 0.021486000057851   4: 0.021485257800395   1: 0.021484703008075 

training_5237     6: 0.603527076289365   8: 0.222351295934584   0: 0.021768518772461   9: 0.021766427257904   1: 0.021765649025333   5: 0.021765348797558   7: 0.021764842729368   4: 0.021763842541604   3: 0.021763609725884   2: 0.021763388925939 

training_5238     6: 0.771658801381726   4: 0.055249360678511   2: 0.050745286304482   1: 0.017486136387485   8: 0.017482728717739   9: 0.017476387169042   5: 0.017475882927586   0: 0.017475488024491   7: 0.017475187274058   3: 0.017474741134879 

training_524      6: 0.755682657283957   1: 0.079455798136229   2: 0.020619742510575   5: 0.020618177553306   4: 0.020608947283923   9: 0.020608538042756   0: 0.020605180326313   8: 0.020601467001143   7: 0.020599868550403   3: 0.020599623311395 

training_5240     6: 0.769748453736570   7: 0.087132791277076   4: 0.017906208281751   0: 0.017888984795180   1: 0.017888850486344   8: 0.017887487053658   3: 0.017887104205107   5: 0.017887019985350   9: 0.017886975391571   2: 0.017886124787392 

training_5241     6: 0.653071235354445   0: 0.223257565425992   1: 0.036730123765743   9: 0.012423405976245   8: 0.012421831947472   7: 0.012420730473143   5: 0.012420426150233   2: 0.012418455609880   4: 0.012418114084164   3: 0.012418111212684 

training_5243     0: 0.437687172216944   6: 0.387371356796657   9: 0.039578851354779   4: 0.019391196233496   5: 0.019340520479990   8: 0.019338949042956   1: 0.019325052539126   3: 0.019322597037703   2: 0.019322273993095   7: 0.019322030305255 

training_5244     6: 0.688135913253497   1: 0.089487744904408   0: 0.085336027741340   3: 0.063781972672435   7: 0.012218735854947   8: 0.012209534541124   9: 0.012208357841272   5: 0.012208302011989   4: 0.012207093408678   2: 0.012206317770310 

training_5245     6: 0.556890124538634   7: 0.260677831773926   9: 0.022804914702443   0: 0.022804713431913   8: 0.022804319999956   5: 0.022804055071047   1: 0.022803966285180   2: 0.022803500698355   4: 0.022803337623760   3: 0.022803235874785 

training_525      6: 0.702776547811679   5: 0.090522148179007   1: 0.084729701825694   0: 0.059219788532294   9: 0.010470653722152   3: 0.010458940619615   8: 0.010458347254812   2: 0.010454649985167   4: 0.010454631974398   7: 0.010454590095181 

training_5250     6: 0.480860892393840   1: 0.144197849844077   9: 0.141807288717187   5: 0.122736112751517   3: 0.044368552426043   0: 0.013217615761530   4: 0.013209616378745   8: 0.013201982623422   7: 0.013201513017715   2: 0.013198576085924 

training_5251     0: 0.780009325570816   6: 0.024460299974460   9: 0.024448265039787   7: 0.024443115568568   5: 0.024442928660444   8: 0.024442618480154   1: 0.024439083696079   4: 0.024438908483259   3: 0.024437757580845   2: 0.024437696945587 

training_5253     6: 0.688825110745858   0: 0.185283032247282   5: 0.015747053233247   9: 0.015739976033192   3: 0.015734566417850   4: 0.015734557617551   1: 0.015734392014875   8: 0.015734322686943   7: 0.015733917736640   2: 0.015733071266561 

training_5254     9: 0.772717999059730   5: 0.025261020298429   6: 0.025259340513828   4: 0.025255646511068   8: 0.025252887793204   0: 0.025252276087036   7: 0.025250656842519   1: 0.025250592600470   2: 0.025249802356858   3: 0.025249777936858 

training_5255     6: 0.779289488677235   1: 0.076131190004878   7: 0.029728896493874   5: 0.028926373917323   8: 0.027287597164374   2: 0.011731988073214   0: 0.011730234265885   9: 0.011725180750607   4: 0.011724694714959   3: 0.011724355937653 

training_5256     6: 0.777453350117386   9: 0.104133728229081   0: 0.014805793163051   5: 0.014804737816086   8: 0.014802389899397   7: 0.014801018226458   1: 0.014800466205355   4: 0.014800198309327   3: 0.014799357862423   2: 0.014798960171437 

training_5257     5: 0.646003355437119   3: 0.200514112570732   9: 0.019198105890858   1: 0.019189987316523   8: 0.019189753193332   6: 0.019183680931923   0: 0.019182654725587   4: 0.019180706729313   2: 0.019179190293973   7: 0.019178452910640 

training_5258     6: 0.795050155390424   0: 0.077788235347631   1: 0.056722268193439   8: 0.015300855919266   5: 0.009196063079507   2: 0.009192595127247   9: 0.009189656714736   7: 0.009188221870909   4: 0.009186131661095   3: 0.009185816695747 

training_5260     6: 0.590766441777024   0: 0.175048307461036   3: 0.091219606652688   9: 0.020428495547632   5: 0.020425659904026   1: 0.020422849002443   8: 0.020422594287711   7: 0.020422481882601   4: 0.020421839481439   2: 0.020421724003399 

training_5264     5: 0.413378745434248   3: 0.292721330637906   6: 0.124417763499978   4: 0.067845102709696   0: 0.016960174695050   9: 0.016945622059817   8: 0.016939734464733   1: 0.016932173644665   2: 0.016930838503276   7: 0.016928514350631 

training_5266     6: 0.840702136851340   0: 0.017701324087289   9: 0.017701130231806   5: 0.017700312215025   1: 0.017700021340304   8: 0.017699111790662   4: 0.017699102809085   3: 0.017699000848687   7: 0.017698937344093   2: 0.017698922481709 

training_5268     6: 0.786726736331124   1: 0.075797413434158   4: 0.032650539957625   5: 0.025942513146959   3: 0.022925135724827   7: 0.011193514725881   0: 0.011192353852327   9: 0.011191243938789   2: 0.011190802363633   8: 0.011189746524679 

training_5269     9: 0.834636921302804   6: 0.018384650027038   8: 0.018373473959435   0: 0.018373357129073   5: 0.018373168452124   1: 0.018372914913920   4: 0.018371699574477   7: 0.018371590101858   2: 0.018371115854255   3: 0.018371108685016 

training_5270     6: 0.706889140205821   1: 0.142501636471341   0: 0.054363311913252   8: 0.023927214050448   4: 0.020377185089704   5: 0.010394052748950   3: 0.010387109995047   7: 0.010387100670966   9: 0.010386801092082   2: 0.010386447762388 

training_5271     6: 0.828812105494013   0: 0.094361629120648   1: 0.009625208615653   7: 0.009600718080159   9: 0.009600508688581   5: 0.009600313228931   8: 0.009600117018728   2: 0.009599814735134   4: 0.009599792663707   3: 0.009599792354447 

training_5272     0: 0.353264065950341   6: 0.276925072538064   7: 0.232990082721943   1: 0.019551826584876   8: 0.019549271237417   5: 0.019546044175764   2: 0.019544736283386   9: 0.019543109550726   4: 0.019543093214549   3: 0.019542697742934 

training_5273     6: 0.639063085287601   1: 0.240092927278527   0: 0.034749751993363   9: 0.012300863374522   2: 0.012299828517219   5: 0.012299596714265   7: 0.012299083341176   4: 0.012298417156081   8: 0.012298229024128   3: 0.012298217313119 

training_5274     6: 0.762284883584702   0: 0.098438044377687   5: 0.017411124067363   9: 0.017410177710860   8: 0.017409754074232   4: 0.017409671395189   1: 0.017409396189940   7: 0.017409211290769   2: 0.017408944966255   3: 0.017408792343003 

training_5276     1: 0.490488922302966   6: 0.282892886283271   9: 0.080337287899745   0: 0.050030654712376   8: 0.016289362179452   7: 0.015997577586354   4: 0.015996819878549   5: 0.015993949153346   3: 0.015989690025187   2: 0.015982849978752 

training_5277     9: 0.704744934943822   8: 0.108763882917820   4: 0.064238244190772   6: 0.017473054245721   5: 0.017466614545519   0: 0.017464939367319   1: 0.017463738121769   7: 0.017461652411774   3: 0.017461589213376   2: 0.017461350042110 

training_5278     6: 0.789314123853161   9: 0.062819976610773   2: 0.040511203928005   3: 0.032058977331072   0: 0.020198280267620   5: 0.011089887985337   1: 0.011037532524622   7: 0.010996129908451   8: 0.010987476472339   4: 0.010986411118618 

training_5279     6: 0.801303653359564   0: 0.074329585734672   1: 0.032546897194726   9: 0.013124119504197   7: 0.013119678230825   5: 0.013118079958256   8: 0.013115701586645   4: 0.013115445496797   2: 0.013113526919588   3: 0.013113312014729 

training_528      5: 0.768029108465541   4: 0.025778071989392   8: 0.025774293429829   3: 0.025774230524276   9: 0.025774156090535   2: 0.025774150737891   1: 0.025774025771452   0: 0.025774023410557   7: 0.025774020999802   6: 0.025773918580727 

training_5280     6: 0.846841339414496   0: 0.028795668649751   1: 0.015595001783656   5: 0.015539018261726   7: 0.015538377270674   8: 0.015538284485816   9: 0.015538276326499   3: 0.015538093475199   4: 0.015538004689109   2: 0.015537935643074 

training_5281     6: 0.818818872346403   0: 0.046040759939867   1: 0.016896572191539   5: 0.016896318866368   4: 0.016895204242873   2: 0.016890756638283   9: 0.016890566657278   8: 0.016890513353902   7: 0.016890402315098   3: 0.016890033448389 

training_5283     1: 0.649723611658229   6: 0.154811942364001   3: 0.096193436882340   5: 0.014188428800285   0: 0.014183217514429   9: 0.014181695426636   8: 0.014180093247727   2: 0.014179275891177   7: 0.014179202868086   4: 0.014179095347090 

training_5284     5: 0.698900134298169   1: 0.033465800458696   0: 0.033462884344443   6: 0.033457021024719   7: 0.033453949572485   4: 0.033453892529470   9: 0.033453349330140   2: 0.033451705184199   8: 0.033451046810486   3: 0.033450216447194 

training_5285     6: 0.800205797153889   0: 0.083334686430183   5: 0.030716628414369   1: 0.025978094349774   3: 0.009978847845912   9: 0.009966854220495   8: 0.009957167841511   7: 0.009954339248960   4: 0.009953851089334   2: 0.009953733405572 

training_5286     1: 0.540155720219749   0: 0.364396394611676   3: 0.016758909371746   7: 0.011287326185852   6: 0.011243704462011   5: 0.011242067918968   4: 0.011230791348587   2: 0.011229874527232   9: 0.011228402638195   8: 0.011226808715984 

training_5287     5: 0.489968856954678   6: 0.246887787297740   9: 0.089335442925698   8: 0.054373765235275   4: 0.019906622985920   0: 0.019906605368813   1: 0.019906534443275   2: 0.019905039848950   7: 0.019904681778225   3: 0.019904663161426 

training_5288     6: 0.636533204482634   1: 0.250020796629400   0: 0.014185169099421   4: 0.014181594193587   9: 0.014180199697093   8: 0.014180050495274   5: 0.014179910167760   7: 0.014179789551709   3: 0.014179659899764   2: 0.014179625783357 

training_529      5: 0.792224794029643   8: 0.023087234606799   6: 0.023086446422150   3: 0.023086438035605   0: 0.023086115964221   4: 0.023086088260240   1: 0.023085975848195   2: 0.023085658608101   7: 0.023085640165594   9: 0.023085608059452 

training_5290     6: 0.812624242471405   0: 0.124291996701861   8: 0.011303634740476   1: 0.007398303475007   2: 0.007397671926873   7: 0.007397276544162   9: 0.007396990891098   5: 0.007396935090207   4: 0.007396487524386   3: 0.007396460634524 

training_5291     5: 0.627127947925627   1: 0.123591871677175   9: 0.058549631731904   8: 0.044403070417489   3: 0.032718432781393   6: 0.029923935698920   2: 0.028295550043869   0: 0.018494473482130   4: 0.018451921206348   7: 0.018443165035145 

training_5292     6: 0.751116088221005   9: 0.084479832042785   7: 0.046094778638549   4: 0.016923135499706   8: 0.016909106871565   3: 0.016898820784988   0: 0.016895207666613   5: 0.016894471822594   1: 0.016894459600517   2: 0.016894098851679 

training_5293     0: 0.746367334260710   6: 0.097840351143653   9: 0.037363102592580   5: 0.016928587282381   1: 0.016919159796176   4: 0.016916518562004   8: 0.016916455824769   2: 0.016916341084534   7: 0.016916214037500   3: 0.016915935415694 

training_5295     1: 0.707018396549223   6: 0.133022201363210   3: 0.057693358805224   5: 0.014616063069240   0: 0.014614923153857   4: 0.014610025580942   2: 0.014607690526280   7: 0.014605961915340   9: 0.014605767808396   8: 0.014605611228288 

training_5296     0: 0.515706857021154   5: 0.300151332187341   6: 0.023020241092332   8: 0.023018593271740   1: 0.023018166390041   9: 0.023017337647458   7: 0.023017135983098   3: 0.023016952010988   4: 0.023016808453580   2: 0.023016575942269 

training_5297     5: 0.702429475886790   2: 0.111207418636444   4: 0.023299435524369   6: 0.023295085249352   8: 0.023295064814856   9: 0.023294834236852   7: 0.023294751175550   0: 0.023294733086677   3: 0.023294660330655   1: 0.023294541058454 

training_5299     6: 0.470755155621505   7: 0.200471806113156   0: 0.179707624753380   1: 0.021301357209210   4: 0.021299998414867   5: 0.021298599624533   9: 0.021291668740573   2: 0.021291580749684   3: 0.021291340271744   8: 0.021290868501346 

training_53       5: 0.494097710890000   2: 0.302818870286027   3: 0.025386004285005   4: 0.025386000064338   6: 0.025385343473860   8: 0.025385281056020   1: 0.025385278028502   0: 0.025385258987367   7: 0.025385200043545   9: 0.025385052885335 

training_530      5: 0.807359995518118   2: 0.059196730423568   6: 0.016706764797893   0: 0.016686284170386   1: 0.016680543008506   4: 0.016675206700462   7: 0.016673887340263   9: 0.016673625242254   3: 0.016673542037976   8: 0.016673420760573 

training_5300     5: 0.693362434770656   8: 0.086129088671610   1: 0.027563857549980   0: 0.027563841881992   9: 0.027563762687003   6: 0.027563675050503   3: 0.027563422694689   2: 0.027563376687595   7: 0.027563311165320   4: 0.027563228840651 

training_5303     1: 0.756228284307393   6: 0.027090543212407   5: 0.027087942037367   0: 0.027086976685003   7: 0.027084993060738   4: 0.027084838251329   2: 0.027084335353424   9: 0.027084202703398   8: 0.027083961979958   3: 0.027083922408985 

training_5304     1: 0.449451680563733   6: 0.332973683107177   8: 0.066520933391138   5: 0.021587553287164   0: 0.021582945612536   4: 0.021577593419910   2: 0.021577187727959   9: 0.021576342730316   7: 0.021576217248836   3: 0.021575862911231 

training_5308     3: 0.484546796018886   5: 0.301077807983850   4: 0.026801761413309   1: 0.026797677127724   6: 0.026797646375398   0: 0.026797049976026   9: 0.026795716344151   8: 0.026795605535075   7: 0.026795078711730   2: 0.026794860513852 

training_5309     0: 0.787524824533789   5: 0.043054001669289   4: 0.021369035747684   6: 0.021188151498571   9: 0.021162943632509   1: 0.021143731244466   2: 0.021141289173968   7: 0.021138869470162   3: 0.021138615431589   8: 0.021138537597974 

training_531      5: 0.793491265480052   0: 0.022945840771954   1: 0.022945698105076   4: 0.022945589156038   3: 0.022945584333425   6: 0.022945568272885   2: 0.022945176948344   8: 0.022945122487133   7: 0.022945112733553   9: 0.022945041711540 

training_5312     4: 0.815829955535742   6: 0.020478722113439   0: 0.020470870568478   5: 0.020464818887043   1: 0.020461507784453   9: 0.020460392300755   7: 0.020458605904533   8: 0.020458594563919   3: 0.020458288000309   2: 0.020458244341330 

training_5313     4: 0.778681706943883   5: 0.024600226777562   6: 0.024590319419822   0: 0.024590257565040   9: 0.024589923054977   8: 0.024589776434521   3: 0.024589659468342   1: 0.024589620908811   2: 0.024589276062395   7: 0.024589233364646 

training_5314     5: 0.788136196269313   4: 0.023543466428413   8: 0.023540309839652   6: 0.023540081093674   0: 0.023540077572726   9: 0.023540061044295   3: 0.023540008755977   2: 0.023539955407496   7: 0.023539925798848   1: 0.023539917789606 

training_5315     6: 0.756331657691125   7: 0.099928673569624   0: 0.027813851669595   8: 0.016632974267757   2: 0.016580240098368   1: 0.016544078688682   9: 0.016543313805407   5: 0.016542813127434   4: 0.016541269795985   3: 0.016541127286022 

training_5316     5: 0.796646253678820   4: 0.022599718624521   6: 0.022595371004941   1: 0.022594410131502   8: 0.022594197560278   9: 0.022594058167621   0: 0.022594052649225   3: 0.022594014544497   2: 0.022593977526541   7: 0.022593946112054 

training_5317     5: 0.830361302561766   4: 0.018854351065909   0: 0.018848287287385   6: 0.018848143745542   1: 0.018848124080093   3: 0.018848098533005   8: 0.018848010540809   9: 0.018847938569681   2: 0.018847894092579   7: 0.018847849523231 

training_5318     6: 0.651505823758706   0: 0.196976974632854   3: 0.049511973929008   1: 0.044869325855335   7: 0.021089983860424   9: 0.009769162124848   8: 0.006584651567781   4: 0.006568042386752   5: 0.006562108064951   2: 0.006561953819340 

training_532      8: 0.405644423342086   5: 0.208960592610473   1: 0.174734598546902   2: 0.071256371793738   9: 0.048167310305149   0: 0.018255045808678   6: 0.018253369852670   4: 0.018245725317172   7: 0.018242060228566   3: 0.018240502194566 

training_5320     8: 0.402311344357746   1: 0.347876519216682   5: 0.031233301589828   0: 0.031230286872544   6: 0.031229274383032   4: 0.031226641333374   2: 0.031223705597467   9: 0.031223366719820   7: 0.031223253110130   3: 0.031222306819376 

training_5321     5: 0.596572637341175   0: 0.169698458245107   1: 0.111508699840399   6: 0.017465957998407   4: 0.017461710022222   2: 0.017458862852132   9: 0.017458517548933   8: 0.017458436241583   7: 0.017458404028009   3: 0.017458315882032 

training_5323     6: 0.773787624790419   1: 0.078287229919612   7: 0.030434203323864   5: 0.029631093885678   8: 0.027991900727159   2: 0.011978133150992   0: 0.011976661739479   9: 0.011971505382811   4: 0.011970998693669   3: 0.011970648386317 

training_5326     6: 0.341651000459932   1: 0.250451939986685   4: 0.200090705542475   2: 0.029693943934250   0: 0.029690861555575   5: 0.029689387613765   9: 0.029685878019651   8: 0.029684810446042   7: 0.029680978947018   3: 0.029680493494608 

training_5327     5: 0.815641735028896   4: 0.020489769748067   1: 0.020484328817979   6: 0.020483720986616   0: 0.020483655608118   8: 0.020483441175515   9: 0.020483389292007   7: 0.020483341926750   3: 0.020483310487931   2: 0.020483306928120 

training_5328     1: 0.519533837829096   6: 0.283246072435056   3: 0.087285973253251   5: 0.015708510378476   4: 0.015706782609601   0: 0.015705202411174   8: 0.015703959229186   9: 0.015703375188311   2: 0.015703227967456   7: 0.015703058698393 

training_5329     0: 0.581910516162565   4: 0.189416239885779   2: 0.028607814299503   5: 0.028583712565531   9: 0.028582688211858   6: 0.028581946220076   8: 0.028579706357593   1: 0.028579658507915   3: 0.028579410383902   7: 0.028578307405278 

training_533      5: 0.594767727417970   4: 0.200953217854419   3: 0.025548996573898   8: 0.025533016567079   9: 0.025532984331884   0: 0.025532922607638   2: 0.025532904286702   1: 0.025532831743670   7: 0.025532722652356   6: 0.025532675964385 

training_5330     6: 0.795351473872661   8: 0.056863915773270   0: 0.049696625876753   5: 0.014017078944835   1: 0.014012623852822   3: 0.014011839373788   9: 0.014011707058374   2: 0.014011669170392   4: 0.014011596732820   7: 0.014011469344286 

training_5331     8: 0.460667855546072   0: 0.343981665614125   3: 0.041234418249110   1: 0.022024301626193   5: 0.022021120936505   6: 0.022017755581023   7: 0.022015823229699   2: 0.022013173137510   4: 0.022013062755816   9: 0.022010823323947 

training_5332     1: 0.581031254669728   4: 0.175461584344236   6: 0.060757074527695   8: 0.059597008191833   0: 0.020533494017490   5: 0.020525061836004   7: 0.020524413949089   9: 0.020524351757315   2: 0.020523193603586   3: 0.020522563103024 

training_5333     0: 0.795044965661533   6: 0.022780552684911   8: 0.022772715450111   5: 0.022772714981371   1: 0.022772441963126   9: 0.022771929990642   7: 0.022771604358828   4: 0.022771252380688   2: 0.022771102808142   3: 0.022770719720650 

training_5334     7: 0.799176566403513   2: 0.022335976576643   6: 0.022319313988777   1: 0.022318948820783   0: 0.022314265484391   5: 0.022311616517242   8: 0.022307891833377   4: 0.022306323003215   9: 0.022305149433675   3: 0.022303947938385 

training_5335     1: 0.496165148449704   8: 0.197067055694514   6: 0.127896718752553   0: 0.065982471771303   4: 0.025455745920539   9: 0.017521773370235   5: 0.017485630960750   3: 0.017475889677046   2: 0.017474809313752   7: 0.017474756089603 

training_5336     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_5338     6: 0.749905745270672   0: 0.149577817599283   1: 0.013366979564630   9: 0.013008380857094   8: 0.012449399069296   3: 0.012392089775105   5: 0.012325954708465   7: 0.012325101030662   2: 0.012324376065003   4: 0.012324156059789 

training_5339     5: 0.747232980676534   6: 0.079611149961910   1: 0.071897110435687   7: 0.014517241919732   4: 0.014459003215303   0: 0.014457737979397   8: 0.014456396917754   2: 0.014456196265669   9: 0.014456101500556   3: 0.014456081127458 

training_534      5: 0.762914849617903   4: 0.026348189178539   8: 0.026342828988235   2: 0.026342072857922   0: 0.026342071982894   7: 0.026342069853906   3: 0.026342065564196   1: 0.026342046241330   9: 0.026341942291475   6: 0.026341863423599 

training_5340     0: 0.624604924826878   2: 0.188704851696039   9: 0.058638723147274   7: 0.018307376144026   5: 0.018294364630581   6: 0.018291897059904   1: 0.018290907983826   8: 0.018290282457828   4: 0.018288684974952   3: 0.018287987078690 

training_5342     4: 0.766653947416819   9: 0.087652108010901   5: 0.018225935258395   0: 0.018221083017677   6: 0.018219704924723   1: 0.018208291174243   2: 0.018205053266322   7: 0.018204765056578   3: 0.018204585026099   8: 0.018204526848244 

training_5344     6: 0.774603822703411   9: 0.025049187172551   8: 0.025046348461019   0: 0.025044289018388   7: 0.025043581605795   1: 0.025043212686907   3: 0.025042849229907   5: 0.025042408721563   2: 0.025042220008754   4: 0.025042080391705 

training_5345     6: 0.484384900655753   1: 0.295921869184166   5: 0.114848009443371   3: 0.034334028564286   8: 0.014939826522437   0: 0.011272595398768   9: 0.011084559211663   7: 0.011078178472676   2: 0.011068055983431   4: 0.011067976563449 

training_5346     9: 0.438200763642305   5: 0.372296284703920   3: 0.023688511216772   2: 0.023688310924314   4: 0.023688102600558   6: 0.023687884862048   1: 0.023687754574125   0: 0.023687663006321   7: 0.023687472579564   8: 0.023687251890074 

training_5349     2: 0.492908473126548   5: 0.297982539406154   6: 0.073364233427364   1: 0.019402661042895   0: 0.019393744251842   9: 0.019393326575635   3: 0.019390205820399   8: 0.019389520243152   4: 0.019387746337857   7: 0.019387549768153 

training_535      5: 0.508918229061370   0: 0.277775079701232   4: 0.026668085921122   1: 0.026665867619704   2: 0.026662585125395   3: 0.026662307686553   8: 0.026662195756474   7: 0.026661975892671   9: 0.026661889820175   6: 0.026661783415305 

training_5350     5: 0.585487495603799   0: 0.163903368663659   8: 0.065439731205502   1: 0.026506970003309   6: 0.026450530789268   9: 0.026443522589749   4: 0.026442464766680   2: 0.026442376600532   7: 0.026441918743178   3: 0.026441621034323 

training_5351     5: 0.633367955401722   0: 0.194425020765693   3: 0.047758473859024   2: 0.017785455146301   6: 0.017779797125826   9: 0.017779722612024   1: 0.017778586445349   4: 0.017776114501338   8: 0.017774525652915   7: 0.017774348489808 

training_5352     1: 0.475902617950951   0: 0.376514685983867   5: 0.030283062736176   6: 0.016798317994187   8: 0.016752952723400   4: 0.016750126058257   3: 0.016749775373040   9: 0.016749674162058   2: 0.016749446907577   7: 0.016749340110486 

training_5354     4: 0.801718043782563   5: 0.022036201405998   6: 0.022031041239951   0: 0.022030964900422   1: 0.022030913916322   9: 0.022030707457638   8: 0.022030640500616   3: 0.022030530590010   7: 0.022030480092831   2: 0.022030476113650 

training_5355     4: 0.746953778631514   5: 0.028123426886945   8: 0.028116009817572   6: 0.028115444424948   9: 0.028115419025006   7: 0.028115307116999   3: 0.028115198863930   2: 0.028115173137329   0: 0.028115133918459   1: 0.028115108177299 

training_5356     5: 0.731379477718111   8: 0.117937819168643   4: 0.018836604435324   1: 0.018836253479668   6: 0.018836139106074   0: 0.018836090210872   9: 0.018834748163585   3: 0.018834420355146   2: 0.018834279479372   7: 0.018834167883205 

training_5357     1: 0.789254957590905   0: 0.060373165106162   5: 0.018798112510998   6: 0.018797440472341   3: 0.018797243306783   8: 0.018796205815798   4: 0.018796100117217   9: 0.018795751995949   2: 0.018795606970196   7: 0.018795416113651 

training_5358     0: 0.519637779353517   4: 0.309217733026222   6: 0.021403452184194   9: 0.021400711115105   5: 0.021398261957989   1: 0.021392680405954   8: 0.021390577798927   2: 0.021387247886467   3: 0.021385854069775   7: 0.021385702201851 

training_5359     5: 0.795901779352749   1: 0.073993317575319   4: 0.016266275165213   6: 0.016263695970674   9: 0.016263067113168   0: 0.016262816301505   8: 0.016262566659598   3: 0.016262172177384   7: 0.016262157149244   2: 0.016262152535144 

training_536      5: 0.452895635790952   4: 0.344986440256539   3: 0.025265734738977   6: 0.025264829590748   8: 0.025264768384436   0: 0.025264684377314   7: 0.025264517176644   2: 0.025264505186546   1: 0.025264489755558   9: 0.025264394742286 

training_5360     9: 0.803336023781402   8: 0.021855074359313   6: 0.021854839274719   5: 0.021851655150633   0: 0.021851182721629   1: 0.021850876904170   7: 0.021850429447946   4: 0.021850122370039   2: 0.021849921096171   3: 0.021849874893978 

training_5362     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_5363     6: 0.654087718647563   5: 0.190155401883338   2: 0.040074856067957   1: 0.016554120741339   8: 0.016523827429610   0: 0.016522355474909   9: 0.016520714886797   7: 0.016520476414990   4: 0.016520301879423   3: 0.016520226574075 

training_5366     1: 0.685164777011904   5: 0.172764033333242   4: 0.056407209666146   8: 0.012513381759034   3: 0.012473088195946   7: 0.012145682250225   6: 0.012136787241576   0: 0.012134216410952   9: 0.012131020258655   2: 0.012129803872320 

training_5367     5: 0.770125373300287   4: 0.025544765033620   8: 0.025541402666313   6: 0.025541301918062   3: 0.025541265090249   0: 0.025541264647253   9: 0.025541245522878   2: 0.025541187724909   7: 0.025541101456982   1: 0.025541092639446 

training_5371     6: 0.794071167841041   0: 0.092323058303337   1: 0.014203022674963   5: 0.014201521963809   9: 0.014200485594849   8: 0.014200257934340   7: 0.014200239982788   2: 0.014200229896682   4: 0.014200096247168   3: 0.014199919561024 

training_5373     5: 0.719168601239123   1: 0.031220036504859   6: 0.031212874384082   0: 0.031205147483094   2: 0.031201076025322   9: 0.031199686935353   8: 0.031198868943375   7: 0.031198034151216   4: 0.031198023736387   3: 0.031197650597188 

training_5375     6: 0.734512315123046   9: 0.029500693426611   7: 0.029500546048124   0: 0.029500204628555   1: 0.029498494800027   5: 0.029497924676754   8: 0.029497866382468   3: 0.029497433810709   2: 0.029497328048225   4: 0.029497193055481 

training_5376     6: 0.722899024998332   1: 0.103090740139012   0: 0.099862226904780   8: 0.018933067427881   9: 0.015329948725799   3: 0.007982866966119   5: 0.007976591398571   4: 0.007975708835168   7: 0.007975007607358   2: 0.007974816996979 

training_5377     0: 0.445095848252426   1: 0.364677485514015   6: 0.054031137784191   3: 0.036321539128515   9: 0.032900766912747   5: 0.018741755952662   8: 0.012066207530495   4: 0.012062575173944   2: 0.012060499348188   7: 0.012042184402816 

training_5378     6: 0.748182572283598   9: 0.027981136811287   7: 0.027980944068603   0: 0.027980876856065   5: 0.027980471668138   4: 0.027979607679331   1: 0.027979214285278   8: 0.027978717969591   3: 0.027978301023920   2: 0.027978157354189 

training_5379     6: 0.520518755153961   5: 0.268321136159445   2: 0.079032180928502   1: 0.032042612949300   0: 0.016925434265718   3: 0.016636210390802   9: 0.016631394575712   8: 0.016630985858793   4: 0.016630705358612   7: 0.016630584359155 

training_538      4: 0.761472430526496   2: 0.069945659204935   5: 0.021079321565493   9: 0.021072832820865   6: 0.021072175178539   1: 0.021072035581835   0: 0.021071863416733   8: 0.021071332473552   3: 0.021071288004191   7: 0.021071061227362 

training_5382     6: 0.836925282293647   0: 0.047059389291137   1: 0.021534810168817   8: 0.013505498763597   3: 0.013498399832406   5: 0.013498274217593   7: 0.013495685425753   2: 0.013494297194247   9: 0.013494199386539   4: 0.013494163426265 

training_5383     6: 0.689305542546828   5: 0.153291823924447   1: 0.045222629623605   4: 0.016030981642245   9: 0.016029524461229   0: 0.016025556991251   8: 0.016024071687137   7: 0.016023361173980   2: 0.016023312323612   3: 0.016023195625667 

training_5385     0: 0.295651254497534   4: 0.251277222310761   5: 0.217854687837386   9: 0.132875844760320   6: 0.017069281345146   1: 0.017057220216251   8: 0.017054188086774   2: 0.017053634992708   7: 0.017053364727739   3: 0.017053301225382 

training_5388     6: 0.734562681592103   7: 0.122582760660295   0: 0.017858331490707   5: 0.017858138539746   9: 0.017857021838018   3: 0.017856534411597   1: 0.017856512752392   8: 0.017856262155534   4: 0.017856216047119   2: 0.017855540512488 

training_5389     6: 0.710345368416504   1: 0.103354654882958   3: 0.073983031717244   9: 0.016059731240297   0: 0.016055633595135   5: 0.016043670713873   7: 0.016039856469088   8: 0.016039446519161   4: 0.016039355939388   2: 0.016039250506353 

training_539      4: 0.507386154488205   5: 0.154579005368341   2: 0.152232877258278   0: 0.026543556800881   8: 0.026543305402139   3: 0.026543123058421   1: 0.026543091397430   6: 0.026543023029068   7: 0.026542951209004   9: 0.026542911988232 

training_5390     5: 0.359132707459572   6: 0.276838283497808   3: 0.160294256090290   0: 0.086214731158102   2: 0.038801668902869   1: 0.015747000526990   4: 0.015743362807421   8: 0.015743087708514   9: 0.015742610324387   7: 0.015742291524048 

training_5391     6: 0.809236001931969   1: 0.068841623505321   7: 0.029546280280372   4: 0.019762729719860   8: 0.018101450436769   0: 0.010906851938341   5: 0.010901947170149   9: 0.010901126307030   2: 0.010901002353364   3: 0.010900986356825 

training_5392     6: 0.478181776786262   7: 0.372616881659878   9: 0.047437341398788   1: 0.014543984177120   0: 0.014540173204169   5: 0.014537390003778   4: 0.014536216805084   8: 0.014535493368423   2: 0.014535388056551   3: 0.014535354539949 

training_5394     6: 0.678371724165000   0: 0.145987281932559   1: 0.095578812524771   8: 0.031714887431099   4: 0.008058373935799   7: 0.008058302265998   5: 0.008058043956242   9: 0.008057697848729   3: 0.008057487782256   2: 0.008057388157545 

training_5396     5: 0.476563853643434   2: 0.371167886346390   6: 0.019046818155078   1: 0.019036064024433   0: 0.019035447825701   9: 0.019031983080495   8: 0.019030913249063   4: 0.019029487363400   7: 0.019028914094371   3: 0.019028632217635 

training_5398     7: 0.502437628918392   6: 0.356875442390548   1: 0.017594820533650   0: 0.017593760042275   5: 0.017587178720296   9: 0.017582692885356   4: 0.017582338085992   2: 0.017582237040647   8: 0.017582044355263   3: 0.017581857027580 

training_5400     6: 0.824771667952970   3: 0.039287641536531   0: 0.016995068908298   5: 0.016994161145382   1: 0.016992628794532   4: 0.016991991637811   8: 0.016991810512881   9: 0.016991682049723   2: 0.016991680314220   7: 0.016991667147652 

training_5402     5: 0.399605085161530   3: 0.289269122267259   1: 0.115235324927599   0: 0.027991717747683   6: 0.027990229847770   4: 0.027985379955875   2: 0.027981027566207   7: 0.027980951953608   9: 0.027980724808040   8: 0.027980435764429 

training_5404     8: 0.650115878384277   6: 0.186803055027391   3: 0.054762002423047   5: 0.015606569449052   0: 0.015454569743151   9: 0.015453260581023   1: 0.015452440495962   2: 0.015450876338200   7: 0.015450696934293   4: 0.015450650623603 

training_5407     4: 0.707402635720466   0: 0.107429135930931   5: 0.023153326914374   1: 0.023145145647463   6: 0.023145096714933   3: 0.023145023375336   8: 0.023145001672125   2: 0.023144945362596   9: 0.023144882257121   7: 0.023144806404655 

training_5408     6: 0.707647555584412   8: 0.132870079774440   0: 0.038519565521941   3: 0.017340576540445   5: 0.017273579548332   1: 0.017270509259050   4: 0.017269607509601   2: 0.017269548867264   7: 0.017269495368150   9: 0.017269482026364 

training_5409     9: 0.626116187484353   6: 0.187342151253357   0: 0.051075492846541   5: 0.019367975819233   1: 0.019363903619997   4: 0.019347404526789   8: 0.019346974398325   2: 0.019346747544918   3: 0.019346594448327   7: 0.019346568058160 

training_541      5: 0.648735851376258   6: 0.120112754300081   0: 0.094962018031100   1: 0.019459088895662   4: 0.019456040302482   9: 0.019455525988648   8: 0.019455035385742   7: 0.019454717164448   2: 0.019454577854347   3: 0.019454390701233 

training_5410     0: 0.559909260082124   5: 0.208346956835004   9: 0.056452162518694   1: 0.055290873704275   6: 0.020015527272275   4: 0.019999797934801   8: 0.019997556180689   7: 0.019996051982968   2: 0.019995959060190   3: 0.019995854428979 

training_5411     9: 0.517070654839689   6: 0.251100043773973   2: 0.081462674394472   0: 0.021689807337380   5: 0.021450221893183   1: 0.021450136173298   8: 0.021447231186756   4: 0.021445296715890   7: 0.021442206107948   3: 0.021441727577410 

training_5412     6: 0.678886905481392   5: 0.134713447464026   0: 0.109130165442636   1: 0.020242929370699   8: 0.009510836322819   9: 0.009503829158446   7: 0.009503740935182   2: 0.009502814054120   4: 0.009502780039776   3: 0.009502551730904 

training_5414     5: 0.780821628504514   9: 0.024366210754459   6: 0.024354573360915   4: 0.024353235732031   0: 0.024351430147224   2: 0.024351313150515   3: 0.024350811268166   1: 0.024350513253728   8: 0.024350145081210   7: 0.024350138747238 

training_5415     5: 0.631822079280546   6: 0.204874301470437   4: 0.020415344414510   1: 0.020413156790942   0: 0.020412753739422   8: 0.020412612714492   9: 0.020412563231094   2: 0.020412420113075   7: 0.020412416769421   3: 0.020412351476062 

training_5416     5: 0.829761352361845   4: 0.018917887485260   6: 0.018916530095394   7: 0.018915117541136   9: 0.018915071280499   0: 0.018914967760289   8: 0.018914858363394   1: 0.018914827869998   3: 0.018914709030704   2: 0.018914678211480 

training_5417     5: 0.777246806343752   7: 0.068464946067705   0: 0.019314898186634   4: 0.019286398846555   6: 0.019281507417606   1: 0.019281301846374   9: 0.019281068405273   8: 0.019281054144864   3: 0.019281029593169   2: 0.019280989148068 

training_5421     3: 0.475554887655098   5: 0.204057894625619   6: 0.149060616633562   0: 0.054549070983828   1: 0.019466762446795   9: 0.019463161182052   2: 0.019463073346588   8: 0.019462030986091   4: 0.019461860399587   7: 0.019460641740781 

training_5422     5: 0.791302047691173   6: 0.059047365363035   4: 0.018711164765181   0: 0.018705913853335   8: 0.018705697140196   1: 0.018705613372824   9: 0.018705597804614   2: 0.018705552245772   3: 0.018705527375918   7: 0.018705520387952 

training_5423     6: 0.598220385889156   9: 0.200854145682706   4: 0.090355763934138   5: 0.015798508550280   1: 0.015798326115196   8: 0.015796437160984   7: 0.015795248304753   0: 0.015794326798374   3: 0.015793540213705   2: 0.015793317350707 

training_5426     5: 0.742665832708027   8: 0.105467710903574   0: 0.019083130201965   7: 0.019053273962637   6: 0.019016966446812   9: 0.018978992893088   4: 0.018934867855738   2: 0.018933228897430   1: 0.018933059366420   3: 0.018932936764308 

training_5429     1: 0.781015681834551   6: 0.047298049893906   9: 0.021474380125151   3: 0.021473266073398   5: 0.021465450284219   4: 0.021462298382751   0: 0.021459737655766   8: 0.021455902012277   7: 0.021448499957383   2: 0.021446733780598 

training_543      6: 0.439538478644890   2: 0.421389044521101   5: 0.017387847385341   4: 0.017385017308797   8: 0.017384078856863   1: 0.017383898315689   9: 0.017383647102782   0: 0.017383416036669   7: 0.017382488228943   3: 0.017382083598924 

training_5431     5: 0.536251141588899   6: 0.325313913832404   0: 0.017305855600034   4: 0.017305295769930   1: 0.017304913908267   2: 0.017304624195980   8: 0.017303835552479   7: 0.017303651028954   9: 0.017303577524282   3: 0.017303190998770 

training_5434     8: 0.512323550977950   2: 0.250478305548116   5: 0.029654082454880   6: 0.029650777336554   0: 0.029650570437755   1: 0.029650178959307   9: 0.029648834154143   3: 0.029648580789070   4: 0.029647895049472   7: 0.029647224292753 

training_5435     5: 0.397494897900027   0: 0.268726527997172   6: 0.152629029226812   7: 0.075626710706886   1: 0.017591573895741   8: 0.017586433384977   4: 0.017586420433775   9: 0.017586366623631   2: 0.017586146654569   3: 0.017585893176410 

training_5437     5: 0.634045517335546   8: 0.104381550762023   1: 0.101574365132289   7: 0.063298146040803   6: 0.016122977662740   4: 0.016120220644385   0: 0.016114676897138   3: 0.016114241982813   9: 0.016114225851018   2: 0.016114077691245 

training_5438     4: 0.745537882462715   5: 0.057588551679937   6: 0.024613262573883   9: 0.024610677857465   0: 0.024609466172450   1: 0.024608815636689   8: 0.024608671614819   7: 0.024607988779012   2: 0.024607415285241   3: 0.024607267937789 

training_5439     8: 0.726537537674972   2: 0.120661639964216   6: 0.019104049500969   0: 0.019100981772960   1: 0.019100656412226   5: 0.019099515880803   9: 0.019099510062064   7: 0.019098898168007   4: 0.019098683722936   3: 0.019098526840848 

training_544      0: 0.615935768531461   4: 0.244816087297352   6: 0.017450161920980   5: 0.017414600900216   1: 0.017399350297202   2: 0.017399067847662   9: 0.017397336061480   8: 0.017396378445134   3: 0.017395861855075   7: 0.017395386843437 

training_5440     5: 0.527652353816637   6: 0.181123608980320   2: 0.132018999553558   3: 0.022755752905134   1: 0.022752904091734   0: 0.022750901112571   4: 0.022746242792949   9: 0.022735620856230   8: 0.022732165147624   7: 0.022731450743244 

training_5441     5: 0.458016626511085   0: 0.377483191680189   1: 0.020566246719931   6: 0.020565816181111   4: 0.020562024315914   7: 0.020561697764836   2: 0.020561675999240   8: 0.020561433593382   9: 0.020560775258037   3: 0.020560511976275 

training_5442     0: 0.637603270588391   1: 0.230719470114349   5: 0.016461307166635   6: 0.016461059130948   8: 0.016459542688162   4: 0.016459444292197   2: 0.016459134155353   9: 0.016459111478301   7: 0.016458956419822   3: 0.016458703965841 

training_5443     5: 0.804791055697920   6: 0.021696749292576   0: 0.021691541034587   4: 0.021689488497283   1: 0.021689371993681   8: 0.021689169417346   7: 0.021689068706679   9: 0.021688287414792   2: 0.021687648561042   3: 0.021687619384093 

training_5444     5: 0.748377200927021   4: 0.027961522721272   8: 0.027957842831210   9: 0.027957737706773   3: 0.027957716176072   2: 0.027957681657416   7: 0.027957618959604   0: 0.027957590493260   1: 0.027957571661890   6: 0.027957516865481 

training_5445     6: 0.725277035358143   5: 0.106328806225282   3: 0.053270091178852   7: 0.025358786637390   9: 0.024292457915470   8: 0.013118915053612   0: 0.013113100144480   1: 0.013081648352107   2: 0.013079659080155   4: 0.013079500054509 

training_5447     6: 0.689574184302553   0: 0.184432596073767   7: 0.028927548164984   1: 0.013870533339675   8: 0.013867872609368   3: 0.013867693124556   5: 0.013866292660744   9: 0.013866139391951   4: 0.013863775750417   2: 0.013863364581987 

training_545      1: 0.445114964994048   6: 0.175389761447411   3: 0.142403477545606   0: 0.123914037096464   7: 0.028347301975260   5: 0.016980716149094   8: 0.016974728948698   2: 0.016958856234971   4: 0.016958287641695   9: 0.016957867966753 

training_5451     5: 0.444316263498160   0: 0.334892123016447   4: 0.027603649087242   3: 0.027598908788698   2: 0.027598505806198   8: 0.027598374441015   9: 0.027598264093541   1: 0.027598105479049   7: 0.027597991953305   6: 0.027597813836345 

training_5452     5: 0.823498332360380   4: 0.019616018936800   1: 0.019611030171565   6: 0.019610995464503   0: 0.019610892333754   8: 0.019610595770972   9: 0.019610564460315   2: 0.019610546852449   3: 0.019610513987100   7: 0.019610509662163 

training_5453     6: 0.844643150349249   3: 0.030174035172864   7: 0.029126638469109   8: 0.013750248234835   0: 0.013719361827627   5: 0.013717720726604   1: 0.013717609784549   9: 0.013717135602869   4: 0.013717118262465   2: 0.013716981569828 

training_5454     5: 0.331606864489687   1: 0.271169363111971   6: 0.219992684187562   9: 0.073266992088083   4: 0.017329262356531   0: 0.017329090321781   7: 0.017326543333977   8: 0.017326488828311   3: 0.017326372638119   2: 0.017326338643978 

training_5455     1: 0.767923264298144   0: 0.061508038143872   8: 0.021392655873989   7: 0.021325368957932   6: 0.021310098654107   5: 0.021309901813866   2: 0.021309732456179   4: 0.021307244975753   9: 0.021307046265426   3: 0.021306648560732 

training_5456     6: 0.426051232454403   0: 0.393245503929320   3: 0.085536227303624   4: 0.013630090265302   5: 0.013591803380219   1: 0.013591393284544   9: 0.013588927476403   8: 0.013588781104890   2: 0.013588233004568   7: 0.013587807796727 

training_5458     6: 0.750005909968363   0: 0.146465190951017   1: 0.019441616943396   8: 0.018702747156426   9: 0.010949066224307   5: 0.010887636680187   3: 0.010887077424281   4: 0.010887020573733   7: 0.010886947568710   2: 0.010886786509580 

training_546      5: 0.772743351213216   6: 0.025251054956202   3: 0.025251045146489   4: 0.025250939628726   0: 0.025250850218014   1: 0.025250766249465   8: 0.025250635084328   7: 0.025250529228566   2: 0.025250468768302   9: 0.025250359506691 

training_5460     6: 0.521702381591349   5: 0.263241167663333   9: 0.026892024807053   4: 0.026884508088808   8: 0.026882797628219   0: 0.026881604392877   1: 0.026879584681657   7: 0.026879129905848   2: 0.026878539024643   3: 0.026878262216214 

training_5461     4: 0.737008915446766   5: 0.029226579130420   6: 0.029221623202630   0: 0.029220957375352   1: 0.029220385625350   2: 0.029220380598680   3: 0.029220357309896   8: 0.029220333809644   7: 0.029220310886679   9: 0.029220156614583 

training_5464     4: 0.773480454598043   5: 0.025174659186572   0: 0.025169111978576   7: 0.025168290285160   9: 0.025168029064299   3: 0.025168012030490   8: 0.025167972597780   2: 0.025167865824641   6: 0.025167828620360   1: 0.025167775814078 

training_5465     6: 0.568593050179815   5: 0.259743409954099   1: 0.031807013939670   0: 0.020282155842802   2: 0.019962109221571   7: 0.019928175005546   4: 0.019925837023436   9: 0.019921187232497   8: 0.019919187893704   3: 0.019917873706859 

training_5467     6: 0.786381226432273   7: 0.080335915980129   8: 0.044668348403630   5: 0.016472239523285   0: 0.016176342682328   1: 0.011478956887433   9: 0.011141616103126   2: 0.011115388321824   4: 0.011115111478965   3: 0.011114854187008 

training_5469     0: 0.505182750280062   6: 0.211908510303324   8: 0.148949613985783   3: 0.019161478383498   5: 0.019140150829336   1: 0.019136008199113   4: 0.019131044193528   7: 0.019130236205146   9: 0.019130120762723   2: 0.019130086857488 

training_547      4: 0.381631360549876   1: 0.344117220299079   7: 0.114342699538108   2: 0.051169827829466   0: 0.018137122535950   9: 0.018131207578736   5: 0.018124144823699   6: 0.018120780344159   8: 0.018113077555264   3: 0.018112558945663 

training_5470     3: 0.462553099055440   5: 0.328354481609524   2: 0.026191483952399   6: 0.026132414824851   4: 0.026130366867326   1: 0.026130303246989   0: 0.026129009150540   9: 0.026126820279164   8: 0.026126492172675   7: 0.026125528841093 

training_5471     6: 0.687037500775186   8: 0.186866366122535   1: 0.034130504875832   0: 0.027319641202190   7: 0.016734058782900   3: 0.009583353635161   5: 0.009583104171676   4: 0.009582368045978   9: 0.009582054480237   2: 0.009581047908305 

training_5472     6: 0.845496958841099   0: 0.042693212754848   1: 0.013980150876965   5: 0.013977560653663   9: 0.013976144721175   7: 0.013975931411148   4: 0.013975308088242   8: 0.013975183450472   2: 0.013974782782068   3: 0.013974766420321 

training_5473     6: 0.389228089323353   1: 0.342137980061232   5: 0.185369771134858   2: 0.014699548533429   7: 0.011650706193557   0: 0.011645172098586   9: 0.011322280610845   8: 0.011315859803188   4: 0.011315424540961   3: 0.011315167699990 

training_5474     0: 0.556752120365925   5: 0.168780439782823   1: 0.166620416738702   6: 0.015422120316119   3: 0.015405866768924   9: 0.015404541972714   8: 0.015403844809006   2: 0.015403727990708   4: 0.015403639915098   7: 0.015403281339980 

training_5475     4: 0.724610618000077   3: 0.108809783371784   5: 0.020827848564437   1: 0.020824020842247   6: 0.020823842668861   0: 0.020823678573350   9: 0.020820412176361   8: 0.020819990495780   7: 0.020819903916902   2: 0.020819901390200 

training_5476     6: 0.752726981090114   0: 0.027477338136035   1: 0.027476060985237   2: 0.027475074041102   8: 0.027474507950279   9: 0.027474320403270   5: 0.027474266673700   3: 0.027474031257681   7: 0.027473802538772   4: 0.027473616923809 

training_5477     0: 0.497433702406844   4: 0.293506616255691   5: 0.065881158920065   6: 0.020460752116398   1: 0.020460002204700   3: 0.020451770610378   8: 0.020451738140613   9: 0.020451602428653   2: 0.020451577641608   7: 0.020451079275050 

training_548      5: 0.652421160459682   1: 0.152202796251381   3: 0.024422425838200   0: 0.024422406292950   6: 0.024422325538589   4: 0.024422147345731   8: 0.024421793063819   2: 0.024421700374878   7: 0.024421642259902   9: 0.024421602574869 

training_5481     6: 0.656472490780820   1: 0.162430533183441   5: 0.073494012765772   0: 0.015386814841381   2: 0.015386469239467   7: 0.015370869173338   3: 0.015368244234970   9: 0.015366526078198   8: 0.015363628313053   4: 0.015360411389560 

training_5483     5: 0.741395480567562   4: 0.028736186951371   8: 0.028733618675913   3: 0.028733613323969   2: 0.028733554797201   0: 0.028733547103585   1: 0.028733537018388   6: 0.028733521894468   9: 0.028733479480875   7: 0.028733460186668 

training_5485     6: 0.769451599515664   0: 0.080343216220760   7: 0.040371850106464   9: 0.015719420030287   5: 0.015687957505357   8: 0.015687616336866   4: 0.015687454659139   1: 0.015683967447670   2: 0.015683513947154   3: 0.015683404230641 

training_5487     6: 0.673134713951171   5: 0.174219676735802   8: 0.039645018923494   9: 0.016325204940056   0: 0.016114879204472   1: 0.016113181710056   2: 0.016111997825579   7: 0.016111850045845   4: 0.016111793283664   3: 0.016111683379860 

training_5490     6: 0.568865737044658   3: 0.213483319841801   9: 0.027208889359716   0: 0.027208727841856   7: 0.027205902346770   1: 0.027205662272837   8: 0.027205644982082   5: 0.027205526450210   2: 0.027205303679038   4: 0.027205286181033 

training_5491     6: 0.600477997034863   1: 0.257504960114028   5: 0.017755772656527   8: 0.017753283896366   0: 0.017752526058570   4: 0.017751501936964   7: 0.017751245286648   2: 0.017750992163385   3: 0.017750876760694   9: 0.017750844091954 

training_5492     5: 0.744135315607658   6: 0.028433499592747   4: 0.028431724132406   9: 0.028430135047484   1: 0.028428632259080   8: 0.028428587436559   0: 0.028428313125975   3: 0.028428205986486   7: 0.028427878925572   2: 0.028427707886032 

training_5494     5: 0.774418021825048   4: 0.025068100518020   8: 0.025064460357155   6: 0.025064444746023   2: 0.025064225759355   9: 0.025064223607919   3: 0.025064190768277   0: 0.025064180749459   1: 0.025064110558912   7: 0.025064041109832 

training_5495     5: 0.756746111622200   4: 0.027031720986502   8: 0.027027919562403   3: 0.027027864416921   2: 0.027027804842360   0: 0.027027744271360   6: 0.027027716969274   9: 0.027027716041967   1: 0.027027711944900   7: 0.027027689342114 

training_5496     5: 0.510938688116829   4: 0.287449055657149   1: 0.025208225866747   2: 0.025203442246303   9: 0.025203010179263   0: 0.025200023400171   7: 0.025199961049407   8: 0.025199285432187   3: 0.025199168595602   6: 0.025199139456343 

training_5498     6: 0.755251773221134   5: 0.027199032593801   7: 0.027198409394784   1: 0.027195801286273   9: 0.027195611229784   0: 0.027192447096966   4: 0.027192230802620   8: 0.027192159392385   3: 0.027191327154356   2: 0.027191207827897 

training_5499     1: 0.631748512858372   8: 0.199602274400277   0: 0.041365687028927   6: 0.018226935362514   5: 0.018178399084049   7: 0.018176752417548   4: 0.018175995559604   9: 0.018175977074900   2: 0.018174802504169   3: 0.018174663709639 

training_550      6: 0.675937883073842   5: 0.100968395691811   9: 0.075250154570715   0: 0.063436447725250   1: 0.014079280525391   4: 0.014068040916129   7: 0.014065438647608   8: 0.014065078532940   2: 0.014064895203034   3: 0.014064385113278 

training_5500     5: 0.555865147893538   6: 0.296052699698118   0: 0.018513918448625   4: 0.018512791128776   8: 0.018510443104506   1: 0.018510342893352   9: 0.018510020945135   7: 0.018508370944783   2: 0.018508236491203   3: 0.018508028451965 

training_5501     4: 0.770466636741047   5: 0.025511488832758   8: 0.025503017284590   9: 0.025502819741180   3: 0.025502805365947   2: 0.025502743328201   7: 0.025502686985948   0: 0.025502647875114   1: 0.025502590796383   6: 0.025502563048832 

training_5502     5: 0.737760162656045   3: 0.029139123866930   4: 0.029137994543083   6: 0.029137754697295   1: 0.029137683826290   0: 0.029137667690485   2: 0.029137486724134   7: 0.029137468292554   8: 0.029137362561046   9: 0.029137295142137 

training_5505     1: 0.516177077199512   0: 0.311182240570373   5: 0.021584962758349   6: 0.021584568897615   4: 0.021579839826046   9: 0.021579716027901   7: 0.021578122100896   8: 0.021578103284655   3: 0.021577809608186   2: 0.021577559726468 

training_5506     6: 0.801579672009157   1: 0.068807568501358   2: 0.033435692539777   0: 0.013746430123466   5: 0.013739854479171   8: 0.013739025552343   4: 0.013738535586866   9: 0.013737792173745   7: 0.013737728024333   3: 0.013737701009785 

training_5507     6: 0.580450547984546   0: 0.324739276668462   1: 0.011852876882440   5: 0.011851231976850   9: 0.011851128684305   8: 0.011851082310779   2: 0.011851074392681   7: 0.011851006770554   4: 0.011850909830230   3: 0.011850864499154 

training_5508     6: 0.754965613068173   7: 0.060661649174980   9: 0.043042576810223   5: 0.020237915665284   8: 0.020185605382873   1: 0.020184458171933   0: 0.020181108439703   4: 0.020180505462802   2: 0.020180388565731   3: 0.020180179258299 

training_551      2: 0.545526345551843   1: 0.228145634270473   4: 0.075874068105481   5: 0.038009429768241   6: 0.018790076833184   0: 0.018779870507056   9: 0.018725439472238   8: 0.018723327430295   3: 0.018713328274690   7: 0.018712479786498 

training_5511     6: 0.488979123639486   5: 0.367707074767288   9: 0.031688955532288   1: 0.015952464433052   0: 0.015947491729977   4: 0.015945174720743   2: 0.015945155761303   8: 0.015945109841718   7: 0.015944819610036   3: 0.015944629964109 

training_5516     1: 0.682611296052632   4: 0.135854774277414   9: 0.052905041557106   5: 0.029983510950020   8: 0.016569790290038   7: 0.016448930706879   0: 0.016419548865213   6: 0.016410823168463   2: 0.016400665421470   3: 0.016395618710765 

training_5517     5: 0.522946414954853   8: 0.281273929921201   6: 0.061633168588486   1: 0.019191735545606   0: 0.019183574569167   2: 0.019160933908764   9: 0.019154784598914   4: 0.019152050012152   3: 0.019151729502978   7: 0.019151678397878 

training_5518     6: 0.802731570971588   1: 0.051132392256917   0: 0.046359081875166   9: 0.014294057037635   5: 0.014253368103840   8: 0.014246500566610   7: 0.014245885564573   3: 0.014245863640486   2: 0.014245642137017   4: 0.014245637846168 

training_552      4: 0.415811014110938   6: 0.228956890576077   2: 0.191518399279950   5: 0.023393230111793   0: 0.023390611797736   9: 0.023388477298674   1: 0.023387094408036   8: 0.023385709168996   7: 0.023384812133561   3: 0.023383761114240 

training_5520     5: 0.770470805826657   0: 0.056995728019392   6: 0.021576631982078   1: 0.021570063883292   9: 0.021567554788797   8: 0.021564093165178   7: 0.021563978954360   4: 0.021563905740353   2: 0.021563852523330   3: 0.021563385116564 

training_5522     5: 0.791522327202638   4: 0.023164849554975   3: 0.023164584183142   6: 0.023164219142681   1: 0.023164110945604   8: 0.023164036247642   0: 0.023164032400249   7: 0.023163998778810   2: 0.023163984979489   9: 0.023163856564770 

training_5523     6: 0.745868248478186   0: 0.085352923194947   3: 0.070688546111293   9: 0.014016547167837   1: 0.014016344868214   8: 0.014014812290373   7: 0.014011557662997   5: 0.014010673971189   4: 0.014010326711249   2: 0.014010019543716 

training_5525     5: 0.846264934806737   7: 0.032436398587524   0: 0.015414758066273   9: 0.015131184420814   6: 0.015128540643649   2: 0.015126638953486   1: 0.015126480516441   4: 0.015123862313520   8: 0.015123683425436   3: 0.015123518266120 

training_5526     6: 0.440719816266201   2: 0.216675917127920   8: 0.205361797407993   5: 0.019607777073716   4: 0.019607565445735   9: 0.019606594979645   1: 0.019605506073454   0: 0.019605286161290   7: 0.019605000112872   3: 0.019604739351175 

training_5528     5: 0.543795681190243   1: 0.172791647060255   4: 0.118718586091983   0: 0.023530289615831   2: 0.023527807281463   3: 0.023527578352950   9: 0.023527425776701   6: 0.023527397421652   8: 0.023526875080999   7: 0.023526712127924 

training_553      1: 0.464989128136896   9: 0.381022451894569   7: 0.019297265163799   0: 0.019250289911177   4: 0.019245574912831   5: 0.019245490316732   8: 0.019240152945800   6: 0.019238090006245   2: 0.019236996048078   3: 0.019234560663873 

training_5530     4: 0.776252401610091   5: 0.024866839020841   0: 0.024861103546772   8: 0.024860228812964   6: 0.024860218932863   9: 0.024860161370903   1: 0.024859986610047   7: 0.024859762072564   3: 0.024859671778204   2: 0.024859626244749 

training_5531     8: 0.435170853146560   6: 0.364398738357403   1: 0.046539465682502   5: 0.022010693409290   0: 0.021983820783483   7: 0.021980253395998   4: 0.021979911483377   9: 0.021979747041834   3: 0.021978287313193   2: 0.021978229386360 

training_5532     5: 0.818995019271353   6: 0.020113346857280   4: 0.020112746497052   7: 0.020111979633288   8: 0.020111408116125   9: 0.020111297268048   1: 0.020111274233076   0: 0.020111221641665   3: 0.020110876595439   2: 0.020110829886673 

training_5533     2: 0.727449193962427   6: 0.111715361161869   1: 0.020108012211121   5: 0.020107830996145   0: 0.020106988860184   7: 0.020104368168592   4: 0.020103970154302   3: 0.020101526163531   9: 0.020101476676088   8: 0.020101271645741 

training_5535     5: 0.744461181559510   4: 0.028396822502248   8: 0.028393210574642   9: 0.028393120220512   1: 0.028393093542328   0: 0.028393091061462   6: 0.028392758915568   3: 0.028392336283368   2: 0.028392213139810   7: 0.028392172200553 

training_5537     5: 0.801593517287877   0: 0.022050629513186   1: 0.022048241618643   6: 0.022047701755066   9: 0.022043765981478   7: 0.022043499139230   2: 0.022043317037626   8: 0.022043198494961   4: 0.022043155346948   3: 0.022042973824985 

training_5538     4: 0.603486386394717   9: 0.223058518787513   5: 0.021685973333238   2: 0.021685731684902   6: 0.021684951943035   0: 0.021680030580031   1: 0.021679928720733   3: 0.021679560425452   8: 0.021679509319910   7: 0.021679408810469 

training_554      5: 0.462127460618367   4: 0.338533035958999   3: 0.024918497149543   0: 0.024917443102026   8: 0.024917394267377   6: 0.024917358606758   1: 0.024917295190275   2: 0.024917246167389   7: 0.024917165058771   9: 0.024917103880496 

training_5540     5: 0.608435664305390   4: 0.148392016699173   1: 0.073893556002738   2: 0.024237273283173   0: 0.024187067263492   6: 0.024186621041062   7: 0.024176839613722   9: 0.024163739950205   3: 0.024163668295257   8: 0.024163553545789 

training_5541     6: 0.685194623999663   5: 0.086556442148522   9: 0.080095236522299   3: 0.049570127366766   0: 0.029780061211277   4: 0.013848442378297   2: 0.013743683313759   1: 0.013739040488581   7: 0.013737596871072   8: 0.013734745699762 

training_5542     6: 0.818600015212620   0: 0.056314771028915   1: 0.035384138851086   3: 0.025401752117911   2: 0.010740975534039   9: 0.010733624058817   5: 0.010713841103508   8: 0.010704354360745   4: 0.010704175620725   7: 0.010702352111635 

training_5543     5: 0.495606786336216   4: 0.336008017377225   7: 0.049651959884667   2: 0.017030272127241   1: 0.016986576984400   6: 0.016950101978684   0: 0.016945175512824   3: 0.016940576764095   8: 0.016940295509547   9: 0.016940237525101 

training_5544     4: 0.816143764294540   3: 0.020483437074638   5: 0.020425975030613   2: 0.020425215315160   6: 0.020423509934625   1: 0.020421045125826   9: 0.020420095999321   0: 0.020419701537744   8: 0.020418921483294   7: 0.020418334204239 

training_5545     4: 0.724718806323327   5: 0.030590558556315   8: 0.030586548641176   6: 0.030586531068278   0: 0.030586437886179   1: 0.030586288403400   2: 0.030586284249893   7: 0.030586214660294   9: 0.030586173239800   3: 0.030586156971338 

training_5546     5: 0.778187429207531   6: 0.024646643516225   2: 0.024646296797272   3: 0.024645991735123   9: 0.024645961754862   4: 0.024645750443259   8: 0.024645550788770   0: 0.024645512092024   7: 0.024645437255411   1: 0.024645426409522 

training_5549     2: 0.365866115051819   5: 0.341374581175923   4: 0.036605565941212   1: 0.036603699715548   3: 0.036592456733117   8: 0.036591978959255   7: 0.036591665590625   9: 0.036591421537352   0: 0.036591387688137   6: 0.036591127607012 

training_555      5: 0.763638090409807   2: 0.054087640407736   8: 0.046173019530970   6: 0.019447127008144   0: 0.019444525426149   1: 0.019443338427726   9: 0.019443015307636   7: 0.019441193071925   3: 0.019441168344736   4: 0.019440882065170 

training_5553     1: 0.438935584009732   2: 0.240147692954555   6: 0.171411585597857   3: 0.021376746112856   4: 0.021357159157497   0: 0.021355392667817   5: 0.021354703222132   7: 0.021354389044815   9: 0.021353698295421   8: 0.021353048937317 

training_5554     6: 0.736279457746826   0: 0.111027271032970   3: 0.041621508540471   8: 0.033938029185332   2: 0.019677849549308   4: 0.011492467617236   5: 0.011492368879635   9: 0.011491107589047   7: 0.011489981814339   1: 0.011489958044836 

training_5555     5: 0.770799891661229   4: 0.025472179154362   0: 0.025466781485022   1: 0.025466618184040   6: 0.025466177852478   8: 0.025465860691551   9: 0.025465738792130   2: 0.025465662370961   3: 0.025465550207702   7: 0.025465539600525 

training_5556     5: 0.453036363304902   2: 0.333756701804580   4: 0.026655882624356   1: 0.026653207613365   8: 0.026650505927227   9: 0.026649878423421   3: 0.026649517591557   7: 0.026649351281025   0: 0.026649343775706   6: 0.026649247653862 

training_5558     6: 0.753119013958157   9: 0.065243680859975   3: 0.051222001140700   0: 0.048433578903765   1: 0.013677898763794   5: 0.013676088879480   4: 0.013663884642416   7: 0.013659072340441   2: 0.013658444995280   8: 0.013646335515994 

training_5559     4: 0.602947064595415   6: 0.179566156371194   5: 0.093221657432040   7: 0.017955512065553   9: 0.017727064019163   2: 0.017722369530303   1: 0.017718317579949   0: 0.017718003534277   3: 0.017712225674765   8: 0.017711629197342 

training_5561     6: 0.722643344226602   1: 0.112705732777164   0: 0.098670873936483   9: 0.014205043858274   8: 0.008968055443471   3: 0.008607055921348   5: 0.008558433416999   4: 0.008547784686799   7: 0.008546937482956   2: 0.008546738249904 

training_5563     5: 0.811876756054543   6: 0.020913755390618   0: 0.020906894600411   9: 0.020902949462852   4: 0.020901946623700   1: 0.020900603325156   8: 0.020900203839440   7: 0.020899487366776   2: 0.020898908905890   3: 0.020898494430614 

training_5564     6: 0.540910059750841   8: 0.263939722054012   2: 0.049603309207537   9: 0.020797277896464   4: 0.020795985780770   5: 0.020794545493822   1: 0.020790380560558   0: 0.020789921840203   7: 0.020789493568563   3: 0.020789303847231 

training_5565     4: 0.660301752497557   6: 0.146254541033935   5: 0.024189027609713   8: 0.024179528864724   3: 0.024179314932472   2: 0.024179250987012   9: 0.024179168707998   0: 0.024179165497517   1: 0.024179136001774   7: 0.024179113867298 

training_5566     4: 0.652192059564996   8: 0.105799834864253   5: 0.089201052131739   0: 0.021881972943785   1: 0.021864391549548   2: 0.021824852125582   6: 0.021810569587583   3: 0.021809561782310   9: 0.021807900680345   7: 0.021807804769859 

training_5567     0: 0.510646734134338   6: 0.173162932799758   9: 0.105934619045520   8: 0.076345246203933   2: 0.042069860478964   5: 0.018408905250359   1: 0.018377795642173   7: 0.018353681605135   4: 0.018352198053908   3: 0.018348026785912 

training_5568     5: 0.718220006484606   7: 0.031324063262853   1: 0.031310026446092   0: 0.031309657556449   3: 0.031306176646565   2: 0.031306107384815   6: 0.031306092777182   4: 0.031306069491603   8: 0.031305910865185   9: 0.031305889084650 

training_557      5: 0.764973483528464   8: 0.068719277863149   4: 0.020792587131219   0: 0.020789987410597   6: 0.020788136053640   3: 0.020787349285508   9: 0.020787319505410   2: 0.020787297352095   7: 0.020787295934537   1: 0.020787265935382 

training_5570     6: 0.800800992520669   0: 0.076513964189910   5: 0.052154657667595   4: 0.010203140772504   9: 0.010066052182477   8: 0.010057091909121   1: 0.010052804880026   7: 0.010050682505091   2: 0.010050311410670   3: 0.010050301961937 

training_5571     5: 0.391842331331094   4: 0.243789535587318   8: 0.167694916055383   6: 0.028100650222806   0: 0.028098968106346   1: 0.028097572185707   3: 0.028094796119153   9: 0.028094407438636   2: 0.028093537250808   7: 0.028093285702750 

training_5572     4: 0.734530135368307   5: 0.029503460284802   6: 0.029498539414263   0: 0.029495880996954   8: 0.029495501670684   3: 0.029495433289920   2: 0.029495330208822   7: 0.029495271880275   9: 0.029495238562642   1: 0.029495208323332 

training_5573     5: 0.843264577134695   7: 0.017451776068912   6: 0.017417878332140   1: 0.017413973913184   0: 0.017411390096120   4: 0.017411094125457   2: 0.017407628201759   9: 0.017407334159729   8: 0.017407214660093   3: 0.017407133307910 

training_5575     4: 0.810071323050620   5: 0.021108122848852   6: 0.021103640312232   0: 0.021102846788655   1: 0.021102813643418   9: 0.021102462525154   2: 0.021102350497623   3: 0.021102270785322   8: 0.021102115507315   7: 0.021102054040809 

training_5576     5: 0.801503392028467   8: 0.054786929403452   4: 0.017969018128031   9: 0.017963214700732   6: 0.017962955398016   0: 0.017962952417718   3: 0.017962915503387   1: 0.017962897866830   7: 0.017962897266678   2: 0.017962827286689 

training_5579     5: 0.752397285534248   4: 0.070565061209504   2: 0.022150826253726   9: 0.022150217541679   1: 0.022143593763299   6: 0.022122315995093   0: 0.022119073334317   3: 0.022117391766647   7: 0.022117327820202   8: 0.022116906781286 

training_558      3: 0.492291970721614   0: 0.305392523262795   1: 0.025297273893544   6: 0.025294169454135   5: 0.025293179387102   2: 0.025287784458551   4: 0.025287733677439   7: 0.025286013309650   9: 0.025284849353005   8: 0.025284502482164 

training_5582     5: 0.651276137454725   0: 0.175470638447891   4: 0.021660199548649   6: 0.021657190760011   1: 0.021656653567611   8: 0.021656032652002   3: 0.021655829290306   7: 0.021655809906482   9: 0.021655768464639   2: 0.021655739907682 

training_5583     0: 0.470792937666751   5: 0.318415201643358   6: 0.026352065144636   4: 0.026351683677217   9: 0.026348944239659   1: 0.026348805382607   8: 0.026348238635288   2: 0.026347648871366   7: 0.026347491063008   3: 0.026346983676110 

training_5585     1: 0.503239089781572   5: 0.382098514341581   7: 0.026754350657158   0: 0.012567202698751   6: 0.012562099450441   4: 0.012557510566309   3: 0.012555360036379   2: 0.012555339104169   9: 0.012555290165458   8: 0.012555243198181 

training_5586     5: 0.447639586043510   4: 0.285654410402970   6: 0.135362319747014   8: 0.018866170275525   0: 0.018757394400350   1: 0.018746621455286   9: 0.018744021642955   7: 0.018743241370394   3: 0.018743202844544   2: 0.018743031817451 

training_559      1: 0.485749222367346   4: 0.198455009883011   6: 0.190183145859845   5: 0.017948621538508   0: 0.017945291609167   9: 0.017945214912093   2: 0.017943660064763   3: 0.017943583150176   7: 0.017943235040804   8: 0.017943015574285 

training_5592     4: 0.785928366574588   9: 0.053858855947719   0: 0.020046554963246   5: 0.020030627098773   6: 0.020026988921154   8: 0.020022163984741   7: 0.020021821315698   1: 0.020021786343116   2: 0.020021418142267   3: 0.020021416708698 

training_5593     5: 0.584771671079672   8: 0.102208827442981   3: 0.101563089866732   0: 0.099190464439735   1: 0.018720798302003   6: 0.018710159487981   9: 0.018709736513373   4: 0.018708871912610   2: 0.018708520527579   7: 0.018707860427334 

training_5594     5: 0.770019404130089   4: 0.025556078530467   6: 0.025554202893046   8: 0.025553724782469   9: 0.025552928771137   1: 0.025552901498242   7: 0.025552754590831   0: 0.025552727269392   2: 0.025552702412960   3: 0.025552575121367 

training_5595     4: 0.815468999049081   6: 0.020513359129108   9: 0.020506819941515   5: 0.020505797122766   0: 0.020504695004950   1: 0.020500381201848   3: 0.020500362238142   8: 0.020500031735471   2: 0.020499874714926   7: 0.020499679862194 

training_5596     5: 0.386093475269559   3: 0.380854852305783   9: 0.090863701449610   6: 0.020319957311274   1: 0.020317471619952   0: 0.020315801636827   8: 0.020309230712415   4: 0.020309080954216   7: 0.020308314488693   2: 0.020308114251671 

training_5597     6: 0.294222279814589   5: 0.275634035821552   8: 0.208662484923368   0: 0.124588503138887   1: 0.016172279097651   7: 0.016145859315333   9: 0.016143853965745   3: 0.016143763346013   2: 0.016143603452224   4: 0.016143337124637 

training_5598     6: 0.771541773905550   8: 0.073510238479796   0: 0.047118641939891   7: 0.024006927669501   1: 0.013974541162485   3: 0.013972380355579   5: 0.013970654657331   9: 0.013969057106653   2: 0.013968185280104   4: 0.013967599443109 

training_56       6: 0.655679865894150   5: 0.196774099844167   7: 0.041458511588880   4: 0.030321831238742   8: 0.012644496458489   3: 0.012628007245184   0: 0.012626949158044   9: 0.012625450391832   1: 0.012621065117414   2: 0.012619723063098 

training_560      4: 0.769948242733043   5: 0.025566744728795   8: 0.025560836733385   3: 0.025560707386430   1: 0.025560686946070   2: 0.025560659828393   9: 0.025560567777169   0: 0.025560536381119   7: 0.025560530857695   6: 0.025560486627902 

training_5600     5: 0.805621058655148   4: 0.021602777944596   6: 0.021597611606419   0: 0.021597167026875   8: 0.021597111522653   1: 0.021596960635988   9: 0.021596864347677   3: 0.021596853179012   2: 0.021596824551184   7: 0.021596770530450 

training_5602     4: 0.691853709651991   8: 0.114357558339121   5: 0.024232894858405   0: 0.024224336055454   1: 0.024223509312806   6: 0.024223114090337   9: 0.024221487615856   2: 0.024221397871528   3: 0.024220999117191   7: 0.024220993087311 

training_5603     8: 0.491845913564286   5: 0.279827204521748   3: 0.028542340088721   4: 0.028541838291438   0: 0.028540615766329   6: 0.028540562165537   1: 0.028540501261849   2: 0.028540488064011   7: 0.028540308732639   9: 0.028540227543442 

training_5604     5: 0.765809387548267   3: 0.026022003865267   4: 0.026021410560696   6: 0.026021102831412   0: 0.026021091916423   8: 0.026021084144598   1: 0.026020995161932   2: 0.026020994961805   7: 0.026020982941541   9: 0.026020946068059 

training_5606     8: 0.595969725102809   1: 0.183390730043603   6: 0.027596272342077   7: 0.027579340787610   0: 0.027578538352334   9: 0.027577237633841   5: 0.027577234888262   2: 0.027577036526259   3: 0.027576980745056   4: 0.027576903578149 

training_5608     5: 0.744003051574560   9: 0.096420992083413   6: 0.019956737937525   0: 0.019949326337556   1: 0.019949280392814   8: 0.019946284253551   4: 0.019944400290962   2: 0.019943382526430   7: 0.019943294631062   3: 0.019943249972126 

training_5609     6: 0.812747868897008   0: 0.042259079463213   5: 0.018137724784125   1: 0.018125653279150   4: 0.018124502404479   2: 0.018123238663622   9: 0.018120846413356   3: 0.018120554727321   8: 0.018120354873903   7: 0.018120176493824 

training_5610     6: 0.795481170839303   3: 0.039280603503987   8: 0.038046281515269   1: 0.018192101532973   7: 0.018190724375440   9: 0.018163727884427   0: 0.018163512263557   5: 0.018161631597511   2: 0.018160232133661   4: 0.018160014353871 

training_5611     6: 0.782066696513662   0: 0.075219863452110   8: 0.017999788867314   1: 0.017816937488657   9: 0.017816476247621   5: 0.017816366574828   7: 0.017816075121217   4: 0.017816019641882   3: 0.017815904090981   2: 0.017815872001728 

training_5615     5: 0.502658111347613   6: 0.234315637644909   3: 0.127883053397916   2: 0.019313985540092   4: 0.019310383217797   0: 0.019306990570612   1: 0.019306746310321   8: 0.019303267834730   7: 0.019301219481642   9: 0.019300604654368 

training_5617     5: 0.440453505434241   6: 0.321864770611169   4: 0.029722731035301   8: 0.029710383547171   1: 0.029708397679135   3: 0.029708202802881   0: 0.029708181938522   9: 0.029708152662769   2: 0.029707932343003   7: 0.029707741945808 

training_562      6: 0.694237430981877   8: 0.094096367262170   1: 0.071684320667429   0: 0.060390643158300   5: 0.013265980304159   3: 0.013265483418979   9: 0.013265477583529   7: 0.013264983915203   4: 0.013264776030433   2: 0.013264536677922 

training_5620     5: 0.590634767957611   6: 0.234847925503348   1: 0.039025450549727   8: 0.019394161187654   7: 0.019359987529020   0: 0.019349367508510   9: 0.019347752320973   4: 0.019347359496700   2: 0.019346736803501   3: 0.019346491142956 

training_5624     4: 0.703113757403688   0: 0.089102678439041   6: 0.026004149085130   5: 0.025973768627707   8: 0.025967811890649   9: 0.025967677823067   3: 0.025967636595572   2: 0.025967567849894   1: 0.025967481449160   7: 0.025967470836093 

training_5627     1: 0.437924389078166   5: 0.250916723269338   6: 0.177212860335836   7: 0.019158966027933   0: 0.019138808612766   9: 0.019130214572713   4: 0.019130191412763   8: 0.019129852485500   3: 0.019129141887814   2: 0.019128852317171 

training_5629     4: 0.407287653823632   6: 0.350049082873272   5: 0.030344174272689   8: 0.030332774879575   1: 0.030331507130651   9: 0.030331258208059   3: 0.030331104455343   0: 0.030331060095320   2: 0.030330812070282   7: 0.030330572191177 

training_5630     3: 0.347094651271329   6: 0.334041955894471   0: 0.151995020164149   9: 0.081007769155933   2: 0.014339314429068   8: 0.014311166378147   7: 0.014311125524629   1: 0.014301112547367   5: 0.014300247508546   4: 0.014297637126361 

training_5632     5: 0.788091724442888   8: 0.064629319369131   4: 0.018412466978530   1: 0.018409819947296   6: 0.018409593269269   3: 0.018409566903467   0: 0.018409546050147   9: 0.018409494985854   2: 0.018409305896132   7: 0.018409162157286 

training_5634     1: 0.475206559793937   0: 0.182261390863514   7: 0.152863750083421   6: 0.027098899595370   4: 0.027096189217054   5: 0.027095196696446   8: 0.027094725429172   2: 0.027094670499826   9: 0.027094346110883   3: 0.027094271710376 

training_5635     6: 0.574325234992222   0: 0.265084990531923   3: 0.040026958668727   5: 0.017226345504604   4: 0.017223776594840   8: 0.017223529083250   1: 0.017223345169240   9: 0.017222163221261   2: 0.017221852036348   7: 0.017221804197585 

training_5636     6: 0.714097400014987   0: 0.093557268859008   7: 0.079731151984340   5: 0.016090566306168   4: 0.016087899178057   1: 0.016087783019150   2: 0.016087264045505   8: 0.016087192546821   9: 0.016087173469172   3: 0.016086300576794 

training_5637     6: 0.505521273713228   7: 0.271667412374403   1: 0.027852710796605   0: 0.027852303221355   8: 0.027851714755777   5: 0.027851300446522   9: 0.027850994449593   2: 0.027850943883701   4: 0.027850842057455   3: 0.027850504301362 

training_5639     6: 0.654400819339018   4: 0.169742054399506   8: 0.074237592701371   5: 0.014754638495220   0: 0.014495603921581   1: 0.014483000942007   9: 0.014473236254408   7: 0.014471558244860   3: 0.014470837920937   2: 0.014470657781093 

training_5640     6: 0.779347220523655   7: 0.076731766275019   5: 0.017992562777227   0: 0.017991775631691   1: 0.017990185048657   4: 0.017989569577598   3: 0.017989271104637   2: 0.017989233108195   9: 0.017989225235533   8: 0.017989190717788 

training_5641     1: 0.502855813225864   0: 0.216775720272599   8: 0.087965274631782   5: 0.067421006437848   4: 0.043299977985793   6: 0.016344729129081   3: 0.016340763909658   2: 0.016335863347673   9: 0.016333274787488   7: 0.016327576272213 

training_5643     1: 0.374062168005307   6: 0.287887228910226   0: 0.226325557223648   7: 0.031776127054904   9: 0.020600586367692   5: 0.011882568919393   4: 0.011868049486837   8: 0.011866149237261   2: 0.011865808107356   3: 0.011865756687375 

training_5644     5: 0.453247961970118   6: 0.307582774737567   0: 0.054755095134824   8: 0.051734506929457   9: 0.022126469849326   1: 0.022112319495355   7: 0.022110403096375   2: 0.022110328562489   4: 0.022110255529907   3: 0.022109884694582 

training_5647     5: 0.442817051673277   2: 0.263644022817438   6: 0.180036251533788   1: 0.016217205388128   0: 0.016215578308581   9: 0.016215268430882   4: 0.016215239302646   7: 0.016213373477064   8: 0.016213313803867   3: 0.016212695264330 

training_5648     6: 0.567689004618091   0: 0.183500668151888   8: 0.113903682537184   3: 0.040440385403827   5: 0.015745326630177   1: 0.015745158060935   9: 0.015744091362219   7: 0.015744031472238   4: 0.015744013543463   2: 0.015743638219978 

training_5650     4: 0.740853771005615   5: 0.028799978005984   8: 0.028794118971062   9: 0.028793502026093   3: 0.028793256244623   7: 0.028793169895341   2: 0.028793146704239   1: 0.028793042183664   6: 0.028793014142025   0: 0.028793000821353 

training_5652     6: 0.753704859124651   1: 0.027376753490292   0: 0.027370396576654   5: 0.027367922892389   4: 0.027364343418489   2: 0.027364100133214   7: 0.027363105563346   8: 0.027362916911789   9: 0.027362813913080   3: 0.027362787976096 

training_5654     5: 0.783771814317901   4: 0.024032172937281   8: 0.024024694905749   0: 0.024024554980145   3: 0.024024521286996   9: 0.024024501781029   2: 0.024024459316882   1: 0.024024438331030   7: 0.024024428719935   6: 0.024024413423053 

training_5655     6: 0.722073214173067   7: 0.064739654759796   8: 0.059453445700019   0: 0.056468070460911   1: 0.016220222174114   9: 0.016211080768103   5: 0.016208901861996   3: 0.016208800163088   4: 0.016208378786308   2: 0.016208231152598 

training_5657     5: 0.799904674700248   9: 0.053306182914134   3: 0.018367359039934   8: 0.018358707682177   6: 0.018347160501729   4: 0.018344819049274   0: 0.018343616624867   2: 0.018343457444753   1: 0.018343050724732   7: 0.018340971318151 

training_5658     5: 0.470784218413172   7: 0.300960534256592   9: 0.067614488622015   0: 0.022950965549374   6: 0.022950176902867   4: 0.022950170463777   2: 0.022948240350470   1: 0.022947168674722   3: 0.022947087452400   8: 0.022946949314612 

training_5659     0: 0.548666071352871   4: 0.156927479151857   3: 0.147455566550245   1: 0.048814003917907   9: 0.016376003773452   5: 0.016371163937326   6: 0.016359539758384   7: 0.016344645365228   2: 0.016344078467942   8: 0.016341447724788 

training_5660     0: 0.579533859342901   4: 0.221914636016948   7: 0.051575470374048   1: 0.045915581205485   6: 0.016846864950523   5: 0.016846707318967   9: 0.016842583850460   8: 0.016842051962656   2: 0.016841129017241   3: 0.016841115960772 

training_5661     5: 0.477141896960295   6: 0.333186069550769   1: 0.039954966585460   8: 0.039440310545622   0: 0.018438758795125   4: 0.018407676481064   9: 0.018359556260254   7: 0.018357180468265   3: 0.018356825910684   2: 0.018356758442463 

training_5662     5: 0.374104922826799   1: 0.268592866876546   3: 0.189065465677820   8: 0.024034581747785   4: 0.024034369271727   6: 0.024033838952377   0: 0.024033705699027   2: 0.024033460234144   7: 0.024033439240129   9: 0.024033349473646 

training_5663     5: 0.787238265158225   4: 0.023641513732429   3: 0.023640389919378   6: 0.023640127179404   1: 0.023640104541702   2: 0.023639992175297   7: 0.023639974976336   0: 0.023639928963114   8: 0.023639889293721   9: 0.023639814060395 

training_5664     6: 0.752694002966108   1: 0.027498660167435   0: 0.027478733759859   5: 0.027478004035480   2: 0.027477083808843   7: 0.027475202577403   9: 0.027474985311855   4: 0.027474640795867   3: 0.027474468730166   8: 0.027474217846984 

training_5665     5: 0.467663784325518   0: 0.361420568646473   1: 0.021373015300345   6: 0.021367038500240   8: 0.021363328381309   9: 0.021362934150954   7: 0.021362611696837   2: 0.021362509220650   4: 0.021362413127101   3: 0.021361796650572 

training_5667     5: 0.593047358789536   6: 0.252115451554991   9: 0.019423589222168   0: 0.019357180558646   1: 0.019353312197351   2: 0.019343394969319   7: 0.019340444537234   8: 0.019339938345598   4: 0.019339830488388   3: 0.019339499336769 

training_5669     4: 0.767071916091000   5: 0.025884328009122   6: 0.025882509911722   1: 0.025881968487993   2: 0.025881665613255   7: 0.025880724399752   8: 0.025880354423018   3: 0.025879808105873   9: 0.025878478662912   0: 0.025878246295354 

training_5670     6: 0.346746361160994   5: 0.260487474966460   8: 0.149761066345736   4: 0.120836312354125   2: 0.040590530146799   1: 0.016318441000654   3: 0.016317995347415   0: 0.016314713992546   9: 0.016313915006371   7: 0.016313189678900 

training_5671     6: 0.606617571039384   1: 0.225982176201580   7: 0.033042742670412   5: 0.028242239998144   0: 0.017749120280623   2: 0.017704664566597   9: 0.017670791532695   8: 0.017664643076490   4: 0.017663144501320   3: 0.017662906132755 

training_5672     0: 0.792018906642432   3: 0.058705571955879   6: 0.018667756376977   1: 0.018660495159466   5: 0.018659330465155   8: 0.018658945741362   9: 0.018657963469606   7: 0.018657339613212   4: 0.018656965144189   2: 0.018656725431722 

training_5675     5: 0.747964565081402   0: 0.111240792087095   2: 0.017610842284673   6: 0.017604420411685   9: 0.017600083877924   4: 0.017598221179788   1: 0.017598153564167   7: 0.017594601043409   8: 0.017594447528584   3: 0.017593872941274 

training_5677     5: 0.776372536892191   4: 0.024850238764311   6: 0.024848998902568   2: 0.024847394911036   0: 0.024847009623395   8: 0.024846908689447   7: 0.024846888011801   9: 0.024846858566332   3: 0.024846614905613   1: 0.024846550733306 

training_5678     5: 0.751907085308240   6: 0.027567909825067   4: 0.027567903026242   0: 0.027567879096639   1: 0.027566583409746   9: 0.027565037165723   8: 0.027564847834488   3: 0.027564298037478   2: 0.027564255461282   7: 0.027564200835095 

training_5679     4: 0.753858821843039   5: 0.027355900962771   8: 0.027348467499570   9: 0.027348455174625   0: 0.027348185457521   3: 0.027348176020489   2: 0.027348087617973   1: 0.027348022857743   7: 0.027347950952407   6: 0.027347931613863 

training_5680     5: 0.600437889520862   8: 0.236944506527335   4: 0.020329071606170   0: 0.020328647057482   6: 0.020328221541129   9: 0.020326722250295   1: 0.020326385701345   3: 0.020326210095100   7: 0.020326179560508   2: 0.020326166139771 

training_5682     5: 0.801378981632818   4: 0.022073237998931   8: 0.022068595772472   0: 0.022068549456642   3: 0.022068479838530   9: 0.022068460002637   2: 0.022068458321767   6: 0.022068443186976   7: 0.022068420561022   1: 0.022068373228205 

training_5683     6: 0.792584133611506   0: 0.061628935824007   4: 0.042947104440678   8: 0.024120986843427   5: 0.013131858428556   1: 0.013121175645758   9: 0.013117917620468   2: 0.013116129598875   7: 0.013116039232373   3: 0.013115718754352 

training_5684     6: 0.827427497428629   5: 0.046938696892432   0: 0.026396054733599   1: 0.014290482203038   4: 0.014159351877778   9: 0.014157940523401   8: 0.014157836519477   7: 0.014157567149763   2: 0.014157366519164   3: 0.014157206152719 

training_5686     2: 0.491000743001721   6: 0.262637315324138   9: 0.093832736127510   7: 0.039528107506895   1: 0.018839964634022   5: 0.018838641787854   0: 0.018834430906203   4: 0.018831213457192   3: 0.018829095605805   8: 0.018827751648660 

training_5687     5: 0.597118107597397   0: 0.125667670429634   3: 0.112895352814744   4: 0.023474606974281   6: 0.023474148272691   7: 0.023474104444961   8: 0.023474091891155   2: 0.023473987422176   1: 0.023473981423362   9: 0.023473948729599 

training_5688     2: 0.399559220520538   5: 0.359963715106698   6: 0.030066862317379   0: 0.030066047741178   1: 0.030065848598521   4: 0.030060578347905   9: 0.030056879667145   7: 0.030054138790331   3: 0.030053441732119   8: 0.030053267178187 

training_5689     5: 0.449762071987364   6: 0.257100813080428   8: 0.106325883338916   0: 0.057864260747064   9: 0.021507280888423   1: 0.021492464071768   7: 0.021487011230434   2: 0.021486989219263   4: 0.021486768396316   3: 0.021486457040024 

training_5690     0: 0.324300669951783   1: 0.303750799851568   6: 0.163102341894154   9: 0.060215782057252   7: 0.056803125579087   5: 0.046927299112033   4: 0.011225633853892   2: 0.011224986803578   8: 0.011224874343979   3: 0.011224486552674 

training_5692     6: 0.821827528296121   5: 0.050014331484573   0: 0.026175094842618   1: 0.014717066339933   4: 0.014546038746484   8: 0.014544291571871   9: 0.014544259140648   7: 0.014543996616795   2: 0.014543795971848   3: 0.014543596989108 

training_5693     3: 0.430077636075054   6: 0.223509664841447   1: 0.138507566789428   0: 0.048874439931658   2: 0.044336324848354   5: 0.042991652057734   9: 0.017927427359326   8: 0.017925270975918   7: 0.017925115384414   4: 0.017924901736666 

training_5694     5: 0.595245591739700   4: 0.192749129541323   6: 0.026501245811117   1: 0.026501109714829   0: 0.026500917804561   2: 0.026500612350586   9: 0.026500578782930   3: 0.026500422807831   8: 0.026500315549056   7: 0.026500075898067 

training_57       6: 0.639739966485448   7: 0.122785244933918   5: 0.089535768938515   0: 0.044208294536323   4: 0.017290392617419   8: 0.017290272693533   1: 0.017288145141139   9: 0.017287421318998   3: 0.017287320693250   2: 0.017287172641457 

training_5701     5: 0.400814883968532   1: 0.154402244264518   0: 0.151354572929791   6: 0.145861830642461   4: 0.024596208501070   3: 0.024594855610980   2: 0.024594016413428   7: 0.024593826727674   8: 0.024593817305360   9: 0.024593743636186 

training_5702     6: 0.721430608683324   1: 0.136519670234144   5: 0.038213214914861   3: 0.021708887630026   8: 0.014134036599994   0: 0.013889331456219   7: 0.013526525947112   4: 0.013526448876674   9: 0.013525795880455   2: 0.013525479777191 

training_5706     6: 0.565292484869196   2: 0.325847740545951   0: 0.013623318561423   1: 0.013610351816217   9: 0.013609754987007   5: 0.013607786041077   4: 0.013603064329331   7: 0.013602560080151   8: 0.013601833661600   3: 0.013601105108046 

training_5707     5: 0.777109511799351   2: 0.024766502814055   6: 0.024766288878883   4: 0.024766115550515   0: 0.024765495328417   3: 0.024765366801919   1: 0.024765341986070   8: 0.024765165198437   9: 0.024765161363369   7: 0.024765050278984 

training_5708     0: 0.586144953472338   1: 0.172314125823872   7: 0.121780294317051   6: 0.017117095583019   5: 0.017108304565324   2: 0.017107634633224   9: 0.017107091594339   8: 0.017106988927261   4: 0.017106817563632   3: 0.017106693519941 

training_5710     1: 0.519786611314427   6: 0.365970155253608   9: 0.024160542536927   5: 0.017497394018071   2: 0.012302382577194   0: 0.012092958855601   8: 0.012075357896735   4: 0.012048357744882   7: 0.012033373024091   3: 0.012032866778464 

training_5711     0: 0.293383627945402   6: 0.288160388265158   2: 0.266983703900091   4: 0.050457486257978   1: 0.030344100388570   8: 0.028225484388966   5: 0.010708738875907   7: 0.010608532254799   9: 0.010566148470124   3: 0.010561789253005 

training_5712     5: 0.347810350291153   6: 0.276830853765482   2: 0.258229311127296   0: 0.016735116792381   1: 0.016733866993002   4: 0.016733774177404   9: 0.016733365815857   8: 0.016731371691716   3: 0.016731090388635   7: 0.016730898957074 

training_5713     1: 0.588062617710314   4: 0.234408908697738   5: 0.043895588338976   6: 0.019094609039348   0: 0.019093564865608   2: 0.019089804236340   9: 0.019089031718249   8: 0.019088775374156   7: 0.019088610054560   3: 0.019088489964711 

training_5715     6: 0.517412767914649   0: 0.241257561115124   1: 0.030168175302652   9: 0.030166647488446   8: 0.030166557128270   2: 0.030165869444795   5: 0.030165837131603   7: 0.030165591139914   3: 0.030165565842205   4: 0.030165427492342 

training_5716     5: 0.543226287206985   8: 0.236562383622671   4: 0.027532101251281   1: 0.027526798195904   6: 0.027526142631104   0: 0.027525965542798   2: 0.027525523304891   3: 0.027525087367950   7: 0.027524879807416   9: 0.027524831069001 

training_5717     6: 0.773762652791505   0: 0.070133716317242   1: 0.065443294695367   8: 0.024727479865095   3: 0.011013549605972   9: 0.011000920491579   5: 0.010991387854237   7: 0.010976046327706   4: 0.010975732912072   2: 0.010975219139224 

training_5719     6: 0.736432210386849   0: 0.137775861975483   5: 0.015727270360113   7: 0.015727148705052   4: 0.015726568823375   1: 0.015723328196023   9: 0.015722554635173   8: 0.015722149604509   2: 0.015721754669452   3: 0.015721152643970 

training_5720     5: 0.484411283811754   4: 0.318491666896568   2: 0.024638281513388   3: 0.024637706095137   6: 0.024637693788835   0: 0.024636833046810   8: 0.024636771427536   1: 0.024636733339311   7: 0.024636530784670   9: 0.024636499295991 

training_5721     5: 0.772138914868380   3: 0.025318651660509   4: 0.025318120116393   6: 0.025317818372714   0: 0.025317814139619   8: 0.025317798487447   7: 0.025317772586261   1: 0.025317738035516   2: 0.025317718566836   9: 0.025317653166325 

training_5722     5: 0.742227702650861   3: 0.028642338987730   1: 0.028641791505726   4: 0.028641469548563   0: 0.028641346529709   6: 0.028641343336203   7: 0.028641097718361   2: 0.028641040203094   9: 0.028641008796138   8: 0.028640860723615 

training_5723     5: 0.571198576099048   2: 0.235375759789633   4: 0.024186712725578   8: 0.024177534662418   9: 0.024177092837107   1: 0.024177081840428   0: 0.024176996410738   3: 0.024176831071097   6: 0.024176823466770   7: 0.024176591097184 

training_5724     6: 0.429719628554281   1: 0.384626875024058   0: 0.071860223432303   7: 0.039101471823224   9: 0.012452332946319   5: 0.012450165674727   3: 0.012447967766936   8: 0.012447346390916   4: 0.012447275098023   2: 0.012446713289215 

training_5725     4: 0.825427704251394   6: 0.019408921380902   5: 0.019400420286542   9: 0.019398440798770   0: 0.019396161484174   7: 0.019395129361498   8: 0.019393515838654   1: 0.019393497229762   3: 0.019393217227992   2: 0.019392992140311 

training_5727     6: 0.599307213826306   5: 0.140051988462294   7: 0.132634879239596   3: 0.030249591005723   0: 0.023214996756493   1: 0.014916793723903   9: 0.014908267862388   8: 0.014905699415273   4: 0.014905469236918   2: 0.014905100471107 

training_5729     5: 0.453366494664142   1: 0.346180327700579   3: 0.025062954924632   8: 0.025056390710224   4: 0.025056234957234   6: 0.025055792204380   0: 0.025055670356566   2: 0.025055449666339   7: 0.025055372861609   9: 0.025055311954296 

training_5731     5: 0.746002190662731   4: 0.028227385801972   3: 0.028221452203431   8: 0.028221430033124   2: 0.028221334329859   6: 0.028221272749930   7: 0.028221259467015   9: 0.028221246332260   0: 0.028221245619154   1: 0.028221182800525 

training_5732     0: 0.674663500776729   5: 0.106082961022018   9: 0.062096838242485   3: 0.053133738476224   6: 0.017341037453844   4: 0.017338108809212   1: 0.017338067316373   8: 0.017336152905438   2: 0.017335032954968   7: 0.017334562042709 

training_5734     6: 0.804702070055382   1: 0.072683267008256   3: 0.015330477942101   5: 0.015329958527692   2: 0.015328607734010   9: 0.015327506536835   8: 0.015325886963737   0: 0.015324992151531   7: 0.015323644429839   4: 0.015323588650618 

training_5737     6: 0.526233181730009   2: 0.242152156777917   0: 0.105955357154219   8: 0.018063185704370   5: 0.017935346965648   1: 0.017934518200943   9: 0.017932927805051   4: 0.017931562819453   7: 0.017931116197514   3: 0.017930646644875 

training_5738     5: 0.777336396614040   4: 0.024745130976680   8: 0.024740024959992   3: 0.024739921045624   2: 0.024739841095815   9: 0.024739811003393   7: 0.024739784375711   0: 0.024739707756533   6: 0.024739693090166   1: 0.024739689082046 

training_5739     0: 0.366757630460481   5: 0.323931019361393   6: 0.210464440597137   9: 0.014146882162393   1: 0.014119843098255   2: 0.014117492800548   4: 0.014116297507411   7: 0.014115836384993   3: 0.014115290570073   8: 0.014115267057316 

training_5740     0: 0.448663858261568   4: 0.318111136823225   6: 0.057658408453009   1: 0.052459963383685   5: 0.036781330058639   2: 0.017379591174315   9: 0.017290907725841   8: 0.017218875445580   7: 0.017218831137277   3: 0.017217097536861 

training_5741     4: 0.791682939804630   5: 0.047325387440975   7: 0.020127924746889   6: 0.020125154380554   1: 0.020123949606367   0: 0.020123296544371   8: 0.020123029033357   2: 0.020122908747906   9: 0.020122737880071   3: 0.020122671814879 

training_5742     5: 0.759736023134751   3: 0.080515950175710   2: 0.019971549588052   6: 0.019970665675122   9: 0.019969530525704   1: 0.019968271703655   0: 0.019967805187887   4: 0.019967499935419   8: 0.019966382523029   7: 0.019966321550672 

training_5743     5: 0.534689226144649   7: 0.227043238949261   1: 0.084347724397861   0: 0.021993269183455   6: 0.021990633116303   2: 0.021988190360443   3: 0.021988160263631   4: 0.021986937417601   8: 0.021986704747775   9: 0.021985915419020 

training_5744     4: 0.785534534537965   1: 0.062973643247463   5: 0.018946311606724   6: 0.018942737902876   8: 0.018939557748664   0: 0.018935483773704   9: 0.018932079457157   2: 0.018931946746879   7: 0.018931905421563   3: 0.018931799557005 

training_5746     0: 0.528510916666847   5: 0.182226960698611   7: 0.145668949332232   2: 0.033904984254885   8: 0.032990872603048   6: 0.015346156714237   1: 0.015341607170160   4: 0.015337356595875   9: 0.015336212832998   3: 0.015335983131107 

training_5749     4: 0.385232672719327   3: 0.224017383728109   6: 0.213041700662005   0: 0.025403875365560   5: 0.025393042971867   1: 0.025382896132998   2: 0.025382667652191   9: 0.025382072892637   8: 0.025381924373281   7: 0.025381763502026 

training_5750     6: 0.656646837663463   1: 0.157541085825264   5: 0.063599259423328   3: 0.025643029897004   2: 0.016430943142543   0: 0.016055696322077   7: 0.016026317813570   8: 0.016019397971800   4: 0.016019165276397   9: 0.016018266664553 

training_5751     5: 0.444196596193471   6: 0.367921353700063   1: 0.023490143067598   0: 0.023486554252227   2: 0.023485019578342   4: 0.023484534635672   9: 0.023484246521955   8: 0.023484060975317   7: 0.023483846323850   3: 0.023483644751504 

training_5752     6: 0.812115944863738   0: 0.079819430934956   9: 0.025942115544744   3: 0.019825288919065   7: 0.010406553567282   1: 0.010380347060747   5: 0.010379787829862   2: 0.010376970070399   8: 0.010376855089602   4: 0.010376706119607 

training_5754     0: 0.771581135910846   1: 0.025385532630712   6: 0.025381617714928   5: 0.025379717265123   7: 0.025379162325872   4: 0.025378860267819   9: 0.025378758776913   2: 0.025378572538416   3: 0.025378334261701   8: 0.025378308307670 

training_5755     1: 0.654308105702590   6: 0.151868668409841   5: 0.086983104064198   9: 0.023378272957124   0: 0.014498066644883   7: 0.013894051300982   2: 0.013777264333464   3: 0.013764588858903   4: 0.013764202590489   8: 0.013763675137527 

training_5756     0: 0.744868130385518   6: 0.141398038020010   1: 0.014737278471868   2: 0.014352215292116   9: 0.014126168161846   5: 0.014105791811940   4: 0.014105040696288   8: 0.014102883215265   7: 0.014102301770072   3: 0.014102152175077 

training_5757     1: 0.393739732428068   4: 0.243461282715821   6: 0.229214673664873   2: 0.019140154165521   5: 0.019084614980932   0: 0.019075084853684   8: 0.019071328886179   9: 0.019071267047661   3: 0.019070934145676   7: 0.019070927111585 

training_5758     4: 0.753858871909034   5: 0.027355851005473   8: 0.027348467477562   9: 0.027348455152972   0: 0.027348185443276   3: 0.027348176006497   2: 0.027348087606375   1: 0.027348022847889   7: 0.027347950944473   6: 0.027347931606449 

training_5761     6: 0.768207171149543   0: 0.118226269833406   5: 0.029096122029212   1: 0.022092862299887   4: 0.018739276897688   2: 0.008742531669374   3: 0.008736199702750   9: 0.008725928270000   8: 0.008717143422641   7: 0.008716494725498 

training_5762     2: 0.464157214075447   0: 0.333366736803171   9: 0.044000365004967   7: 0.043872920540867   1: 0.019107814681760   6: 0.019102158331699   5: 0.019100218249115   4: 0.019098111792992   3: 0.019097231987662   8: 0.019097228532321 

training_5764     6: 0.501118177039709   5: 0.294782086229990   4: 0.025515708894941   9: 0.025515378159428   8: 0.025513229068883   0: 0.025512189875742   7: 0.025511620603206   1: 0.025510884269520   2: 0.025510528586412   3: 0.025510197272167 

training_5765     6: 0.801475582550083   7: 0.075985393980846   0: 0.023700686329460   1: 0.014135545908008   5: 0.014123998197926   8: 0.014118284847699   4: 0.014117372980391   9: 0.014115960282856   3: 0.014113777575701   2: 0.014113397347031 

training_5767     6: 0.744739482761010   0: 0.088212818513271   8: 0.041150398318352   9: 0.017997687913150   5: 0.017995006211424   4: 0.017982581654047   1: 0.017981436198667   7: 0.017980972287468   2: 0.017980886222239   3: 0.017978729920373 

training_5768     6: 0.766963868380303   9: 0.025894027421865   7: 0.025893372342560   1: 0.025893223073924   0: 0.025893195870614   5: 0.025893170524556   8: 0.025892887393370   2: 0.025892259944999   3: 0.025892023900941   4: 0.025891971146868 

training_5769     6: 0.850382838276069   4: 0.031566866712706   5: 0.026172338526602   0: 0.013151729383624   9: 0.013128100265031   1: 0.013122143071717   2: 0.013119193682214   8: 0.013118965207831   7: 0.013118929600081   3: 0.013118895274125 

training_5778     6: 0.842620413126220   0: 0.079540500072630   1: 0.018516133351858   8: 0.008477597508675   5: 0.008475034108596   4: 0.008474652078117   7: 0.008474166576673   9: 0.008473952073686   2: 0.008473776422820   3: 0.008473774680725 

training_5779     6: 0.767344911546657   7: 0.084185733975181   0: 0.078120851786004   4: 0.010052512234170   1: 0.010050359268019   5: 0.010049804761538   9: 0.010049384202346   8: 0.010049360977812   3: 0.010048546917886   2: 0.010048534330386 

training_5780     0: 0.838534207384698   3: 0.017943937567448   6: 0.017943834429265   5: 0.017941718973654   1: 0.017941470655173   8: 0.017939957283865   4: 0.017939859492493   9: 0.017939343528794   7: 0.017937966959609   2: 0.017937703725001 

training_5782     6: 0.602948176586002   7: 0.135366391082965   0: 0.118900207191791   8: 0.020411707008063   9: 0.020400045400192   5: 0.020395298269590   1: 0.020394995797601   2: 0.020394474981300   3: 0.020394367024461   4: 0.020394336658035 

training_5783     6: 0.521698761526818   0: 0.265050763713817   7: 0.073444827378029   5: 0.019973841518624   9: 0.019973060240089   1: 0.019972335936163   8: 0.019971909988337   4: 0.019971867798742   2: 0.019971382252786   3: 0.019971249646595 

training_5785     6: 0.787838795407921   1: 0.049588004428421   7: 0.020353070475573   9: 0.020322824078336   5: 0.020321119579290   0: 0.020316300854965   8: 0.020315190069937   4: 0.020315135363609   3: 0.020314969261972   2: 0.020314590479976 

training_5786     6: 0.814267889884081   0: 0.089941448055018   9: 0.024134343377094   7: 0.010263152397674   3: 0.010234480363953   5: 0.010233819585497   1: 0.010232767986755   8: 0.010230769226019   2: 0.010230710483223   4: 0.010230618640686 

training_5787     6: 0.479466502218212   0: 0.354523931882604   1: 0.042630437455523   2: 0.037054835964201   8: 0.027057161355856   7: 0.015764457418943   5: 0.010877767939386   4: 0.010875836104689   3: 0.010874979042302   9: 0.010874090618284 

training_5788     6: 0.421712728120983   7: 0.290637077208089   1: 0.163754515717346   0: 0.037776605022291   2: 0.014389457204398   5: 0.014361321472450   9: 0.014342747377890   4: 0.014342229541753   8: 0.014341920396558   3: 0.014341397938242 

training_5789     6: 0.713872868229906   1: 0.130540764649784   0: 0.036234129010390   9: 0.029013795592653   8: 0.015064336216481   5: 0.015060390600934   4: 0.015054381064883   2: 0.015053947069047   7: 0.015052862692952   3: 0.015052524872971 

training_5791     6: 0.708289058657223   7: 0.107270798077481   5: 0.074538757647667   0: 0.015706543322811   1: 0.015700560891449   8: 0.015699170203715   4: 0.015699148164352   9: 0.015698715541139   2: 0.015698663097993   3: 0.015698584396171 

training_5792     6: 0.576706873833004   1: 0.270310587338318   9: 0.045425580317780   7: 0.015370004569600   0: 0.015366559995100   5: 0.015364733393626   2: 0.015364289656402   8: 0.015364156607962   3: 0.015363607560088   4: 0.015363606728121 

training_5793     1: 0.560966507990096   6: 0.274562219949519   9: 0.040442159654520   5: 0.032154509885633   4: 0.020998584356471   8: 0.015290553099700   0: 0.014030320862780   7: 0.014023999660992   2: 0.013777381477581   3: 0.013753763062708 

training_5796     6: 0.745437775664871   0: 0.105849850881561   1: 0.036697770906791   8: 0.033130116366336   7: 0.027686909146360   2: 0.010252939991733   9: 0.010252030851013   4: 0.010247224627307   5: 0.010223795867385   3: 0.010221585696642 

training_5797     8: 0.771809567293475   6: 0.025381948569880   5: 0.025356827446082   9: 0.025355875882939   4: 0.025351984227925   7: 0.025351927497730   0: 0.025349834360811   1: 0.025349563979713   3: 0.025346402273769   2: 0.025346068467676 

training_5798     6: 0.445829782587159   8: 0.335658303382475   3: 0.091381871899211   7: 0.018164492750685   9: 0.018163247596925   0: 0.018162885570902   5: 0.018161012152699   1: 0.018160371607089   2: 0.018159016638258   4: 0.018159015814597 

training_58       6: 0.813762328782326   5: 0.020705671119004   1: 0.020697846659102   8: 0.020695085098318   0: 0.020692414947371   4: 0.020691825587120   9: 0.020690438074377   2: 0.020688374890752   7: 0.020688298390140   3: 0.020687716451491 

training_5800     6: 0.753152566683333   0: 0.133122355420347   5: 0.030572577523688   1: 0.026514367509707   8: 0.009717843009739   2: 0.009418833888466   4: 0.009379566422834   7: 0.009374736432870   3: 0.009373844914217   9: 0.009373308194799 

training_5803     6: 0.497291805805022   0: 0.255911594351015   9: 0.030873159552983   7: 0.030847637029559   1: 0.030847441048039   8: 0.030846741538997   5: 0.030845949969337   3: 0.030845310773563   2: 0.030845270480860   4: 0.030845089450624 

training_5804     6: 0.508340285471737   0: 0.248891029540151   9: 0.030348076531355   1: 0.030346837431092   8: 0.030346780928211   7: 0.030346743028001   5: 0.030346017834483   2: 0.030344847823961   3: 0.030344763939969   4: 0.030344617471038 

training_5805     6: 0.610926086798774   0: 0.280510660520371   5: 0.013571292336172   9: 0.013570902283933   1: 0.013570543142891   7: 0.013570271267655   8: 0.013570212933210   4: 0.013570211345269   2: 0.013569915623925   3: 0.013569903747801 

training_5807     6: 0.570899899387907   0: 0.283384058499635   5: 0.018215806629066   9: 0.018215634039182   1: 0.018214626164388   8: 0.018214279982611   7: 0.018214081242426   4: 0.018214074378191   2: 0.018213798828104   3: 0.018213740848489 

training_5808     6: 0.471246262479054   0: 0.290658095597349   1: 0.084429373571625   7: 0.056496591647623   5: 0.042112757783283   9: 0.018521192361416   8: 0.009164820241977   3: 0.009127869375637   4: 0.009121717556560   2: 0.009121319385477 

training_5810     6: 0.766619499058147   0: 0.064021234505493   1: 0.061721913293511   3: 0.027148346141018   9: 0.013443989249725   8: 0.013414692529577   5: 0.013409567239394   7: 0.013407173934345   4: 0.013406854445937   2: 0.013406729602853 

training_5811     6: 0.804012058759655   5: 0.060075692211177   8: 0.016997855037324   1: 0.016989140448031   0: 0.016989012991605   9: 0.016987980923057   4: 0.016987325112002   7: 0.016987130708389   3: 0.016986982340425   2: 0.016986821468334 

training_5812     6: 0.672454902674248   0: 0.166358672101710   1: 0.039355148437735   8: 0.031323241736954   9: 0.022507811511901   5: 0.013670106033359   4: 0.013582715972659   3: 0.013582532187485   7: 0.013582495168379   2: 0.013582374175569 

training_5814     6: 0.628869686570518   3: 0.173111505347715   9: 0.024756834459401   8: 0.024755370185538   0: 0.024753027473064   7: 0.024752392193455   1: 0.024751134876983   5: 0.024750444431409   2: 0.024749994232209   4: 0.024749610229707 

training_5815     5: 0.527843712992199   6: 0.223807081851469   8: 0.081109060116320   1: 0.023896391121873   9: 0.023894938581530   0: 0.023890358558371   4: 0.023890229323672   2: 0.023889934073360   7: 0.023889749260002   3: 0.023888544121206 

training_5818     6: 0.695636509323133   1: 0.085374236906859   3: 0.051788526341951   8: 0.049924748262440   5: 0.019554337595181   4: 0.019552202296513   9: 0.019551374525573   0: 0.019539909138855   7: 0.019539824535157   2: 0.019538331074338 

training_5819     9: 0.848347833297695   6: 0.016853051720128   8: 0.016850770893497   5: 0.016850710863967   0: 0.016850120534263   4: 0.016849891691867   1: 0.016849759217855   2: 0.016849327042120   3: 0.016849279936094   7: 0.016849254802514 

training_5822     5: 0.434999324251771   0: 0.361620149717531   3: 0.094580811642575   6: 0.015550104804822   1: 0.015543127615174   8: 0.015542289671367   9: 0.015541840718446   4: 0.015541273304296   7: 0.015540863157860   2: 0.015540215116159 

training_5826     6: 0.721633301354282   0: 0.084770219947055   5: 0.056271488436423   2: 0.019630185602773   8: 0.019616330818061   1: 0.019615899006091   7: 0.019615876038944   9: 0.019615629903950   4: 0.019615624397907   3: 0.019615444494514 

training_5827     6: 0.689748271560624   0: 0.193733380648311   7: 0.026985247206412   9: 0.016570328925867   3: 0.015774272452657   8: 0.011447982784133   5: 0.011444231179091   1: 0.011434881851232   2: 0.011430711141814   4: 0.011430692249858 

training_5830     6: 0.806036451402770   0: 0.041567685527109   7: 0.031905745179603   9: 0.017264178400638   8: 0.017228921247522   5: 0.017206663318857   1: 0.017201895937565   3: 0.017198145579545   4: 0.017196053566127   2: 0.017194259840264 

training_5833     6: 0.692047937979609   8: 0.164378223359271   1: 0.017947728891951   0: 0.017947270077418   5: 0.017947154305415   9: 0.017947101895093   4: 0.017946728388313   2: 0.017945989867165   3: 0.017945938390657   7: 0.017945926845109 

training_5835     6: 0.823012718798786   7: 0.061705856352811   0: 0.014428380685346   5: 0.014412228303822   1: 0.014406968113990   8: 0.014406966679447   9: 0.014406961318693   3: 0.014406722002626   4: 0.014406610562278   2: 0.014406587182200 

training_5836     6: 0.554220521148211   8: 0.279647584569878   1: 0.046391488363647   0: 0.017110840324592   5: 0.017107246929397   9: 0.017105625498075   4: 0.017104531500818   7: 0.017104222649288   2: 0.017104029692578   3: 0.017103909323516 

training_5838     6: 0.744151634347123   1: 0.028431130474675   9: 0.028429297019817   5: 0.028428473332708   7: 0.028428097624613   0: 0.028426969990459   8: 0.028426523861390   4: 0.028426009993511   3: 0.028426006483516   2: 0.028425856872188 

training_5839     6: 0.827179248202533   9: 0.019203344603255   5: 0.019202946985201   0: 0.019202559859248   7: 0.019202235306824   1: 0.019202191529646   8: 0.019202113626338   2: 0.019201853061061   4: 0.019201760968110   3: 0.019201745857785 

training_5841     6: 0.846645653735648   0: 0.054306895361184   1: 0.012430242246549   8: 0.012376674271356   5: 0.012374275679592   9: 0.012373868610568   7: 0.012373149417070   4: 0.012373127498747   3: 0.012373066122058   2: 0.012373047057228 

training_5842     6: 0.649195356184746   7: 0.147607743445543   9: 0.067691555529275   8: 0.033289603117807   1: 0.017055942530998   0: 0.017048749496963   5: 0.017031849434297   4: 0.017026899084596   3: 0.017026202921991   2: 0.017026098253785 

training_5845     6: 0.653882174999905   5: 0.132700774701410   4: 0.026685170458353   9: 0.026682729919664   8: 0.026677657715486   0: 0.026675160600448   3: 0.026674844206606   1: 0.026674352961142   7: 0.026673653635558   2: 0.026673480801426 

training_5847     6: 0.697612167448790   9: 0.078934259290497   7: 0.067760526051815   1: 0.053378435986691   0: 0.017076118118074   5: 0.017048721108307   8: 0.017047657552369   2: 0.017047444304374   4: 0.017047362145839   3: 0.017047307993244 

training_5848     6: 0.826936093538233   3: 0.035361302123030   0: 0.026334641211846   7: 0.026103422989706   4: 0.014291607878943   8: 0.014249575880103   9: 0.014192099343090   1: 0.014185981385478   5: 0.014176997621262   2: 0.014168278028309 

training_5849     6: 0.533767973954794   9: 0.313979643578436   7: 0.039257893569621   8: 0.016148904782935   0: 0.016145234303003   5: 0.016141246909802   1: 0.016140142027766   4: 0.016139731285845   3: 0.016139626558595   2: 0.016139603029203 

training_5850     6: 0.508008684641466   1: 0.306972298594702   9: 0.106339356874957   3: 0.017063592065197   0: 0.010322634492464   5: 0.010259517652100   8: 0.010258568623554   4: 0.010258556772644   7: 0.010258398713147   2: 0.010258391569770 

training_5852     6: 0.811748239605836   1: 0.044001658862961   0: 0.033291089693265   3: 0.032060085238301   2: 0.013153847983448   8: 0.013151610573684   9: 0.013151533785359   5: 0.013148526493993   7: 0.013146744660908   4: 0.013146663102244 

training_5854     3: 0.512881188480376   6: 0.184971759698000   9: 0.072588034547976   1: 0.059153945785382   5: 0.058965058728012   0: 0.022337186564895   7: 0.022296884598580   4: 0.022269376208081   8: 0.022268662987397   2: 0.022267902401301 

training_5858     6: 0.842592836885311   0: 0.079569359365186   1: 0.018514857420169   8: 0.008477592588524   5: 0.008475033168088   4: 0.008474651475246   7: 0.008474166640703   9: 0.008473952004044   2: 0.008473776198259   3: 0.008473774254471 

training_5861     9: 0.817007807151642   6: 0.020338981127066   8: 0.020334213591576   1: 0.020333384510959   0: 0.020332394319159   5: 0.020332133846094   2: 0.020330784523875   7: 0.020330612186996   4: 0.020329987718612   3: 0.020329701024021 

training_5866     6: 0.605817180938219   7: 0.124074464050157   3: 0.076560155511373   1: 0.073921249642783   0: 0.038078032227695   9: 0.016316693579716   8: 0.016309715226419   5: 0.016307784983677   2: 0.016307564798008   4: 0.016307159041953 

training_5868     0: 0.499006078618027   6: 0.292809587677560   1: 0.100175948476642   4: 0.024052319574407   3: 0.014026362732365   5: 0.013989802592790   7: 0.013985474375784   9: 0.013985314658390   8: 0.013984708513596   2: 0.013984402780438 

training_5870     6: 0.477453077916693   1: 0.414606926308826   0: 0.013493686013821   8: 0.013492953888422   7: 0.013492812932069   5: 0.013492717123911   9: 0.013492347953331   4: 0.013491881805542   2: 0.013491845676183   3: 0.013491750381202 

training_5873     6: 0.631956933131327   4: 0.155169343187419   0: 0.088273067498123   9: 0.038216792768294   5: 0.014455118026395   3: 0.014387779528093   1: 0.014386804764523   2: 0.014385037263562   8: 0.014384922440888   7: 0.014384201391374 

training_5875     4: 0.498188325691936   1: 0.328707259715909   6: 0.021639974335510   5: 0.021639260225070   0: 0.021639135061583   2: 0.021638558463626   8: 0.021637080674719   7: 0.021637011491386   3: 0.021636773006543   9: 0.021636621333717 

training_5876     0: 0.692449202262895   5: 0.148199562661505   1: 0.019923460931508   6: 0.019920927173914   9: 0.019918489219317   4: 0.019918301077557   3: 0.019917948218665   2: 0.019917635626046   8: 0.019917245956828   7: 0.019917226871764 

training_5879     6: 0.686939429842668   0: 0.197077109000957   5: 0.024878131342639   7: 0.024137964440674   8: 0.019161019181631   1: 0.009660884088277   2: 0.009632179233759   9: 0.009522737892495   4: 0.009495350503012   3: 0.009495194473889 

training_5880     6: 0.732184993076071   8: 0.100462662962949   0: 0.049850203556135   1: 0.016787958259757   5: 0.016787221978320   4: 0.016785547311873   2: 0.016785531250596   3: 0.016785350863529   9: 0.016785307782019   7: 0.016785222958751 

training_5883     6: 0.752146345552088   5: 0.027574529089743   4: 0.027546540420770   8: 0.027542674850946   9: 0.027537303995894   1: 0.027531921966824   0: 0.027531390506387   7: 0.027531105293838   3: 0.027529117219355   2: 0.027529071104155 

training_5886     6: 0.706487365907950   9: 0.148871792202614   1: 0.018082659864574   0: 0.018082383525307   5: 0.018082045510794   7: 0.018080404476462   4: 0.018078796810282   2: 0.018078400921034   3: 0.018078108809954   8: 0.018078041971027 

training_5887     6: 0.682124627482086   0: 0.201370158131535   5: 0.014645770400551   8: 0.014555664479937   1: 0.014552423238308   9: 0.014551268580518   4: 0.014550264455338   2: 0.014549974385925   7: 0.014549961539368   3: 0.014549887306433 

training_5888     0: 0.522873249240166   5: 0.178199265378518   6: 0.131228554734224   7: 0.067004737857765   4: 0.032875111352461   1: 0.020095043190877   2: 0.014772234652348   9: 0.011059968978757   3: 0.010946942141344   8: 0.010944892473540 

training_5889     5: 0.422021445583656   2: 0.230309430497550   4: 0.220132942642779   6: 0.018243995572322   0: 0.018235990358226   1: 0.018219000323947   9: 0.018209932300248   7: 0.018209923018539   8: 0.018209286022797   3: 0.018208053679935 

training_5894     5: 0.588094591827433   0: 0.255902213160958   4: 0.019502896759370   6: 0.019501488729196   7: 0.019500099209479   1: 0.019499925041100   8: 0.019499738791476   9: 0.019499733270766   2: 0.019499674470604   3: 0.019499638739616 

training_5895     6: 0.811506859173517   0: 0.088082148067514   9: 0.026179469614993   7: 0.010628243040642   3: 0.010602383029530   1: 0.010602267525349   5: 0.010601954303588   8: 0.010598968076986   2: 0.010598904898070   4: 0.010598802269813 

training_5896     6: 0.598480218547355   0: 0.221902765018480   1: 0.059590688365055   8: 0.042546979434917   9: 0.018738462849271   5: 0.011754730872811   7: 0.011748295644313   2: 0.011747252024998   4: 0.011745435384025   3: 0.011745171858775 

training_5898     4: 0.780292978125456   5: 0.024418490558848   8: 0.024411289299770   3: 0.024411142838588   9: 0.024411126653477   2: 0.024411083825540   0: 0.024411001508888   1: 0.024410985733610   7: 0.024410973322403   6: 0.024410928133420 

training_5899     0: 0.602630944457307   1: 0.238671005204516   5: 0.030127349819774   4: 0.018716575528508   6: 0.018369144989413   9: 0.018330170210375   2: 0.018292437855737   7: 0.018287723899637   3: 0.018287382839343   8: 0.018287265195391 

training_59       6: 0.604422907095203   8: 0.237176332663222   0: 0.042895591535302   1: 0.016517218218863   5: 0.016501113528431   2: 0.016498056061218   9: 0.016497973171738   3: 0.016497628506614   7: 0.016496836742024   4: 0.016496342477384 

training_5900     0: 0.633421927659256   6: 0.205669666222100   9: 0.038616671648052   4: 0.017532993109057   1: 0.017468165203939   5: 0.017458833110395   3: 0.017458188031637   8: 0.017458036752054   7: 0.017457868790003   2: 0.017457649473508 

training_5901     5: 0.465405220746063   0: 0.238700860027721   1: 0.138268020799990   4: 0.022520134934870   3: 0.022518074691767   8: 0.022517825622269   9: 0.022517520200765   6: 0.022517480520077   2: 0.022517433612792   7: 0.022517428843685 

training_5902     1: 0.689143175878966   6: 0.142084325621535   5: 0.035714334273929   3: 0.019025887102812   9: 0.019005965351296   7: 0.019005901517584   8: 0.019005850973367   0: 0.019005499450181   2: 0.019004721115569   4: 0.019004338714761 

training_5905     9: 0.773892923420977   8: 0.025125203411233   6: 0.025124459545803   5: 0.025123387638576   0: 0.025122710878798   4: 0.025122573783969   1: 0.025122401091419   3: 0.025122166080188   7: 0.025122134170192   2: 0.025122039978845 

training_5906     4: 0.745490332371913   5: 0.028284334245123   6: 0.028278541293680   1: 0.028278462641769   0: 0.028278265981560   9: 0.028278188886042   8: 0.028278095608553   3: 0.028278061096095   2: 0.028277890842995   7: 0.028277827032269 

training_5908     6: 0.794823030805122   0: 0.090846253536988   1: 0.014306551410441   5: 0.014294382068334   3: 0.014290890618709   4: 0.014289332859934   9: 0.014287899752759   8: 0.014287356450836   2: 0.014287192719177   7: 0.014287109777700 

training_5909     9: 0.500352789632725   6: 0.356238218253078   8: 0.017953769137214   2: 0.017923918319391   0: 0.017923318978293   1: 0.017922823791390   5: 0.017922473013694   4: 0.017921124111028   3: 0.017920971831510   7: 0.017920592931676 

training_5910     9: 0.394477157862960   5: 0.389149499256218   4: 0.076065643181885   0: 0.020257298567429   7: 0.020118131703321   3: 0.020067756838630   6: 0.020062131952254   2: 0.019965803956234   8: 0.019918948280689   1: 0.019917628400378 

training_5911     4: 0.720322192292858   7: 0.097527960601725   5: 0.022785271772549   3: 0.022767038480208   8: 0.022766501169131   9: 0.022766381770097   6: 0.022766246463555   2: 0.022766202290124   0: 0.022766172615201   1: 0.022766032544552 

training_5912     5: 0.393951507293367   3: 0.381707061396869   4: 0.028049396279556   8: 0.028042029884630   6: 0.028041870005344   0: 0.028041819398464   2: 0.028041678300799   9: 0.028041640382684   1: 0.028041527773182   7: 0.028041469285106 

training_5913     5: 0.404028971382445   1: 0.345439355839094   4: 0.031322578331794   6: 0.031320849655528   9: 0.031316654409539   8: 0.031314849743869   0: 0.031314531426007   3: 0.031314512701648   7: 0.031313917334675   2: 0.031313779175400 

training_5914     5: 0.538981475003327   1: 0.146631903038650   4: 0.145536463464048   6: 0.024122190006943   8: 0.024121947438073   9: 0.024121677926444   3: 0.024121637571068   0: 0.024121333576987   7: 0.024120693815622   2: 0.024120678158837 

training_5915     0: 0.638654328898195   3: 0.136450055468059   5: 0.028115938124458   9: 0.028113106186313   1: 0.028112819142482   6: 0.028111924913694   4: 0.028111178909309   2: 0.028110614915253   7: 0.028110261786748   8: 0.028109771655489 

training_5919     0: 0.604621615395511   5: 0.265962211974755   3: 0.016182800583014   1: 0.016178306370042   6: 0.016178075646070   9: 0.016176323248705   2: 0.016175590900206   4: 0.016175441564612   7: 0.016174819914138   8: 0.016174814402946 

training_5922     5: 0.491970996959587   9: 0.270953844584674   6: 0.029640614134413   4: 0.029637035041241   1: 0.029637020896487   7: 0.029634416813279   8: 0.029633345867650   3: 0.029632226891021   2: 0.029631847059248   0: 0.029628651752400 

training_5925     4: 0.820954297253520   6: 0.019932559906561   5: 0.019892870402702   9: 0.019889159600947   0: 0.019888908793068   8: 0.019888534431345   1: 0.019888470156482   3: 0.019888422773219   2: 0.019888417685722   7: 0.019888358996436 

training_5926     5: 0.481975279656298   2: 0.293623466305846   4: 0.028054883434352   6: 0.028051522619672   9: 0.028050345946261   7: 0.028049089306623   3: 0.028048989433984   8: 0.028048905313259   1: 0.028048887919339   0: 0.028048630064364 

training_5930     5: 0.762113131688454   4: 0.026436315736304   6: 0.026431471273195   1: 0.026431428655815   3: 0.026431403046857   8: 0.026431363577768   0: 0.026431298221717   9: 0.026431294533307   2: 0.026431209015999   7: 0.026431084250585 

training_5931     5: 0.769184917404335   6: 0.075024258017546   4: 0.019479174873821   1: 0.019474099454646   8: 0.019473240669681   0: 0.019473031311917   3: 0.019472993796879   9: 0.019472774952165   2: 0.019472768452685   7: 0.019472741066324 

training_5932     2: 0.346276568176151   6: 0.292868953435354   8: 0.156573246709206   1: 0.087046786136975   5: 0.019541385863437   4: 0.019540399082307   0: 0.019538406806206   7: 0.019538328982691   9: 0.019538209295170   3: 0.019537715512502 

training_5933     6: 0.819480132279754   5: 0.020059799288184   7: 0.020058592844445   0: 0.020057925254197   1: 0.020057558315517   3: 0.020057403894330   8: 0.020057370016021   9: 0.020057217965862   4: 0.020057054013592   2: 0.020056946128098 

training_5934     2: 0.406861742464847   5: 0.367476743198870   8: 0.103594096611307   6: 0.017450501854838   1: 0.017438894088015   0: 0.017437473294063   9: 0.017436007759372   4: 0.017435260216256   7: 0.017434641455433   3: 0.017434639056999 

training_5935     5: 0.448625256328011   2: 0.374852943331007   6: 0.022093862461630   9: 0.022077093195012   0: 0.022075532724474   1: 0.022064389098765   4: 0.022053075267373   3: 0.022052987485379   8: 0.022052583773864   7: 0.022052276334485 

training_5937     1: 0.645428190138331   5: 0.086276627253817   4: 0.075464067163793   6: 0.052503944267056   0: 0.023421479712161   3: 0.023381850529734   8: 0.023381249997555   9: 0.023381214832853   7: 0.023380795247480   2: 0.023380580857221 

training_5938     5: 0.643295533046058   1: 0.117403537685477   6: 0.101788850206348   2: 0.019658712455528   4: 0.019648052660574   0: 0.019645342229267   3: 0.019640348905775   9: 0.019639977514780   8: 0.019639962635002   7: 0.019639682661192 

training_5939     6: 0.534431808923478   5: 0.247539946182381   4: 0.027256261064143   9: 0.027255329731386   0: 0.027254461425370   7: 0.027253057773125   8: 0.027252949554269   1: 0.027252277289997   3: 0.027252081763518   2: 0.027251826292334 

training_5941     6: 0.808029074892960   7: 0.088068613978772   5: 0.013001412882174   1: 0.013000566964076   0: 0.012991486877916   9: 0.012990919616052   4: 0.012983103517712   8: 0.012981618310756   2: 0.012976618349202   3: 0.012976584610380 

training_5945     9: 0.801635599559328   8: 0.022044195914612   6: 0.022043080810558   5: 0.022040910382389   0: 0.022039991598071   1: 0.022039895787575   4: 0.022039386585256   2: 0.022039191855127   7: 0.022038961121832   3: 0.022038786385252 

training_5946     1: 0.713474109097611   3: 0.118569603335283   0: 0.044128621460043   6: 0.017692149053848   5: 0.017691239842208   4: 0.017689456452214   8: 0.017688991098845   9: 0.017688819385219   2: 0.017688711435834   7: 0.017688298838895 

training_5947     6: 0.827321658282500   5: 0.019196891668322   4: 0.019193746865903   9: 0.019188121312025   0: 0.019184568187918   1: 0.019184305085326   8: 0.019182971542257   3: 0.019182675751276   2: 0.019182633500887   7: 0.019182427803585 

training_5949     1: 0.382307673907584   6: 0.300656703850367   5: 0.206806748066473   8: 0.015748107372666   0: 0.015747889641548   2: 0.015747516183514   4: 0.015747104177904   9: 0.015746375056036   3: 0.015746263690146   7: 0.015745618053762 

training_5950     4: 0.694274123826464   6: 0.127488875405865   5: 0.022285180675184   0: 0.022281172827756   1: 0.022278910862812   9: 0.022278737469860   8: 0.022278409509039   3: 0.022278273636578   2: 0.022278171038047   7: 0.022278144748393 

training_5951     5: 0.781386079457895   6: 0.024305402233009   8: 0.024299680746277   9: 0.024291942257189   0: 0.024289027141551   7: 0.024288121220474   1: 0.024285879469144   4: 0.024285512637106   2: 0.024284781573744   3: 0.024283573263611 

training_5954     6: 0.780198287012671   7: 0.063669696167333   0: 0.062590264202067   5: 0.024138137682842   1: 0.011574571266177   9: 0.011567542711807   2: 0.011565500589866   4: 0.011565445841002   3: 0.011565323379386   8: 0.011565231146850 

training_5955     2: 0.326875354987930   4: 0.233573042429211   6: 0.229487301891193   1: 0.088395169702013   0: 0.020288985928463   5: 0.020278685854581   8: 0.020275939244417   7: 0.020275755879221   9: 0.020275380224663   3: 0.020274383858307 

training_5957     6: 0.642799828933532   1: 0.193817813687286   4: 0.049307269348921   7: 0.016306581630036   0: 0.016296249433275   2: 0.016296245680728   5: 0.016294347061930   8: 0.016294088661615   9: 0.016293846595137   3: 0.016293728967539 

training_5958     2: 0.337651678909054   6: 0.308606831403618   8: 0.153178446244181   1: 0.084754907567492   5: 0.019303364501660   4: 0.019302523265362   0: 0.019300823115922   7: 0.019300710364454   9: 0.019300620281556   3: 0.019300094346701 

training_5960     5: 0.773018365493605   3: 0.025221024701284   4: 0.025220316542627   2: 0.025220212468128   6: 0.025220104499011   7: 0.025220071459354   1: 0.025220037635577   0: 0.025220010036811   8: 0.025219954308913   9: 0.025219902854690 

training_5964     6: 0.707493367810805   0: 0.179801337249247   1: 0.026079680059696   5: 0.012450856190462   4: 0.012365129853459   8: 0.012362929458566   9: 0.012361901257467   7: 0.012361669236395   2: 0.012361566186104   3: 0.012361562697799 

training_5965     1: 0.651557107191842   5: 0.214201411660021   4: 0.035360074283623   6: 0.014140650890522   7: 0.014136198263930   3: 0.014121530104893   9: 0.014121400253071   0: 0.014121228049365   8: 0.014120921958112   2: 0.014119477344621 

training_5967     5: 0.780041161026351   6: 0.024441907776326   4: 0.024441765806329   8: 0.024441243114335   0: 0.024439316845173   1: 0.024439192649773   9: 0.024439012403206   3: 0.024438921823371   2: 0.024438796709607   7: 0.024438681845529 

training_5968     4: 0.734373757615845   5: 0.029519461921389   8: 0.029513521597723   3: 0.029513460096463   2: 0.029513358582583   0: 0.029513335263118   7: 0.029513311468235   9: 0.029513294888275   6: 0.029513275894079   1: 0.029513222672290 

training_5969     4: 0.728450973925687   8: 0.098757174254500   5: 0.021609017399538   0: 0.021597836457288   6: 0.021597744955330   9: 0.021597591365995   3: 0.021597491682047   1: 0.021597456633023   2: 0.021597376533487   7: 0.021597336793104 

training_5972     6: 0.746347814959046   0: 0.102437839966425   9: 0.035914347377623   1: 0.016493713417183   5: 0.016471551043119   4: 0.016469353270210   8: 0.016467026034040   7: 0.016466475084162   2: 0.016466011532257   3: 0.016465867315935 

training_5973     6: 0.699254627679877   0: 0.189579480599123   1: 0.031424684251296   2: 0.011398414839825   7: 0.011391670830174   5: 0.011390914872017   9: 0.011390490675746   3: 0.011390139276913   8: 0.011390057455194   4: 0.011389519519835 

training_5974     4: 0.613593689197805   9: 0.187853960017810   5: 0.024822507370120   1: 0.024821297640480   0: 0.024820712569567   6: 0.024819847532600   3: 0.024817686106642   8: 0.024817457406798   2: 0.024816916551087   7: 0.024815925607091 

training_5975     1: 0.530062988160798   0: 0.308731818392883   6: 0.020154606450826   4: 0.020154100438884   5: 0.020150888548911   7: 0.020150171941292   9: 0.020149818943043   8: 0.020148781150514   2: 0.020148523321369   3: 0.020148302651479 

training_5976     4: 0.764810293430822   5: 0.026137781957622   0: 0.026131738124245   1: 0.026131615809838   8: 0.026131514397846   3: 0.026131478193626   2: 0.026131464251352   6: 0.026131387036602   9: 0.026131367274928   7: 0.026131359523120 

training_5977     0: 0.421134927413745   5: 0.282407424834179   4: 0.088588184708729   8: 0.079157977421710   6: 0.021455206632922   1: 0.021453528319251   3: 0.021451916509428   2: 0.021450558868559   9: 0.021450219416611   7: 0.021450055874866 

training_5980     6: 0.755138649992404   9: 0.027220158783725   0: 0.027208896175235   8: 0.027205370037689   1: 0.027204646802800   7: 0.027204587674224   2: 0.027204536316663   5: 0.027204488440480   3: 0.027204364824997   4: 0.027204300951783 

training_5981     6: 0.757744144514784   9: 0.026936218158759   8: 0.026923351991011   3: 0.026914659156399   0: 0.026914528801554   5: 0.026914351308551   1: 0.026914114158637   7: 0.026913227685071   2: 0.026912705579825   4: 0.026912698645411 

training_5982     5: 0.486505167281963   0: 0.269643051696276   4: 0.030492232198022   1: 0.030480369037038   3: 0.030480082175258   6: 0.030480024055430   2: 0.030479910644129   7: 0.030479848209040   8: 0.030479828306150   9: 0.030479486396694 

training_5984     5: 0.774973147561932   4: 0.025007518440516   0: 0.025002821915673   8: 0.025002513866644   6: 0.025002480184143   9: 0.025002392991047   1: 0.025002310570473   7: 0.025002290095522   2: 0.025002268231039   3: 0.025002256143011 

training_5985     6: 0.717503164751318   1: 0.106535335154973   5: 0.066806881589741   0: 0.056345394285199   9: 0.009725820026172   4: 0.008692829571990   7: 0.008624954419696   8: 0.008589507915514   2: 0.008588131370365   3: 0.008587980915033 

training_5986     6: 0.329334274384846   5: 0.233361256343674   8: 0.204847754206233   9: 0.103607025277707   4: 0.041184384527415   2: 0.017535766783841   1: 0.017534664680752   0: 0.017534098938770   7: 0.017530439895337   3: 0.017530334961425 

training_5991     5: 0.552373355291308   4: 0.149294494234594   0: 0.143352665837385   6: 0.022140086341977   1: 0.022139985213945   8: 0.022139979652514   3: 0.022139958059466   7: 0.022139876113380   2: 0.022139833314546   9: 0.022139765940884 

training_5993     5: 0.599994737650233   0: 0.219090752430044   4: 0.022622030375646   1: 0.022613334495919   3: 0.022613287162794   8: 0.022613203661154   2: 0.022613195209167   6: 0.022613186100755   9: 0.022613175185230   7: 0.022613097729058 

training_5994     5: 0.766534761179285   4: 0.025944127868907   8: 0.025940541433973   3: 0.025940234964087   9: 0.025940197514718   2: 0.025940129846047   7: 0.025940081696644   1: 0.025939979885973   0: 0.025939979402999   6: 0.025939966207365 

training_5998     8: 0.666308443730167   6: 0.199482643797666   0: 0.016777659981350   1: 0.016777340204092   9: 0.016776474884630   5: 0.016775970325680   7: 0.016775711565764   2: 0.016775329901392   4: 0.016775300062405   3: 0.016775125546853 

training_6        8: 0.568622230294196   6: 0.141275709678452   2: 0.114211776425735   3: 0.041243178736325   5: 0.038556996166669   0: 0.019240072681286   7: 0.019218489486976   9: 0.019210681105422   1: 0.019210532806055   4: 0.019210332618885 

training_6000     6: 0.491536723841266   9: 0.248367336326210   1: 0.111698273069497   3: 0.046962045506611   0: 0.016909935369170   5: 0.016906493560836   7: 0.016906091116396   4: 0.016904612444547   2: 0.016904297730934   8: 0.016904191034533 

training_6003     5: 0.391907213368298   8: 0.257111809227077   1: 0.152211498369252   3: 0.078152366617652   9: 0.020112400445150   6: 0.020110726987672   0: 0.020107169138988   4: 0.020096189749599   2: 0.020095648740079   7: 0.020094977356232 

training_6005     5: 0.635745573107823   1: 0.156577710097436   4: 0.025964574408990   8: 0.025959128746513   3: 0.025959019500731   9: 0.025958956788418   2: 0.025958896054656   7: 0.025958774371481   0: 0.025958712652972   6: 0.025958654270979 

training_6006     6: 0.712425679794134   0: 0.113310967638824   5: 0.041356044623554   1: 0.039232740762037   9: 0.015614655251012   7: 0.015613217969809   8: 0.015612153505238   3: 0.015612066823994   4: 0.015611290991764   2: 0.015611182639635 

training_6010     5: 0.775093885009336   4: 0.024992209680882   0: 0.024989643462291   8: 0.024989495613578   9: 0.024989436402035   1: 0.024989423461356   6: 0.024989173773380   3: 0.024989021687937   2: 0.024988914290284   7: 0.024988796618920 

training_6013     0: 0.399861630543508   5: 0.342288727918610   6: 0.032238598869369   4: 0.032234650118771   7: 0.032230074346588   8: 0.032230021792369   9: 0.032229391986509   3: 0.032229152177637   1: 0.032229093039772   2: 0.032228659206867 

training_6014     5: 0.831177836718902   6: 0.018761334961671   4: 0.018759414849199   1: 0.018758590343116   0: 0.018758508629191   9: 0.018757117650580   7: 0.018756856999552   2: 0.018756817704128   3: 0.018756795562588   8: 0.018756726581074 

training_6017     5: 0.782684108421377   4: 0.024151184720528   8: 0.024145764693638   9: 0.024145684463364   3: 0.024145611970067   0: 0.024145569946157   2: 0.024145549582992   6: 0.024145548963121   7: 0.024145505747782   1: 0.024145471490973 

training_6018     5: 0.666680109962442   1: 0.134844466311439   6: 0.024813526525429   0: 0.024812900789963   4: 0.024810058785237   7: 0.024808356226334   9: 0.024807758466006   2: 0.024807647171265   8: 0.024807628621942   3: 0.024807547139942 

training_6020     1: 0.629890474147882   6: 0.102905008224933   5: 0.101288400938298   0: 0.023704560263157   2: 0.023702461984285   4: 0.023702325981969   8: 0.023701889206923   3: 0.023701664537662   9: 0.023701618218621   7: 0.023701596496269 

training_6023     6: 0.325403476850017   9: 0.295261467379644   0: 0.202479219856450   7: 0.079928856931593   1: 0.029844320768645   8: 0.013418734908770   5: 0.013418117461871   2: 0.013415831278119   4: 0.013415260777709   3: 0.013414713787182 

training_6025     6: 0.580741665610854   0: 0.228608982553518   7: 0.071422972006421   4: 0.035054819954930   5: 0.014156729499545   3: 0.014084958724653   8: 0.013983782802313   2: 0.013982628520738   1: 0.013982212356535   9: 0.013981247970491 

training_6026     9: 0.697077242521193   1: 0.033677986594496   0: 0.033669138587693   6: 0.033663769736272   2: 0.033657299171407   5: 0.033655405722694   7: 0.033650379660909   4: 0.033650094757929   3: 0.033649686166035   8: 0.033648997081372 

training_6027     5: 0.798044126725316   0: 0.057349234643657   7: 0.018081142848814   6: 0.018080772111789   1: 0.018078477805852   9: 0.018076428072625   8: 0.018073810757724   2: 0.018072626013005   4: 0.018072166947418   3: 0.018071214073801 

training_6030     2: 0.708940354891133   7: 0.068964977635091   9: 0.056345186838940   1: 0.025003478920738   0: 0.023804174609828   6: 0.023566471428438   5: 0.023439177079582   4: 0.023326696940872   8: 0.023308962094784   3: 0.023300519560593 

training_6033     5: 0.660829678658428   0: 0.149431704848926   6: 0.023718020136389   8: 0.023717618964048   9: 0.023717484788106   3: 0.023717306129068   2: 0.023717225573296   4: 0.023717150194034   1: 0.023717076748479   7: 0.023716733959226 

training_6034     0: 0.604704257483987   6: 0.178405111554576   8: 0.067070669045117   5: 0.032036719788171   1: 0.028199167416135   7: 0.017986257801020   4: 0.017902562235793   3: 0.017901417700617   2: 0.017896979724382   9: 0.017896857250202 

training_6035     6: 0.425893284371898   2: 0.318543531252874   5: 0.135352538506933   0: 0.017177492837084   1: 0.017173088563680   4: 0.017172912746306   7: 0.017172062889019   9: 0.017172052547480   8: 0.017171703014959   3: 0.017171333269769 

training_6037     6: 0.757424751119257   0: 0.146092817990507   1: 0.012064895123871   9: 0.012062549481618   5: 0.012060473446801   2: 0.012060362987034   8: 0.012059374845725   4: 0.012058269223071   7: 0.012058258130003   3: 0.012058247652112 

training_6041     5: 0.625044961188925   1: 0.161505950929698   4: 0.026684149309249   8: 0.026681066305341   9: 0.026680755236883   3: 0.026680675395275   2: 0.026680637076250   7: 0.026680629997264   0: 0.026680629733877   6: 0.026680544827238 

training_6042     4: 0.777907467590511   6: 0.024689534058544   5: 0.024682586383775   7: 0.024676538041038   9: 0.024675938134492   0: 0.024674431338388   1: 0.024674140746852   8: 0.024673595640117   3: 0.024672906325876   2: 0.024672861740407 

training_6043     5: 0.685622390925308   9: 0.115060181193704   3: 0.024915212349736   4: 0.024914902680868   6: 0.024914610868472   0: 0.024914600661864   8: 0.024914592975701   2: 0.024914507095228   1: 0.024914506551022   7: 0.024914494698096 

training_6044     8: 0.715385730992309   5: 0.031630346938163   4: 0.031624788239505   6: 0.031624748345445   0: 0.031623627831261   9: 0.031622400163953   3: 0.031622214462929   1: 0.031622177111630   7: 0.031622100646544   2: 0.031621865268261 

training_6046     8: 0.790109598738191   2: 0.064574203865374   0: 0.018168021068759   6: 0.018167154310515   1: 0.018164502372360   5: 0.018163868954371   9: 0.018163667574189   7: 0.018163166321285   4: 0.018163036325164   3: 0.018162780469793 

training_6047     5: 0.744982829116803   0: 0.115773838390348   1: 0.044449007233263   9: 0.013673480950986   6: 0.013521790062579   4: 0.013521373833172   8: 0.013519889790158   7: 0.013519674567193   3: 0.013519099304079   2: 0.013519016751419 

training_6048     4: 0.751370794441169   5: 0.027633490093072   0: 0.027624576967023   3: 0.027624567068557   8: 0.027624538637319   9: 0.027624488680420   6: 0.027624443044650   2: 0.027624404871138   7: 0.027624364617177   1: 0.027624331579476 

training_6051     4: 0.784176880794287   5: 0.023984666819347   7: 0.023980891610890   8: 0.023979806965195   0: 0.023979730259719   3: 0.023979696030742   2: 0.023979653199249   9: 0.023979581687396   1: 0.023979548267665   6: 0.023979544365508 

training_6054     6: 0.691905776212209   2: 0.181171585352418   4: 0.015885946101713   5: 0.015876900434492   0: 0.015864334087664   1: 0.015864153827661   8: 0.015858396551678   9: 0.015857770063555   7: 0.015857627022008   3: 0.015857510346602 

training_6055     5: 0.736349671800404   2: 0.029298970643899   4: 0.029297851621045   6: 0.029297809559734   9: 0.029295831881659   8: 0.029292152077713   3: 0.029292057552456   0: 0.029291952226905   1: 0.029291853234107   7: 0.029291849402078 

training_6056     9: 0.505088718275955   6: 0.327618613627836   0: 0.020935743909736   1: 0.020916729959383   5: 0.020911436981527   4: 0.020907250386736   2: 0.020906367337236   3: 0.020905272452902   8: 0.020905119270598   7: 0.020904747798091 

training_6058     6: 0.776878826615875   0: 0.081176569705589   2: 0.039609056810946   8: 0.026440097713146   1: 0.012650154408457   7: 0.012649641427606   5: 0.012649267163518   4: 0.012648898191116   9: 0.012648897982131   3: 0.012648589981615 

training_6059     5: 0.808498429464462   6: 0.021306683554102   9: 0.021295249200532   0: 0.021279323202777   8: 0.021275375744380   1: 0.021275230198174   4: 0.021267658787626   2: 0.021267560863152   3: 0.021267428311065   7: 0.021267060673731 

training_6060     6: 0.477067490585687   9: 0.310395833118029   0: 0.106016678200751   7: 0.026861036275278   2: 0.019553174635541   1: 0.012030594798305   5: 0.012020345609087   4: 0.012018401362393   3: 0.012018332168271   8: 0.012018113246659 

training_6062     6: 0.803975167938224   1: 0.063243838807931   0: 0.032189803399677   8: 0.020867491361958   5: 0.020300259972360   7: 0.011885752425160   3: 0.011885725453616   9: 0.011885583107054   4: 0.011883260259161   2: 0.011883117274860 

training_6063     6: 0.748721689221812   7: 0.100135269396183   3: 0.045218458128625   0: 0.015135262418856   5: 0.015132863149540   1: 0.015131542628638   4: 0.015131334058625   8: 0.015131287454228   9: 0.015131271002708   2: 0.015131022540785 

training_6065     0: 0.420065851976640   5: 0.399624257682407   9: 0.043649589366628   6: 0.019534899372343   1: 0.019528792042716   8: 0.019521297209347   4: 0.019518984611146   2: 0.019518905980281   7: 0.019518842399804   3: 0.019518579358688 

training_6067     6: 0.496500427094432   9: 0.245670647219727   1: 0.110605786872056   3: 0.046558958482216   0: 0.016781372070641   5: 0.016777912906137   7: 0.016777498644406   4: 0.016776040477470   2: 0.016775730770889   8: 0.016775625462025 

training_6068     1: 0.401309866289050   9: 0.383036545024478   0: 0.026964087199799   6: 0.026963772885467   8: 0.026955890585674   5: 0.026954576400554   2: 0.026954088564227   7: 0.026953941422418   4: 0.026953787095040   3: 0.026953444533294 

training_6069     9: 0.523822455098253   1: 0.256226993289854   8: 0.027499819197637   5: 0.027497864461095   0: 0.027495838533042   6: 0.027495635303961   7: 0.027491430336926   4: 0.027490743874203   2: 0.027489757784346   3: 0.027489462120684 

training_6070     1: 0.607692133311937   0: 0.206707614552095   6: 0.023205968358666   5: 0.023204509870808   4: 0.023199194320129   2: 0.023198360790952   8: 0.023198228280143   3: 0.023198115596416   9: 0.023198104113216   7: 0.023197770805638 

training_6073     5: 0.807430263084522   4: 0.021402596371767   6: 0.021396747442569   0: 0.021396193437639   1: 0.021396059633287   8: 0.021395810345432   9: 0.021395774908648   3: 0.021395548116440   7: 0.021395525113548   2: 0.021395481546149 

training_6075     6: 0.668337461756372   5: 0.195961875911703   4: 0.016965180888182   7: 0.016964801054765   1: 0.016963003511998   0: 0.016961999011600   3: 0.016961611058095   8: 0.016961449641562   9: 0.016961423829075   2: 0.016961193336648 

training_6078     4: 0.772446274003631   5: 0.025288666130236   8: 0.025283341201499   9: 0.025283222700856   3: 0.025283165183874   2: 0.025283149426168   0: 0.025283122492756   1: 0.025283121010651   7: 0.025283024400246   6: 0.025282913450082 

training_6079     6: 0.734574005673665   0: 0.073891398978036   8: 0.066155294011762   1: 0.050072550906326   5: 0.020613390787189   7: 0.010942981342536   9: 0.010939499577970   3: 0.010938172806767   2: 0.010937612273435   4: 0.010935093642314 

training_6081     6: 0.668087769548004   0: 0.167691631930140   7: 0.049469528391145   5: 0.016394641506490   1: 0.016393853538963   9: 0.016393494639301   4: 0.016392600213840   8: 0.016392248062853   3: 0.016392172602360   2: 0.016392059566903 

training_6082     9: 0.492815040723965   1: 0.335355283950013   6: 0.021485352128815   0: 0.021481245821524   5: 0.021479807545999   8: 0.021477512153211   7: 0.021477027379015   4: 0.021476873921411   2: 0.021476303742256   3: 0.021475552633791 

training_6083     6: 0.710839587587638   0: 0.151490654368820   8: 0.039734178276275   1: 0.014167784164901   7: 0.013963132542480   5: 0.013961590083373   9: 0.013961368645049   2: 0.013960632226437   4: 0.013960539559018   3: 0.013960532546009 

training_6084     5: 0.770100810912455   9: 0.061032497251807   4: 0.021113882017624   0: 0.021108961229734   7: 0.021107844020347   8: 0.021107290878107   2: 0.021107242363025   6: 0.021107179992900   1: 0.021107167100034   3: 0.021107124233966 

training_6085     1: 0.360835848048154   9: 0.359176861027326   6: 0.133329258855089   0: 0.039310375249030   5: 0.017905314859414   4: 0.017888900426989   8: 0.017888789339293   7: 0.017888535947600   2: 0.017888323715739   3: 0.017887792531367 

training_6086     6: 0.782656959723715   9: 0.101144105781553   0: 0.041250361673471   5: 0.010908990617323   1: 0.010880233535682   4: 0.010656622063794   2: 0.010627068980108   7: 0.010626207858156   8: 0.010625115406893   3: 0.010624334359307 

training_6088     5: 0.733429227570573   4: 0.101104356186621   3: 0.020683575474740   1: 0.020683425938131   8: 0.020683332245091   0: 0.020683289685039   2: 0.020683231679957   9: 0.020683217005866   6: 0.020683173005740   7: 0.020683171208243 

training_6090     6: 0.416610150862231   3: 0.363867558152205   0: 0.122175326285816   2: 0.034525529497055   5: 0.012774947131043   1: 0.010126305959866   8: 0.009982230931628   4: 0.009980015704092   9: 0.009979467287569   7: 0.009978468188495 

training_6091     6: 0.698927898470342   0: 0.143523408155032   1: 0.074713256659990   8: 0.016779029654407   5: 0.011031795010413   9: 0.011016326285545   2: 0.011010418815116   7: 0.011004266362819   4: 0.010996942810221   3: 0.010996657776115 

training_6092     1: 0.597395869808526   9: 0.237246711583963   6: 0.041788964059141   5: 0.017667077317747   8: 0.017652758439215   0: 0.017651297955780   4: 0.017650313083242   2: 0.017649357673944   7: 0.017649070104204   3: 0.017648579974238 

training_6093     1: 0.432098220895243   7: 0.320300854107684   6: 0.105200252341697   0: 0.020346834616518   5: 0.020346024836905   9: 0.020342520266341   2: 0.020341695147595   4: 0.020341462737549   3: 0.020341107379739   8: 0.020341027670730 

training_6094     5: 0.807766593882028   4: 0.021361383603209   6: 0.021359272885679   1: 0.021359126791172   0: 0.021359057094371   3: 0.021359015542580   8: 0.021358961997090   9: 0.021358893387471   2: 0.021358854884812   7: 0.021358839931589 

training_6096     1: 0.563744399134808   0: 0.260078839611369   5: 0.043788606861819   4: 0.019008208768611   6: 0.018916787267488   9: 0.018903161117743   2: 0.018890791817540   8: 0.018890141448280   7: 0.018889589379850   3: 0.018889474592493 

training_6101     4: 0.375896247235881   6: 0.342533819531393   0: 0.129939432671914   2: 0.047146909531564   9: 0.017429011640943   5: 0.017416672086906   1: 0.017412467588874   3: 0.017408833040633   8: 0.017408648072487   7: 0.017407958599407 

training_6102     4: 0.745489688530940   5: 0.028284976281802   6: 0.028278541678280   1: 0.028278462992891   0: 0.028278266249114   9: 0.028278189120769   8: 0.028278095803919   3: 0.028278061276739   2: 0.028277890951611   7: 0.028277827113936 

training_6103     1: 0.413308780110998   5: 0.237370739245096   2: 0.166144377907904   6: 0.076876910848760   0: 0.017718739903790   8: 0.017716747570778   9: 0.017716305545233   4: 0.017716160274069   7: 0.017715942508277   3: 0.017715296085095 

training_6104     5: 0.684457566953699   0: 0.098164134059090   9: 0.081688279298172   6: 0.019387696113136   4: 0.019386449292692   1: 0.019383353399492   8: 0.019383294523921   7: 0.019383182696976   2: 0.019383033372092   3: 0.019383010290730 

training_6105     5: 0.735409815539374   4: 0.096232853057478   0: 0.021046139184115   6: 0.021045402650525   1: 0.021045325953218   3: 0.021044148997133   9: 0.021044113257717   8: 0.021044104215301   2: 0.021044076373404   7: 0.021044020771735 

training_6106     5: 0.575271228626272   7: 0.251657457794085   6: 0.021636404665064   8: 0.021635432708950   0: 0.021634070766026   1: 0.021633832791950   9: 0.021633250661019   4: 0.021633060791750   3: 0.021632691303595   2: 0.021632569891291 

training_6107     5: 0.786348238770411   4: 0.023741550789754   1: 0.023740051376733   0: 0.023739598642585   6: 0.023738659955180   8: 0.023738485754100   3: 0.023738392332205   2: 0.023738341788176   9: 0.023738341387813   7: 0.023738339203042 

training_6108     6: 0.718806933131793   0: 0.158942508232014   1: 0.040085838785374   7: 0.020838581468169   9: 0.010623800313479   8: 0.010141864934804   5: 0.010140656107813   2: 0.010139986934319   3: 0.010139938485088   4: 0.010139891607146 

training_6111     6: 0.734208593842556   0: 0.124643854102706   7: 0.017664972590122   5: 0.017647392651957   1: 0.017642136032166   2: 0.017640088233497   9: 0.017639368138650   8: 0.017638807380566   4: 0.017638394757743   3: 0.017636392270037 

training_6113     0: 0.535915700515554   5: 0.308706879865090   6: 0.033127737745725   1: 0.031301804446344   8: 0.015184761550285   7: 0.015158550947806   9: 0.015157059613416   4: 0.015149696913010   2: 0.015149679810941   3: 0.015148128591829 

training_6114     6: 0.501378950627956   0: 0.358800051810186   8: 0.055301300836167   5: 0.012074847209578   1: 0.012074528210331   9: 0.012074304589231   7: 0.012074158434023   2: 0.012074018081133   4: 0.012073921246729   3: 0.012073918954666 

training_6115     5: 0.815900674108931   4: 0.020457486660668   6: 0.020456048624582   7: 0.020455211943508   0: 0.020455187951216   8: 0.020455136849325   1: 0.020455118954329   9: 0.020455109380399   3: 0.020455074345367   2: 0.020454951181673 

training_6116     6: 0.509355987722394   0: 0.355601144538230   1: 0.032938801720890   8: 0.014588334253159   9: 0.014587404711676   5: 0.014586325811776   7: 0.014586258354924   4: 0.014585484652091   3: 0.014585171415129   2: 0.014585086819731 

training_6119     6: 0.772684543396660   0: 0.102044332501036   5: 0.027258880932190   2: 0.025246256740713   9: 0.012129050125618   1: 0.012128905735740   8: 0.012127516778941   4: 0.012127249422140   7: 0.012126728989265   3: 0.012126535377696 

training_6120     5: 0.762403388354291   4: 0.026400565926913   1: 0.026400346741290   3: 0.026399823687155   0: 0.026399741355970   6: 0.026399403830003   2: 0.026399233802101   8: 0.026399232077598   7: 0.026399155446445   9: 0.026399108778234 

training_6121     6: 0.418441990080574   1: 0.261466969784681   9: 0.177747001047034   2: 0.031074789160374   3: 0.028126591153603   7: 0.027869906844288   4: 0.013821002076106   0: 0.013818837727339   5: 0.013818578245900   8: 0.013814333880102 

training_6123     4: 0.800739227726706   5: 0.022147571736957   6: 0.022139424976853   0: 0.022139339721483   1: 0.022139285691311   8: 0.022139198896941   9: 0.022139070269383   3: 0.022139069685721   2: 0.022138928224362   7: 0.022138883070284 

training_6124     5: 0.739411708427576   1: 0.055270397832969   8: 0.054613179309578   6: 0.021612932446533   9: 0.021521352292612   0: 0.021518328719277   4: 0.021513410051784   2: 0.021513195997585   7: 0.021513010836086   3: 0.021512484086000 

training_6125     6: 0.699663321776143   7: 0.087012485311527   0: 0.073421470377574   2: 0.068034318411839   1: 0.021057350402101   9: 0.010166343103240   5: 0.010161770286523   3: 0.010161099346645   8: 0.010160923667259   4: 0.010160917317148 

training_6127     6: 0.697401977194912   5: 0.134159786120495   8: 0.060856186230802   1: 0.015373583461680   0: 0.015371440604173   9: 0.015367508113723   3: 0.015367489812390   7: 0.015367418120118   4: 0.015367310342877   2: 0.015367299998829 

training_6128     6: 0.825762191567027   8: 0.061052265215938   1: 0.014191692984378   3: 0.014146908828897   0: 0.014144920499991   2: 0.014142155319549   5: 0.014141159453172   9: 0.014139703667429   7: 0.014139511110074   4: 0.014139491353545 

training_6129     5: 0.796108838663533   4: 0.022656722243957   9: 0.022655826670841   6: 0.022655085177572   1: 0.022654421431571   8: 0.022654335328636   0: 0.022654138607851   2: 0.022653678494164   3: 0.022653586604015   7: 0.022653366777860 

training_6130     5: 0.822114895841015   0: 0.019769492279180   6: 0.019766680510110   1: 0.019765846374704   4: 0.019765638119865   9: 0.019763917506071   8: 0.019763470008336   3: 0.019763466873187   7: 0.019763339612825   2: 0.019763252874707 

training_6134     5: 0.782339158545292   4: 0.024188389975005   8: 0.024184391547909   9: 0.024184110929531   6: 0.024184065590279   3: 0.024184013771825   7: 0.024183998385764   0: 0.024183988860856   2: 0.024183966953628   1: 0.024183915439911 

training_6135     5: 0.668384561114305   6: 0.132534966506907   8: 0.063757883691729   0: 0.019335623337279   1: 0.019334964742416   4: 0.019331199779092   9: 0.019330737552686   2: 0.019330355691087   7: 0.019329884998422   3: 0.019329822586078 

training_6137     6: 0.769125188321801   3: 0.059678721030303   0: 0.055284967833017   4: 0.049143239709965   7: 0.011155379016533   5: 0.011145026475841   8: 0.011144724999977   1: 0.011112090957739   9: 0.011105395367457   2: 0.011105266287367 

training_6138     4: 0.799853963691394   8: 0.062349264123322   5: 0.017238835653928   6: 0.017227444011830   0: 0.017226081914212   1: 0.017221767091697   9: 0.017220898131215   7: 0.017220810110596   2: 0.017220518386105   3: 0.017220416885702 

training_6142     6: 0.702942212311785   0: 0.150501232897910   1: 0.033199780584520   7: 0.029016291962632   5: 0.014058598934562   4: 0.014058011651056   8: 0.014056916490221   9: 0.014056549532603   2: 0.014055284883669   3: 0.014055120751044 

training_6146     5: 0.716644748996683   7: 0.147005043220942   4: 0.017045540609213   6: 0.017044320455871   8: 0.017043762134722   0: 0.017043708349899   9: 0.017043492426829   1: 0.017043326569656   2: 0.017043055454085   3: 0.017043001782102 

training_6147     5: 0.772390368927819   4: 0.025292071191328   0: 0.025291298585562   6: 0.025290813061966   9: 0.025290068285564   3: 0.025289194545097   8: 0.025289073029752   2: 0.025289050713438   7: 0.025289049205670   1: 0.025289012453805 

training_6149     5: 0.839102884077771   4: 0.017880483817488   6: 0.017880164406797   0: 0.017877673471508   1: 0.017876993909622   7: 0.017876811369760   8: 0.017876621698214   9: 0.017876415281541   3: 0.017875985028965   2: 0.017875966938334 

training_6153     6: 0.458617290624321   0: 0.436061127654604   7: 0.024009767681557   2: 0.018287333201079   3: 0.010504930272240   5: 0.010504470171985   9: 0.010504224639136   8: 0.010503739336310   1: 0.010503681520328   4: 0.010503434898440 

training_6154     5: 0.798259417251351   6: 0.022417383745188   8: 0.022416189127459   1: 0.022416059785091   3: 0.022415478883462   7: 0.022415387974650   0: 0.022415302989468   4: 0.022415137451585   2: 0.022414864557635   9: 0.022414778234112 

training_6155     5: 0.771682689204056   3: 0.025369392792977   4: 0.025368897876338   6: 0.025368507031234   8: 0.025368493547555   0: 0.025368491489370   1: 0.025368397242451   2: 0.025368395366039   7: 0.025368385677362   9: 0.025368349772617 

training_6156     6: 0.652901834533698   0: 0.225615942677514   1: 0.052657336788128   3: 0.018156533097727   8: 0.008445165284196   5: 0.008445073257058   2: 0.008444980140787   9: 0.008444897336019   7: 0.008444312375513   4: 0.008443924509359 

training_6157     6: 0.448367462261979   9: 0.235754760853411   0: 0.210300590248441   4: 0.031832585111385   1: 0.012375322804492   5: 0.012290338064723   3: 0.012270454563693   8: 0.012269577624737   2: 0.012269479954522   7: 0.012269428512617 

training_6158     6: 0.750771022594970   1: 0.098223119357344   9: 0.069330458545252   7: 0.011689696307830   4: 0.011669332653028   0: 0.011667403798666   8: 0.011665572909349   3: 0.011662150822540   5: 0.011661161576742   2: 0.011660081434279 

training_6159     6: 0.508790970416946   9: 0.256375288272992   5: 0.029359309981509   0: 0.029358099649751   4: 0.029354898084571   1: 0.029354554126884   7: 0.029352575892447   2: 0.029351951883596   8: 0.029351223768500   3: 0.029351127922805 

training_6163     6: 0.852248602892974   0: 0.030412692098646   1: 0.027476031617816   7: 0.012842952761514   9: 0.012841256966307   5: 0.012837191178673   8: 0.012836407424927   4: 0.012835440353473   2: 0.012835074482055   3: 0.012834350223615 

training_6165     5: 0.763006946808943   3: 0.093549212399374   4: 0.017932604200018   6: 0.017930376232102   0: 0.017930287130403   1: 0.017930275012397   8: 0.017930142876459   9: 0.017930104448662   7: 0.017930082077043   2: 0.017929968814599 

training_6166     2: 0.607455849679918   6: 0.205013350511139   5: 0.048997630908974   0: 0.047593575738049   1: 0.015160357272619   3: 0.015157455395724   4: 0.015157151587627   9: 0.015155071893714   8: 0.015154901124485   7: 0.015154655887750 

training_6169     6: 0.769415807263095   0: 0.108432085461376   5: 0.026349217012536   2: 0.024287213216923   1: 0.011920781497559   9: 0.011920578014090   8: 0.011919111072528   4: 0.011918795850569   7: 0.011918303195780   3: 0.011918107415544 

training_6172     5: 0.805004528334692   4: 0.021669534292010   1: 0.021666309130326   0: 0.021666282781562   6: 0.021665900258301   8: 0.021665677431483   9: 0.021665474695446   3: 0.021665447373991   2: 0.021665440822340   7: 0.021665404879849 

training_6173     4: 0.716761483951807   5: 0.031476291506063   8: 0.031470471645516   6: 0.031470364993540   3: 0.031470309529241   2: 0.031470252904990   9: 0.031470248283752   0: 0.031470246295560   7: 0.031470165697469   1: 0.031470165192063 

training_6175     5: 0.621308191656160   3: 0.184114078734234   4: 0.024326831224604   6: 0.024324505137682   0: 0.024321600847677   1: 0.024321444929747   7: 0.024321269565637   9: 0.024321148275306   8: 0.024320603369414   2: 0.024320326259540 

training_6176     6: 0.742008835695195   5: 0.028671581696749   0: 0.028666962823760   8: 0.028666769164236   1: 0.028665225656183   9: 0.028665173560395   4: 0.028664975875108   3: 0.028663759326653   7: 0.028663650368543   2: 0.028663065833179 

training_6177     6: 0.799665814559625   0: 0.071211141028136   1: 0.048784947018734   9: 0.011576027277648   5: 0.011460662643223   8: 0.011460623504973   7: 0.011460596029958   2: 0.011460186290814   4: 0.011460103886756   3: 0.011459897760133 

training_6178     6: 0.746996285696473   7: 0.088308669232270   8: 0.048015758670701   9: 0.016725192388328   5: 0.016665129350485   1: 0.016664354362572   0: 0.016660619632757   2: 0.016656882356261   4: 0.016653997967134   3: 0.016653110343017 

training_6179     5: 0.675439549469824   3: 0.129852435026443   9: 0.065891566401330   4: 0.018407049639317   6: 0.018402162694811   0: 0.018401993717908   7: 0.018401830890623   8: 0.018401227610598   1: 0.018401130194217   2: 0.018401054354929 

training_6180     5: 0.552609506228808   6: 0.181388005474306   2: 0.121352648777987   0: 0.062793534370344   1: 0.013646333383679   8: 0.013642399331763   9: 0.013642277087848   7: 0.013641969604390   4: 0.013641844714892   3: 0.013641481025983 

training_6181     5: 0.828529244420686   4: 0.019056003566366   6: 0.019052869094407   0: 0.019052022105191   2: 0.019051955358667   1: 0.019051761449768   9: 0.019051713754587   8: 0.019051549123289   7: 0.019051516157553   3: 0.019051364969486 

training_6184     6: 0.733819827214559   0: 0.069387241833513   7: 0.068770405256626   4: 0.053859753545087   2: 0.012431639809986   5: 0.012347624938555   1: 0.012346622388859   9: 0.012345853798084   8: 0.012345587838098   3: 0.012345443376633 

training_6185     5: 0.750809544882776   0: 0.027691349239782   4: 0.027689949394742   6: 0.027687546390801   1: 0.027687461892066   3: 0.027686912004287   2: 0.027686836395587   8: 0.027686832732443   7: 0.027686811180236   9: 0.027686755887281 

training_6186     5: 0.765352507528799   4: 0.026076653998549   6: 0.026073220441709   0: 0.026072560990328   1: 0.026072231036339   8: 0.026071095926590   2: 0.026070515589300   9: 0.026070456132892   3: 0.026070449679107   7: 0.026070308676386 

training_6187     5: 0.673120159777453   6: 0.090850570071208   3: 0.071347037254962   7: 0.058073781283317   4: 0.017771684713798   1: 0.017768184079675   0: 0.017768161961390   8: 0.017767076529131   9: 0.017766692093184   2: 0.017766652235882 

training_6188     0: 0.703832129143519   6: 0.074093243644873   2: 0.069347494058926   1: 0.021823130426347   5: 0.021821445671913   4: 0.021817276892137   8: 0.021816395850858   9: 0.021816352636146   3: 0.021816273259251   7: 0.021816258416029 

training_6189     0: 0.471134810754129   6: 0.213867123452353   5: 0.150341608687185   9: 0.065695020180786   4: 0.025903006262563   8: 0.014632010105004   1: 0.014624058911994   7: 0.014604574451969   2: 0.014599060990534   3: 0.014598726203484 

training_6197     6: 0.635486370157117   0: 0.241415333210496   8: 0.038095621086941   9: 0.028488166815006   7: 0.013639877791177   1: 0.008675309799664   3: 0.008565373974259   5: 0.008554831793184   4: 0.008539846923358   2: 0.008539268448798 

training_6198     5: 0.720246679731422   0: 0.140286306470906   3: 0.017441924264291   4: 0.017438508272424   6: 0.017435805374814   1: 0.017431168561196   7: 0.017430286161380   9: 0.017430195035986   8: 0.017429800994263   2: 0.017429325133318 

training_6199     1: 0.580025847735627   0: 0.236910082641326   5: 0.022885349347393   4: 0.022885068772370   6: 0.022883552845240   2: 0.022883329597557   9: 0.022881950834620   8: 0.022881804337752   7: 0.022881561496339   3: 0.022881452391776 

training_6201     6: 0.707712327758917   9: 0.107180243338051   5: 0.091401168487661   1: 0.018067303894412   0: 0.012610008465861   7: 0.012608689468032   8: 0.012606696333989   2: 0.012605801990892   4: 0.012604117085923   3: 0.012603643176262 

training_6202     6: 0.431937726282404   5: 0.230029820578118   0: 0.207170742771551   1: 0.045328944952965   9: 0.014256711797774   4: 0.014256531000248   7: 0.014255292752360   3: 0.014254922395670   8: 0.014254856674563   2: 0.014254450794347 

training_6204     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_6205     5: 0.663871214048080   2: 0.158666981625293   8: 0.022184723313789   6: 0.022184151402345   1: 0.022182511034489   0: 0.022182414866036   9: 0.022182379295916   3: 0.022182116197053   4: 0.022182028583230   7: 0.022181479633770 

training_6208     6: 0.734221915203941   0: 0.095206283025919   9: 0.055590116580002   1: 0.016441289691159   7: 0.016425524032242   5: 0.016424105108692   4: 0.016422975062678   8: 0.016422835292929   2: 0.016422625296338   3: 0.016422330706100 

training_6209     6: 0.802203873318379   1: 0.059818461754283   8: 0.051096598933815   5: 0.016393894033119   9: 0.016033510100250   7: 0.011154123405772   0: 0.010831298142816   4: 0.010823660927337   3: 0.010823301498459   2: 0.010821277885770 

training_6211     5: 0.776951113971915   4: 0.024788436118519   8: 0.024782736761932   9: 0.024782609875954   0: 0.024782590485483   3: 0.024782580423928   7: 0.024782562832509   2: 0.024782510785710   1: 0.024782476855596   6: 0.024782381888454 

training_6212     5: 0.590415662082310   0: 0.195127634375564   1: 0.026822285578139   6: 0.026806791704889   4: 0.026805791158360   9: 0.026804885240054   2: 0.026804828585969   3: 0.026804308134773   7: 0.026804228218391   8: 0.026803584921550 

training_6213     5: 0.850085692438396   4: 0.016658993880856   6: 0.016657885565739   1: 0.016657635680941   0: 0.016657236588332   8: 0.016656747411215   9: 0.016656659048909   7: 0.016656493964047   3: 0.016656364025943   2: 0.016656291395622 

training_6214     0: 0.417386328827746   2: 0.260387651234012   6: 0.187647563208140   5: 0.019232610920986   4: 0.019227808452557   8: 0.019225811169261   1: 0.019224752434845   9: 0.019222972469541   3: 0.019222318926528   7: 0.019222182356385 

training_6215     6: 0.549278080553182   1: 0.317901312112452   8: 0.046074582277582   3: 0.021212562082748   5: 0.010950353364752   0: 0.010927454640052   4: 0.010915638877031   7: 0.010914553310445   9: 0.010913838010871   2: 0.010911624770886 

training_6217     5: 0.453512330315327   1: 0.316222612060841   0: 0.100562736633673   4: 0.035146490357668   3: 0.023460325781194   6: 0.014352907679045   7: 0.014203336318779   2: 0.014183592080973   9: 0.014178048427546   8: 0.014177620344954 

training_6218     6: 0.558389347315708   5: 0.193651635952585   0: 0.095450637262918   8: 0.040107990061959   2: 0.018734268584496   1: 0.018733432180157   9: 0.018733271673737   3: 0.018733201668039   4: 0.018733152832897   7: 0.018733062467505 

training_6220     5: 0.649866227613003   7: 0.136572922603382   2: 0.065177557902643   0: 0.041092328108608   3: 0.018603309613067   4: 0.017742763118024   6: 0.017739449368088   8: 0.017736886715738   1: 0.017735445737006   9: 0.017733109220442 

training_6221     6: 0.695514984806154   0: 0.124009450630124   7: 0.063797796636282   5: 0.016671617165593   1: 0.016668529630719   8: 0.016668159264509   4: 0.016667656554840   9: 0.016667424982481   2: 0.016667365093658   3: 0.016667015235641 

training_6222     5: 0.735833748387384   2: 0.070365317794549   8: 0.058727837343778   1: 0.019296670103158   0: 0.019296242906344   4: 0.019296216745057   9: 0.019296174876443   6: 0.019296109352020   3: 0.019295924919639   7: 0.019295757571628 

training_6223     8: 0.332095771298060   0: 0.310826007169998   1: 0.215517592628860   5: 0.020226057842618   6: 0.020225967216587   9: 0.020222002185490   2: 0.020221915427027   4: 0.020221849201442   7: 0.020221544188641   3: 0.020221292841278 

training_6225     6: 0.822393942574984   0: 0.067955027292239   5: 0.020681740816928   8: 0.019135494987553   1: 0.011670439618230   4: 0.011635246716461   7: 0.011632996081953   9: 0.011632117530496   2: 0.011631544270116   3: 0.011631450111040 

training_6227     4: 0.730935129303580   5: 0.029901384230827   8: 0.029896006126595   9: 0.029895569906139   0: 0.029895404979666   3: 0.029895350940160   7: 0.029895326865519   2: 0.029895305481613   1: 0.029895301409794   6: 0.029895220756107 

training_6231     5: 0.776317650133260   4: 0.024857296155230   3: 0.024853237169905   8: 0.024853211732376   2: 0.024853172981304   1: 0.024853148140088   9: 0.024853085729072   0: 0.024853083305382   6: 0.024853068491629   7: 0.024853046161755 

training_6232     5: 0.794481756590460   4: 0.022841608338906   0: 0.022834922166635   8: 0.022834868244861   9: 0.022834610284465   3: 0.022834533206104   1: 0.022834526103826   6: 0.022834494574278   2: 0.022834342179231   7: 0.022834338311235 

training_6233     5: 0.793568349000355   4: 0.022940202003668   6: 0.022937141227225   1: 0.022936778859233   8: 0.022936344555291   3: 0.022936313479234   0: 0.022936253366486   9: 0.022936245472222   2: 0.022936201095687   7: 0.022936170940599 

training_6234     5: 0.830650667297780   4: 0.018822482669775   1: 0.018816137700190   8: 0.018816025389245   0: 0.018815979542841   6: 0.018815910039623   9: 0.018815723691165   2: 0.018815691365430   3: 0.018815691241384   7: 0.018815691062567 

training_6235     5: 0.647112602447332   4: 0.163100792331259   2: 0.023724981703607   3: 0.023723954134302   6: 0.023723142936375   1: 0.023723095041281   7: 0.023722928968818   0: 0.023722918587030   8: 0.023722795274672   9: 0.023722788575325 

training_6236     6: 0.505138418911403   7: 0.272050258225265   1: 0.027852712911294   0: 0.027852305116632   8: 0.027851716538501   5: 0.027851301492975   9: 0.027850995213918   2: 0.027850944483316   4: 0.027850842520871   3: 0.027850504585825 

training_6239     6: 0.620411786360417   7: 0.201234949234085   5: 0.022296152810567   4: 0.022294517403625   0: 0.022294393686997   1: 0.022294046956881   8: 0.022294029172619   9: 0.022293780805754   2: 0.022293247963231   3: 0.022293095605826 

training_6240     5: 0.778391337879148   4: 0.024626325805642   9: 0.024623381584513   0: 0.024622897756629   1: 0.024622767757991   6: 0.024622743036648   7: 0.024622703861327   3: 0.024622669209477   2: 0.024622638363827   8: 0.024622534744797 

training_6242     4: 0.788966331695918   5: 0.023453873099473   8: 0.023448180602686   9: 0.023447438411920   3: 0.023447425619665   6: 0.023447395198166   2: 0.023447371979008   0: 0.023447368639507   1: 0.023447321946424   7: 0.023447292807233 

training_6243     4: 0.762767604027608   5: 0.026369844011657   8: 0.026358064743824   9: 0.026358009052392   0: 0.026357867343077   3: 0.026357817256718   2: 0.026357776904180   1: 0.026357727204630   7: 0.026357673095037   6: 0.026357616360875 

training_6244     5: 0.793768182204534   2: 0.022974834784492   4: 0.022912725605753   1: 0.022907943658984   0: 0.022907501529139   6: 0.022906711108650   8: 0.022905836775852   9: 0.022905434344377   3: 0.022905423225717   7: 0.022905406762500 

training_6246     5: 0.697237965864603   8: 0.129863809603633   0: 0.021755406454060   7: 0.021622744356169   6: 0.021591905114793   1: 0.021590051280136   9: 0.021585725602857   4: 0.021584460374035   2: 0.021584253752398   3: 0.021583677597316 

training_6248     5: 0.816280012905356   4: 0.020421084485205   1: 0.020412783453656   0: 0.020412662280355   6: 0.020412552205101   9: 0.020412307884581   8: 0.020412193960693   2: 0.020412145639131   3: 0.020412132593580   7: 0.020412124592343 

training_6252     5: 0.483580693448454   2: 0.195808839391036   3: 0.157857504846153   0: 0.023255749867175   6: 0.023253267272579   9: 0.023249967575323   4: 0.023248959139898   1: 0.023248955206591   8: 0.023248322723040   7: 0.023247740529752 

training_6253     6: 0.719067165600435   1: 0.150684038236243   0: 0.038595954137983   9: 0.013163927545913   8: 0.013082867214891   5: 0.013081851147923   7: 0.013081574837094   2: 0.013080925853384   4: 0.013080908799347   3: 0.013080786626786 

training_6254     5: 0.703654201783573   1: 0.141342446354628   6: 0.019377715088039   4: 0.019377251257492   0: 0.019375385481798   9: 0.019375304965124   3: 0.019374669493967   2: 0.019374517288971   8: 0.019374307194330   7: 0.019374201092078 

training_6257     4: 0.692562687353235   2: 0.081789647963364   7: 0.071284155361898   1: 0.022078783668762   5: 0.022052882874141   6: 0.022046959500151   8: 0.022046350866707   3: 0.022046214407196   9: 0.022046194214583   0: 0.022046123789964 

training_6259     6: 0.720083255102828   0: 0.155090729211917   1: 0.029319725221241   7: 0.023665752161291   5: 0.011976911561863   8: 0.011975916021615   4: 0.011972505257015   9: 0.011972074835693   2: 0.011971640339332   3: 0.011971490287205 

training_6264     6: 0.718806583949486   0: 0.159506846482190   1: 0.015214301432746   5: 0.015211318587583   2: 0.015210821015411   9: 0.015210780120505   4: 0.015210083070022   8: 0.015209969989298   7: 0.015209787427092   3: 0.015209507925667 

training_6265     6: 0.747669199223537   0: 0.089711693821502   5: 0.064828523265892   1: 0.014020140061972   3: 0.013969670205941   8: 0.013962431858411   9: 0.013961211854340   7: 0.013959206398086   2: 0.013959051270424   4: 0.013958872039894 

training_6267     6: 0.433060776979787   5: 0.235815687931884   0: 0.124410928724772   1: 0.089178220887863   2: 0.038659186060335   8: 0.015782411181591   9: 0.015774873119802   3: 0.015773402750625   4: 0.015772378725614   7: 0.015772133637726 

training_6269     6: 0.778058632382834   0: 0.058166497816611   4: 0.041261071316745   1: 0.041063234556743   7: 0.020703538893010   8: 0.012160740833351   3: 0.012151822342921   5: 0.012147042150173   9: 0.012143836541034   2: 0.012143583166578 

training_6271     5: 0.665501217116831   6: 0.073312030324585   7: 0.066375840267381   2: 0.063224343062792   4: 0.050078236751098   3: 0.016311063534481   0: 0.016303463233066   1: 0.016298086106654   9: 0.016297958206095   8: 0.016297761397018 

training_6273     5: 0.764028517973300   4: 0.026222061199257   8: 0.026218778476802   3: 0.026218771813438   9: 0.026218736078258   0: 0.026218720630689   2: 0.026218703895844   1: 0.026218646480479   7: 0.026218553067170   6: 0.026218510384764 

training_6274     5: 0.721239667555519   2: 0.116903849566687   4: 0.020234560173071   6: 0.020233427610475   8: 0.020232239978549   9: 0.020231664923933   0: 0.020231615179996   7: 0.020231072138029   1: 0.020231028409395   3: 0.020230874464347 

training_6275     5: 0.790989669113060   3: 0.023223931646975   2: 0.023223667817201   4: 0.023223543608124   1: 0.023223506619681   6: 0.023223242302228   0: 0.023223181707572   7: 0.023223116021075   9: 0.023223089577684   8: 0.023223051586400 

training_6276     0: 0.701894291624964   5: 0.076867033310103   8: 0.069798902119711   1: 0.021636048945763   9: 0.021634507126019   6: 0.021634433385316   4: 0.021634219487814   3: 0.021633550536386   2: 0.021633547787455   7: 0.021633465676469 

training_6277     1: 0.413354108733950   0: 0.409798890339778   5: 0.022131561098989   4: 0.022126179883078   6: 0.022103283392536   9: 0.022102136496718   8: 0.022097744124034   7: 0.022095642027011   3: 0.022095266454404   2: 0.022095187449503 

training_6278     5: 0.520251369863223   7: 0.187721747822722   1: 0.091168823524439   6: 0.079045843716553   9: 0.020353476753541   0: 0.020301609180542   4: 0.020295454951512   8: 0.020287725983590   2: 0.020287250305917   3: 0.020286697897960 

training_6279     5: 0.837283858703883   6: 0.018082256938744   1: 0.018081247116496   0: 0.018080133197734   4: 0.018079585391239   8: 0.018079000360471   9: 0.018078783160907   7: 0.018078592967427   3: 0.018078337291191   2: 0.018078204871906 

training_6280     5: 0.666549839618193   4: 0.147197215473316   1: 0.023285896960299   0: 0.023283169633402   6: 0.023281137498839   3: 0.023280874108573   2: 0.023280574697615   9: 0.023280476247905   8: 0.023280470050790   7: 0.023280345711069 

training_6282     0: 0.606766216386887   3: 0.235057197176220   9: 0.055333119915865   1: 0.014706379377202   5: 0.014699055514034   6: 0.014691584822630   2: 0.014690139495934   4: 0.014687066272574   8: 0.014684818482304   7: 0.014684422556350 

training_6283     5: 0.780179244159325   4: 0.072008138242593   7: 0.018477495383906   6: 0.018477231421736   1: 0.018476759567904   0: 0.018476501050418   9: 0.018476362314697   8: 0.018476356332543   2: 0.018475970210068   3: 0.018475941316809 

training_6287     5: 0.799035936957732   6: 0.022336602542363   0: 0.022330946483764   1: 0.022329855801752   9: 0.022329275475688   8: 0.022328404181177   2: 0.022327346495062   3: 0.022327297167185   7: 0.022327245183879   4: 0.022327089711398 

training_6288     4: 0.799878459399420   5: 0.022244242962127   6: 0.022235575215526   0: 0.022235196264160   1: 0.022235080969414   8: 0.022234478260081   7: 0.022234366591053   3: 0.022234254717570   2: 0.022234235356248   9: 0.022234110264401 

training_6293     5: 0.689319093611967   6: 0.136039410763851   4: 0.064288148022644   0: 0.015767435240549   1: 0.015765091242017   9: 0.015764810888267   3: 0.015764157408426   2: 0.015764049773165   8: 0.015763992982223   7: 0.015763810066890 

training_6294     2: 0.741084806657043   5: 0.028776418369709   4: 0.028769970882976   9: 0.028768207761724   1: 0.028767131026572   6: 0.028767000642071   8: 0.028766954988406   7: 0.028766891681371   0: 0.028766566770949   3: 0.028766051219179 

training_6295     5: 0.496776169011456   7: 0.276632802867199   4: 0.028325038662240   3: 0.028324307959461   6: 0.028324244335869   0: 0.028323930206451   1: 0.028323897274044   8: 0.028323280623668   2: 0.028323266026203   9: 0.028323063033409 

training_6296     6: 0.569469805200805   2: 0.094898275518555   8: 0.088178015247610   0: 0.071565488524581   1: 0.065003951451373   5: 0.051966700731342   3: 0.014743445928117   7: 0.014726591065718   9: 0.014723905578189   4: 0.014723820753710 

training_6297     5: 0.597145456180171   0: 0.237086027917700   3: 0.020728496422816   4: 0.020726264367205   6: 0.020724016949682   1: 0.020718602311099   7: 0.020718112757495   9: 0.020718090690854   8: 0.020717770004807   2: 0.020717162398170 

training_6298     4: 0.607029377644936   1: 0.123640237561858   0: 0.100550627174867   5: 0.024117527809162   8: 0.024110667990959   9: 0.024110483036440   3: 0.024110358023443   2: 0.024110287402703   6: 0.024110224038348   7: 0.024110209317285 

training_6299     4: 0.467608138442038   9: 0.314671204787646   5: 0.027224486066798   0: 0.027213955540991   2: 0.027213946363030   8: 0.027213889198660   1: 0.027213717831082   3: 0.027213637919247   6: 0.027213582330116   7: 0.027213441520392 

training_6301     9: 0.463463575746051   6: 0.213404386947589   2: 0.181440319980826   7: 0.036716296880646   8: 0.017507274557060   5: 0.017497617267661   0: 0.017494713676162   4: 0.017493118158857   1: 0.017492642494762   3: 0.017490054290386 

training_6305     5: 0.527182589093332   7: 0.257447664670527   3: 0.026922628013496   4: 0.026921573234737   6: 0.026921537431757   1: 0.026921177795099   0: 0.026921165738412   2: 0.026920635489324   8: 0.026920578222985   9: 0.026920450310331 

training_6306     4: 0.719127698458061   5: 0.031213997946746   2: 0.031208125223356   9: 0.031207586774677   6: 0.031207436109644   3: 0.031207262578778   8: 0.031207080996065   1: 0.031207054569214   7: 0.031206911250057   0: 0.031206846093401 

training_6309     5: 0.774892603666632   3: 0.076943575987051   8: 0.042997225064005   4: 0.015028289000497   6: 0.015024278963527   1: 0.015023802807040   9: 0.015022917371824   7: 0.015022733153998   0: 0.015022605236929   2: 0.015021968748497 

training_6310     4: 0.561370578854391   5: 0.214864522938957   3: 0.060577157469873   2: 0.057654506860929   6: 0.017591479702785   9: 0.017588701788963   0: 0.017588519185807   7: 0.017588475365040   1: 0.017588142847836   8: 0.017587914985416 

training_6311     5: 0.588799497728576   6: 0.198256415165298   4: 0.026620802711031   1: 0.026618190101175   0: 0.026617893850232   7: 0.026617808298346   9: 0.026617687152862   8: 0.026617389778097   3: 0.026617179431418   2: 0.026617135782966 

training_6312     5: 0.599283905050684   0: 0.218878784316623   3: 0.046826342923492   2: 0.019297910140743   9: 0.019292162373562   6: 0.019287507893143   4: 0.019284808360586   1: 0.019284011009510   7: 0.019282286268197   8: 0.019282281663461 

training_6313     4: 0.716937785185221   5: 0.070758179478491   3: 0.070361095274259   6: 0.020278382412099   1: 0.020278136205817   0: 0.020278007658928   9: 0.020277532190942   8: 0.020277048276781   2: 0.020276953573427   7: 0.020276879744036 

training_6315     5: 0.812074700787134   6: 0.020902361258764   1: 0.020889808523051   0: 0.020880259275501   8: 0.020877976835031   9: 0.020875628923732   7: 0.020875549382805   4: 0.020874867015878   2: 0.020874541950680   3: 0.020874306047424 

training_6317     6: 0.580800291162978   9: 0.200446711660607   5: 0.073222088456990   3: 0.046000836979498   1: 0.028163389545308   8: 0.014312505407985   0: 0.014267521331702   7: 0.014262856052273   4: 0.014261979526017   2: 0.014261819876642 

training_6323     5: 0.749839638822723   0: 0.086352061184371   4: 0.020479302983117   8: 0.020475710303542   6: 0.020475684059898   3: 0.020475564138155   2: 0.020475556838395   9: 0.020475546599148   1: 0.020475480556656   7: 0.020475454513994 

training_6324     5: 0.662465125517328   4: 0.155721333314122   9: 0.022737414343087   6: 0.022731877960451   1: 0.022726831986512   0: 0.022725419251609   7: 0.022723407046313   3: 0.022723004665122   2: 0.022722887693322   8: 0.022722698222135 

training_6325     5: 0.809286896043040   4: 0.021196272241279   6: 0.021189882589520   0: 0.021189757126324   1: 0.021189690685167   8: 0.021189640725774   9: 0.021189593111221   3: 0.021189446894005   2: 0.021189438019909   7: 0.021189382563760 

training_6326     6: 0.509718449024182   1: 0.181490873932435   0: 0.075663797686218   5: 0.074841809679006   8: 0.072736475717329   9: 0.019028330066329   3: 0.019028004171281   4: 0.018333187903088   7: 0.017836413791727   2: 0.011322658028407 

training_6331     1: 0.718825636381040   5: 0.124736232119233   4: 0.020116790028212   6: 0.019804257102531   0: 0.019421416213918   3: 0.019420578111431   9: 0.019420038280698   7: 0.019419364450145   2: 0.019417969299076   8: 0.019417718013715 

training_6333     5: 0.721955327164006   0: 0.030928896129948   8: 0.030899866280186   6: 0.030892211173186   4: 0.030889066301552   9: 0.030887289764648   1: 0.030886902228884   2: 0.030886866890057   7: 0.030886824875882   3: 0.030886749191652 

training_6335     5: 0.629247210134127   0: 0.238509689922227   6: 0.016536615809708   1: 0.016532153963521   8: 0.016530504776651   7: 0.016529204022561   3: 0.016529101016693   4: 0.016528670429437   9: 0.016528634213988   2: 0.016528215711087 

training_6337     6: 0.410610992835924   1: 0.409792454957365   0: 0.073835407398414   9: 0.029709909851172   7: 0.020780229268887   5: 0.011054935480433   4: 0.011054234673238   8: 0.011054190871594   3: 0.011053835093689   2: 0.011053809569284 

training_6338     6: 0.417254744185428   1: 0.416683667742288   0: 0.058513817545585   9: 0.033080619053504   4: 0.021048522994832   7: 0.018383756082020   5: 0.011689848700283   8: 0.007782285436676   2: 0.007781819832068   3: 0.007780918427316 

training_6339     6: 0.601107435750000   3: 0.192139521006938   7: 0.088996293684322   5: 0.016846160417933   1: 0.016828776452131   9: 0.016824553352297   0: 0.016822097070218   8: 0.016821397995254   2: 0.016806984336385   4: 0.016806779934522 

training_6340     0: 0.595264082485626   6: 0.185526563191925   5: 0.084641985639736   7: 0.055718159975893   1: 0.017600814729529   9: 0.012557540084525   4: 0.012194080860453   8: 0.012167356392948   2: 0.012164942563304   3: 0.012164474076060 

training_6341     5: 0.747638755186665   8: 0.087741711292151   6: 0.020579802200928   2: 0.020578079510400   0: 0.020577944967049   4: 0.020577503574372   1: 0.020577258298492   7: 0.020576590680664   3: 0.020576190993068   9: 0.020576163296210 

training_6342     6: 0.754011079149578   9: 0.027362528221950   7: 0.027335275511719   8: 0.027332083819256   1: 0.027327478628642   2: 0.027326594564279   0: 0.027326456023367   3: 0.027326179337906   5: 0.027326164050822   4: 0.027326160692481 

training_6344     6: 0.618428965639384   7: 0.250539453262090   0: 0.016433364342000   1: 0.016403099804429   9: 0.016371674245544   5: 0.016366086960399   8: 0.016365307727949   2: 0.016364288713873   3: 0.016363880004951   4: 0.016363879299380 

training_6346     6: 0.513210806941544   1: 0.200354205560491   0: 0.185365966200422   9: 0.030336243104973   7: 0.028106193101054   5: 0.008613950818527   4: 0.008537398309827   3: 0.008494889300107   8: 0.008490891098472   2: 0.008489455564583 

training_6347     2: 0.392257310470637   5: 0.374805658605949   9: 0.029189824246996   8: 0.029144875634268   3: 0.029106717897876   6: 0.029105241144259   1: 0.029102505962290   4: 0.029097815809479   0: 0.029096694678589   7: 0.029093355549658 

training_6348     6: 0.729074081990325   3: 0.082959928651584   0: 0.057086936856319   1: 0.046306755595960   5: 0.014096139541899   8: 0.014095685678474   9: 0.014095467134516   7: 0.014095047193198   2: 0.014095004742517   4: 0.014094952615208 

training_6349     4: 0.304225814919700   5: 0.261185018596439   1: 0.234720712296071   2: 0.073562675257787   9: 0.042732625569545   6: 0.016725579017760   3: 0.016714156220193   0: 0.016712071976133   8: 0.016711827878058   7: 0.016709518268313 

training_6350     6: 0.861360577815326   9: 0.015406959587133   0: 0.015405243431478   5: 0.015404736243592   8: 0.015404715237914   1: 0.015404241879648   7: 0.015403448640338   3: 0.015403407658847   4: 0.015403381234496   2: 0.015403288271229 

training_6352     6: 0.717685224457549   7: 0.105720686088474   0: 0.056605428333436   8: 0.041119606336307   3: 0.019620774989673   1: 0.011877042512877   9: 0.011844266975764   5: 0.011843373319402   4: 0.011842402826339   2: 0.011841194160179 

training_6353     6: 0.539397465010478   0: 0.287142763542413   8: 0.086087899044911   5: 0.012488687700091   1: 0.012482658808139   2: 0.012481760190487   4: 0.012481009237537   9: 0.012479752802864   3: 0.012479232234746   7: 0.012478771428333 

training_6354     6: 0.459936573185107   7: 0.326535440578312   8: 0.054394623511079   1: 0.022743475690271   9: 0.022735361038627   5: 0.022733247426855   0: 0.022730879886394   3: 0.022730556294696   2: 0.022729981586284   4: 0.022729860802376 

training_6355     5: 0.397364045483225   8: 0.354328754318698   9: 0.031042434621087   1: 0.031041719793597   4: 0.031040177465306   3: 0.031039773044921   6: 0.031037887808249   0: 0.031035728355050   2: 0.031034800132356   7: 0.031034678977510 

training_6356     5: 0.487081197115846   3: 0.283098659760318   8: 0.094004548743880   1: 0.019443552707531   0: 0.019406762506926   6: 0.019406000882307   4: 0.019394131495783   9: 0.019390277183326   7: 0.019389201363855   2: 0.019385668240227 

training_6357     6: 0.373873492558922   1: 0.352704628282868   0: 0.178310627132180   3: 0.020931000412765   8: 0.014546751682062   7: 0.013664071525730   9: 0.011586250460184   5: 0.011574964443747   4: 0.011404251092601   2: 0.011403962408942 

training_6358     5: 0.672844625684912   9: 0.165960512835849   0: 0.020159039330557   7: 0.020155354283789   6: 0.020155106670233   1: 0.020145731413849   3: 0.020145364588581   4: 0.020145204032315   8: 0.020144945232378   2: 0.020144115927538 

training_6359     9: 0.464898613401758   6: 0.422169078759303   0: 0.025677188447466   1: 0.012515268951621   5: 0.012463994927431   8: 0.012456544151278   2: 0.012455605946974   3: 0.012455097080861   4: 0.012454333751904   7: 0.012454274581405 

training_6361     9: 0.343261690198730   6: 0.280511061015066   0: 0.225994607658004   3: 0.032607512879594   4: 0.032479099427842   1: 0.017066770910862   5: 0.017021944369793   8: 0.017020751385727   2: 0.017018338164379   7: 0.017018223990003 

training_6362     6: 0.778351242695732   9: 0.024634793541174   0: 0.024630412286785   8: 0.024629289408135   5: 0.024627149438040   1: 0.024626676005755   7: 0.024625266928422   4: 0.024625165044149   2: 0.024625023819588   3: 0.024624980832219 

training_6364     6: 0.719919331168223   9: 0.031138205269794   8: 0.031136240381297   0: 0.031116369481290   5: 0.031115597440169   1: 0.031115579634340   2: 0.031114948919742   7: 0.031114719400346   3: 0.031114513523488   4: 0.031114494781311 

training_6365     6: 0.481152421724803   9: 0.286094998912860   0: 0.029096085407290   8: 0.029095370968839   1: 0.029094517789628   5: 0.029093837362870   2: 0.029093566934518   7: 0.029093309370865   3: 0.029093033615611   4: 0.029092857912718 

training_6366     6: 0.479311998827617   8: 0.286899643018106   9: 0.029226465900407   0: 0.029225927549099   5: 0.029224402832639   1: 0.029223624311480   2: 0.029222322204649   7: 0.029222157018954   3: 0.029221742652220   4: 0.029221715684829 

training_6368     6: 0.499905565844254   0: 0.202690589684835   1: 0.193694477900905   2: 0.014823979319509   5: 0.014816672699234   8: 0.014814070896149   4: 0.014814055966789   7: 0.014813774362014   9: 0.014813756344822   3: 0.014813056981488 

training_6369     6: 0.734471564715673   9: 0.115299447832063   0: 0.055601150887203   8: 0.013535427560512   1: 0.013515986302173   5: 0.013515783159095   3: 0.013515202332928   2: 0.013515167369286   7: 0.013515165507763   4: 0.013515104333304 

training_6371     6: 0.753557357567491   2: 0.095067036383103   8: 0.018923331309803   1: 0.018922897634187   5: 0.018922208376076   9: 0.018921999617898   0: 0.018921803916245   7: 0.018921682091358   4: 0.018920884336859   3: 0.018920798766980 

training_6372     1: 0.657278209055739   5: 0.122833038003633   0: 0.077920101827053   6: 0.020293495857971   4: 0.020283275670115   8: 0.020279656602906   3: 0.020278973458827   9: 0.020278078946897   2: 0.020277817520543   7: 0.020277353056316 

training_6373     0: 0.558412309132477   6: 0.324270720509101   5: 0.014731757507462   1: 0.014656019129497   8: 0.014655704608575   4: 0.014655547061601   2: 0.014654888629034   9: 0.014654676396711   7: 0.014654228388234   3: 0.014654148637309 

training_6375     6: 0.769368913848696   5: 0.059493408127481   1: 0.057012822253785   3: 0.031144110819068   0: 0.013836398971314   8: 0.013831424460837   2: 0.013829106576320   7: 0.013828479550564   4: 0.013828466939279   9: 0.013826868452656 

training_6376     6: 0.832066372357594   7: 0.049684147162035   1: 0.032274553383737   5: 0.012306621915264   0: 0.012285245313555   4: 0.012284725351244   9: 0.012274959224000   8: 0.012274902504169   3: 0.012274237642233   2: 0.012274235146169 

training_6382     1: 0.553626733472746   6: 0.177126194659024   0: 0.152200244757835   9: 0.025560122265352   8: 0.023841843234950   5: 0.013532310581486   4: 0.013530503229587   2: 0.013527755861544   3: 0.013527230561087   7: 0.013527061376389 

training_6384     6: 0.656905857460206   0: 0.157346080749016   5: 0.052775892600229   7: 0.039037788453681   1: 0.015658261780362   3: 0.015657696893092   8: 0.015656949279899   9: 0.015654583339599   4: 0.015653708800473   2: 0.015653180643444 

training_6385     6: 0.821244468413693   9: 0.019862894714564   0: 0.019862605715599   5: 0.019861926248854   7: 0.019861691146078   8: 0.019861654403695   1: 0.019861412730232   4: 0.019861246791445   2: 0.019861115632847   3: 0.019860984202994 

training_6386     6: 0.642764281277469   5: 0.226902246171660   8: 0.016361805159677   1: 0.016284811473342   0: 0.016283749864554   2: 0.016281186851430   7: 0.016280787118959   9: 0.016280540375812   4: 0.016280493344955   3: 0.016280098362143 

training_6394     6: 0.725810301232036   8: 0.030466605882512   5: 0.030466583024759   0: 0.030466342411324   1: 0.030466055318932   9: 0.030465079704636   7: 0.030464868864247   4: 0.030464819911020   3: 0.030464683344709   2: 0.030464660305825 

training_6398     6: 0.755341464697626   0: 0.027186235392213   9: 0.027185784478116   1: 0.027184709024156   8: 0.027184153611102   5: 0.027183840101761   3: 0.027183566349137   2: 0.027183553367587   7: 0.027183397121527   4: 0.027183295856775 

training_6399     9: 0.443706144141967   6: 0.420792479085787   8: 0.016942209770200   0: 0.016938513600409   5: 0.016938190447003   1: 0.016937227306099   3: 0.016936520347911   7: 0.016936306324011   2: 0.016936272214973   4: 0.016936136761641 

training_64       5: 0.829850411722596   6: 0.018915433558820   1: 0.018907853146053   0: 0.018905513939252   9: 0.018905215159651   8: 0.018904621578930   4: 0.018903922891800   3: 0.018903656132376   2: 0.018901900157679   7: 0.018901471712842 

training_6400     6: 0.782084379438442   0: 0.100699974174123   1: 0.036689930556496   8: 0.016802621539639   7: 0.014839523898316   2: 0.011654374027059   3: 0.011419011436167   9: 0.008631966103396   5: 0.008589397485885   4: 0.008588821340476 

training_6402     1: 0.339226035290284   7: 0.276965582731551   0: 0.190084772243269   4: 0.078994063391402   6: 0.045173321424751   5: 0.013915002488525   9: 0.013911604943013   8: 0.013910191155505   2: 0.013909774223046   3: 0.013909652108654 

training_6404     6: 0.730960321719096   3: 0.077848342935160   9: 0.066454065616382   8: 0.030926184101830   2: 0.028108653201158   1: 0.013148586355102   0: 0.013139577107906   5: 0.013138796743153   7: 0.013137782442029   4: 0.013137689778184 

training_6405     6: 0.768978647390484   8: 0.025671387867928   1: 0.025671152858600   5: 0.025670728806002   0: 0.025669156073230   4: 0.025668141106140   2: 0.025667837932133   7: 0.025667807887073   9: 0.025667623257845   3: 0.025667516820565 

training_6406     6: 0.841998608814123   0: 0.046055296760660   1: 0.025502441718091   7: 0.019670323594701   9: 0.011155787268567   5: 0.011128862401594   3: 0.011123145747634   4: 0.011122039584400   8: 0.011121905314453   2: 0.011121588795777 

training_6407     6: 0.790000450996987   8: 0.092266779661032   1: 0.014719761944802   0: 0.014718219497040   5: 0.014717099090640   9: 0.014715850103945   4: 0.014715509175320   2: 0.014715499636043   7: 0.014715420355541   3: 0.014715409538649 

training_6410     1: 0.455899722750070   6: 0.190852516941884   0: 0.162604915429441   3: 0.057372031921758   2: 0.055786146043084   9: 0.036561022938819   5: 0.010236128420117   4: 0.010231046491460   8: 0.010228508894198   7: 0.010227960169171 

training_6412     6: 0.744012374276379   9: 0.055331515857835   0: 0.048249780153004   3: 0.047979840869931   4: 0.017412949730290   7: 0.017405673622672   5: 0.017402775306653   1: 0.017402478584655   2: 0.017401425643887   8: 0.017401185954695 

training_6413     1: 0.454364554089633   2: 0.237634916212401   0: 0.173585643701328   5: 0.019248416954205   4: 0.019220007857120   6: 0.019196118953246   7: 0.019193942838148   9: 0.019188779017005   8: 0.019184918613298   3: 0.019182701763615 

training_6414     6: 0.751632760003412   1: 0.078680035300416   3: 0.054012321884358   0: 0.016534587650065   8: 0.016524446501220   7: 0.016523381795458   5: 0.016523306095999   9: 0.016523167071535   4: 0.016523027559538   2: 0.016522966137998 

training_6416     0: 0.481955969433256   9: 0.287503824976325   5: 0.028848051667425   4: 0.028837372888922   6: 0.028820261145758   8: 0.028809567352114   7: 0.028807983706555   2: 0.028805790538062   1: 0.028805617475292   3: 0.028805560816291 

training_6417     0: 0.732486750340283   5: 0.029748294702184   4: 0.029741080174121   6: 0.029729234929907   7: 0.029718285880481   9: 0.029717896136023   8: 0.029716442189820   2: 0.029714130660916   1: 0.029714118978657   3: 0.029713766007608 

training_6419     5: 0.826989013037259   6: 0.019224531428227   1: 0.019224045587235   0: 0.019223870864436   2: 0.019223720698365   7: 0.019223110219601   4: 0.019223109730383   9: 0.019223062432624   3: 0.019222803437347   8: 0.019222732564523 

training_6420     5: 0.767065829256600   4: 0.025886642626973   1: 0.025883098095039   2: 0.025881557719200   9: 0.025881374246631   0: 0.025880645153000   8: 0.025880366721393   3: 0.025880211718759   7: 0.025880154284751   6: 0.025880120177654 

training_6421     6: 0.805283180107828   0: 0.064018128561715   7: 0.016365426193861   5: 0.016335280869829   4: 0.016334348113436   1: 0.016333273819965   9: 0.016333273492555   2: 0.016332676236102   8: 0.016332294369700   3: 0.016332118235009 

training_6422     5: 0.827326390503124   6: 0.019190706451791   0: 0.019187494822860   1: 0.019187171673984   2: 0.019185497755430   4: 0.019185359671501   8: 0.019184850448999   9: 0.019184744922415   7: 0.019184065352922   3: 0.019183718396975 

training_6425     1: 0.688363157812024   6: 0.160749068906878   7: 0.019146380937978   0: 0.018845864787472   8: 0.018820028380498   5: 0.018817462760723   2: 0.018815754303560   9: 0.018815645636017   4: 0.018814397372920   3: 0.018812239101931 

training_6426     6: 0.735218930315370   0: 0.178986567150290   3: 0.019645476087343   9: 0.009475487278447   1: 0.009461036179320   7: 0.009449116026549   8: 0.009442792285168   5: 0.009440748649197   4: 0.009439994357904   2: 0.009439851670411 

training_6427     6: 0.464542805276074   0: 0.404529142414668   9: 0.016371887420078   5: 0.016368929535666   4: 0.016365281910202   1: 0.016365164522524   8: 0.016364667630952   7: 0.016364598710820   2: 0.016363863738961   3: 0.016363658840056 

training_6428     1: 0.372299386223885   5: 0.307196612118287   6: 0.244844915165484   0: 0.010822850839841   4: 0.010810668047726   3: 0.010805745695665   2: 0.010805212382531   8: 0.010805142953997   9: 0.010804925455700   7: 0.010804541116883 

training_6430     6: 0.568178108341426   7: 0.218349168508769   1: 0.104749589194646   0: 0.026970880045802   5: 0.013690732975335   4: 0.013621101804550   9: 0.013611529026835   8: 0.013609944345080   2: 0.013609553184861   3: 0.013609392572698 

training_6432     6: 0.751974839677180   9: 0.085489015290658   4: 0.068052176284098   0: 0.013609131133689   1: 0.013528576674584   2: 0.013513713060158   7: 0.013471491143866   5: 0.013462478104934   8: 0.013449455476588   3: 0.013449123154244 

training_6433     0: 0.735263625780738   1: 0.148006547540825   5: 0.014597804904109   6: 0.014593849448174   7: 0.014590325501179   4: 0.014590143357864   2: 0.014589622453876   3: 0.014589555802406   9: 0.014589288888118   8: 0.014589236322712 

training_6434     1: 0.414632792195528   6: 0.315141041811055   4: 0.133692867717792   7: 0.032207812504264   0: 0.030884042837982   5: 0.014734792268483   8: 0.014677988066548   9: 0.014677780251253   2: 0.014675573038652   3: 0.014675309308443 

training_6435     0: 0.620288710794510   9: 0.160933247628558   6: 0.027358063017042   1: 0.027353206173148   5: 0.027349529437525   8: 0.027344413642795   3: 0.027344157130616   7: 0.027343032840669   2: 0.027342841115721   4: 0.027342798219416 

training_6436     6: 0.778498286324562   5: 0.057770866643901   9: 0.036938494652996   2: 0.032218807665096   0: 0.015825360213262   8: 0.015754068290444   7: 0.015751153170096   1: 0.015748042345370   4: 0.015747481887911   3: 0.015747438806362 

training_6437     5: 0.762195956216569   0: 0.098079415447433   8: 0.017474124856228   4: 0.017466285517859   6: 0.017464469306909   1: 0.017464107816512   9: 0.017464096140617   7: 0.017464076099800   2: 0.017463752749524   3: 0.017463715848549 

training_6438     0: 0.520942954030640   5: 0.368342883666977   9: 0.014011642388384   6: 0.013818933740921   1: 0.013816215914422   8: 0.013814285355690   4: 0.013814154984232   2: 0.013813096876121   7: 0.013812976067327   3: 0.013812856975285 

training_6440     5: 0.750586086139001   0: 0.027736637233665   4: 0.027712572703622   6: 0.027710177560603   1: 0.027709604905647   7: 0.027709483712241   8: 0.027709073449141   2: 0.027708904570793   9: 0.027708780783514   3: 0.027708678941774 

training_6441     1: 0.712170076020571   4: 0.088877694154869   5: 0.024872586668999   6: 0.024872475079724   0: 0.024869497618540   7: 0.024867860899737   9: 0.024867808522204   8: 0.024867616478964   2: 0.024867466024306   3: 0.024866918532086 

training_6442     0: 0.668814644019811   1: 0.128098761508990   9: 0.078986359489793   4: 0.017738753314515   6: 0.017737295669186   5: 0.017726644737406   7: 0.017724752880609   8: 0.017724396132633   2: 0.017724215697915   3: 0.017724176549141 

training_6443     7: 0.535047162652468   6: 0.225841526749794   1: 0.029901397710152   0: 0.029894504069144   5: 0.029893553410800   4: 0.029886140443571   9: 0.029885324519758   2: 0.029884522657149   3: 0.029883131529567   8: 0.029882736257595 

training_6445     1: 0.553180365725678   6: 0.252287620123576   2: 0.052531279430817   5: 0.020292588840813   9: 0.020288440964030   0: 0.020286135494686   8: 0.020285083842780   3: 0.020283336588479   4: 0.020282831194258   7: 0.020282317794883 

training_6447     5: 0.828749748521103   0: 0.043506140672680   6: 0.015985527968904   4: 0.015967953990914   8: 0.015966317046389   1: 0.015965580826264   7: 0.015965103332932   9: 0.015964900236252   2: 0.015964373384294   3: 0.015964354020267 

training_6449     1: 0.683987477323274   2: 0.035119277810498   6: 0.035115512711776   0: 0.035114435511060   7: 0.035112276057042   9: 0.035111428878043   5: 0.035111058163924   4: 0.035110223177420   8: 0.035109374108406   3: 0.035108936258558 

training_6450     1: 0.467273569553456   6: 0.381679903852541   8: 0.038638366960150   5: 0.016061453077573   0: 0.016059673749072   2: 0.016058665571287   3: 0.016057203225247   4: 0.016057202869759   9: 0.016057113313227   7: 0.016056847827688 

training_6451     6: 0.769166606401130   0: 0.088176813397425   2: 0.045661019481936   4: 0.013888767224328   8: 0.013869439510941   3: 0.013852905833866   9: 0.013851962498781   1: 0.013845867133297   5: 0.013844066390352   7: 0.013842552127944 

training_6452     9: 0.470349330295482   6: 0.379419368925949   8: 0.018788048149487   1: 0.018779987615969   5: 0.018778141095918   0: 0.018777592931004   3: 0.018777106838746   4: 0.018777013116940   2: 0.018776750973919   7: 0.018776660056586 

training_6453     6: 0.541554001940069   0: 0.334467003989085   1: 0.045041076795018   9: 0.011298721134826   8: 0.011277506445682   5: 0.011273479582243   4: 0.011273055705135   3: 0.011271953211246   2: 0.011271640579414   7: 0.011271560617281 

training_6454     5: 0.607222213190496   7: 0.168609846685564   8: 0.072791897599136   4: 0.021627623810159   6: 0.021625265943943   9: 0.021625181735347   0: 0.021624574431053   1: 0.021624490365143   3: 0.021624472229284   2: 0.021624434009875 

training_6455     5: 0.546142034366673   9: 0.226550231099242   3: 0.085701594044911   4: 0.020232027834209   1: 0.020229278643813   8: 0.020229162362972   0: 0.020229032000114   2: 0.020228967086660   6: 0.020228848198738   7: 0.020228824362667 

training_6456     5: 0.722086827508598   9: 0.092357020576484   6: 0.055012927601175   3: 0.043115090146037   7: 0.014659694705739   4: 0.014597608211595   1: 0.014543806525068   0: 0.014542938958573   2: 0.014542165529555   8: 0.014541920237176 

training_6457     5: 0.436953186958418   3: 0.356751007036780   0: 0.025788765726237   6: 0.025787843231486   1: 0.025787555380216   4: 0.025787023921910   9: 0.025786390715836   8: 0.025786228632385   7: 0.025786046925336   2: 0.025785951471396 

training_6458     4: 0.767454645315915   5: 0.025846940833242   6: 0.025837548927190   0: 0.025837437694186   1: 0.025837412802066   8: 0.025837318257258   3: 0.025837256529258   9: 0.025837247328919   2: 0.025837113566954   7: 0.025837078745013 

training_6459     5: 0.555803427677419   1: 0.212854325685976   4: 0.028924494736095   8: 0.028920459917744   6: 0.028919487815732   0: 0.028919295420112   2: 0.028915035705926   3: 0.028914573480360   9: 0.028914503414543   7: 0.028914396146094 

training_6460     5: 0.432303122938645   9: 0.167229441243225   2: 0.128538637808679   3: 0.125626766065859   6: 0.024384367965804   7: 0.024383820803327   4: 0.024383779255234   0: 0.024383757796600   1: 0.024383367372083   8: 0.024382938750544 

training_6461     0: 0.471933788501942   5: 0.209502235562413   3: 0.153540116350355   9: 0.054016514869348   6: 0.018509087037515   4: 0.018501040148772   1: 0.018499857369400   7: 0.018499849655058   8: 0.018499178740973   2: 0.018498331764224 

training_6463     1: 0.540685884305607   0: 0.176267805513973   6: 0.144322087145602   2: 0.051225437757370   3: 0.036812625355725   9: 0.010143164221220   5: 0.010141420428438   7: 0.010134040346611   4: 0.010134024278452   8: 0.010133510647003 

training_6464     6: 0.494715641498055   0: 0.313696224157502   7: 0.038648899071187   5: 0.021851243474853   9: 0.021850541634681   4: 0.021848913450584   8: 0.021848065515413   1: 0.021847081719760   2: 0.021846864609344   3: 0.021846524868621 

training_6465     0: 0.664426012857831   2: 0.141685648870995   6: 0.084662827303187   5: 0.015620987512661   7: 0.015604432945581   4: 0.015601393628364   9: 0.015600618930103   1: 0.015599859095186   8: 0.015599113145587   3: 0.015599105710506 

training_6466     5: 0.770058471815523   6: 0.084222919277976   1: 0.018236585797533   0: 0.018216533467326   4: 0.018214928759609   8: 0.018210788462728   9: 0.018210068441458   3: 0.018209936627049   2: 0.018209908659823   7: 0.018209858690974 

training_6471     6: 0.332276424892399   1: 0.304821134861199   0: 0.112253335094726   5: 0.088354664374185   8: 0.053479632859283   4: 0.047464785781913   7: 0.028613912355177   9: 0.010913295173779   2: 0.010911481581403   3: 0.010911333025936 

training_6473     1: 0.616753219958274   0: 0.151647385738677   6: 0.149185645141194   7: 0.011784386578186   5: 0.011774782535965   9: 0.011773052180359   4: 0.011771191005360   8: 0.011770335106072   2: 0.011770036405616   3: 0.011769965350298 

training_6474     5: 0.658168952280567   7: 0.162814198623473   4: 0.022378720008543   1: 0.022378576028516   6: 0.022378042729496   0: 0.022377180327655   3: 0.022376765842983   2: 0.022375900378134   8: 0.022375893029393   9: 0.022375770751241 

training_6475     5: 0.825566430879347   6: 0.019383064692455   4: 0.019382258456661   8: 0.019382186746191   0: 0.019381692430322   7: 0.019381499408511   9: 0.019381029238055   1: 0.019380893362984   2: 0.019380522641264   3: 0.019380422144210 

training_6476     4: 0.625420639223752   1: 0.094220970262174   6: 0.094122109179709   5: 0.070177172927633   9: 0.019524660655029   2: 0.019345159027338   7: 0.019330294799737   3: 0.019293079209774   8: 0.019284342931195   0: 0.019281571783660 

training_6477     4: 0.500589471760655   6: 0.299233098580791   2: 0.068922189719263   5: 0.018878509030812   0: 0.018761251710784   3: 0.018733972847106   9: 0.018722193553236   7: 0.018721823487418   1: 0.018719391558861   8: 0.018718097751073 

training_6478     5: 0.772413464868116   1: 0.025288207143639   0: 0.025288041644428   6: 0.025287571190806   4: 0.025287353157130   3: 0.025287198398107   2: 0.025287141933994   8: 0.025287084765707   7: 0.025286993235004   9: 0.025286943663069 

training_6481     0: 0.538795360208576   6: 0.303663651218874   9: 0.021813332483885   1: 0.021441427989894   4: 0.019555538659141   5: 0.018967577281748   3: 0.018954266579707   7: 0.018940742244033   8: 0.018934476027001   2: 0.018933627307141 

training_6483     6: 0.550795774947340   9: 0.242198751788435   1: 0.076169627089788   0: 0.041661559899283   8: 0.014867059135783   7: 0.014861866352602   5: 0.014861708469574   2: 0.014861281076452   3: 0.014861276743705   4: 0.014861094497039 

training_6484     6: 0.531177308989243   0: 0.268444403647379   9: 0.025071094579805   1: 0.025044366036449   7: 0.025044303860038   2: 0.025043846645544   5: 0.025043738769559   4: 0.025043703175623   3: 0.025043634720232   8: 0.025043599576131 

training_6485     4: 0.689039064993031   1: 0.157890679927418   5: 0.019142514197283   8: 0.019132849632566   3: 0.019132791157954   6: 0.019132622029902   0: 0.019132542297403   9: 0.019132381320952   7: 0.019132329762609   2: 0.019132224680883 

training_6486     6: 0.863386266721216   0: 0.027533761005522   5: 0.013740377629167   8: 0.013645240963532   9: 0.013631029486055   1: 0.013613144959733   7: 0.013612710770041   2: 0.013612549673651   4: 0.013612517730924   3: 0.013612401060158 

training_6488     9: 0.451473406135602   5: 0.363629983856194   0: 0.055687477139498   2: 0.018489168044458   1: 0.018467734700196   6: 0.018467360293598   4: 0.018447280356047   7: 0.018446161390086   3: 0.018445842954248   8: 0.018445585130074 

training_6491     5: 0.678673910941035   1: 0.139626610217071   4: 0.022714801259524   6: 0.022714592792312   7: 0.022712481952070   0: 0.022711841908282   8: 0.022711733687720   9: 0.022711416259040   3: 0.022711356115349   2: 0.022711254867597 

training_6492     6: 0.700149223299658   0: 0.145751006766313   1: 0.040691384991805   8: 0.027650078837620   9: 0.014366553666980   5: 0.014287809594115   2: 0.014277530566765   7: 0.014275740559234   4: 0.014275543010924   3: 0.014275128706586 

training_6493     6: 0.791554217292364   8: 0.065825068235072   0: 0.038687791665135   1: 0.036285272901045   7: 0.011291339500747   9: 0.011278714787498   5: 0.011270824499498   4: 0.011269537950030   3: 0.011269281894124   2: 0.011267951274488 

training_6494     6: 0.576282690900556   0: 0.253472340155733   9: 0.059493057454234   5: 0.015822920035350   1: 0.015822528226257   7: 0.015821840552314   8: 0.015821679483941   4: 0.015821260564250   2: 0.015820890528569   3: 0.015820792098795 

training_6495     5: 0.790050137809466   4: 0.023331292184155   8: 0.023327647652399   9: 0.023327329585674   3: 0.023327324320414   2: 0.023327296792031   7: 0.023327295469335   6: 0.023327278699373   0: 0.023327207839449   1: 0.023327189647704 

training_6496     5: 0.784690889337651   4: 0.023926547872592   6: 0.023926165947080   3: 0.023926119964443   1: 0.023923657425512   0: 0.023922725855493   8: 0.023921300653714   7: 0.023921201289985   9: 0.023920707452237   2: 0.023920684201294 

training_6497     1: 0.321326907710967   2: 0.275212960870862   0: 0.216111678615105   5: 0.060102692595278   6: 0.021212095601532   4: 0.021207569476397   9: 0.021206855118329   8: 0.021206707763326   7: 0.021206289373563   3: 0.021206242874641 

training_6498     0: 0.778706161944599   4: 0.058200890832029   5: 0.020393394228447   6: 0.020392819241242   1: 0.020387346587190   9: 0.020384507643450   3: 0.020383780091701   8: 0.020383750398700   2: 0.020383691810692   7: 0.020383657221951 

training_6499     1: 0.762208262166852   5: 0.026425580740231   6: 0.026422156972633   0: 0.026421963262444   4: 0.026421025903237   2: 0.026420444241329   3: 0.026420350338112   9: 0.026420258889310   8: 0.026420023928875   7: 0.026419933556975 

training_65       5: 0.790584936354370   6: 0.023277815272990   4: 0.023269693835255   1: 0.023267152515407   0: 0.023266933666103   8: 0.023266838377025   9: 0.023266773048022   2: 0.023266629772207   3: 0.023266614785695   7: 0.023266612372924 

training_6500     5: 0.630380323934053   0: 0.179067786713130   4: 0.023823761109357   1: 0.023819053880392   6: 0.023818549871407   8: 0.023818326997962   3: 0.023818165567188   2: 0.023818050815716   9: 0.023818032918712   7: 0.023817948192084 

training_6502     6: 0.455591409341949   2: 0.209097318553565   0: 0.177433847286693   7: 0.043924135141108   1: 0.018998531561917   5: 0.018993930465229   4: 0.018992120351499   9: 0.018989906072971   8: 0.018989446686387   3: 0.018989354538680 

training_6503     5: 0.574743633406364   1: 0.212795027318535   9: 0.087602209408062   6: 0.017862284216600   0: 0.017838092663241   4: 0.017832141620786   7: 0.017831990026138   8: 0.017831917279758   2: 0.017831374199465   3: 0.017831329861050 

training_6504     4: 0.727922857996870   6: 0.069901719206311   0: 0.064168573644872   1: 0.019724577033700   5: 0.019718938847458   8: 0.019712811772833   3: 0.019712666176934   2: 0.019712659601265   9: 0.019712608613790   7: 0.019712587105968 

training_6505     5: 0.619122132585744   6: 0.152556120424839   4: 0.028543434597577   0: 0.028540936876812   9: 0.028540112740146   7: 0.028539631408363   8: 0.028539591145606   3: 0.028539425360996   2: 0.028539368657542   1: 0.028539246202375 

training_6506     5: 0.350876974144419   0: 0.248557926235836   1: 0.142281621710421   3: 0.115709982433214   4: 0.023763245438067   6: 0.023762734170758   8: 0.023762016892506   7: 0.023761980006007   2: 0.023761763442961   9: 0.023761755525811 

training_6507     5: 0.417023480464897   3: 0.361491074278137   6: 0.027688188316201   1: 0.027687063404828   0: 0.027686982054239   4: 0.027686860572665   9: 0.027684376535087   8: 0.027684185518546   7: 0.027683941345228   2: 0.027683847510173 

training_6509     5: 0.646299703597492   4: 0.158262348994435   1: 0.024432943976049   0: 0.024431549407628   6: 0.024430318060648   8: 0.024429466214718   3: 0.024428929513703   2: 0.024428434126938   7: 0.024428166347802   9: 0.024428139760587 

training_6511     6: 0.712595728950784   3: 0.126032951979790   1: 0.040417998692875   0: 0.017280478257089   5: 0.017280182256197   7: 0.017279276818241   9: 0.017278549761808   4: 0.017278494845745   8: 0.017278254978931   2: 0.017278083458539 

training_6514     5: 0.553583996811352   8: 0.256860655943834   3: 0.023695093748941   4: 0.023694931536512   0: 0.023694541223432   6: 0.023694306401142   1: 0.023694141769176   2: 0.023694136868901   7: 0.023694120878871   9: 0.023694074817839 

training_6515     6: 0.636730280411204   0: 0.227571964116353   8: 0.033895323303340   1: 0.014545431654729   5: 0.014543694735192   4: 0.014543349805841   9: 0.014542928621443   7: 0.014542607192244   2: 0.014542223030195   3: 0.014542197129459 

training_6520     4: 0.754224883118776   5: 0.027314243994994   0: 0.027310001832189   8: 0.027307510978291   9: 0.027307440507986   3: 0.027307299262646   2: 0.027307245307345   1: 0.027307159148605   7: 0.027307153362235   6: 0.027307062486931 

training_6521     0: 0.788787175993731   4: 0.023481339195749   5: 0.023475015765180   6: 0.023474560858637   9: 0.023465075665542   8: 0.023464450706656   1: 0.023464004738529   7: 0.023463997347356   2: 0.023462413702538   3: 0.023461966026082 

training_6522     5: 0.722881128024036   3: 0.113128450652416   0: 0.020512683670534   4: 0.020502172464942   6: 0.020496510237766   9: 0.020496090505020   8: 0.020495850915205   1: 0.020495747124800   7: 0.020495719909391   2: 0.020495646495890 

training_6523     5: 0.812954299601987   4: 0.020785776280653   6: 0.020784086940942   1: 0.020782451579863   0: 0.020782407661523   8: 0.020782303910460   2: 0.020782290753910   3: 0.020782198197807   9: 0.020782111220557   7: 0.020782073852297 

training_6524     5: 0.627067050755972   4: 0.221868857935806   6: 0.018897607294596   9: 0.018885209565786   1: 0.018882696848356   7: 0.018880242008648   0: 0.018880004157267   2: 0.018879539893306   3: 0.018879524346925   8: 0.018879267193338 

training_6525     0: 0.778028183740058   6: 0.062071189452836   5: 0.020006866195411   1: 0.019990696208551   4: 0.019986080859734   2: 0.019983826426846   3: 0.019983707768568   9: 0.019983493140466   7: 0.019983240179021   8: 0.019982716028510 

training_6527     1: 0.746104933389450   2: 0.068305761298510   5: 0.023205358363323   4: 0.023200711927905   0: 0.023200080430591   6: 0.023198879469859   9: 0.023196495325223   8: 0.023196350161977   7: 0.023195862104108   3: 0.023195567529055 

training_6528     5: 0.769290198399890   3: 0.025635060197679   4: 0.025634629194391   8: 0.025634358227081   0: 0.025634354380467   6: 0.025634352087692   2: 0.025634277017957   1: 0.025634274032800   7: 0.025634262601707   9: 0.025634233860336 

training_6529     5: 0.835947974417817   6: 0.018231625543939   4: 0.018229325921512   1: 0.018228317044730   0: 0.018227969756577   9: 0.018227537024920   8: 0.018227276990711   7: 0.018226771286825   2: 0.018226619498422   3: 0.018226582514547 

training_6531     6: 0.671559120493235   0: 0.223210135364184   1: 0.032418707522160   9: 0.021731251520901   2: 0.008545031328676   5: 0.008510733022671   7: 0.008509828315861   8: 0.008505668485201   4: 0.008504923332707   3: 0.008504600614403 

training_6532     5: 0.761013448232111   0: 0.073573320894802   6: 0.020688098201340   1: 0.020679322741278   9: 0.020675039842052   2: 0.020674720672325   3: 0.020674196188938   7: 0.020674147398778   4: 0.020673981696446   8: 0.020673724131931 

training_6533     5: 0.758627286055943   4: 0.026822127931415   6: 0.026819131824560   0: 0.026818958965204   1: 0.026818955538420   3: 0.026818828279963   9: 0.026818749623569   8: 0.026818727020264   2: 0.026818653457773   7: 0.026818581302889 

training_6534     5: 0.595398948589588   3: 0.203303953217871   4: 0.025167284314131   1: 0.025161951253995   0: 0.025161803166840   8: 0.025161428129385   6: 0.025161306840304   9: 0.025161207345441   2: 0.025161171747697   7: 0.025160945394748 

training_6535     6: 0.567378776012907   3: 0.190829211782767   0: 0.111692711660916   8: 0.036454303169149   1: 0.015617794343795   5: 0.015612698277746   2: 0.015606039264291   4: 0.015603863383867   9: 0.015602512373669   7: 0.015602089730894 

training_6537     9: 0.634124805806083   1: 0.152308658675684   5: 0.041252806987396   0: 0.024637879263361   7: 0.024618836187078   8: 0.024617457764014   6: 0.024617377266628   4: 0.024613319948094   2: 0.024604906769434   3: 0.024603951332227 

training_6538     8: 0.741973980089818   1: 0.072050101625659   0: 0.023253487146409   6: 0.023252685619667   5: 0.023250636163939   9: 0.023247578146798   4: 0.023244759514881   2: 0.023244691386852   3: 0.023241263933583   7: 0.023240816372396 

training_6539     5: 0.792931744560652   0: 0.058490148862878   3: 0.018641024441460   6: 0.018567530433965   1: 0.018563365875096   9: 0.018561672254744   4: 0.018561365548874   7: 0.018561242955395   8: 0.018560995903274   2: 0.018560909163663 

training_6540     5: 0.656497900719786   1: 0.102762052674984   3: 0.088339260730123   4: 0.021779909822315   8: 0.021770471327983   6: 0.021770171877018   0: 0.021770170377008   9: 0.021770107575695   2: 0.021769981970446   7: 0.021769972924641 

training_6541     6: 0.772136246354596   1: 0.084096754099209   3: 0.068634201704457   8: 0.019327466840322   5: 0.009332751215089   0: 0.009325140210042   4: 0.009287691448608   7: 0.009286914220216   2: 0.009286832748540   9: 0.009286001158921 

training_6542     5: 0.308862620953680   6: 0.281330429728707   8: 0.198325775825580   4: 0.030214979179605   0: 0.030211547660323   1: 0.030211381016132   2: 0.030211241981846   3: 0.030210823768524   9: 0.030210796014691   7: 0.030210403870912 

training_6543     8: 0.803258095789177   2: 0.045641519126272   6: 0.043099081510361   0: 0.015456167171557   1: 0.015435808502695   9: 0.015422520848932   5: 0.015422255726996   3: 0.015421621671877   7: 0.015421595297147   4: 0.015421334354987 

training_6546     0: 0.418713580038031   6: 0.284889667059995   9: 0.112770577705857   1: 0.075082777965906   5: 0.029747806069607   2: 0.015760538223785   7: 0.015759772167152   8: 0.015758564054781   3: 0.015758457103821   4: 0.015758259611065 

training_6547     6: 0.590664960583070   5: 0.198505353556568   8: 0.095997310049577   4: 0.033533214317982   9: 0.013555651036498   1: 0.013553068437561   0: 0.013548703572111   2: 0.013547365433389   7: 0.013547194932285   3: 0.013547178080958 

training_6549     4: 0.778009198479919   5: 0.024672619973285   6: 0.024667363607551   8: 0.024665115749548   0: 0.024665025485260   2: 0.024664271497473   9: 0.024664240293972   7: 0.024664084667203   1: 0.024664055507324   3: 0.024664024738465 

training_6551     5: 0.814654669264059   4: 0.020598328542214   0: 0.020593683128482   6: 0.020593552592047   8: 0.020593465395828   9: 0.020593351105827   3: 0.020593271976410   1: 0.020593237966661   2: 0.020593233781444   7: 0.020593206247027 

training_6552     4: 0.777398596839903   5: 0.024739230902124   8: 0.024732936711218   0: 0.024732859256061   3: 0.024732816378740   9: 0.024732773433031   2: 0.024732732996932   1: 0.024732701042311   6: 0.024732700880518   7: 0.024732651559163 

training_6556     1: 0.577234588262262   0: 0.228792293760320   6: 0.024270440699958   5: 0.024252429214906   8: 0.024244491921870   9: 0.024242544433377   4: 0.024242385612848   7: 0.024240947601078   3: 0.024240241810288   2: 0.024239636683093 

training_6557     6: 0.654488886372788   5: 0.179427851125759   9: 0.049409283894447   0: 0.016682924344144   1: 0.016667411103625   8: 0.016665317710803   4: 0.016665007406331   7: 0.016664707116134   2: 0.016664357183727   3: 0.016664253742241 

training_6559     6: 0.430698995621139   4: 0.423030684429227   5: 0.018289485669505   1: 0.018285413861089   2: 0.018285341923961   0: 0.018284586468409   9: 0.018282822303261   7: 0.018280960235398   3: 0.018280902397211   8: 0.018280807090801 

training_6561     6: 0.438353304598372   5: 0.210903460540510   7: 0.197723425152843   4: 0.042576475363334   8: 0.018416292878892   0: 0.018408525138662   3: 0.018406651491022   9: 0.018405685888687   2: 0.018404113649132   1: 0.018402065298546 

training_6562     0: 0.376919259469616   5: 0.351460855799024   1: 0.152351146154797   6: 0.017067389379422   2: 0.017049021605592   9: 0.017035193089989   7: 0.017034780003913   4: 0.017027726102793   8: 0.017027693800914   3: 0.017026934593942 

training_6568     5: 0.566089919417116   6: 0.244514226791394   0: 0.023675457421164   1: 0.023675069325712   3: 0.023674659991589   4: 0.023674565477220   8: 0.023674375691899   7: 0.023674142718991   2: 0.023673872446063   9: 0.023673710718852 

training_6572     5: 0.664967666914893   0: 0.132440975022133   3: 0.025324459131657   4: 0.025324188640906   8: 0.025323863924007   6: 0.025323857517846   2: 0.025323765925992   1: 0.025323761867366   7: 0.025323748221355   9: 0.025323712833846 

training_6573     4: 0.818099532191207   5: 0.020217649026159   6: 0.020211460682234   2: 0.020210753826308   9: 0.020210626158187   3: 0.020210235946668   0: 0.020210033447914   1: 0.020209955069191   8: 0.020209900169057   7: 0.020209853483075 

training_6575     5: 0.577092174730664   2: 0.138192845597705   3: 0.122640772300177   4: 0.023153773872783   6: 0.023153545748534   8: 0.023153477101415   7: 0.023153442888829   0: 0.023153409654222   1: 0.023153319574320   9: 0.023153238531352 

training_6576     6: 0.728553184033425   0: 0.089049472464544   4: 0.073792628959712   8: 0.041618990912389   3: 0.011536007128893   1: 0.011102289959578   5: 0.011093078087213   2: 0.011084974936316   9: 0.011084742049857   7: 0.011084631468072 

training_6577     5: 0.451264042214804   9: 0.198408378412086   0: 0.170098976962594   8: 0.059733986494811   3: 0.020093941862444   2: 0.020081889343530   7: 0.020081436713050   6: 0.020080294397889   1: 0.020078577111665   4: 0.020078476487126 

training_6578     6: 0.766830741197223   9: 0.079184167727214   7: 0.039621549049427   0: 0.016347662151348   1: 0.016347297990634   8: 0.016337847807225   4: 0.016333124077810   5: 0.016332950159868   2: 0.016332538071093   3: 0.016332121768159 

training_6581     5: 0.446753339048469   6: 0.363138608272506   8: 0.085061374277827   0: 0.029266630969224   1: 0.012633185566693   9: 0.012632206459129   4: 0.012629321652720   7: 0.012629040527605   2: 0.012628250098849   3: 0.012628043126979 

training_6583     1: 0.550639432622700   6: 0.238415456972791   2: 0.072490763194407   5: 0.019789256421743   4: 0.019782023931403   0: 0.019778832820848   9: 0.019777554829505   8: 0.019776988063818   3: 0.019775077700061   7: 0.019774613442725 

training_6584     5: 0.433813517838388   3: 0.314333674315034   4: 0.031492805221980   6: 0.031481047465495   1: 0.031480780441926   0: 0.031480333423961   8: 0.031479665864381   9: 0.031479590027578   2: 0.031479364662324   7: 0.031479220738932 

training_6585     6: 0.787228688063408   0: 0.080501266732123   4: 0.034440076685950   5: 0.013976674086191   1: 0.013976207752113   9: 0.013975900453906   8: 0.013975858726976   3: 0.013975224377098   7: 0.013975112849726   2: 0.013974990272508 

training_6586     5: 0.754677820467642   1: 0.059122978718843   0: 0.023334895108078   6: 0.023274759674678   2: 0.023269750166629   8: 0.023265737987527   4: 0.023264702584342   9: 0.023264057204341   3: 0.023262656065988   7: 0.023262642021931 

training_6588     6: 0.693149812122713   5: 0.119713572235639   8: 0.088246336837044   1: 0.037662759597345   9: 0.010217194464103   0: 0.010208737849491   7: 0.010200967771464   2: 0.010200775128609   3: 0.010199977356407   4: 0.010199866637186 

training_6590     5: 0.564818247408126   6: 0.257884232252898   9: 0.022177816702044   3: 0.022162019959711   0: 0.022161410313617   1: 0.022160984414244   4: 0.022159263981058   8: 0.022159194900525   7: 0.022158538712433   2: 0.022158291355342 

training_6591     5: 0.756444844681590   4: 0.054450950751084   1: 0.050598778125123   9: 0.043301115199393   0: 0.015868707482138   6: 0.015867567089234   8: 0.015867146011528   2: 0.015867036573317   3: 0.015866946876686   7: 0.015866907209907 

training_6592     5: 0.721840969959386   0: 0.077776412269690   3: 0.050321879261460   7: 0.046254398837888   4: 0.037743938704681   6: 0.013219767541188   1: 0.013212490740232   9: 0.013210911871390   2: 0.013209954985330   8: 0.013209275828754 

training_6593     6: 0.758504316004660   0: 0.147585189344308   5: 0.011741673467942   9: 0.011738951890689   1: 0.011738894233884   7: 0.011738336537265   4: 0.011738292034399   8: 0.011738215612218   3: 0.011738161049874   2: 0.011737969824762 

training_6594     5: 0.773791913571183   4: 0.061147837315753   6: 0.020644206238407   9: 0.020634546001944   0: 0.020632897640428   1: 0.020630419872575   7: 0.020629698732588   3: 0.020629585381360   8: 0.020629552499438   2: 0.020629342746324 

training_6595     6: 0.725937578287862   7: 0.064683749870403   0: 0.053143629127222   8: 0.047367231104919   3: 0.038369054646520   5: 0.014101194641083   1: 0.014100734652849   9: 0.014099277401608   4: 0.014098893807420   2: 0.014098656460115 

training_6596     6: 0.798159531120747   5: 0.022429609411931   4: 0.022427729431240   8: 0.022427720997848   9: 0.022426949126713   0: 0.022426364091028   1: 0.022425778721796   7: 0.022425763453334   2: 0.022425361644790   3: 0.022425192000573 

training_6597     5: 0.806919420958592   6: 0.021456539880422   0: 0.021455421064720   4: 0.021454063036131   1: 0.021453449835153   7: 0.021452511661673   9: 0.021452376146600   8: 0.021452258909189   2: 0.021451994188805   3: 0.021451964318716 

training_6598     6: 0.730484611864717   0: 0.134615038348561   5: 0.037314895247320   1: 0.013943838458076   9: 0.013943703538003   8: 0.013941274900853   4: 0.013939648276400   2: 0.013939081586396   7: 0.013938975406964   3: 0.013938932372708 

training_66       5: 0.635075361667664   3: 0.181333167747822   6: 0.064028373247862   4: 0.017081803256914   2: 0.017081023988782   8: 0.017080763914543   0: 0.017080264789538   9: 0.017079961882925   1: 0.017079747049615   7: 0.017079532454335 

training_6601     5: 0.799932215419578   4: 0.022232516444722   6: 0.022232084118946   8: 0.022230575789670   1: 0.022229131231285   9: 0.022229078224782   0: 0.022228984441726   2: 0.022228602633451   7: 0.022228450684041   3: 0.022228361011799 

training_6603     6: 0.774978977520261   0: 0.086567536675664   3: 0.046847471509640   1: 0.044915993200628   5: 0.007794163138637   7: 0.007789979631132   4: 0.007777736175340   9: 0.007777460446077   8: 0.007775505820751   2: 0.007775175881870 

training_6604     6: 0.403062565916353   0: 0.317725187380890   2: 0.120772689872289   5: 0.054930912703917   1: 0.017255821151977   9: 0.017251222196820   4: 0.017250882812103   8: 0.017250706007357   7: 0.017250045085412   3: 0.017249966872881 

training_6606     6: 0.734885752372765   9: 0.148831385966996   0: 0.027861764219640   3: 0.018722254677736   8: 0.011988951447681   4: 0.011563065226636   1: 0.011546220190116   5: 0.011534570403431   2: 0.011533386431318   7: 0.011532649063682 

training_6607     5: 0.732551298189833   6: 0.029723726330513   0: 0.029717689569592   2: 0.029716179837324   1: 0.029716035514362   7: 0.029715623115123   4: 0.029715126179896   9: 0.029715122623337   3: 0.029714618133995   8: 0.029714580506024 

training_6609     4: 0.519452698296014   3: 0.282522718923805   5: 0.024763748794803   6: 0.024755575084674   0: 0.024751850141279   8: 0.024750985366730   7: 0.024750872561136   9: 0.024750661710624   1: 0.024750554862754   2: 0.024750334258180 

training_6611     5: 0.707672649013887   6: 0.032493807314470   0: 0.032481866974762   4: 0.032481052594294   7: 0.032479554969907   8: 0.032478935507535   9: 0.032478654194624   1: 0.032478213208779   3: 0.032477842532935   2: 0.032477423688807 

training_6612     5: 0.760769275505951   8: 0.092526203833738   9: 0.018343069992008   6: 0.018339493442144   1: 0.018339445695886   0: 0.018338317115995   4: 0.018336811411531   2: 0.018336162001752   7: 0.018335661051554   3: 0.018335559949441 

training_6616     5: 0.550941745202231   6: 0.228647675470800   3: 0.084233769884539   1: 0.019457357573596   0: 0.019455720881961   4: 0.019453516498795   8: 0.019453181827680   2: 0.019452617181888   9: 0.019452281278924   7: 0.019452134199586 

training_6619     6: 0.576387921005749   9: 0.274081758938802   1: 0.018833277816059   0: 0.018749752210435   8: 0.018707109435121   2: 0.018680433950073   4: 0.018658350166420   5: 0.018645966677151   7: 0.018628327778272   3: 0.018627102021918 

training_6620     5: 0.556384718343084   3: 0.247937655457629   4: 0.024465820515795   0: 0.024459788500219   6: 0.024459197916658   8: 0.024458946713339   9: 0.024458701321756   1: 0.024458428479103   2: 0.024458402186673   7: 0.024458340565744 

training_6621     6: 0.795132033368575   0: 0.078042323930973   9: 0.015854625401209   5: 0.015854033956890   7: 0.015853451728538   1: 0.015853174012106   4: 0.015852808660372   8: 0.015852557576194   2: 0.015852520893713   3: 0.015852470471430 

training_6622     6: 0.411596765671158   4: 0.326985559664265   1: 0.079033031071908   9: 0.077147636060142   0: 0.035767870200700   5: 0.013900789595377   8: 0.013892938820977   3: 0.013892058768180   7: 0.013891972476469   2: 0.013891377670824 

training_6623     6: 0.615772546198424   0: 0.239313273518494   8: 0.018123267179881   5: 0.018116166030993   1: 0.018113057323862   7: 0.018112682580282   3: 0.018112445918604   4: 0.018112375110476   9: 0.018112124494723   2: 0.018112061644261 

training_6626     6: 0.717996359081912   7: 0.104102314582833   8: 0.044500397312580   5: 0.019060532293059   0: 0.019058100177313   1: 0.019057141639548   2: 0.019056731779679   4: 0.019056341945168   3: 0.019056208555522   9: 0.019055872632386 

training_6629     5: 0.643918312978313   1: 0.166840344936462   6: 0.023658050088588   0: 0.023655573512158   3: 0.023654974278028   2: 0.023654909559754   7: 0.023654617700187   4: 0.023654600083974   9: 0.023654359840476   8: 0.023654257022059 

training_6630     1: 0.662879313501475   2: 0.158231572960145   3: 0.053274778278890   6: 0.017960930568865   0: 0.017946242564411   5: 0.017942419058866   9: 0.017941566094148   4: 0.017941241441130   8: 0.017941075271653   7: 0.017940860260418 

training_6632     6: 0.533276231676407   3: 0.283012929188879   0: 0.069519090230781   8: 0.016330143459867   7: 0.016310975757392   1: 0.016310909559357   5: 0.016310625937069   9: 0.016309826241084   2: 0.016309677754812   4: 0.016309590194351 

training_6635     5: 0.781143161980114   1: 0.050792126201016   3: 0.037603991684591   2: 0.018655379137240   9: 0.018643831259053   6: 0.018638449833052   4: 0.018632084339535   8: 0.018631574869189   0: 0.018630916776156   7: 0.018628483920053 

training_6636     5: 0.597769166227474   1: 0.125454555376647   3: 0.115228941956537   8: 0.052095877702919   4: 0.018246534960178   2: 0.018242003580548   6: 0.018241411315423   0: 0.018241120545368   9: 0.018240698115969   7: 0.018239690218936 

training_6637     6: 0.798159528206787   5: 0.022429609581022   4: 0.022427729440277   8: 0.022427723475065   9: 0.022426949355349   0: 0.022426364108266   1: 0.022425778726129   7: 0.022425763457486   2: 0.022425361647233   3: 0.022425192002384 

training_6638     6: 0.396394426676237   8: 0.295063777076206   0: 0.189788155167691   5: 0.016970390174387   1: 0.016967109161524   4: 0.016966848194925   2: 0.016964273446029   7: 0.016961933673408   9: 0.016961933561713   3: 0.016961152867880 

training_6639     6: 0.523800262050377   1: 0.317324230897382   0: 0.052624428092973   7: 0.031374991513238   9: 0.021089481284817   4: 0.010787568233114   8: 0.010759203897876   5: 0.010748906146709   3: 0.010746953889464   2: 0.010743973994050 

training_6641     5: 0.750284999979154   0: 0.076154995181684   4: 0.021700065462345   1: 0.021695187850951   6: 0.021694776300351   8: 0.021694297660920   7: 0.021694033129794   9: 0.021693975544034   3: 0.021693854312921   2: 0.021693814577847 

training_6642     5: 0.765326227758595   4: 0.026079030893712   0: 0.026074684210955   3: 0.026074675384745   2: 0.026074417141335   8: 0.026074364781887   9: 0.026074248455043   7: 0.026074166920249   1: 0.026074117445501   6: 0.026074067007978 

training_6647     5: 0.789336917299764   0: 0.023407956007055   3: 0.023407212751113   4: 0.023407114498331   1: 0.023407016327097   6: 0.023406901693885   2: 0.023406759519181   7: 0.023406757813923   8: 0.023406721753080   9: 0.023406642336572 

training_6650     2: 0.617452126577346   6: 0.171015799717340   9: 0.026444083157857   5: 0.026443398192961   0: 0.026441628046493   4: 0.026441477490870   1: 0.026441331162943   8: 0.026440174181645   7: 0.026440030063931   3: 0.026439951408613 

training_6652     6: 0.707033197050297   8: 0.113203588295315   9: 0.058190324139918   2: 0.036147159536155   1: 0.014243252938374   0: 0.014238449407980   3: 0.014237497244475   5: 0.014235769392043   7: 0.014235534022085   4: 0.014235227973357 

training_6653     5: 0.796628980975269   1: 0.057216682902349   7: 0.034203263435949   0: 0.033292180277088   4: 0.013113074961463   8: 0.013111889136643   2: 0.013108946846492   6: 0.013108832373064   9: 0.013108282618176   3: 0.013107866473506 

training_6654     5: 0.739364497678286   1: 0.028975974744570   6: 0.028960686023741   0: 0.028959183193456   4: 0.028956948399806   8: 0.028956932734217   2: 0.028956752050529   9: 0.028956377921962   3: 0.028956368368557   7: 0.028956278884875 

training_6655     5: 0.735617837925482   4: 0.090844904575315   1: 0.021731127036623   0: 0.021709979830677   2: 0.021689073369399   6: 0.021688808377146   9: 0.021683601723472   8: 0.021679365462242   3: 0.021677838889577   7: 0.021677462810068 

training_6656     6: 0.473748858304273   0: 0.198817291610049   2: 0.139479075991221   7: 0.098497451965208   9: 0.035404525887563   1: 0.015072104592218   8: 0.011964238824394   5: 0.009016937507517   4: 0.009000612441314   3: 0.008998902876242 

training_6657     6: 0.786445282435574   0: 0.083442498443220   8: 0.037891351403062   7: 0.026393107561621   9: 0.024245655094357   5: 0.009161593821980   1: 0.008204429132809   3: 0.008074930485197   4: 0.008072101442883   2: 0.008069050179297 

training_6658     1: 0.407716131983284   6: 0.364226433744355   0: 0.095750479480747   4: 0.029425617228360   8: 0.028455847289594   2: 0.015231402615592   5: 0.014807544297556   9: 0.014798287141369   7: 0.014794650773203   3: 0.014793605445940 

training_6659     5: 0.791280534043442   6: 0.023201527258818   1: 0.023197987410893   0: 0.023193729968887   8: 0.023189901747855   7: 0.023187506467270   2: 0.023187455966130   4: 0.023187411302424   9: 0.023187170580744   3: 0.023186775253537 

training_6660     2: 0.613990602840182   6: 0.212430455314658   0: 0.056174470465141   8: 0.016777454299858   5: 0.016774349006569   3: 0.016774162811166   1: 0.016770213237784   9: 0.016770160331987   4: 0.016769070419044   7: 0.016769061273611 

training_6661     5: 0.760062579450882   6: 0.026660822928116   0: 0.026660230059986   1: 0.026660140554768   9: 0.026659986158248   8: 0.026659468900976   2: 0.026659266582738   3: 0.026659191428999   7: 0.026659179052720   4: 0.026659134882567 

training_6665     1: 0.450069038843321   6: 0.236588133862084   0: 0.199751478637017   2: 0.041616146655340   3: 0.019442870036390   9: 0.013951707904670   5: 0.009677717841122   7: 0.009636784431217   8: 0.009633141017468   4: 0.009632980771370 

training_6666     0: 0.764729232670229   1: 0.026151061374846   6: 0.026150082885125   5: 0.026139691649235   7: 0.026139555244747   9: 0.026138512431037   2: 0.026138329778351   8: 0.026138158950844   4: 0.026137752377626   3: 0.026137622637961 

training_6668     4: 0.788266344354719   5: 0.023530465579303   8: 0.023525589173856   9: 0.023525482876537   0: 0.023525465116362   3: 0.023525382072197   2: 0.023525371582777   1: 0.023525338862279   6: 0.023525287883660   7: 0.023525272498310 

training_6669     4: 0.644833330383054   9: 0.145630421587552   5: 0.026202097052142   0: 0.026192324136924   1: 0.026192106963695   8: 0.026191344185708   6: 0.026190731805960   2: 0.026189433286187   3: 0.026189112706131   7: 0.026189097892647 

training_6670     5: 0.705381633385869   1: 0.103118946898947   0: 0.072040804132880   4: 0.017072864918390   6: 0.017066259652919   7: 0.017065250482841   2: 0.017064107993913   9: 0.017063750726219   3: 0.017063199129029   8: 0.017063182678993 

training_6672     5: 0.828110645064653   4: 0.019102815119233   6: 0.019098689223867   0: 0.019098573294256   8: 0.019098492436409   7: 0.019098236747029   1: 0.019098225352906   9: 0.019098149905438   3: 0.019098093386330   2: 0.019098079469881 

training_6673     5: 0.435810123431721   6: 0.369592516682819   3: 0.024325637128525   4: 0.024325273217285   8: 0.024324561763801   0: 0.024324540095917   2: 0.024324381021241   1: 0.024324365617068   7: 0.024324333011636   9: 0.024324268029987 

training_6674     5: 0.720211324923012   0: 0.121015385921415   1: 0.019859004510297   6: 0.019849441572410   4: 0.019845427299536   9: 0.019845394101747   8: 0.019843928334288   7: 0.019843825102837   2: 0.019843333054589   3: 0.019842935179869 

training_6675     1: 0.699057280845209   5: 0.033754908079885   4: 0.033620851969660   8: 0.033376872671799   7: 0.033367879824201   2: 0.033366251559715   0: 0.033364806890888   3: 0.033364605587442   6: 0.033363569209161   9: 0.033362973362040 

training_6677     6: 0.702059848152625   1: 0.173292151914164   7: 0.015588667012777   0: 0.015582253608585   2: 0.015580610335073   5: 0.015579827981490   8: 0.015579427639927   9: 0.015579168428313   3: 0.015579050820189   4: 0.015578994106857 

training_6679     4: 0.782778231767001   5: 0.024140410804366   8: 0.024135337296008   3: 0.024135220707965   0: 0.024135197353397   9: 0.024135165391076   2: 0.024135147441360   6: 0.024135104052007   1: 0.024135099314927   7: 0.024135085871892 

training_6680     5: 0.741479838081001   1: 0.085960551960251   0: 0.021587822994006   6: 0.021571647924430   4: 0.021569199091978   8: 0.021568386924459   3: 0.021566322236848   7: 0.021566196716672   9: 0.021565072420902   2: 0.021564961649453 

training_6681     4: 0.755017331183150   1: 0.062287648343017   8: 0.022853458048978   5: 0.022839528270493   7: 0.022836607256188   6: 0.022834076699710   0: 0.022833248362493   3: 0.022832935320034   2: 0.022832589619192   9: 0.022832576896746 

training_6682     0: 0.686733266711994   6: 0.157989355126722   5: 0.019413296250157   1: 0.019413226567301   4: 0.019410085689767   9: 0.019408569003814   3: 0.019408374005196   2: 0.019408356460054   8: 0.019407849994179   7: 0.019407620190815 

training_6683     5: 0.671340771754925   3: 0.132829479758496   4: 0.024480710748605   2: 0.024479220976825   0: 0.024479008984019   6: 0.024478678025787   1: 0.024478453037340   8: 0.024477908952094   7: 0.024477902843425   9: 0.024477864918485 

training_6684     5: 0.773485199070048   1: 0.025169155680641   6: 0.025168784997003   0: 0.025168726015011   3: 0.025168671684968   4: 0.025168469505425   8: 0.025167802568542   7: 0.025167790474553   2: 0.025167727702673   9: 0.025167672301136 

training_6685     5: 0.665512759825898   4: 0.146434487176575   0: 0.023507242704822   2: 0.023507011128926   3: 0.023506885269248   9: 0.023506581212225   6: 0.023506489467331   1: 0.023506350452202   8: 0.023506098815567   7: 0.023506093947206 

training_6686     5: 0.621936518136943   0: 0.190221340298869   3: 0.023480817548135   4: 0.023480738956330   6: 0.023480607434826   1: 0.023480497915993   8: 0.023479963905031   2: 0.023479930287476   7: 0.023479888245214   9: 0.023479697271184 

training_6687     5: 0.768317943601059   8: 0.066989847324881   2: 0.020586863146209   1: 0.020586730962139   4: 0.020586618737329   6: 0.020586552224623   0: 0.020586468221252   9: 0.020586459483810   3: 0.020586348463283   7: 0.020586167835415 

training_6689     1: 0.516783872323936   5: 0.318893764825122   9: 0.044644473869703   2: 0.022657482686545   3: 0.022045902752601   6: 0.020236587594848   0: 0.013993196206881   4: 0.013627530418211   8: 0.013560416771376   7: 0.013556772550777 

training_6694     2: 0.555531057036920   4: 0.259529271364614   1: 0.023140261908067   6: 0.023127582966301   0: 0.023124724719581   5: 0.023119449906858   9: 0.023108481008233   7: 0.023106929143902   8: 0.023106204159857   3: 0.023106037785667 

training_6695     4: 0.471150960864530   1: 0.298667211395230   9: 0.077549785086207   5: 0.021811053008071   0: 0.021806071903487   6: 0.021804256567815   2: 0.021803190132386   8: 0.021802700704001   7: 0.021802557390176   3: 0.021802212948097 

training_6696     4: 0.716112202002535   5: 0.031554126264801   1: 0.031542093002578   6: 0.031542066042333   3: 0.031541870633026   2: 0.031541696260095   7: 0.031541634545568   0: 0.031541543411800   8: 0.031541475607617   9: 0.031541292229647 

training_6697     0: 0.749910928440609   4: 0.065613247110540   1: 0.023063096946473   8: 0.023062038627747   5: 0.023061208979362   6: 0.023059081447372   2: 0.023057742410298   3: 0.023057701104798   9: 0.023057638698664   7: 0.023057316234137 

training_6699     6: 0.486920105979534   5: 0.269733501588432   1: 0.050447743305074   0: 0.045907033450964   7: 0.045736113872732   3: 0.044359514262165   9: 0.014227068857430   4: 0.014223136700948   2: 0.014223047352523   8: 0.014222734630197 

training_6701     4: 0.755473586958500   5: 0.027174853426347   0: 0.027169115963248   8: 0.027169082659736   6: 0.027168934820672   9: 0.027168933252293   3: 0.027168912423107   2: 0.027168895926476   1: 0.027168883277328   7: 0.027168801292293 

training_6702     1: 0.775617039223292   3: 0.055767625596915   6: 0.021091358158637   5: 0.021078329421401   9: 0.021076997317489   0: 0.021075802525437   8: 0.021074390941699   4: 0.021073174383809   7: 0.021072712240892   2: 0.021072570190429 

training_6705     5: 0.776853301831768   6: 0.024795379365184   0: 0.024794559658029   3: 0.024794365925919   4: 0.024794026387444   8: 0.024793757364493   9: 0.024793669203078   2: 0.024793654364718   1: 0.024793649274300   7: 0.024793636625066 

training_6707     0: 0.601029778174123   1: 0.265154223270070   7: 0.044688790524038   6: 0.012761835014401   9: 0.012733343179566   5: 0.012727380623801   8: 0.012726605319036   4: 0.012726194846507   2: 0.012726140860326   3: 0.012725708188132 

training_6708     6: 0.571422307268017   5: 0.226455431710265   8: 0.079533403040111   0: 0.040542916977462   4: 0.028439318472593   1: 0.010755735165401   9: 0.010716843560480   7: 0.010713678536401   2: 0.010710873020730   3: 0.010709492248540 

training_6709     5: 0.728823299527678   7: 0.097729014405313   1: 0.021682378881306   4: 0.021681703363257   3: 0.021680992695634   6: 0.021680739574494   2: 0.021680604113603   0: 0.021680466452544   8: 0.021680422853216   9: 0.021680378132955 

training_6710     0: 0.600882330928011   7: 0.126035584714493   9: 0.077563567699767   4: 0.068033679947839   1: 0.021249056354823   5: 0.021248920501809   6: 0.021247938696653   2: 0.021246623305113   8: 0.021246228999966   3: 0.021246068851526 

training_6711     4: 0.811416181510039   5: 0.020958964335750   1: 0.020954000311260   0: 0.020953220295277   6: 0.020953164580121   8: 0.020953012188543   3: 0.020952997641110   9: 0.020952961707832   2: 0.020952784256856   7: 0.020952713173210 

training_6712     6: 0.441347338589199   5: 0.349895942382904   8: 0.074027729188074   7: 0.038345584155354   3: 0.016076667547757   0: 0.016067821305246   2: 0.016065174419966   1: 0.016060007844182   9: 0.016057628398786   4: 0.016056106168533 

training_6713     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_6714     9: 0.417208339704965   6: 0.366554110688058   5: 0.045138868599057   1: 0.038705421701456   2: 0.022069511629249   0: 0.022067605147636   3: 0.022064475330305   4: 0.022064220844983   7: 0.022063917855787   8: 0.022063528498503 

training_6716     6: 0.831367179964621   1: 0.056580182616262   8: 0.022618683923283   7: 0.017065373257231   3: 0.016875349026788   5: 0.014156990022607   4: 0.010394432105616   0: 0.010322086661536   9: 0.010310590608311   2: 0.010309131813748 

training_6719     1: 0.395240199372545   6: 0.222266209849016   7: 0.147308116932005   0: 0.147031822742486   5: 0.014693017852595   4: 0.014692644989182   9: 0.014692560378947   2: 0.014691976698262   8: 0.014691912465383   3: 0.014691538719579 

training_6720     6: 0.766234738239654   0: 0.098119916689900   8: 0.034106886769664   1: 0.026264261093056   2: 0.012546795729231   5: 0.012546443218378   4: 0.012545637451620   9: 0.012545248400821   3: 0.012545145278532   7: 0.012544927129143 

training_6721     0: 0.377382980089709   1: 0.259426970816042   6: 0.153402407115539   7: 0.133515789608971   4: 0.012749014407059   5: 0.012712379179831   9: 0.012703279979469   2: 0.012702515035260   8: 0.012702446710696   3: 0.012702217057424 

training_6722     6: 0.714027678868071   0: 0.145055560515192   1: 0.067976320535115   3: 0.017091005793157   5: 0.012088270802551   7: 0.011927967864383   2: 0.008021442481289   9: 0.007959918605555   4: 0.007930675886627   8: 0.007921158648060 

training_6723     1: 0.750034545139188   5: 0.106184428212843   6: 0.017979417575747   0: 0.017976951977273   4: 0.017974133683547   8: 0.017972653138453   9: 0.017970311985097   7: 0.017969688766942   2: 0.017968952258220   3: 0.017968917262690 

training_6725     5: 0.522642359592802   6: 0.300282010588661   0: 0.055990439418508   8: 0.017302840414639   1: 0.017300745496404   9: 0.017299695625922   4: 0.017296605522670   2: 0.017295329232302   7: 0.017295008882326   3: 0.017294965225766 

training_6726     6: 0.281748621003642   2: 0.277534073834212   0: 0.226235503657143   3: 0.115815780218196   9: 0.016635837496238   8: 0.016498079678374   4: 0.016438838165076   1: 0.016434836190799   7: 0.016340684699787   5: 0.016317745056533 

training_6729     5: 0.799106415157647   4: 0.022324751993191   6: 0.022322507771947   0: 0.022322304662180   1: 0.022321238390201   8: 0.022320689163710   3: 0.022320556638267   9: 0.022320535523110   2: 0.022320513846916   7: 0.022320486852832 

training_6730     5: 0.675133805838431   3: 0.139472555724309   4: 0.023176085272367   2: 0.023174653044308   0: 0.023174530156236   6: 0.023174219103745   1: 0.023173924899537   8: 0.023173519259356   7: 0.023173373531376   9: 0.023173333170335 

training_6731     8: 0.404331576298583   6: 0.382746429698350   1: 0.065428571588888   4: 0.021111854357694   9: 0.021074990706391   5: 0.021063577570831   0: 0.021063323648046   3: 0.021060137384562   2: 0.021059936765522   7: 0.021059601981132 

training_6732     6: 0.594453970391847   5: 0.129059079328774   2: 0.126815199578424   0: 0.055050029902359   7: 0.015779588809537   8: 0.015772693474525   1: 0.015769952857003   4: 0.015769259079249   9: 0.015765425173246   3: 0.015764801405036 

training_6733     5: 0.785669343659918   3: 0.023814988068965   4: 0.023814799219156   6: 0.023814685783239   0: 0.023814638411500   1: 0.023814624699173   8: 0.023814330479457   2: 0.023814231600586   7: 0.023814205326185   9: 0.023814152751822 

training_6734     5: 0.706750947515919   7: 0.072843320568473   8: 0.070145268922429   6: 0.021467049537150   1: 0.021466401536921   9: 0.021465861663396   0: 0.021465803599848   4: 0.021465327417861   2: 0.021465079741767   3: 0.021464939496236 

training_6735     6: 0.705553932716879   3: 0.145630796350071   1: 0.018614653825091   5: 0.018600714234864   0: 0.018600363812363   8: 0.018600254934448   9: 0.018600104620178   7: 0.018599944759054   4: 0.018599893350535   2: 0.018599341396517 

training_6737     0: 0.686389940304441   6: 0.120225977967475   3: 0.044273979872178   1: 0.040896289712150   4: 0.018094300283769   2: 0.018079861847087   9: 0.018073599278207   5: 0.017995431419781   7: 0.017985730406640   8: 0.017984888908272 

training_6738     5: 0.761634522934760   2: 0.080640467875046   6: 0.019720660780690   4: 0.019716648033647   0: 0.019715143866382   8: 0.019715102631943   9: 0.019714942578589   7: 0.019714235015810   1: 0.019714207398218   3: 0.019714068884916 

training_6739     5: 0.659645308643776   1: 0.115524850198854   4: 0.087008096491615   6: 0.019704429280140   9: 0.019694014069697   0: 0.019689011483572   7: 0.019683937661911   8: 0.019683914838379   3: 0.019683285808506   2: 0.019683151523550 

training_6740     6: 0.667861890697412   5: 0.158797821349358   7: 0.039262348061496   9: 0.038300546092549   2: 0.016001832802560   1: 0.015958595559993   0: 0.015958040073823   4: 0.015953588186873   8: 0.015953269867222   3: 0.015952067308714 

training_6741     5: 0.687626672356313   7: 0.091728910638863   9: 0.087770857047058   6: 0.018991681446361   0: 0.018981160473911   1: 0.018980713910785   4: 0.018980483909103   8: 0.018980339208254   3: 0.018979621486620   2: 0.018979559522731 

training_6742     6: 0.531532133254686   0: 0.260924480318164   5: 0.071022402019588   1: 0.049504470143149   7: 0.022851693244726   8: 0.017992136644070   9: 0.015141340929458   2: 0.010449241360371   4: 0.010291098380393   3: 0.010291003705395 

training_6743     1: 0.446182709537183   5: 0.346802068041346   4: 0.025882038052450   6: 0.025877861927912   0: 0.025877595748994   9: 0.025876260805047   8: 0.025875650087943   3: 0.025875470280196   7: 0.025875228800421   2: 0.025875116718507 

training_6744     6: 0.726419986682213   1: 0.119950978813276   0: 0.063457444251023   5: 0.013162525173047   8: 0.012842919134029   7: 0.012838213699739   2: 0.012834194746677   4: 0.012831997942446   3: 0.012831126700541   9: 0.012830612857009 

training_6746     6: 0.665486741267708   9: 0.174438298988476   8: 0.047730664761531   3: 0.031910915275034   0: 0.013423145298977   1: 0.013408075589631   5: 0.013401470131667   2: 0.013400570535185   4: 0.013400265297108   7: 0.013399852854683 

training_6747     5: 0.657411162353897   6: 0.143644380536002   7: 0.058642629280570   9: 0.020051583538597   2: 0.020050992502026   4: 0.020042654482170   1: 0.020040879062175   0: 0.020039701324615   3: 0.020038120435246   8: 0.020037896484704 

training_6748     5: 0.505816395256519   6: 0.352133399348329   0: 0.017760441664186   1: 0.017756655845079   9: 0.017756336075001   7: 0.017756256367436   2: 0.017755552456773   4: 0.017755463379318   8: 0.017755415706454   3: 0.017754083900907 

training_6751     6: 0.814188374827446   0: 0.020647428779700   5: 0.020646930072445   1: 0.020646740776462   8: 0.020645644540275   7: 0.020645153841080   2: 0.020645092214527   4: 0.020645081222167   9: 0.020644920201981   3: 0.020644633523916 

training_6752     6: 0.374910265463923   0: 0.258053983918361   4: 0.237319865476683   3: 0.028455265714070   8: 0.027181832641193   5: 0.021787132601191   2: 0.013121381781771   7: 0.013061307973996   1: 0.013057200906330   9: 0.013051763522482 

training_6757     6: 0.829802307477326   0: 0.036301388585109   4: 0.016738880797641   5: 0.016738588372581   1: 0.016737146898892   8: 0.016736755830962   9: 0.016736600068392   3: 0.016736221097500   7: 0.016736096195906   2: 0.016736014675691 

training_6758     6: 0.794228886639518   9: 0.047499494483901   5: 0.047263606732296   0: 0.015859836166772   8: 0.015859119478873   1: 0.015858192481433   4: 0.015857909020392   7: 0.015857801116263   2: 0.015857598905007   3: 0.015857554975544 

training_6759     4: 0.742108655665685   5: 0.028662294299501   8: 0.028653968630332   9: 0.028653661170975   6: 0.028653619452729   0: 0.028653596767093   2: 0.028653594929024   3: 0.028653594618475   7: 0.028653543800562   1: 0.028653470665624 

training_6760     6: 0.508921435871738   2: 0.263582212750918   1: 0.108982150525177   5: 0.031999160118666   9: 0.014421082140898   3: 0.014420086580293   8: 0.014419064501278   7: 0.014418461787200   0: 0.014418408243630   4: 0.014417937480201 

training_6761     5: 0.577233180232534   6: 0.239437979404966   3: 0.022958343875448   2: 0.022918936547639   9: 0.022912299640797   4: 0.022909196030801   8: 0.022908464548465   0: 0.022907720527128   1: 0.022907665360094   7: 0.022906213832129 

training_6762     6: 0.594991812424424   5: 0.124522945824945   2: 0.101876082528773   3: 0.065371848475013   4: 0.018877189622490   0: 0.018874363826905   1: 0.018871807622469   9: 0.018871432748696   7: 0.018871399683207   8: 0.018871117243079 

training_6763     5: 0.390875340564201   7: 0.319032157678825   6: 0.079383844781073   8: 0.077414253484429   1: 0.022219312317986   2: 0.022218336986729   0: 0.022215848646123   3: 0.022215121190860   4: 0.022213148489425   9: 0.022212635860350 

training_6764     6: 0.697253638159200   9: 0.133044766312160   0: 0.044544860807619   1: 0.017969314907608   5: 0.017867070466091   8: 0.017865133871421   4: 0.017864428770340   3: 0.017863969668607   7: 0.017863429761732   2: 0.017863387275221 

training_6765     5: 0.800763591972712   4: 0.022141044363024   6: 0.022137933067112   8: 0.022137078265923   0: 0.022136833092641   1: 0.022136778711219   9: 0.022136753568483   3: 0.022136702602823   2: 0.022136658771078   7: 0.022136625584986 

training_6767     7: 0.441979348943929   6: 0.376654962499439   2: 0.048830433059427   5: 0.018956613574227   9: 0.018939860841281   1: 0.018934523662164   0: 0.018929508525572   4: 0.018928526267436   3: 0.018923522594556   8: 0.018922700031967 

training_677      6: 0.611312344837409   2: 0.149174121790554   8: 0.079142483290291   1: 0.046809402244641   9: 0.040425816048209   0: 0.019985688110450   5: 0.013289984058196   3: 0.013289175391928   4: 0.013286336506668   7: 0.013284647721653 

training_6770     6: 0.624814088741414   8: 0.208270035051692   0: 0.080275004100895   5: 0.012390672381294   1: 0.012385419543446   4: 0.012377436418669   7: 0.012373021123350   9: 0.012371828195409   2: 0.012371619989754   3: 0.012370874454078 

training_6771     5: 0.756631127400226   4: 0.087298844839070   6: 0.019509781246822   8: 0.019509186250567   1: 0.019509183800901   9: 0.019508857735078   0: 0.019508676879185   2: 0.019508159604177   7: 0.019508143487302   3: 0.019508038756674 

training_6773     5: 0.751049263149524   3: 0.089996928284201   1: 0.019870405909943   0: 0.019870028715936   4: 0.019869414013139   6: 0.019869343396395   8: 0.019869163055230   2: 0.019868552612291   9: 0.019868457453588   7: 0.019868443409753 

training_6774     5: 0.800351287610263   4: 0.022184884103039   0: 0.022183772822912   1: 0.022183243533892   6: 0.022183241574273   3: 0.022183165981780   8: 0.022182686500169   9: 0.022182619229968   7: 0.022182612244597   2: 0.022182486399107 

training_6776     5: 0.570109483938283   0: 0.144039235161803   3: 0.120914851769940   7: 0.023570320558362   6: 0.023561497616765   4: 0.023561398588460   1: 0.023560865387105   8: 0.023560848639359   9: 0.023560760870755   2: 0.023560737469169 

training_6777     5: 0.433765197183986   4: 0.276597921216709   3: 0.120818832383942   7: 0.024125470873211   6: 0.024115512234713   1: 0.024115490577054   0: 0.024115468365967   2: 0.024115464122789   8: 0.024115374080180   9: 0.024115268961449 

training_6778     6: 0.607456368219560   0: 0.085260780157544   7: 0.076865136298999   8: 0.071941135364237   1: 0.055075686610896   2: 0.039256777642005   5: 0.016050538580672   9: 0.016032374640880   4: 0.016030908025434   3: 0.016030294459774 

training_6779     5: 0.712015398401165   1: 0.126434948051959   4: 0.020195486292733   6: 0.020194325092958   0: 0.020193519478623   8: 0.020193340643856   9: 0.020193297289090   7: 0.020193277299865   3: 0.020193256174119   2: 0.020193151275631 

training_6783     5: 0.781655689004650   4: 0.024264438065664   6: 0.024261356796331   0: 0.024260490218319   1: 0.024260386282208   7: 0.024260272297916   8: 0.024259495790493   9: 0.024259417902952   3: 0.024259227757493   2: 0.024259225883974 

training_6784     6: 0.378511949604494   1: 0.272097950240031   4: 0.218811734062470   2: 0.037851801953054   5: 0.015457311011039   7: 0.015457206330954   3: 0.015454303165591   0: 0.015453227031844   9: 0.015452949622156   8: 0.015451566978367 

training_6785     4: 0.791425606592855   5: 0.023179317734205   0: 0.023174822173253   7: 0.023174451721751   8: 0.023174420467604   9: 0.023174403610334   3: 0.023174338654656   2: 0.023174293774043   1: 0.023174235584590   6: 0.023174109686710 

training_6787     5: 0.703099878971605   0: 0.085655919428279   4: 0.049449224119809   7: 0.047588927053224   2: 0.034845564268179   6: 0.015873730576507   9: 0.015872932060645   3: 0.015872722503393   1: 0.015870710314836   8: 0.015870390703523 

training_6788     6: 0.748867936647500   0: 0.121054438041380   7: 0.034478213618599   1: 0.013661757660732   8: 0.013658530155070   9: 0.013658009793383   5: 0.013657742678795   4: 0.013654636486338   2: 0.013654533479986   3: 0.013654201438217 

training_6789     1: 0.751682919587476   0: 0.067874137430759   7: 0.042406933579855   9: 0.019733911549059   6: 0.019720202115122   5: 0.019717496119014   8: 0.019716286568280   4: 0.019716211555945   2: 0.019716112258441   3: 0.019715789236050 

training_679      1: 0.400851239419530   0: 0.244738465786871   5: 0.133685867943532   3: 0.115797939921801   6: 0.017493817515804   8: 0.017487931872732   9: 0.017487320097407   7: 0.017486001564398   4: 0.017485861622012   2: 0.017485554255913 

training_6790     0: 0.731024761489765   5: 0.029930348135541   4: 0.029916650416660   6: 0.029876732275597   8: 0.029876336979990   9: 0.029876060583767   3: 0.029875880091002   1: 0.029875190646654   2: 0.029874349048338   7: 0.029873690332685 

training_6791     9: 0.387173616431801   6: 0.266079117798856   0: 0.179253182273481   1: 0.055501469647407   7: 0.026651791448566   2: 0.025972510575415   5: 0.014844090277950   4: 0.014842599322045   3: 0.014840931775608   8: 0.014840690448870 

training_6794     5: 0.804198809261232   9: 0.021772615712389   7: 0.021756801835575   2: 0.021756489039192   8: 0.021754286789595   1: 0.021752566551512   4: 0.021752325792932   3: 0.021752323034183   0: 0.021751945361897   6: 0.021751836621493 

training_6797     0: 0.478911302326608   2: 0.218927116807681   6: 0.182905713385127   5: 0.017044024124470   4: 0.017038511747290   9: 0.017036163215910   1: 0.017035815817913   3: 0.017034661892945   8: 0.017033757521655   7: 0.017032933160401 

training_6798     6: 0.601976196605098   7: 0.192978579041080   5: 0.025691863584400   4: 0.025661084738654   2: 0.025624458841666   3: 0.025616348408655   1: 0.025614210904172   8: 0.025613414108074   0: 0.025612564511048   9: 0.025611279257152 

training_6799     4: 0.502883874260617   5: 0.301080857825491   0: 0.024518144132156   8: 0.024506974307459   6: 0.024501990341970   1: 0.024501801013627   9: 0.024501716024658   3: 0.024501713997051   2: 0.024501500222300   7: 0.024501427874671 

training_68       4: 0.441632727286773   6: 0.370194557899602   3: 0.049475634017881   1: 0.019841130607352   5: 0.019812140677569   2: 0.019809300177492   0: 0.019809202597873   7: 0.019808778926838   9: 0.019808532716470   8: 0.019807995092151 

training_680      5: 0.728921390480204   0: 0.131585955168871   6: 0.017454750017768   7: 0.017454163199375   4: 0.017442711488544   1: 0.017429136094020   2: 0.017428168198499   8: 0.017428122149262   3: 0.017427944764097   9: 0.017427658439361 

training_6801     5: 0.660593457247547   0: 0.155803913748137   6: 0.022954085335100   8: 0.022951762916329   9: 0.022950921669569   3: 0.022949538667313   4: 0.022949452853640   1: 0.022949436090242   7: 0.022948908011176   2: 0.022948523460947 

training_6802     5: 0.677191926930315   0: 0.139928522809133   3: 0.022860964449815   4: 0.022860319055310   6: 0.022860176974984   7: 0.022859664627352   8: 0.022859652256145   1: 0.022859637816882   9: 0.022859587788749   2: 0.022859547291316 

training_6804     6: 0.736717601678243   0: 0.105717388584693   7: 0.046584034370899   5: 0.015856461887953   9: 0.015855695728654   1: 0.015853914659343   3: 0.015853867129963   4: 0.015853792522702   8: 0.015853791182455   2: 0.015853452255098 

training_6805     1: 0.443366701668949   0: 0.315624778347743   6: 0.030130518799482   2: 0.030130356077302   5: 0.030125906835734   7: 0.030125588307935   8: 0.030125123833805   9: 0.030124229186314   4: 0.030124002549239   3: 0.030122794393497 

training_6807     6: 0.671091323165176   3: 0.118144935643110   8: 0.083803588792638   0: 0.018152533652286   5: 0.018142766940868   1: 0.018138632039975   4: 0.018132350189197   9: 0.018131723368679   2: 0.018131280229038   7: 0.018130865979034 

training_6809     4: 0.639103009396717   0: 0.136464708376307   5: 0.028061531993571   1: 0.028054188404627   8: 0.028053747389039   9: 0.028053187319039   6: 0.028052991913326   3: 0.028052323363834   2: 0.028052197513536   7: 0.028052114330002 

training_6810     6: 0.474982691149196   5: 0.359462076687460   8: 0.020702211863705   4: 0.020700327680726   1: 0.020694637980951   2: 0.020694473108574   0: 0.020693110050279   9: 0.020690383725121   3: 0.020690180220758   7: 0.020689907533230 

training_6811     0: 0.446067745345136   6: 0.395920990078952   3: 0.048786720299794   8: 0.029340773915675   9: 0.020798771134991   5: 0.012075388851161   4: 0.011766100241032   1: 0.011750638038579   2: 0.011750049727749   7: 0.011742822366931 

training_6813     5: 0.530628771883986   8: 0.309985217004547   6: 0.019929286657419   0: 0.019925031511415   4: 0.019924157801454   1: 0.019922698002238   9: 0.019922546627808   7: 0.019920939527635   3: 0.019920760396094   2: 0.019920590587405 

training_6814     5: 0.564557593978395   7: 0.151967824453091   9: 0.116290889899799   4: 0.023887568038172   6: 0.023882815794821   8: 0.023882752495328   0: 0.023882727754672   3: 0.023882629844248   1: 0.023882603861161   2: 0.023882593880313 

training_6815     1: 0.789881806976940   0: 0.061619496624530   2: 0.046173927899856   7: 0.014662039733964   8: 0.014619050309331   5: 0.014614311175380   6: 0.014614024915678   9: 0.014605933043795   4: 0.014605146449673   3: 0.014604262870852 

training_6816     6: 0.493791747865143   2: 0.310604909270194   1: 0.073292298621889   0: 0.034473735531027   5: 0.014649295457191   9: 0.014641397559801   4: 0.014639705082350   3: 0.014636357846258   8: 0.014635548642368   7: 0.014635004123779 

training_6817     6: 0.391520209621204   3: 0.249995707386715   5: 0.193794554776431   0: 0.044923867276525   7: 0.019981449520528   1: 0.019961516415509   9: 0.019957533538542   8: 0.019956086198359   4: 0.019955319579474   2: 0.019953755686713 

training_6818     1: 0.738707587019969   5: 0.101112289496439   0: 0.040574851592447   8: 0.017142419880925   6: 0.017081450125689   7: 0.017077602455938   4: 0.017077283503400   2: 0.017075599749525   9: 0.017075574265646   3: 0.017075341910023 

training_6819     0: 0.552738908803610   1: 0.256311272872391   2: 0.092422217696250   6: 0.014216965937498   3: 0.014065834076964   5: 0.014050879460504   9: 0.014049036133598   4: 0.014048408123066   7: 0.014048290820967   8: 0.014048186075153 

training_682      0: 0.571934057738379   1: 0.261302556518091   6: 0.020856665034073   5: 0.020845466022190   9: 0.020845458080147   8: 0.020844357722329   7: 0.020843784643426   4: 0.020843131922427   2: 0.020842379186496   3: 0.020842143132440 

training_6825     5: 0.635015767878311   9: 0.174196352504367   4: 0.023851423533043   1: 0.023850120906099   0: 0.023849099005972   6: 0.023848398829356   3: 0.023847769620188   2: 0.023847069964130   7: 0.023847025875876   8: 0.023846971882659 

training_6827     5: 0.810302125831290   6: 0.021079997107541   0: 0.021078200627422   1: 0.021077743686910   8: 0.021077234375264   3: 0.021077013603645   2: 0.021077001674292   4: 0.021076974808106   7: 0.021076968154424   9: 0.021076740131104 

training_6828     6: 0.449843480727542   1: 0.348718475498491   9: 0.062480573976327   0: 0.019855306179724   5: 0.019851869826799   2: 0.019851358021408   8: 0.019850657135208   4: 0.019850308112410   3: 0.019849083447839   7: 0.019848887074251 

training_6830     5: 0.761071158984688   4: 0.026549977092587   6: 0.026549959820650   0: 0.026549636385573   1: 0.026547694176699   3: 0.026546419652370   8: 0.026546398242928   2: 0.026546297990857   7: 0.026546232090869   9: 0.026546225562780 

training_6831     6: 0.384016273148897   5: 0.310734123748856   4: 0.038170010306164   3: 0.038155051232649   2: 0.038154542471419   8: 0.038154509596405   7: 0.038154154862961   9: 0.038153859784518   0: 0.038153839679336   1: 0.038153635168795 

training_6836     9: 0.381399108829372   6: 0.262322754880909   3: 0.133383259159567   2: 0.088640947325156   7: 0.038777574119716   5: 0.019104890930478   4: 0.019096721016182   1: 0.019094117346392   0: 0.019092425758214   8: 0.019088200634012 

training_6837     4: 0.713306167236173   1: 0.080805964398960   0: 0.066007569380507   5: 0.019988954471190   6: 0.019982725862365   8: 0.019981963725509   9: 0.019981744576872   2: 0.019981649279097   3: 0.019981637790045   7: 0.019981623279280 

training_684      6: 0.610492727090028   9: 0.161124356901998   7: 0.098671261248928   0: 0.041553975610821   1: 0.014969724015357   5: 0.014645039907480   2: 0.014636710119917   8: 0.014636244984317   4: 0.014634996705611   3: 0.014634963415543 

training_6840     5: 0.743571346801475   6: 0.128296698853889   7: 0.016103497144070   2: 0.016046215493311   4: 0.016000416500851   3: 0.015999420487764   0: 0.015997297499564   9: 0.015995836676419   1: 0.015995015961854   8: 0.015994254580804 

training_6841     6: 0.490416287576923   7: 0.271580895586301   0: 0.106837560522632   4: 0.043446760152962   5: 0.014621625409779   8: 0.014621562773305   1: 0.014620994691626   2: 0.014618877685792   9: 0.014617922375042   3: 0.014617513225640 

training_6844     0: 0.462662704295774   6: 0.294137454237091   1: 0.096410515647815   2: 0.072450058145663   9: 0.024658502673846   5: 0.009941036509965   3: 0.009935468171708   4: 0.009934859397865   7: 0.009934705091432   8: 0.009934695828841 

training_6846     1: 0.505426975775308   6: 0.257813676481616   8: 0.124325718367675   3: 0.023281475403649   0: 0.014862213083611   7: 0.014858738660125   9: 0.014858617399949   5: 0.014858254194808   4: 0.014857411986340   2: 0.014856918646920 

training_6848     5: 0.528036555238373   2: 0.263984190225506   4: 0.026008011254563   1: 0.025996746610939   0: 0.025996018144914   8: 0.025995845721064   6: 0.025995799466303   3: 0.025995722442603   9: 0.025995567765460   7: 0.025995543130275 

training_6849     1: 0.766855741438987   8: 0.099652391270817   2: 0.049638554242220   5: 0.011983170473241   6: 0.011982788109625   3: 0.011981157543488   0: 0.011978376431335   9: 0.011978157339689   4: 0.011975549774976   7: 0.011974113375622 

training_685      6: 0.309979378308838   5: 0.274948203706985   1: 0.203268437502031   2: 0.066756206217136   8: 0.039896679502569   9: 0.034109469793161   4: 0.028171247144132   3: 0.014347151215963   0: 0.014264525363279   7: 0.014258701245906 

training_6850     4: 0.740728184684805   5: 0.028817585840371   6: 0.028807263516520   8: 0.028807215813352   0: 0.028806759892603   7: 0.028806705098447   2: 0.028806669041295   3: 0.028806629833898   1: 0.028806510830076   9: 0.028806475448633 

training_6852     5: 0.394345561642227   2: 0.231556812510576   4: 0.213838633624843   1: 0.022896920567618   6: 0.022895698268455   0: 0.022894534026367   3: 0.022893444250811   7: 0.022893084557108   8: 0.022892756996420   9: 0.022892553555575 

training_6853     5: 0.809619496250206   1: 0.021155352305876   0: 0.021154331472956   6: 0.021153993090239   2: 0.021153171617866   4: 0.021153069937618   9: 0.021153028705156   8: 0.021152647640705   3: 0.021152508850095   7: 0.021152400129285 

training_6855     1: 0.442154168487659   7: 0.380504116688415   0: 0.022171860468486   8: 0.022170278417785   6: 0.022169191129623   5: 0.022168444735513   4: 0.022166913819792   9: 0.022165369285301   2: 0.022164881899146   3: 0.022164775068280 

training_6856     1: 0.712832214108022   4: 0.139229691353322   6: 0.018494191813179   0: 0.018493104229113   5: 0.018492918226879   2: 0.018492167652260   9: 0.018491763437505   8: 0.018491362645975   3: 0.018491303238594   7: 0.018491283295150 

training_6859     5: 0.755057060664568   4: 0.027219312014330   8: 0.027215878745368   9: 0.027215514154649   3: 0.027215463529389   7: 0.027215416534696   2: 0.027215415921595   1: 0.027215327709252   0: 0.027215316062654   6: 0.027215294663499 

training_686      5: 0.782553262114143   9: 0.024175947018199   8: 0.024162602245033   6: 0.024159698590781   4: 0.024159441133093   0: 0.024158376289431   1: 0.024158130613961   2: 0.024157563930448   3: 0.024157550752068   7: 0.024157427312842 

training_6860     5: 0.556763664873779   1: 0.150064007268152   8: 0.135796055255281   4: 0.022486208682149   6: 0.022484191619907   7: 0.022482221360894   0: 0.022481403340113   9: 0.022480768260385   3: 0.022480746475709   2: 0.022480732863631 

training_6861     5: 0.771328281742865   4: 0.025408938185433   3: 0.025408317961041   1: 0.025407849496808   2: 0.025407843292675   0: 0.025407828773241   6: 0.025407762473259   7: 0.025407746257785   8: 0.025407729593580   9: 0.025407702223312 

training_6862     5: 0.328582659946728   7: 0.294018837265390   1: 0.206931384381025   3: 0.024354956805884   2: 0.024354179059854   6: 0.024352838899511   0: 0.024352191637095   9: 0.024351080234742   4: 0.024350973286364   8: 0.024350898483408 

training_6863     1: 0.610903526714254   5: 0.177471469109865   6: 0.097053515023467   9: 0.016370047697613   0: 0.016369559197053   4: 0.016367628676136   3: 0.016366466164951   8: 0.016366033041435   7: 0.016365951926737   2: 0.016365802448489 

training_6864     5: 0.364258574434172   7: 0.231323133047422   1: 0.229099428555881   3: 0.025050279606395   2: 0.025047169347545   6: 0.025045875519010   0: 0.025044978900542   9: 0.025043653754978   4: 0.025043473145727   8: 0.025043433688328 

training_6865     4: 0.727415092989354   5: 0.030294281673021   9: 0.030286537591640   8: 0.030286505208656   6: 0.030286389586216   3: 0.030286327456192   2: 0.030286265398063   0: 0.030286260859402   7: 0.030286169823096   1: 0.030286169414359 

training_6866     6: 0.822299465542951   7: 0.035494997378302   0: 0.033640225979664   4: 0.015511058986846   5: 0.015510834319613   1: 0.015509216983888   9: 0.015508912372621   8: 0.015508881690703   3: 0.015508247647689   2: 0.015508159097723 

training_6869     1: 0.491723049557830   6: 0.356478185295499   0: 0.047139714503871   7: 0.028162142907540   5: 0.012751296836819   9: 0.012750796845726   3: 0.012748974449340   4: 0.012748857192401   8: 0.012748709083788   2: 0.012748273327185 

training_687      5: 0.771384924431768   6: 0.060490958202862   8: 0.021040017510440   0: 0.021035367619099   9: 0.021022083093284   7: 0.021013078177587   1: 0.021011082870406   4: 0.021004114801260   2: 0.020999333344435   3: 0.020999039948858 

training_6871     2: 0.570537909152789   7: 0.201234443546434   5: 0.028535237219307   4: 0.028530828676296   9: 0.028528743677529   8: 0.028527371440736   6: 0.028526950062402   3: 0.028526448482635   1: 0.028526069121298   0: 0.028525998620573 

training_6872     6: 0.673675202299093   5: 0.148419983752430   9: 0.054787179218827   7: 0.017597370453148   0: 0.017588690681527   1: 0.017587479263571   8: 0.017587143834512   2: 0.017585965443324   4: 0.017585718176261   3: 0.017585266877309 

training_6873     1: 0.736664472293597   4: 0.076435609472912   0: 0.023367348109542   6: 0.023365169686165   5: 0.023362501894878   2: 0.023361609446318   9: 0.023361532185371   8: 0.023360747013007   7: 0.023360540542540   3: 0.023360469355671 

training_6874     5: 0.724401372889035   6: 0.127255744959355   0: 0.018550420732751   1: 0.018544070127358   8: 0.018541973417084   2: 0.018541831862787   4: 0.018541680106526   9: 0.018541114203125   7: 0.018541089983943   3: 0.018540701718037 

training_6875     5: 0.779022811063861   6: 0.024562237499143   8: 0.024552433361841   0: 0.024552430699379   9: 0.024552247504717   3: 0.024551874289025   4: 0.024551812806709   1: 0.024551626864250   7: 0.024551265086682   2: 0.024551260824394 

training_6876     6: 0.641975178132515   1: 0.238574969463375   0: 0.031090293587107   9: 0.024016124695487   8: 0.018255489772000   2: 0.009245571006738   7: 0.009220836930066   4: 0.009208656482207   5: 0.009207152401702   3: 0.009205727528803 

training_6877     1: 0.401354234681438   5: 0.296632318049013   8: 0.161032727567071   0: 0.044497536057051   6: 0.016085194555368   4: 0.016080273395135   9: 0.016079616435446   7: 0.016079472816663   2: 0.016079318064284   3: 0.016079308378532 

training_688      6: 0.607029561105579   7: 0.170460652889829   2: 0.055136311629419   5: 0.051227409419659   0: 0.034286140885472   4: 0.016380865869233   8: 0.016373414173109   3: 0.016369667131032   1: 0.016368465842305   9: 0.016367511054362 

training_6880     4: 0.763386096151884   7: 0.073290187583343   5: 0.020421750690661   6: 0.020419649776437   1: 0.020416349181194   0: 0.020414258954236   8: 0.020413081328836   3: 0.020413008958756   9: 0.020412833856072   2: 0.020412783518579 

training_6881     5: 0.558201945602002   4: 0.177348547660949   6: 0.102100919661254   9: 0.023194660239426   3: 0.023193019965813   0: 0.023192486591923   1: 0.023192462064614   2: 0.023192086756791   8: 0.023192083015778   7: 0.023191788441451 

training_6882     6: 0.754112841516303   0: 0.130886138313904   5: 0.014376778547388   1: 0.014376508702379   8: 0.014374723504795   9: 0.014374709923192   7: 0.014374698924695   3: 0.014374624355693   4: 0.014374527247619   2: 0.014374448964031 

training_6884     6: 0.516804491251093   7: 0.251088228713902   0: 0.095122029526961   4: 0.041650703415796   5: 0.015890961784261   8: 0.015890859204275   1: 0.015890580244571   2: 0.015888320299005   9: 0.015887089197655   3: 0.015886736362481 

training_6886     3: 0.439389572753514   0: 0.324543947278714   2: 0.046962742839294   7: 0.044969286000647   5: 0.042773760936452   6: 0.020275905326465   1: 0.020273649658508   4: 0.020271006925562   9: 0.020270367019180   8: 0.020269761261665 

training_6887     0: 0.715198003661095   1: 0.151935824255154   5: 0.029934068654636   4: 0.014812133540095   6: 0.014711061177835   9: 0.014693122376064   2: 0.014679752816343   7: 0.014679189143685   8: 0.014678440371837   3: 0.014678404003255 

training_6888     5: 0.597774356370960   8: 0.178031285014170   6: 0.068661219482214   0: 0.022220952155484   1: 0.022220377629615   4: 0.022219335497102   9: 0.022218609944598   2: 0.022218590154635   3: 0.022217790016772   7: 0.022217483734450 

training_689      1: 0.691086646299420   6: 0.034325461486540   0: 0.034324804066953   9: 0.034323442921067   4: 0.034323385703948   2: 0.034323352737720   8: 0.034323280826907   7: 0.034323238621416   3: 0.034323196551854   5: 0.034323190784175 

training_6890     6: 0.745565295377793   7: 0.100689993233644   0: 0.065371257884812   2: 0.014409465285229   8: 0.012448117673580   1: 0.012390696187515   5: 0.012305233557898   3: 0.012277908762678   9: 0.012273082063561   4: 0.012268949973290 

training_6893     6: 0.629588220242744   7: 0.244403417841917   5: 0.015753740717092   9: 0.015753598348174   2: 0.015753126197861   4: 0.015751689163764   8: 0.015749812398265   0: 0.015749444218395   1: 0.015748967856421   3: 0.015747983015367 

training_6894     5: 0.645121368133864   6: 0.160362963000200   1: 0.024315840127632   0: 0.024314818584148   2: 0.024314586094343   4: 0.024314412987720   9: 0.024314384849879   3: 0.024314273359867   7: 0.024313732983481   8: 0.024313619878867 

training_6897     6: 0.706537192612465   0: 0.143924899121195   7: 0.018693569756807   1: 0.018693101664025   5: 0.018692453714703   9: 0.018692261496614   2: 0.018692161861031   8: 0.018691905698839   4: 0.018691309856647   3: 0.018691144217674 

training_6898     6: 0.792272054396931   5: 0.023083102660548   0: 0.023081335956754   7: 0.023081147272517   1: 0.023080583455520   9: 0.023080536952564   2: 0.023080531810383   4: 0.023080351968762   8: 0.023080247783342   3: 0.023080107742678 

training_69       8: 0.545405810403492   6: 0.285849228427022   5: 0.021095400137072   4: 0.021094354584139   0: 0.021093277678075   1: 0.021093211411477   7: 0.021093049057791   9: 0.021092967024061   2: 0.021091410759444   3: 0.021091290517427 

training_690      5: 0.780400269499121   4: 0.024400998983021   8: 0.024400499949202   6: 0.024400034490134   3: 0.024399998218544   0: 0.024399910865082   1: 0.024399731408651   7: 0.024399528253283   2: 0.024399514620271   9: 0.024399513712690 

training_6903     6: 0.697325860982635   1: 0.152548776805287   3: 0.038427946211048   0: 0.015968971634764   8: 0.015956474744499   5: 0.015954801290334   9: 0.015954477718977   7: 0.015954447927331   4: 0.015954193109640   2: 0.015954049575485 

training_6905     9: 0.522869975133634   6: 0.324819312481978   8: 0.019063560593706   7: 0.019043363165326   5: 0.019036760290772   2: 0.019034222562351   0: 0.019033599045512   1: 0.019033523892803   4: 0.019033103112118   3: 0.019032579721799 

training_6906     6: 0.743216330654608   1: 0.066834846198059   5: 0.037836465559543   3: 0.037567571237682   0: 0.034554868317128   8: 0.015998522264817   9: 0.015998007013211   7: 0.015997966059411   4: 0.015997732262917   2: 0.015997690432624 

training_6907     0: 0.570370640234321   6: 0.194317358186958   9: 0.078499341730359   3: 0.045269239199161   4: 0.018600773483774   5: 0.018597485872298   1: 0.018587516669664   8: 0.018586367782774   7: 0.018586270337253   2: 0.018585006503438 

training_6908     1: 0.397141440605770   5: 0.223951490885937   3: 0.204593991167756   8: 0.046372234974774   2: 0.021418433562385   0: 0.021361133696990   6: 0.021298306992751   4: 0.021287923201977   9: 0.021287656482665   7: 0.021287388428995 

training_6909     6: 0.774332471657497   0: 0.025076460575077   5: 0.025076447864584   1: 0.025075859925210   7: 0.025073956544956   8: 0.025073222420938   3: 0.025073213375718   4: 0.025072940325903   9: 0.025072881118234   2: 0.025072546191883 

training_691      5: 0.740703541864500   4: 0.088369177059131   0: 0.021366565623004   8: 0.021366405935699   3: 0.021365957649827   6: 0.021365939416145   1: 0.021365747271639   7: 0.021365562971995   2: 0.021365551545480   9: 0.021365550662579 

training_6912     6: 0.810564738287846   8: 0.044196004281960   7: 0.018157457728461   3: 0.018155547692154   5: 0.018154990296805   1: 0.018154770820151   0: 0.018154728516508   2: 0.018154025894386   9: 0.018153969723098   4: 0.018153766758631 

training_6913     2: 0.660059727170407   1: 0.100173605875900   9: 0.076396920173364   0: 0.043847061538450   6: 0.019926417761590   5: 0.019923236339226   4: 0.019919934430209   7: 0.019918920789213   8: 0.019918289718987   3: 0.019915886202654 

training_6914     1: 0.514607712019525   6: 0.208539759416779   5: 0.122683724427957   0: 0.047085423500916   9: 0.044915720067377   2: 0.018322278029289   8: 0.013167402628686   4: 0.010271304563748   7: 0.010210519472337   3: 0.010196155873386 

training_6917     5: 0.544135190018468   4: 0.256457443534588   3: 0.024926507509668   9: 0.024926105914008   6: 0.024926020834238   0: 0.024925920170438   8: 0.024925830625663   1: 0.024925766636205   2: 0.024925654415831   7: 0.024925560340893 

training_692      5: 0.593711765174255   4: 0.227389397778589   8: 0.022363509146968   6: 0.022362821520790   3: 0.022362421152014   0: 0.022362317608573   1: 0.022362113890947   7: 0.022361935326115   2: 0.022361859866261   9: 0.022361858535489 

training_6920     6: 0.827383304411668   5: 0.019180944151538   0: 0.019180086320993   1: 0.019179707190846   9: 0.019179532564774   2: 0.019179443979359   7: 0.019179425674899   8: 0.019179356175862   3: 0.019179157979454   4: 0.019179041550606 

training_6922     0: 0.429317268374597   6: 0.334915329284493   1: 0.123503922038381   7: 0.026967401554297   9: 0.018799242785111   8: 0.018243936267029   5: 0.017337621013211   3: 0.010414598257535   4: 0.010250603269353   2: 0.010250077155991 

training_6926     6: 0.625784795866978   1: 0.247631868070199   0: 0.044901186523165   7: 0.028909658432489   4: 0.008804082663185   5: 0.008795251826793   9: 0.008794053736374   8: 0.008793100629736   2: 0.008793018886119   3: 0.008792983364962 

training_6927     6: 0.713999533685023   1: 0.111859353311262   7: 0.073009974797141   3: 0.032452042675633   8: 0.011486713013944   0: 0.011441567225732   5: 0.011439278837747   9: 0.011437279988293   2: 0.011437153298531   4: 0.011437103166693 

training_6928     1: 0.584712876003996   0: 0.246106149112318   2: 0.047276078344600   9: 0.045121210125647   3: 0.021346381729386   6: 0.011099128794184   5: 0.011091348546553   4: 0.011083596738788   8: 0.011081760008731   7: 0.011081470595797 

training_6929     2: 0.432734758320814   6: 0.388516457318304   1: 0.063683151748490   0: 0.016495097556666   4: 0.016432147545363   9: 0.016431405976064   5: 0.016431017696969   8: 0.016425484592325   3: 0.016425322652171   7: 0.016425156592833 

training_693      5: 0.785850076943733   6: 0.023797526396554   0: 0.023794563020961   4: 0.023794502358897   1: 0.023794384940533   8: 0.023794068364372   2: 0.023793966237611   3: 0.023793949170240   9: 0.023793625436482   7: 0.023793337130619 

training_6930     1: 0.574971989044153   2: 0.149467309753205   9: 0.065586881590946   5: 0.052329183177263   7: 0.050985648012359   6: 0.021334656931226   0: 0.021332770204859   8: 0.021330776604715   4: 0.021330747520798   3: 0.021330037160475 

training_6931     5: 0.579105836651480   7: 0.211846032693987   3: 0.026131718916276   4: 0.026131439172127   6: 0.026130883526631   0: 0.026130869668589   2: 0.026130865132005   1: 0.026130864604705   9: 0.026130750095508   8: 0.026130739538692 

training_6934     6: 0.640191730308290   1: 0.173788320551879   0: 0.070795842084872   8: 0.024928202572442   4: 0.024792423231239   5: 0.013103792190009   3: 0.013103019778821   7: 0.013100120879001   9: 0.013098310873740   2: 0.013098237529708 

training_6935     6: 0.648198874625713   1: 0.150822114002077   0: 0.055809089328612   7: 0.045002066960378   9: 0.031119901731113   8: 0.013814260181549   3: 0.013814193564945   5: 0.013807282466401   4: 0.013806453934797   2: 0.013805763204415 

training_6939     6: 0.711347390178315   9: 0.090404610802510   7: 0.057107156231589   0: 0.043644767652593   5: 0.016254062692738   1: 0.016248805407178   4: 0.016248611521760   8: 0.016248475306397   2: 0.016248132506997   3: 0.016247987699924 

training_694      8: 0.595969540073476   1: 0.183390882380112   6: 0.027596304956959   7: 0.027579340824250   0: 0.027578538376444   9: 0.027577237639238   5: 0.027577234893712   2: 0.027577036529380   3: 0.027576980747198   4: 0.027576903579231 

training_6941     6: 0.768349854660785   1: 0.056509847683190   0: 0.040049932128283   2: 0.035650722482001   3: 0.034607614332931   5: 0.012972345945866   8: 0.012965089891702   7: 0.012964944110417   9: 0.012964824484561   4: 0.012964824280264 

training_6942     6: 0.645188333432573   5: 0.129772838024204   4: 0.028144485849650   9: 0.028139912855392   0: 0.028129500857628   8: 0.028125773569643   7: 0.028125354786158   2: 0.028124869308096   3: 0.028124687689909   1: 0.028124243626747 

training_6943     6: 0.781451415581998   7: 0.075558323427441   9: 0.027452757114597   0: 0.016656923736971   1: 0.016523848955405   5: 0.016474511638881   4: 0.016471059561677   8: 0.016470944703029   3: 0.016470368820929   2: 0.016469846459073 

training_6944     1: 0.474537069079328   6: 0.379334715117062   0: 0.039827498791752   9: 0.024567957942640   2: 0.024351705046488   7: 0.011518761283274   5: 0.011467182997575   8: 0.011465278829259   4: 0.011465076896660   3: 0.011464754015962 

training_6945     6: 0.617481051679357   1: 0.221602322836368   0: 0.050288397781453   7: 0.030008036538696   5: 0.013446682271156   8: 0.013435666271503   2: 0.013434635245625   9: 0.013434557313687   4: 0.013434363204405   3: 0.013434286857749 

training_6946     6: 0.723579885278823   0: 0.120168678401303   7: 0.019555176912912   5: 0.019533999212272   1: 0.019530847128787   8: 0.019528150336217   9: 0.019527326077503   2: 0.019526193206118   3: 0.019525075354638   4: 0.019524668091429 

training_695      5: 0.790501150684715   4: 0.023279696440436   8: 0.023277917137467   6: 0.023277828591182   3: 0.023277465871815   0: 0.023277387527494   9: 0.023277235682338   1: 0.023277226442493   2: 0.023277048115644   7: 0.023277043506416 

training_6951     6: 0.534385783750900   7: 0.288308636901448   9: 0.022164349559716   0: 0.022163665088045   5: 0.022163462972744   8: 0.022163450013938   1: 0.022163364419959   4: 0.022162527584774   2: 0.022162469596717   3: 0.022162290111758 

training_6952     6: 0.835335091435442   5: 0.018298032898103   9: 0.018296580245355   8: 0.018296208297513   7: 0.018296109014960   0: 0.018295936216380   4: 0.018295784344377   1: 0.018295685335573   2: 0.018295525104353   3: 0.018295047107943 

training_6953     4: 0.425487340591542   5: 0.336102493269482   9: 0.050844296339917   3: 0.050130066845932   1: 0.022953466665343   6: 0.022917336108618   0: 0.022898983098457   8: 0.022891047911529   2: 0.022888111819618   7: 0.022886857349563 

training_6954     6: 0.762740428751765   0: 0.101923342548024   9: 0.046538751691227   7: 0.012708901034892   1: 0.012685629271244   2: 0.012682350323526   4: 0.012681122253684   5: 0.012680587381135   3: 0.012679456300410   8: 0.012679430444094 

training_6955     6: 0.668458428684837   9: 0.175252658758006   0: 0.019541245714595   5: 0.019540062846488   7: 0.019535395493468   4: 0.019535198486873   1: 0.019535039901093   8: 0.019534391340345   3: 0.019533931382237   2: 0.019533647392056 

training_6957     6: 0.637731155440716   1: 0.142836089547924   5: 0.115694529858471   8: 0.014990802699345   0: 0.014798754237163   3: 0.014794183014125   9: 0.014791962287650   4: 0.014787802422420   2: 0.014787455045696   7: 0.014787265446489 

training_6959     6: 0.606782599161922   0: 0.304978853642231   7: 0.017344779545849   3: 0.010131673387866   8: 0.010130909728683   1: 0.010129032405601   5: 0.010127144031250   4: 0.010125290508186   9: 0.010125258695463   2: 0.010124458892950 

training_696      0: 0.664681433949833   1: 0.100149527606903   8: 0.070846039990373   9: 0.050384530770449   5: 0.031548591238961   4: 0.016506693972728   6: 0.016479448132817   3: 0.016468129026857   2: 0.016467838641367   7: 0.016467766669714 

training_6960     6: 0.703850941951422   2: 0.142764473451752   5: 0.019176940341032   0: 0.019173816646729   1: 0.019173157001779   3: 0.019172769090659   4: 0.019172398551040   8: 0.019172098045768   7: 0.019171852933786   9: 0.019171551986032 

training_6961     0: 0.518209058426801   6: 0.355378369676436   7: 0.015813048552008   1: 0.015801913624519   8: 0.015800552259645   5: 0.015800203124835   3: 0.015799410076014   9: 0.015799296700755   4: 0.015799127016560   2: 0.015799020542427 

training_6964     6: 0.651733495089513   7: 0.134652360964035   1: 0.087194076269121   5: 0.018063494056033   0: 0.018062672717802   9: 0.018062196781694   8: 0.018058434389977   2: 0.018057890807433   4: 0.018057813761533   3: 0.018057565162858 

training_6965     6: 0.664963099683943   7: 0.116721755184807   9: 0.059190961225263   0: 0.057011056459075   1: 0.017031351410144   5: 0.017017029594934   8: 0.017016923640397   3: 0.017016398546276   4: 0.017015828575966   2: 0.017015595679195 

training_6968     6: 0.737755465220187   0: 0.133257953398041   1: 0.030928942904774   9: 0.014022440879209   5: 0.014021073171017   8: 0.014013956770568   4: 0.014003826999466   7: 0.013999522287842   2: 0.013998914574917   3: 0.013997903793980 

training_6969     1: 0.583493610806456   5: 0.155608854113336   4: 0.032618069354421   3: 0.032614580292290   6: 0.032612509290719   8: 0.032611044666482   7: 0.032610561200326   9: 0.032610541510291   2: 0.032610187486037   0: 0.032610041279643 

training_697      6: 0.774514798533364   8: 0.068362061397075   9: 0.036131059333860   0: 0.033854393073372   2: 0.014556090568697   5: 0.014519994439142   1: 0.014516383192999   3: 0.014515317462059   7: 0.014514979047201   4: 0.014514922952231 

training_6970     6: 0.707995211619192   0: 0.173416367326959   9: 0.014826953755458   8: 0.014825368971319   5: 0.014824961899540   4: 0.014822943387940   7: 0.014822472398349   1: 0.014822144543509   2: 0.014821829667147   3: 0.014821746430589 

training_6972     1: 0.570461726117990   5: 0.210385068748303   6: 0.027397419539715   3: 0.027395694625168   4: 0.027395535623954   8: 0.027393561574197   9: 0.027393513648349   0: 0.027393448884265   7: 0.027392268674882   2: 0.027391762563178 

training_6975     6: 0.641570023784884   7: 0.168858578559215   9: 0.023697316185825   5: 0.023697006190738   8: 0.023696873750610   0: 0.023696704080255   1: 0.023696247480650   2: 0.023695902258856   4: 0.023695732757302   3: 0.023695614951665 

training_6976     6: 0.492182245228686   8: 0.320514396766004   5: 0.039498342436837   2: 0.035862118044390   0: 0.018673685864428   1: 0.018657388325346   4: 0.018653183536272   7: 0.018653139990465   9: 0.018652933779100   3: 0.018652566028471 

training_698      4: 0.747060703759286   5: 0.028112129550067   8: 0.028103631643543   9: 0.028103603630091   3: 0.028103449481916   2: 0.028103384657149   7: 0.028103303361111   0: 0.028103289859218   1: 0.028103270559615   6: 0.028103233498003 

training_6981     9: 0.848036837834739   6: 0.016886646286458   8: 0.016885424382250   5: 0.016885399928808   0: 0.016884800986971   4: 0.016884573536322   1: 0.016884433885613   2: 0.016884007814417   3: 0.016883957918738   7: 0.016883917425685 

training_6982     6: 0.797945033813045   1: 0.057280368745943   8: 0.018115292107059   5: 0.018095389705848   0: 0.018094458060056   9: 0.018094130479117   2: 0.018093996922969   7: 0.018093914779280   3: 0.018093748733377   4: 0.018093666653305 

training_6983     0: 0.445156638221390   6: 0.339700328024524   5: 0.026911143201463   4: 0.026904499406080   8: 0.026893649368750   9: 0.026888220121875   7: 0.026886766900179   1: 0.026886290630623   2: 0.026886253521437   3: 0.026886210603679 

training_6985     6: 0.655846409542848   3: 0.183152434752125   5: 0.061335156951176   0: 0.014263349796284   1: 0.014235836000593   4: 0.014234526998931   8: 0.014233333917867   7: 0.014233134963470   9: 0.014232968706427   2: 0.014232848370278 

training_6986     1: 0.415267901790338   9: 0.355320913852340   4: 0.028693142829098   5: 0.028691983338541   8: 0.028674714331622   3: 0.028672350675605   6: 0.028671500313326   0: 0.028671203400177   2: 0.028668972891289   7: 0.028667316577666 

training_699      5: 0.462285024994231   7: 0.337543061600515   4: 0.025029375349727   0: 0.025020603605692   8: 0.025020581873096   2: 0.025020427655109   3: 0.025020389647658   1: 0.025020311228497   9: 0.025020216059386   6: 0.025020007986089 

training_6993     6: 0.689865842744523   8: 0.165971169602099   5: 0.018021405732579   1: 0.018021219702563   0: 0.018020841988453   9: 0.018020462034946   4: 0.018020345208136   7: 0.018019599789922   2: 0.018019583921090   3: 0.018019529275689 

training_6994     6: 0.764929741912524   0: 0.098164996598845   1: 0.041596438793459   3: 0.013620761062200   5: 0.013615353639046   4: 0.013614676397729   7: 0.013614604941439   8: 0.013614538776025   2: 0.013614478056697   9: 0.013614409822036 

training_6995     6: 0.790312509581299   7: 0.046905317711617   0: 0.040063222089448   1: 0.017588145278249   9: 0.017535080685867   8: 0.017521815448111   4: 0.017520083555617   5: 0.017519591896676   3: 0.017517350643846   2: 0.017516883109269 

training_6996     6: 0.802200396601705   1: 0.087386377805385   0: 0.043386511802232   5: 0.019937439532846   4: 0.008239500604211   3: 0.007808679495070   9: 0.007766668283407   2: 0.007760418929775   7: 0.007757028872318   8: 0.007756978073051 

training_6998     6: 0.731907579599250   0: 0.160925126694379   1: 0.013400123510991   5: 0.013398973369179   2: 0.013395148028865   7: 0.013394907470629   9: 0.013394860551353   8: 0.013394791375569   4: 0.013394393885212   3: 0.013394095514572 

training_6999     5: 0.689907783189214   7: 0.104133774256143   3: 0.082542844625513   9: 0.017637263991701   8: 0.017632820846040   6: 0.017631856925081   1: 0.017630110261442   4: 0.017628565869771   0: 0.017627904190331   2: 0.017627075844764 

training_700      5: 0.545719378381433   9: 0.261806036450885   8: 0.024060033593070   4: 0.024059764681334   3: 0.024059420458484   6: 0.024059335145291   0: 0.024059304767537   1: 0.024059081989305   7: 0.024058829424346   2: 0.024058815108315 

training_7000     9: 0.713528473938379   4: 0.031843319615552   5: 0.031839744423338   3: 0.031829143937292   8: 0.031828699285468   1: 0.031827712688679   0: 0.031826731355434   6: 0.031826013179944   2: 0.031825167037910   7: 0.031824994538005 

training_7001     6: 0.795504783841142   1: 0.083822466403164   3: 0.035287546810213   5: 0.012215388214314   4: 0.012202703597047   7: 0.012200853639245   9: 0.012192357337971   0: 0.012191946722509   8: 0.012191478085653   2: 0.012190475348743 

training_7003     5: 0.398571473697323   6: 0.262734959092812   3: 0.174781482489194   0: 0.045281946667437   7: 0.038760261733997   9: 0.015984028101136   1: 0.015978937226853   8: 0.015971826778366   4: 0.015969053445889   2: 0.015966030766993 

training_7004     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_7005     9: 0.759303388125575   6: 0.026758680666670   5: 0.026757795457303   4: 0.026744853820926   0: 0.026743703575592   1: 0.026739475565054   8: 0.026739222480787   7: 0.026738943417649   2: 0.026737245016633   3: 0.026736691873812 

training_7006     6: 0.559932464152910   9: 0.222033266471519   5: 0.027259021416480   0: 0.027258042059937   8: 0.027254562328758   7: 0.027253363174117   4: 0.027253003413021   1: 0.027252738510097   2: 0.027251870991379   3: 0.027251667481782 

training_7007     6: 0.759604044202231   9: 0.026713431922386   5: 0.026713198220065   7: 0.026712229769743   8: 0.026711265649856   0: 0.026709528692841   1: 0.026709356426696   3: 0.026709069775380   2: 0.026708985530671   4: 0.026708889810132 

training_7008     5: 0.556356181563695   6: 0.223911923522990   3: 0.098184063953911   9: 0.017371258493381   1: 0.017370106468573   8: 0.017366980379882   0: 0.017362761254611   4: 0.017360504303688   2: 0.017358197006781   7: 0.017358023052488 

training_7009     6: 0.577130510370559   5: 0.213160507097192   9: 0.026229262256745   8: 0.026225769625998   4: 0.026213602684657   3: 0.026209480302690   1: 0.026208546117190   0: 0.026207883803785   7: 0.026207549203656   2: 0.026206888537527 

training_701      5: 0.732019479902424   4: 0.087413304939710   6: 0.022572479770408   0: 0.022571517740167   8: 0.022571152449955   3: 0.022570700635705   1: 0.022570462323361   9: 0.022570342706122   7: 0.022570285924516   2: 0.022570273607631 

training_7010     9: 0.755936325794659   7: 0.027162557683366   5: 0.027119755648127   6: 0.027115148209622   8: 0.027113171770052   4: 0.027112633756913   0: 0.027111273389847   1: 0.027110545621136   2: 0.027109405736554   3: 0.027109182389723 

training_7011     6: 0.578855162209408   1: 0.208611200822045   9: 0.118431341123048   0: 0.013444589372467   5: 0.013444488040277   7: 0.013442797198538   4: 0.013442771487282   8: 0.013442733402979   3: 0.013442459172522   2: 0.013442457171434 

training_7012     6: 0.736324132993957   9: 0.074068040342297   7: 0.073043754508182   0: 0.016658476608794   8: 0.016656234716136   5: 0.016652310805050   3: 0.016649703702669   1: 0.016649568501511   4: 0.016649264381476   2: 0.016648513439928 

training_7013     6: 0.576323398904444   7: 0.223077531477651   0: 0.069146930570743   1: 0.031980190168163   4: 0.031222653586140   9: 0.013682380572946   8: 0.013645022586115   5: 0.013641573062879   2: 0.013640163785395   3: 0.013640155285523 

training_7014     6: 0.781454677770413   7: 0.086996038780387   1: 0.031318496269322   0: 0.014330230171178   2: 0.014322391462683   9: 0.014317593048465   5: 0.014317392597316   8: 0.014316958567297   4: 0.014313392467940   3: 0.014312828864999 

training_7015     6: 0.860172539275997   0: 0.028294232039436   1: 0.014030333492610   7: 0.013930919831440   5: 0.013930865333725   9: 0.013929176580008   4: 0.013928365573807   8: 0.013928059582122   3: 0.013927758949635   2: 0.013927749341220 

training_702      5: 0.574074947476484   6: 0.169501674360357   4: 0.088375948175651   8: 0.024007554320509   3: 0.024007054163881   0: 0.024006888345211   1: 0.024006663882771   7: 0.024006434204588   2: 0.024006418912640   9: 0.024006416157909 

training_7020     9: 0.796081322481850   6: 0.022659762819066   8: 0.022659203251920   5: 0.022658250403763   0: 0.022657422022242   1: 0.022657230446774   4: 0.022657112325163   7: 0.022656746406819   3: 0.022656512519182   2: 0.022656437323220 

training_7023     6: 0.637718716397621   1: 0.142820743554590   5: 0.115714815578787   8: 0.014998310510057   0: 0.014798747576296   3: 0.014794183263390   9: 0.014791960556549   4: 0.014787802243610   2: 0.014787454870179   7: 0.014787265448921 

training_7024     1: 0.474600963934419   6: 0.379332981915021   0: 0.039767144476901   9: 0.024565802711975   2: 0.024351689145052   7: 0.011519123424318   5: 0.011467184283680   8: 0.011465278825648   4: 0.011465076818489   3: 0.011464754464499 

training_7027     9: 0.615485098640825   6: 0.224815129655572   8: 0.019967986984788   1: 0.019964848056496   5: 0.019962067425545   0: 0.019961533246246   3: 0.019961314948582   4: 0.019960937891583   7: 0.019960577740864   2: 0.019960505409498 

training_7029     6: 0.686467317577391   0: 0.195275845107269   8: 0.014784533221124   9: 0.014784079725277   5: 0.014783489432871   4: 0.014781582864131   7: 0.014781303892002   1: 0.014780839592033   2: 0.014780556304010   3: 0.014780452283892 

training_703      0: 0.618494419857428   4: 0.198349218031713   5: 0.022901605842968   1: 0.022900311397816   6: 0.022896611661424   8: 0.022892326615467   2: 0.022891655525955   7: 0.022891417923927   9: 0.022891385030594   3: 0.022891048112707 

training_7030     0: 0.518255125772237   6: 0.355332306629196   7: 0.015813045122101   1: 0.015801913357964   8: 0.015800551991370   5: 0.015800202983310   3: 0.015799409922083   9: 0.015799296771546   4: 0.015799126961886   2: 0.015799020488307 

training_7031     6: 0.828867703089774   0: 0.019020806376750   5: 0.019016617941887   3: 0.019015064436970   1: 0.019013619185831   7: 0.019013614682697   9: 0.019013498825184   8: 0.019013424417973   4: 0.019013061735815   2: 0.019012589307120 

training_7032     6: 0.790916696812125   0: 0.089342153899731   3: 0.046735436699312   1: 0.010432218525572   9: 0.010429943925526   5: 0.010429108782089   2: 0.010428901035294   7: 0.010428627631441   8: 0.010428565309580   4: 0.010428347379330 

training_7036     0: 0.518354266074756   6: 0.360856868867593   7: 0.038025046045767   1: 0.026893972691510   9: 0.009313208613305   8: 0.009312831651093   5: 0.009312108524573   4: 0.009310884068352   2: 0.009310480835150   3: 0.009310332627900 

training_7037     6: 0.789718159352544   8: 0.074041997400668   0: 0.040569918312079   4: 0.020810957630062   5: 0.019415307206055   7: 0.011475294099970   1: 0.010998097991796   3: 0.010990501426239   9: 0.010989916713667   2: 0.010989849866920 

training_7039     1: 0.765790129276285   5: 0.026026503851921   0: 0.026025442015888   6: 0.026024623559992   4: 0.026023909867126   9: 0.026022737984002   3: 0.026021818657470   8: 0.026021655853951   7: 0.026021641188346   2: 0.026021537745020 

training_704      6: 0.411123845930923   1: 0.281523685265084   7: 0.173413325966694   8: 0.033198682913060   0: 0.031650301029098   3: 0.013928584909659   5: 0.013791509971955   2: 0.013791405217845   9: 0.013790475953459   4: 0.013788182842224 

training_7041     1: 0.766710876832265   6: 0.099350033317522   0: 0.033359400302471   7: 0.014445038660538   5: 0.014365610534271   3: 0.014359385272656   9: 0.014353101278691   4: 0.014352516968710   2: 0.014352052918614   8: 0.014351983914262 

training_7043     6: 0.758809765723296   5: 0.140573366829147   9: 0.020530450127220   0: 0.012024309279684   1: 0.011361634804697   8: 0.011340604037151   7: 0.011340191113500   4: 0.011339938011179   2: 0.011339897459145   3: 0.011339842614982 

training_7045     5: 0.614463322898526   6: 0.243272607710358   7: 0.017790650299345   3: 0.017787609693612   1: 0.017784404645381   0: 0.017781650485163   8: 0.017780592411391   9: 0.017780416334214   4: 0.017779781372774   2: 0.017778964149236 

training_7046     0: 0.497883396549481   8: 0.237277304666848   5: 0.122646490381126   6: 0.020320782569047   1: 0.020316313687428   4: 0.020311927734091   9: 0.020311811145510   2: 0.020310973349950   3: 0.020310674791047   7: 0.020310325125473 

training_7047     6: 0.772228889322524   1: 0.075080181022911   5: 0.019098177516639   0: 0.019095015807170   9: 0.019087723635178   7: 0.019085939950161   8: 0.019081558753487   4: 0.019080977057308   3: 0.019080939966317   2: 0.019080596968306 

training_7048     4: 0.748870117726027   5: 0.070639287447570   6: 0.022562595166747   9: 0.022562252018680   1: 0.022561508018468   0: 0.022561315548177   8: 0.022560792615774   3: 0.022560783884118   2: 0.022560712102092   7: 0.022560635472347 

training_7049     6: 0.480859155812476   9: 0.355289946490883   5: 0.020491406519967   4: 0.020485578750459   8: 0.020482450734305   1: 0.020480564848376   0: 0.020479666860823   7: 0.020477349625843   3: 0.020477094302310   2: 0.020476786054559 

training_7052     5: 0.747893688874712   4: 0.028014539257066   0: 0.028011776111695   3: 0.028011575391958   8: 0.028011574521638   6: 0.028011393738596   2: 0.028011391423423   9: 0.028011363405252   1: 0.028011353191900   7: 0.028011344083760 

training_7057     4: 0.509090561350856   6: 0.264396037808444   0: 0.028322169240928   1: 0.028321046784509   5: 0.028317398332900   2: 0.028317055448882   9: 0.028310348959436   7: 0.028309150266204   3: 0.028308342159912   8: 0.028307889647929 

training_7058     5: 0.547923876539111   0: 0.138605058997112   1: 0.117185164614390   8: 0.069711994855306   2: 0.034493318200930   3: 0.032023675616681   6: 0.015022207001067   9: 0.015012404727129   4: 0.015011902278493   7: 0.015010397169781 

training_706      1: 0.804719723358970   9: 0.041967176767465   6: 0.034208476768708   0: 0.017194715898349   5: 0.016993932677072   4: 0.016993610089993   8: 0.016981356638391   7: 0.016980732964269   3: 0.016980237123920   2: 0.016980037712863 

training_7060     5: 0.654850774467374   4: 0.128628198318489   0: 0.099831706566818   1: 0.016674766177504   6: 0.016671388221479   9: 0.016668943602617   2: 0.016668776113205   3: 0.016668528327213   8: 0.016668459823959   7: 0.016668458381342 

training_7061     5: 0.791724065372048   9: 0.066423560730557   3: 0.033701438767846   4: 0.028352977876358   0: 0.013409680669602   1: 0.013281631104270   6: 0.013278285489278   8: 0.013277872679527   7: 0.013275299711986   2: 0.013275187598529 

training_7062     6: 0.788168334043126   0: 0.105727181949288   1: 0.021392733139661   8: 0.014743300492821   5: 0.011669054179309   9: 0.011664158698870   7: 0.011660330472419   4: 0.011659591380081   2: 0.011657690634849   3: 0.011657625009575 

training_7063     5: 0.811855263440254   1: 0.020905904439805   6: 0.020905893576379   0: 0.020905782511487   3: 0.020904904839089   4: 0.020904697470322   7: 0.020904409039457   9: 0.020904393641356   8: 0.020904380374423   2: 0.020904370667427 

training_7064     6: 0.705415057843225   5: 0.102304138304978   1: 0.024042533898652   0: 0.024039975878904   4: 0.024035117815385   2: 0.024033439062485   3: 0.024032885238154   8: 0.024032559227163   9: 0.024032430464235   7: 0.024031862266819 

training_7065     5: 0.530414175687465   2: 0.300987955732750   8: 0.055824009544793   6: 0.016116205355025   1: 0.016116154297037   0: 0.016111380198628   9: 0.016108508922728   4: 0.016107754601019   7: 0.016107403828750   3: 0.016106451831805 

training_7066     6: 0.518841504389317   1: 0.287690670171115   5: 0.101792897348291   0: 0.013139451744413   4: 0.013091324233329   7: 0.013089439673676   9: 0.013089260428111   8: 0.013088526358053   3: 0.013088519515943   2: 0.013088406137751 

training_7067     2: 0.455800958502147   6: 0.299198676544906   4: 0.081993026288284   3: 0.069065954404447   1: 0.015782531830516   5: 0.015652276596290   0: 0.015634291782110   8: 0.015626719681892   9: 0.015622827005430   7: 0.015622737363977 

training_7068     4: 0.520496040649087   6: 0.153629670146981   1: 0.152987865974886   0: 0.057345250416233   5: 0.019258971009006   2: 0.019257122972724   8: 0.019256747605590   9: 0.019256429670445   7: 0.019256251224402   3: 0.019255650330646 

training_707      5: 0.585005930405808   7: 0.217547649393782   6: 0.024686398688241   0: 0.024680423674723   3: 0.024680281407144   4: 0.024680129927774   8: 0.024679963685596   1: 0.024679791920100   2: 0.024679785755938   9: 0.024679645140895 

training_7070     6: 0.562908410803688   7: 0.300388947447222   5: 0.017105934841913   8: 0.017086505573509   3: 0.017086398524309   4: 0.017086240841291   1: 0.017085549098651   9: 0.017084645350791   0: 0.017084232968896   2: 0.017083134549730 

training_7071     6: 0.774107066587131   8: 0.064325489449353   0: 0.058436906330482   7: 0.028851691446627   1: 0.019073128309581   3: 0.011044873629497   5: 0.011040640701171   4: 0.011040170121251   9: 0.011040054472533   2: 0.011039978952375 

training_7072     5: 0.557241119473925   7: 0.247470428421563   6: 0.024413857323182   4: 0.024413522964582   0: 0.024411049869876   8: 0.024410271862044   9: 0.024410171458555   3: 0.024410014351578   1: 0.024409895200606   2: 0.024409669074089 

training_7073     0: 0.345432259377294   1: 0.245002551384807   5: 0.190421720611629   6: 0.127906510141338   2: 0.015249512652568   4: 0.015199770953501   9: 0.015198185963099   8: 0.015196758168060   7: 0.015196489738577   3: 0.015196241009128 

training_7074     5: 0.782818508997751   4: 0.024135213269231   8: 0.024131135435093   9: 0.024130850375867   3: 0.024130822339231   2: 0.024130754590290   0: 0.024130727734505   7: 0.024130685660173   1: 0.024130684262091   6: 0.024130617335769 

training_7075     6: 0.586932846451598   1: 0.164035394139030   0: 0.148399889362054   8: 0.014391936583900   5: 0.014375588146012   4: 0.014373494302537   9: 0.014373390501096   3: 0.014372845140125   2: 0.014372591703274   7: 0.014372023670375 

training_7076     5: 0.772702296574557   6: 0.025256082543414   8: 0.025256066371811   9: 0.025255717003634   4: 0.025255250354354   0: 0.025255233178118   3: 0.025255107439259   1: 0.025254925969212   7: 0.025254707547536   2: 0.025254613018106 

training_7077     5: 0.778648741219466   3: 0.024595472369540   0: 0.024595078184536   1: 0.024594961972120   4: 0.024594537378096   6: 0.024594342296726   2: 0.024594336427168   7: 0.024594200892721   8: 0.024594165701366   9: 0.024594163558261 

training_7078     5: 0.615675886272704   0: 0.235833969170277   6: 0.018562662849495   4: 0.018562351726696   1: 0.018561295149751   9: 0.018561176136463   7: 0.018560867026413   8: 0.018560735896292   3: 0.018560541606578   2: 0.018560514165332 

training_7079     4: 0.764348981792258   5: 0.026195054604830   6: 0.026183866511878   0: 0.026182768905198   8: 0.026182055339752   9: 0.026181649683950   1: 0.026181537415825   2: 0.026181485260445   3: 0.026181353124624   7: 0.026181247361239 

training_708      9: 0.809776826853587   8: 0.021197093870228   7: 0.021145626008811   6: 0.021144313416317   5: 0.021128028387550   2: 0.021123929987938   0: 0.021121681483305   1: 0.021121423825579   4: 0.021120621998963   3: 0.021120454167723 

training_7080     9: 0.583380753260821   6: 0.259430952367025   8: 0.019662916881408   1: 0.019648316014990   5: 0.019647293715669   0: 0.019646470516690   3: 0.019646221587918   4: 0.019646075961870   7: 0.019645586552853   2: 0.019645413140757 

training_7083     5: 0.822074771724208   4: 0.019770773894687   6: 0.019770714909009   1: 0.019770373624017   0: 0.019770034184625   9: 0.019769033758248   2: 0.019768830434786   8: 0.019768717753348   7: 0.019768412666317   3: 0.019768337050755 

training_7085     5: 0.326415703116615   2: 0.190709431468814   6: 0.189794437466687   9: 0.180594594362115   0: 0.018756039670065   1: 0.018750880292616   3: 0.018745260187804   8: 0.018744946676489   7: 0.018744370514951   4: 0.018744336243844 

training_7087     6: 0.531109066895272   3: 0.224110605096180   9: 0.074900832713580   1: 0.053765531102685   5: 0.019354364367278   4: 0.019353426392489   2: 0.019352158155087   8: 0.019351788629436   0: 0.019351695336079   7: 0.019350531311913 

training_7088     6: 0.481900661204837   0: 0.228921543135960   1: 0.190121106429313   5: 0.030465213536691   8: 0.019993043183017   4: 0.010951802500392   7: 0.009645702966623   3: 0.009371339920502   9: 0.009343503685994   2: 0.009286083436671 

training_709      1: 0.555703553326515   9: 0.205837550150020   6: 0.029809625590156   5: 0.029808696357727   0: 0.029808424018532   4: 0.029807407954156   8: 0.029806703122094   2: 0.029806061078526   7: 0.029806019152026   3: 0.029805959250248 

training_7090     1: 0.595173613160805   0: 0.143911853375108   6: 0.089962895056055   2: 0.052997310897502   4: 0.019666162159610   5: 0.019660604578912   7: 0.019659261067595   8: 0.019656729255880   9: 0.019655894425292   3: 0.019655676023240 

training_7092     4: 0.813317380884741   5: 0.020747279065429   0: 0.020742308290228   6: 0.020742208647446   8: 0.020741900579503   1: 0.020741897563535   9: 0.020741836326611   2: 0.020741772360465   3: 0.020741723832441   7: 0.020741692449601 

training_7093     5: 0.377832376587597   1: 0.326768479219363   3: 0.117075941035585   0: 0.061200850434413   6: 0.019524992342432   8: 0.019521023127380   9: 0.019519496376923   4: 0.019519179979007   7: 0.019519141906165   2: 0.019518518991135 

training_7096     5: 0.667263445855839   7: 0.139890696483117   4: 0.024108833236917   6: 0.024105769597258   9: 0.024105672136678   8: 0.024105563686400   3: 0.024105045284276   1: 0.024105031277501   2: 0.024104975212786   0: 0.024104967229230 

training_7097     6: 0.657293961743565   9: 0.164439807080287   7: 0.056459718542025   1: 0.033458442971876   0: 0.014732206392506   5: 0.014723927543132   4: 0.014723184438252   8: 0.014723112822944   2: 0.014723091551187   3: 0.014722546914226 

training_7098     6: 0.740154834318722   5: 0.028879725592607   0: 0.028873974322750   9: 0.028871106520868   4: 0.028870626826434   8: 0.028870463526491   1: 0.028870457971131   7: 0.028869906823593   3: 0.028869728060189   2: 0.028869176037217 

training_7099     6: 0.814692264277151   0: 0.069357189618745   5: 0.014499110865375   1: 0.014498898305763   9: 0.014494611196916   4: 0.014492355724069   7: 0.014491800862641   8: 0.014491713645327   3: 0.014491029203031   2: 0.014491026300981 

training_71       5: 0.514962840220625   8: 0.296733729288347   3: 0.023538661272369   4: 0.023538396749079   0: 0.023537845665490   6: 0.023537832674448   1: 0.023537777344110   2: 0.023537723509527   7: 0.023537642341439   9: 0.023537550934566 

training_7100     9: 0.602669388043249   8: 0.220803016263686   6: 0.022068843491213   5: 0.022066650305373   0: 0.022065889153005   1: 0.022065666779699   4: 0.022065373460010   2: 0.022065232221076   7: 0.022065052518661   3: 0.022064887764026 

training_7101     0: 0.795046180855933   6: 0.022779342100333   8: 0.022772714477540   5: 0.022772714007714   1: 0.022772441116797   9: 0.022771929368106   7: 0.022771603875200   4: 0.022771252046978   2: 0.022771102538217   3: 0.022770719613182 

training_7102     0: 0.602409077211161   6: 0.272047984896488   5: 0.015698535581760   1: 0.015693646287354   4: 0.015693101375530   9: 0.015692658256621   3: 0.015691660562926   8: 0.015691635269940   7: 0.015691129129131   2: 0.015690571429088 

training_7103     6: 0.684823603498400   1: 0.176937760945243   2: 0.063225790313062   9: 0.010744296879356   0: 0.010739487084685   7: 0.010713688589087   8: 0.010710011271549   5: 0.010703843054476   3: 0.010700772154628   4: 0.010700746209514 

training_7104     6: 0.639199837593522   9: 0.146721135355399   1: 0.073137453896396   0: 0.020153791794788   5: 0.020134583193413   7: 0.020130799278993   8: 0.020130775373476   2: 0.020130752030635   3: 0.020130559029739   4: 0.020130312453638 

training_7106     0: 0.382261030723560   5: 0.315330008108492   4: 0.037814523747175   3: 0.037800050937959   2: 0.037799553377779   8: 0.037799521258715   7: 0.037799175029871   9: 0.037798886944031   1: 0.037798668855116   6: 0.037798581017301 

training_7107     0: 0.555855660119793   5: 0.282801954844617   4: 0.035027699429461   7: 0.030634966518489   1: 0.029009870248986   6: 0.013340358685004   9: 0.013333335716080   8: 0.013333017292469   2: 0.013331622302762   3: 0.013331514842339 

training_7109     1: 0.574812601405904   3: 0.156307543105548   7: 0.067286037814483   5: 0.047134969824418   2: 0.045598184214804   4: 0.022309576620941   0: 0.021689251505935   6: 0.021621490706939   9: 0.021620250040420   8: 0.021620094760608 

training_7110     1: 0.637775989461165   7: 0.215987451830168   6: 0.039651699027417   0: 0.015275779829431   5: 0.015219266371798   3: 0.015218402791204   4: 0.015218038189657   2: 0.015217813770007   8: 0.015217790035110   9: 0.015217768694043 

training_7111     0: 0.549143867207542   4: 0.152268167855985   6: 0.115936764083053   7: 0.071862234522288   5: 0.018815551562699   1: 0.018574415277677   9: 0.018350887642970   2: 0.018349876830651   3: 0.018349130683595   8: 0.018349104333541 

training_7113     5: 0.709301678406722   8: 0.079174664478527   0: 0.069645566092612   1: 0.020285545524071   4: 0.020267758561443   6: 0.020267084395940   3: 0.020264526472855   2: 0.020264412534866   9: 0.020264408300852   7: 0.020264355232113 

training_7115     4: 0.720171497129641   1: 0.100111042265289   5: 0.022470337074725   8: 0.022464133344702   6: 0.022463951681309   0: 0.022463906084502   9: 0.022463887732935   3: 0.022463766055383   2: 0.022463764840383   7: 0.022463713791131 

training_7117     9: 0.769273113951005   6: 0.025646306848347   5: 0.025644118753352   4: 0.025637794184348   0: 0.025635702641489   7: 0.025633549859277   1: 0.025633428853803   8: 0.025632733191185   3: 0.025631712946474   2: 0.025631538770720 

training_7119     6: 0.824695932147523   8: 0.054884488869859   9: 0.015061336831549   0: 0.015052303857458   5: 0.015051706064790   1: 0.015051394807421   3: 0.015050783050876   7: 0.015050775249452   2: 0.015050646824334   4: 0.015050632296737 

training_712      1: 0.459000431500123   0: 0.195216551449204   7: 0.123767923692169   5: 0.108096163690021   6: 0.018989538541461   4: 0.018988423265908   8: 0.018985884863143   2: 0.018985129960684   9: 0.018985009428196   3: 0.018984943609091 

training_7120     5: 0.830018725191100   0: 0.061852814585122   6: 0.013520568983032   9: 0.013519432044916   4: 0.013515606282237   1: 0.013515199312947   2: 0.013514700277291   8: 0.013514478063026   7: 0.013514273003177   3: 0.013514202257152 

training_7123     5: 0.264684745544039   9: 0.255966533018467   8: 0.251433855324974   4: 0.032568874232432   0: 0.032563501553953   3: 0.032557136239354   2: 0.032556914089312   1: 0.032556672361605   7: 0.032556176291067   6: 0.032555591344797 

training_7124     6: 0.657152356557715   8: 0.170584353046348   0: 0.038859037928445   1: 0.036147557753311   3: 0.030316281890302   5: 0.013394695902637   4: 0.013386691530108   2: 0.013386627503435   7: 0.013386243851997   9: 0.013386154035701 

training_7126     0: 0.443707014237189   6: 0.439662647470753   7: 0.018828151937518   1: 0.018363835788442   9: 0.013327780938577   3: 0.013278416267657   2: 0.013228279817664   5: 0.013203372992369   8: 0.013200949000814   4: 0.013199551549016 

training_7128     5: 0.677556150424021   9: 0.109323321535161   0: 0.058628680825223   1: 0.054433464062188   8: 0.016713554293141   7: 0.016671254754929   6: 0.016670498880416   4: 0.016669931662543   2: 0.016666579342900   3: 0.016666564219478 

training_7129     6: 0.398559583277851   9: 0.275954878618596   5: 0.124267093602340   7: 0.091835319959304   0: 0.018235636148635   4: 0.018230766029527   8: 0.018230393044860   1: 0.018229125604806   3: 0.018228924362080   2: 0.018228279352000 

training_7130     5: 0.639582721896152   6: 0.199473683180316   3: 0.036453877341096   0: 0.027357571999102   4: 0.016291198792997   8: 0.016224306773905   9: 0.016164601709539   1: 0.016152859983689   7: 0.016152216401316   2: 0.016146961921888 

training_7132     5: 0.692960231032431   8: 0.122308715577071   2: 0.023091859450472   0: 0.023091816156169   3: 0.023091682891501   6: 0.023091558006075   1: 0.023091425405147   4: 0.023091317583540   7: 0.023090715190375   9: 0.023090678707219 

training_7133     5: 0.785450722811112   4: 0.023841899011100   6: 0.023838836845792   8: 0.023838603679502   0: 0.023838389123302   3: 0.023838388540083   9: 0.023838372576101   2: 0.023838303583528   7: 0.023838263934310   1: 0.023838219895172 

training_7135     6: 0.758827164527465   0: 0.133842742833853   1: 0.028963064213093   9: 0.024248546204308   7: 0.009049367939353   8: 0.009024484633449   5: 0.009012500089687   3: 0.009011009088610   2: 0.009010963156950   4: 0.009010157313233 

training_7136     9: 0.582343979143377   6: 0.249332318660005   1: 0.021047583152055   0: 0.021042917483643   5: 0.021042123407813   4: 0.021039021275835   2: 0.021038693553341   3: 0.021037924931478   7: 0.021037793798358   8: 0.021037644594097 

training_7139     5: 0.757302628937050   7: 0.087608583512751   4: 0.019388933526661   9: 0.019387051562600   6: 0.019386503040262   8: 0.019385799400134   0: 0.019385396813643   1: 0.019385246142048   2: 0.019385231943694   3: 0.019384625121156 

training_714      1: 0.548480386600437   6: 0.221899969161748   0: 0.104306662701956   4: 0.051706864359542   8: 0.023300353456452   5: 0.010098254139927   2: 0.010053657065448   3: 0.010053580002575   7: 0.010051332564720   9: 0.010048939947195 

training_7141     5: 0.749934007042422   7: 0.077807667670301   6: 0.021533494451664   0: 0.021532903493115   1: 0.021532583458505   4: 0.021532169084378   9: 0.021532089764019   2: 0.021531825684594   8: 0.021531682480052   3: 0.021531576870949 

training_7143     6: 0.798682643318416   0: 0.070092550838731   4: 0.038786351101803   3: 0.013603482097562   7: 0.013163639764676   8: 0.013151248061037   9: 0.013132473099903   5: 0.013129972352468   1: 0.013129075361117   2: 0.013128564004288 

training_7146     5: 0.779895131416711   6: 0.024459403878189   1: 0.024457756627037   0: 0.024456532262820   4: 0.024455723931624   3: 0.024455544121838   9: 0.024455141027161   2: 0.024454971725518   7: 0.024454913281251   8: 0.024454881727850 

training_7148     5: 0.781471018272235   0: 0.024358613669687   6: 0.024286446421342   1: 0.024276769235459   7: 0.024270811284540   4: 0.024267640632310   3: 0.024267512973766   8: 0.024267086635356   2: 0.024267076788436   9: 0.024267024086871 

training_7149     5: 0.587729521299141   6: 0.176628434578373   0: 0.077986392501512   4: 0.038356242191670   8: 0.020039832414914   9: 0.019911430783981   1: 0.019857483534358   7: 0.019849987451224   2: 0.019820434150412   3: 0.019820241094415 

training_715      4: 0.792220099303595   5: 0.023092631825096   0: 0.023086174518000   6: 0.023086146093130   8: 0.023085944507477   3: 0.023085906043028   9: 0.023085796509453   2: 0.023085793533523   1: 0.023085767351264   7: 0.023085740315434 

training_7150     6: 0.627759869141446   9: 0.152608450891709   1: 0.114376395854633   0: 0.028369538193727   4: 0.012816862515522   5: 0.012815530795270   2: 0.012814339053441   8: 0.012813210410032   7: 0.012812978075120   3: 0.012812825069100 

training_7152     6: 0.774769195704842   2: 0.025046541503402   9: 0.025030064396573   1: 0.025024178414441   0: 0.025022702360294   4: 0.025022304094725   5: 0.025022153368087   7: 0.025021686402044   8: 0.025020678609303   3: 0.025020495146289 

training_7154     6: 0.468750076332268   8: 0.382361123926320   7: 0.029455189043531   5: 0.017063257444687   9: 0.017063031769919   0: 0.017062644361218   1: 0.017061759263075   3: 0.017061195428981   2: 0.017061095898345   4: 0.017060626531654 

training_7155     0: 0.482109179032193   6: 0.208383482103129   4: 0.122145600689104   1: 0.070732759694429   9: 0.059676259999724   5: 0.011453325949350   2: 0.011388834617082   8: 0.011370841992594   7: 0.011370040786709   3: 0.011369675135684 

training_7157     5: 0.799957577955656   6: 0.022234817425101   4: 0.022227560317089   7: 0.022227282940638   1: 0.022225957671735   0: 0.022225729194193   3: 0.022225617573929   9: 0.022225405817819   8: 0.022225102439707   2: 0.022224948664132 

training_7158     5: 0.669781451633144   6: 0.167386528561259   0: 0.020361068746380   1: 0.020356495390445   7: 0.020353088912864   9: 0.020352536231610   2: 0.020352443313338   3: 0.020352231677645   8: 0.020352127554379   4: 0.020352027978938 

training_7159     8: 0.657850613551486   6: 0.212095277801058   1: 0.016258125366614   0: 0.016258038560959   9: 0.016257055388629   5: 0.016256792453271   7: 0.016256241671772   4: 0.016256020637097   2: 0.016255989587917   3: 0.016255844981198 

training_7160     6: 0.587643704542108   5: 0.173248482463262   1: 0.069987568687517   8: 0.056476100863794   7: 0.018779531912550   0: 0.018776006302341   2: 0.018772449333365   9: 0.018772167452142   4: 0.018772056471052   3: 0.018771931971868 

training_7161     6: 0.692959284952814   5: 0.105865848601528   1: 0.084625063848970   0: 0.053303769621135   4: 0.010551563523166   9: 0.010543943029658   3: 0.010538981880662   8: 0.010537832384966   7: 0.010536890428839   2: 0.010536821728262 

training_7166     6: 0.317675773058387   8: 0.301641252010247   4: 0.220592020541547   9: 0.053395411714363   2: 0.017804882521942   5: 0.017779774832998   0: 0.017778373497956   1: 0.017778130137240   7: 0.017777288790056   3: 0.017777092895263 

training_7167     5: 0.823356724913201   6: 0.019647796892515   9: 0.019629117228600   0: 0.019626350695503   1: 0.019623945883925   4: 0.019623755794666   7: 0.019623597108295   8: 0.019623421534355   3: 0.019622873025284   2: 0.019622416923656 

training_7168     6: 0.434181829350231   0: 0.350360043066062   8: 0.072991699670891   1: 0.020355249672931   5: 0.020354182422874   4: 0.020353062033257   3: 0.020351855863771   7: 0.020351070027015   9: 0.020350855495792   2: 0.020350152397177 

training_7174     6: 0.761634761025337   4: 0.103198901496760   1: 0.038565292623181   0: 0.023126637746584   9: 0.012534525312166   2: 0.012291648321436   5: 0.012180235686542   3: 0.012156690043625   8: 0.012156037599724   7: 0.012155270144645 

training_7177     6: 0.547610897553892   9: 0.301699771662992   1: 0.038810102652897   0: 0.015984431948676   7: 0.015984141225301   5: 0.015984117837182   4: 0.015982184973781   8: 0.015981587210331   2: 0.015981531292190   3: 0.015981233642757 

training_718      6: 0.663147046509409   0: 0.124054520188524   1: 0.076044131822234   8: 0.044492897579449   3: 0.037702794086133   9: 0.017078749071059   7: 0.009631600990343   5: 0.009284009401394   4: 0.009283517987830   2: 0.009280732363625 

training_7184     5: 0.685573374820167   2: 0.144275282360380   4: 0.021275246671057   6: 0.021269193981938   8: 0.021268576926442   1: 0.021267944534804   0: 0.021267891203776   9: 0.021267760418648   7: 0.021267546879915   3: 0.021267182202874 

training_7185     5: 0.390715513429025   1: 0.326541956312617   4: 0.127491929930694   0: 0.022183149838141   6: 0.022181765302059   3: 0.022177709814330   9: 0.022177549495408   2: 0.022177060899461   8: 0.022176745549200   7: 0.022176619429064 

training_7188     6: 0.463663461602334   5: 0.325086595370661   8: 0.026410168768159   1: 0.026409473645441   4: 0.026407181997685   9: 0.026407012413836   7: 0.026405979419886   0: 0.026404572269743   2: 0.026402914186974   3: 0.026402640325280 

training_7189     5: 0.687324999088738   0: 0.100633463374215   1: 0.026507052471914   6: 0.026505712058792   9: 0.026505083916561   2: 0.026504866138256   3: 0.026504780592220   8: 0.026504741495166   7: 0.026504650835596   4: 0.026504650028542 

training_7190     5: 0.568299505062536   2: 0.216736332446121   4: 0.026874399850252   8: 0.026870327736341   6: 0.026870150862973   0: 0.026870114895418   9: 0.026869911668626   3: 0.026869864468409   7: 0.026869708938560   1: 0.026869684070765 

training_7191     5: 0.515591072860553   0: 0.292372819894265   4: 0.024013262804741   1: 0.024003855538884   6: 0.024003836506292   8: 0.024003306216344   2: 0.024003106347096   3: 0.024003006179506   9: 0.024002915571361   7: 0.024002818080959 

training_7192     4: 0.810416981330088   5: 0.021070922303492   6: 0.021064487297898   0: 0.021064118686467   9: 0.021064092154761   8: 0.021063997149056   1: 0.021063903592628   3: 0.021063873722304   2: 0.021063843327663   7: 0.021063780435642 

training_7193     5: 0.681669045044186   6: 0.071165457250419   0: 0.068680416920868   8: 0.066468487775751   4: 0.018671962886541   1: 0.018669744281870   7: 0.018669058831655   9: 0.018668647258161   2: 0.018668594595607   3: 0.018668585154942 

training_7196     6: 0.461916681240999   7: 0.248640346384220   9: 0.094988573652807   5: 0.082680339533143   3: 0.029801989235574   0: 0.016402359736165   1: 0.016399643214454   4: 0.016390964659688   8: 0.016389619810337   2: 0.016389482532613 

training_7199     1: 0.386374345222372   3: 0.182139787094633   4: 0.178482617004284   5: 0.080944167967983   0: 0.069862256324137   9: 0.020447650286520   6: 0.020447451821498   2: 0.020434798975696   8: 0.020433593999797   7: 0.020433331303080 

training_7204     8: 0.750806745339983   5: 0.027694331790326   6: 0.027689422094316   0: 0.027688341185765   4: 0.027687360380565   1: 0.027687084391369   9: 0.027686964270052   3: 0.027686867985720   2: 0.027686523323813   7: 0.027686359238091 

training_7205     6: 0.780736420407265   1: 0.024363523087322   7: 0.024363276466308   0: 0.024362867569420   9: 0.024362524221614   8: 0.024362389689649   5: 0.024362339500211   2: 0.024362236958574   4: 0.024362221479982   3: 0.024362200619655 

training_7207     8: 0.790109501245758   2: 0.064574303752435   0: 0.018168019006293   6: 0.018167153963657   1: 0.018164502377919   5: 0.018163868957762   9: 0.018163667577116   7: 0.018163166322808   4: 0.018163036326159   3: 0.018162780470093 

training_7208     5: 0.716912621606396   6: 0.031456837646002   0: 0.031455810772320   1: 0.031453821330223   8: 0.031453715306844   3: 0.031453598187034   7: 0.031453462744674   2: 0.031453430185697   9: 0.031453414363238   4: 0.031453287857572 

training_7209     1: 0.317165560306243   5: 0.305783154138046   7: 0.167228870106063   0: 0.078442086943206   6: 0.021898507890810   3: 0.021896530005601   2: 0.021896449438641   4: 0.021896368592571   8: 0.021896242141212   9: 0.021896230437610 

training_7212     5: 0.619799811606878   4: 0.193675840362006   0: 0.078115082441775   3: 0.015528078569736   6: 0.015482976402315   7: 0.015482326435136   9: 0.015479883568012   1: 0.015479112095961   8: 0.015478680099402   2: 0.015478208418779 

training_7215     6: 0.830055472991244   1: 0.018883316333318   0: 0.018883133111800   8: 0.018882989928404   5: 0.018882826193159   7: 0.018882802732543   9: 0.018882623826379   3: 0.018882321494930   2: 0.018882268112628   4: 0.018882245275593 

training_7216     5: 0.451039883780655   6: 0.370725387013988   9: 0.036994092816037   7: 0.036264006195476   3: 0.035356237815233   4: 0.014118633751485   0: 0.013877832622640   1: 0.013876478683357   2: 0.013873779095280   8: 0.013873668225849 

training_7217     5: 0.689681851210172   0: 0.081713464552066   1: 0.072107958796953   6: 0.022379210904898   9: 0.022353942019838   8: 0.022353516898463   7: 0.022352670969772   2: 0.022352552660981   3: 0.022352425354074   4: 0.022352406632782 

training_7218     0: 0.589823086599040   6: 0.130984509654734   1: 0.105181545899293   3: 0.065563994456820   5: 0.018079561684403   2: 0.018074547316850   4: 0.018074264967775   8: 0.018073331162144   9: 0.018072680341155   7: 0.018072477917784 

training_722      5: 0.751148386246937   6: 0.027650784742492   2: 0.027650736289151   4: 0.027650616420483   1: 0.027650391456166   3: 0.027650164400177   0: 0.027649940277328   9: 0.027649730749144   7: 0.027649703892002   8: 0.027649545526121 

training_7220     1: 0.407164506152497   7: 0.390897023163806   8: 0.025256271313074   5: 0.025248160841246   6: 0.025245509858944   0: 0.025241852706048   9: 0.025237180597474   4: 0.025237160375948   2: 0.025236847422402   3: 0.025235487568562 

training_7221     6: 0.733577936380923   1: 0.096549710505743   0: 0.021554432690153   5: 0.021216708942695   9: 0.021188910191690   8: 0.021184542516646   3: 0.021184129784756   4: 0.021182029076118   7: 0.021181756908791   2: 0.021179843002486 

training_7222     6: 0.796742519125898   0: 0.051968120844896   7: 0.040873554567976   5: 0.040647424221240   9: 0.011634424310690   1: 0.011627125879387   4: 0.011626967209228   3: 0.011626925752379   8: 0.011626685191436   2: 0.011626252896870 

training_7225     5: 0.456147998482157   9: 0.318877366385109   7: 0.066419418520103   1: 0.022656057675013   0: 0.022652865541997   6: 0.022651552763639   4: 0.022649559359992   2: 0.022648798467768   3: 0.022648327487225   8: 0.022648055316996 

training_7226     5: 0.811503988557921   4: 0.020945889486688   1: 0.020944320357786   0: 0.020943847370048   9: 0.020943807228807   6: 0.020943779369175   8: 0.020943638346469   3: 0.020943631878717   2: 0.020943626678526   7: 0.020943470725862 

training_7229     5: 0.814570679261790   4: 0.020609326506369   1: 0.020602737643240   8: 0.020602625984449   6: 0.020602607687730   0: 0.020602544752963   9: 0.020602465610320   3: 0.020602373775770   2: 0.020602361789546   7: 0.020602276987823 

training_7234     5: 0.416651067627414   3: 0.393911055174452   7: 0.057436599953401   1: 0.018881712341711   6: 0.018876282165931   0: 0.018868880728916   9: 0.018844059503528   2: 0.018843867529444   4: 0.018843782096677   8: 0.018842692878526 

training_7235     5: 0.506922236772534   8: 0.298081489336470   6: 0.024375554058530   3: 0.024374862905976   0: 0.024374794242153   4: 0.024374567625454   1: 0.024374477813866   2: 0.024374115353353   9: 0.024373980939915   7: 0.024373920951749 

training_724      1: 0.490617704408985   0: 0.240203706371168   6: 0.088196001799944   2: 0.085701139285992   5: 0.015916454566275   9: 0.015873510230271   4: 0.015873251381321   8: 0.015872944872840   7: 0.015872650054766   3: 0.015872637028439 

training_7240     0: 0.448124569980370   6: 0.425343887221125   8: 0.026031764421898   1: 0.014361090187680   5: 0.014358447904968   9: 0.014356346207555   7: 0.014356037565270   2: 0.014356014810627   4: 0.014355991383661   3: 0.014355850316845 

training_7244     5: 0.515014919338938   8: 0.300358564805759   4: 0.023080282934428   2: 0.023079595970984   6: 0.023078502316250   1: 0.023078070542730   0: 0.023077884476675   3: 0.023077432265600   9: 0.023077416800659   7: 0.023077330547977 

training_7245     5: 0.603396857335468   0: 0.228013598293702   1: 0.021074265874974   4: 0.021074011693032   6: 0.021073808279465   2: 0.021073676645822   3: 0.021073647987870   8: 0.021073428670372   9: 0.021073386794519   7: 0.021073318424778 

training_7247     4: 0.494848228874800   7: 0.308005979603057   1: 0.024689356467427   5: 0.024662768035610   6: 0.024642262415297   2: 0.024634432002629   0: 0.024634278787383   9: 0.024629758295178   8: 0.024629262564374   3: 0.024623672954246 

training_725      1: 0.436064289691544   5: 0.379975129871971   0: 0.052537182860701   4: 0.018781543494174   6: 0.018780028996817   9: 0.018773643485501   8: 0.018772645172431   3: 0.018771882078336   2: 0.018771831014543   7: 0.018771823333982 

training_7250     5: 0.407669215701919   3: 0.392911772660571   4: 0.024928266502469   0: 0.024927365715170   6: 0.024927334505364   8: 0.024927307355176   7: 0.024927255818776   1: 0.024927253376000   2: 0.024927192509811   9: 0.024927035854744 

training_7253     0: 0.670799543719526   1: 0.114929894860633   6: 0.046491121294436   5: 0.024233438707241   2: 0.024023370672602   4: 0.023905204334493   7: 0.023904664759861   9: 0.023904478737761   8: 0.023904445064300   3: 0.023903837849148 

training_7256     2: 0.637896402648830   5: 0.040310883349194   4: 0.040304808422423   6: 0.040228813620274   0: 0.040213844246813   8: 0.040212096828966   9: 0.040209297515425   7: 0.040208405855916   3: 0.040207833057722   1: 0.040207614454437 

training_7259     5: 0.813903536213462   1: 0.020685059808082   6: 0.020684878548920   9: 0.020676971177500   0: 0.020676482028569   7: 0.020675780737851   8: 0.020675299718827   4: 0.020674596602024   2: 0.020673832019183   3: 0.020673563145583 

training_7260     6: 0.437827853859229   1: 0.283064006083367   5: 0.102485571367543   4: 0.080569886818286   8: 0.021082217794994   0: 0.015327155800478   9: 0.014967412835080   2: 0.014892712711929   7: 0.014891917973893   3: 0.014891264755202 

training_7261     5: 0.422805086097248   4: 0.414385746961773   6: 0.020352155103214   1: 0.020351352776841   0: 0.020351323747573   9: 0.020351265577140   7: 0.020351000084698   8: 0.020350946023844   2: 0.020350599852079   3: 0.020350523775591 

training_7263     6: 0.396060774205070   0: 0.359997945567870   9: 0.100142732970735   8: 0.048521571216478   3: 0.028013775422335   2: 0.018878005921153   1: 0.012125766424228   5: 0.012087913135601   4: 0.012086046230626   7: 0.012085468905905 

training_7264     5: 0.650797746573810   0: 0.220709173064455   2: 0.016078552129737   4: 0.016061452926433   6: 0.016059724827542   1: 0.016059421600113   8: 0.016059076380571   9: 0.016058496005959   7: 0.016058197638250   3: 0.016058158853129 

training_7266     5: 0.784017182576407   1: 0.024000431193812   6: 0.023999305869672   2: 0.023999154376728   0: 0.023998021551915   3: 0.023997688678114   4: 0.023997582253889   9: 0.023996914924194   7: 0.023996861486644   8: 0.023996857088626 

training_7267     5: 0.774982669214057   3: 0.025002821966831   4: 0.025002201108768   6: 0.025001798493177   1: 0.025001781657227   0: 0.025001775102968   2: 0.025001768823903   7: 0.025001750985938   9: 0.025001717945803   8: 0.025001714701327 

training_7272     5: 0.745813268343489   0: 0.077871083380217   4: 0.022043976313279   6: 0.022041521237118   9: 0.022041118312659   1: 0.022038791231992   8: 0.022037820649768   7: 0.022037742982206   3: 0.022037354490326   2: 0.022037323058948 

training_7275     5: 0.787714011634619   6: 0.023590969661921   7: 0.023587657715125   1: 0.023587245208922   9: 0.023587165158209   8: 0.023586985321257   0: 0.023586626460906   2: 0.023586492611420   3: 0.023586447092803   4: 0.023586399134817 

training_7276     4: 0.763927391317112   5: 0.026240301234890   8: 0.026229216473149   9: 0.026229197360425   3: 0.026229141500652   0: 0.026229105121076   2: 0.026229041290640   1: 0.026228964115739   7: 0.026228833121896   6: 0.026228808464422 

training_7277     5: 0.699211700550959   0: 0.110385011540061   6: 0.023811663882101   8: 0.023799649090702   3: 0.023799365009714   4: 0.023799004030170   1: 0.023798726654080   2: 0.023798444562321   7: 0.023798287330808   9: 0.023798147349085 

training_7278     5: 0.639467848287979   1: 0.175690725538523   0: 0.023114003175490   6: 0.023106737270785   7: 0.023103967553326   3: 0.023103887020186   4: 0.023103558795244   8: 0.023103184380452   2: 0.023103069490754   9: 0.023103018487262 

training_7279     2: 0.410922104952019   5: 0.388537908463243   3: 0.025068547712092   4: 0.025067977178603   8: 0.025067373510196   0: 0.025067359375488   6: 0.025067358175616   1: 0.025067161407227   7: 0.025067139600495   9: 0.025067069625021 

training_728      5: 0.667507998725094   4: 0.199744516574895   6: 0.016603595679530   0: 0.016601205074791   1: 0.016598610946101   2: 0.016590314150647   9: 0.016588949329155   7: 0.016588455226386   8: 0.016588397848745   3: 0.016587956444655 

training_7286     5: 0.725553026389181   1: 0.094073910169582   6: 0.022547415623830   0: 0.022547255893875   4: 0.022547044461578   3: 0.022546697805575   9: 0.022546323827532   2: 0.022546203152368   8: 0.022546120833408   7: 0.022546001843071 

training_7287     6: 0.701288715173309   2: 0.160523181505620   7: 0.033781204468868   4: 0.014931286433727   5: 0.014916175806242   9: 0.014913170372910   0: 0.014912084032287   1: 0.014911940379978   8: 0.014911401780076   3: 0.014910840046982 

training_7296     5: 0.445670424924918   1: 0.373197618933680   6: 0.022658262058102   2: 0.022649541444865   0: 0.022642988914798   8: 0.022639225605246   3: 0.022637969870176   4: 0.022634897703609   9: 0.022634866444983   7: 0.022634204099625 

training_7297     5: 0.659563182438424   9: 0.145780704070150   8: 0.024333761151364   6: 0.024332662946004   0: 0.024331974969078   4: 0.024331902785204   3: 0.024331796514078   1: 0.024331507432135   2: 0.024331289708972   7: 0.024331217984592 

training_730      9: 0.481165665547015   6: 0.302695998538703   8: 0.069057416804401   1: 0.054808350249096   7: 0.023397206992277   3: 0.016614708546432   0: 0.013440351464848   5: 0.013203935122588   4: 0.012831656685219   2: 0.012784710049422 

training_7302     4: 0.710037201929508   7: 0.126190135209744   5: 0.020478747267004   6: 0.020473513253758   0: 0.020471874957165   1: 0.020470261369021   8: 0.020469986022491   9: 0.020469585496450   2: 0.020469464021773   3: 0.020469230473085 

training_7304     6: 0.687170100036219   1: 0.125903654975674   0: 0.119366728384503   7: 0.009660073576326   4: 0.009651935059807   9: 0.009651039095509   5: 0.009649481632364   2: 0.009649145784882   8: 0.009649035549101   3: 0.009648805905616 

training_7305     1: 0.707146263131041   6: 0.084529994313226   5: 0.047514039313434   9: 0.046202403858854   0: 0.019102300774929   4: 0.019101229307995   2: 0.019101025531115   3: 0.019101018845797   8: 0.019100943312876   7: 0.019100781610733 

training_7308     6: 0.834653044541682   0: 0.049952455954056   1: 0.036391819939670   5: 0.011289713237022   7: 0.011289572568611   8: 0.011289320012024   2: 0.011284284366526   4: 0.011283735505051   9: 0.011283682173182   3: 0.011282371702175 

training_731      4: 0.810857385365644   5: 0.021022435692379   8: 0.021015349864934   9: 0.021015212566747   1: 0.021015201326266   0: 0.021015040460701   6: 0.021015023366953   2: 0.021014844272535   3: 0.021014812960574   7: 0.021014694123268 

training_7310     6: 0.628624547844501   0: 0.282668149156695   3: 0.011199909018517   1: 0.011088426895996   9: 0.011070796813824   8: 0.011070441851496   5: 0.011069756324320   4: 0.011069435416779   7: 0.011069273280876   2: 0.011069263396997 

training_7311     6: 0.590885369113544   1: 0.217339389732891   8: 0.073441823523320   3: 0.034891208939412   5: 0.013907777893632   0: 0.013907394462424   2: 0.013906946194752   9: 0.013906807808337   7: 0.013906655668458   4: 0.013906626663230 

training_7312     6: 0.604736056304339   0: 0.180346885174315   5: 0.119988772295065   8: 0.013576661322459   1: 0.013561173707585   3: 0.013560425343364   9: 0.013558095879060   7: 0.013557661972121   2: 0.013557206499272   4: 0.013557061502420 

training_7313     6: 0.720108111495289   0: 0.150719992249408   1: 0.051735392705429   8: 0.017598823241436   9: 0.011382724351634   7: 0.009930174674130   5: 0.009633937843623   4: 0.009630351757002   2: 0.009630295535954   3: 0.009630196146095 

training_7314     6: 0.628606991166734   0: 0.113914472589057   5: 0.109206301904212   1: 0.048043194805159   8: 0.016709797073848   7: 0.016704693747360   9: 0.016703779374423   2: 0.016703767270226   4: 0.016703665931295   3: 0.016703336137685 

training_7315     5: 0.437189109881928   3: 0.173136950897332   6: 0.117941763565813   0: 0.110447358249870   7: 0.052639535126364   4: 0.043312606268815   1: 0.016341036821358   8: 0.016331879961998   9: 0.016330312381178   2: 0.016329446845344 

training_7317     5: 0.772762663447877   0: 0.025248977471028   1: 0.025248963829057   4: 0.025248778445640   6: 0.025248620616857   3: 0.025248538045503   2: 0.025248456364176   8: 0.025248385118309   7: 0.025248323059330   9: 0.025248293602224 

training_7318     3: 0.377320801002427   6: 0.344118389579412   7: 0.078032888928691   9: 0.053217575357290   4: 0.051793353003486   5: 0.019107704332265   0: 0.019106210698275   1: 0.019102090659974   8: 0.019102056787499   2: 0.019098929650680 

training_7319     1: 0.728513553978385   0: 0.108012116742611   8: 0.027225974036952   6: 0.019527085243916   4: 0.019456574786056   5: 0.019453761134988   7: 0.019452969313624   9: 0.019452890041979   2: 0.019452582634534   3: 0.019452492086955 

training_732      5: 0.535402566991586   1: 0.269560495363831   2: 0.075070301058096   6: 0.017145176506239   0: 0.017142114817336   8: 0.017137859868799   9: 0.017135885767300   7: 0.017135540634742   4: 0.017135180952707   3: 0.017134878039363 

training_7320     5: 0.775620000880137   4: 0.024931911824399   3: 0.024931787940889   0: 0.024930998762361   6: 0.024930950523943   8: 0.024930931993269   2: 0.024930909965375   1: 0.024930901658438   7: 0.024930817839461   9: 0.024930788611729 

training_7321     9: 0.728821065350131   6: 0.030142898016885   0: 0.030134360688215   8: 0.030133624825625   1: 0.030131551600454   5: 0.030129181991864   7: 0.030127413157570   3: 0.030126921697902   2: 0.030126915416660   4: 0.030126067254694 

training_7322     6: 0.484490871059114   5: 0.163440755280013   2: 0.157785636013268   0: 0.051265249832767   4: 0.049872227833408   3: 0.018631795584560   8: 0.018629689239678   1: 0.018628996231769   9: 0.018627631887543   7: 0.018627147037880 

training_7323     6: 0.669842752955001   1: 0.130558615228072   5: 0.096007078893838   0: 0.026501862619943   4: 0.012849767829928   9: 0.012849307439366   3: 0.012849018724873   8: 0.012847803793426   7: 0.012847028270235   2: 0.012846764245318 

training_7326     6: 0.654068940700888   0: 0.139055188704370   1: 0.068945032942884   8: 0.056589676997109   5: 0.024419429326466   7: 0.011387629575613   9: 0.011385925491575   3: 0.011383238923389   4: 0.011382561002702   2: 0.011382376335002 

training_7329     9: 0.403334368492081   5: 0.201176534429693   3: 0.185629508243646   6: 0.029988021195756   4: 0.029981760397752   1: 0.029979654747296   0: 0.029979307793102   2: 0.029977316291666   7: 0.029976820040058   8: 0.029976708368949 

training_733      1: 0.681462041359012   9: 0.137799769404490   0: 0.036103290160205   5: 0.020697572331384   4: 0.020692653346744   6: 0.020653314084643   7: 0.020649506779241   8: 0.020648245119893   3: 0.020648119554477   2: 0.020645487859910 

training_7330     5: 0.774187500596608   1: 0.074126306073429   4: 0.018964722749170   6: 0.018960354206177   8: 0.018960346560379   0: 0.018960258736495   9: 0.018960177436452   3: 0.018960139538334   2: 0.018960114967218   7: 0.018960079135740 

training_7331     5: 0.592379154447712   0: 0.127046912384506   6: 0.120835149997950   1: 0.022823975484796   4: 0.022821983610357   8: 0.022818655264506   3: 0.022818634668488   9: 0.022818553694575   2: 0.022818493253513   7: 0.022818487193598 

training_7332     6: 0.649165319265160   0: 0.128586871783637   4: 0.077876180079590   3: 0.033235965210947   2: 0.028979656484572   7: 0.016495731834183   1: 0.016450571008439   9: 0.016410248089092   5: 0.016407111191658   8: 0.016392345052722 

training_7336     6: 0.785280844080011   0: 0.084528583292561   7: 0.028844894674501   3: 0.014479934512066   5: 0.014478937673816   1: 0.014477613099904   2: 0.014477605251179   4: 0.014477508436835   9: 0.014477102721785   8: 0.014476976257341 

training_7337     0: 0.578958452344070   2: 0.154770190422350   5: 0.140787707368488   6: 0.017966044419386   9: 0.017965869950948   1: 0.017915268203940   4: 0.017911304927032   8: 0.017909053370227   7: 0.017908096422938   3: 0.017908012570620 

training_7338     5: 0.758208626086687   7: 0.080502613473981   4: 0.020164372400859   0: 0.020161919645207   6: 0.020160620654136   1: 0.020160548067903   8: 0.020160338334792   9: 0.020160332437512   2: 0.020160316726168   3: 0.020160312172754 

training_7339     7: 0.448008708757812   4: 0.301507494125442   5: 0.031322676598512   1: 0.031312619202400   3: 0.031308521693674   8: 0.031308454773522   2: 0.031308171680836   0: 0.031307909820349   9: 0.031307889113942   6: 0.031307554233511 

training_734      4: 0.777163838657637   5: 0.024763392517427   8: 0.024759295026875   3: 0.024759121642586   0: 0.024759096908157   2: 0.024759088692836   9: 0.024759075687071   6: 0.024759057324359   1: 0.024759018216156   7: 0.024759015326895 

training_7341     5: 0.640254349331528   8: 0.098037898610442   2: 0.071667393841575   0: 0.069711132000872   6: 0.020082791295367   4: 0.020072019165428   1: 0.020044259736755   7: 0.020043627821306   9: 0.020043271692395   3: 0.020043256504332 

training_7342     0: 0.414634987082387   2: 0.355408887047883   7: 0.099716563844745   6: 0.018719915845421   1: 0.018610711462819   5: 0.018588504294740   8: 0.018582261374300   4: 0.018580559304551   9: 0.018579569123432   3: 0.018578040619722 

training_7344     0: 0.436091024622860   4: 0.274929231135116   9: 0.109122920894866   3: 0.054906860237103   6: 0.020831648465045   7: 0.020831053070868   5: 0.020823020833324   1: 0.020822345118747   8: 0.020821168610686   2: 0.020820727011386 

training_7346     5: 0.786832486456521   1: 0.023689405215877   3: 0.023685061727452   0: 0.023685026374846   4: 0.023685016114911   6: 0.023684993813793   2: 0.023684618634222   8: 0.023684525279748   7: 0.023684474031396   9: 0.023684392351234 

training_7349     5: 0.522174547606260   9: 0.259524719945662   3: 0.067603549810211   6: 0.021529687434849   1: 0.021528971892790   0: 0.021528804226803   8: 0.021527894652683   2: 0.021527824266907   4: 0.021527234621149   7: 0.021526765542686 

training_735      6: 0.522654035668728   5: 0.228908212701681   0: 0.067554413610416   2: 0.060273735943556   1: 0.020104388088030   4: 0.020101879071680   9: 0.020101033978859   7: 0.020100830494577   3: 0.020100830480461   8: 0.020100639962012 

training_7352     6: 0.456622741290151   4: 0.375948795836140   0: 0.020950577914666   1: 0.020948144571895   9: 0.020929197153879   5: 0.020925273238754   2: 0.020920021666505   8: 0.020918682661663   7: 0.020918360902530   3: 0.020918204763817 

training_7353     1: 0.475874317220409   3: 0.288217629669859   0: 0.081736225709506   9: 0.022089993367067   6: 0.022015627938498   5: 0.022014932764830   4: 0.022013770852885   8: 0.022012707687943   2: 0.022012695147559   7: 0.022012099641445 

training_7354     7: 0.571001292904503   3: 0.162476459202481   2: 0.092727685558056   9: 0.056315595903793   1: 0.019590765109946   5: 0.019589620277944   0: 0.019581550789074   6: 0.019577976786260   4: 0.019570800325344   8: 0.019568253142597 

training_7355     6: 0.727156408751069   0: 0.140724898502146   5: 0.017644992108216   1: 0.016416213494158   3: 0.016388280811949   2: 0.016350093309348   4: 0.016332854444172   9: 0.016330941109800   7: 0.016328175849932   8: 0.016327141619208 

training_7356     6: 0.801287114894675   0: 0.087697622207764   1: 0.020048911234255   8: 0.016150501195814   3: 0.012521989679607   5: 0.012460462784361   4: 0.012458983984389   7: 0.012458636987994   9: 0.012458233007908   2: 0.012457544023232 

training_7357     9: 0.369311578324495   6: 0.367116849494937   5: 0.093358650825996   8: 0.039377131107417   7: 0.035871716901462   1: 0.033110223852896   3: 0.015467598661849   0: 0.015467273788949   2: 0.015460021820327   4: 0.015458955221670 

training_7358     5: 0.806172311374083   6: 0.021541047278090   1: 0.021537897114235   0: 0.021537243098631   4: 0.021536498369475   9: 0.021535414500143   3: 0.021535227289779   7: 0.021534913603984   8: 0.021534824007719   2: 0.021534623363861 

training_7359     5: 0.720072154773561   7: 0.112560472132003   0: 0.048336103596681   4: 0.017006768332201   1: 0.017006525950005   6: 0.017004680432176   8: 0.017003726774724   9: 0.017003442233762   3: 0.017003072221971   2: 0.017003053552916 

training_736      9: 0.383471277385914   0: 0.229973187499071   1: 0.221158753019038   6: 0.041409404569641   4: 0.020698827897128   7: 0.020675381636773   5: 0.020654285519561   2: 0.020653365584925   8: 0.020652912571471   3: 0.020652604316478 

training_7362     0: 0.737858300872970   1: 0.092875395843387   7: 0.021284118803269   5: 0.021143449744246   6: 0.021143050283788   4: 0.021139823920069   9: 0.021139266873751   3: 0.021139132466683   2: 0.021139063070211   8: 0.021138398121625 

training_7363     5: 0.438979556891208   4: 0.310921141403801   3: 0.087703978061586   7: 0.023212374815684   1: 0.023197907422030   0: 0.023197626362080   6: 0.023197261428347   2: 0.023196891333283   9: 0.023196637067409   8: 0.023196625214573 

training_7366     6: 0.432382086129629   1: 0.224133920413827   5: 0.190266926963698   4: 0.070341160447642   8: 0.030101125485153   0: 0.010661994684607   9: 0.010626608275645   3: 0.010546074028055   2: 0.010473139660540   7: 0.010466963911203 

training_7367     6: 0.775711224703969   1: 0.086652972098362   5: 0.017223316080001   4: 0.017208768894363   0: 0.017206355418342   8: 0.017204256477877   2: 0.017198444919090   3: 0.017198418572451   7: 0.017198248159542   9: 0.017197994676002 

training_7370     1: 0.621274420503275   5: 0.097122133823409   9: 0.080176650666036   2: 0.066245230429690   6: 0.022533895669960   4: 0.022532012129448   0: 0.022530381638373   8: 0.022528930288752   7: 0.022528221663289   3: 0.022528123187768 

training_7375     6: 0.622225344726067   0: 0.205216486696271   9: 0.083982515362063   1: 0.025927291000591   7: 0.010443824162316   5: 0.010442026325687   8: 0.010440735763370   4: 0.010440700131598   2: 0.010440571486399   3: 0.010440504345640 

training_7379     5: 0.792339044730064   6: 0.064550423868029   8: 0.017909062532694   1: 0.017892130270691   0: 0.017885785652877   7: 0.017885259011688   9: 0.017885052013688   4: 0.017884636319215   2: 0.017884512655792   3: 0.017884092945261 

training_7381     6: 0.539208444330369   9: 0.192147113030730   2: 0.117178436689787   7: 0.047401010969589   1: 0.017356906349284   5: 0.017353812977453   4: 0.017340401813483   0: 0.017340061385746   3: 0.017338243568915   8: 0.017335568884643 

training_7382     5: 0.601969513705777   4: 0.186303901945026   6: 0.090946386361412   1: 0.017261429310170   0: 0.017254702375214   9: 0.017253117324384   2: 0.017252839174807   3: 0.017252836811481   8: 0.017252726148345   7: 0.017252546843384 

training_7385     5: 0.423797793318082   7: 0.178229092177074   4: 0.135808798178881   3: 0.116420976515851   2: 0.024293174846465   8: 0.024291805279338   6: 0.024290881078795   9: 0.024290146809574   1: 0.024288735030281   0: 0.024288596765659 

training_7386     1: 0.608548701548749   0: 0.114125818004967   5: 0.094984339426336   8: 0.051407839680060   6: 0.021857575331815   9: 0.021823466640502   4: 0.021815434099423   3: 0.021812369821632   7: 0.021812244641057   2: 0.021812210805458 

training_7387     6: 0.741540152790592   7: 0.028719243996161   1: 0.028718860658091   0: 0.028718439444612   8: 0.028717786342108   5: 0.028717465009188   9: 0.028717172663149   2: 0.028717146983574   4: 0.028717022539460   3: 0.028716709573065 

training_7388     5: 0.784322132811848   7: 0.067713391329309   4: 0.018497884196157   1: 0.018496876087345   6: 0.018495952157173   0: 0.018495144630518   3: 0.018494702697236   9: 0.018494656436507   2: 0.018494636871724   8: 0.018494622782181 

training_7389     6: 0.585155973726288   7: 0.194484130281043   8: 0.027545705269190   0: 0.027545262595068   5: 0.027545040485118   1: 0.027545018582183   9: 0.027544871809537   4: 0.027544707171687   2: 0.027544647635887   3: 0.027544642443999 

training_739      4: 0.617863938379769   6: 0.163348114977544   8: 0.058641591523639   5: 0.022883010370898   0: 0.022881113781342   1: 0.022878175785153   2: 0.022876670770397   9: 0.022876470026836   3: 0.022875579096182   7: 0.022875335288240 

training_7390     6: 0.743173696621371   1: 0.028537420311007   7: 0.028537353737373   0: 0.028536993480812   8: 0.028536330299818   5: 0.028536019626560   9: 0.028535708336692   2: 0.028535682351266   4: 0.028535556228921   3: 0.028535239006180 

training_7391     1: 0.673239501323387   0: 0.197270751238373   6: 0.059585753110029   7: 0.010253264470461   4: 0.010247524523637   8: 0.009941671521134   9: 0.009874863780051   5: 0.009864804040446   2: 0.009862455997095   3: 0.009859409995387 

training_7394     6: 0.704483735024026   0: 0.138657874377263   8: 0.064874678045523   1: 0.013180958693422   9: 0.013135150876474   5: 0.013134303963543   7: 0.013133537406933   2: 0.013133273472884   3: 0.013133244389170   4: 0.013133243750763 

training_7395     6: 0.820176383868890   7: 0.041197132570974   5: 0.017329622024329   4: 0.017328582068749   0: 0.017328549859875   8: 0.017328352903049   1: 0.017328206273608   9: 0.017327970957296   2: 0.017327667624342   3: 0.017327531848888 

training_7397     9: 0.496273205787628   2: 0.308631037160903   1: 0.082526827575085   5: 0.016088076628377   4: 0.016084268430792   6: 0.016082096835378   0: 0.016079867658528   3: 0.016079508454060   8: 0.016077854801656   7: 0.016077256667594 

training_7398     5: 0.794374333799904   4: 0.022851312713986   1: 0.022847787123444   6: 0.022847087147938   0: 0.022846954881925   7: 0.022846588267330   3: 0.022846565119035   8: 0.022846485804721   9: 0.022846453164786   2: 0.022846431976932 

training_74       5: 0.684217552785451   7: 0.139445736818949   8: 0.055827069247570   9: 0.017217153353325   6: 0.017216769770039   1: 0.017216050614521   4: 0.017215858994779   0: 0.017215372778138   2: 0.017214344723967   3: 0.017214090913261 

training_7404     4: 0.665899835767398   1: 0.144215034236931   5: 0.023741789522699   2: 0.023736734429730   9: 0.023736394038926   6: 0.023735795801993   0: 0.023733995879346   8: 0.023733758880411   3: 0.023733381296582   7: 0.023733280145984 

training_7406     6: 0.731862184096189   0: 0.068669479604197   1: 0.057458816338642   7: 0.054357111884807   8: 0.014727017194181   3: 0.014604664667786   5: 0.014581208147262   9: 0.014580067399055   2: 0.014579752812306   4: 0.014579697855575 

training_7407     1: 0.429275252421220   6: 0.362596379233882   9: 0.048370232800762   5: 0.041326124951975   0: 0.019769094610545   4: 0.019759736103058   7: 0.019732740407043   2: 0.019725847786207   3: 0.019723020934557   8: 0.019721570750751 

training_7408     9: 0.508561193636052   6: 0.240741064398255   4: 0.131002202568036   2: 0.028252737607835   0: 0.015665381887113   7: 0.015160415347420   1: 0.015157469573204   8: 0.015155360883731   5: 0.015154979132815   3: 0.015149194965540 

training_741      1: 0.639210228298157   6: 0.204494365191496   5: 0.019541200125952   2: 0.019538925844134   0: 0.019538861911997   4: 0.019536052463349   7: 0.019535616560501   3: 0.019534957332932   8: 0.019534917340616   9: 0.019534874930867 

training_7410     5: 0.690344771143614   6: 0.147041273466787   8: 0.020331236024992   4: 0.020330271284830   1: 0.020328381691623   9: 0.020325431189400   0: 0.020324893766627   7: 0.020324806662720   3: 0.020324496074087   2: 0.020324438695320 

training_7413     5: 0.574896571204219   7: 0.147612987782524   3: 0.106301496344659   4: 0.024455914743576   6: 0.024455573801866   8: 0.024455559217740   0: 0.024455556476170   1: 0.024455488606432   2: 0.024455449447871   9: 0.024455402374942 

training_7419     6: 0.578720749175118   8: 0.201849422069509   5: 0.027435646394598   1: 0.027429937936858   0: 0.027429136923990   4: 0.027429086454186   7: 0.027427535209546   9: 0.027426613533514   2: 0.027426566785972   3: 0.027425305516709 

training_742      6: 0.773844043884347   0: 0.106300985888578   1: 0.027742607224222   8: 0.020324826769731   5: 0.018534792660065   7: 0.011053057827726   2: 0.010551145111398   4: 0.010550127002006   3: 0.010549294235969   9: 0.010549119395957 

training_7420     6: 0.759669539661049   8: 0.026733532237999   5: 0.026703960083967   7: 0.026701305600069   0: 0.026699444534314   9: 0.026699078807777   1: 0.026698970135089   4: 0.026698671867298   2: 0.026697815678600   3: 0.026697681393837 

training_7421     5: 0.588195154930129   6: 0.271889356653556   8: 0.017491522121570   1: 0.017490606072637   0: 0.017490490266598   9: 0.017489232334714   7: 0.017488801468188   4: 0.017488685103736   2: 0.017488380877836   3: 0.017487770171036 

training_7423     6: 0.431567525221696   2: 0.189601011165694   9: 0.154721778709100   0: 0.139440782760846   5: 0.014113555064560   1: 0.014112619821913   4: 0.014111671666655   8: 0.014111135797797   7: 0.014110193404816   3: 0.014109726386922 

training_7424     6: 0.490245148382574   0: 0.273208877603138   7: 0.132483545944471   5: 0.014871583396011   1: 0.014870823925032   4: 0.014866090229984   8: 0.014865026149181   9: 0.014863543865498   2: 0.014862953593028   3: 0.014862406911084 

training_7425     8: 0.762997998778059   6: 0.026340300096426   5: 0.026335938147883   9: 0.026334938597330   0: 0.026332728114610   7: 0.026332695841343   4: 0.026332103113625   1: 0.026331451223792   2: 0.026331025299811   3: 0.026330820787121 

training_7426     8: 0.775167133282862   6: 0.024985870055510   9: 0.024983635606398   5: 0.024983439088748   0: 0.024980527700033   2: 0.024980380453768   1: 0.024980209321065   4: 0.024979985604353   7: 0.024979919230515   3: 0.024978899656749 

training_7427     5: 0.459914106677466   6: 0.275784394494311   0: 0.095545170601415   3: 0.075686143169749   7: 0.015569262201230   4: 0.015504410819213   1: 0.015500133198515   2: 0.015499821701120   9: 0.015498419386379   8: 0.015498137750602 

training_7428     8: 0.488692748616092   6: 0.405220903046163   0: 0.021111490194813   9: 0.012154095471362   5: 0.012148146069038   1: 0.012135670349718   4: 0.012135191175120   3: 0.012134499702374   7: 0.012133816798373   2: 0.012133438576948 

training_7429     6: 0.853380239867682   4: 0.016292523222185   9: 0.016291730034339   0: 0.016291488253257   1: 0.016291431544015   8: 0.016290734136774   7: 0.016290651675319   5: 0.016290518631082   2: 0.016290410880455   3: 0.016290271754892 

training_743      5: 0.616368460295711   1: 0.147645659418837   2: 0.129505181374966   9: 0.015225494678455   3: 0.015216125405838   6: 0.015213745871980   8: 0.015211967688201   0: 0.015209112954355   4: 0.015202412374816   7: 0.015201839936842 

training_7432     4: 0.687395189430862   0: 0.117630844706746   5: 0.024378589290390   6: 0.024372396013446   8: 0.024371346231174   9: 0.024370758582385   1: 0.024370389591752   3: 0.024370221815483   7: 0.024370145628817   2: 0.024370118708946 

training_7433     0: 0.547474981735935   1: 0.273020253641736   6: 0.022443591392590   5: 0.022439911745177   9: 0.022439620195058   7: 0.022436539912322   8: 0.022436532005605   4: 0.022436489570516   2: 0.022436429776724   3: 0.022435650024335 

training_7437     8: 0.373414140077868   6: 0.349235388540780   7: 0.134924584850552   9: 0.020350797955532   5: 0.020348874830980   0: 0.020346483163900   4: 0.020345836936576   1: 0.020345002087160   2: 0.020344616311088   3: 0.020344275245564 

training_7438     5: 0.820665212537399   4: 0.019929192555974   6: 0.019929062237079   0: 0.019928228287896   9: 0.019924943025887   7: 0.019924928256686   8: 0.019924767491545   3: 0.019924689487191   1: 0.019924567038007   2: 0.019924409082337 

training_7439     4: 0.770899108473257   5: 0.025461321200634   8: 0.025455192285059   3: 0.025455031499516   9: 0.025454976303457   6: 0.025454970865855   2: 0.025454901952882   0: 0.025454867624193   7: 0.025454836344511   1: 0.025454793450635 

training_7441     5: 0.725031562721290   8: 0.108836773627802   6: 0.020767988984868   0: 0.020767531018002   4: 0.020767519168632   1: 0.020767461834423   9: 0.020765500499565   2: 0.020765282647309   7: 0.020765199015973   3: 0.020765180482136 

training_7442     5: 0.356652438634437   1: 0.315479516318159   6: 0.205575271681900   2: 0.036757282182077   7: 0.014330319407596   4: 0.014247813625737   0: 0.014240993236074   9: 0.014239689195578   8: 0.014238642400498   3: 0.014238033317944 

training_7443     6: 0.363303092857463   4: 0.238953439803964   8: 0.190322802896581   7: 0.062546571155133   0: 0.042820667071496   1: 0.035728441625893   5: 0.016610227287457   9: 0.016572284431708   3: 0.016571425253530   2: 0.016571047616776 

training_7444     5: 0.783284251733139   7: 0.054677074938526   0: 0.046853315959729   1: 0.016480933538612   6: 0.016454997590765   4: 0.016452029515813   2: 0.016451977452651   9: 0.016449386914903   8: 0.016448116278104   3: 0.016447916077760 

training_7447     6: 0.444538387984950   1: 0.375525854541131   0: 0.046615181343944   9: 0.019117663341013   5: 0.019039713977129   4: 0.019034997606871   7: 0.019032403090851   8: 0.019032295449115   3: 0.019031863975285   2: 0.019031638689710 

training_7449     4: 0.660394980543341   1: 0.117397920851396   5: 0.027782707877891   6: 0.027775908250582   0: 0.027775104577840   9: 0.027775066134934   2: 0.027774726250403   8: 0.027774610338185   3: 0.027774574551805   7: 0.027774400623623 

training_745      2: 0.648883173793370   8: 0.166168312829610   3: 0.023130504137587   0: 0.023123899861045   1: 0.023122518075569   6: 0.023122398914099   5: 0.023122324251143   4: 0.023110186846741   9: 0.023108394541086   7: 0.023108286749751 

training_7452     6: 0.462514839465916   2: 0.257395833700962   5: 0.120873196381439   3: 0.055398721188584   0: 0.017303437634686   1: 0.017303348142238   7: 0.017303194242334   4: 0.017302760717139   9: 0.017302623666178   8: 0.017302044860525 

training_7453     4: 0.432850208961920   6: 0.266213996049230   1: 0.166185915344750   5: 0.019252176582517   0: 0.019251172057248   2: 0.019249619043062   8: 0.019249341108990   7: 0.019249214857570   3: 0.019249185641543   9: 0.019249170353170 

training_7455     5: 0.702496493337435   7: 0.090007228909056   2: 0.083204819248155   1: 0.017807211572854   0: 0.017802393034097   9: 0.017749118982472   4: 0.017736432464283   6: 0.017732702729011   8: 0.017732443733988   3: 0.017731155988650 

training_7459     5: 0.543229314995460   7: 0.237604043034116   4: 0.027401247149004   8: 0.027395426482008   6: 0.027395107095293   2: 0.027395045963046   0: 0.027394998981013   3: 0.027394979941153   9: 0.027394974107488   1: 0.027394862251418 

training_7460     1: 0.469747816331842   6: 0.339741694623816   9: 0.062531017679862   0: 0.018289924750355   7: 0.018284318322531   5: 0.018282680866928   2: 0.018281435048171   4: 0.018280514801004   8: 0.018280359794831   3: 0.018280237780660 

training_7462     5: 0.574524530338868   2: 0.207107461295206   4: 0.080928184523333   6: 0.019636669444845   3: 0.019634964583255   9: 0.019634265703634   0: 0.019633737215075   7: 0.019633548856360   1: 0.019633477224717   8: 0.019633160814707 

training_7464     5: 0.752443534566149   1: 0.027516206957693   6: 0.027510059629736   0: 0.027509133166135   4: 0.027504759112185   2: 0.027504191154296   9: 0.027503301861789   3: 0.027503282435212   7: 0.027502989662694   8: 0.027502541454112 

training_7465     5: 0.640444999309816   1: 0.170289589667664   0: 0.058400525317357   4: 0.018699317330921   6: 0.018694696832702   8: 0.018694298269998   9: 0.018694229760909   3: 0.018694194030909   2: 0.018694174946124   7: 0.018693974533599 

training_7466     5: 0.804710658197977   4: 0.021702145607652   1: 0.021699355892843   0: 0.021699241886684   6: 0.021698834925380   2: 0.021698363475907   7: 0.021697911402461   8: 0.021697901341211   9: 0.021697805515704   3: 0.021697781754181 

training_7468     4: 0.625293967169920   5: 0.156229711330205   2: 0.027322339308582   6: 0.027314506997918   1: 0.027307079345989   8: 0.027306732700353   0: 0.027306659312239   3: 0.027306450964626   7: 0.027306332215460   9: 0.027306220654707 

training_7469     1: 0.711620285939290   2: 0.129359522704654   5: 0.020039565846670   4: 0.019939248523242   9: 0.019865836972427   8: 0.019852847900885   6: 0.019835011254010   0: 0.019833467572434   7: 0.019827353648354   3: 0.019826859638033 

training_7470     4: 0.495118783134265   5: 0.201942981228529   3: 0.098103338809585   9: 0.063780700144174   6: 0.051260702694808   1: 0.017963301625059   0: 0.017961400906460   2: 0.017956500827711   8: 0.017956439075569   7: 0.017955851553841 

training_7471     6: 0.748667987818569   0: 0.138983549332680   1: 0.019737858761776   3: 0.013347211685137   5: 0.013212371750653   8: 0.013212256963190   2: 0.013210177067130   9: 0.013209712421206   7: 0.013209534319808   4: 0.013209339879852 

training_7472     5: 0.732826580906674   4: 0.029692596842064   6: 0.029687438805225   1: 0.029685065599322   0: 0.029684871485028   3: 0.029684817626837   2: 0.029684719279486   7: 0.029684708928150   8: 0.029684678697713   9: 0.029684521829502 

training_7474     3: 0.449611847759404   5: 0.361586519541638   4: 0.023600730519989   9: 0.023600415525766   6: 0.023600206322475   0: 0.023600113429553   8: 0.023600106934844   7: 0.023600099314000   2: 0.023599983277133   1: 0.023599977375197 

training_7475     2: 0.446252832617280   1: 0.343314910764309   8: 0.047577605421260   6: 0.023274155198053   5: 0.023269901136924   0: 0.023266708777583   4: 0.023262297885165   9: 0.023261869021030   7: 0.023260284506863   3: 0.023259434671532 

training_7476     4: 0.610393385617759   1: 0.181862457663626   5: 0.025973888039697   6: 0.025971447627195   9: 0.025967218871423   3: 0.025966470181462   8: 0.025966466988188   0: 0.025966428268816   2: 0.025966163618608   7: 0.025966073123227 

training_7477     6: 0.754901837516009   1: 0.134979982862293   3: 0.022593499973050   0: 0.012557384955530   4: 0.012551695593766   5: 0.012483575305761   7: 0.012483295288922   8: 0.012482991604607   9: 0.012482933380149   2: 0.012482803519911 

training_748      0: 0.484774969895957   6: 0.199417747439211   1: 0.180791013919731   4: 0.039432348359707   3: 0.030127111477058   7: 0.013096575260820   5: 0.013092620877054   2: 0.013089563787909   9: 0.013089245542666   8: 0.013088803439887 

training_7481     1: 0.356263645280042   5: 0.244684713548191   6: 0.183908643762544   9: 0.083269895771309   2: 0.060869951956082   0: 0.014207770675590   7: 0.014202302441810   4: 0.014198490953472   8: 0.014197889515937   3: 0.014196696095021 

training_7482     5: 0.769546236462090   1: 0.025618822005067   6: 0.025614829137125   0: 0.025607931135865   9: 0.025602476700554   2: 0.025602127809161   3: 0.025602021262658   7: 0.025601960345095   8: 0.025601895760623   4: 0.025601699381762 

training_7483     4: 0.518503007316986   3: 0.167785781516801   8: 0.146145678125374   5: 0.023944327971983   6: 0.023937083331126   1: 0.023936999202071   0: 0.023936985424033   9: 0.023936943247358   2: 0.023936627990174   7: 0.023936565874093 

training_7484     9: 0.719376194751102   8: 0.091185596696787   1: 0.023958067986678   0: 0.023665968114740   6: 0.023659544425781   5: 0.023653681068555   4: 0.023628460647106   2: 0.023627943924221   7: 0.023623618010040   3: 0.023620924374989 

training_7487     5: 0.753071214607794   4: 0.027437532510408   6: 0.027437235257351   3: 0.027436889023953   1: 0.027436642213441   9: 0.027436349386171   0: 0.027436315889334   2: 0.027436131346324   7: 0.027435857315347   8: 0.027435832449876 

training_7488     5: 0.682860600263740   8: 0.102147088157406   4: 0.075809714700526   0: 0.019886414627997   6: 0.019883794348796   1: 0.019882937720824   3: 0.019882678715942   9: 0.019882589600320   2: 0.019882268267811   7: 0.019881913596639 

training_7490     1: 0.451289194844428   5: 0.279656133333098   8: 0.097469110267766   7: 0.067863444817593   6: 0.017297993988264   0: 0.017289199346015   2: 0.017284007518598   4: 0.017283928810601   9: 0.017283808418006   3: 0.017283178655631 

training_7491     5: 0.625199205267500   4: 0.121392150112143   6: 0.113219720578378   9: 0.020031762720449   2: 0.020027030233546   7: 0.020026751187086   3: 0.020026368046642   0: 0.020025988687870   1: 0.020025549809859   8: 0.020025473356527 

training_7494     1: 0.728960973470827   8: 0.108783394388290   5: 0.020284727126628   6: 0.020284022763479   4: 0.020283322435959   9: 0.020281483495158   0: 0.020281154491718   3: 0.020280940356082   2: 0.020280107177291   7: 0.020279874294567 

training_7495     5: 0.800037705674425   4: 0.022222747095680   6: 0.022218030823942   1: 0.022217987243109   8: 0.022217731694238   0: 0.022217334878908   9: 0.022217178458485   2: 0.022217119463938   3: 0.022217109473889   7: 0.022217055193386 

training_7496     6: 0.603352808978218   5: 0.197608918874118   1: 0.101284500814648   8: 0.014053284431766   9: 0.013979553676362   3: 0.013948467371712   4: 0.013947280079240   0: 0.013943237518591   2: 0.013941006321912   7: 0.013940941933433 

training_7497     1: 0.418234381935006   4: 0.257169942214911   0: 0.145782757507205   5: 0.059451350894377   6: 0.019895484285458   9: 0.019893700900442   2: 0.019893218932724   8: 0.019893111178269   3: 0.019893085269680   7: 0.019892966881928 

training_7498     5: 0.428445318921220   9: 0.305151608537243   4: 0.113484725561629   1: 0.021848508005207   0: 0.021848183117293   2: 0.021846534806350   6: 0.021845487478257   7: 0.021843506321330   3: 0.021843482103241   8: 0.021842645148229 

training_7499     6: 0.402180545237403   0: 0.355808907626037   8: 0.144928685496620   1: 0.042248455225930   3: 0.012398625575347   9: 0.008501112922226   5: 0.008486305605677   7: 0.008482604740184   2: 0.008482384070093   4: 0.008482373500484 

training_75       6: 0.781569765295259   1: 0.086464358660200   5: 0.016498239944420   3: 0.016496167595853   0: 0.016495604446422   2: 0.016495369480767   4: 0.016495227808921   7: 0.016495182098374   8: 0.016495074015243   9: 0.016495010654541 

training_7500     6: 0.553662837005352   1: 0.288691704518652   3: 0.046271214006319   2: 0.026729822767673   8: 0.019813332983797   5: 0.018865464433663   0: 0.012254285017905   9: 0.011265196995271   7: 0.011223189069245   4: 0.011222953202124 

training_7501     6: 0.737531951433398   0: 0.103730002447830   8: 0.034919908540723   5: 0.017693392010490   1: 0.017688409919444   3: 0.017687765631200   2: 0.017687457005872   4: 0.017687117912594   9: 0.017687017401022   7: 0.017686977697427 

training_7504     0: 0.394825185716532   4: 0.327192217922242   3: 0.060166563358780   5: 0.058278176405120   9: 0.052755135608250   6: 0.021366710898755   1: 0.021357608648662   2: 0.021353669491037   8: 0.021352902320541   7: 0.021351829630081 

training_7505     5: 0.781589858255265   4: 0.024270810023924   6: 0.024267696289840   0: 0.024267569959725   8: 0.024267501997569   1: 0.024267434776912   9: 0.024267394354651   3: 0.024267280877931   7: 0.024267255009804   2: 0.024267198454379 

training_7508     6: 0.446400764805526   5: 0.295313705763717   4: 0.032296752197061   8: 0.032284836186319   9: 0.032284760302201   3: 0.032283970069773   2: 0.032283940474310   1: 0.032283831690661   7: 0.032283732781921   0: 0.032283705728511 

training_7510     6: 0.730254008232188   0: 0.086021203797656   1: 0.059919822245568   9: 0.041665492029093   2: 0.013737382437629   8: 0.013721728304066   7: 0.013694120249029   5: 0.013665417167977   4: 0.013660473880959   3: 0.013660351655835 

training_7512     6: 0.796797765267752   0: 0.082042247752303   9: 0.023957054203729   7: 0.013891324698027   1: 0.013889625345600   5: 0.013889360966302   8: 0.013883878552436   2: 0.013883107751632   3: 0.013882866652093   4: 0.013882768810127 

training_7514     0: 0.687337903229625   6: 0.171732042983972   1: 0.017628993455751   5: 0.017625799230354   4: 0.017617038204918   9: 0.017612525819167   2: 0.017611734026134   3: 0.017611344400216   7: 0.017611331869113   8: 0.017611286780750 

training_7515     6: 0.799960549405303   0: 0.054834339284959   1: 0.042275782536306   3: 0.031439473463129   4: 0.011927521644297   5: 0.011913557180282   9: 0.011912424472049   7: 0.011912348670154   8: 0.011912012881391   2: 0.011911990462128 

training_7516     5: 0.813862233309047   4: 0.020685434535128   1: 0.020682237151985   0: 0.020681747333661   6: 0.020681700030317   8: 0.020681420878429   9: 0.020681403208107   3: 0.020681297817494   2: 0.020681269739564   7: 0.020681255996267 

training_7517     5: 0.775013490020186   2: 0.024999420742618   3: 0.024998861836440   4: 0.024998804418297   1: 0.024998332623811   0: 0.024998306914799   6: 0.024998245635988   7: 0.024998193905404   8: 0.024998174047651   9: 0.024998169854807 

training_7518     5: 0.770186524422733   4: 0.025536245637492   3: 0.025535075970337   6: 0.025534970877494   9: 0.025534869133280   0: 0.025534541117477   2: 0.025534474676148   1: 0.025534441855257   7: 0.025534439151115   8: 0.025534417158667 

training_7519     5: 0.536962891048983   1: 0.254656536478022   0: 0.026053874499286   3: 0.026047346892638   4: 0.026047218260607   6: 0.026046819445989   2: 0.026046445400186   7: 0.026046301458388   8: 0.026046300200607   9: 0.026046266315294 

training_7520     5: 0.782535108525947   6: 0.024164440308715   8: 0.024163643567078   0: 0.024163176863690   1: 0.024163036177393   9: 0.024162599086491   3: 0.024162270947781   4: 0.024162221720725   2: 0.024161777240365   7: 0.024161725561814 

training_7521     6: 0.735679255358107   0: 0.116397600775611   1: 0.041592441666824   9: 0.025133416009010   7: 0.013542290830879   5: 0.013532948648553   3: 0.013531304637279   2: 0.013530887660823   8: 0.013529970252286   4: 0.013529884160627 

training_7528     6: 0.520911733599864   0: 0.230205846792107   9: 0.031111394695067   2: 0.031110709596197   1: 0.031110687402830   8: 0.031110130460267   5: 0.031109956648347   7: 0.031109937324763   4: 0.031109824062612   3: 0.031109779417946 

training_7529     6: 0.744372760646356   0: 0.115362336046798   5: 0.037607813600398   9: 0.014801158691219   4: 0.014715957001524   1: 0.014651765533306   2: 0.014622553780168   8: 0.014622187593413   3: 0.014621750455275   7: 0.014621716651543 

training_7531     6: 0.706903746998433   4: 0.096489878850318   8: 0.067093822552100   1: 0.018515167362100   0: 0.018514685132533   5: 0.018503181300986   9: 0.018495389464111   7: 0.018494991431423   3: 0.018494752663433   2: 0.018494384244563 

training_7533     6: 0.694019155238148   1: 0.158499260074450   0: 0.041465343080952   8: 0.027478229699562   4: 0.013115180970986   5: 0.013090151772476   3: 0.013083713104632   7: 0.013083705683405   2: 0.013082639543798   9: 0.013082620831591 

training_7534     6: 0.678876298796010   0: 0.120698662394191   2: 0.098287242719274   1: 0.022993862089434   8: 0.013269570213153   3: 0.013233681706712   7: 0.013175859076194   9: 0.013156983368918   5: 0.013154903068499   4: 0.013152936567615 

training_7537     6: 0.336444281677310   0: 0.320245293938769   1: 0.201056392169226   9: 0.056744211119418   3: 0.024875514156985   5: 0.012137659769499   2: 0.012125560481879   8: 0.012124041596615   7: 0.012123622325029   4: 0.012123422765271 

training_7538     6: 0.778288162880850   0: 0.107645709210119   3: 0.021867914844335   1: 0.021253445034812   9: 0.011884744947040   8: 0.011828284897390   5: 0.011812692644183   7: 0.011806750644081   4: 0.011806163483473   2: 0.011806131413717 

training_7539     0: 0.387654276491036   6: 0.344517218472803   7: 0.145103518543827   1: 0.017535491269381   5: 0.017534616324533   4: 0.017533574130329   9: 0.017530839335663   8: 0.017530529859926   2: 0.017530060793320   3: 0.017529874779182 

training_754      6: 0.804991960977753   1: 0.077613275098713   0: 0.014675469204084   5: 0.014674788933185   9: 0.014674343111341   4: 0.014674087882215   7: 0.014674048496252   3: 0.014674035233943   8: 0.014674032454601   2: 0.014673958607914 

training_7541     5: 0.561717278784197   1: 0.221288749178381   9: 0.027168824390855   6: 0.027141188339471   0: 0.027120341470848   8: 0.027116529694825   4: 0.027112938093564   7: 0.027112256610721   3: 0.027110992339543   2: 0.027110901097594 

training_7543     6: 0.827649624149401   1: 0.028522479635991   0: 0.018059373282239   5: 0.017999356089382   8: 0.017990795714187   7: 0.017989399769478   4: 0.017948537469563   9: 0.017947805569737   2: 0.017946376412418   3: 0.017946251907603 

training_7544     5: 0.520134682984622   6: 0.310295518420736   4: 0.021233813804747   1: 0.021194295140136   9: 0.021192040510305   0: 0.021191923449082   7: 0.021189796138170   8: 0.021189786247326   2: 0.021189078881917   3: 0.021189064422960 

training_7545     6: 0.702321098013528   0: 0.103627105181683   1: 0.068011790175259   7: 0.049773095649949   3: 0.025251350817476   5: 0.017609921088526   8: 0.008843099066430   9: 0.008278612692660   2: 0.008143604674068   4: 0.008140322640421 

training_7548     0: 0.458939065115881   5: 0.240077500863562   8: 0.172768268450248   6: 0.018326424524020   1: 0.018319656869154   9: 0.018316134015076   7: 0.018314799933471   2: 0.018313030591592   4: 0.018312991252666   3: 0.018312128384330 

training_7552     0: 0.420180315721683   6: 0.372851571224397   7: 0.088094685389464   1: 0.026851816354199   2: 0.015740011906831   9: 0.015294607090454   5: 0.015265569971980   8: 0.015242704151881   3: 0.015239553952391   4: 0.015239164236719 

training_7554     6: 0.743471701260639   0: 0.028533174867309   7: 0.028500474179897   5: 0.028499812272668   9: 0.028499766775873   8: 0.028499602355712   1: 0.028499516203722   2: 0.028498674062848   4: 0.028498643799065   3: 0.028498634222267 

training_7555     6: 0.798704466337827   0: 0.022372281593697   9: 0.022368341636000   7: 0.022366788984556   8: 0.022366021362248   5: 0.022365930547588   1: 0.022364406912862   2: 0.022364024019431   4: 0.022363870610840   3: 0.022363867994952 

training_7557     6: 0.837542648839311   0: 0.034703752062774   5: 0.016060478463405   4: 0.015966319664178   1: 0.015954867884734   9: 0.015954822257295   8: 0.015954462639610   7: 0.015954438299466   2: 0.015954128783613   3: 0.015954081105614 

training_7558     0: 0.303517734929378   1: 0.232767459777457   6: 0.163456168347202   3: 0.101945274598323   8: 0.089859822417160   4: 0.044527099111060   5: 0.015982419970869   2: 0.015982270785181   9: 0.015981582057957   7: 0.015980168005414 

training_7559     9: 0.587503967698027   1: 0.245745743967308   6: 0.020851936673169   0: 0.020846843114215   5: 0.020846494049741   8: 0.020842911933987   7: 0.020841136840136   4: 0.020841026763489   2: 0.020840057722564   3: 0.020839881237363 

training_756      5: 0.395146114464747   3: 0.381606756394715   6: 0.027919091641480   4: 0.027910698551460   1: 0.027903626102286   8: 0.027903327488501   7: 0.027902818902664   2: 0.027902633063697   0: 0.027902527694884   9: 0.027902405695565 

training_7562     9: 0.743480628422950   6: 0.104320945830058   3: 0.046345913344531   1: 0.015123005514491   0: 0.015122523726892   8: 0.015122279498860   5: 0.015122017300572   4: 0.015121194059720   7: 0.015120747576017   2: 0.015120744725909 

training_7564     9: 0.731679716623429   6: 0.029836482425214   5: 0.029816936073046   0: 0.029813613234308   1: 0.029810645625105   4: 0.029809272770340   8: 0.029809004855200   2: 0.029808988234066   3: 0.029807719287310   7: 0.029807620871983 

training_7565     6: 0.657494525551448   9: 0.161980363449551   7: 0.041638226805413   1: 0.040108893287705   2: 0.016619227485027   3: 0.016443121258753   0: 0.016429249809567   5: 0.016428867464697   4: 0.016428812806250   8: 0.016428712081588 

training_7566     6: 0.612556438098710   7: 0.206231065372989   1: 0.054182492588281   3: 0.033238135083300   9: 0.026280465799309   5: 0.022707897763766   0: 0.018080849346783   8: 0.008911932345538   4: 0.008905508932917   2: 0.008905214668407 

training_7568     6: 0.753366937949182   0: 0.079810213989152   1: 0.052456502200985   8: 0.016364884238331   9: 0.016343199126407   7: 0.016337120493347   5: 0.016331779903663   3: 0.016329895189291   4: 0.016329760851961   2: 0.016329706057681 

training_7569     6: 0.730289781687508   0: 0.071039816637948   8: 0.049760529488204   5: 0.021280619134846   9: 0.021277164437202   7: 0.021270949857258   4: 0.021270634645598   1: 0.021270447341948   2: 0.021270033380261   3: 0.021270023389226 

training_757      0: 0.671732818886796   7: 0.159434344964192   5: 0.021119667989511   1: 0.021108524033106   6: 0.021103332243661   4: 0.021102648794796   8: 0.021101677787717   2: 0.021099337358351   9: 0.021098975197387   3: 0.021098672744485 

training_7570     0: 0.492718961300221   6: 0.347759141908222   1: 0.042285013594154   3: 0.016756112110507   7: 0.016753859514665   5: 0.016747592864925   8: 0.016746752679816   4: 0.016746635595712   2: 0.016743030813652   9: 0.016742899618125 

training_7571     9: 0.632171659934235   6: 0.185522586094479   4: 0.053290908022160   8: 0.018434166763601   5: 0.018431897209165   1: 0.018431224144427   0: 0.018430807479657   3: 0.018429564745568   7: 0.018428661799183   2: 0.018428523807524 

training_7574     5: 0.603373312702096   6: 0.178216575169081   9: 0.027309460478406   7: 0.027301735761620   2: 0.027301460832433   8: 0.027301368016607   4: 0.027299178348512   1: 0.027299113432897   0: 0.027299083706750   3: 0.027298711551598 

training_7576     6: 0.787383635292491   5: 0.099079901911022   0: 0.024804842405744   7: 0.012679633220548   9: 0.012677134036373   4: 0.012676000249957   1: 0.012675470752886   8: 0.012674553395503   3: 0.012674469690360   2: 0.012674359045115 

training_7577     6: 0.434975564094807   9: 0.236400685591035   5: 0.187271936847976   0: 0.035650622784300   1: 0.017687994123910   8: 0.017612211200110   7: 0.017608971859114   4: 0.017597921033181   2: 0.017597091445876   3: 0.017597001019691 

training_7579     6: 0.817187231401708   7: 0.056783982456046   0: 0.015760170114371   8: 0.015759264141878   9: 0.015755484737196   5: 0.015752121628327   1: 0.015751430228975   4: 0.015750499022634   2: 0.015749932069014   3: 0.015749884199852 

training_758      4: 0.563778643974872   0: 0.156773767779696   5: 0.104145396949160   6: 0.025065669533970   9: 0.025040961557576   7: 0.025040870353818   1: 0.025040004311042   8: 0.025039198487907   2: 0.025037869896481   3: 0.025037617155478 

training_7580     9: 0.775927991212568   6: 0.024905857175517   5: 0.024898667970315   0: 0.024896821873211   8: 0.024896392321309   1: 0.024895805536197   4: 0.024895619753623   2: 0.024894657649242   7: 0.024894641195329   3: 0.024893545312689 

training_7581     9: 0.749857393908055   5: 0.027809413278588   4: 0.027804819610862   6: 0.027792670204921   8: 0.027792126510047   0: 0.027790446235713   7: 0.027789738925788   2: 0.027787961594704   1: 0.027787798542723   3: 0.027787631188600 

training_7583     6: 0.574350637932075   9: 0.266357418230894   7: 0.043723139867669   0: 0.016570088665101   5: 0.016535220053050   3: 0.016496265158221   8: 0.016493879111066   4: 0.016491838350136   1: 0.016490920717232   2: 0.016490591914555 

training_7584     6: 0.767959675837106   3: 0.062584426156258   9: 0.045767939826918   0: 0.017700112309193   5: 0.017670814755574   1: 0.017667223358250   8: 0.017662900497162   7: 0.017662773253596   4: 0.017662210745570   2: 0.017661923260374 

training_7585     6: 0.762132066674585   3: 0.073978130005641   9: 0.020486845424963   7: 0.020486458829054   0: 0.020486437544972   5: 0.020486415166788   8: 0.020486225804901   1: 0.020486087109620   2: 0.020485724820318   4: 0.020485608619157 

training_7587     6: 0.539014895034441   8: 0.202381029111711   0: 0.132739640627413   3: 0.035601003943954   9: 0.015051059954614   5: 0.015046557260431   1: 0.015043674497757   7: 0.015041390756480   2: 0.015040478820253   4: 0.015040269992946 

training_7590     6: 0.745309205461856   9: 0.028300338562574   7: 0.028299378276737   0: 0.028299226997447   1: 0.028299085778840   8: 0.028298963775396   5: 0.028298856313673   2: 0.028298500442237   3: 0.028298387239302   4: 0.028298057151940 

training_7591     6: 0.794150606307497   9: 0.022872970631808   7: 0.022872552743803   8: 0.022872361926673   0: 0.022872310901451   5: 0.022872291330857   1: 0.022872207360175   2: 0.022871621611144   4: 0.022871616248857   3: 0.022871460937734 

training_7592     6: 0.694051072160127   1: 0.158466537052545   0: 0.041466146326162   8: 0.027478236820602   4: 0.013115176512300   5: 0.013090151976751   3: 0.013083712953600   7: 0.013083705841035   2: 0.013082639536601   9: 0.013082620820278 

training_7593     1: 0.608562257774677   6: 0.203527724162478   0: 0.089239036339977   5: 0.014105389558510   9: 0.014101022043118   8: 0.014095367945106   3: 0.014093077846837   4: 0.014092648208735   7: 0.014091867136199   2: 0.014091608984364 

training_7596     5: 0.302138091522699   6: 0.266052383012125   1: 0.163123958385811   7: 0.142075439154129   0: 0.051264811188416   8: 0.015070986999379   3: 0.015068682385447   4: 0.015068566300361   9: 0.015068543752198   2: 0.015068537299435 

training_7599     9: 0.766566993116590   6: 0.072870100012550   8: 0.020074386331907   1: 0.020070580461025   0: 0.020070552418858   5: 0.020070485765443   3: 0.020069883040093   4: 0.020069140825296   7: 0.020069028227755   2: 0.020068849800485 

training_76       6: 0.461106819935756   8: 0.323443953128687   5: 0.026943561212596   4: 0.026933467342440   9: 0.026930617606761   7: 0.026930227030664   1: 0.026929044871827   0: 0.026928134299394   3: 0.026927195955545   2: 0.026926978616328 

training_7600     6: 0.723915915962017   0: 0.157212942599943   5: 0.014861230921391   1: 0.014860665973804   8: 0.014858660136567   9: 0.014858659091300   7: 0.014858220809038   4: 0.014858194817821   3: 0.014857809481102   2: 0.014857700207018 

training_7602     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_7603     0: 0.440619753605905   5: 0.279097778564448   1: 0.117654961304807   7: 0.045733426780569   6: 0.019491970222056   9: 0.019486350251894   8: 0.019481480759980   4: 0.019478548657457   3: 0.019478058060616   2: 0.019477671792268 

training_7604     6: 0.733225549470273   1: 0.097273263099920   5: 0.039695150888101   0: 0.018586190137547   9: 0.018539930893818   4: 0.018539140069143   2: 0.018536085866635   3: 0.018535244146295   7: 0.018535192899592   8: 0.018534252528675 

training_7605     1: 0.473242988112363   6: 0.356385498695985   8: 0.059730625989196   3: 0.043356533077937   9: 0.011221098319120   5: 0.011216104240336   0: 0.011215774734357   7: 0.011211155258556   2: 0.011210190285737   4: 0.011210031286412 

training_7606     6: 0.757750058968757   9: 0.071449460659820   8: 0.063516380965635   0: 0.015402081585103   7: 0.015337691772158   4: 0.015317886498521   1: 0.015311722892922   5: 0.015305335755740   3: 0.015304905461720   2: 0.015304475439624 

training_7609     6: 0.642875399405379   1: 0.201460321585376   9: 0.036550684488066   7: 0.017052857790348   4: 0.017028259388099   5: 0.017016800722091   0: 0.017010664240483   8: 0.017005420643185   2: 0.016999934448978   3: 0.016999657287994 

training_7611     6: 0.744384486520168   0: 0.115354168241478   5: 0.037607726792689   9: 0.014799405274212   4: 0.014714238644055   1: 0.014651766144975   2: 0.014622553684341   8: 0.014622187626702   3: 0.014621750444359   7: 0.014621716627021 

training_7614     6: 0.538844572991160   8: 0.202641545499932   0: 0.132649371091371   3: 0.035601065531946   9: 0.015051072969985   5: 0.015046555083154   1: 0.015043676547336   7: 0.015041391319648   2: 0.015040478961466   4: 0.015040270004002 

training_7618     0: 0.639646122139891   6: 0.211863099662648   5: 0.018575339723048   2: 0.018562468549531   4: 0.018561505064431   1: 0.018559903994816   9: 0.018558907972228   7: 0.018557788757875   8: 0.018557736161620   3: 0.018557127973911 

training_762      1: 0.451660056949143   5: 0.276527445438675   8: 0.115886336185002   3: 0.037746167646323   0: 0.037399307572014   4: 0.016233436325138   2: 0.016139237259011   6: 0.016138749825195   7: 0.016136400296114   9: 0.016132862503386 

training_7620     5: 0.706905172821401   9: 0.105956793635982   4: 0.023399261678856   0: 0.023391587841844   1: 0.023391446283093   8: 0.023391377275590   6: 0.023391256141714   2: 0.023391059489548   3: 0.023391026327006   7: 0.023391018504965 

training_7621     4: 0.680690594403855   5: 0.103228955262928   0: 0.027021827877417   3: 0.027015545912140   2: 0.027010710609197   6: 0.027007079582359   1: 0.027006457545002   9: 0.027006363098196   8: 0.027006309032955   7: 0.027006156675951 

training_7622     5: 0.673776134951766   2: 0.135295764293202   6: 0.023867176760417   1: 0.023866461742025   3: 0.023866397844804   0: 0.023866108619097   4: 0.023865862822268   8: 0.023865388787878   9: 0.023865363862071   7: 0.023865340316472 

training_7623     6: 0.737162125002620   7: 0.083386970261963   9: 0.047773646676577   0: 0.018930512451986   1: 0.018797386425904   5: 0.018790945520155   8: 0.018790134210940   3: 0.018789640792380   4: 0.018789417700210   2: 0.018789220957264 

training_7625     6: 0.815166985683964   0: 0.041858362880307   8: 0.040325649734363   1: 0.029040012826001   5: 0.012275837290765   7: 0.012275118448723   4: 0.012264584171692   9: 0.012264527214567   2: 0.012264481396236   3: 0.012264440353382 

training_7626     6: 0.735692337609792   0: 0.116401728124511   1: 0.041575164568612   9: 0.025133412611410   7: 0.013542359768410   5: 0.013532948655750   3: 0.013531305006610   2: 0.013530889253913   8: 0.013529970245863   4: 0.013529884155129 

training_7627     6: 0.453058866127859   1: 0.246317402284589   0: 0.089176262322601   9: 0.058123802158514   5: 0.057981155061195   4: 0.019254521143464   3: 0.019023788542752   8: 0.019022799608510   2: 0.019020780274349   7: 0.019020622476168 

training_7628     6: 0.801762084315577   0: 0.096585518574049   1: 0.040499671430164   9: 0.008776954244773   7: 0.008737304224457   2: 0.008734636837698   8: 0.008730083378414   5: 0.008725910867220   4: 0.008723983257271   3: 0.008723852870377 

training_7629     6: 0.698641544721083   1: 0.096278148943747   3: 0.051702708864475   9: 0.048844054780570   4: 0.035839394327236   7: 0.013762392724423   2: 0.013753371143919   5: 0.013729263692518   0: 0.013728375377296   8: 0.013720745424731 

training_7631     5: 0.650867739541800   9: 0.170748116520857   1: 0.022302360662372   0: 0.022299797626529   6: 0.022298339487697   4: 0.022297115748902   3: 0.022296750261448   2: 0.022296658415059   7: 0.022296575773044   8: 0.022296545962292 

training_7632     6: 0.746917137807716   1: 0.117014505533337   7: 0.042392163897165   0: 0.013416291787130   5: 0.013381298436391   9: 0.013376583090812   3: 0.013376299894939   8: 0.013375458107847   4: 0.013375248718621   2: 0.013375012726042 

training_7633     6: 0.334010601689604   0: 0.321452051955938   1: 0.201972699053559   9: 0.056930728303149   3: 0.024936072452263   5: 0.012150358725076   2: 0.012138269568904   8: 0.012136747421936   7: 0.012136334210963   4: 0.012136136618609 

training_7634     5: 0.725663044234593   9: 0.110335527350713   6: 0.020505028963512   4: 0.020502304364515   0: 0.020499817226797   7: 0.020499304531388   3: 0.020498954157026   1: 0.020498855708399   8: 0.020498764159909   2: 0.020498399303149 

training_7635     1: 0.675915175701558   8: 0.176474188452037   6: 0.018550668671117   5: 0.018443386609589   0: 0.018437294789527   3: 0.018437005931339   7: 0.018436396358384   4: 0.018435622338000   2: 0.018435362827472   9: 0.018434898320977 

training_7636     5: 0.643587227254789   6: 0.111461447527937   9: 0.088202390777850   4: 0.022393393716197   1: 0.022392897377789   0: 0.022392885351628   8: 0.022392820936427   2: 0.022392406662691   3: 0.022392348719433   7: 0.022392181675259 

training_7637     1: 0.465641966814691   6: 0.295038215869948   5: 0.029918872463206   0: 0.029916565379181   4: 0.029914345100938   2: 0.029914190266033   7: 0.029914039067763   3: 0.029913982559047   9: 0.029913971199003   8: 0.029913851280189 

training_7638     6: 0.757179770444530   9: 0.026985891372586   8: 0.026984492373710   0: 0.026980321917856   7: 0.026979106242035   1: 0.026979047097609   4: 0.026978013483605   2: 0.026977908178161   5: 0.026977799951866   3: 0.026977648938043 

training_7639     5: 0.669213641742614   6: 0.132618850141273   2: 0.088423989295981   0: 0.015680300985557   1: 0.015679751545139   9: 0.015677488751410   4: 0.015676815963529   7: 0.015676644310308   8: 0.015676400308792   3: 0.015676116955398 

training_764      5: 0.745778243107534   2: 0.067435601066736   4: 0.023363037279251   6: 0.023353648332656   0: 0.023348314670323   1: 0.023348275507434   9: 0.023343719042406   3: 0.023343188665533   8: 0.023343000898448   7: 0.023342971429679 

training_7640     6: 0.762213978268238   2: 0.059219260492765   0: 0.041706812387803   3: 0.040788455727329   8: 0.016012684976824   5: 0.016012609686338   4: 0.016012012178249   1: 0.016011886674268   9: 0.016011319598445   7: 0.016010980009741 

training_7641     5: 0.426490017997337   0: 0.330625485040825   6: 0.030367565210960   1: 0.030361955261932   9: 0.030360083761004   4: 0.030359307753375   2: 0.030359181062730   7: 0.030358974797901   8: 0.030358932133641   3: 0.030358496980297 

training_7642     6: 0.659924838014801   1: 0.181685355105737   7: 0.041723665892579   9: 0.035417802941803   8: 0.013555052460849   0: 0.013553112359598   4: 0.013538653491666   2: 0.013534854273707   5: 0.013533564175092   3: 0.013533101284167 

training_7643     6: 0.812334987230998   0: 0.046846114197519   8: 0.026345529327909   2: 0.025960799616895   1: 0.024817894028557   5: 0.012740263757482   3: 0.012738722003039   4: 0.012738602105344   9: 0.012738598984027   7: 0.012738488748230 

training_7644     6: 0.367510328618894   5: 0.247035730410257   0: 0.238304735294288   4: 0.064036361581450   1: 0.013854392760514   8: 0.013852941145670   9: 0.013851745682163   2: 0.013851447191654   7: 0.013851225446838   3: 0.013851091868272 

training_7645     6: 0.676568610204745   1: 0.097731019631095   3: 0.052981431580330   4: 0.051732184342446   9: 0.050037668339719   7: 0.014217030507035   2: 0.014198402644327   5: 0.014180963173408   0: 0.014180288381568   8: 0.014172401195326 

training_7647     0: 0.468297888285413   6: 0.348691284722163   2: 0.057612603897707   5: 0.017928299487963   4: 0.017921066955076   9: 0.017910956585518   1: 0.017909891087012   3: 0.017909456569131   8: 0.017909435578415   7: 0.017909116831602 

training_7650     6: 0.681075910212652   1: 0.160496546545211   7: 0.028961394600898   5: 0.024494652399185   0: 0.017591031552683   2: 0.017524330611182   9: 0.017471292670554   8: 0.017461870638499   4: 0.017461711345512   3: 0.017461259423623 

training_7652     9: 0.606968124997010   6: 0.231425328768951   8: 0.020220821193824   1: 0.020201722067691   5: 0.020198122813126   0: 0.020197616725501   3: 0.020197563346594   4: 0.020197072603486   2: 0.020196819383571   7: 0.020196808100246 

training_7657     4: 0.458355300585062   5: 0.357766061662356   3: 0.022985486342374   1: 0.022985163888713   0: 0.022984991110925   6: 0.022984980072745   9: 0.022984798815748   2: 0.022984427714620   8: 0.022984411043362   7: 0.022984378764094 

training_7659     6: 0.599260853110540   8: 0.220136689501504   7: 0.056315641388351   1: 0.033601101558297   0: 0.015123917128938   5: 0.015116479418575   9: 0.015112469916372   4: 0.015111342174413   2: 0.015110992199505   3: 0.015110513603505 

training_7662     6: 0.715241069398161   0: 0.112160964103866   1: 0.044716132103018   7: 0.041405098314042   5: 0.014413867937932   9: 0.014413197944135   4: 0.014412643837767   8: 0.014412450802369   2: 0.014412410687389   3: 0.014412164871321 

training_7669     6: 0.712194623369902   0: 0.164525454791305   1: 0.026818548792871   5: 0.013883348069433   8: 0.013764710655088   7: 0.013762848513165   9: 0.013762650787382   3: 0.013762649388210   2: 0.013762597163389   4: 0.013762568469253 

training_767      5: 0.814623863385469   6: 0.020609554267878   1: 0.020600470615901   0: 0.020600429324100   8: 0.020595124932706   4: 0.020594966329298   2: 0.020594709800490   9: 0.020594359134490   3: 0.020593343087414   7: 0.020593179122253 

training_7670     5: 0.813777139038071   8: 0.020704512010090   6: 0.020702981997471   9: 0.020701585992248   1: 0.020692333951812   0: 0.020687043916062   2: 0.020684121970104   7: 0.020684038674853   4: 0.020683284319336   3: 0.020682958129952 

training_7671     6: 0.528164452397547   0: 0.280556645530086   9: 0.049049770930465   5: 0.034747456502454   8: 0.030111050377114   3: 0.015538155899387   1: 0.015465035070564   4: 0.015457484889175   2: 0.015456946341911   7: 0.015453002061297 

training_7672     1: 0.262416824344674   5: 0.244266223077815   6: 0.164885888788940   0: 0.137603979729506   7: 0.056482823813201   9: 0.053463536180439   3: 0.033661009650701   2: 0.015744192250814   4: 0.015739803474325   8: 0.015735718689586 

training_7673     5: 0.797644656536387   4: 0.055463585632019   2: 0.018380167435306   9: 0.018378823400070   1: 0.018374300152220   6: 0.018355286323520   0: 0.018352455842598   8: 0.018350714057730   7: 0.018350083053060   3: 0.018349927567090 

training_7674     9: 0.477125005429641   6: 0.371124350588936   8: 0.018972296534611   5: 0.018971931549195   0: 0.018969326630098   7: 0.018968218513535   1: 0.018967958704203   2: 0.018967016154655   4: 0.018966996741965   3: 0.018966899153162 

training_7676     4: 0.757694727550158   5: 0.026928601404195   8: 0.026922596483850   3: 0.026922150852843   9: 0.026922135686520   2: 0.026922053739332   7: 0.026922024562629   0: 0.026921941051888   1: 0.026921912277562   6: 0.026921856391024 

training_7678     5: 0.602917248187861   4: 0.234804411834069   2: 0.020290669292993   1: 0.020288750453424   6: 0.020287384497667   0: 0.020287255304460   8: 0.020285032255364   9: 0.020280228162720   7: 0.020279512098661   3: 0.020279507912780 

training_7679     5: 0.412542704511307   0: 0.355784717568332   8: 0.068895183218136   1: 0.055220211291694   2: 0.017944077639913   4: 0.017928168592349   7: 0.017925899052571   9: 0.017925235817944   6: 0.017918358068320   3: 0.017915444239436 

training_768      0: 0.594774258404465   6: 0.280780899189608   1: 0.021736294442077   5: 0.014676245701455   3: 0.014673931447545   8: 0.014672195824521   9: 0.014672077411606   4: 0.014671581731644   2: 0.014671314620073   7: 0.014671201227006 

training_7681     5: 0.667507752072866   4: 0.139673434749968   6: 0.024104991533710   0: 0.024102628029369   3: 0.024102478003664   1: 0.024101967951193   7: 0.024101701570757   9: 0.024101692639236   2: 0.024101677005296   8: 0.024101676443942 

training_7682     5: 0.650364637195099   8: 0.158418601246703   3: 0.023903325916480   4: 0.023903193796297   9: 0.023902486998380   0: 0.023902057041487   2: 0.023901518457048   6: 0.023901509564884   7: 0.023901341347844   1: 0.023901328435777 

training_7684     6: 0.601874734812567   0: 0.114610227198213   7: 0.100428809299233   1: 0.075052421376338   9: 0.032156919983756   3: 0.015185219929511   2: 0.015179832605309   5: 0.015173123833777   4: 0.015169378542481   8: 0.015169332418813 

training_7686     5: 0.688276588718775   7: 0.132206909502971   0: 0.022470197626843   6: 0.022447287393145   1: 0.022438815599512   8: 0.022434656053105   9: 0.022432266269412   4: 0.022431993963450   2: 0.022430689547027   3: 0.022430595325759 

training_7687     5: 0.683400070327148   2: 0.148618301046196   3: 0.030090158105312   0: 0.029581455987354   7: 0.018138574719635   6: 0.018052291831081   1: 0.018038609861428   8: 0.018030078091236   9: 0.018025834561781   4: 0.018024625468828 

training_7690     5: 0.725713472796859   8: 0.080607244590772   0: 0.024210324128977   4: 0.024210198301111   1: 0.024210045736003   9: 0.024209938847727   6: 0.024209885461182   3: 0.024209691561136   2: 0.024209637525668   7: 0.024209561050567 

training_7693     1: 0.713202128596659   0: 0.139388476784327   4: 0.034823571690329   6: 0.016093252717403   5: 0.016089077049406   8: 0.016084170486100   9: 0.016081941497835   3: 0.016080619939647   2: 0.016078395105240   7: 0.016078366133054 

training_7694     5: 0.604363079724968   0: 0.112418124730734   8: 0.088432324941643   6: 0.027834572617032   1: 0.027827488322699   9: 0.027825240515378   3: 0.027825117919817   2: 0.027824748980507   4: 0.027824695790048   7: 0.027824606457173 

training_7696     4: 0.460654067944337   5: 0.365229211434622   6: 0.021783526148903   0: 0.021766363736763   1: 0.021765564919877   2: 0.021762215207604   9: 0.021760384921947   7: 0.021759792461548   3: 0.021759454512786   8: 0.021759418711612 

training_7698     6: 0.608900346028014   5: 0.206783595612507   1: 0.023047292144172   0: 0.023043944375214   2: 0.023040027586628   4: 0.023038708373626   7: 0.023037042879008   9: 0.023036860311334   8: 0.023036269880545   3: 0.023035912808951 

training_77       8: 0.431166806543319   6: 0.351367259642442   5: 0.027190903466831   4: 0.027185329522493   1: 0.027185116442060   0: 0.027182313097088   9: 0.027181755145212   7: 0.027181072515312   2: 0.027180217935992   3: 0.027179225689251 

training_7700     6: 0.787511206083895   1: 0.041148539685574   7: 0.040770475189889   5: 0.018655055352905   0: 0.018653383568176   8: 0.018652999788743   4: 0.018652628416262   9: 0.018652172527607   3: 0.018651780842179   2: 0.018651758544770 

training_7702     5: 0.518119939057222   4: 0.163082942671793   1: 0.155914518891115   6: 0.023277961287094   9: 0.023271815367657   2: 0.023268122372988   0: 0.023266667628887   7: 0.023266495827906   8: 0.023266160366597   3: 0.023265376528742 

training_7704     1: 0.554545411561763   0: 0.194287697392789   8: 0.091666195028633   5: 0.063759892614572   6: 0.015961435400842   2: 0.015960692314885   4: 0.015955583306687   9: 0.015954872568804   7: 0.015954159444239   3: 0.015954060366786 

training_7707     5: 0.649332549908346   8: 0.140126544990793   1: 0.026319444346425   6: 0.026318170718229   0: 0.026317865442408   9: 0.026317240064491   3: 0.026317131577346   2: 0.026317100145901   4: 0.026317001506215   7: 0.026316951299846 

training_7709     5: 0.775904202820697   3: 0.024900076139072   4: 0.024899739579737   6: 0.024899487098125   0: 0.024899478109049   8: 0.024899471301087   1: 0.024899399103009   2: 0.024899398459677   7: 0.024899388692693   9: 0.024899358696853 

training_7710     6: 0.487179358050929   0: 0.316658776519595   7: 0.073211667292427   8: 0.049949057379805   1: 0.012173837554790   9: 0.012166848117634   5: 0.012165838306828   4: 0.012165058185897   2: 0.012164839081639   3: 0.012164719510457 

training_7715     1: 0.467378983247514   6: 0.322794504442246   3: 0.048702300939745   9: 0.035009871692003   0: 0.033157969644419   5: 0.018846360187620   8: 0.018564687421801   4: 0.018517065558254   2: 0.018514295926701   7: 0.018513960939698 

training_7716     8: 0.838865877031633   6: 0.017907138075175   0: 0.017904883180174   1: 0.017904514765235   5: 0.017903751514065   9: 0.017903559748122   7: 0.017902988811769   4: 0.017902488972638   2: 0.017902453564916   3: 0.017902344336273 

training_7722     0: 0.544226334318733   6: 0.209012840933178   2: 0.102819272392496   1: 0.042551296993676   9: 0.027902723639722   3: 0.014700545758719   5: 0.014698420349304   4: 0.014697389566536   8: 0.014696145477498   7: 0.014695030570136 

training_7723     5: 0.547091205611177   1: 0.284984897221101   9: 0.021005901917002   4: 0.020992828266805   8: 0.020988908723328   0: 0.020988843190736   6: 0.020988094905232   7: 0.020986689707722   3: 0.020986342263216   2: 0.020986288193681 

training_7725     5: 0.605487235171706   2: 0.168638651659104   6: 0.097299399373236   0: 0.018386553008886   1: 0.018366559227007   8: 0.018365386223890   4: 0.018364263906409   9: 0.018364195499884   7: 0.018363940493938   3: 0.018363815435941 

training_7726     5: 0.615255747365913   2: 0.196357134953607   4: 0.023551354599178   6: 0.023548921081319   8: 0.023548503310793   9: 0.023548320816717   0: 0.023547532946099   7: 0.023547530235213   1: 0.023547521819919   3: 0.023547432871241 

training_7728     5: 0.658832927568829   8: 0.147676507483579   4: 0.024190224174233   1: 0.024186061095653   3: 0.024185851651592   2: 0.024185746341445   0: 0.024185698800223   6: 0.024185680768654   9: 0.024185660205403   7: 0.024185641910389 

training_7729     9: 0.598154016504343   7: 0.143306629824470   4: 0.065728389964438   2: 0.065691505253433   1: 0.021193930949722   0: 0.021192990192531   5: 0.021191648977103   6: 0.021187925023952   8: 0.021176579135502   3: 0.021176384174506 

training_773      4: 0.755944819712372   5: 0.027122851957569   8: 0.027116695914990   3: 0.027116672990332   2: 0.027116602241691   0: 0.027116537863325   1: 0.027116515500237   6: 0.027116446712538   9: 0.027116437118815   7: 0.027116419988131 

training_7730     4: 0.793700212497375   5: 0.022927357799953   0: 0.022922389130881   6: 0.022922324581693   8: 0.022921766651129   7: 0.022921376917094   9: 0.022921361305469   1: 0.022921133110292   3: 0.022921073789997   2: 0.022921004216117 

training_7732     5: 0.755191448861714   3: 0.027201607472911   4: 0.027201276467659   8: 0.027200899754440   0: 0.027200880131574   6: 0.027200862060601   2: 0.027200780167084   1: 0.027200771949376   7: 0.027200754579258   9: 0.027200718555383 

training_7733     6: 0.675821690293269   0: 0.156483993820161   9: 0.039685288044812   1: 0.035229064122208   5: 0.022794014372779   3: 0.021127574580467   8: 0.012220892684806   2: 0.012213099294833   4: 0.012212611517673   7: 0.012211771268992 

training_7734     5: 0.780993062686980   4: 0.024337460308410   8: 0.024333856414199   9: 0.024333747855204   0: 0.024333704655090   6: 0.024333668737100   3: 0.024333655565684   2: 0.024333653555338   7: 0.024333595963933   1: 0.024333594258061 

training_7735     4: 0.660183553349491   0: 0.110963207176033   9: 0.074002732491239   5: 0.022127620039809   8: 0.022122889355651   1: 0.022122032169322   6: 0.022120490830508   7: 0.022119416288852   3: 0.022119062537530   2: 0.022118995761565 

training_7736     6: 0.404056905493716   5: 0.316130208690083   8: 0.138047427674519   0: 0.020256754579142   1: 0.020253085795819   4: 0.020251965303020   9: 0.020251749574125   7: 0.020251159953524   2: 0.020250443531092   3: 0.020250299404960 

training_7737     9: 0.504866152571596   1: 0.351486895255130   5: 0.017969147072655   0: 0.017959181268854   6: 0.017957111707758   2: 0.017954385199462   4: 0.017952285314366   8: 0.017951712559606   7: 0.017951590560067   3: 0.017951538490506 

training_7738     1: 0.629524838435680   5: 0.132327008428794   6: 0.029782238822051   7: 0.029771640984027   3: 0.029767751933276   9: 0.029766465412393   4: 0.029766306448962   0: 0.029766296298455   8: 0.029765993669284   2: 0.029761459567078 

training_7739     5: 0.819537808306642   4: 0.020055364114379   6: 0.020051340552670   2: 0.020051162064794   0: 0.020050923841280   8: 0.020050842999685   9: 0.020050777661641   1: 0.020050722954171   3: 0.020050568150167   7: 0.020050489354570 

training_774      5: 0.704344288365274   0: 0.076857762550781   9: 0.060872067324064   8: 0.052286947363872   4: 0.017608941996116   6: 0.017606796457001   1: 0.017605934596320   7: 0.017605887227090   3: 0.017605700731363   2: 0.017605673388117 

training_7742     6: 0.694474556316485   1: 0.137414264294985   8: 0.050498472712217   9: 0.046078340108517   5: 0.017729864853739   2: 0.010857996796384   4: 0.010781589898266   0: 0.010734215784626   7: 0.010733051740743   3: 0.010697647494038 

training_7743     7: 0.420718589307100   4: 0.323320892403411   5: 0.032005340064497   6: 0.031999681817805   0: 0.031999070285867   8: 0.031991797118907   3: 0.031991712004680   2: 0.031991234939155   1: 0.031990841053113   9: 0.031990841005464 

training_7744     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_7746     5: 0.777433898036763   4: 0.024730029435142   3: 0.024730007795261   1: 0.024729611998041   6: 0.024729535723204   0: 0.024729533260196   2: 0.024729389465235   7: 0.024729348543942   8: 0.024729327768357   9: 0.024729317973858 

training_7747     7: 0.315678180821386   1: 0.313394639521681   0: 0.238550154664632   4: 0.041696826697456   6: 0.015141332527808   5: 0.015126040721654   8: 0.015108895884726   2: 0.015103220634527   9: 0.015101560949853   3: 0.015099147576277 

training_7749     1: 0.501509678069046   7: 0.253493368692828   6: 0.107880007095555   8: 0.019631742149722   0: 0.019583455971070   9: 0.019580722660530   5: 0.019580665075476   4: 0.019580259544370   2: 0.019580083974550   3: 0.019580016766853 

training_7752     5: 0.566344370466284   7: 0.140875947311734   0: 0.121806205914360   9: 0.046658239950938   4: 0.039460416750563   3: 0.016977708845463   6: 0.016975486432053   1: 0.016967986275595   8: 0.016967150766979   2: 0.016966487286032 

training_7755     4: 0.665107207031331   0: 0.110689804030517   5: 0.028039403190002   6: 0.028025616497903   1: 0.028023856978380   3: 0.028023314584275   9: 0.028023291783238   8: 0.028022926835027   2: 0.028022320684230   7: 0.028022258385097 

training_7757     1: 0.600156504813684   5: 0.226910879386831   8: 0.021629102255457   6: 0.021623140895512   0: 0.021617879097213   7: 0.021613925598116   9: 0.021613723632318   4: 0.021612057487004   3: 0.021612049202194   2: 0.021610737631670 

training_776      5: 0.652931610772432   2: 0.149905169361579   6: 0.024649081218755   7: 0.024646440775303   1: 0.024645370519656   3: 0.024644777355305   4: 0.024644609751276   9: 0.024644534985966   0: 0.024644219523316   8: 0.024644185736411 

training_7761     5: 0.511837463623183   8: 0.206781006759289   0: 0.120938917425674   2: 0.022931198904000   6: 0.022920102529277   3: 0.022918851175372   4: 0.022918699163928   1: 0.022918025984934   7: 0.022917951791516   9: 0.022917782642826 

training_7762     5: 0.736002268069788   2: 0.099792150358781   3: 0.020535549295327   4: 0.020527369414241   6: 0.020525825005978   0: 0.020524853980636   9: 0.020524546485059   1: 0.020523195454711   8: 0.020522267407227   7: 0.020521974528251 

training_7763     6: 0.384531068461317   5: 0.363608782856422   1: 0.105981466448573   8: 0.041698408849109   0: 0.017391848263441   4: 0.017358835953325   7: 0.017357629849834   9: 0.017357539823203   2: 0.017357259436399   3: 0.017357160058378 

training_7764     8: 0.750805839556659   5: 0.027695101679184   6: 0.027689446723054   0: 0.027688447458922   4: 0.027687361471351   1: 0.027687085473209   9: 0.027686965164616   3: 0.027686868778125   2: 0.027686523944832   7: 0.027686359750048 

training_7765     1: 0.406207832637251   6: 0.383676402498129   5: 0.138362944656728   0: 0.018745319965972   9: 0.008841425597049   8: 0.008840035685909   2: 0.008831890182652   3: 0.008831488180792   4: 0.008831344918889   7: 0.008831315676630 

training_7766     5: 0.489053825985093   1: 0.319898051071112   4: 0.023882574939172   3: 0.023881129027671   6: 0.023881115932967   0: 0.023880952378092   9: 0.023880948640911   8: 0.023880588109787   7: 0.023880414800994   2: 0.023880399114200 

training_7767     6: 0.735428447799517   0: 0.133783942317012   9: 0.056605841808151   5: 0.010599102025056   1: 0.010598690360523   4: 0.010597790780694   8: 0.010596999232871   7: 0.010596701830561   2: 0.010596265241504   3: 0.010596218604110 

training_7768     5: 0.631920080385592   2: 0.176085619709058   4: 0.024006980900155   6: 0.024000341797127   0: 0.023998242888644   3: 0.023998232519750   1: 0.023997898703414   9: 0.023997802026440   7: 0.023997428680204   8: 0.023997372389613 

training_7769     8: 0.790108670276727   2: 0.064574978710377   0: 0.018168014916152   6: 0.018167313295533   1: 0.018164502759693   5: 0.018163869106100   9: 0.018163667697272   7: 0.018163166382801   4: 0.018163036370205   3: 0.018162780485141 

training_7771     6: 0.736573448248732   1: 0.145584456317943   0: 0.026755066253247   2: 0.021178771346481   7: 0.011659550060925   5: 0.011657344713385   9: 0.011656873940957   4: 0.011645479123403   3: 0.011644559230345   8: 0.011644450764582 

training_7773     6: 0.764503998220319   1: 0.026174877807500   5: 0.026168024929651   0: 0.026167919815177   8: 0.026164614541871   4: 0.026164552409441   2: 0.026164230750157   9: 0.026164100950986   7: 0.026164046328075   3: 0.026163634246823 

training_7774     5: 0.600305380336668   9: 0.186004890891169   4: 0.026718671190758   0: 0.026716391613314   1: 0.026711481424451   7: 0.026709109614870   6: 0.026708785084882   8: 0.026708702732560   2: 0.026708314695864   3: 0.026708272415465 

training_7775     6: 0.464858197311674   8: 0.167810159438225   9: 0.125938227830915   1: 0.116367563130058   4: 0.061477859200992   2: 0.012819689291159   0: 0.012693495290441   7: 0.012682543381747   5: 0.012679975994806   3: 0.012672289129983 

training_7776     5: 0.690862917136538   4: 0.122359017215349   6: 0.023348633682291   8: 0.023348162606438   3: 0.023347193304049   0: 0.023347063912430   1: 0.023346982257310   7: 0.023346763995193   9: 0.023346651179546   2: 0.023346614710856 

training_778      4: 0.531783326721843   5: 0.286005651276354   0: 0.022778253300329   1: 0.022777333743728   6: 0.022777033075287   2: 0.022775953969059   3: 0.022775903537282   7: 0.022775632387344   9: 0.022775535837900   8: 0.022775376150872 

training_7782     5: 0.772300705779643   2: 0.025300599895977   3: 0.025300232748811   4: 0.025300048315041   7: 0.025299835497545   6: 0.025299783865150   0: 0.025299722157956   1: 0.025299716449483   8: 0.025299702423309   9: 0.025299652867085 

training_7784     4: 0.456252928650947   1: 0.318386203007725   5: 0.028174700769479   2: 0.028172932717959   0: 0.028171201140261   6: 0.028170598232214   9: 0.028168535255950   7: 0.028168338192756   3: 0.028167313917361   8: 0.028167248115347 

training_7785     5: 0.636922344509806   8: 0.151112233905525   6: 0.026518710522863   1: 0.026508286089804   0: 0.026495945573253   7: 0.026490813118436   9: 0.026488261301655   3: 0.026488030517446   4: 0.026487821221325   2: 0.026487553239888 

training_7789     4: 0.452268546116306   6: 0.254422771764196   1: 0.178863511185405   5: 0.016406882208677   3: 0.016343633279161   0: 0.016342282495823   2: 0.016338941887392   7: 0.016338184193159   9: 0.016338084217779   8: 0.016337162652102 

training_7790     4: 0.817303824191298   5: 0.020302367014314   2: 0.020301629545536   6: 0.020300181505196   9: 0.020299513717313   1: 0.020299119985171   0: 0.020298969668436   3: 0.020298247734377   7: 0.020298090842885   8: 0.020298055795474 

training_7791     6: 0.726780318330505   5: 0.097611504215162   1: 0.068030251121504   4: 0.015374277338305   0: 0.015370104808814   9: 0.015367907532131   2: 0.015367395365248   3: 0.015366522369600   8: 0.015365861693429   7: 0.015365857225302 

training_7792     6: 0.644845894493405   5: 0.111293111522365   0: 0.087748606342248   8: 0.078159301085148   1: 0.019472275465392   2: 0.011698601251609   3: 0.011696678818600   9: 0.011696506437383   7: 0.011694526369578   4: 0.011694498214272 

training_7795     1: 0.694110776919368   5: 0.033993279768561   4: 0.033990144123803   8: 0.033988334645282   6: 0.033986765781946   9: 0.033986494183257   0: 0.033986482111526   7: 0.033986053338701   2: 0.033985971906242   3: 0.033985697221315 

training_7796     1: 0.627506438822100   7: 0.227624790588948   6: 0.030823814564728   0: 0.027649148556185   4: 0.014420205632069   8: 0.014416082468054   5: 0.014404183889378   9: 0.014387870547389   3: 0.014384142244391   2: 0.014383322686759 

training_7797     1: 0.474709118250482   5: 0.227614335043836   6: 0.180245311417653   0: 0.016778727291876   8: 0.016776854811146   3: 0.016775570429813   4: 0.016775430808661   9: 0.016775165554179   7: 0.016775043247480   2: 0.016774443144875 

training_78       8: 0.753417767431644   5: 0.027402701585448   6: 0.027399695731399   4: 0.027398434367439   1: 0.027398188900311   9: 0.027397700317986   0: 0.027397143269278   7: 0.027396489732205   2: 0.027396249814738   3: 0.027395628849553 

training_780      4: 0.664699301370055   5: 0.118918503887373   6: 0.027086004823228   3: 0.027050303808830   1: 0.027044580987618   0: 0.027042508206877   9: 0.027040053183748   7: 0.027039748695663   2: 0.027039569528426   8: 0.027039425508183 

training_7802     6: 0.769500422508220   0: 0.103703130283652   1: 0.031915574032743   3: 0.025429005516503   7: 0.011724140615878   9: 0.011608781356360   2: 0.011597176329296   5: 0.011517602917135   8: 0.011502462824171   4: 0.011501703616042 

training_7804     6: 0.803765200372983   0: 0.075883107909212   1: 0.048233860868700   7: 0.010320042615040   5: 0.010300982620780   9: 0.010300086172350   3: 0.010299638010029   2: 0.010299449281480   4: 0.010298915979831   8: 0.010298716169594 

training_7805     2: 0.369987690895042   6: 0.348126380922660   5: 0.035328556940564   4: 0.035310660151880   8: 0.035211543719464   3: 0.035209363124940   7: 0.035207772473190   0: 0.035206640510245   9: 0.035206394095231   1: 0.035204997166784 

training_7807     8: 0.770862777287381   6: 0.025467727032622   9: 0.025461915060614   1: 0.025459437188373   5: 0.025459187053593   7: 0.025459145807689   0: 0.025458338422495   3: 0.025457272710496   2: 0.025457109120176   4: 0.025457090316561 

training_7809     0: 0.446512995481984   6: 0.331719748106483   8: 0.074794815636707   1: 0.041012340429156   7: 0.017748595851524   5: 0.017649428753643   9: 0.017646075308225   4: 0.017639716587375   3: 0.017638479051996   2: 0.017637804792906 

training_781      5: 0.785271031352942   4: 0.023862500630551   6: 0.023858600403912   0: 0.023858528687962   8: 0.023858330448655   1: 0.023858296262469   9: 0.023858216659896   3: 0.023858210702712   2: 0.023858178742690   7: 0.023858106108211 

training_7810     1: 0.610197764443039   5: 0.161426551693628   7: 0.066217032224240   2: 0.032101665104818   3: 0.031714357084151   0: 0.030310927102454   6: 0.017013984847130   4: 0.017008012570114   9: 0.017005337001190   8: 0.017004367929236 

training_7813     1: 0.673875096316894   8: 0.113533135380788   6: 0.079573370842868   5: 0.019005186110515   0: 0.019003923201506   4: 0.019002797604489   2: 0.019001971749142   9: 0.019001652036671   7: 0.019001616683478   3: 0.019001250073649 

training_7814     1: 0.411536938467656   5: 0.344141107334771   0: 0.067161071906510   6: 0.055906749641976   4: 0.020209440686500   7: 0.020209097452331   9: 0.020209091373944   8: 0.020208968196000   2: 0.020208791862579   3: 0.020208743077731 

training_7816     1: 0.695344933336181   3: 0.163011563371998   5: 0.017755580358130   0: 0.017728408799371   4: 0.017706498882920   6: 0.017699487499813   7: 0.017691722663138   2: 0.017688915881834   9: 0.017686732589402   8: 0.017686156617213 

training_7817     1: 0.480603926756411   0: 0.360640130764143   5: 0.019849651981280   6: 0.019845315433102   4: 0.019844661182955   8: 0.019843825599773   9: 0.019843360311439   2: 0.019843117225313   7: 0.019843095071939   3: 0.019842915673646 

training_7818     6: 0.847504048177066   8: 0.016950383074460   9: 0.016944354627043   5: 0.016944190669476   7: 0.016943406556138   0: 0.016943199046526   1: 0.016943086501144   4: 0.016942840571908   2: 0.016942343641440   3: 0.016942147134800 

training_7819     4: 0.621320428337147   1: 0.163006449157356   0: 0.026968945530401   6: 0.026959598928141   5: 0.026958843501405   8: 0.026957484457100   7: 0.026957193386440   2: 0.026957067185351   3: 0.026957064972230   9: 0.026956924544430 

training_7820     4: 0.550759257261280   1: 0.288177099768552   5: 0.039211193852138   6: 0.017423713430916   0: 0.017407851139867   9: 0.017405337706130   2: 0.017404418139202   8: 0.017404101202250   7: 0.017403537956062   3: 0.017403489543603 

training_7821     5: 0.447629113568462   6: 0.362274909535228   2: 0.023785767864115   4: 0.023763922219398   8: 0.023758411734475   9: 0.023757766693807   3: 0.023757592029134   7: 0.023757580819002   0: 0.023757496977301   1: 0.023757438559079 

training_7823     6: 0.712761890814143   2: 0.071437854067220   0: 0.070962588592932   3: 0.031784205523544   9: 0.031770023013502   4: 0.016262574245280   1: 0.016258981550060   5: 0.016257734172432   7: 0.016252789337006   8: 0.016251358683882 

training_7824     1: 0.691970201437257   6: 0.104577638819084   9: 0.043058159947852   0: 0.022937767011825   5: 0.022910807358654   8: 0.022909455810133   4: 0.022909385259563   7: 0.022909074534854   2: 0.022908792283410   3: 0.022908717537369 

training_7825     6: 0.460773247194065   0: 0.325788784230685   4: 0.068503996162383   1: 0.020709605391782   5: 0.020705296092661   3: 0.020704933250793   9: 0.020704385033070   2: 0.020703445226310   8: 0.020703155190895   7: 0.020703152227356 

training_7826     5: 0.782624062348574   4: 0.024156228291141   6: 0.024153052744227   1: 0.024152707012236   8: 0.024152607977655   9: 0.024152526009118   0: 0.024152467779503   2: 0.024152135333345   3: 0.024152109910949   7: 0.024152102593250 

training_7828     5: 0.712844234156603   8: 0.031917945884448   4: 0.031910785760139   0: 0.031904025869200   1: 0.031903970719123   2: 0.031903938333561   9: 0.031903874970923   3: 0.031903803613257   6: 0.031903719878673   7: 0.031903700814074 

training_783      4: 0.767190523329976   5: 0.025874152798899   8: 0.025867241474343   9: 0.025867094852837   3: 0.025867078497687   2: 0.025866939274620   7: 0.025866806225573   0: 0.025866747206781   1: 0.025866718453750   6: 0.025866697885534 

training_7830     5: 0.825070591574334   6: 0.019439007782961   4: 0.019438723385838   0: 0.019436817912634   3: 0.019436208379776   9: 0.019436046277181   8: 0.019435908479449   7: 0.019435738688460   1: 0.019435650527633   2: 0.019435306991734 

training_7831     1: 0.632307254631995   5: 0.172468164408781   0: 0.062216995964463   6: 0.019152589659026   2: 0.018976404947447   4: 0.018975918482712   8: 0.018975868296317   3: 0.018975787784133   9: 0.018975746708566   7: 0.018975269116560 

training_7835     5: 0.572386108472658   8: 0.140896126781428   3: 0.116694071601168   7: 0.024297266120388   4: 0.024289007606891   9: 0.024288241488696   0: 0.024287712808502   2: 0.024287261594355   6: 0.024287162498978   1: 0.024287041026936 

training_7836     5: 0.700721804498841   6: 0.137393308873903   9: 0.020243940971566   8: 0.020236952868529   4: 0.020236708730293   0: 0.020233965160485   7: 0.020233714346925   1: 0.020233348190325   3: 0.020233149248559   2: 0.020233107110573 

training_7837     5: 0.480765490154981   8: 0.135066536694053   1: 0.124478765443963   0: 0.116269292509817   7: 0.023905559893729   3: 0.023903503593484   4: 0.023902966373115   2: 0.023902872496898   6: 0.023902586248974   9: 0.023902426590985 

training_7838     5: 0.814677490887071   4: 0.020594937479909   8: 0.020592386976859   6: 0.020591516516148   0: 0.020591019922923   1: 0.020590876112699   9: 0.020590677135005   2: 0.020590388535297   3: 0.020590370734107   7: 0.020590335699982 

training_7839     1: 0.704148476414474   0: 0.099828749026552   6: 0.050284497921800   8: 0.039392029132649   5: 0.017771870004005   3: 0.017720614448416   4: 0.017716241620370   7: 0.017713950804119   9: 0.017711944391991   2: 0.017711626235622 

training_7840     5: 0.458658526812038   4: 0.359801064528127   3: 0.022720609717515   2: 0.022694234923929   9: 0.022689854947342   6: 0.022689711047806   1: 0.022687221029387   0: 0.022686857945696   8: 0.022685980221938   7: 0.022685938826221 

training_7841     5: 0.843016163221016   6: 0.017444049694131   4: 0.017443947686198   0: 0.017442709919806   9: 0.017442477782998   1: 0.017442353451017   8: 0.017442196197011   7: 0.017442129586558   2: 0.017441995558388   3: 0.017441976902877 

training_7842     6: 0.753561747376955   0: 0.058445816488935   7: 0.051688854567105   2: 0.019484411876412   9: 0.019471368408564   5: 0.019470370967870   3: 0.019470164213355   8: 0.019469958737551   1: 0.019468976819226   4: 0.019468330544027 

training_7843     5: 0.741546468111497   4: 0.028719134031579   9: 0.028716904678142   8: 0.028716887985121   3: 0.028716833018597   0: 0.028716815460242   2: 0.028716796224885   1: 0.028716747546359   7: 0.028716721474292   6: 0.028716691469285 

training_7845     5: 0.512569713170650   2: 0.294683205704287   3: 0.024100167733967   6: 0.024093621645217   1: 0.024093351635795   4: 0.024092800136198   9: 0.024092337550960   0: 0.024092079950037   8: 0.024091392132681   7: 0.024091330340208 

training_7847     5: 0.765126157612698   1: 0.058916227489771   0: 0.043092591545431   7: 0.018997473491419   6: 0.018995492928588   9: 0.018978586180667   8: 0.018973914031573   2: 0.018973663971640   4: 0.018973117872149   3: 0.018972774876064 

training_7848     6: 0.478399238127055   0: 0.308510530384521   9: 0.056943297329519   5: 0.049441719735827   4: 0.017788998456807   8: 0.017785920433621   1: 0.017785432394264   2: 0.017783090874245   7: 0.017781287573114   3: 0.017780484691027 

training_7850     5: 0.695019601639563   0: 0.116120974470690   4: 0.023625448201412   2: 0.023605867203863   1: 0.023605425014692   3: 0.023605002409969   6: 0.023604760086899   8: 0.023604377050127   9: 0.023604345645200   7: 0.023604198277585 

training_7851     5: 0.453051107843541   8: 0.181154885360006   3: 0.116418641977066   0: 0.107384705620983   2: 0.023676942898665   7: 0.023670252648208   6: 0.023662435782438   4: 0.023660943176591   1: 0.023660164511668   9: 0.023659920180833 

training_7854     6: 0.516305436672655   1: 0.195165400258523   9: 0.152720361545572   0: 0.040877165498702   4: 0.015825669432622   2: 0.015822903354362   7: 0.015821732057411   8: 0.015820870546853   5: 0.015820456291214   3: 0.015820004342085 

training_7855     9: 0.701399146810698   2: 0.112718077920170   6: 0.049696989942971   0: 0.019493505375378   1: 0.019453142016883   7: 0.019451925763292   5: 0.019451821721979   4: 0.019446377131870   3: 0.019445025457953   8: 0.019443987858807 

training_7857     4: 0.555819869064794   0: 0.212395271496484   5: 0.028977572715927   7: 0.028975720489891   8: 0.028972335026487   9: 0.028972030221248   6: 0.028972008693114   3: 0.028971768553376   2: 0.028971752265752   1: 0.028971671472928 

training_7858     6: 0.423214927175775   8: 0.323540711085706   4: 0.031713496404729   5: 0.031689859552776   0: 0.031645117340560   9: 0.031640150096766   7: 0.031639360646712   1: 0.031639261981744   2: 0.031638797737974   3: 0.031638317977260 

training_7859     4: 0.568242283895956   0: 0.203373840315252   1: 0.028556161807497   7: 0.028548724050764   5: 0.028547418338867   2: 0.028547262145331   6: 0.028546718268577   9: 0.028546381482079   8: 0.028545605242476   3: 0.028545604453202 

training_7860     6: 0.666093081965664   7: 0.125416232542449   1: 0.026068797518052   0: 0.026064486445303   2: 0.026063749709757   5: 0.026059528155034   8: 0.026058692619050   4: 0.026058584185938   9: 0.026058573927391   3: 0.026058272931362 

training_7861     5: 0.679987357860511   3: 0.122958655406589   7: 0.024640896705453   1: 0.024631512750337   0: 0.024630579363079   6: 0.024630543139438   8: 0.024630394451887   4: 0.024630355504937   2: 0.024630072678435   9: 0.024629632139333 

training_7862     6: 0.664782129981970   8: 0.113549455727470   1: 0.027729806443447   0: 0.027713160775304   5: 0.027705916878248   9: 0.027705904715943   2: 0.027703924213930   4: 0.027703757086558   7: 0.027703073473763   3: 0.027702870703369 

training_7864     5: 0.765312736432053   1: 0.103577565613629   6: 0.016391494703689   0: 0.016390269628300   7: 0.016388138188512   2: 0.016388098855392   3: 0.016388055799517   9: 0.016388022635567   4: 0.016387898345461   8: 0.016387719797880 

training_7865     1: 0.514519983712018   6: 0.239294511157595   4: 0.067825498408553   0: 0.039585584251091   2: 0.038894558570983   8: 0.037313714357406   3: 0.015654322882866   5: 0.015642628608464   9: 0.015636571876226   7: 0.015632626174799 

training_7866     5: 0.780672250516299   1: 0.064067781723038   2: 0.019441417629904   6: 0.019412140709270   0: 0.019411388414121   7: 0.019405202170271   8: 0.019398457916096   4: 0.019397289555176   9: 0.019397231949110   3: 0.019396839416714 

training_7867     4: 0.457798523157397   1: 0.365126728656792   0: 0.022204969694889   5: 0.022140228373596   6: 0.022129049249752   7: 0.022122072408494   9: 0.022121887682788   8: 0.022119696493418   2: 0.022118910696764   3: 0.022117933586108 

training_7869     1: 0.360570335470245   5: 0.309490934013821   9: 0.179476666004181   6: 0.021502599684927   4: 0.021495632011890   7: 0.021493585203751   2: 0.021493321249859   0: 0.021492913425747   8: 0.021492263517264   3: 0.021491749418314 

training_787      9: 0.536266525207438   6: 0.284725312579912   1: 0.036700798672476   3: 0.036610343973187   0: 0.017624656620836   4: 0.017620880102068   5: 0.017615893937642   2: 0.017612336369498   8: 0.017612156685008   7: 0.017611095851933 

training_7870     5: 0.368093211291863   6: 0.356523505995208   8: 0.166302182364521   0: 0.015586772853804   4: 0.015583627751167   1: 0.015582790346714   2: 0.015582370618054   9: 0.015582188402308   3: 0.015581684701364   7: 0.015581665674998 

training_7871     6: 0.536290065450558   0: 0.200922343902570   1: 0.087272740242492   8: 0.080949031605273   5: 0.015783648024647   4: 0.015777648331158   7: 0.015770975132153   3: 0.015745800711990   9: 0.015744213006313   2: 0.015743533592845 

training_7872     1: 0.415525139692737   6: 0.344300459124756   0: 0.092038941618682   9: 0.034070193559038   5: 0.027237425719462   7: 0.026124984072817   8: 0.015188805895912   3: 0.015176974223989   4: 0.015168895263546   2: 0.015168180829062 

training_7873     6: 0.726130648313911   1: 0.139691302412975   0: 0.059661761203049   2: 0.015963653339267   7: 0.009800909049789   5: 0.009752490383930   4: 0.009750343131115   3: 0.009750197674652   9: 0.009749710520662   8: 0.009748983970649 

training_7874     1: 0.493612824447757   0: 0.346094069729911   2: 0.044991329909721   6: 0.016474602579727   5: 0.016472962506634   7: 0.016472598561072   4: 0.016471664335953   9: 0.016471190848136   3: 0.016469389921119   8: 0.016469367159970 

training_7875     5: 0.590712902383325   0: 0.264065126538095   6: 0.018158782703729   2: 0.018154858443991   1: 0.018152888216601   8: 0.018152279204693   9: 0.018151247782867   4: 0.018150979018717   7: 0.018150785965730   3: 0.018150149742252 

training_7876     5: 0.376628196063658   0: 0.270104409081726   9: 0.132502649435140   2: 0.129240525864049   6: 0.015258036324944   8: 0.015256636066809   1: 0.015255137339536   4: 0.015251882182677   7: 0.015251313790338   3: 0.015251213851123 

training_7877     6: 0.768330661331159   1: 0.103302023695669   0: 0.052449497124824   4: 0.010849285592375   3: 0.010848177724017   5: 0.010845850245712   8: 0.010844262842619   7: 0.010843777043779   9: 0.010843507045818   2: 0.010842957354027 

training_7878     5: 0.654425263357995   4: 0.038401702940347   3: 0.038396911483021   2: 0.038396753458257   8: 0.038396743244424   7: 0.038396633106740   9: 0.038396541489859   0: 0.038396535312372   1: 0.038396471810749   6: 0.038396443796237 

training_7879     4: 0.547858924977643   6: 0.297406112518552   2: 0.039048114264480   1: 0.016764988076096   5: 0.016637862338997   0: 0.016473312587873   3: 0.016454850122819   9: 0.016452177995472   8: 0.016452004890013   7: 0.016451652228056 

training_7880     5: 0.769447785032738   4: 0.025620294801032   6: 0.025616931199306   8: 0.025616830723634   9: 0.025616471385809   3: 0.025616432490664   7: 0.025616354931077   0: 0.025616347410601   2: 0.025616325249264   1: 0.025616226775874 

training_7881     7: 0.389836050860466   5: 0.339778580125403   6: 0.033808446708719   0: 0.033803138593656   4: 0.033799567733453   1: 0.033798011569259   8: 0.033795473426756   9: 0.033794774670974   3: 0.033793251687173   2: 0.033792704624140 

training_7883     4: 0.541410399874710   5: 0.254723530034664   0: 0.070240821561168   6: 0.019093343586535   7: 0.019092939478349   9: 0.019088621361411   8: 0.019088348460608   1: 0.019087813225572   2: 0.019087232513443   3: 0.019086949903537 

training_7884     5: 0.757310966062847   4: 0.026969929490406   8: 0.026965194797652   9: 0.026964993984114   3: 0.026964905269730   2: 0.026964871418961   6: 0.026964858122317   0: 0.026964798875216   7: 0.026964771060674   1: 0.026964710918083 

training_7887     4: 0.678047913550655   5: 0.094798358066783   7: 0.028396102491712   8: 0.028395944465507   1: 0.028393838618204   2: 0.028393737267013   3: 0.028393693221748   0: 0.028393508907703   6: 0.028393483571312   9: 0.028393419839364 

training_7888     6: 0.724957778401099   8: 0.064381908875128   0: 0.056243536113009   7: 0.042804156283783   1: 0.018624715452045   5: 0.018599194423309   9: 0.018597632405330   3: 0.018597200069142   2: 0.018596946811452   4: 0.018596931165703 

training_7891     1: 0.578550803190117   9: 0.166923118601178   2: 0.091135018619643   6: 0.023348343992117   0: 0.023344785237164   5: 0.023341657045772   4: 0.023339699821128   7: 0.023339108761793   3: 0.023338743801791   8: 0.023338720929298 

training_7893     1: 0.429959632972520   6: 0.294824222576888   5: 0.185222190984976   8: 0.012870981617754   0: 0.012857470289697   4: 0.012853591292917   3: 0.012853374948026   2: 0.012853032212893   9: 0.012852754639171   7: 0.012852748465158 

training_7894     5: 0.774075373576990   6: 0.025113709215971   0: 0.025107452142848   8: 0.025105879058150   9: 0.025104000584841   1: 0.025099650780016   3: 0.025098797119936   7: 0.025098750456494   4: 0.025098649449382   2: 0.025097737615371 

training_7895     2: 0.382672280267039   4: 0.306812853858609   3: 0.164025504947733   1: 0.020947866097894   0: 0.020932960671533   5: 0.020929530373662   6: 0.020925148227015   9: 0.020921349736506   8: 0.020916765585194   7: 0.020915740234816 

training_7896     0: 0.593494574789614   6: 0.265852568907518   1: 0.017584572892980   5: 0.017584433131902   2: 0.017582219386024   8: 0.017580980768214   9: 0.017580607483723   4: 0.017580515613715   7: 0.017579966170634   3: 0.017579560855676 

training_7897     1: 0.396522854658839   6: 0.266285468404769   5: 0.127600159843839   3: 0.060468392025817   0: 0.057917327128582   4: 0.018278723595812   9: 0.018232488300903   2: 0.018232009324257   7: 0.018231969210497   8: 0.018230607506685 

training_7899     6: 0.647776326862546   1: 0.113225533752676   0: 0.082273808788560   5: 0.038929408543072   2: 0.036813476237946   4: 0.016196567100246   8: 0.016196478445335   7: 0.016196321568378   9: 0.016196174340277   3: 0.016195904360965 

training_7901     6: 0.565224438239940   5: 0.201152846217739   1: 0.109186065017133   8: 0.025940816823232   0: 0.025619638854049   9: 0.014575412284819   3: 0.014575311287783   2: 0.014575303346508   4: 0.014575218833697   7: 0.014574949095101 

training_7902     5: 0.814244511770054   4: 0.040265228113500   9: 0.018228023514940   6: 0.018196614677401   7: 0.018189819722031   0: 0.018181699390439   1: 0.018179683865964   8: 0.018173090499888   2: 0.018170691763354   3: 0.018170636682430 

training_7903     0: 0.493146945022708   2: 0.225100947369369   5: 0.090952879165611   9: 0.090632744170512   6: 0.016700080786793   4: 0.016694537808404   1: 0.016694520687425   8: 0.016692616937821   7: 0.016692414928491   3: 0.016692313122867 

training_7904     5: 0.427203414095829   4: 0.303652013730894   0: 0.163963460289163   6: 0.015031765362504   1: 0.015027130279816   9: 0.015025927329830   7: 0.015024673129728   2: 0.015024351716496   8: 0.015024067073016   3: 0.015023196992724 

training_7907     6: 0.765044713188621   0: 0.120579747708027   1: 0.014299082012312   5: 0.014298755351443   9: 0.014297423537827   2: 0.014296457327927   3: 0.014296169991816   4: 0.014295984861312   8: 0.014295908224065   7: 0.014295757796650 

training_791      6: 0.621971336760849   1: 0.132212320014764   7: 0.106701596254224   8: 0.043667503453311   5: 0.015917188147119   0: 0.015910863037050   9: 0.015906316880598   2: 0.015904450869002   4: 0.015904345508145   3: 0.015904079074936 

training_7912     5: 0.608651634385897   0: 0.111826594670964   8: 0.077379489437666   6: 0.051956729216787   1: 0.048448200888641   4: 0.020349212544122   9: 0.020347463720084   7: 0.020347371110492   3: 0.020346699184069   2: 0.020346604841279 

training_7913     5: 0.599987737936823   4: 0.200282917563990   3: 0.024966843446708   6: 0.024966177666738   8: 0.024966169752190   0: 0.024966158460513   1: 0.024966068979585   2: 0.024966033179308   7: 0.024965988850262   9: 0.024965904163882 

training_7914     4: 0.776222267043049   5: 0.024870886789406   0: 0.024863448382147   8: 0.024863436536877   3: 0.024863380489328   1: 0.024863371079648   2: 0.024863344755509   9: 0.024863324609980   6: 0.024863299382397   7: 0.024863240931659 

training_7917     6: 0.634230349414595   0: 0.144205333027111   1: 0.123224825300715   9: 0.018872492536799   8: 0.013250139847934   7: 0.013243936691339   5: 0.013243885683221   2: 0.013243094497511   3: 0.013243007549290   4: 0.013242935451484 

training_7918     4: 0.446939591130215   6: 0.263130508933762   0: 0.166874342828570   1: 0.022560077669968   3: 0.016755639860877   8: 0.016755255319607   9: 0.016749421563661   5: 0.016747535022244   7: 0.016743871540612   2: 0.016743756130485 

training_7920     5: 0.565612283199629   6: 0.214899813911621   2: 0.027440187735633   8: 0.027438814984209   0: 0.027436775715130   9: 0.027436570345250   1: 0.027434465255865   7: 0.027434057333747   4: 0.027434029275175   3: 0.027433002243743 

training_7921     6: 0.618500794145166   5: 0.193093361786006   9: 0.023554850319287   8: 0.023551164733046   4: 0.023551014247005   0: 0.023550904438981   7: 0.023550066375898   1: 0.023549656141411   2: 0.023549187905234   3: 0.023548999907966 

training_7922     4: 0.723378468031178   5: 0.030740834352528   0: 0.030735576783158   8: 0.030735147731700   3: 0.030735131663682   9: 0.030735068523740   6: 0.030735040083352   2: 0.030734973534588   7: 0.030734903433050   1: 0.030734855863024 

training_7924     6: 0.561631097478065   0: 0.280673290662447   8: 0.040226477022776   9: 0.016786315536349   5: 0.016784246498840   4: 0.016781730550802   7: 0.016779633193737   1: 0.016779525531489   2: 0.016778987504730   3: 0.016778696020764 

training_7927     0: 0.584532256492934   1: 0.164073233359220   6: 0.079223221270646   5: 0.056982725735385   2: 0.055270406789192   7: 0.011998856861030   8: 0.011992142853268   9: 0.011976628244427   4: 0.011975539874175   3: 0.011974988519723 

training_7928     5: 0.826884931445311   1: 0.019247284429351   0: 0.019238619838287   6: 0.019238169226856   4: 0.019232486941299   3: 0.019232449210185   8: 0.019231850809748   9: 0.019231595898282   7: 0.019231369557532   2: 0.019231242643149 

training_793      6: 0.566996365716299   7: 0.265761131642325   9: 0.020911794364729   1: 0.020907672613118   5: 0.020905619257182   0: 0.020905599122508   2: 0.020904673796741   3: 0.020902603553651   8: 0.020902488266707   4: 0.020902051666741 

training_7930     1: 0.624249072968821   2: 0.152460276605257   5: 0.059816915514159   4: 0.051875210029713   6: 0.018643382717001   9: 0.018597537653912   8: 0.018596031985894   0: 0.018591513890302   3: 0.018585071325906   7: 0.018584987309035 

training_7934     6: 0.768056698002742   0: 0.086374397409110   8: 0.052378589369213   5: 0.023807985315397   1: 0.011570857351083   4: 0.011563827934563   7: 0.011563331346314   9: 0.011561846112817   3: 0.011561248418044   2: 0.011561218740717 

training_7935     0: 0.612661827387036   8: 0.222204306992123   2: 0.020645190896002   4: 0.020645088470454   6: 0.020643883032235   9: 0.020643847433271   5: 0.020641780460133   1: 0.020640347113222   7: 0.020636932407236   3: 0.020636795808287 

training_7937     6: 0.810221633294586   1: 0.090568028008544   0: 0.016331687976061   5: 0.012041175088429   7: 0.011889890006753   8: 0.011802512029036   4: 0.011786517857090   9: 0.011786473565208   3: 0.011786405274729   2: 0.011785676899565 

training_7939     1: 0.436333496475589   6: 0.317070532412268   7: 0.130989409809832   5: 0.016525589433472   4: 0.016518402347611   0: 0.016516630683748   9: 0.016512813451375   3: 0.016511259001737   2: 0.016511144766864   8: 0.016510721617505 

training_7940     1: 0.591054012086036   6: 0.221026901173790   8: 0.094326225239338   2: 0.020319875623804   0: 0.012222682977268   9: 0.012213974927575   5: 0.012209807023681   4: 0.012209453279320   7: 0.012209249593673   3: 0.012207818075514 

training_7942     5: 0.776056867811390   3: 0.024882980522264   4: 0.024882871746333   6: 0.024882818752573   1: 0.024882611511786   0: 0.024882564932248   8: 0.024882409974549   2: 0.024882298068817   7: 0.024882289057321   9: 0.024882287622719 

training_7943     6: 0.601634702722800   7: 0.174142846090533   8: 0.028028954081813   0: 0.028028000011675   5: 0.028027773275068   1: 0.028027754054832   9: 0.028027626424476   4: 0.028027487849073   3: 0.028027428180140   2: 0.028027427309590 

training_7948     5: 0.722199904824215   7: 0.077397743713560   9: 0.061911388359934   3: 0.019800556528650   8: 0.019792994690902   6: 0.019782083067798   4: 0.019779416531784   0: 0.019779235976149   2: 0.019778849165055   1: 0.019777827141953 

training_7949     1: 0.570941685778070   5: 0.247922490815624   6: 0.022675022977824   9: 0.022641329856920   0: 0.022639455220715   8: 0.022636590902137   4: 0.022636447766530   3: 0.022636036880734   2: 0.022635676623282   7: 0.022635263178163 

training_7950     6: 0.846790398768151   3: 0.041318294629776   0: 0.027618456507796   1: 0.021741634129217   5: 0.010438687388987   2: 0.010419149534564   4: 0.010418689277642   8: 0.010418300846751   9: 0.010418261940407   7: 0.010418126976710 

training_7951     6: 0.647505474229675   0: 0.131999141046538   3: 0.071778701340119   1: 0.048711896568423   5: 0.016670261229104   4: 0.016668122334426   8: 0.016667098144014   9: 0.016666640490445   2: 0.016666430356315   7: 0.016666234260941 

training_7953     5: 0.778061215986354   2: 0.059316793478911   4: 0.020333721237019   0: 0.020327011033662   6: 0.020326984519967   8: 0.020326916677389   3: 0.020326895979163   9: 0.020326867407761   1: 0.020326804081380   7: 0.020326789598394 

training_7954     5: 0.818939424608305   6: 0.020125525324662   0: 0.020122645078445   4: 0.020120970817118   8: 0.020115775981019   1: 0.020115736688663   2: 0.020115436002296   7: 0.020115000223836   9: 0.020114874210280   3: 0.020114611065376 

training_7955     5: 0.622910291687571   0: 0.111130952244582   1: 0.100579031285698   4: 0.023626113657270   6: 0.023626078437728   3: 0.023625703260839   9: 0.023625672411657   7: 0.023625417586981   2: 0.023625383894689   8: 0.023625355532985 

training_7956     3: 0.792947326218447   5: 0.023026151402580   4: 0.023005262709518   6: 0.023003247147430   0: 0.023003159968528   8: 0.023003117019998   2: 0.023003014272820   7: 0.023002960276522   1: 0.023002946762823   9: 0.023002814221333 

training_7957     6: 0.794571482747459   5: 0.051430693363461   0: 0.019250993033587   1: 0.019250155095483   4: 0.019249930769149   3: 0.019249485354683   9: 0.019249414395380   2: 0.019249376251674   7: 0.019249291866630   8: 0.019249177122494 

training_7958     5: 0.470255271189574   0: 0.288225592897644   1: 0.086094955420679   4: 0.022215472925702   6: 0.022201987339381   2: 0.022201736162711   9: 0.022201666741385   3: 0.022201247892713   8: 0.022201175325944   7: 0.022200894104267 

training_7959     6: 0.407117451665522   9: 0.376936434870213   1: 0.081464311550868   8: 0.041850337156280   5: 0.015443193964821   0: 0.015441161138447   4: 0.015438485105451   2: 0.015437034155212   7: 0.015435813402961   3: 0.015435776990226 

training_7961     6: 0.784655862056404   0: 0.086012210571264   5: 0.016179241511646   1: 0.016167725903144   8: 0.016166077757420   4: 0.016164549159514   2: 0.016163964592840   7: 0.016163761849346   9: 0.016163320789074   3: 0.016163285809348 

training_7962     6: 0.812401854631496   4: 0.041628828704991   9: 0.018249802056819   0: 0.018246954854253   5: 0.018246947078364   3: 0.018245926692866   1: 0.018245529293451   8: 0.018244745960891   2: 0.018244717051130   7: 0.018244693675739 

training_7963     1: 0.597283125191828   4: 0.217493164325763   6: 0.050061299713194   8: 0.019442084927744   0: 0.019311949618379   7: 0.019287240044834   9: 0.019283876289456   5: 0.019282860384666   2: 0.019278004830684   3: 0.019276394673452 

training_7964     8: 0.448068221901074   1: 0.388594014890104   5: 0.020423791944139   6: 0.020421509644731   0: 0.020419174522809   4: 0.020416934409393   7: 0.020416329633448   2: 0.020415697131848   9: 0.020412628226443   3: 0.020411697696010 

training_7966     0: 0.466325718412670   3: 0.328362310548798   4: 0.070903868794650   6: 0.019217657378594   1: 0.019202268622978   9: 0.019198692414771   5: 0.019198458988993   8: 0.019197583033032   7: 0.019197001079478   2: 0.019196440726035 

training_7967     0: 0.493555864673608   8: 0.301388452904724   3: 0.064155916686302   6: 0.020140290202444   5: 0.020134722654802   1: 0.020127183863496   2: 0.020125515911110   4: 0.020125231649781   9: 0.020123679352574   7: 0.020123142101160 

training_7968     1: 0.513174629896011   6: 0.203272354228729   3: 0.124469272293083   5: 0.054087564131820   7: 0.028714739937763   0: 0.015267470444901   8: 0.015254359595643   9: 0.015253422864160   4: 0.015253133740981   2: 0.015253052866909 

training_7969     7: 0.694213212687976   5: 0.033983839730908   2: 0.033981507140510   1: 0.033979508369244   0: 0.033977230763045   6: 0.033976951759812   4: 0.033974266425600   9: 0.033972911333466   8: 0.033970554763546   3: 0.033970017025892 

training_797      0: 0.601391525449122   1: 0.157666788938307   3: 0.092056852347802   6: 0.046589171306465   4: 0.017067062250521   5: 0.017051118073705   9: 0.017044819197877   8: 0.017044376530671   7: 0.017044239760595   2: 0.017044046144935 

training_7970     5: 0.615224187882833   6: 0.250080509424201   0: 0.016837896595966   4: 0.016837714210472   1: 0.016837363064735   8: 0.016837157553725   9: 0.016836894305890   7: 0.016836150940517   2: 0.016836121256448   3: 0.016836004765212 

training_7971     8: 0.760777496971580   5: 0.026585849276781   6: 0.026585636852484   0: 0.026580302287452   1: 0.026579340957549   4: 0.026579334536019   9: 0.026579004749392   7: 0.026578817671656   2: 0.026577625670736   3: 0.026576591026351 

training_7972     6: 0.634550667290846   0: 0.117764375372958   3: 0.103647710313531   9: 0.067848275583963   5: 0.017455236242441   2: 0.011932665174473   7: 0.011731408255909   1: 0.011705217778009   4: 0.011696383325333   8: 0.011668060662537 

training_7974     5: 0.543500405124391   2: 0.227511750362423   3: 0.074616757447891   6: 0.022055870971401   1: 0.022054618581111   7: 0.022053007869137   0: 0.022052920828224   9: 0.022052190853699   4: 0.022051316470891   8: 0.022051161490831 

training_7975     5: 0.416763940736888   0: 0.246778501035700   1: 0.130341075542351   2: 0.078184099179058   6: 0.021325025724357   9: 0.021322554310766   7: 0.021321927200719   4: 0.021321189845247   3: 0.021321156584736   8: 0.021320529840178 

training_7977     1: 0.459562111771359   7: 0.394621414530397   4: 0.026515854355634   0: 0.023136934610168   6: 0.016048422345416   9: 0.016032625069263   5: 0.016029483091529   8: 0.016018109574587   2: 0.016017701627026   3: 0.016017343024621 

training_7979     5: 0.741770492300079   1: 0.064982102169795   6: 0.024158178484860   0: 0.024157172904595   2: 0.024156824457100   4: 0.024156158085001   9: 0.024155216144687   7: 0.024154895132834   8: 0.024154530382874   3: 0.024154429938176 

training_798      6: 0.723713717261039   5: 0.085483086368210   0: 0.063693108885177   8: 0.036026882317622   1: 0.015281697928013   2: 0.015161661732786   4: 0.015160600197165   9: 0.015160027006312   3: 0.015159697983826   7: 0.015159520319850 

training_7980     5: 0.586833358284512   6: 0.252515496348149   8: 0.020097232850275   0: 0.020082860532418   1: 0.020079347022112   9: 0.020078998758194   7: 0.020078813873894   4: 0.020078677561789   2: 0.020078198099145   3: 0.020077016669512 

training_7983     7: 0.310113150226051   6: 0.248852961131142   1: 0.206623802249470   4: 0.091754912215987   5: 0.023781273298038   0: 0.023777440359872   9: 0.023774806623166   8: 0.023774168533588   2: 0.023774142422434   3: 0.023773342940252 

training_7984     5: 0.647741798553315   8: 0.093645939788475   0: 0.077893164284199   4: 0.025826317426952   7: 0.025820318766993   1: 0.025816652188284   6: 0.025815820102629   9: 0.025814571965340   3: 0.025814555928278   2: 0.025810860995535 

training_7985     6: 0.434419256145510   2: 0.174724501006776   4: 0.160411425012335   0: 0.117187247061178   3: 0.018994351599721   1: 0.018860108590536   5: 0.018858512187595   9: 0.018848911925701   7: 0.018848288142079   8: 0.018847398328570 

training_7987     5: 0.743693986284203   4: 0.028480888628712   6: 0.028480426377609   9: 0.028479661725013   8: 0.028479124038806   0: 0.028478034345940   1: 0.028477489840844   7: 0.028476840353319   2: 0.028476796057974   3: 0.028476752347581 

training_7990     5: 0.561765840911804   0: 0.142415832900420   6: 0.130021547584632   3: 0.023686251985082   4: 0.023685378703957   1: 0.023685233465924   7: 0.023685057630575   2: 0.023685048060491   8: 0.023684970191388   9: 0.023684838565727 

training_7991     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_7992     1: 0.455504534659697   5: 0.379386100410606   6: 0.020643427034145   0: 0.020643102011088   8: 0.020637662652054   4: 0.020637607479974   2: 0.020637141697470   9: 0.020637021926444   7: 0.020636830276288   3: 0.020636571852234 

training_7993     1: 0.592835487547819   5: 0.238566785022395   6: 0.021080034193271   0: 0.021075167675823   9: 0.021074297258656   2: 0.021073952778687   8: 0.021073848500487   7: 0.021073575938237   4: 0.021073551123283   3: 0.021073299961341 

training_7994     5: 0.700277366763158   4: 0.083783955698040   1: 0.081381635661459   8: 0.019240602486642   6: 0.019220909530608   0: 0.019219285904399   9: 0.019219222351753   7: 0.019219126125363   3: 0.019218953109433   2: 0.019218942369145 

training_7997     5: 0.479489136055969   1: 0.300163203582804   7: 0.069328088258643   6: 0.021580909260349   0: 0.021575844939722   9: 0.021573466315087   4: 0.021573305376421   2: 0.021572661572145   8: 0.021572012906303   3: 0.021571371732557 

training_80       5: 0.512563285204781   6: 0.349772781468321   8: 0.017209902392079   0: 0.017209120339753   1: 0.017209087376083   9: 0.017207591744987   4: 0.017207461657336   7: 0.017207373318120   2: 0.017206967922864   3: 0.017206428575676 

training_800      6: 0.532514331644084   9: 0.173309956711476   7: 0.151398224029647   8: 0.020404643869046   0: 0.020402039428474   5: 0.020400931506622   1: 0.020395812629151   2: 0.020391966999655   3: 0.020391343975168   4: 0.020390749206677 

training_8000     6: 0.460516510409892   0: 0.388110817227234   1: 0.032928505917167   7: 0.031964905654536   5: 0.014427359386683   4: 0.014410884407611   2: 0.014410449344658   9: 0.014410433315011   8: 0.014410171086783   3: 0.014409963250425 

training_8001     5: 0.802071779386361   4: 0.021995098126118   8: 0.021991871944002   6: 0.021991819159248   9: 0.021991683824580   0: 0.021991677436365   3: 0.021991569369507   7: 0.021991538914431   2: 0.021991515520144   1: 0.021991446319244 

training_8002     4: 0.726957688219736   1: 0.030345597222343   6: 0.030341088728504   0: 0.030340656854427   5: 0.030339774152294   2: 0.030337866516078   8: 0.030336554841758   9: 0.030333909733280   3: 0.030333596739938   7: 0.030333266991641 

training_8003     6: 0.830586740355262   0: 0.039914977506774   4: 0.027984444912435   5: 0.024992928411934   2: 0.012761079808716   1: 0.012752171354137   8: 0.012752097179332   7: 0.012751961340498   3: 0.012751830821150   9: 0.012751768309762 

training_8004     6: 0.749971502523361   0: 0.076011428828302   5: 0.053495879519281   8: 0.033307059584807   3: 0.032275578568741   1: 0.011002340518074   7: 0.010986793831531   4: 0.010984213438562   9: 0.010982665454558   2: 0.010982537732784 

training_8005     5: 0.759692516744756   4: 0.026707658824974   8: 0.026700254316398   3: 0.026700096692997   9: 0.026700017140418   2: 0.026699967857134   6: 0.026699933088312   7: 0.026699918036613   0: 0.026699848734498   1: 0.026699788563900 

training_8007     5: 0.521324998530695   0: 0.200079269752926   2: 0.081360678683598   1: 0.069183657572426   4: 0.021358439681654   6: 0.021340300273282   9: 0.021338830864406   3: 0.021338372656290   7: 0.021337746740644   8: 0.021337705244080 

training_8008     6: 0.592608139460985   0: 0.242662181249675   1: 0.065274804415559   4: 0.022462638222211   5: 0.021004091538531   7: 0.011201085224132   2: 0.011197804244941   9: 0.011196571926865   8: 0.011196552686126   3: 0.011196131030975 

training_8009     6: 0.727807619211177   5: 0.101794608528394   1: 0.074081071221055   2: 0.027142825692333   0: 0.014381897310595   9: 0.010977505944164   3: 0.010956010977046   7: 0.010954354417566   8: 0.010952403798091   4: 0.010951702899579 

training_8010     4: 0.581577189754425   6: 0.264301700566080   5: 0.033602848864005   7: 0.017243401943558   1: 0.017218409261657   0: 0.017215310716990   9: 0.017210827465921   8: 0.017210419799528   2: 0.017210244856508   3: 0.017209646771328 

training_8011     5: 0.724079943146149   9: 0.030760371237958   6: 0.030656567480068   7: 0.030645818364343   4: 0.030645798439597   0: 0.030642796428742   1: 0.030642702654337   8: 0.030642521126191   2: 0.030641753175467   3: 0.030641727947147 

training_8012     5: 0.521940203828051   4: 0.312444067825593   1: 0.020706505243026   6: 0.020705697272157   0: 0.020705101041273   2: 0.020701417216693   9: 0.020701217747369   8: 0.020699260096529   7: 0.020698318415752   3: 0.020698211313557 

training_8015     9: 0.469661790788841   6: 0.229037615671449   1: 0.105933980382642   5: 0.066514947456332   7: 0.036466945880017   2: 0.018485416604815   4: 0.018477692209535   0: 0.018474458526209   8: 0.018474390090005   3: 0.018472762390154 

training_8016     5: 0.594775557417806   0: 0.217337858159550   1: 0.023487536110860   6: 0.023486579555189   4: 0.023485936732438   3: 0.023485748769529   9: 0.023485327944916   2: 0.023485185610895   8: 0.023485141883646   7: 0.023485127815172 

training_8017     4: 0.737481287857124   8: 0.093132458144116   5: 0.021179384686765   6: 0.021173119857667   1: 0.021172734163993   0: 0.021172608019617   3: 0.021172185603422   9: 0.021172110583195   2: 0.021172110547379   7: 0.021172000536721 

training_8020     1: 0.537685350189027   7: 0.175680016523326   8: 0.160384887265303   6: 0.018054330875631   0: 0.018040952934476   5: 0.018035328871178   4: 0.018030711302197   2: 0.018029864657898   9: 0.018029678265907   3: 0.018028879115057 

training_8021     6: 0.429479998877925   8: 0.280349443908710   0: 0.140550890620389   9: 0.034023277006726   7: 0.033480898707667   5: 0.016502750244001   1: 0.016414069483183   3: 0.016403039876756   4: 0.016397902106566   2: 0.016397729168076 

training_8022     5: 0.426885415847729   0: 0.290674187537399   1: 0.191880340249783   9: 0.012945993769501   6: 0.012941459292359   8: 0.012935461545375   7: 0.012934560612658   4: 0.012934456672796   2: 0.012934238751129   3: 0.012933885721270 

training_8023     1: 0.302616874213247   2: 0.294660223745578   5: 0.274288610407845   6: 0.018363121596046   0: 0.018352135197884   4: 0.018343920359874   3: 0.018343799316470   7: 0.018343796301038   8: 0.018343795713203   9: 0.018343723148815 

training_8025     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_8026     4: 0.677643257820454   1: 0.121483544589587   5: 0.025117033231748   6: 0.025109338045923   0: 0.025108229000131   8: 0.025108108507837   9: 0.025107877241997   3: 0.025107570192053   7: 0.025107560714855   2: 0.025107480655415 

training_8027     5: 0.818259304246180   4: 0.020198710977198   1: 0.020193259407486   0: 0.020192885532424   6: 0.020192723799048   2: 0.020192719060110   8: 0.020192694681935   7: 0.020192576614416   3: 0.020192566461757   9: 0.020192559219446 

training_8028     5: 0.782587938888895   3: 0.024157774985449   4: 0.024157125902871   1: 0.024156934467888   0: 0.024156857396676   2: 0.024156806406768   6: 0.024156658972777   7: 0.024156657142061   8: 0.024156623144198   9: 0.024156622692417 

training_8029     6: 0.723617078326103   0: 0.106553121056505   1: 0.079287663370148   2: 0.031002157333510   5: 0.009938978315622   4: 0.009921008388845   8: 0.009920758069705   9: 0.009920424657821   7: 0.009919439873535   3: 0.009919370608206 

training_8030     4: 0.800610732208454   5: 0.022159869870175   1: 0.022154065879041   0: 0.022153934001875   6: 0.022153694356511   8: 0.022153585035513   2: 0.022153578324059   9: 0.022153537914368   3: 0.022153512540334   7: 0.022153489869669 

training_8032     5: 0.358836630671180   4: 0.318795758814002   1: 0.105670246984801   8: 0.077604363758776   0: 0.050969942055228   9: 0.017632527672549   6: 0.017628074909914   2: 0.017622387399039   3: 0.017620126139811   7: 0.017619941594701 

training_8036     5: 0.716200857954143   8: 0.075053081479132   0: 0.069524319028219   6: 0.020064915022113   4: 0.019862595453862   1: 0.019861007515748   2: 0.019858368241462   9: 0.019858327515711   7: 0.019858304988623   3: 0.019858222800988 

training_8039     5: 0.395008057415973   6: 0.231027488660458   8: 0.152225972216576   4: 0.086670821245231   1: 0.036326198041369   0: 0.036188351256991   9: 0.015750350011002   7: 0.015602111671756   2: 0.015600691132962   3: 0.015599958347682 

training_8040     1: 0.743112618764981   6: 0.123978766842222   7: 0.016820870331167   0: 0.016619385387862   5: 0.016585954766884   9: 0.016583415287851   3: 0.016580040204945   8: 0.016573311676933   4: 0.016573064627779   2: 0.016572572109375 

training_8041     6: 0.565905827566197   9: 0.201764418717683   0: 0.130020558972178   4: 0.044384919212953   7: 0.009780301604400   1: 0.009691404592141   2: 0.009614520179455   5: 0.009614197284993   8: 0.009612040961070   3: 0.009611810908931 

training_8044     6: 0.680927627906501   0: 0.155867949888168   9: 0.059110408170911   1: 0.031221376574114   4: 0.016776479982213   2: 0.013573190601596   3: 0.010633188336664   5: 0.010630408577356   8: 0.010629796567669   7: 0.010629573394808 

training_8045     5: 0.768551800871933   4: 0.071927776848659   3: 0.019964793868965   6: 0.019941468166998   0: 0.019937041897375   1: 0.019936383939814   9: 0.019935718293335   8: 0.019935497595113   7: 0.019934821055714   2: 0.019934697462094 

training_8047     5: 0.681033966091872   0: 0.157926619339384   4: 0.020161303445180   6: 0.020128237411805   9: 0.020125399826789   8: 0.020125302383857   1: 0.020125278730415   7: 0.020124784680285   2: 0.020124567811223   3: 0.020124540279190 

training_8048     4: 0.687946603360615   5: 0.127455657649542   6: 0.023075900022470   7: 0.023074886532810   0: 0.023074885788933   8: 0.023074687924640   1: 0.023074375523515   9: 0.023074365936950   3: 0.023074343094761   2: 0.023074294165766 

training_8050     5: 0.511239124047035   6: 0.314265790826388   4: 0.021815764346118   0: 0.021814350593383   1: 0.021812432369070   9: 0.021811178507332   2: 0.021810768927842   7: 0.021810368200279   8: 0.021810247666206   3: 0.021809974516347 

training_8051     5: 0.511446369266090   6: 0.314058542029555   4: 0.021815761378893   0: 0.021814354171872   1: 0.021812433995208   9: 0.021811179228274   2: 0.021810769199961   7: 0.021810368474310   8: 0.021810247755490   3: 0.021809974500348 

training_8055     6: 0.747781191918892   0: 0.106421132778528   5: 0.051347914245916   1: 0.031716917367552   9: 0.010573940289889   4: 0.010546463102479   8: 0.010427749583724   7: 0.010395176337707   3: 0.010394795020085   2: 0.010394719355228 

training_8056     4: 0.651559078946946   5: 0.197429246544433   6: 0.018878019522975   1: 0.018876521774511   8: 0.018876299903882   0: 0.018876280637643   3: 0.018876214222467   7: 0.018876158107612   9: 0.018876105688537   2: 0.018876074650994 

training_8060     6: 0.656629751521279   1: 0.155299331025016   0: 0.121075778810028   5: 0.009574841376478   4: 0.009572210113373   3: 0.009571507445349   9: 0.009570438082379   7: 0.009569510312475   2: 0.009568380910026   8: 0.009568250403597 

training_8063     6: 0.828612979948072   9: 0.041911831686568   8: 0.033411646402778   1: 0.013841764541380   7: 0.013774635044628   0: 0.013693449270631   5: 0.013691747860488   2: 0.013687555065819   4: 0.013687287399142   3: 0.013687102780494 

training_8064     6: 0.671043248944471   9: 0.156395321024075   1: 0.040297816214824   0: 0.039769302253450   5: 0.015426061836611   7: 0.015416443973863   4: 0.015414929520360   8: 0.015412837042702   2: 0.015412060970809   3: 0.015411978218834 

training_8068     1: 0.540718309895091   6: 0.282925725741645   0: 0.088679229880905   4: 0.018708964614147   8: 0.011573821221920   5: 0.011494771748928   9: 0.011475273408439   7: 0.011474882840547   2: 0.011474515568699   3: 0.011474505079679 

training_8069     6: 0.806901375813231   0: 0.059598528900987   7: 0.050605123295554   1: 0.024585934826003   3: 0.009719488835588   4: 0.009718464366843   5: 0.009718231885885   9: 0.009717782823874   8: 0.009717567467046   2: 0.009717501784990 

training_8074     6: 0.635038668752781   0: 0.190727325714225   1: 0.083367487769705   7: 0.020793882357029   5: 0.019434059650588   9: 0.010138013810346   2: 0.010136269470402   8: 0.010121899845153   3: 0.010121242560932   4: 0.010121150068838 

training_8080     6: 0.797159768290516   0: 0.084805490486791   1: 0.039627979114249   3: 0.022643957157083   7: 0.013228570903095   9: 0.008549007476860   8: 0.008505571474376   5: 0.008493553382755   2: 0.008493102140457   4: 0.008492999573818 

training_8085     0: 0.633473928657000   6: 0.229913829318480   5: 0.036472417214645   7: 0.024904971988681   4: 0.020964665671145   1: 0.010868306343095   2: 0.010851122846419   3: 0.010850404779676   8: 0.010850395712948   9: 0.010849957467912 

training_8086     6: 0.804879994692130   0: 0.076861174632383   7: 0.014784389236241   1: 0.014783298257749   2: 0.014782138568783   5: 0.014782050068217   9: 0.014781835723481   3: 0.014781786262703   8: 0.014781694075588   4: 0.014781638482725 

training_8087     6: 0.834696949663220   5: 0.018384878394482   4: 0.018375127607163   1: 0.018364571981778   0: 0.018363951196716   9: 0.018363841264723   3: 0.018363370494582   8: 0.018362885646183   2: 0.018362350787530   7: 0.018362072963624 

training_8088     6: 0.703814670536442   0: 0.141430285405381   4: 0.042500657590693   3: 0.031947384524589   1: 0.022059297583636   5: 0.011649670057429   2: 0.011649564088510   8: 0.011649535024555   7: 0.011649475858982   9: 0.011649459329782 

training_8089     9: 0.526895494227632   6: 0.243283745651229   0: 0.071096114244379   7: 0.046378260708678   8: 0.018727183289822   1: 0.018725640891415   2: 0.018725090946573   3: 0.018724596894931   5: 0.018723768682262   4: 0.018720104463081 

training_8091     0: 0.567211645693124   6: 0.229107709503119   4: 0.112349965861713   5: 0.017679397017612   9: 0.013453804285628   1: 0.012100566435182   7: 0.012029880010217   3: 0.012022775024519   2: 0.012022218162732   8: 0.012022038006153 

training_8094     6: 0.755161975000763   8: 0.080582642929392   3: 0.046142923403505   1: 0.027028505514860   0: 0.015217867944147   7: 0.015183249453032   5: 0.015178352085228   4: 0.015172998747752   9: 0.015167126211385   2: 0.015164358709938 

training_8096     6: 0.643551483987552   3: 0.220239689203208   1: 0.025914574988874   8: 0.016203243382230   0: 0.015737690768902   5: 0.015673340258829   9: 0.015672940938396   4: 0.015670826859915   7: 0.015669187089662   2: 0.015667022522430 

training_8097     6: 0.706598270330176   1: 0.181701422597867   0: 0.022742104905029   9: 0.018275716298007   3: 0.011976086243031   8: 0.011923355829420   5: 0.011732511349344   4: 0.011683926987234   7: 0.011683496194642   2: 0.011683109265249 

training_8098     6: 0.485928454245031   0: 0.406120077354915   8: 0.026898276071188   1: 0.026032991884414   3: 0.016635005765147   7: 0.007678165814728   5: 0.007677620102464   4: 0.007677594102742   9: 0.007676021457173   2: 0.007675793202199 

training_81       6: 0.484375973845447   8: 0.374763598523782   5: 0.017635438944418   3: 0.017605209577871   0: 0.017604866696815   4: 0.017604654662642   1: 0.017604298354511   7: 0.017602477687917   9: 0.017602149286127   2: 0.017601332420470 

training_8100     6: 0.466344191240690   1: 0.407781668034487   0: 0.021118205339609   4: 0.014979067875596   5: 0.014977356181737   2: 0.014960246776116   8: 0.014960158642132   9: 0.014959913786848   7: 0.014959906292103   3: 0.014959285830682 

training_8102     6: 0.773006280605287   0: 0.082292072317712   9: 0.032551947122609   5: 0.031086973813247   8: 0.013582073779639   1: 0.013498978149610   2: 0.013498888012761   4: 0.013494308881198   3: 0.013494245142948   7: 0.013494232174989 

training_8103     6: 0.721133003514948   5: 0.143137703559241   9: 0.017007547510834   1: 0.016963467790661   0: 0.016961578689018   8: 0.016960254404484   2: 0.016959308811115   7: 0.016959147936082   3: 0.016959125344948   4: 0.016958862438668 

training_8105     6: 0.690292766223673   1: 0.098506447174515   3: 0.066578757056164   7: 0.044323545831655   0: 0.041927613241803   4: 0.011676503356903   5: 0.011676358408713   8: 0.011672768309995   2: 0.011672646711721   9: 0.011672593684858 

training_8106     6: 0.832424377276931   0: 0.090399918830462   8: 0.009662743725487   1: 0.009646413028943   3: 0.009645455482739   5: 0.009644552702340   2: 0.009644333627006   9: 0.009644084586227   4: 0.009644072785309   7: 0.009644047954555 

training_8108     2: 0.337100499401315   6: 0.297717453681865   0: 0.117406405812034   1: 0.105129107949940   9: 0.050263591929512   3: 0.032128929768821   5: 0.015068685760347   4: 0.015061952170041   7: 0.015061766572823   8: 0.015061606953302 

training_8109     6: 0.655142658930961   1: 0.176930342171063   5: 0.057399986943551   8: 0.046056393980846   7: 0.010770385586803   9: 0.010752949001741   3: 0.010740213984910   0: 0.010736804994871   2: 0.010735452970844   4: 0.010734811434410 

training_811      5: 0.738147311814759   0: 0.084420359295159   1: 0.022190436138068   6: 0.022183524867941   9: 0.022177178845365   8: 0.022176536183672   7: 0.022176241545827   3: 0.022176186653978   2: 0.022176143785386   4: 0.022176080869845 

training_8111     6: 0.840373664907607   9: 0.051372501332038   0: 0.013692414345536   1: 0.013562992581702   5: 0.013523835220643   7: 0.013508288985156   4: 0.013498253494592   3: 0.013489659401088   8: 0.013489332490232   2: 0.013489057241405 

training_8112     6: 0.800107658111130   5: 0.022215197107635   4: 0.022210880384089   0: 0.022210402833484   9: 0.022210021787200   7: 0.022209462393952   8: 0.022209416274291   1: 0.022209226381444   2: 0.022208945557515   3: 0.022208789169260 

training_8113     6: 0.745065577686678   1: 0.083586646797831   0: 0.067403752951174   7: 0.027884748001920   8: 0.012677203536080   9: 0.012676772550865   5: 0.012676545846182   3: 0.012676432524737   4: 0.012676244669136   2: 0.012676075435398 

training_8115     0: 0.279835290176486   5: 0.222730016966535   1: 0.216408360211836   6: 0.189168245733901   2: 0.018548551630222   7: 0.014662708960245   9: 0.014662294190872   4: 0.014662245958359   8: 0.014661329786151   3: 0.014660956385393 

training_8117     6: 0.759655603922981   0: 0.116462075924818   4: 0.034064292602105   1: 0.024713764310762   9: 0.010860933181038   8: 0.010856142191348   2: 0.010848323425619   5: 0.010848290890312   7: 0.010845758952805   3: 0.010844814598213 

training_8119     6: 0.656339812785830   2: 0.082617614004031   4: 0.079396440056719   9: 0.076338028800388   0: 0.017556113586702   7: 0.017552710958181   5: 0.017552682563094   1: 0.017549145132608   3: 0.017548776633937   8: 0.017548675478510 

training_8120     4: 0.559799231782306   7: 0.218877880893270   5: 0.027672927250822   6: 0.027670486106771   0: 0.027664808648736   8: 0.027664079644607   1: 0.027663838716223   9: 0.027663243918234   2: 0.027661909981020   3: 0.027661593058011 

training_8123     6: 0.528963178998447   2: 0.230029206074896   5: 0.030138514866306   1: 0.030130098252540   4: 0.030130077858928   0: 0.030124718400819   7: 0.030121652713624   8: 0.030121224211425   9: 0.030120795247471   3: 0.030120533375544 

training_8125     5: 0.667175806461515   3: 0.090717811852287   4: 0.074220027538089   7: 0.060546246218327   9: 0.017895727872531   6: 0.017893208920793   8: 0.017890860511950   1: 0.017887220043131   0: 0.017886961840029   2: 0.017886128741350 

training_8126     6: 0.365296230025137   0: 0.185883594135384   2: 0.161799647249680   8: 0.113506255451842   7: 0.068420179016216   1: 0.021024082023554   4: 0.021022824515734   5: 0.021021550792711   3: 0.021013312394524   9: 0.021012324395220 

training_8130     0: 0.518659275293092   6: 0.221272910810485   4: 0.159405093252134   8: 0.020878233240154   5: 0.014062486755145   1: 0.013594961833316   3: 0.013033188609090   2: 0.013032727463587   9: 0.013030869417953   7: 0.013030253325044 

training_8131     6: 0.692299763535925   9: 0.088985865882753   0: 0.087880873862858   1: 0.035972575486125   2: 0.023722102302494   4: 0.022696466421976   7: 0.012111807319279   5: 0.012110684549228   8: 0.012110229754661   3: 0.012109630884699 

training_8132     6: 0.846237557130969   5: 0.017086301337641   4: 0.017085020245685   9: 0.017084796112652   0: 0.017084783968189   8: 0.017084655110068   1: 0.017084560709605   7: 0.017084269762015   2: 0.017084085714712   3: 0.017083969908464 

training_8134     6: 0.704648433134149   1: 0.095682559324843   4: 0.062916122133695   7: 0.061984388569173   0: 0.012473981859322   5: 0.012460824115117   9: 0.012460310510125   2: 0.012458831727727   8: 0.012457352778643   3: 0.012457195847205 

training_8135     6: 0.813565841733166   9: 0.074984896849261   1: 0.028799818737017   0: 0.011864107458416   5: 0.011800238963972   3: 0.011798737943654   8: 0.011798157334262   7: 0.011797004854122   4: 0.011795864574764   2: 0.011795331551366 

training_8137     6: 0.692455008317963   0: 0.236941862883044   4: 0.009186250034471   1: 0.008932463957370   7: 0.008748151469320   5: 0.008747953458711   8: 0.008747491068901   2: 0.008747162232818   9: 0.008747028864760   3: 0.008746627712642 

training_8138     6: 0.795093414204921   5: 0.057447006478372   0: 0.018433534463496   4: 0.018433211300600   9: 0.018432841748413   8: 0.018432295630571   1: 0.018432170111592   2: 0.018432102717610   7: 0.018431964953588   3: 0.018431458390836 

training_8140     6: 0.608919405526399   8: 0.225571679504949   5: 0.042361114773856   7: 0.017593332576136   0: 0.017593035701060   9: 0.017592791902534   4: 0.017592667054486   1: 0.017592442429709   2: 0.017591819760218   3: 0.017591710770652 

training_8141     6: 0.729085224925634   1: 0.119190275219828   0: 0.039007388406791   7: 0.035970432583258   3: 0.020752448341330   8: 0.011199743679374   5: 0.011199679267823   9: 0.011198425235420   4: 0.011198331232267   2: 0.011198051108275 

training_8144     0: 0.741191798803993   8: 0.028769107971771   5: 0.028758117476259   6: 0.028757486011049   1: 0.028756562649810   7: 0.028754280610202   9: 0.028753782541200   3: 0.028753509105291   4: 0.028752838786129   2: 0.028752516044295 

training_8145     0: 0.835141617370624   8: 0.018322470383366   6: 0.018322098691307   5: 0.018318842632160   1: 0.018317285021036   9: 0.018317005217791   7: 0.018315410672534   3: 0.018315336521732   4: 0.018315127364935   2: 0.018314806124514 

training_8147     9: 0.854542930911324   6: 0.016163645393901   8: 0.016162520520600   5: 0.016162330046076   0: 0.016161970046480   1: 0.016161601577397   4: 0.016161598884777   2: 0.016161180417450   7: 0.016161114500210   3: 0.016161107701784 

training_8149     6: 0.690667844200324   7: 0.093626454629459   9: 0.047008574927562   3: 0.043679969270693   0: 0.042431762824078   5: 0.016521790306720   1: 0.016517004917629   2: 0.016515936457773   8: 0.016515715688644   4: 0.016514946777119 

training_8151     6: 0.821126384502546   0: 0.082578721126899   1: 0.019376834071549   9: 0.010992169260580   7: 0.010991315665248   5: 0.010987680926574   8: 0.010986939630255   3: 0.010986659558708   4: 0.010986656660647   2: 0.010986638596997 

training_8153     6: 0.806704643885998   0: 0.064779243593520   8: 0.037835518143139   5: 0.012955954500146   1: 0.012955602248443   9: 0.012954759296323   4: 0.012953698579774   7: 0.012953690342743   2: 0.012953454697854   3: 0.012953434712059 

training_8155     5: 0.659353949136788   6: 0.122251428186203   3: 0.092898781188143   9: 0.017935843086001   8: 0.017929345008907   0: 0.017927428536270   1: 0.017927337732841   4: 0.017926915977608   2: 0.017924514073618   7: 0.017924457073622 

training_8156     6: 0.728071241186689   0: 0.167119742778997   5: 0.013105372215473   1: 0.013101459962968   2: 0.013100603247488   7: 0.013100430680525   4: 0.013100425811491   8: 0.013100317286117   9: 0.013100287365178   3: 0.013100119465074 

training_8158     6: 0.805050027356017   0: 0.062048201444631   8: 0.031402878477138   4: 0.014503739679667   5: 0.014500273265450   7: 0.014499921626609   1: 0.014499215510598   9: 0.014498928555211   2: 0.014498430138376   3: 0.014498383946303 

training_8159     6: 0.508542993581749   7: 0.193213286920182   2: 0.176043219309318   8: 0.017475724708302   3: 0.017465004559215   5: 0.017453009695490   1: 0.017452683083099   0: 0.017452117780616   4: 0.017451050022998   9: 0.017450910339032 

training_816      6: 0.501705532397320   0: 0.279784463886385   7: 0.062798870220288   9: 0.022302106985595   2: 0.022248678841298   5: 0.022239104073447   3: 0.022233026616193   8: 0.022230729977657   1: 0.022229598334443   4: 0.022227888667374 

training_8160     9: 0.496289865953968   6: 0.346074129275723   8: 0.032049273049103   7: 0.023913560508284   3: 0.023240102208352   1: 0.022913312979519   0: 0.014046535564015   5: 0.013837438240508   2: 0.013817945610554   4: 0.013817836609974 

training_8161     6: 0.768312673200522   8: 0.077359593790352   0: 0.042397536568318   7: 0.015995158760552   1: 0.015992133909251   9: 0.015989960261886   5: 0.015989424497186   4: 0.015988089286397   3: 0.015987771217172   2: 0.015987658508364 

training_8162     6: 0.500474871212497   5: 0.218002193226579   1: 0.165703698272573   3: 0.037207580853447   8: 0.021866222838012   9: 0.011360218331846   0: 0.011353191574031   4: 0.011346186178999   7: 0.011343016444115   2: 0.011342821067902 

training_8163     6: 0.782329232074081   5: 0.101352240169901   4: 0.014542130865085   0: 0.014541748719801   1: 0.014540976759973   9: 0.014540376839542   8: 0.014539154179414   3: 0.014538868393163   7: 0.014537636148335   2: 0.014537635850705 

training_8164     6: 0.719158534657972   3: 0.107753640361157   0: 0.078321271746702   1: 0.013545603647023   5: 0.013542394289454   8: 0.013536096925752   9: 0.013536037920112   4: 0.013535890719064   2: 0.013535552251626   7: 0.013534977481138 

training_8166     6: 0.783448454187235   8: 0.058502171799449   7: 0.050006350803180   5: 0.023348350442207   0: 0.014127870073102   1: 0.014117106609113   2: 0.014113145190979   4: 0.014112457525421   3: 0.014112100457598   9: 0.014111992911716 

training_8167     6: 0.510703873230732   8: 0.360010909406788   9: 0.028453188065493   7: 0.014425485261453   1: 0.014402663275736   0: 0.014401473618019   2: 0.014400815767646   5: 0.014400798737866   3: 0.014400670589051   4: 0.014400122047216 

training_8168     6: 0.835551728518879   3: 0.041304163007347   9: 0.015396249454255   0: 0.015394134827798   1: 0.015392913201063   8: 0.015392881038523   5: 0.015392286292361   7: 0.015392229964787   4: 0.015391724678559   2: 0.015391689016427 

training_8169     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_817      5: 0.694178638072219   3: 0.131604585570441   6: 0.021779306849368   0: 0.021777429931683   9: 0.021776973534331   1: 0.021776915252429   8: 0.021776889120889   4: 0.021776491950118   2: 0.021776394408437   7: 0.021776375310084 

training_8172     6: 0.705172168413787   3: 0.162515900706428   0: 0.033703325295912   5: 0.014108772708449   1: 0.014086075517974   9: 0.014083750973982   7: 0.014082601291494   8: 0.014082559321482   4: 0.014082457556815   2: 0.014082388213678 

training_8173     6: 0.811067952032122   3: 0.039315606470510   0: 0.038847384127739   8: 0.028807154356100   1: 0.013664635922581   5: 0.013662052616209   9: 0.013660100985853   4: 0.013658477716313   7: 0.013658418238900   2: 0.013658217533673 

training_8174     6: 0.697077467863785   3: 0.138852752200388   5: 0.020510132175232   9: 0.020509371833327   7: 0.020508844591914   0: 0.020508645534210   8: 0.020508441360973   4: 0.020508256064762   1: 0.020508109926182   2: 0.020507978449227 

training_8176     6: 0.805215516719014   0: 0.087156400831373   1: 0.013456441709235   5: 0.013454087659196   7: 0.013453617784383   9: 0.013453256139935   8: 0.013453025463210   2: 0.013452824063831   3: 0.013452470694603   4: 0.013452358935221 

training_8177     0: 0.553028281942429   1: 0.304380681169302   6: 0.017834188393816   8: 0.017827116842980   5: 0.017822760451854   9: 0.017822113350332   7: 0.017821673864027   4: 0.017821130222460   2: 0.017821087078908   3: 0.017820966683893 

training_8178     6: 0.608464138016097   9: 0.254242573575015   7: 0.030681978013303   0: 0.015246070957809   8: 0.015239015739870   1: 0.015226000962817   5: 0.015225791052788   4: 0.015225178007574   2: 0.015224652334056   3: 0.015224601340672 

training_8179     6: 0.746355955354425   0: 0.116554261337481   8: 0.038875740313426   7: 0.014041823827004   2: 0.014031506713323   9: 0.014028992546420   5: 0.014028646529082   1: 0.014028261411590   4: 0.014027876528684   3: 0.014026935438566 

training_818      5: 0.446933663482132   3: 0.335253847977103   4: 0.027231930361740   8: 0.027226015429432   0: 0.027226012360139   9: 0.027225823958609   6: 0.027225819371904   1: 0.027225726993456   2: 0.027225720549397   7: 0.027225439516086 

training_8180     6: 0.745915830457191   9: 0.028234448216087   7: 0.028233106914182   0: 0.028231691482157   1: 0.028231613441915   5: 0.028231479579126   8: 0.028230787556055   3: 0.028230419939085   2: 0.028230385358627   4: 0.028230237055575 

training_8182     9: 0.783613559611334   6: 0.024045108375055   8: 0.024044608064304   5: 0.024043250484039   0: 0.024042778032293   4: 0.024042422989152   1: 0.024042281760567   7: 0.024042170292549   3: 0.024041930829346   2: 0.024041889561360 

training_8184     6: 0.721126001425153   5: 0.143143833510335   9: 0.017008420155145   1: 0.016963467238759   0: 0.016961578660068   8: 0.016960254413217   2: 0.016959308851553   7: 0.016959147960377   3: 0.016959125343434   4: 0.016958862441959 

training_8186     6: 0.832448926582324   0: 0.090372781494317   8: 0.009664449556919   1: 0.009647293983160   3: 0.009645456018223   5: 0.009644553030918   2: 0.009644333775601   9: 0.009644084660176   4: 0.009644072867782   7: 0.009644048030580 

training_8188     6: 0.655174986321308   1: 0.176899725173210   5: 0.057405903213137   8: 0.046048987964319   7: 0.010770200931483   9: 0.010752919807138   3: 0.010740209053230   0: 0.010736803792333   2: 0.010735452312280   4: 0.010734811431562 

training_8189     6: 0.707259880251329   1: 0.185443423522005   0: 0.022725217819991   9: 0.012691966384617   3: 0.012655531690183   8: 0.012381724966440   5: 0.011790803225724   4: 0.011684821702391   7: 0.011683508302167   2: 0.011683122135153 

training_8190     6: 0.758338818991687   1: 0.095601225066940   9: 0.034965314893873   3: 0.016152785817651   0: 0.015842953381929   5: 0.015822061824157   4: 0.015820411696104   7: 0.015819279491970   2: 0.015818733960440   8: 0.015818414875250 

training_8193     6: 0.484326143051939   8: 0.320410108893542   5: 0.037785153564774   3: 0.033900932866007   7: 0.032139158115618   9: 0.023715782271769   2: 0.023125595914167   1: 0.022074518893859   0: 0.011288817508798   4: 0.011233788919527 

training_8194     9: 0.711381453590313   6: 0.131524169258903   8: 0.019641586940844   3: 0.019637446022059   5: 0.019636742368381   1: 0.019636279057080   0: 0.019636170540221   4: 0.019635634917878   2: 0.019635278481805   7: 0.019635238822516 

training_8197     6: 0.565546304640357   7: 0.204643936195986   8: 0.077089021218774   2: 0.021858322410107   0: 0.021832466134746   3: 0.021810554565710   9: 0.021806111073440   1: 0.021805186966734   5: 0.021804701582222   4: 0.021803395211923 

training_8198     6: 0.807372537300762   0: 0.073974257729833   1: 0.039852460693383   3: 0.022769200364928   7: 0.013287747646128   9: 0.008591062063340   8: 0.008547441574705   5: 0.008535459550597   2: 0.008534944684014   4: 0.008534888392310 

training_8199     6: 0.522758636602696   9: 0.257466545456855   1: 0.069282640012078   5: 0.021505589958839   8: 0.021499485123526   0: 0.021498110280270   7: 0.021497568353500   4: 0.021497378461142   2: 0.021497373579806   3: 0.021496672171289 

training_82       0: 0.521799303382733   5: 0.307820807661621   6: 0.021320661452701   4: 0.021295131240027   1: 0.021294797755907   9: 0.021294433335940   2: 0.021294084545211   7: 0.021293853493145   8: 0.021293578619944   3: 0.021293348512771 

training_820      2: 0.383527303071203   6: 0.283461182861849   0: 0.204803583032593   7: 0.018570835768796   5: 0.018277827145658   1: 0.018275634116252   8: 0.018272390730037   4: 0.018271237216078   9: 0.018270022115598   3: 0.018269983941937 

training_8200     6: 0.717058303633644   7: 0.181626247145557   8: 0.024088021472169   1: 0.020347482875551   2: 0.009508882248106   0: 0.009502768901006   5: 0.009497857768702   9: 0.009457366224578   3: 0.009456563589047   4: 0.009456506141639 

training_8204     1: 0.485654225073686   6: 0.277830929289702   2: 0.114278455838608   0: 0.037577144210154   5: 0.014118721486614   4: 0.014108375827641   9: 0.014108349921341   7: 0.014108038917864   8: 0.014107892739777   3: 0.014107866694613 

training_8205     6: 0.718125372154349   1: 0.142669014619467   5: 0.030964720307600   4: 0.015481587255235   0: 0.015478586292254   7: 0.015470652360413   2: 0.015460801429829   9: 0.015451084243379   8: 0.015449310084624   3: 0.015448871252850 

training_8206     6: 0.722003125676653   7: 0.120495917330835   1: 0.048525916436556   0: 0.015570375924519   2: 0.015568251180207   8: 0.015567918937044   5: 0.015567624488035   9: 0.015567082280569   4: 0.015566989037037   3: 0.015566798708544 

training_8209     6: 0.478400442318175   2: 0.160639995701307   1: 0.145072447353947   9: 0.075039288815738   5: 0.065626480437494   0: 0.015054954398133   7: 0.015041892209517   4: 0.015041704336800   8: 0.015041613217414   3: 0.015041181211475 

training_8210     6: 0.593579391899158   9: 0.212764264633194   0: 0.089857168583249   1: 0.025572213280386   4: 0.015361806964583   3: 0.012939250920072   2: 0.012576755141673   5: 0.012471731149169   8: 0.012446028624204   7: 0.012431388804312 

training_8211     6: 0.782665069103101   9: 0.078277271930739   5: 0.017387138418584   1: 0.017382887572775   4: 0.017382573094739   0: 0.017381558605438   8: 0.017381429830691   7: 0.017380901096723   3: 0.017380649592054   2: 0.017380520755156 

training_8212     6: 0.452814436025581   7: 0.351371499624782   5: 0.024479441117732   9: 0.024478395324317   0: 0.024476913993618   8: 0.024476678583978   4: 0.024476312699101   1: 0.024475961444259   2: 0.024475209869398   3: 0.024475151317232 

training_8213     6: 0.687547592205232   0: 0.148100714837608   1: 0.036886059980013   7: 0.036468134326374   5: 0.015180988320814   2: 0.015176231440168   8: 0.015162255379577   9: 0.015159531505755   3: 0.015159261929421   4: 0.015159230075038 

training_8214     6: 0.838125426528906   7: 0.036976926954222   2: 0.015614795211220   5: 0.015614142816417   0: 0.015612010153548   1: 0.015611703473872   3: 0.015611565925903   8: 0.015611288499138   9: 0.015611133277502   4: 0.015611007159272 

training_8217     0: 0.640719619726271   6: 0.107462613782205   7: 0.085654928728933   3: 0.056325694584922   5: 0.018313199744815   2: 0.018307048253389   4: 0.018305515676580   1: 0.018304724844121   9: 0.018303580970110   8: 0.018303073688653 

training_8218     5: 0.746874773991200   6: 0.028126149120019   1: 0.028125995918959   0: 0.028125676470592   9: 0.028125444619596   8: 0.028124650838249   4: 0.028124565304145   3: 0.028124425267764   2: 0.028124258936550   7: 0.028124059532928 

training_8219     5: 0.645174765569695   6: 0.161734570351047   4: 0.024142031815991   0: 0.024139830402093   1: 0.024135347117931   8: 0.024134959835676   3: 0.024134731820210   7: 0.024134713518981   2: 0.024134623958913   9: 0.024134425609464 

training_8220     6: 0.329188318833109   0: 0.280826379608453   4: 0.155879098293140   7: 0.084298830073435   9: 0.053234465075208   5: 0.019322606999550   1: 0.019317290600799   2: 0.019312320603938   3: 0.019310353612819   8: 0.019310336299549 

training_8221     5: 0.769390275500810   2: 0.066769738740245   6: 0.020482492716172   0: 0.020481201859231   1: 0.020480486677260   8: 0.020480340997432   9: 0.020479496437218   4: 0.020479362036756   7: 0.020478319911269   3: 0.020478285123608 

training_8222     1: 0.507102076733192   0: 0.336717996237787   3: 0.057230918908894   7: 0.026723905925259   6: 0.012039599904163   5: 0.012038553130306   8: 0.012037794435448   9: 0.012037598804481   4: 0.012035884289728   2: 0.012035671630743 

training_8223     0: 0.394918765894887   5: 0.297887915089573   4: 0.038413481740235   3: 0.038398023260357   2: 0.038397491461780   8: 0.038397457127061   7: 0.038397087185690   9: 0.038396779327438   1: 0.038396546424586   6: 0.038396452488393 

training_8224     0: 0.740366153932662   6: 0.105273662823148   3: 0.050203653659020   5: 0.014882612580569   1: 0.014881639498423   9: 0.014881234626716   4: 0.014878516145595   2: 0.014878314783667   8: 0.014877191797016   7: 0.014877020153185 

training_8225     1: 0.578066519896091   7: 0.203206679828071   0: 0.081040847648001   9: 0.027323562854571   3: 0.018848112684941   6: 0.018404082975171   5: 0.018288786935331   8: 0.018276431599174   4: 0.018273068848185   2: 0.018271906730464 

training_8226     5: 0.527721606422159   0: 0.279485938003913   4: 0.024104144063262   8: 0.024099090898254   6: 0.024098729963454   9: 0.024098620601685   3: 0.024098061051417   2: 0.024098001389421   7: 0.024097999229508   1: 0.024097808376925 

training_8227     5: 0.714476225973891   4: 0.109841220320182   2: 0.021970731972314   1: 0.021967274153352   0: 0.021961274213908   6: 0.021958820169497   9: 0.021956714356532   3: 0.021956046082316   8: 0.021955905451130   7: 0.021955787306877 

training_8229     5: 0.815786239995491   3: 0.051319316726283   4: 0.016616431772488   6: 0.016612719086693   0: 0.016611284269902   1: 0.016611255525875   8: 0.016611081815293   9: 0.016610808577140   7: 0.016610432104987   2: 0.016610430125847 

training_8234     6: 0.686165093369592   0: 0.112588293791139   1: 0.081940785081738   7: 0.017047444193079   5: 0.017045253804899   8: 0.017044730035458   9: 0.017043223556605   3: 0.017042138458022   2: 0.017041556811717   4: 0.017041480897751 

training_8236     5: 0.630701988633222   1: 0.186636596698914   4: 0.022836520403373   6: 0.022832752963860   0: 0.022832400566018   8: 0.022832309387624   9: 0.022831949982571   3: 0.022831896459212   2: 0.022831842471917   7: 0.022831742433288 

training_8240     6: 0.755223576537753   9: 0.076190415770649   0: 0.058154812123309   1: 0.030077110359031   5: 0.013394457140721   4: 0.013392217682670   3: 0.013392122400504   8: 0.013392009859548   7: 0.013391644418175   2: 0.013391633707639 

training_8244     6: 0.695309612543473   0: 0.120020272508470   1: 0.082130600463319   7: 0.014681380531883   5: 0.014644462444868   9: 0.014644038144818   8: 0.014642776341236   4: 0.014642468682467   3: 0.014642259436626   2: 0.014642128902839 

training_8245     5: 0.697695648486138   1: 0.033595340428163   0: 0.033591373772914   4: 0.033590802273918   6: 0.033588929390049   2: 0.033588410550076   3: 0.033587603317814   8: 0.033587354226848   9: 0.033587272367947   7: 0.033587265186133 

training_8246     6: 0.706849688506247   7: 0.070979942861341   4: 0.061474393085620   8: 0.041087974517275   0: 0.040475539219302   9: 0.015893652624907   5: 0.015833970674894   1: 0.015807293998964   2: 0.015799084491794   3: 0.015798460019656 

training_8247     9: 0.705462498587324   6: 0.128834215937951   8: 0.020729713816291   1: 0.020713470010136   3: 0.020711239583391   5: 0.020710874545199   0: 0.020710232222213   4: 0.020709529674014   2: 0.020709196777255   7: 0.020709028846225 

training_8252     6: 0.479962794963453   1: 0.301126629527876   9: 0.135933751799976   5: 0.023981045424148   8: 0.014636385739402   2: 0.008920810359460   0: 0.008888887529376   4: 0.008850489431975   3: 0.008849610303897   7: 0.008849594920437 

training_8253     1: 0.399034621608900   8: 0.366074802830373   5: 0.029378066880182   6: 0.029363905501456   7: 0.029362039087323   0: 0.029360595822864   4: 0.029357401948847   9: 0.029357088459791   3: 0.029355918029344   2: 0.029355559830918 

training_8254     2: 0.450894973435215   5: 0.331247910905320   4: 0.027236329579329   3: 0.027233874052810   8: 0.027232356877989   9: 0.027231910190929   6: 0.027230778706363   0: 0.027230688860326   1: 0.027230644293746   7: 0.027230533097973 

training_8255     4: 0.639987718838073   2: 0.163949703749287   5: 0.024513706797168   1: 0.024509983296323   9: 0.024509965801977   0: 0.024508740998875   6: 0.024508066017718   3: 0.024505000206877   8: 0.024504175253479   7: 0.024502939040222 

training_8257     6: 0.681746182303343   0: 0.077561910941214   4: 0.073101037688192   1: 0.060536968657194   5: 0.026015259509789   8: 0.025936346170426   7: 0.013831560091260   3: 0.013757100994494   2: 0.013756950115929   9: 0.013756683528159 

training_8258     6: 0.419038610205812   5: 0.300951331132772   1: 0.125607612627302   2: 0.059022339363538   7: 0.022970489484981   0: 0.016000392191355   9: 0.014155228550822   8: 0.014092262774510   4: 0.014081107252422   3: 0.014080626416486 

training_8259     9: 0.399736184291771   0: 0.263418505596768   5: 0.200153011053423   1: 0.019535149200582   6: 0.019534367256617   8: 0.019526458519722   2: 0.019525013250128   4: 0.019524941200157   7: 0.019523193376896   3: 0.019523176253936 

training_8262     5: 0.836740243196316   9: 0.055191144553059   3: 0.013510502453775   4: 0.013510291385520   8: 0.013509706627781   6: 0.013508602906854   0: 0.013507786876450   1: 0.013507586271266   2: 0.013507318076790   7: 0.013506817652190 

training_8264     1: 0.678241084879237   8: 0.083223388416856   3: 0.071041574536636   2: 0.061089977157829   6: 0.017770742296645   0: 0.017734131810797   5: 0.017733402530200   9: 0.017725035411353   4: 0.017720819996554   7: 0.017719842963892 

training_8269     5: 0.772216801252471   1: 0.025309666091260   3: 0.025309638695826   4: 0.025309361043337   0: 0.025309354512760   6: 0.025309290377342   2: 0.025308987322530   8: 0.025308983024650   9: 0.025308970070773   7: 0.025308947609051 

training_8270     5: 0.540062828188527   0: 0.239077539894120   4: 0.027613410913992   8: 0.027607328677205   6: 0.027606736799504   9: 0.027606657433571   3: 0.027606560767793   1: 0.027606387307923   2: 0.027606291695289   7: 0.027606258322076 

training_8273     6: 0.794634025672274   8: 0.039643310954974   4: 0.038640190031194   1: 0.033486608308417   5: 0.015607286003655   0: 0.015598265607201   9: 0.015597847907080   3: 0.015597552863852   2: 0.015597487803731   7: 0.015597424847622 

training_8275     5: 0.788049384996866   1: 0.086871932208672   0: 0.015638789787913   6: 0.015635734288789   4: 0.015635661178101   9: 0.015633879396470   2: 0.015633691606394   8: 0.015633667858109   3: 0.015633665280466   7: 0.015633593398221 

training_8276     5: 0.614065721938776   1: 0.256457921160539   8: 0.016194132629369   6: 0.016192899221322   0: 0.016186445620892   4: 0.016181216801435   9: 0.016180531703521   3: 0.016180514262238   2: 0.016180327266662   7: 0.016180289395245 

training_8279     4: 0.490557446711801   2: 0.198160178532754   6: 0.108168036025644   0: 0.029020546005875   1: 0.029019006833797   5: 0.029017872698637   8: 0.029015254014499   3: 0.029014207828103   7: 0.029014091963043   9: 0.029013359385848 

training_828      5: 0.762542324162093   3: 0.026384851917055   4: 0.026384533091530   0: 0.026384132368408   1: 0.026384090802326   8: 0.026384086211723   6: 0.026384074406040   2: 0.026384030674179   7: 0.026383949774294   9: 0.026383926592352 

training_8286     5: 0.771976802345434   4: 0.025342031246860   6: 0.025335364519584   9: 0.025335353682922   8: 0.025335183436604   0: 0.025335150697424   1: 0.025335096917084   3: 0.025335067340196   2: 0.025335001197901   7: 0.025334948615990 

training_8287     1: 0.428207452370423   3: 0.224629075949365   8: 0.209165722031796   5: 0.019717786829215   4: 0.019715251470177   0: 0.019714214325289   6: 0.019713316438028   2: 0.019712682318897   9: 0.019712561064458   7: 0.019711937202352 

training_8288     4: 0.658678824681679   1: 0.143920442791616   5: 0.024687573576221   0: 0.024685403093677   6: 0.024679618304770   2: 0.024671443412207   9: 0.024669580744841   8: 0.024669441819233   3: 0.024669013885045   7: 0.024668657690710 

training_8289     5: 0.568805644922445   0: 0.279942756223578   6: 0.018911239259012   4: 0.018909312510555   1: 0.018905412086474   8: 0.018905368387113   3: 0.018905135122134   9: 0.018905129235362   7: 0.018905011106611   2: 0.018904991146716 

training_829      6: 0.497500115646753   1: 0.331411501661226   5: 0.053677882484095   9: 0.030270828006903   7: 0.025819515136253   2: 0.012283466472837   8: 0.012261184851113   0: 0.012259904069337   4: 0.012258369602005   3: 0.012257232069478 

training_8291     4: 0.713008174269109   2: 0.072941535444765   6: 0.072000961601662   5: 0.020302630606376   1: 0.020293543195207   3: 0.020290861581852   0: 0.020290817999433   8: 0.020290582143618   7: 0.020290461930047   9: 0.020290431227933 

training_8292     5: 0.743855441980732   8: 0.082478545702647   4: 0.021710323293976   9: 0.021708248612904   7: 0.021708059254883   1: 0.021707932386840   6: 0.021707889435891   3: 0.021707888652135   0: 0.021707853581837   2: 0.021707817098155 

training_8293     0: 0.612197895251167   6: 0.133822275950420   4: 0.124050239132400   9: 0.018564397172283   1: 0.018563128636815   5: 0.018562467576696   2: 0.018560139915526   7: 0.018559945768014   3: 0.018559792671583   8: 0.018559717925096 

training_8294     5: 0.722125184393600   7: 0.104760262411580   1: 0.021641216225837   4: 0.021640745043333   6: 0.021639397839568   0: 0.021639046141200   8: 0.021638558703888   2: 0.021638557614827   9: 0.021638548736769   3: 0.021638482889398 

training_8296     5: 0.545765086642052   9: 0.253920421811400   4: 0.025047453708836   8: 0.025038414165800   0: 0.025038335609723   6: 0.025038314735204   1: 0.025038235660277   3: 0.025038053383383   2: 0.025037918660791   7: 0.025037765622534 

training_8297     4: 0.719459136206372   5: 0.031177334859432   0: 0.031170618559992   6: 0.031170478091863   3: 0.031170469740684   8: 0.031170438982291   1: 0.031170408235839   2: 0.031170398877112   9: 0.031170377642991   7: 0.031170338803424 

training_8298     1: 0.586988573546202   5: 0.143479187792112   4: 0.065753283265158   9: 0.062585254655198   6: 0.043107274324254   0: 0.019626613312064   8: 0.019618917110900   7: 0.019614314019858   2: 0.019613319103090   3: 0.019613262871164 

training_8299     8: 0.624413375442509   6: 0.246005735826573   1: 0.016199125690195   0: 0.016198995614353   9: 0.016197697968344   5: 0.016197629740088   7: 0.016197160629982   2: 0.016196886628431   4: 0.016196740669472   3: 0.016196651790053 

training_83       5: 0.823826038833137   6: 0.019576615571062   1: 0.019575717286858   8: 0.019575622132381   0: 0.019575268645797   9: 0.019574395916601   4: 0.019574287933440   3: 0.019574073314636   7: 0.019574057114771   2: 0.019573923251319 

training_830      6: 0.755731230180397   9: 0.027145233785850   8: 0.027144536136986   0: 0.027144203291017   5: 0.027140170654412   1: 0.027139380413245   7: 0.027139186437708   2: 0.027138724623303   3: 0.027138693474228   4: 0.027138641002852 

training_8300     4: 0.817970560795387   5: 0.020239931473705   9: 0.020225262524134   0: 0.020224891400646   6: 0.020223663514804   1: 0.020223363189527   3: 0.020223283324976   8: 0.020223072278901   2: 0.020223005005274   7: 0.020222966492646 

training_8302     6: 0.746716051003644   0: 0.028152307653953   5: 0.028143777781340   1: 0.028143039412887   8: 0.028141295230356   9: 0.028141105711864   7: 0.028140902921820   4: 0.028140716515340   2: 0.028140580773711   3: 0.028140222995084 

training_8306     6: 0.715909906753961   0: 0.127937648139820   5: 0.019524061737561   1: 0.019519234002660   7: 0.019518708178041   3: 0.019518488809606   9: 0.019518142650984   4: 0.019518051541176   2: 0.019517921382320   8: 0.019517836803871 

training_8308     6: 0.716410411053599   5: 0.138930833086524   7: 0.037873300418513   2: 0.015283309851564   1: 0.015271592621790   0: 0.015255142486320   3: 0.015245175104379   9: 0.015244053122790   4: 0.015243287347917   8: 0.015242894906605 

training_8309     6: 0.833504233268414   0: 0.018504123258990   5: 0.018501073597198   1: 0.018499581979712   4: 0.018499178664478   9: 0.018498608197648   8: 0.018498556250261   7: 0.018498334082810   3: 0.018498165948412   2: 0.018498144752077 

training_8311     0: 0.465065495831124   6: 0.406153491303103   7: 0.029922030052900   5: 0.014134183672534   4: 0.014123045248270   1: 0.014122297485832   3: 0.014120521699225   8: 0.014120286680549   9: 0.014119684224955   2: 0.014118963801508 

training_8313     5: 0.709589811848740   6: 0.129924291145145   4: 0.020063225750892   0: 0.020061959742348   9: 0.020060565657584   8: 0.020060520819864   1: 0.020060509243017   2: 0.020059828262538   3: 0.020059644662524   7: 0.020059642867347 

training_8314     6: 0.401111841270931   0: 0.348385260062445   5: 0.130830874083834   1: 0.032020300511932   7: 0.023451635780472   3: 0.012862186314143   9: 0.012835529486383   4: 0.012834856268988   8: 0.012834545261180   2: 0.012832970959692 

training_8317     5: 0.775621958068984   4: 0.024937924054237   8: 0.024930679409494   9: 0.024930080669218   6: 0.024930075287693   3: 0.024929934714248   1: 0.024929855045680   2: 0.024929854546491   0: 0.024929840948934   7: 0.024929797255021 

training_8318     5: 0.620076995281145   0: 0.191690214056121   4: 0.023531601253589   9: 0.023531424982140   6: 0.023530952495890   1: 0.023530156588474   8: 0.023527411912988   3: 0.023527316011104   7: 0.023526998247570   2: 0.023526929170979 

training_8319     6: 0.833769487578772   8: 0.018471775690721   9: 0.018470070269236   7: 0.018470011263852   0: 0.018469936535120   5: 0.018469930915371   1: 0.018469898561611   2: 0.018469747984993   3: 0.018469603446885   4: 0.018469537753440 

training_8320     5: 0.716735053342605   0: 0.066045430128983   9: 0.062568564968511   3: 0.058405100710679   1: 0.016042793720678   6: 0.016042710038463   2: 0.016040309381653   7: 0.016040083413666   8: 0.016040009194599   4: 0.016039945100163 

training_8322     1: 0.505375964619380   7: 0.204474210711057   5: 0.158823592727749   6: 0.018765879649265   0: 0.018763761302062   9: 0.018759801661055   8: 0.018759601832497   2: 0.018759102450762   4: 0.018759084825967   3: 0.018759000220205 

training_8326     6: 0.746824602937656   8: 0.028135979948328   0: 0.028130773481408   9: 0.028130268889009   1: 0.028130222665042   7: 0.028129999672146   3: 0.028129663554543   5: 0.028129533780209   4: 0.028129482388369   2: 0.028129472683291 

training_8327     1: 0.725313295913293   3: 0.071516933602013   9: 0.061201158811002   6: 0.020302624754215   5: 0.020279082171991   0: 0.020278805865889   2: 0.020278200357883   4: 0.020276930607453   8: 0.020276557054743   7: 0.020276410861518 

training_833      6: 0.782971824779396   0: 0.051907084553891   4: 0.038334426746222   2: 0.037093275777651   1: 0.032376100846376   9: 0.011475118120773   8: 0.011462318489618   5: 0.011460945403141   3: 0.011459518451923   7: 0.011459386831008 

training_8331     0: 0.427485018511096   6: 0.397552789089181   9: 0.067575440502434   7: 0.022406055894541   1: 0.014165392650339   5: 0.014163907888624   4: 0.014163136859379   2: 0.014163031885878   8: 0.014162704679512   3: 0.014162522039016 

training_8334     9: 0.629026615706046   6: 0.172735819277135   5: 0.024799172030447   4: 0.024798990207554   0: 0.024784418534248   1: 0.024775649317189   8: 0.024770938792472   7: 0.024770314445106   2: 0.024769437334508   3: 0.024768644355295 

training_8335     5: 0.792176521137321   4: 0.023098869412031   6: 0.023092391502213   9: 0.023091864328378   2: 0.023091684772625   1: 0.023090043660732   8: 0.023089781228361   0: 0.023089639227654   3: 0.023089620251772   7: 0.023089584478912 

training_8337     4: 0.809145585294784   5: 0.021213089796084   6: 0.021206405219460   0: 0.021205612370311   8: 0.021205098439348   1: 0.021204994432217   9: 0.021204888936889   3: 0.021204884530026   2: 0.021204747361795   7: 0.021204693619085 

training_8338     5: 0.425684655165439   7: 0.348887270190265   4: 0.028183644332339   9: 0.028179258198417   8: 0.028178300852393   3: 0.028177503829191   0: 0.028177435403577   1: 0.028177425206464   2: 0.028177407487073   6: 0.028177099334843 

training_8339     5: 0.789591237790089   4: 0.023386841146329   6: 0.023380820693402   9: 0.023379712165260   2: 0.023378719075336   1: 0.023377001330852   8: 0.023376552582381   0: 0.023376491880194   7: 0.023376323548979   3: 0.023376299787178 

training_834      2: 0.591924100041110   6: 0.254479583488699   8: 0.019205061391852   5: 0.019202516619674   9: 0.019200324821117   1: 0.019199490027260   0: 0.019199101407491   4: 0.019197289772825   7: 0.019196682935196   3: 0.019195849494775 

training_8340     4: 0.774742198807768   5: 0.025036687469216   6: 0.025028220997234   0: 0.025027878657710   2: 0.025027624065916   1: 0.025027598190053   9: 0.025027502920981   3: 0.025027488110847   8: 0.025027486621339   7: 0.025027314158936 

training_8342     6: 0.750770622977591   1: 0.111638098324700   7: 0.028052768750000   0: 0.026958859709878   8: 0.013764470782781   3: 0.013763302803841   9: 0.013763121842626   5: 0.013763043235515   2: 0.013762892833952   4: 0.013762818739116 

training_8343     8: 0.750807487557165   5: 0.027693548847151   6: 0.027689410920263   0: 0.027688396093657   4: 0.027687359725473   1: 0.027687083778694   9: 0.027686963729232   3: 0.027686867468885   2: 0.027686522956101   7: 0.027686358923379 

training_8344     8: 0.790109237669635   2: 0.064574568614490   0: 0.018168014606233   6: 0.018167157022095   1: 0.018164502399119   5: 0.018163868970735   9: 0.018163667588107   7: 0.018163166328379   4: 0.018163036329931   3: 0.018162780471275 

training_8347     6: 0.790719658476939   0: 0.046001672723223   7: 0.044315686879387   8: 0.016996330339588   3: 0.016995880882421   5: 0.016995150745505   9: 0.016994721016778   1: 0.016994313223034   4: 0.016993546559432   2: 0.016993039153692 

training_8349     0: 0.508122445520901   6: 0.264738537166888   1: 0.056303862278017   9: 0.055846438115451   2: 0.030615537208503   7: 0.029963610119085   3: 0.013608975081342   5: 0.013601478533922   4: 0.013601092701245   8: 0.013598023274647 

training_835      0: 0.660928805042041   6: 0.167851215443717   2: 0.051685132758289   1: 0.037312919739394   3: 0.013709209803463   9: 0.013706025528988   7: 0.013704519057768   5: 0.013701213225382   8: 0.013700574931176   4: 0.013700384469783 

training_8350     5: 0.802075019621721   4: 0.021994377885425   3: 0.021993559793048   1: 0.021991629635186   6: 0.021991469443911   0: 0.021991168790990   8: 0.021990782284987   2: 0.021990737224779   9: 0.021990728886693   7: 0.021990526433261 

training_8351     1: 0.675286364271560   7: 0.113336522808344   4: 0.059152313513032   5: 0.021754429647700   6: 0.021748230349654   3: 0.021746444544581   0: 0.021746100232117   8: 0.021743644705569   2: 0.021743013517925   9: 0.021742936409517 

training_8353     5: 0.451352272811396   1: 0.369366723879304   8: 0.022433649907286   6: 0.022414418429262   0: 0.022408793774761   4: 0.022406391626653   3: 0.022405216915661   2: 0.022404506757084   9: 0.022404014371249   7: 0.022404011527344 

training_8355     1: 0.768400753669849   4: 0.077900919704637   0: 0.046661923573764   6: 0.015295382894860   5: 0.015294513441763   8: 0.015290190721186   2: 0.015289152988909   7: 0.015289125667447   9: 0.015289057293863   3: 0.015288980043722 

training_8359     1: 0.498686058912031   0: 0.278774144710052   6: 0.079221436785565   4: 0.023386501822498   5: 0.019992175191771   9: 0.019992124322879   8: 0.019987814144678   3: 0.019987100706316   7: 0.019986460407323   2: 0.019986182996887 

training_836      1: 0.392902577535090   5: 0.338869748995770   4: 0.141074548474814   0: 0.018337235845686   6: 0.018285031049449   3: 0.018111456814328   2: 0.018109209873031   9: 0.018103662900171   8: 0.018103300809523   7: 0.018103227702137 

training_8361     1: 0.613342290195809   2: 0.121110667090571   0: 0.099640868152619   9: 0.057932221886305   5: 0.018001285767479   6: 0.017997577906776   8: 0.017994517538327   7: 0.017993734089422   4: 0.017993643619433   3: 0.017993193753259 

training_8363     6: 0.771014425699015   7: 0.061662982304980   0: 0.020920294924057   8: 0.020916147342323   3: 0.020915923366924   5: 0.020914880528454   9: 0.020914653612337   1: 0.020913818153329   4: 0.020913577356350   2: 0.020913296712229 

training_8364     5: 0.521653328963996   1: 0.153444314589082   8: 0.140657388524532   4: 0.026325294814760   3: 0.026320125497658   2: 0.026319964888383   9: 0.026319936902760   6: 0.026319920396244   7: 0.026319884751063   0: 0.026319840671522 

training_8366     5: 0.761525745089438   4: 0.026500177493165   1: 0.026497932657431   0: 0.026497710459653   8: 0.026497607186922   6: 0.026496663088830   2: 0.026496196882210   7: 0.026496102222786   3: 0.026495942836167   9: 0.026495922083397 

training_8367     5: 0.709235977500334   4: 0.073342020461297   1: 0.027181576036707   6: 0.027181092000494   0: 0.027180411757559   2: 0.027176920230001   9: 0.027176436860681   3: 0.027175345207298   7: 0.027175253051377   8: 0.027174966894253 

training_8368     6: 0.725454762569222   1: 0.030526642225592   5: 0.030522613264522   8: 0.030503227653195   4: 0.030500628035391   0: 0.030500154521675   2: 0.030498649618506   9: 0.030498059852353   3: 0.030497643245594   7: 0.030497619013950 

training_837      5: 0.795862444229507   6: 0.046197290171836   4: 0.041259162536392   3: 0.016672966984386   0: 0.016668341847005   9: 0.016668256668173   1: 0.016668122785388   2: 0.016668078645758   8: 0.016667775458896   7: 0.016667560672658 

training_8370     5: 0.405501540344735   6: 0.234256883958056   9: 0.198408239888982   4: 0.023225604474024   1: 0.023123127948383   0: 0.023099882645577   3: 0.023096862179976   8: 0.023096336289401   7: 0.023095886050108   2: 0.023095636220757 

training_8373     6: 0.577068735626150   5: 0.218237160492088   4: 0.073641884927926   1: 0.018724655736137   0: 0.018723085160650   8: 0.018721856571146   9: 0.018721368760828   2: 0.018720834207512   7: 0.018720209679510   3: 0.018720208838052 

training_8374     6: 0.660968960883782   0: 0.191090584501061   1: 0.043548401299205   2: 0.014946338561984   4: 0.014911347010431   5: 0.014908815123467   7: 0.014908695209937   8: 0.014906974746363   9: 0.014905128076069   3: 0.014904754587700 

training_8378     5: 0.760284051946584   6: 0.026640408665193   0: 0.026635994211078   1: 0.026635719921960   3: 0.026634312379825   9: 0.026634170415298   4: 0.026634035208908   7: 0.026634023905415   8: 0.026633826788185   2: 0.026633456557555 

training_8387     6: 0.315301117814497   4: 0.264294881255419   3: 0.238272213891527   0: 0.026032663304131   1: 0.026025104903602   9: 0.026015387232345   2: 0.026015012911550   7: 0.026014899961463   8: 0.026014403306822   5: 0.026014315418644 

training_8388     4: 0.679614363178571   7: 0.143962003997098   5: 0.022064226485589   1: 0.022055409116293   6: 0.022051653408218   0: 0.022051044484343   8: 0.022050517026763   9: 0.022050488956688   3: 0.022050303082139   2: 0.022049990264298 

training_839      6: 0.799513514316998   1: 0.039139417808294   9: 0.035597193706094   0: 0.017971119073351   8: 0.017965542958855   5: 0.017964802374984   4: 0.017964212299689   7: 0.017961687156314   3: 0.017961259488359   2: 0.017961250817063 

training_8391     5: 0.714532396766276   0: 0.067098825690626   2: 0.062361163435356   6: 0.022293652450046   4: 0.022291712031518   8: 0.022284549604657   9: 0.022284475005652   7: 0.022284444299479   1: 0.022284417669424   3: 0.022284363046966 

training_8394     5: 0.541628281127887   3: 0.139666743141756   7: 0.123585911220547   0: 0.065014434666649   4: 0.021690867313155   6: 0.021683032326637   8: 0.021682733858981   9: 0.021682715294161   1: 0.021682647442591   2: 0.021682633607636 

training_8396     6: 0.373061271750504   4: 0.201833240111642   3: 0.172717296575651   1: 0.149147711212733   0: 0.017219267868629   8: 0.017216501781282   5: 0.017202761161055   9: 0.017200932600275   2: 0.017200631170493   7: 0.017200385767735 

training_8399     5: 0.468397083077503   8: 0.200939238803261   2: 0.139185693515772   4: 0.027361143226635   1: 0.027359868523552   0: 0.027351490820986   6: 0.027351460916472   3: 0.027351375224116   7: 0.027351336202880   9: 0.027351309688823 

training_840      1: 0.744413273836858   4: 0.068690322200847   8: 0.046936882609326   3: 0.035797612061946   7: 0.032706649453393   9: 0.014339320739491   6: 0.014281999414692   5: 0.014280185140819   0: 0.014279341008372   2: 0.014274413534256 

training_8400     6: 0.795808932432210   0: 0.052426297841303   1: 0.043707388394032   2: 0.021847246159008   9: 0.014370674628110   5: 0.014369561251371   8: 0.014369271113477   7: 0.014367754661280   3: 0.014367213724838   4: 0.014365659794372 

training_8401     6: 0.462608140232493   5: 0.385352278932715   8: 0.019009145177092   9: 0.019007058034433   0: 0.019005234320212   4: 0.019004398671777   1: 0.019004123182157   7: 0.019003609679330   2: 0.019003098142770   3: 0.019002913627021 

training_8402     6: 0.634582535840499   1: 0.167787250625347   0: 0.024704800796736   8: 0.024704165133308   2: 0.024703704214119   7: 0.024703606362488   9: 0.024703598682986   5: 0.024703503945175   3: 0.024703488178081   4: 0.024703346221261 

training_8405     1: 0.568814684438983   6: 0.329801070521980   8: 0.012674646116633   0: 0.012674592634743   7: 0.012672918232050   5: 0.012672701559365   2: 0.012672621584984   9: 0.012672382736030   4: 0.012672224604080   3: 0.012672157571152 

training_8406     1: 0.588793508210789   0: 0.129717682528672   6: 0.098101046940839   7: 0.081293852627777   5: 0.017025292862909   3: 0.017017786864596   4: 0.017016746907971   9: 0.017012630024004   8: 0.017010767696955   2: 0.017010685335488 

training_8407     5: 0.587183293418322   8: 0.207450329702286   4: 0.025675850604940   3: 0.025670255202770   2: 0.025670158208452   0: 0.025670060680554   7: 0.025670031224700   1: 0.025670029243818   6: 0.025669997616648   9: 0.025669994097512 

training_8409     5: 0.689549020850914   4: 0.034496919810969   2: 0.034495724276170   6: 0.034494526456957   8: 0.034494210467741   1: 0.034494024170682   3: 0.034493973684518   0: 0.034493949737563   9: 0.034493924334570   7: 0.034493726209917 

training_8413     6: 0.835382979049579   0: 0.052275713516285   1: 0.036806710220751   8: 0.010792974008173   3: 0.010791149583836   5: 0.010790413242946   9: 0.010790197042215   4: 0.010790040624667   7: 0.010789947202687   2: 0.010789875508862 

training_8415     6: 0.671020074360942   1: 0.205880183462038   5: 0.015415331947997   7: 0.015384767585506   0: 0.015384100476252   3: 0.015383641576242   8: 0.015383521946204   2: 0.015382942383151   9: 0.015382821455735   4: 0.015382614805934 

training_8416     1: 0.427963555485890   6: 0.395629589946502   5: 0.091020646668824   0: 0.012315763937393   8: 0.012180968289331   9: 0.012178479812561   7: 0.012178044107128   3: 0.012177670614014   4: 0.012177643046518   2: 0.012177638091841 

training_842      6: 0.820444447651828   3: 0.039687134364118   1: 0.035083829109483   4: 0.015029526270052   9: 0.014980099463856   5: 0.014956579520292   0: 0.014954909981148   8: 0.014954728847973   2: 0.014954605314543   7: 0.014954139476707 

training_8421     6: 0.744144600082673   1: 0.096141999507353   8: 0.052636447730593   0: 0.042886067179394   5: 0.019232787454695   3: 0.008995567303524   2: 0.008995272088465   9: 0.008993780713682   7: 0.008987360357093   4: 0.008986117582528 

training_8422     1: 0.374592802319169   5: 0.341216056210598   9: 0.091427400653191   3: 0.076977161707026   8: 0.029228576048830   0: 0.026843730310152   6: 0.015024673190279   4: 0.014897192660610   2: 0.014896604189918   7: 0.014895802710226 

training_8424     5: 0.743656610138801   7: 0.083295723939872   0: 0.021642267594553   4: 0.021633927150667   8: 0.021629861771715   1: 0.021628473854112   9: 0.021628419200517   6: 0.021628373547727   3: 0.021628174710773   2: 0.021628168091263 

training_8425     5: 0.788931600281471   4: 0.023454959312239   6: 0.023452863250180   0: 0.023452536264489   9: 0.023451859490453   1: 0.023451703006476   8: 0.023451268050341   7: 0.023451176789094   3: 0.023451037434326   2: 0.023450996120929 

training_8426     4: 0.560223351453545   5: 0.234633293548732   3: 0.025644254985313   1: 0.025643420440888   6: 0.025643171175366   2: 0.025642916885831   0: 0.025642877940532   7: 0.025642397007159   9: 0.025642251539894   8: 0.025642065022741 

training_8427     6: 0.633046397757851   1: 0.250530322216813   0: 0.024077594203737   4: 0.017427004367472   9: 0.016663315161237   8: 0.011851401284190   7: 0.011605681761292   5: 0.011600622547824   3: 0.011599061676961   2: 0.011598599022623 

training_8428     5: 0.615042750951794   6: 0.201300234317194   7: 0.062613347019001   1: 0.017295407723016   0: 0.017293040546871   8: 0.017291628723679   9: 0.017291613182373   4: 0.017291230903619   2: 0.017290492303708   3: 0.017290254328745 

training_8429     0: 0.671335323683432   2: 0.104102197152855   6: 0.028072778402707   1: 0.028072219692390   5: 0.028071133729105   7: 0.028071093074020   4: 0.028069402743030   9: 0.028068690953151   8: 0.028068607495669   3: 0.028068553073642 

training_843      6: 0.670465127190527   0: 0.186873793419430   1: 0.070320889030783   5: 0.014405703057348   3: 0.014282236343609   9: 0.008739610564752   7: 0.008733766499479   4: 0.008728145092711   8: 0.008725471533801   2: 0.008725257267560 

training_8430     5: 0.416857702698506   0: 0.332686951974644   8: 0.084690687501041   4: 0.057070475576025   7: 0.032555463165761   6: 0.015278272686242   1: 0.015239912427911   3: 0.015207356347196   2: 0.015206990403590   9: 0.015206187219084 

training_8432     0: 0.761898523426605   5: 0.072923292918234   6: 0.020652303704349   3: 0.020651044759025   1: 0.020648184957260   8: 0.020645716466539   4: 0.020645636036164   2: 0.020645257449041   9: 0.020645147513769   7: 0.020644892769014 

training_8433     0: 0.582932950837027   2: 0.213902123042375   6: 0.025399367269629   1: 0.025397400556224   5: 0.025395148106069   4: 0.025394792767235   3: 0.025394697375031   9: 0.025394626042044   8: 0.025394484893994   7: 0.025394409110371 

training_8435     5: 0.545408996477414   6: 0.294708113004241   0: 0.019997799256615   1: 0.019986358456630   7: 0.019984842154544   4: 0.019983295820401   9: 0.019982984449559   8: 0.019982836806864   2: 0.019982588673038   3: 0.019982184900694 

training_8438     0: 0.644410231831850   1: 0.130376050656575   2: 0.092091122077259   5: 0.045975802692053   9: 0.022086127699815   4: 0.013041192873517   6: 0.013021206334472   3: 0.012999853357384   7: 0.012999551019995   8: 0.012998861457080 

training_844      1: 0.729449464506107   5: 0.133617092449227   6: 0.017119111423245   4: 0.017118909244483   0: 0.017117244771983   8: 0.017115870174877   2: 0.017115855601760   9: 0.017115834923537   7: 0.017115328990361   3: 0.017115287914420 

training_8440     8: 0.436699141969277   6: 0.425855778507674   1: 0.054772701191921   3: 0.014992675282723   0: 0.011379916150210   9: 0.011338202055124   7: 0.011255207770548   5: 0.011237467580070   2: 0.011234584576989   4: 0.011234324915464 

training_8441     0: 0.498520161238500   6: 0.198665811762355   3: 0.152808180506725   1: 0.054997735585508   9: 0.027155484870041   5: 0.016110717959841   8: 0.015903486742368   4: 0.011960289051074   2: 0.011942975829928   7: 0.011935156453661 

training_8443     8: 0.595969415519848   1: 0.183390984107620   6: 0.027596327729717   7: 0.027579340849310   0: 0.027578538392951   9: 0.027577237642942   5: 0.027577234897452   2: 0.027577036531517   3: 0.027576980748669   4: 0.027576903579975 

training_8446     6: 0.794992423766257   0: 0.046486816334875   4: 0.040435661722533   5: 0.033358273175462   8: 0.014148151727972   7: 0.014140543279707   9: 0.014112406328872   2: 0.014109002708240   1: 0.014108399786047   3: 0.014108321170036 

training_8447     4: 0.651108459607163   1: 0.161829498963165   5: 0.023389904675309   0: 0.023381939623796   6: 0.023381844826742   8: 0.023381836170231   9: 0.023381671753542   3: 0.023381635872565   2: 0.023381627675078   7: 0.023381580832409 

training_8448     5: 0.597141671371499   4: 0.113926570038031   6: 0.092685566087918   0: 0.070314290897714   9: 0.020991113241908   1: 0.020988828470683   7: 0.020988073216485   8: 0.020988002355337   2: 0.020987950989233   3: 0.020987933331191 

training_8449     6: 0.828768579157292   5: 0.032755414927651   0: 0.017365259357388   4: 0.017312081654690   1: 0.017308048137493   9: 0.017299401403955   3: 0.017298674794728   8: 0.017298552902017   2: 0.017297076620027   7: 0.017296911044759 

training_8451     6: 0.747128720286034   1: 0.091370683195560   0: 0.049007843031422   9: 0.016071576829051   7: 0.016070993516938   5: 0.016070693620455   8: 0.016070203137617   2: 0.016069815483062   4: 0.016069754530310   3: 0.016069716369550 

training_8453     6: 0.682678838721709   0: 0.097999524568803   5: 0.070255193741621   3: 0.056350272902561   4: 0.027618204942507   7: 0.013021825958861   1: 0.013019447623435   9: 0.013019127058310   8: 0.013018845863139   2: 0.013018718619054 

training_8454     5: 0.562206205817227   8: 0.235550211429251   0: 0.025281118027306   6: 0.025280876944533   1: 0.025280747980171   3: 0.025280346421398   2: 0.025280143930648   4: 0.025280121721603   9: 0.025280114393362   7: 0.025280113334500 

training_8457     4: 0.490655843336488   5: 0.342763035818107   1: 0.020823046840164   6: 0.020822999460476   0: 0.020822926944129   9: 0.020822534019752   8: 0.020822512770162   3: 0.020822491755577   2: 0.020822328125138   7: 0.020822280930007 

training_8458     3: 0.463454340502236   5: 0.295581712330013   4: 0.030128709549627   6: 0.030121484508029   0: 0.030119694394535   2: 0.030119139022855   1: 0.030119071158947   8: 0.030118943025195   9: 0.030118715987551   7: 0.030118189521011 

training_846      5: 0.763298145361115   4: 0.026303765346010   8: 0.026299976847000   3: 0.026299891252433   9: 0.026299842256297   2: 0.026299794595791   7: 0.026299699173206   0: 0.026299651579470   1: 0.026299627683393   6: 0.026299605905285 

training_8467     5: 0.711956954862669   1: 0.059835457651254   8: 0.055241372222993   3: 0.024765887185479   0: 0.024745673573455   4: 0.024731370515855   6: 0.024693256829124   9: 0.024677053662926   2: 0.024676697183752   7: 0.024676276312491 

training_8472     0: 0.653634891888779   5: 0.181468149821831   6: 0.020875358142600   1: 0.020593307284369   9: 0.020572274974275   2: 0.020571751001789   8: 0.020571724609763   4: 0.020571343909666   3: 0.020570661038619   7: 0.020570537328308 

training_8475     6: 0.590032951247879   0: 0.167197293367599   1: 0.088328653827507   7: 0.049653401013167   8: 0.017479386080426   5: 0.017472552310742   4: 0.017469433257499   9: 0.017459308986415   3: 0.017453578772590   2: 0.017453441136176 

training_8478     6: 0.782960230618436   1: 0.080383273441633   5: 0.033225157664993   7: 0.032517932704724   4: 0.011853079156538   2: 0.011828738235104   9: 0.011820321204040   0: 0.011809646765659   3: 0.011800875349682   8: 0.011800744859190 

training_8479     5: 0.471356154950663   6: 0.357598826206049   8: 0.057322905263327   1: 0.016249982689317   0: 0.016247926080114   4: 0.016245261345252   9: 0.016245018154475   2: 0.016244768949679   7: 0.016244668370038   3: 0.016244487991086 

training_848      4: 0.686193180591702   0: 0.110424735402940   5: 0.025429968767412   7: 0.025426116461516   9: 0.025421213511815   8: 0.025421115051246   3: 0.025421053447846   2: 0.025420942775006   1: 0.025420896748767   6: 0.025420777241751 

training_8480     1: 0.594182394029530   2: 0.154096451989246   6: 0.055017839161250   7: 0.051910631510742   0: 0.049486347334853   5: 0.019078062655587   4: 0.019062209669266   3: 0.019057560135264   9: 0.019054566587582   8: 0.019053936926681 

training_8481     4: 0.771868458730694   5: 0.025358847778508   0: 0.025348801148760   1: 0.025348563945819   3: 0.025346113531892   8: 0.025346080091138   6: 0.025345896251497   9: 0.025345828919606   2: 0.025345760010268   7: 0.025345649591818 

training_8487     4: 0.757159020204407   5: 0.026987362805502   8: 0.026982339285063   9: 0.026981865471493   3: 0.026981668060921   7: 0.026981601947350   2: 0.026981589412301   0: 0.026981533018953   1: 0.026981531092202   6: 0.026981488701807 

training_8488     4: 0.781983636650807   5: 0.024228184713197   3: 0.024224462128433   0: 0.024223718651942   6: 0.024223488201398   8: 0.024223435991452   9: 0.024223290095172   2: 0.024223287461856   1: 0.024223267184340   7: 0.024223228921403 

training_8489     5: 0.750480804918726   6: 0.091026562651850   4: 0.019815874203568   0: 0.019815766950856   1: 0.019811145120253   9: 0.019810811313742   8: 0.019810485364816   7: 0.019809737176692   2: 0.019809551579625   3: 0.019809260719871 

training_849      4: 0.348814099665147   5: 0.327527217136216   9: 0.091499100403684   7: 0.080133403750137   6: 0.025355195665943   1: 0.025344735761156   0: 0.025339536025310   2: 0.025331716580312   8: 0.025329590070078   3: 0.025325404942017 

training_8490     3: 0.443319126565156   5: 0.355963942307867   4: 0.025090428252782   7: 0.025090303732945   1: 0.025089496012794   0: 0.025089448932081   2: 0.025089436814687   6: 0.025089348552607   8: 0.025089239751246   9: 0.025089229077836 

training_8491     5: 0.584179120259409   1: 0.131029216649452   3: 0.118085053342172   6: 0.023820827786016   2: 0.023816671583482   4: 0.023816298578618   9: 0.023814471391636   0: 0.023813670485017   8: 0.023812373559507   7: 0.023812296364692 

training_8493     1: 0.459758786443547   6: 0.398696336926443   8: 0.036337971265094   9: 0.015032243795351   0: 0.015031627901834   5: 0.015028898845746   2: 0.015028766546690   3: 0.015028545151176   4: 0.015028445798475   7: 0.015028377325644 

training_8496     0: 0.779658724380849   2: 0.099037508086545   6: 0.015164967572225   1: 0.015164889554307   5: 0.015163669604735   4: 0.015162557098585   9: 0.015162258550655   7: 0.015161999011233   8: 0.015161819119404   3: 0.015161607021463 

training_8497     6: 0.401705516346911   7: 0.313699338604807   0: 0.163002755548397   4: 0.026655304615249   8: 0.016165566344480   1: 0.015760181179937   5: 0.015756032719624   9: 0.015752072152009   2: 0.015751811687461   3: 0.015751420801126 

training_85       5: 0.457882901828614   2: 0.263893371013105   4: 0.106648045851634   8: 0.024520827576788   3: 0.024514452265961   9: 0.024510433294719   0: 0.024507925059061   7: 0.024507388890760   6: 0.024507363748743   1: 0.024507290470616 

training_850      5: 0.500424115515584   1: 0.216373530233639   6: 0.146841154953990   0: 0.019490164733292   4: 0.019481126087287   7: 0.019480194158643   2: 0.019478279821239   8: 0.019477450002088   9: 0.019477111872569   3: 0.019476872621669 

training_8501     5: 0.664615564975352   0: 0.141564471605409   3: 0.024228249504103   4: 0.024227994945895   7: 0.024227352254208   1: 0.024227326593756   2: 0.024227301760288   6: 0.024227281870408   8: 0.024227232475253   9: 0.024227224015329 

training_8502     4: 0.537766742276246   5: 0.266602057931381   6: 0.024458165199101   2: 0.024456152898750   1: 0.024455439198923   0: 0.024454124536886   9: 0.024453230613636   3: 0.024452331577999   7: 0.024451182959090   8: 0.024450572807989 

training_8506     0: 0.337999616443036   9: 0.267112499511052   6: 0.220339075467593   5: 0.081468856274579   1: 0.024145692083360   3: 0.013797362264240   7: 0.013788457534865   4: 0.013782968195887   8: 0.013782753705303   2: 0.013782718520086 

training_8509     1: 0.423998432965475   7: 0.281804468220301   4: 0.157492410355292   0: 0.032258773708426   2: 0.017540922017203   5: 0.017421373953924   6: 0.017373835563738   9: 0.017370204152071   3: 0.017370112597645   8: 0.017369466465925 

training_851      1: 0.704290655813528   4: 0.152123363831701   5: 0.017951125460649   6: 0.017949492695152   8: 0.017949176448217   0: 0.017948441751971   9: 0.017948203073173   2: 0.017947248160575   7: 0.017946266546135   3: 0.017946026218900 

training_8510     1: 0.374503202430506   5: 0.230019034503058   6: 0.173188379712953   0: 0.116097738411389   3: 0.045166746720266   8: 0.012218791985753   2: 0.012203625627764   4: 0.012201744147644   9: 0.012200752471249   7: 0.012199983989419 

training_8512     6: 0.592917942695002   1: 0.277132148900711   7: 0.016273462827363   0: 0.016245436403044   5: 0.016241213693210   4: 0.016240785623166   2: 0.016240658717926   9: 0.016236563698513   8: 0.016236036358049   3: 0.016235751083016 

training_8513     5: 0.741722120757352   1: 0.055131159608594   8: 0.054494352900319   6: 0.021275924894507   0: 0.021233435987438   7: 0.021230530626724   2: 0.021228557544673   4: 0.021228045143524   3: 0.021227986784934   9: 0.021227885751934 

training_8514     1: 0.555561904684569   0: 0.143250208402317   2: 0.139836214555581   5: 0.048268720739356   4: 0.018890873342498   6: 0.018843966752706   9: 0.018837832594608   8: 0.018837592334505   7: 0.018836377071633   3: 0.018836309522227 

training_8516     8: 0.436550903752477   6: 0.423586342094918   1: 0.034720430210735   0: 0.029274403681698   3: 0.012826163926342   7: 0.012702180064025   9: 0.012636663503066   5: 0.012568888848611   2: 0.012567150548872   4: 0.012566873369256 

training_8518     0: 0.636421766637116   1: 0.196102258832378   3: 0.033515423529868   6: 0.032760614311694   5: 0.016867619245986   9: 0.016867202068852   7: 0.016866882518846   4: 0.016866119836239   8: 0.016866115049114   2: 0.016865997969908 

training_852      0: 0.564556409078921   4: 0.285482766942374   9: 0.018756897961835   6: 0.018748512287015   5: 0.018748116705913   2: 0.018743636976009   1: 0.018743282236475   3: 0.018741006901439   7: 0.018739686862962   8: 0.018739684047058 

training_8520     5: 0.517667701413737   2: 0.262316495081034   4: 0.027505630995054   1: 0.027502889357779   8: 0.027501456961038   9: 0.027501375280616   3: 0.027501281141645   7: 0.027501101041122   0: 0.027501072933852   6: 0.027500995794123 

training_8521     5: 0.795422322829959   7: 0.058726061241591   4: 0.018234590665526   6: 0.018232086440680   0: 0.018232020662136   1: 0.018230866565168   8: 0.018230624123465   9: 0.018230524990999   3: 0.018230477231188   2: 0.018230425249287 

training_8522     6: 0.780795742368975   0: 0.064032257138439   1: 0.040228736492122   3: 0.026463677933333   8: 0.014749491533738   5: 0.014747463228637   9: 0.014745932701250   4: 0.014745721096612   2: 0.014745603006732   7: 0.014745374500163 

training_8526     5: 0.643293631920490   6: 0.169530513609696   0: 0.071436296503705   7: 0.029714629646389   1: 0.014344653155621   4: 0.014337649783932   9: 0.014336732780632   3: 0.014335510050154   2: 0.014335225402272   8: 0.014335157147110 

training_8528     5: 0.583257266211292   8: 0.245684230031322   4: 0.021386138679813   6: 0.021382765067922   1: 0.021382236000513   0: 0.021381634752696   9: 0.021381553242189   3: 0.021381448297033   7: 0.021381394246072   2: 0.021381333471149 

training_853      1: 0.663316024358473   6: 0.191916973129884   0: 0.031643406576064   7: 0.019991047944440   2: 0.016204179511024   4: 0.015750916214671   3: 0.015322030214933   5: 0.015292389187553   9: 0.015285359902007   8: 0.015277672960950 

training_8530     4: 0.799540338543477   5: 0.022277409100042   6: 0.022274739775713   2: 0.022274020717909   9: 0.022273273675186   0: 0.022272634106523   1: 0.022272608392063   3: 0.022271741823548   7: 0.022271678202607   8: 0.022271555662933 

training_8533     5: 0.577559711522604   1: 0.185154888233790   0: 0.029665085150295   6: 0.029664995376574   8: 0.029659349824720   7: 0.029659282546303   4: 0.029659238896498   2: 0.029659200657477   3: 0.029659179297443   9: 0.029659068494296 

training_8534     5: 0.541652950339532   1: 0.223229497357259   6: 0.029393085864804   0: 0.029392946233256   2: 0.029390038705417   4: 0.029389188679750   3: 0.029388479236504   7: 0.029388009361127   9: 0.029387968972457   8: 0.029387835249894 

training_8535     6: 0.810911112186655   3: 0.049370317359842   1: 0.030117116880972   0: 0.015678059340773   5: 0.015667113417432   2: 0.015662123808477   9: 0.015649202963425   8: 0.015648430350750   4: 0.015648399909311   7: 0.015648123782363 

training_8536     1: 0.767268269923731   0: 0.025862759353034   5: 0.025861713527935   6: 0.025860637442659   9: 0.025858401320076   4: 0.025858091286537   8: 0.025857744344136   2: 0.025857481384022   7: 0.025857457051711   3: 0.025857444366161 

training_8540     5: 0.833000794410256   6: 0.018575649366096   4: 0.018554503498944   1: 0.018553784321174   0: 0.018553388921820   8: 0.018552882434333   3: 0.018552342140697   9: 0.018552272863972   2: 0.018552233675181   7: 0.018552148367529 

training_8541     5: 0.543625842914513   9: 0.176780853771227   6: 0.167261786078687   4: 0.016089414053658   0: 0.016058237984109   1: 0.016041462544575   8: 0.016036041184310   7: 0.016035705883738   2: 0.016035383769512   3: 0.016035271815671 

training_8543     0: 0.617119942751704   1: 0.146104648909521   5: 0.061831785450231   2: 0.025066039307119   6: 0.025029966727864   8: 0.025002590047680   9: 0.024964081030973   4: 0.024961164328557   7: 0.024959948700347   3: 0.024959832746004 

training_8544     7: 0.380354635281954   0: 0.249319340964812   6: 0.188284710085597   5: 0.047500459774498   2: 0.022429405940563   3: 0.022426747577703   1: 0.022423248386172   4: 0.022421703716869   9: 0.022420057871081   8: 0.022419690400751 

training_8545     5: 0.784914165745925   6: 0.023899043359346   0: 0.023898790885477   1: 0.023898694711592   8: 0.023898655503826   9: 0.023898405231747   4: 0.023898271510321   3: 0.023898183915973   2: 0.023897960670320   7: 0.023897828465472 

training_8546     0: 0.776106520547121   5: 0.067336361125975   1: 0.019573982192446   6: 0.019572941845361   4: 0.019570058732363   7: 0.019568755368009   8: 0.019568002367668   2: 0.019567924645811   9: 0.019567735433554   3: 0.019567717741693 

training_8547     5: 0.624193863787421   6: 0.138678038519997   9: 0.080354592657760   8: 0.064779042651626   1: 0.015335648873328   4: 0.015334734955173   2: 0.015333683555114   0: 0.015332130414556   7: 0.015329374731514   3: 0.015328889853511 

training_855      6: 0.724516058347118   1: 0.079331324670014   0: 0.077094145206020   7: 0.017017912821799   5: 0.017009566523259   9: 0.017007689704333   8: 0.017006128077848   2: 0.017006006471563   4: 0.017005792639757   3: 0.017005375538290 

training_8553     7: 0.452268997570623   6: 0.298120539508972   0: 0.093068267852542   9: 0.038655482348777   5: 0.020116439722737   4: 0.019580705432922   2: 0.019553070268554   1: 0.019547324693281   8: 0.019545096235364   3: 0.019544076366230 

training_8554     6: 0.723894854309023   1: 0.099487707430662   3: 0.053303922861033   0: 0.029793831444593   5: 0.015586897540447   4: 0.015586751230160   8: 0.015586669980066   7: 0.015586507803960   9: 0.015586470604847   2: 0.015586386795209 

training_8555     5: 0.504011187120195   0: 0.311598442099212   6: 0.023063669850047   1: 0.023049495088136   4: 0.023047732001103   7: 0.023046846037410   2: 0.023046649870912   3: 0.023046430508065   8: 0.023046274419090   9: 0.023043273005830 

training_8556     5: 0.696002272961583   4: 0.111507056197810   0: 0.024066091830253   3: 0.024061355653787   9: 0.024061079680242   6: 0.024060595514280   1: 0.024060518972283   7: 0.024060432394179   2: 0.024060347904628   8: 0.024060248890955 

training_8558     5: 0.586220282851980   0: 0.235865033089280   1: 0.022250775088986   6: 0.022242652127212   9: 0.022237349768673   2: 0.022237100560057   4: 0.022237001543153   7: 0.022236818301715   8: 0.022236551237274   3: 0.022236435431670 

training_8559     4: 0.644476301483889   2: 0.090653179822816   6: 0.088795801795647   5: 0.025160373209082   1: 0.025155506950133   8: 0.025151924243171   0: 0.025151828670983   9: 0.025151728384591   3: 0.025151682242172   7: 0.025151673197517 

training_856      6: 0.803530807087546   0: 0.063550238814489   7: 0.025493413188708   8: 0.023494494327689   5: 0.022322099565964   1: 0.012322506601200   9: 0.012322108636288   2: 0.012321460649300   4: 0.012321437503413   3: 0.012321433625401 

training_8561     1: 0.720787978567619   6: 0.123197482795884   0: 0.059496207198961   2: 0.018130261835464   5: 0.013245995461468   8: 0.013090149519969   7: 0.013016914398582   3: 0.013011957297660   4: 0.013011812688700   9: 0.013011240235695 

training_8562     5: 0.742502707594601   6: 0.079223481918082   1: 0.022286259164281   0: 0.022286243070977   2: 0.022283705355889   7: 0.022283621870094   4: 0.022283591757083   3: 0.022283506835634   9: 0.022283470164910   8: 0.022283412268449 

training_8563     6: 0.679464337327791   0: 0.166919138512958   4: 0.057167177973816   1: 0.029315772935135   2: 0.015506854111098   3: 0.010399454102547   8: 0.010375085349210   9: 0.010341120737841   5: 0.010271699389524   7: 0.010239359560081 

training_8565     4: 0.419179297616507   5: 0.360763773380520   8: 0.077483816309284   3: 0.020368469899404   6: 0.020368291973114   0: 0.020367742815742   9: 0.020367524773027   7: 0.020367360978670   1: 0.020367182817851   2: 0.020366539435882 

training_8567     6: 0.440800862554852   4: 0.230002296322780   9: 0.121186157230547   2: 0.091612583127212   0: 0.033359537177150   8: 0.016646687080743   3: 0.016625590798144   5: 0.016607285296334   1: 0.016581449527696   7: 0.016577550884542 

training_8569     6: 0.361985092438025   5: 0.229074163074924   1: 0.211047662795612   2: 0.069588663779889   0: 0.047895411298059   9: 0.028299760450024   3: 0.016406577799363   8: 0.012158601304977   4: 0.011884055426208   7: 0.011660011632920 

training_857      6: 0.752435762050251   1: 0.105143619383307   5: 0.033972959482527   2: 0.015560656396825   0: 0.015483752632982   9: 0.015481063620298   7: 0.015480853554439   8: 0.015480609229913   4: 0.015480364601922   3: 0.015480359047535 

training_8571     0: 0.485466031162574   5: 0.290438288073917   2: 0.054289576510200   1: 0.042913698185647   6: 0.021168440260835   3: 0.021148498126144   7: 0.021146085321483   8: 0.021143547159300   4: 0.021142977303691   9: 0.021142857896208 

training_8572     7: 0.424639144888053   0: 0.215513076289730   6: 0.178074926828840   5: 0.057308790493679   1: 0.020755793435792   2: 0.020746852513759   3: 0.020742810591085   4: 0.020741003291704   9: 0.020739207934411   8: 0.020738393732948 

training_8574     6: 0.526095899714485   0: 0.178694866383774   5: 0.131341422028771   1: 0.058006124907093   4: 0.017644899213689   9: 0.017644460501052   7: 0.017643724576820   8: 0.017643330739215   3: 0.017642638965342   2: 0.017642632969758 

training_8577     5: 0.751673857257334   3: 0.074761011640717   4: 0.021700070663326   6: 0.021699707858928   1: 0.021695128153868   0: 0.021694670543413   8: 0.021694057859375   9: 0.021693893893733   2: 0.021693806794360   7: 0.021693795334945 

training_8578     6: 0.810893880647494   0: 0.092088971979903   1: 0.022572406593239   7: 0.010679469876179   8: 0.010629690856960   5: 0.010628169106689   9: 0.010627530164555   4: 0.010627463542283   2: 0.010626257352488   3: 0.010626159880211 

training_8579     4: 0.698363714991401   9: 0.129984035973180   5: 0.021464613956740   6: 0.021457846811663   1: 0.021456984546074   0: 0.021456643566121   8: 0.021454525569091   3: 0.021453925566183   7: 0.021453881870041   2: 0.021453827149506 

training_8580     4: 0.627461682510497   5: 0.182118448281672   6: 0.023855491412238   9: 0.023822555296081   0: 0.023801564632087   1: 0.023788744341006   7: 0.023788410415052   8: 0.023788130236502   3: 0.023787528930868   2: 0.023787443943997 

training_8581     5: 0.712387146043189   8: 0.162143567763802   4: 0.015685841808781   6: 0.015684435492678   1: 0.015683862794821   0: 0.015683751282057   9: 0.015683057651306   7: 0.015682791269271   2: 0.015682776020478   3: 0.015682769873617 

training_8582     5: 0.757583729502021   4: 0.026943066554453   6: 0.026934825052002   1: 0.026934421202074   8: 0.026934220954261   0: 0.026934210656934   7: 0.026934020507332   3: 0.026933896619960   9: 0.026933837059995   2: 0.026933771890969 

training_8584     6: 0.749192124336852   1: 0.027882115544101   5: 0.027874661127477   0: 0.027865856917396   3: 0.027865120952015   8: 0.027864973483259   7: 0.027864570638425   9: 0.027863940319303   4: 0.027863383742214   2: 0.027863252938958 

training_8585     6: 0.743103440650651   5: 0.104790328372886   0: 0.055978982705092   1: 0.013739757926055   9: 0.013732027963130   7: 0.013731347536029   8: 0.013731219506969   2: 0.013731020053874   4: 0.013730963746527   3: 0.013730911538788 

training_8586     6: 0.760438720855189   1: 0.026629752762761   8: 0.026618561745711   0: 0.026618309618397   7: 0.026616679005026   9: 0.026616435061777   5: 0.026616330143087   4: 0.026615223062115   2: 0.026615001666281   3: 0.026614986079657 

training_8587     6: 0.744528796107848   1: 0.028388117304543   0: 0.028387613180565   5: 0.028385420993335   8: 0.028385398720020   7: 0.028385204479968   9: 0.028385194483506   2: 0.028384795136015   3: 0.028384759658947   4: 0.028384699935253 

training_8588     6: 0.859612147060057   1: 0.015599382604635   0: 0.015599188138992   5: 0.015599160619600   9: 0.015598543592788   8: 0.015598522140888   7: 0.015598357702353   3: 0.015598314512754   2: 0.015598210646873   4: 0.015598172981059 

training_859      4: 0.773429981576613   3: 0.061177781269044   5: 0.020678360562447   6: 0.020677041076532   1: 0.020672999370502   0: 0.020672897651428   8: 0.020672840668265   2: 0.020672762434375   9: 0.020672705521289   7: 0.020672629869505 

training_8590     6: 0.739140590248051   1: 0.028986551283225   0: 0.028986036638930   8: 0.028985719423246   9: 0.028984453495221   7: 0.028984370828728   5: 0.028983202310628   3: 0.028983055566113   2: 0.028983022872059   4: 0.028982997333800 

training_8591     1: 0.478278588488699   6: 0.346826982121254   7: 0.056231828528727   8: 0.016954155781079   0: 0.016952557838492   9: 0.016952372318677   5: 0.016951360665501   3: 0.016950872520973   4: 0.016950771662790   2: 0.016950510073811 

training_8592     6: 0.784884034599801   1: 0.077326550602238   0: 0.063759775385213   2: 0.010586543279566   5: 0.010581276592540   4: 0.010572659952277   7: 0.010572424378086   3: 0.010572289028339   9: 0.010572270246851   8: 0.010572175935089 

training_8595     0: 0.438563678917553   6: 0.266994262648814   5: 0.214964251750289   1: 0.011369217834107   7: 0.011359464702959   9: 0.011353676902968   2: 0.011350288430651   4: 0.011349713358106   8: 0.011348619198916   3: 0.011346826255638 

training_8596     6: 0.724005075931433   0: 0.171818307067554   5: 0.013026273052095   1: 0.013022471132573   2: 0.013021533076521   4: 0.013021370137537   7: 0.013021366749539   9: 0.013021276144347   8: 0.013021257508924   3: 0.013021069199478 

training_8597     6: 0.858227851071058   0: 0.034101405339483   9: 0.033680962041776   1: 0.010577935926110   4: 0.010572335152389   5: 0.010569641584181   8: 0.010568176333692   7: 0.010567289633272   2: 0.010567211956122   3: 0.010567190961916 

training_8598     6: 0.752283669311730   9: 0.066997498339228   0: 0.065308575331543   1: 0.046596622167936   4: 0.017133800746980   8: 0.010342955026903   5: 0.010334955122879   7: 0.010334248251432   2: 0.010334042424783   3: 0.010333633276588 

training_8599     6: 0.789690035251831   0: 0.085145488972329   1: 0.031887517498246   9: 0.013580348965784   3: 0.013368662501506   5: 0.013322553134008   4: 0.013261054842754   8: 0.013252867735739   2: 0.013246094296111   7: 0.013245376801691 

training_86       5: 0.765710066618092   0: 0.026034216673521   2: 0.026032401172711   6: 0.026032136059302   3: 0.026032117876882   4: 0.026032096308820   1: 0.026031996393218   7: 0.026031693668921   9: 0.026031644778466   8: 0.026031630450067 

training_8600     6: 0.702487900487401   1: 0.111742147175986   0: 0.097209346708163   2: 0.023810580253548   9: 0.010807037906263   5: 0.010801787885116   4: 0.010787086245043   8: 0.010785096167753   3: 0.010784769384426   7: 0.010784247786301 

training_8602     6: 0.540504543176112   1: 0.246890656500963   9: 0.079139929381741   5: 0.058808383448069   7: 0.021220741062388   0: 0.010695446606411   8: 0.010685230716292   2: 0.010685123096243   3: 0.010684985659347   4: 0.010684960352434 

training_8603     6: 0.721801502017339   7: 0.090599032177855   4: 0.079828089262588   0: 0.015398323434175   5: 0.015397524651601   1: 0.015395698318822   9: 0.015395214319161   2: 0.015394986341354   8: 0.015394939402271   3: 0.015394690074831 

training_8604     6: 0.688175218405015   0: 0.114410929952967   3: 0.097015846102985   5: 0.014515644550717   8: 0.014315551204665   9: 0.014314542162959   7: 0.014313665267007   1: 0.014313237163831   4: 0.014312728691714   2: 0.014312636498139 

training_8605     6: 0.385941654617036   1: 0.335089462202745   8: 0.034880036083728   7: 0.034875682502585   9: 0.034870676881370   0: 0.034870372251448   5: 0.034868589488056   3: 0.034867944901344   2: 0.034867865246497   4: 0.034867715825190 

training_8606     6: 0.792213795160795   7: 0.072971988079175   0: 0.054390966171245   1: 0.011494576869064   3: 0.011490830319521   8: 0.011489574113550   4: 0.011487618747192   5: 0.011487405562027   2: 0.011486731128781   9: 0.011486513848650 

training_8607     6: 0.610512621304910   1: 0.193001362547333   0: 0.103846395741020   5: 0.013234840740208   9: 0.013234589317012   8: 0.013234472310916   7: 0.013234214530242   3: 0.013233871228605   4: 0.013233855113954   2: 0.013233777165801 

training_8608     6: 0.640405895705234   1: 0.196252433052117   0: 0.079850242253873   5: 0.011927929547488   8: 0.011927836927103   7: 0.011927368033397   9: 0.011927206914758   3: 0.011927126385310   4: 0.011926991292398   2: 0.011926969888322 

training_8609     4: 0.424421607538296   2: 0.207273742008777   9: 0.150237843440851   5: 0.031168004469027   8: 0.031158870380563   3: 0.031156265972812   1: 0.031149442164663   0: 0.031146942301121   6: 0.031144606328624   7: 0.031142675395267 

training_861      5: 0.678929681614368   8: 0.096942850741987   0: 0.087233296910958   6: 0.019563391756363   4: 0.019557543978120   9: 0.019556245595724   7: 0.019554578665771   1: 0.019554306337768   2: 0.019554212606687   3: 0.019553891792254 

training_8610     6: 0.549264730827488   0: 0.208595504075522   3: 0.126614875156251   1: 0.016505632533792   9: 0.016504411802280   5: 0.016503979885142   2: 0.016502994863861   4: 0.016502862775084   7: 0.016502557595641   8: 0.016502450484939 

training_8611     5: 0.430822701720255   6: 0.348909574172319   3: 0.061232201655087   8: 0.034162901404871   0: 0.033459824518893   2: 0.032729256337990   4: 0.014685281844061   9: 0.014668440001666   1: 0.014665717929526   7: 0.014664100415333 

training_8612     9: 0.423626790339256   4: 0.348138953850847   5: 0.028540276727868   6: 0.028530596782889   0: 0.028530500324564   1: 0.028530379892040   3: 0.028529117463131   8: 0.028526201571472   2: 0.028523633531732   7: 0.028523549516200 

training_8613     6: 0.682752761651174   8: 0.128920479827765   0: 0.083942774578433   3: 0.014922839079331   5: 0.014911594753148   9: 0.014910754907674   1: 0.014910523885769   4: 0.014909545252632   7: 0.014909472421873   2: 0.014909253642202 

training_8614     5: 0.556514593305590   6: 0.189098472163475   7: 0.093744967430323   3: 0.055073444002819   4: 0.017603955058597   9: 0.017598282723809   1: 0.017594244533483   0: 0.017592354004262   8: 0.017591478084988   2: 0.017588208692655 

training_8615     1: 0.551863103724609   6: 0.249533693389321   5: 0.039123553796098   9: 0.037334589531399   0: 0.028299886360929   2: 0.018858381610037   8: 0.018751280767556   7: 0.018750286529797   3: 0.018744007881546   4: 0.018741216408707 

training_8616     5: 0.730949787135591   6: 0.029901335691252   4: 0.029896924018389   8: 0.029893319384677   0: 0.029893234555377   7: 0.029893226037362   1: 0.029893102217422   9: 0.029893094130015   2: 0.029893014495863   3: 0.029892962334052 

training_8617     1: 0.524697783673849   3: 0.245587010042275   9: 0.028724755172682   8: 0.028718585203058   5: 0.028715510088033   0: 0.028713740513127   4: 0.028711936691412   6: 0.028711736893517   2: 0.028709561185618   7: 0.028709380536428 

training_8618     1: 0.486023083897703   6: 0.214062730510026   3: 0.178029044501825   7: 0.019187229220684   0: 0.017121373664334   5: 0.017117927292057   9: 0.017116007332062   4: 0.017115024795625   8: 0.017114737001257   2: 0.017112841784428 

training_8619     5: 0.623698575729743   0: 0.130705842180823   3: 0.121693653943572   6: 0.017708478380622   1: 0.017701372109468   7: 0.017701012349127   9: 0.017699522848102   4: 0.017698052943454   8: 0.017697701006875   2: 0.017695788508214 

training_8621     6: 0.618219013793341   0: 0.300518063774805   8: 0.014171415116846   5: 0.014087300233351   1: 0.008938674465962   9: 0.008831331657279   2: 0.008831246800342   7: 0.008803429392113   4: 0.008799785157855   3: 0.008799739608106 

training_8623     6: 0.759318576253215   1: 0.096274835766433   9: 0.049365538388542   3: 0.022040439590904   0: 0.012299458004793   5: 0.012142861398420   4: 0.012139674823921   8: 0.012139666913906   7: 0.012139530487961   2: 0.012139418371905 

training_8624     6: 0.823539152777407   0: 0.019607269304705   9: 0.019607247197464   7: 0.019607182929971   8: 0.019607153912389   5: 0.019606794151222   1: 0.019606749541176   2: 0.019606341888620   3: 0.019606056630114   4: 0.019606051666931 

training_8628     1: 0.508436097206308   6: 0.274667096330691   0: 0.138529814099656   8: 0.021973200496946   5: 0.009413459956513   4: 0.009396598575144   9: 0.009396167795201   7: 0.009395878802299   3: 0.009395849447303   2: 0.009395837289939 

training_8629     9: 0.848348855703560   6: 0.016852035289833   8: 0.016850768534671   5: 0.016850709717482   0: 0.016850119785985   4: 0.016849891091408   1: 0.016849758705450   2: 0.016849326813320   3: 0.016849279737504   7: 0.016849254620787 

training_8630     6: 0.716156991410821   0: 0.100626245249461   9: 0.071195680203826   2: 0.030177551034457   8: 0.018683481201031   4: 0.017867571718566   1: 0.011353031718221   5: 0.011316253565458   3: 0.011311662963783   7: 0.011311530934375 

training_8632     6: 0.588052200118047   2: 0.093443409648528   4: 0.092156075308191   1: 0.085887924594214   0: 0.063302490725261   7: 0.020127461124711   9: 0.014258762773199   5: 0.014257560339133   8: 0.014257135730675   3: 0.014256979638041 

training_8635     6: 0.603336662863180   1: 0.268787681068260   0: 0.044421252014770   5: 0.011922923747581   9: 0.011922639746669   3: 0.011922050059701   7: 0.011921796782977   8: 0.011921711569733   4: 0.011921667749653   2: 0.011921614397475 

training_8636     6: 0.538823405051305   8: 0.321403671783608   5: 0.017473408844816   0: 0.017473075048032   1: 0.017472461416003   9: 0.017471883555523   4: 0.017470659949816   7: 0.017470519276641   3: 0.017470499781065   2: 0.017470415293189 

training_8637     6: 0.747456728078918   0: 0.100613084392079   5: 0.053530992173836   3: 0.023296717669292   1: 0.012777900921117   7: 0.012489269390194   8: 0.012458988024185   9: 0.012458837397646   4: 0.012458768514055   2: 0.012458713438678 

training_8638     6: 0.567494806048969   7: 0.285045654890530   0: 0.040655785381960   1: 0.015260424829032   8: 0.015257973024862   5: 0.015257765038297   2: 0.015257473105276   9: 0.015257178390369   4: 0.015256508392830   3: 0.015256430897876 

training_8641     6: 0.755116173704515   1: 0.075374365098370   0: 0.050904289553596   8: 0.016944661866069   5: 0.016944088086003   7: 0.016943657475439   9: 0.016943324241922   3: 0.016943198499199   2: 0.016943146031086   4: 0.016943095443801 

training_8643     1: 0.726307915276642   5: 0.030433001542928   4: 0.030427529970022   9: 0.030424505067281   8: 0.030414671794321   3: 0.030403864495116   6: 0.030399213098025   0: 0.030398420800958   2: 0.030395671413375   7: 0.030395206541333 

training_8644     5: 0.385721206952765   6: 0.379239163824580   0: 0.132382203938255   3: 0.014989503654791   1: 0.014619696945217   4: 0.014612194703891   8: 0.014609730157749   9: 0.014609634259304   2: 0.014608653462606   7: 0.014608012100842 

training_865      5: 0.532782641521738   9: 0.181594564786826   8: 0.133869364039787   6: 0.021682537334076   1: 0.021681058692166   0: 0.021680281890132   4: 0.021678442254403   7: 0.021677297097463   3: 0.021677144677878   2: 0.021676667705532 

training_8654     6: 0.812981788818778   1: 0.045561589706499   5: 0.017685991051666   4: 0.017683055575875   8: 0.017681935819158   0: 0.017681558699472   9: 0.017681533885011   7: 0.017681241946297   2: 0.017680744477329   3: 0.017680560019913 

training_8656     6: 0.765667369682446   0: 0.097825765589451   1: 0.034080760463489   9: 0.014633558956223   8: 0.014633248718745   5: 0.014632750992170   7: 0.014632606152046   3: 0.014631920243753   2: 0.014631409404781   4: 0.014630609796897 

training_8657     1: 0.477995939295759   6: 0.347111459063072   7: 0.056230004462396   8: 0.016954154180681   0: 0.016952557044123   9: 0.016952371122667   5: 0.016951360425839   3: 0.016950872870248   4: 0.016950771526577   2: 0.016950510008638 

training_8658     6: 0.610505823048796   1: 0.192990994734705   0: 0.103863562095429   5: 0.013234840705828   9: 0.013234589149254   8: 0.013234472319810   7: 0.013234214441163   3: 0.013233871224443   4: 0.013233855112790   2: 0.013233777167783 

training_866      5: 0.611124276344676   0: 0.194638148174511   9: 0.024307892591312   8: 0.024283232479797   6: 0.024278024878120   3: 0.024274134606880   4: 0.024273926317920   1: 0.024273691015388   2: 0.024273339332750   7: 0.024273334258646 

training_8661     6: 0.706443025951414   5: 0.110785416825362   0: 0.071718142454498   1: 0.015866849605729   9: 0.015865472343905   7: 0.015864596045415   8: 0.015864375054958   2: 0.015864141623186   3: 0.015864008416432   4: 0.015863971679101 

training_8662     6: 0.784855054100094   1: 0.077350598326700   0: 0.063764763194646   2: 0.010586512331769   5: 0.010581253543848   4: 0.010572659518991   7: 0.010572424018500   3: 0.010572288972757   9: 0.010572270104622   8: 0.010572175888074 

training_8663     6: 0.539169154762130   1: 0.247863777429494   9: 0.079384800394538   5: 0.058968290306219   7: 0.021239336544342   0: 0.010683178156271   8: 0.010673017860628   2: 0.010672915102283   3: 0.010672777345584   4: 0.010672752098512 

training_8664     6: 0.618238412062699   0: 0.300498028462561   8: 0.014171458890203   5: 0.014087432351889   1: 0.008939136244133   9: 0.008831328087978   2: 0.008831250039799   7: 0.008803429078669   4: 0.008799785166363   3: 0.008799739615705 

training_8665     9: 0.487846746239881   5: 0.257825838233233   4: 0.031798620162367   3: 0.031792190292604   8: 0.031791515834209   1: 0.031790675948865   0: 0.031789945696767   2: 0.031788517331562   6: 0.031788075524588   7: 0.031787874735922 

training_8666     1: 0.508353190611323   6: 0.274674158401283   0: 0.138605591156821   8: 0.021973266828194   5: 0.009413461449351   4: 0.009396598368339   9: 0.009396167742383   7: 0.009395878792223   3: 0.009395849404864   2: 0.009395837245220 

training_8667     6: 0.603194002893190   1: 0.268945732285603   0: 0.044405857195601   5: 0.011922924895752   9: 0.011922642564446   3: 0.011922049853698   7: 0.011921796723759   8: 0.011921711479028   4: 0.011921667740179   2: 0.011921614368742 

training_8668     5: 0.508603696165786   1: 0.238053353555782   9: 0.135480486296565   8: 0.016844080574697   6: 0.016840350605505   0: 0.016838705811964   3: 0.016837851800392   4: 0.016835413626379   2: 0.016833180121588   7: 0.016832881441341 

training_867      6: 0.595762321338545   7: 0.228313658451945   8: 0.049887314425042   1: 0.043040904079157   0: 0.013838440386629   5: 0.013835312438330   9: 0.013832688314129   4: 0.013832203926092   3: 0.013828899453913   2: 0.013828257186217 

training_8670     6: 0.852094508270034   1: 0.016434603450673   0: 0.016434532606308   5: 0.016434422195538   9: 0.016433829804830   8: 0.016433809092967   7: 0.016433657276053   3: 0.016433621066781   2: 0.016433527691990   4: 0.016433488544827 

training_8671     6: 0.712765231579417   0: 0.191437608454648   1: 0.011976351092590   5: 0.011975013625374   9: 0.011974631173851   7: 0.011974390320505   4: 0.011974266331138   8: 0.011974227893183   2: 0.011974196868704   3: 0.011974082660589 

training_8672     6: 0.549457788671106   0: 0.208467637843855   3: 0.126549679862504   1: 0.016505638300647   9: 0.016504411554515   5: 0.016503980098564   2: 0.016502993945976   4: 0.016502862246158   7: 0.016502557166502   8: 0.016502450310174 

training_8673     0: 0.739438582144102   8: 0.028959408434338   6: 0.028957671680602   9: 0.028950298050705   5: 0.028950082562694   1: 0.028949995261192   7: 0.028949108900888   2: 0.028948436160877   4: 0.028948258507334   3: 0.028948158297269 

training_8674     6: 0.755115772405007   1: 0.075415068096561   0: 0.050863987725348   8: 0.016944661846838   5: 0.016944088094576   7: 0.016943657434637   9: 0.016943324264276   3: 0.016943198610948   2: 0.016943146059538   4: 0.016943095462271 

training_8675     6: 0.664616251195060   1: 0.155202583068172   8: 0.073840037771385   3: 0.037686295582068   2: 0.017016766747876   0: 0.010361200943055   9: 0.010319705936394   5: 0.010319257033416   7: 0.010319098616376   4: 0.010318803106198 

training_8676     6: 0.640196108990844   1: 0.196458489675134   0: 0.079853973124794   5: 0.011927929887051   8: 0.011927836024711   7: 0.011927367391413   9: 0.011927207127901   3: 0.011927126519915   4: 0.011926991340066   2: 0.011926969918172 

training_8677     6: 0.591704869583457   0: 0.304351199227704   5: 0.013398271568225   8: 0.012938364231800   9: 0.012936645028899   1: 0.012935018992216   4: 0.012934406294733   7: 0.012934010881004   2: 0.012933699101978   3: 0.012933515089984 

training_8678     9: 0.662592744146858   6: 0.182842029841541   8: 0.019324843097299   5: 0.019320758677278   3: 0.019320479877869   0: 0.019320345223255   1: 0.019320344597331   4: 0.019319787173985   7: 0.019319355657536   2: 0.019319311707047 

training_868      5: 0.452155541673309   6: 0.306833830627171   0: 0.097741130435578   7: 0.020473107994335   1: 0.020467549230410   3: 0.020466997084635   9: 0.020466160328429   8: 0.020465572229515   4: 0.020465441976682   2: 0.020464668419935 

training_8681     6: 0.397959374151694   0: 0.377096559785974   3: 0.134072009490283   5: 0.012994466183981   1: 0.012982573121014   7: 0.012982083069611   4: 0.012979520761658   8: 0.012978437396739   9: 0.012977853245321   2: 0.012977122793726 

training_8683     6: 0.698397840255648   9: 0.149925054560841   7: 0.019053900514741   0: 0.018948679218926   5: 0.018947678670456   1: 0.018945678143097   4: 0.018945619891143   8: 0.018945554032485   2: 0.018945028580619   3: 0.018944966132043 

training_8684     6: 0.752636740207239   0: 0.096658436705927   5: 0.018848377458020   9: 0.018837002344170   7: 0.018836759267745   4: 0.018836753252238   8: 0.018836659271108   2: 0.018836602112048   1: 0.018836490947853   3: 0.018836178433653 

training_8685     1: 0.585195753717409   3: 0.199240056130263   0: 0.080795501506694   6: 0.019259863569669   9: 0.019253938566220   8: 0.019252911405144   5: 0.019252031272842   4: 0.019250269121098   7: 0.019249943676124   2: 0.019249731034536 

training_8686     6: 0.784148390231975   8: 0.054162902388607   0: 0.047355598924560   9: 0.033354691634964   1: 0.013659884409779   5: 0.013464123663712   7: 0.013463697791175   3: 0.013463596596961   2: 0.013463577420762   4: 0.013463536937504 

training_8688     6: 0.757051668480371   3: 0.076966311252719   1: 0.059977778107622   2: 0.024180447468919   0: 0.013662197499973   8: 0.013648748722041   9: 0.013634890585937   7: 0.013634488992976   5: 0.013623044338313   4: 0.013620424551128 

training_8689     1: 0.351292999327709   6: 0.262277364752481   0: 0.249057626851259   7: 0.045343268481585   5: 0.015342519968172   9: 0.015338730678600   4: 0.015337908904287   8: 0.015336770505367   2: 0.015336467062984   3: 0.015336343467557 

training_8690     6: 0.822800225819253   1: 0.019694102891560   5: 0.019692355674071   0: 0.019692300586169   4: 0.019688128456757   8: 0.019687599037632   7: 0.019686472266888   2: 0.019686396636568   9: 0.019686336613930   3: 0.019686082017172 

training_8691     4: 0.472371407244503   6: 0.320639206977239   0: 0.078324745136577   2: 0.018703703648908   1: 0.018350778876694   5: 0.018333723396952   7: 0.018319664851270   9: 0.018319226155439   3: 0.018318994613948   8: 0.018318549098470 

training_8692     6: 0.639290615878316   0: 0.168322461515207   8: 0.048494316873456   3: 0.045633316141041   5: 0.016383340937921   9: 0.016380148160813   1: 0.016375149480152   4: 0.016373897821476   2: 0.016373419422133   7: 0.016373333769484 

training_8694     6: 0.663022702988113   3: 0.160944011547379   7: 0.022058602327095   8: 0.022000207193636   5: 0.021997106351682   9: 0.021996180907627   0: 0.021995960595758   4: 0.021995271057850   1: 0.021995162572826   2: 0.021994794458035 

training_8696     6: 0.744201291792374   1: 0.110951010620360   3: 0.033503472609117   9: 0.015924751694088   0: 0.015912419684532   5: 0.015902178590393   8: 0.015901576347438   7: 0.015901352211414   2: 0.015901006554317   4: 0.015900939895967 

training_8699     6: 0.639288515299052   0: 0.168324523381260   8: 0.048494333910411   3: 0.045633320435631   5: 0.016383358758573   9: 0.016380147748972   1: 0.016375149437302   4: 0.016373897829566   2: 0.016373419426625   7: 0.016373333772607 

training_87       5: 0.584823518042811   3: 0.210437151123937   6: 0.025593502624643   0: 0.025592945366056   1: 0.025592874894360   4: 0.025592656093679   2: 0.025592011688827   9: 0.025591857570702   7: 0.025591757915092   8: 0.025591724679894 

training_870      6: 0.547857122725261   9: 0.319572537662332   0: 0.016574875976070   5: 0.016572758070510   8: 0.016572556074207   1: 0.016571141215104   4: 0.016570457394630   7: 0.016570016512400   2: 0.016569407551101   3: 0.016569126818384 

training_8701     6: 0.548126633560010   0: 0.232739372008785   5: 0.027409226069230   4: 0.027397904800309   8: 0.027396027646282   9: 0.027390705211349   7: 0.027386037951400   1: 0.027385769511008   2: 0.027384191784094   3: 0.027384131457533 

training_8702     5: 0.490029287085497   6: 0.318347152345547   3: 0.081586140104487   9: 0.015722309849594   8: 0.015720112610071   4: 0.015719898881713   1: 0.015719780150864   0: 0.015719391626045   2: 0.015717971087327   7: 0.015717956258854 

training_8704     1: 0.408226068143448   0: 0.338552110873254   8: 0.119179565330174   6: 0.019157859404845   5: 0.019151255895508   4: 0.019148205255823   7: 0.019146863323386   9: 0.019146765218332   2: 0.019145856408579   3: 0.019145450146651 

training_8705     6: 0.652939946183406   5: 0.153419648894042   0: 0.086069208860209   8: 0.028906151163916   3: 0.017607945195588   1: 0.017007375111207   9: 0.011030152855711   4: 0.011013895141368   2: 0.011004872643700   7: 0.011000803950854 

training_8706     6: 0.684216258391615   0: 0.175465436569365   8: 0.028553876378313   1: 0.015989575853315   5: 0.015966182268444   4: 0.015963876633279   9: 0.015963656107522   7: 0.015960890372554   3: 0.015960140580277   2: 0.015960106845316 

training_8707     6: 0.398090884190228   0: 0.270489782994188   1: 0.210753005364442   7: 0.036636328702178   3: 0.031497350234339   9: 0.010514665008148   5: 0.010507322995777   4: 0.010505715242555   2: 0.010503246421006   8: 0.010501698847139 

training_8708     5: 0.736254068465533   4: 0.081087185928334   6: 0.059876318261212   8: 0.039160305696097   1: 0.013940174525859   3: 0.013938130297957   0: 0.013937712391242   2: 0.013936459550778   7: 0.013935249238129   9: 0.013934395644859 

training_8709     7: 0.505618144874121   2: 0.271682948363537   0: 0.027856579320702   1: 0.027851771834303   6: 0.027839721885547   5: 0.027836230355076   8: 0.027828948931370   4: 0.027828774638862   9: 0.027828766471676   3: 0.027828113324806 

training_8710     6: 0.610585272654043   1: 0.193096503149479   0: 0.103678600993698   5: 0.013234841063955   9: 0.013234590965215   8: 0.013234472233455   7: 0.013234215402304   3: 0.013233871268267   4: 0.013233855124005   2: 0.013233777145579 

training_8711     1: 0.429318648048361   0: 0.162515921352948   7: 0.159989380307103   2: 0.156971329996829   5: 0.015205853432095   6: 0.015201534145107   8: 0.015200918909890   9: 0.015200622718116   4: 0.015198651911390   3: 0.015197139178161 

training_8713     9: 0.344220249354049   6: 0.319173241392261   8: 0.154860239149361   7: 0.069176130568262   3: 0.018808849644730   0: 0.018758593096502   2: 0.018758022143071   1: 0.018751885977315   5: 0.018747330761705   4: 0.018745457912743 

training_8714     6: 0.741977196449910   0: 0.137912224203945   1: 0.053251360387211   9: 0.012722793731990   5: 0.009026566149270   7: 0.009022652454289   8: 0.009022005574019   2: 0.009021838652035   4: 0.009021761788698   3: 0.009021600608635 

training_8716     0: 0.607041613957095   6: 0.224728486961665   9: 0.074885624195547   3: 0.013497932395190   7: 0.013331839337623   1: 0.013313286438726   5: 0.013304773041612   4: 0.013301614091662   8: 0.013298285003786   2: 0.013296544577094 

training_8717     1: 0.648792311337680   5: 0.159397040586869   8: 0.077388440473073   0: 0.016348153972161   9: 0.016347117623054   6: 0.016347113661150   4: 0.016346325979390   3: 0.016345505477506   7: 0.016344009160224   2: 0.016343981728893 

training_872      6: 0.797031718437563   0: 0.073741569612686   1: 0.016165652763443   8: 0.016152350279847   5: 0.016152093031754   9: 0.016151512489333   7: 0.016151447743967   4: 0.016151231933924   3: 0.016151228737393   2: 0.016151194970088 

training_8722     5: 0.787641725277685   1: 0.023597995344285   0: 0.023597775097861   6: 0.023596434288935   2: 0.023594524483500   4: 0.023594520768072   3: 0.023594345363033   9: 0.023594279238741   8: 0.023594215953134   7: 0.023594184184754 

training_8723     6: 0.749588900241612   0: 0.123464649393738   5: 0.045486203549461   9: 0.011640515104368   1: 0.011639104162597   8: 0.011637062495868   7: 0.011636050357616   2: 0.011635911443415   4: 0.011635846505003   3: 0.011635756746322 

training_8724     5: 0.538580344628364   0: 0.293591184834733   6: 0.020980295503004   1: 0.020979122547921   8: 0.020979023118654   2: 0.020978790707797   7: 0.020978352293894   3: 0.020978306234392   4: 0.020977803263666   9: 0.020976776867575 

training_8725     6: 0.789689762890526   0: 0.085132325295007   1: 0.031918164432949   9: 0.013564147990182   3: 0.013368662871658   5: 0.013321761628550   4: 0.013260906257455   8: 0.013252797762941   2: 0.013246094089353   7: 0.013245376781378 

training_8726     6: 0.813403690269549   5: 0.020734199087694   0: 0.020733394129654   9: 0.020733135851393   7: 0.020732978499194   1: 0.020732895229239   8: 0.020732834232719   2: 0.020732494507332   3: 0.020732265647978   4: 0.020732112545249 

training_8728     9: 0.741382766552526   6: 0.093753780614517   8: 0.020631706243812   1: 0.020609833319321   5: 0.020604590250851   0: 0.020604152073344   3: 0.020603722061314   4: 0.020603497377141   7: 0.020603168707583   2: 0.020602782799590 

training_873      6: 0.741855121975954   1: 0.081072747811726   2: 0.070081999553027   0: 0.025709468015362   9: 0.013551915548983   5: 0.013548418585922   7: 0.013546337950795   4: 0.013544762504192   3: 0.013544649457410   8: 0.013544578596629 

training_8730     6: 0.410332675896740   4: 0.271054056143384   2: 0.146898327900173   9: 0.064142869839376   1: 0.017948856769946   5: 0.017937863000417   0: 0.017925792082096   8: 0.017923814584554   7: 0.017918148497738   3: 0.017917595285577 

training_8731     5: 0.752698500328948   4: 0.027480017888396   0: 0.027478835315934   1: 0.027477903487966   8: 0.027477789071432   6: 0.027477549924940   3: 0.027477440941790   9: 0.027477333489111   2: 0.027477331862403   7: 0.027477297689080 

training_8732     5: 0.367738190571974   0: 0.216095385745396   1: 0.106184871694119   6: 0.102335821410247   9: 0.072214786440200   8: 0.061264658231979   4: 0.018542583400788   3: 0.018541325472724   7: 0.018541300107960   2: 0.018541076924613 

training_8733     5: 0.810665781023072   1: 0.021038253677131   6: 0.021037456720043   0: 0.021037411981023   2: 0.021037205257368   4: 0.021037115031885   3: 0.021036921373212   9: 0.021036713221225   7: 0.021036614278030   8: 0.021036527437010 

training_8734     8: 0.517506647873181   5: 0.234209282981773   0: 0.068626852239004   4: 0.059729852209137   6: 0.019999308290734   1: 0.019988574430519   7: 0.019985828009762   9: 0.019985160885111   2: 0.019984404824276   3: 0.019984088256502 

training_8735     6: 0.703561078140005   1: 0.172299917482809   8: 0.015537401504040   0: 0.015517226990086   7: 0.015515470596346   9: 0.015514420200843   5: 0.015514314109777   2: 0.015513798819257   4: 0.015513292042360   3: 0.015513080114477 

training_8736     5: 0.403127659834395   8: 0.398203151399802   2: 0.024834303061168   3: 0.024834220442397   4: 0.024833761799076   6: 0.024833570086490   1: 0.024833560319452   0: 0.024833413382499   9: 0.024833181941543   7: 0.024833177733179 

training_8738     5: 0.712800309535113   1: 0.118705005488366   6: 0.021069911145240   8: 0.021064821859557   7: 0.021060795365537   4: 0.021060772883487   0: 0.021060706007782   9: 0.021060448470529   2: 0.021058677558752   3: 0.021058551685636 

training_874      6: 0.459062016226907   0: 0.387808357836960   8: 0.048498723225755   1: 0.021794953380314   7: 0.013863104320607   3: 0.013795550711571   5: 0.013795482141376   9: 0.013795033521388   4: 0.013794876689640   2: 0.013791901945481 

training_8740     5: 0.634989570394727   0: 0.202668336940386   4: 0.020295549963942   6: 0.020292814583327   1: 0.020292528625177   8: 0.020292415689399   3: 0.020292274131019   9: 0.020292224963968   7: 0.020292162170597   2: 0.020292122537457 

training_8741     5: 0.813455753310851   6: 0.020729667056817   0: 0.020728349373350   4: 0.020727965737966   8: 0.020726861294070   9: 0.020726513918569   7: 0.020726512712133   1: 0.020726492782818   3: 0.020725994237108   2: 0.020725889576318 

training_8742     4: 0.784802939254856   5: 0.023917127730542   8: 0.023910144890719   0: 0.023910060122585   6: 0.023910033593178   9: 0.023910007111003   1: 0.023909983529799   3: 0.023909938574235   2: 0.023909898892918   7: 0.023909866300165 

training_8744     7: 0.389868450405306   6: 0.365070528776513   0: 0.107992991122077   3: 0.019612173958822   1: 0.019580563998396   5: 0.019577594249646   4: 0.019574578144524   9: 0.019574494160668   8: 0.019574437713856   2: 0.019574187470192 

training_8745     5: 0.795027783698251   3: 0.022782178710559   4: 0.022778653588096   8: 0.022773257062594   6: 0.022773155608797   7: 0.022773082873180   9: 0.022773080135322   0: 0.022773049899830   2: 0.022772902711718   1: 0.022772855711654 

training_8746     6: 0.604077883530726   0: 0.300512891550124   7: 0.022497795400072   1: 0.019628953945726   4: 0.015481389843740   9: 0.007565074386310   5: 0.007559755830760   8: 0.007559047185315   2: 0.007558671121655   3: 0.007558537205573 

training_8747     6: 0.696832307769054   0: 0.131605773905166   7: 0.071711881670260   9: 0.028173469870249   2: 0.018449065498336   5: 0.010645891522644   1: 0.010645733743726   8: 0.010645512262474   4: 0.010645386068392   3: 0.010644977689699 

training_8748     1: 0.476588710320364   0: 0.256903593079363   4: 0.112739411275638   9: 0.044983740473470   2: 0.018157303948317   5: 0.018146285586031   6: 0.018125929046659   8: 0.018121771845483   3: 0.018117641425971   7: 0.018115612998704 

training_8749     6: 0.742759243692413   8: 0.072077130855356   0: 0.065623403968771   3: 0.050605540095613   1: 0.011535172434007   7: 0.011482241243835   9: 0.011481435417790   5: 0.011479870061954   2: 0.011478010415985   4: 0.011477951814276 

training_875      6: 0.789988772414889   8: 0.074870506657485   0: 0.051276285772303   7: 0.021934469347300   1: 0.014129700571203   4: 0.009721653880221   9: 0.009572786799262   3: 0.009517550710742   5: 0.009497641842793   2: 0.009490632003801 

training_8750     5: 0.818982165073019   4: 0.020116297769972   1: 0.020113065812651   6: 0.020113022382418   0: 0.020112780159926   8: 0.020112638644747   9: 0.020112533414973   2: 0.020112527896343   3: 0.020112494227564   7: 0.020112474618387 

training_8755     6: 0.431402029779850   2: 0.327123199605913   9: 0.134557266932853   1: 0.022489025326825   3: 0.014084289622887   5: 0.014083349731245   0: 0.014066442856398   4: 0.014064875398009   8: 0.014064871517283   7: 0.014064649228736 

training_8756     1: 0.502864686310208   6: 0.310649532149635   4: 0.073943938351646   0: 0.033720080373436   3: 0.013160773807759   9: 0.013150649154172   2: 0.013143401184757   5: 0.013133147448271   8: 0.013117731907890   7: 0.013116059312225 

training_8757     6: 0.632124098576978   7: 0.164184728760557   5: 0.097116948521412   8: 0.015233933560823   9: 0.015224359624150   4: 0.015224089997546   3: 0.015223628705069   0: 0.015223434252044   1: 0.015222562269898   2: 0.015222215731522 

training_8758     1: 0.460781100470603   3: 0.178702169631571   5: 0.168710342013562   6: 0.027403921178242   0: 0.027402300146789   9: 0.027400560575715   2: 0.027400227757188   4: 0.027400069907647   8: 0.027399671978624   7: 0.027399636340059 

training_8759     6: 0.789663134425358   0: 0.060875031464887   3: 0.035800125348741   7: 0.016242473212224   5: 0.016237345181254   9: 0.016237263101604   1: 0.016236656096923   8: 0.016236535460604   4: 0.016236111290969   2: 0.016235324417436 

training_8760     9: 0.791352145015527   8: 0.023187128111327   6: 0.023185321661551   5: 0.023183702135088   0: 0.023182474079220   1: 0.023182385344978   4: 0.023182134511183   7: 0.023181752648530   3: 0.023181515366071   2: 0.023181441126526 

training_8761     0: 0.330166450515174   9: 0.274323312019152   5: 0.194945819050684   3: 0.082424529286841   1: 0.031945803773652   6: 0.017242079875587   8: 0.017241770397651   4: 0.017237146221256   7: 0.017236640089777   2: 0.017236448770226 

training_8765     6: 0.781805930194836   1: 0.100060753375390   5: 0.025353931109227   9: 0.013297522551807   0: 0.013249947965441   4: 0.013246580741062   8: 0.013246578706436   2: 0.013246461439239   7: 0.013246186200900   3: 0.013246107715660 

training_8767     5: 0.609383862359581   3: 0.209059212563827   4: 0.022697934337782   6: 0.022696407082015   7: 0.022694983208321   0: 0.022694075957061   9: 0.022694036918116   8: 0.022693480677412   1: 0.022693224803791   2: 0.022692782092093 

training_8768     4: 0.466552190913576   5: 0.328957766950432   1: 0.025563695628626   6: 0.025562005731457   0: 0.025561452255158   3: 0.025560844122081   2: 0.025560689164956   9: 0.025560531345944   8: 0.025560426448628   7: 0.025560397439143 

training_8771     1: 0.602702058151665   3: 0.145374711746334   5: 0.072570877081731   6: 0.048121071459759   0: 0.044383071770568   2: 0.017373881180943   8: 0.017369856799530   4: 0.017368374393090   9: 0.017368324597167   7: 0.017367772819213 

training_8777     6: 0.488374209661761   5: 0.329937873454822   1: 0.054934143950777   9: 0.018116119290388   0: 0.018113035253307   2: 0.018111427001297   4: 0.018107348014874   8: 0.018104445263225   3: 0.018101120008452   7: 0.018100278101098 

training_8778     7: 0.439831266875931   6: 0.248487628386669   1: 0.118191576592337   4: 0.081116590740542   5: 0.018734983465087   0: 0.018732355674284   2: 0.018726667906268   9: 0.018726661907368   8: 0.018726371843619   3: 0.018725896607895 

training_8780     5: 0.509925486459267   2: 0.144047637500375   3: 0.084145454364735   6: 0.070817766171401   8: 0.064543829333645   4: 0.053330135357136   7: 0.032941877308405   1: 0.013420991569449   0: 0.013414225885378   9: 0.013412596050209 

training_8781     1: 0.700468068810508   8: 0.091535749268203   9: 0.049560207504144   5: 0.022635712873804   6: 0.022634517527252   0: 0.022634313315538   4: 0.022633368152752   7: 0.022632786425488   2: 0.022632784308040   3: 0.022632491814270 

training_8784     5: 0.589636309130881   4: 0.142005852122840   0: 0.074910971851285   1: 0.072131665481063   6: 0.020221450898568   7: 0.020218955156885   8: 0.020218935553633   3: 0.020218707636535   2: 0.020218631855905   9: 0.020218520312405 

training_8785     5: 0.635112865113323   1: 0.164187287761533   6: 0.025088341162231   3: 0.025087870777340   0: 0.025087607299857   4: 0.025087571116949   8: 0.025087215385812   2: 0.025087106166538   7: 0.025087086678933   9: 0.025087048537484 

training_8788     5: 0.779155616235770   6: 0.024538844173952   3: 0.024538660788708   4: 0.024538605960312   2: 0.024538452425641   0: 0.024538140079983   1: 0.024538080960149   7: 0.024537913169620   9: 0.024537899057003   8: 0.024537787148863 

training_879      3: 0.439031263128000   4: 0.259480644042675   5: 0.037707453694060   8: 0.037685047016391   9: 0.037683349233329   0: 0.037682657781942   6: 0.037682641923466   2: 0.037682615532029   1: 0.037682229984824   7: 0.037682097663284 

training_8791     5: 0.650524014296054   0: 0.125796029748014   2: 0.069656097481587   8: 0.040345396454467   3: 0.018982649154118   9: 0.018942795978377   6: 0.018939939099918   1: 0.018938847656633   4: 0.018938081124125   7: 0.018936149006708 

training_8793     5: 0.531590327170743   0: 0.272970256478955   4: 0.024435804100082   8: 0.024432547326324   6: 0.024429971064494   9: 0.024428955687676   7: 0.024428435513515   2: 0.024427939235800   3: 0.024427891180896   1: 0.024427872241515 

training_8794     4: 0.763725538086695   5: 0.026258825677094   8: 0.026252212637430   0: 0.026252025552192   9: 0.026251995617475   6: 0.026251944905018   2: 0.026251893286664   3: 0.026251881684271   7: 0.026251845881078   1: 0.026251836672083 

training_8795     1: 0.437538521746645   7: 0.229390897536308   2: 0.176414914682996   5: 0.044672278427443   9: 0.018679708478419   6: 0.018663157065282   0: 0.018662080400028   4: 0.018660164133586   3: 0.018659591355012   8: 0.018658686174281 

training_8796     6: 0.815780557364022   0: 0.055881749040025   5: 0.035822311822975   3: 0.022187668453614   4: 0.011792161632322   1: 0.011741401674217   7: 0.011722258078812   9: 0.011718140138355   2: 0.011677562504903   8: 0.011676189290756 

training_8797     5: 0.736669357932210   8: 0.064370856323135   0: 0.054259705209637   6: 0.020689743608914   1: 0.020678401813004   7: 0.020675534729301   9: 0.020664564796225   4: 0.020663989218209   3: 0.020663927765701   2: 0.020663918603665 

training_8799     6: 0.437776641244438   5: 0.331283482945143   0: 0.135586112583566   1: 0.013625585695818   8: 0.013622228787606   4: 0.013622063677612   9: 0.013621840875813   3: 0.013620804122918   7: 0.013620654218950   2: 0.013620585848136 

training_880      6: 0.822341993901585   7: 0.031563726331850   0: 0.018435007772203   5: 0.018260823076965   8: 0.018234698526873   9: 0.018234491545737   4: 0.018233836367333   1: 0.018231919853698   3: 0.018231909012679   2: 0.018231593611077 

training_8800     6: 0.801025520797404   0: 0.090982394762275   5: 0.013501552146022   1: 0.013499939827449   9: 0.013499126134473   8: 0.013498921170012   4: 0.013498393579780   2: 0.013498141291082   7: 0.013498068205716   3: 0.013497942085788 

training_8802     8: 0.587878270071363   6: 0.280352230139032   0: 0.016472357919687   5: 0.016472180825034   1: 0.016471830237494   9: 0.016471120262221   4: 0.016470945496031   7: 0.016470657865398   2: 0.016470272040510   3: 0.016470135143230 

training_8806     6: 0.617147509225195   0: 0.246372140634291   4: 0.017083141236113   5: 0.017070944769226   1: 0.017055953432813   8: 0.017055229785962   9: 0.017054095821946   7: 0.017053964369361   2: 0.017053568496042   3: 0.017053452229051 

training_8808     5: 0.442242758674583   0: 0.358538753013704   8: 0.024905681391552   6: 0.024903185293457   3: 0.024902329775543   9: 0.024902012423092   4: 0.024901914726437   7: 0.024901308092816   2: 0.024901042718110   1: 0.024901013890705 

training_8810     4: 0.802924058007050   5: 0.021907683338706   6: 0.021896702054375   8: 0.021896355105978   3: 0.021896179005550   7: 0.021896022653906   0: 0.021895867056696   9: 0.021895791939635   2: 0.021895706974123   1: 0.021895633863982 

training_8812     6: 0.386807455165089   1: 0.257869138875200   9: 0.162157762838907   2: 0.027602085488567   7: 0.027595496351206   5: 0.027595312864023   8: 0.027593776537520   4: 0.027593371830570   0: 0.027593344358194   3: 0.027592255690724 

training_8814     4: 0.595125467619639   3: 0.189981680911381   5: 0.026867808321379   8: 0.026861474502973   9: 0.026860824346829   1: 0.026860646444570   2: 0.026860624977474   0: 0.026860586850963   7: 0.026860543294699   6: 0.026860342730091 

training_8815     6: 0.459369769824048   9: 0.231789951690488   1: 0.153593024194694   0: 0.079383192632037   7: 0.017039368936153   2: 0.016961742841716   5: 0.010537661313004   4: 0.010443101492834   8: 0.010441354369991   3: 0.010440832705035 

training_882      1: 0.375070032298946   6: 0.217662704749663   3: 0.166996879641872   2: 0.134155027133918   5: 0.031209127097626   0: 0.014983729587105   9: 0.014982213570374   4: 0.014980531608992   8: 0.014980367982111   7: 0.014979386329395 

training_8820     6: 0.569471447692517   9: 0.251198085991738   1: 0.113482959463041   8: 0.012615971403689   0: 0.008880552111549   5: 0.008871411808907   7: 0.008870747714843   4: 0.008870058432396   2: 0.008869965848352   3: 0.008868799532966 

training_8822     5: 0.703303308743532   1: 0.032979533795963   6: 0.032976751169454   0: 0.032974253582011   4: 0.032962872013505   7: 0.032962650079952   9: 0.032961716803693   2: 0.032960269446315   8: 0.032959609575522   3: 0.032959034790052 

training_8823     7: 0.359783837219452   6: 0.342161638287895   4: 0.162358090800523   0: 0.029946258096584   5: 0.017679767649912   1: 0.017625544159102   2: 0.017611792810305   3: 0.017611386169209   9: 0.017611047048923   8: 0.017610637758095 

training_8826     5: 0.734825162985731   2: 0.100866920502194   4: 0.020540616635710   6: 0.020538907887763   0: 0.020538837763429   1: 0.020538291728023   8: 0.020537912094260   3: 0.020537823542473   9: 0.020537786437456   7: 0.020537740422960 

training_8829     6: 0.678509069050501   3: 0.166772331377168   1: 0.019343447935125   5: 0.019341335309429   9: 0.019340544745299   8: 0.019340234519269   0: 0.019339893649455   4: 0.019338090282871   7: 0.019337761794374   2: 0.019337291336509 

training_883      5: 0.826235262258093   3: 0.019339583645022   4: 0.019304376399960   6: 0.019304308070575   0: 0.019303432157755   1: 0.019303082692308   7: 0.019302606024429   9: 0.019302527513168   8: 0.019302501299492   2: 0.019302319939199 

training_8830     9: 0.497344030505898   1: 0.262892046505708   5: 0.075350429145320   6: 0.023491426063897   3: 0.023489508299732   0: 0.023488446936828   4: 0.023487526177324   7: 0.023486626815443   8: 0.023485237287359   2: 0.023484722262490 

training_8835     6: 0.553429424990287   0: 0.236607575665120   9: 0.097602946012647   3: 0.030514417232499   5: 0.013642411626136   1: 0.013641489349455   8: 0.013641369152342   4: 0.013640839285283   2: 0.013639988940221   7: 0.013639537746009 

training_8836     5: 0.610970183529827   1: 0.074489372004299   2: 0.072478416598125   3: 0.051122687308999   9: 0.050403259734136   6: 0.048759941067372   0: 0.022973285828713   7: 0.022934595031705   4: 0.022934536951020   8: 0.022933721945804 

training_8837     0: 0.385129399763147   5: 0.296865311404629   8: 0.133784108954088   1: 0.026318788245739   6: 0.026318387433339   2: 0.026318221772639   9: 0.026317079796540   7: 0.026316251080434   3: 0.026316231965247   4: 0.026316219584198 

training_884      7: 0.422305168663706   6: 0.408404494410528   5: 0.021163277297289   2: 0.021161764080627   0: 0.021161470988848   1: 0.021161387576668   8: 0.021160794325402   9: 0.021160648914534   3: 0.021160527232104   4: 0.021160466510296 

training_8845     6: 0.567633728857368   0: 0.307750595884511   7: 0.025994492534195   1: 0.014092651673819   8: 0.014089770283444   9: 0.014089465917658   3: 0.014088079196915   5: 0.014087407646263   2: 0.014086979421503   4: 0.014086828584325 

training_8846     5: 0.532249634410136   0: 0.295545587067540   8: 0.046934018922882   1: 0.017897711207980   2: 0.017897276587030   6: 0.017896745326862   9: 0.017895388262332   7: 0.017894913608715   4: 0.017894381667471   3: 0.017894342939051 

training_8849     0: 0.582905896081487   1: 0.281785946629388   5: 0.016916076376595   6: 0.016915797274793   4: 0.016913098771859   9: 0.016912929643533   2: 0.016912784609797   8: 0.016912741119256   7: 0.016912466431159   3: 0.016912263062133 

training_885      6: 0.568582641012345   7: 0.201322379858650   5: 0.075527517826769   2: 0.022082574661777   1: 0.022081117003731   9: 0.022081027694522   0: 0.022081012566139   8: 0.022080752429643   3: 0.022080557785458   4: 0.022080419160965 

training_8850     6: 0.700833026390320   8: 0.119306378806658   1: 0.022484745289474   5: 0.022484064233592   0: 0.022483160146623   7: 0.022482444058416   9: 0.022482041013783   4: 0.022481532028949   2: 0.022481475314437   3: 0.022481132717748 

training_8853     5: 0.589925343280747   4: 0.126261300936584   2: 0.112183050393091   8: 0.047246296146048   7: 0.032027610249929   1: 0.026622411341063   6: 0.016691826151675   0: 0.016350779566513   9: 0.016345867540970   3: 0.016345514393381 

training_8854     6: 0.601583565399318   1: 0.128976478890718   4: 0.110794941237936   2: 0.050229758940644   9: 0.025882512354062   8: 0.024924409644634   7: 0.019838939575933   5: 0.012591795549305   0: 0.012590668329552   3: 0.012586930077899 

training_8855     0: 0.499229002363352   6: 0.253830492176095   8: 0.119943891651723   1: 0.027919955019931   5: 0.016540538035004   9: 0.016510509085176   2: 0.016508442391923   7: 0.016506461218584   4: 0.016505820874916   3: 0.016504887183295 

training_8856     6: 0.623946690486474   3: 0.213993945517414   0: 0.068952742748646   8: 0.013584257857109   2: 0.013258474174608   1: 0.013257512659395   9: 0.013254047969737   7: 0.013251150404109   5: 0.013250713051061   4: 0.013250465131447 

training_8857     6: 0.708433567218063   8: 0.111595455141024   2: 0.040618192700909   3: 0.036790153024351   0: 0.017115198037574   5: 0.017092623102756   7: 0.017090101376164   9: 0.017088823275263   1: 0.017088667389059   4: 0.017087218734838 

training_8858     4: 0.745677332149278   5: 0.028267051443606   8: 0.028257491027421   0: 0.028257264709109   9: 0.028257007778929   6: 0.028256826532982   7: 0.028256798985375   1: 0.028256776413256   3: 0.028256760490534   2: 0.028256690469509 

training_8859     4: 0.452094991360037   2: 0.222129736692872   1: 0.132871420902520   5: 0.027565069166679   8: 0.027558138902952   6: 0.027556613224754   9: 0.027556311193209   3: 0.027555955492408   0: 0.027555932800363   7: 0.027555830264206 

training_886      8: 0.416813222549393   4: 0.302756278361275   5: 0.035068357428540   9: 0.035052136181930   3: 0.035051930918206   0: 0.035051791153987   2: 0.035051691510667   6: 0.035051665337361   1: 0.035051465113483   7: 0.035051461445157 

training_8860     5: 0.691787605322864   3: 0.153157398058127   4: 0.019386629126096   0: 0.019381633544058   6: 0.019381496503168   8: 0.019381154469319   9: 0.019381082336134   1: 0.019381017515632   7: 0.019380996105277   2: 0.019380987019324 

training_8861     6: 0.578590723477373   4: 0.198654412887676   9: 0.085571750871192   0: 0.053780995442612   1: 0.013906719505337   5: 0.013905295863651   3: 0.013897908645061   8: 0.013897762886869   2: 0.013897306182462   7: 0.013897124237768 

training_8863     6: 0.462780421491332   5: 0.421993530675589   1: 0.027586411085414   8: 0.012524477538954   0: 0.012520781938600   3: 0.012520026691532   4: 0.012519086127358   9: 0.012518988155955   2: 0.012518228270717   7: 0.012518048024549 

training_8865     5: 0.378560819443983   3: 0.220974471192312   4: 0.151251459259724   8: 0.117524449251726   6: 0.021948828432297   0: 0.021948253389587   1: 0.021948112680538   9: 0.021947923264076   7: 0.021947860225257   2: 0.021947822860500 

training_8866     6: 0.526339542697236   3: 0.204970575872965   5: 0.108338177947032   0: 0.044385312262812   8: 0.043437063581607   9: 0.014568000592239   1: 0.014511310331858   7: 0.014485164079547   4: 0.014484355171797   2: 0.014480497462907 

training_8868     4: 0.755219867725452   5: 0.027205325386912   8: 0.027197197029532   9: 0.027196915655147   3: 0.027196893537988   6: 0.027196865671906   2: 0.027196820892317   7: 0.027196732876056   0: 0.027196732287380   1: 0.027196648937310 

training_887      5: 0.791953093692014   3: 0.077968222030647   0: 0.016271458994156   8: 0.016265215606450   6: 0.016260481331364   1: 0.016257361581270   4: 0.016257196564259   9: 0.016256133378807   7: 0.016255436022356   2: 0.016255400798678 

training_8873     0: 0.355652898031173   9: 0.312661739795840   6: 0.225594555481445   2: 0.015247930479779   8: 0.015150321436802   5: 0.015147799343579   3: 0.015137490422194   1: 0.015137358688625   7: 0.015135072472666   4: 0.015134833847897 

training_8877     6: 0.556982471991507   9: 0.191729335641848   4: 0.084776106923686   8: 0.057207125288967   2: 0.037280605497017   1: 0.014406113649346   0: 0.014405709922103   5: 0.014404635032673   7: 0.014404025190840   3: 0.014403870862013 

training_8879     5: 0.744241523003050   8: 0.066432939957456   2: 0.062303673015166   4: 0.018148026068584   6: 0.018147564739042   0: 0.018145938929774   1: 0.018145577017556   3: 0.018144981173054   9: 0.018144948765446   7: 0.018144827330873 

training_8880     6: 0.678369164263722   7: 0.073116917016262   1: 0.068833566634762   5: 0.045190815116607   0: 0.022470620840463   3: 0.022407237936623   4: 0.022404028046661   2: 0.022402958385617   8: 0.022402811894361   9: 0.022401879864923 

training_8882     6: 0.675030403180888   0: 0.152566645492904   2: 0.088262099614720   1: 0.012021010941353   5: 0.012020750644695   9: 0.012020590566879   3: 0.012020550901413   7: 0.012019806481217   8: 0.012019171825056   4: 0.012018970350876 

training_8884     6: 0.759583108151106   0: 0.124133771710577   1: 0.047315408969827   7: 0.009855362845497   8: 0.009853402454172   2: 0.009852185383146   9: 0.009851848738235   5: 0.009851838489309   3: 0.009851781671832   4: 0.009851291586299 

training_889      6: 0.786983308123663   7: 0.071528868654818   1: 0.068247666689567   4: 0.016933611667421   0: 0.009386351293195   5: 0.009385158733014   9: 0.009384330127962   8: 0.009384009283735   3: 0.009383399898648   2: 0.009383295527977 

training_8890     5: 0.835283195800696   6: 0.018304711645255   0: 0.018302547769672   1: 0.018302222177560   4: 0.018301874640504   8: 0.018301692012173   2: 0.018301134074071   7: 0.018301100168911   9: 0.018300850815542   3: 0.018300670895617 

training_8892     4: 0.823064049354748   5: 0.019665428448202   6: 0.019659156937749   8: 0.019659025404446   0: 0.019659008988917   1: 0.019658754869671   9: 0.019658750091704   3: 0.019658690096129   2: 0.019658580337485   7: 0.019658555470949 

training_8893     4: 0.657878061475585   7: 0.090836670549546   8: 0.086766365752810   5: 0.023513596229749   6: 0.023501572988099   0: 0.023501182470506   9: 0.023501006744616   1: 0.023500940123347   3: 0.023500370977580   2: 0.023500232688163 

training_8895     6: 0.776539503172600   1: 0.062019266441312   5: 0.038782118933656   0: 0.037170139483456   8: 0.014248244039835   2: 0.014248214846777   3: 0.014248206446223   4: 0.014248140696664   7: 0.014248096336160   9: 0.014248069603316 

training_8898     5: 0.649968273248688   2: 0.153323051535667   6: 0.024589808042372   3: 0.024589010238930   0: 0.024588723222485   4: 0.024588586818467   1: 0.024588434102583   7: 0.024588075419495   8: 0.024588039571013   9: 0.024587997800301 

training_8899     4: 0.614997841838368   6: 0.214885818405646   5: 0.021270470244100   9: 0.021265428886629   0: 0.021264705559674   1: 0.021263624456023   8: 0.021263375361439   3: 0.021262991041950   7: 0.021262901814943   2: 0.021262842391229 

training_89       5: 0.776417917477962   6: 0.024844859222621   7: 0.024843198494759   3: 0.024842938893372   4: 0.024842043918245   8: 0.024841952641966   0: 0.024841945773124   9: 0.024841733570699   1: 0.024841717123287   2: 0.024841692883964 

training_890      6: 0.822994722800003   5: 0.019668966492389   7: 0.019667683812951   9: 0.019667465448825   4: 0.019667436568234   0: 0.019667088846055   8: 0.019667033586572   2: 0.019666705369095   1: 0.019666542126838   3: 0.019666354949038 

training_8902     6: 0.757732660914892   7: 0.118999375045490   0: 0.033872788826683   5: 0.019292246568282   1: 0.016888222798401   4: 0.011058091673471   9: 0.010542958169045   8: 0.010538906080347   3: 0.010537730230116   2: 0.010537019693274 

training_8903     6: 0.665529670894710   8: 0.188155432728274   7: 0.036188573982169   0: 0.015738803952967   5: 0.015735000197362   4: 0.015734278484234   3: 0.015730527338981   9: 0.015730304529928   1: 0.015729211267649   2: 0.015728196623726 

training_8905     6: 0.451639159928389   5: 0.314831044194469   1: 0.122572135305607   9: 0.015858112775106   4: 0.015851590187583   0: 0.015850464808982   2: 0.015850128028725   3: 0.015849331007721   7: 0.015849226419074   8: 0.015848807344344 

training_8906     6: 0.339670700907386   1: 0.291155381516241   5: 0.260872653901501   0: 0.015474315796388   2: 0.015471902874406   9: 0.015471281054917   4: 0.015471220639610   7: 0.015471149053025   8: 0.015470712524426   3: 0.015470681732100 

training_8908     5: 0.769203163418344   3: 0.025644786595393   4: 0.025644535370330   0: 0.025644025076089   6: 0.025644016979861   8: 0.025644005555386   1: 0.025643971067035   2: 0.025643885127294   7: 0.025643827981057   9: 0.025643782829211 

training_8909     4: 0.307635171409010   1: 0.307605420587563   0: 0.197278976896081   9: 0.064100543176869   2: 0.037829778106127   5: 0.017113061272490   6: 0.017111549390429   3: 0.017109637456967   7: 0.017108134135983   8: 0.017107727568480 

training_8911     0: 0.750076045050019   8: 0.027807047122472   6: 0.027772225751554   1: 0.027765538853897   7: 0.027764756369399   5: 0.027764525240635   9: 0.027762830424162   4: 0.027762418782885   3: 0.027762384183319   2: 0.027762228221659 

training_8912     5: 0.790215415726258   4: 0.023310284116080   3: 0.023309723521484   6: 0.023309699592827   1: 0.023309516691362   0: 0.023309429267027   2: 0.023309033963852   7: 0.023308981181055   8: 0.023308965454746   9: 0.023308950485308 

training_8914     6: 0.355694612171789   2: 0.300596812632828   5: 0.215263324375967   4: 0.043499106413399   9: 0.014161449821183   0: 0.014159378153865   7: 0.014158524294236   1: 0.014157912109938   8: 0.014154630909263   3: 0.014154249117533 

training_8915     5: 0.784299462720533   4: 0.023974500070824   7: 0.023966017227379   8: 0.023965947630476   6: 0.023965839885323   0: 0.023965747353702   3: 0.023965684660203   9: 0.023965635967182   2: 0.023965634143327   1: 0.023965530341051 

training_8916     1: 0.427642106047854   0: 0.300656421661171   6: 0.071506006132054   8: 0.046367808431475   4: 0.045287728335941   9: 0.042052208690016   3: 0.016623539896955   5: 0.016621987184679   7: 0.016621098872131   2: 0.016621094747723 

training_8918     1: 0.346233524986376   7: 0.276111808693791   4: 0.129809750612659   5: 0.088851459942107   0: 0.026505516184756   6: 0.026502769079441   3: 0.026496528231326   9: 0.026496433350102   8: 0.026496111679968   2: 0.026496097239473 

training_8919     5: 0.386056646487143   3: 0.288165384172855   2: 0.137566521629191   8: 0.067531747028960   1: 0.020115355347774   6: 0.020115134683982   0: 0.020115072200485   4: 0.020112543008077   7: 0.020110935613419   9: 0.020110659828115 

training_8922     6: 0.545529455380051   0: 0.329812893725165   9: 0.015585277627467   1: 0.015584957168022   8: 0.015584292446883   5: 0.015581475670750   2: 0.015580706233805   7: 0.015580437949531   3: 0.015580281373229   4: 0.015580222425098 

training_8925     5: 0.602426842120651   9: 0.198620149851868   4: 0.024872899600043   6: 0.024868897497796   7: 0.024868687864837   3: 0.024868589824323   8: 0.024868584801652   2: 0.024868506465330   0: 0.024868444690546   1: 0.024868397282953 

training_8928     5: 0.775950656124373   4: 0.024895668686829   6: 0.024895086338126   3: 0.024894423421339   9: 0.024894242812324   1: 0.024894189591342   0: 0.024894062413212   2: 0.024893993455679   8: 0.024893854569430   7: 0.024893822587347 

training_8930     5: 0.647533515146550   0: 0.161013949587307   2: 0.023931891879629   1: 0.023931830661275   3: 0.023931803680351   4: 0.023931744902457   6: 0.023931686354614   7: 0.023931241834879   9: 0.023931204984710   8: 0.023931130968227 

training_8932     0: 0.400790968906411   7: 0.313368789919240   1: 0.175052460857462   6: 0.026994218589836   4: 0.013999357542742   5: 0.013962049861012   2: 0.013960484684316   8: 0.013957447912621   9: 0.013957139505482   3: 0.013957082220879 

training_8933     6: 0.464368153448919   1: 0.373449123366282   5: 0.068364741403534   0: 0.013415652713910   7: 0.013401001032627   3: 0.013400613933014   9: 0.013400287788145   4: 0.013400247280998   8: 0.013400172488352   2: 0.013400006544219 

training_8935     4: 0.715203361002567   1: 0.087698119450206   5: 0.058456295337508   7: 0.019808756205942   6: 0.019806940184688   0: 0.019806042641945   8: 0.019805464485297   9: 0.019805039057944   2: 0.019804999484181   3: 0.019804982149723 

training_894      6: 0.550187074739289   1: 0.193810053203769   0: 0.140662849615755   9: 0.040376851617699   7: 0.020338954627287   5: 0.010925541324073   8: 0.010924975578065   4: 0.010924835953535   3: 0.010924510405434   2: 0.010924352935095 

training_8940     6: 0.357668845027020   8: 0.317340362153462   3: 0.111275155369302   1: 0.099998367075659   0: 0.037782183661020   5: 0.019832704001809   4: 0.014122431440768   9: 0.013996353473519   7: 0.013991950315022   2: 0.013991647482419 

training_8941     6: 0.702838780981304   0: 0.077030125490190   8: 0.072048150640301   5: 0.052500997157643   3: 0.021886548124498   2: 0.014863203853383   9: 0.014739650655848   4: 0.014706532267997   1: 0.014693743401243   7: 0.014692267427592 

training_8943     6: 0.486902639678302   8: 0.294098943528023   0: 0.122449267792768   5: 0.025423425265735   1: 0.017667634160752   3: 0.010933038888740   2: 0.010704386291002   7: 0.010608482693865   4: 0.010606580017804   9: 0.010605601683012 

training_8944     6: 0.561760577023390   0: 0.315313496746126   4: 0.035687236383722   1: 0.012466219977544   5: 0.012463161451536   7: 0.012462347701283   8: 0.012462063793050   3: 0.012461781612172   2: 0.012461605612756   9: 0.012461509698421 

training_8945     0: 0.746566740418987   6: 0.110106723881663   4: 0.035141778443362   9: 0.028623981534595   1: 0.013269880861121   2: 0.013260953844535   5: 0.013258834477748   7: 0.013257095091365   8: 0.013257010263820   3: 0.013257001182804 

training_8946     5: 0.706035034964642   2: 0.122483736155184   4: 0.021437087647018   3: 0.021435045803205   6: 0.021434989809248   0: 0.021434932056441   1: 0.021434896165972   8: 0.021434813610702   9: 0.021434794536835   7: 0.021434669250752 

training_8947     6: 0.488473848812510   1: 0.354444796409184   5: 0.019638363961227   0: 0.019638157511419   4: 0.019634428316578   9: 0.019634392071832   8: 0.019634313179600   3: 0.019633938526918   7: 0.019633908565716   2: 0.019633852645017 

training_8948     6: 0.447190801724156   2: 0.376328360900693   8: 0.052844221657119   0: 0.017687948796239   7: 0.017681522977513   1: 0.017656507516380   4: 0.017653534477736   5: 0.017652977623471   9: 0.017652546575275   3: 0.017651577751419 

training_895      7: 0.420519452896641   6: 0.374789514215147   9: 0.025591045346780   5: 0.025588015797002   0: 0.025586226611717   1: 0.025585978278619   8: 0.025585719119600   4: 0.025584957848838   3: 0.025584552809779   2: 0.025584537075878 

training_8950     6: 0.837426801029902   8: 0.042321367403053   1: 0.027712379835882   5: 0.013221070891649   0: 0.013221034354267   4: 0.013219541482378   3: 0.013219521926825   9: 0.013219490252157   2: 0.013219429695646   7: 0.013219363128242 

training_8951     6: 0.373974395786370   8: 0.348362526882270   5: 0.152387604932215   0: 0.017903286659429   9: 0.017903085868256   1: 0.017898877610637   7: 0.017893306522837   3: 0.017892915934553   4: 0.017892317146064   2: 0.017891682657369 

training_8956     5: 0.625164737700132   1: 0.134159876876055   4: 0.075425394794203   6: 0.058940855451343   0: 0.017719083005632   9: 0.017718131089471   8: 0.017718105710513   2: 0.017717997506703   7: 0.017717932305245   3: 0.017717885560703 

training_8959     6: 0.697917234239405   5: 0.167925768890809   1: 0.035571295402306   9: 0.014094620621323   2: 0.014084304375902   4: 0.014082802499812   7: 0.014082653428134   0: 0.014080893968990   8: 0.014080454770953   3: 0.014079971802366 

training_896      6: 0.703490654886436   7: 0.182109876220999   8: 0.026208314803971   9: 0.012611307936112   1: 0.012601256996232   5: 0.012600985208061   0: 0.012597493640082   2: 0.012593556112526   4: 0.012593354764347   3: 0.012593199431235 

training_8961     6: 0.815134866857865   8: 0.054398820936972   0: 0.039056898612885   3: 0.016453497932312   9: 0.016362152069298   7: 0.011731436171431   1: 0.011719640835860   5: 0.011714957613514   4: 0.011714382227294   2: 0.011713346742569 

training_8962     1: 0.513854619072499   6: 0.329803658103440   3: 0.062911435532150   5: 0.013355602705725   0: 0.013347842464246   4: 0.013347737900957   8: 0.013345472537672   9: 0.013344712626439   2: 0.013344527860229   7: 0.013344391196643 

training_8964     6: 0.573976991608678   7: 0.261497058393569   0: 0.059645584685768   2: 0.021311893571418   1: 0.013993357392636   9: 0.013936402577458   5: 0.013924075011815   8: 0.013905996920854   4: 0.013905749479941   3: 0.013902890357864 

training_8965     5: 0.752061592437179   0: 0.091509634711300   1: 0.019558970200549   4: 0.019556566107010   6: 0.019552699170969   2: 0.019552317891598   8: 0.019552220853795   9: 0.019552005161272   7: 0.019551999102298   3: 0.019551994364031 

training_8968     5: 0.598545936876726   8: 0.204546616956797   3: 0.024614455152885   6: 0.024613896255953   9: 0.024613572331010   4: 0.024613430732274   0: 0.024613275751234   1: 0.024613084905262   7: 0.024612956111685   2: 0.024612774926174 

training_8969     4: 0.709164726956188   5: 0.097307417664483   9: 0.024197489677416   6: 0.024195413064450   8: 0.024194451294091   0: 0.024190071953619   1: 0.024189832206778   7: 0.024187404865895   2: 0.024186652327359   3: 0.024186539989720 

training_897      6: 0.650655298365149   3: 0.115682507588161   7: 0.085794118432784   9: 0.021133371864586   1: 0.021129657749342   0: 0.021124364395844   5: 0.021123256700655   8: 0.021122274361170   2: 0.021117793653867   4: 0.021117356888441 

training_8970     5: 0.686985242875684   0: 0.127442776779794   4: 0.023200721544072   6: 0.023197326520046   8: 0.023196072122156   9: 0.023195717489760   7: 0.023195605957693   1: 0.023195554389620   3: 0.023195520999237   2: 0.023195461321939 

training_8971     6: 0.476690144319086   0: 0.270807088361020   1: 0.162949265984998   4: 0.021316790316747   5: 0.011376968983916   9: 0.011373717599798   2: 0.011372690772200   7: 0.011371784105600   3: 0.011370903451991   8: 0.011370646104644 

training_8972     4: 0.535335752372783   5: 0.245421690067726   6: 0.027408969481897   8: 0.027405957484201   9: 0.027405883686373   0: 0.027405245846492   2: 0.027404341118170   7: 0.027404221379793   1: 0.027404122169950   3: 0.027403816392614 

training_8974     6: 0.412452336921975   1: 0.305427128191305   7: 0.180760754499503   5: 0.018749777962748   2: 0.014302659148802   9: 0.013810615140759   8: 0.013628717742124   4: 0.013625056755456   0: 0.013623614920701   3: 0.013619338716627 

training_8975     1: 0.801696657520328   6: 0.022038700058838   0: 0.022034702122590   5: 0.022034325027046   4: 0.022032942406962   9: 0.022032928884713   7: 0.022032802641042   3: 0.022032424017738   8: 0.022032404228066   2: 0.022032113092677 

training_8976     5: 0.766542716514611   9: 0.078356396816424   7: 0.048018124756318   6: 0.015302686553552   1: 0.015298162877576   4: 0.015297564997796   8: 0.015296784716376   3: 0.015296222698064   0: 0.015295937674229   2: 0.015295402395054 

training_8977     5: 0.505510016520880   1: 0.238658935290834   3: 0.119587171461975   6: 0.019468227627252   0: 0.019467243810088   9: 0.019462529443302   2: 0.019462011448647   4: 0.019461770772785   8: 0.019461149893196   7: 0.019460943731042 

training_8978     6: 0.566699484670781   8: 0.157311965184201   0: 0.128629491630905   1: 0.021052740195083   9: 0.021051322143181   5: 0.021051260602038   7: 0.021050998821731   4: 0.021050976909650   2: 0.021050919164251   3: 0.021050840678178 

training_8979     5: 0.816927859338035   4: 0.044704632281482   0: 0.017296396889184   6: 0.017296373738593   1: 0.017296015477478   8: 0.017295927473051   9: 0.017295912527636   7: 0.017295821945428   2: 0.017295558625493   3: 0.017295501703620 

training_8981     5: 0.673262704783744   8: 0.126522718276493   0: 0.062528183509071   1: 0.019694849729416   4: 0.019668388739320   2: 0.019667044141935   6: 0.019664455048739   9: 0.019664288283563   7: 0.019663694844038   3: 0.019663672643681 

training_8982     6: 0.733324466555022   0: 0.143408094564367   1: 0.034184291400267   8: 0.023542214483660   4: 0.010931194539798   9: 0.010928553116266   2: 0.010928362166592   5: 0.010918474946849   7: 0.010917764568811   3: 0.010916583658369 

training_8983     6: 0.585109653467072   7: 0.194530449516445   8: 0.027545705646939   0: 0.027545262820895   5: 0.027545040633877   1: 0.027545018728336   9: 0.027544871907999   4: 0.027544707148834   2: 0.027544647660935   3: 0.027544642468668 

training_8984     0: 0.723106786187777   6: 0.030774111720407   1: 0.030773464521982   7: 0.030764266551494   9: 0.030764181578362   8: 0.030763586974235   5: 0.030763582369420   2: 0.030763439332751   3: 0.030763372979168   4: 0.030763207784403 

training_8985     4: 0.478450427603768   6: 0.278741215067877   5: 0.030361060633613   8: 0.030350236359421   3: 0.030350195573213   2: 0.030349984796433   9: 0.030349445185609   0: 0.030349299361689   7: 0.030349087295536   1: 0.030349048122840 

training_8986     5: 0.688003721269688   4: 0.076594872118218   0: 0.074221022694984   7: 0.056510842482240   1: 0.017453412550734   2: 0.017452825459940   6: 0.017444274602915   8: 0.017439728317970   9: 0.017439655119150   3: 0.017439645384161 

training_8987     1: 0.466250188132995   3: 0.285784134665812   2: 0.091472268604729   4: 0.022358532933080   6: 0.022358464123668   5: 0.022358305373721   0: 0.022356777790696   9: 0.022354295152329   8: 0.022353761312804   7: 0.022353271910165 

training_899      5: 0.338165172512287   3: 0.326001643382413   6: 0.138357185595166   8: 0.096015214091792   9: 0.016958909651016   1: 0.016905433026082   0: 0.016901355161878   4: 0.016900252215951   2: 0.016897478317719   7: 0.016897356045697 

training_8991     6: 0.416923641663050   0: 0.408969695417195   9: 0.086670902596790   4: 0.012715749615043   1: 0.012456623942207   5: 0.012453778481828   7: 0.012453147060648   8: 0.012452277667540   2: 0.012452116411543   3: 0.012452067144155 

training_8992     5: 0.808784110490492   1: 0.021247602290618   6: 0.021247401705388   0: 0.021246404514708   3: 0.021246331806111   4: 0.021246125777372   9: 0.021245629433797   2: 0.021245487562037   8: 0.021245453558010   7: 0.021245452861466 

training_8993     6: 0.812226813047469   7: 0.047697390600103   5: 0.017510574642184   0: 0.017509764968508   8: 0.017509757450568   4: 0.017509618028879   1: 0.017509476919236   9: 0.017509125443583   2: 0.017508796395473   3: 0.017508682503996 

training_8995     4: 0.675778902988110   5: 0.115130013552066   6: 0.026138206908350   2: 0.026136323613289   1: 0.026136243987445   0: 0.026136220806067   9: 0.026136198099914   8: 0.026136144097694   3: 0.026135920764176   7: 0.026135825182888 

training_8996     5: 0.720766115689704   1: 0.069374529482568   0: 0.026291830450792   7: 0.026230139863653   6: 0.026225127608305   9: 0.026223044972788   8: 0.026222507646324   4: 0.026222433861684   2: 0.026222325889839   3: 0.026221944534344 

training_8997     5: 0.699296638142438   0: 0.106710063575100   4: 0.024251732343115   6: 0.024251428453859   1: 0.024248715353520   8: 0.024248614751172   9: 0.024248334090795   2: 0.024248179548126   3: 0.024248163005974   7: 0.024248130735901 

training_8998     1: 0.511031641969537   0: 0.316215872583289   4: 0.056526300367053   2: 0.016612804706856   8: 0.016605618838122   6: 0.016605128044788   5: 0.016601658169885   9: 0.016601492959325   7: 0.016599806744619   3: 0.016599675616525 

training_8999     5: 0.772950612394195   1: 0.054857224865953   7: 0.035035249726519   6: 0.033455920264658   2: 0.017301186360117   3: 0.017284595377738   4: 0.017281431402539   0: 0.017279312873313   9: 0.017278392003584   8: 0.017276074731384 

training_9        5: 0.595116476532514   3: 0.191629990596597   6: 0.079983014297360   1: 0.019041239489153   0: 0.019040681891747   9: 0.019038137398466   2: 0.019037938592464   4: 0.019037776671967   7: 0.019037413026169   8: 0.019037331503564 

training_900      6: 0.535793293740120   8: 0.273480899681439   1: 0.023845388229154   5: 0.023842281201159   0: 0.023841524556928   2: 0.023840276123619   9: 0.023839699261825   4: 0.023839602890636   7: 0.023838815171917   3: 0.023838219143203 

training_9003     4: 0.773518453810257   5: 0.025170335238994   8: 0.025164050941965   0: 0.025164013017247   9: 0.025163979611283   3: 0.025163967553915   2: 0.025163901208997   1: 0.025163887536653   7: 0.025163725398908   6: 0.025163685681783 

training_9007     6: 0.650717533143951   0: 0.234822398153324   1: 0.014313519549020   5: 0.014307100758161   9: 0.014306954953836   8: 0.014306600998128   7: 0.014306565477967   4: 0.014306478573549   2: 0.014306439418898   3: 0.014306408973166 

training_901      6: 0.578054905317475   8: 0.237395688087506   1: 0.023072194679705   5: 0.023069925741632   0: 0.023069493373979   9: 0.023068526168847   2: 0.023068147722540   4: 0.023067615992851   7: 0.023066993750781   3: 0.023066509164685 

training_9010     8: 0.464423378908533   1: 0.307485657743210   9: 0.028527393177863   0: 0.028512474170815   5: 0.028510105833955   6: 0.028508741845213   4: 0.028508503495140   3: 0.028508118126522   2: 0.028507867369269   7: 0.028507759329480 

training_9012     6: 0.792026436360698   5: 0.050270243420724   0: 0.019723028644313   2: 0.019716418126418   1: 0.019714881826586   4: 0.019712898456737   8: 0.019712463520939   9: 0.019711427297250   3: 0.019706602491738   7: 0.019705599854597 

training_9014     1: 0.595540036996202   6: 0.265596303796710   5: 0.017361082877073   0: 0.017359167800491   2: 0.017359019790484   8: 0.017357121663737   7: 0.017357034305583   9: 0.017356964030038   4: 0.017356806559313   3: 0.017356462180369 

training_9015     6: 0.654743820676630   1: 0.189435930095585   0: 0.058714945210552   8: 0.020731574615362   5: 0.019751373702927   7: 0.011355604301726   4: 0.011351527697132   2: 0.011305651011799   3: 0.011305125263312   9: 0.011304447424975 

training_9018     6: 0.699474375645070   7: 0.139212893175538   0: 0.020166135742633   5: 0.020166069340419   1: 0.020164791681082   8: 0.020163705355436   9: 0.020163376353932   4: 0.020163035274870   2: 0.020163033190184   3: 0.020162584240837 

training_9020     0: 0.560603853150145   6: 0.280072362505709   5: 0.019919567223502   4: 0.019916177361442   2: 0.019915766874031   1: 0.019915420004375   9: 0.019915132165257   7: 0.019914175647415   8: 0.019913824423468   3: 0.019913720644657 

training_9021     6: 0.795122155838911   0: 0.051949210203619   5: 0.019118563280594   4: 0.019117129649153   2: 0.019116214101811   1: 0.019115944954136   8: 0.019115524997104   9: 0.019115195050215   7: 0.019115099176198   3: 0.019114962748260 

training_9022     6: 0.807051000774062   0: 0.091684353237749   1: 0.038785625234394   5: 0.011230154183276   7: 0.008765721479132   8: 0.008503636562743   9: 0.008496004136595   4: 0.008494943450717   3: 0.008494292268798   2: 0.008494268672534 

training_9025     1: 0.350980528309463   8: 0.332175060376101   0: 0.153175732834709   4: 0.051002995020911   6: 0.018786129963084   9: 0.018777834643842   7: 0.018776142124187   5: 0.018775967235251   3: 0.018774835895831   2: 0.018774773596621 

training_9027     3: 0.465477441842484   1: 0.264635990048121   0: 0.082617609606177   6: 0.026765265911314   5: 0.026755987948657   4: 0.026751821520120   9: 0.026749613678824   8: 0.026749200420638   2: 0.026748643847947   7: 0.026748425175718 

training_9029     5: 0.750992903644536   4: 0.027672388432364   8: 0.027667399245781   9: 0.027666932794438   3: 0.027666850073984   7: 0.027666786162110   2: 0.027666783670209   1: 0.027666666337837   0: 0.027666652498762   6: 0.027666637139980 

training_903      6: 0.465763577355704   0: 0.381271474961770   1: 0.063151784971728   4: 0.012836826910006   5: 0.012829857024975   8: 0.012829538047654   9: 0.012829405124905   7: 0.012829234254645   3: 0.012829164542303   2: 0.012829136806310 

training_9030     1: 0.589763718336467   5: 0.264580932126002   6: 0.018211801032299   8: 0.018209606487436   0: 0.018208429380518   4: 0.018205833683402   9: 0.018205271749954   7: 0.018204954235639   3: 0.018204783669849   2: 0.018204669298435 

training_9031     2: 0.348676770333506   9: 0.305587834836105   6: 0.145695007399141   1: 0.097988440611026   5: 0.017013176454265   4: 0.017010134679866   0: 0.017008363231611   3: 0.017007185469637   7: 0.017006737673983   8: 0.017006349310858 

training_9032     6: 0.359052775998053   1: 0.325413812269251   5: 0.197246493247620   7: 0.022384297050513   8: 0.022271724165702   4: 0.014732666184920   2: 0.014726885778212   0: 0.014725822731631   9: 0.014722878667221   3: 0.014722643906875 

training_9033     6: 0.387252699723068   7: 0.249613491839343   5: 0.223134845644725   1: 0.020005431742213   0: 0.020002025279737   4: 0.019999549096620   9: 0.019999148431793   2: 0.019997833769713   8: 0.019997771888549   3: 0.019997202584237 

training_9034     5: 0.649914918729555   9: 0.082418220899995   8: 0.074718559748261   0: 0.074142215352327   4: 0.019804788397062   6: 0.019801465403583   2: 0.019799978101385   1: 0.019799968486999   7: 0.019799966030309   3: 0.019799918850523 

training_9036     1: 0.702893272963898   5: 0.117521484146637   2: 0.081279632636748   0: 0.014047181593369   6: 0.014045820380177   9: 0.014042801305961   4: 0.014042634792372   8: 0.014042568096141   7: 0.014042469757164   3: 0.014042134327531 

training_9039     2: 0.741084720919206   5: 0.028776504170205   4: 0.028769970730302   9: 0.028768207633547   1: 0.028767131097433   6: 0.028767000649334   8: 0.028766955057139   7: 0.028766891661905   0: 0.028766566826262   3: 0.028766051254667 

training_904      1: 0.359136272990868   6: 0.313513596585335   0: 0.117969307527512   7: 0.103308321661222   5: 0.017682265013236   9: 0.017679341076215   4: 0.017678614527191   8: 0.017677876415158   2: 0.017677220952659   3: 0.017677183250606 

training_9040     5: 0.592241753624191   6: 0.220039644004279   1: 0.023466462893209   0: 0.023465896590015   3: 0.023464929675151   4: 0.023464560389866   2: 0.023464341256559   8: 0.023464154200561   7: 0.023464136321073   9: 0.023464121045098 

training_9041     0: 0.704567537074023   1: 0.032832978171937   6: 0.032829457964192   5: 0.032825610516072   2: 0.032824661804222   4: 0.032824349485994   3: 0.032823918734949   7: 0.032823885872054   9: 0.032823882306850   8: 0.032823718069707 

training_9044     5: 0.647972753770416   0: 0.166464524611526   6: 0.023199428194656   1: 0.023195065192294   3: 0.023194976742012   7: 0.023194889422098   4: 0.023194859062976   8: 0.023194561755621   2: 0.023194501219320   9: 0.023194440029082 

training_9045     1: 0.660090864343076   0: 0.132633064257317   5: 0.048655755791522   2: 0.022743724369548   6: 0.022677854790245   7: 0.022655044673303   4: 0.022638603936105   3: 0.022638498579921   9: 0.022633342417845   8: 0.022633246841118 

training_9047     0: 0.579538052672178   5: 0.244279949376651   6: 0.041479615458546   1: 0.039915195302304   2: 0.027742355292623   7: 0.013417781400667   3: 0.013407584319327   4: 0.013406713866634   9: 0.013406437876025   8: 0.013406314435045 

training_9048     6: 0.542412816031890   0: 0.302093387148196   4: 0.035282010229736   8: 0.030845106160935   9: 0.027246354662479   5: 0.012428877898019   1: 0.012426046467126   3: 0.012422620897077   2: 0.012421423477962   7: 0.012421357026580 

training_9049     4: 0.762929079296062   5: 0.026349856133477   8: 0.026340673302742   9: 0.026340301005804   3: 0.026340172656484   0: 0.026340067823439   2: 0.026340030765280   7: 0.026339957614294   1: 0.026339941056213   6: 0.026339920346206 

training_9051     6: 0.669061642006602   1: 0.106423694031656   7: 0.082365635957505   8: 0.052856266637610   5: 0.014891264398566   0: 0.014885913872213   4: 0.014884024192916   9: 0.014879020395871   3: 0.014876401870034   2: 0.014876136637026 

training_9053     8: 0.325641925040512   5: 0.270851470614160   1: 0.244483696822913   4: 0.050465471010970   6: 0.018097295007467   0: 0.018093401510996   9: 0.018092139819252   3: 0.018091736373000   2: 0.018091461566425   7: 0.018091402234305 

training_9054     6: 0.351651528173896   8: 0.258696876248839   5: 0.183233603954983   0: 0.029493167201193   1: 0.029490395088576   7: 0.029489602092840   9: 0.029486330880335   2: 0.029486269155666   3: 0.029486134057922   4: 0.029486093145750 

training_9055     6: 0.611169382159492   0: 0.292858312413372   9: 0.025567507090994   8: 0.010078179737514   1: 0.010075785408027   7: 0.010065890773116   5: 0.010046766630123   4: 0.010046082857712   3: 0.010046060775617   2: 0.010046032154033 

training_9056     5: 0.677926371048313   3: 0.119967286713613   7: 0.025273828110346   4: 0.025262179820872   6: 0.025261806569952   1: 0.025261759941402   0: 0.025261744067314   2: 0.025261708937711   8: 0.025261696091396   9: 0.025261618699079 

training_9058     6: 0.813925983060868   0: 0.061014716596413   8: 0.022112394433972   1: 0.020917178073962   7: 0.014161766448604   3: 0.013817381305722   9: 0.013562612987820   5: 0.013516730649948   2: 0.013486431783213   4: 0.013484804659479 

training_9059     0: 0.809410462291996   5: 0.021182943875747   4: 0.021177828432941   1: 0.021176851478624   6: 0.021176551806724   3: 0.021175808074888   2: 0.021175095066929   7: 0.021174903516414   9: 0.021174838067612   8: 0.021174717388126 

training_9060     6: 0.795392008882671   8: 0.072066182792742   7: 0.033417945815946   9: 0.030178704996076   4: 0.018235315584486   1: 0.010148110127325   0: 0.010146743553229   5: 0.010138628311766   3: 0.010138337151486   2: 0.010138022784272 

training_9061     6: 0.728131838825581   5: 0.121360209773706   1: 0.053465800020857   0: 0.013868662279406   7: 0.013866109091231   8: 0.013865146612434   4: 0.013860631433862   9: 0.013860598415701   2: 0.013860541621988   3: 0.013860461925235 

training_9064     1: 0.516619357004840   8: 0.319014397198651   5: 0.020553158481061   6: 0.020550237076938   0: 0.020547028092384   9: 0.020544289637646   4: 0.020543332973708   7: 0.020543084490261   3: 0.020542705357700   2: 0.020542409686813 

training_9065     6: 0.496623879508654   3: 0.191174851861808   7: 0.187117999209783   2: 0.043511125813838   4: 0.023840626720945   0: 0.011547958944183   1: 0.011547865681311   5: 0.011546501676019   9: 0.011544679978682   8: 0.011544510604777 

training_9066     5: 0.765152409833637   4: 0.026098589496033   8: 0.026093760460306   3: 0.026093693261598   0: 0.026093658737558   2: 0.026093610862690   9: 0.026093607001425   6: 0.026093600684157   7: 0.026093549355881   1: 0.026093520306716 

training_9067     0: 0.559878820978382   4: 0.187892137291473   6: 0.031534028354817   1: 0.031531684177083   2: 0.031527759646088   9: 0.031527433032429   5: 0.031527186418303   3: 0.031527015997828   7: 0.031527005628221   8: 0.031526928475376 

training_9068     1: 0.372421876317969   7: 0.311372897772878   5: 0.124394928936775   4: 0.027404600652540   0: 0.027403163782760   6: 0.027403131605975   9: 0.027400406201796   2: 0.027399760208184   8: 0.027399681635316   3: 0.027399552885807 

training_9069     6: 0.783983563832772   0: 0.099585775746729   8: 0.020962734546886   5: 0.014570533991376   4: 0.013543354227453   1: 0.013475173072838   3: 0.013470707446869   9: 0.013469685033902   2: 0.013469619291619   7: 0.013468852809556 

training_9072     0: 0.481297667034194   5: 0.304317773240582   7: 0.087961813689128   9: 0.036411729159592   6: 0.015003741918721   4: 0.015002869524660   1: 0.015002420304804   8: 0.015001095301566   3: 0.015001059976251   2: 0.014999829850502 

training_9073     5: 0.413652680406759   6: 0.361459655733912   1: 0.028113254910408   0: 0.028112933258341   4: 0.028110928777971   2: 0.028110218625533   3: 0.028110176212556   9: 0.028110117217983   8: 0.028110051801348   7: 0.028109983055189 

training_9074     5: 0.771887142790245   4: 0.025347027045195   3: 0.025346135026092   6: 0.025345740199406   1: 0.025345700682338   0: 0.025345691266462   2: 0.025345676808790   8: 0.025345671946661   7: 0.025345630878939   9: 0.025345583355873 

training_9075     6: 0.346361942591865   4: 0.300018216302405   1: 0.217006266983089   0: 0.019536498640023   5: 0.019516073199304   9: 0.019512744633191   8: 0.019512152561777   2: 0.019512137762278   3: 0.019511994116078   7: 0.019511973209990 

training_9076     6: 0.690380892682862   4: 0.107328999001898   0: 0.052408367396325   8: 0.040487729397865   9: 0.038343812502386   5: 0.017967377731970   1: 0.017808227031725   7: 0.011870040687734   2: 0.011703455260714   3: 0.011701098306520 

training_9077     0: 0.453275003621139   6: 0.386107040679808   9: 0.043904977747730   3: 0.027055966556977   2: 0.014947582402959   7: 0.014944902262981   1: 0.014943828729535   5: 0.014941613904526   4: 0.014940797408522   8: 0.014938286685824 

training_9079     6: 0.524623183981347   0: 0.310200665991475   1: 0.020651318132059   8: 0.020649987705612   5: 0.020646454280159   9: 0.020645964023959   2: 0.020645933427453   7: 0.020645806358375   4: 0.020645374888001   3: 0.020645311211558 

training_908      6: 0.616429368448005   7: 0.204883648052605   1: 0.043166341004702   0: 0.029493664214246   8: 0.017671864966571   5: 0.017671603572702   9: 0.017670961947444   4: 0.017670877143197   2: 0.017670849482770   3: 0.017670821167756 

training_9081     1: 0.320108237601134   5: 0.204057462080785   0: 0.188371505789781   4: 0.151286457995585   2: 0.039032436250963   9: 0.035241319039749   6: 0.015479395464891   7: 0.015475148962459   3: 0.015474040543939   8: 0.015473996270716 

training_9087     1: 0.588253053141620   6: 0.196618332460304   2: 0.106730206933755   5: 0.015493304449448   0: 0.015487753125957   9: 0.015483717760629   4: 0.015483606656045   8: 0.015483449334441   7: 0.015483333849927   3: 0.015483242287873 

training_9088     1: 0.568289255051106   0: 0.199368634191304   5: 0.098270601500604   2: 0.038894036477277   6: 0.015866366413969   8: 0.015862741681463   9: 0.015862368475710   7: 0.015862080239582   3: 0.015861975208859   4: 0.015861940760125 

training_9090     5: 0.555872012445669   0: 0.266173367578728   1: 0.056959441912087   6: 0.017290673295628   3: 0.017289252729005   9: 0.017285338327932   8: 0.017284049011379   4: 0.017282117490807   7: 0.017281929184007   2: 0.017281818024758 

training_9091     5: 0.771590219144074   4: 0.025381920489671   6: 0.025379119149411   8: 0.025378692975541   9: 0.025378448640525   1: 0.025378405239964   0: 0.025378395228546   3: 0.025378363846304   7: 0.025378235327145   2: 0.025378199958818 

training_9093     6: 0.690521856734091   0: 0.146850416351454   5: 0.020330470584071   7: 0.020328884766916   1: 0.020328515107300   8: 0.020328400074977   9: 0.020328137566182   3: 0.020327902159290   2: 0.020327773872178   4: 0.020327642783540 

training_9094     6: 0.687386660364562   0: 0.147021289756422   5: 0.020700580543096   7: 0.020699662346985   8: 0.020699479216087   1: 0.020699244530983   9: 0.020698459756844   4: 0.020698242748804   2: 0.020698192689830   3: 0.020698188046387 

training_9095     6: 0.413226562784505   7: 0.358771265126415   8: 0.071521970199626   3: 0.022365588569942   5: 0.022354329735991   0: 0.022352974162970   2: 0.022352952466901   1: 0.022351869411030   9: 0.022351321623748   4: 0.022351165918871 

training_9097     4: 0.814589233147624   5: 0.020607409992605   6: 0.020601769029475   0: 0.020601657133419   1: 0.020601055391566   9: 0.020600693150763   8: 0.020600411721527   7: 0.020599332362287   2: 0.020599312161215   3: 0.020599125909519 

training_9098     4: 0.726326575648537   1: 0.101348644722125   6: 0.021593888998077   9: 0.021558548858625   7: 0.021542316998765   5: 0.021532458027726   8: 0.021530130475258   0: 0.021525017747477   2: 0.021524812703620   3: 0.021517605819791 

training_9100     5: 0.406058660606395   6: 0.240582952641185   9: 0.207499804346419   2: 0.052690101768534   8: 0.015532445816399   1: 0.015530748409814   0: 0.015528666816737   7: 0.015526808318365   4: 0.015525360085433   3: 0.015524451190719 

training_9101     5: 0.595067664869751   1: 0.220785261354828   4: 0.023023665089027   6: 0.023022502166696   0: 0.023017981505125   8: 0.023016875321109   9: 0.023016664900436   3: 0.023016517634335   7: 0.023016451575912   2: 0.023016415582781 

training_9102     1: 0.623243792622484   5: 0.164479753540286   6: 0.089028789312146   0: 0.017614481602439   2: 0.017607602784854   7: 0.017605923559624   4: 0.017605913770266   9: 0.017604653325415   8: 0.017604572706896   3: 0.017604516775591 

training_9103     4: 0.737665226901800   5: 0.029153557329504   0: 0.029149095585682   9: 0.029147621469972   8: 0.029147619496368   3: 0.029147486520580   2: 0.029147422261260   1: 0.029147408983386   7: 0.029147325139631   6: 0.029147236311818 

training_9104     2: 0.311348635694310   6: 0.305031498169066   1: 0.104917456475661   8: 0.072073093718685   5: 0.059230116209602   9: 0.054784797709898   0: 0.040682151337346   4: 0.017315881743144   7: 0.017308291660282   3: 0.017308077282008 

training_9107     6: 0.796619043210185   5: 0.022602068759325   8: 0.022601321223221   9: 0.022599700154762   4: 0.022598523950797   0: 0.022597055121836   7: 0.022596272928403   1: 0.022595676732547   2: 0.022595226748484   3: 0.022595111170438 

training_9108     6: 0.654867454529233   2: 0.145962585891276   1: 0.085558301733907   7: 0.016237116637064   0: 0.016231787924192   5: 0.016231721174004   9: 0.016228224726158   4: 0.016228170838102   8: 0.016227343329164   3: 0.016227293216899 

training_9110     0: 0.615437716090895   6: 0.264528070590584   5: 0.032144745035508   9: 0.012852188235214   1: 0.012507156743068   4: 0.012507049082217   8: 0.012506280271151   7: 0.012505906784471   2: 0.012505474904263   3: 0.012505412262628 

training_9111     5: 0.612558231543924   1: 0.202703065425555   0: 0.023097840300423   4: 0.023095317061828   8: 0.023091179488485   6: 0.023091163327973   3: 0.023090883950564   9: 0.023090810126549   2: 0.023090780330133   7: 0.023090728444567 

training_9112     1: 0.526320580403611   0: 0.314701297782554   6: 0.057802427021248   7: 0.014463891349981   5: 0.014463012481675   9: 0.014452275882607   4: 0.014451478410233   3: 0.014449056207586   2: 0.014448922168978   8: 0.014447058291526 

training_9113     5: 0.748072216136186   4: 0.027998065119009   0: 0.027991552901119   8: 0.027991282817360   6: 0.027991265901127   7: 0.027991151826091   9: 0.027991128865551   3: 0.027991124331457   2: 0.027991123139404   1: 0.027991088962696 

training_9115     5: 0.609994278501109   6: 0.197550298380109   1: 0.024066497630799   4: 0.024058455776705   8: 0.024056954039246   0: 0.024055478011649   3: 0.024054622171740   2: 0.024054488765197   9: 0.024054485993315   7: 0.024054440730133 

training_9116     5: 0.572535934228355   0: 0.210272749377844   6: 0.027149947150369   8: 0.027149927162759   9: 0.027149506572943   3: 0.027149165061370   4: 0.027148608774058   1: 0.027148313507149   7: 0.027147991651709   2: 0.027147856513445 

training_9117     5: 0.634612083598375   1: 0.174318089356004   6: 0.023887435255586   9: 0.023883985323098   3: 0.023883531083977   0: 0.023883446886574   4: 0.023883203756742   8: 0.023882784450479   2: 0.023882731119903   7: 0.023882709169261 

training_9118     6: 0.733495685865366   8: 0.029618779059789   5: 0.029614414049557   1: 0.029613383139810   9: 0.029612723234323   4: 0.029611264864460   0: 0.029610484665568   7: 0.029608985362636   2: 0.029607332812519   3: 0.029606946945970 

training_9120     6: 0.804275040599004   1: 0.047255472551645   7: 0.018560362293170   0: 0.018559416214837   8: 0.018559358681300   9: 0.018559132646110   5: 0.018558516960189   4: 0.018557833113150   2: 0.018557478334575   3: 0.018557388606021 

training_9124     6: 0.697226043706370   8: 0.125113783961887   0: 0.053253366047963   4: 0.017778960166276   5: 0.017773483635576   1: 0.017771415956587   7: 0.017771106231708   9: 0.017770963473667   3: 0.017770607771918   2: 0.017770269048049 

training_9127     5: 0.607662352054131   6: 0.139358829985065   9: 0.092597160917711   2: 0.051845410562966   3: 0.018130799691476   1: 0.018084768671375   8: 0.018082833705396   4: 0.018080811846616   0: 0.018079241836638   7: 0.018077790728625 

training_9128     6: 0.745816471903707   1: 0.028248789323991   8: 0.028243540356078   7: 0.028243148213915   0: 0.028242901236243   9: 0.028241819127696   5: 0.028241061828177   2: 0.028240993797806   3: 0.028240668650046   4: 0.028240605562340 

training_9129     6: 0.701868528583099   1: 0.131356217183406   9: 0.044320812918918   7: 0.017520471855479   8: 0.017493798776309   0: 0.017491499607455   5: 0.017490178197236   2: 0.017486325298847   4: 0.017486104502101   3: 0.017486063077150 

training_913      9: 0.848536797439091   6: 0.016830775390671   8: 0.016829927965017   5: 0.016829853132289   0: 0.016829263073183   4: 0.016829080591483   1: 0.016828905453360   3: 0.016828489886466   7: 0.016828466679719   2: 0.016828440388721 

training_9131     6: 0.521199359052737   1: 0.260844804558999   0: 0.027247285038694   5: 0.027245338836219   9: 0.027244230330778   7: 0.027243945952585   8: 0.027243916320671   4: 0.027243852968718   2: 0.027243776575864   3: 0.027243490364734 

training_9132     6: 0.381548387373850   1: 0.380349446823239   0: 0.029767989563796   5: 0.029762162908042   7: 0.029762104208877   9: 0.029762093750487   3: 0.029762012647190   8: 0.029761959058918   2: 0.029761931740869   4: 0.029761911924732 

training_9133     6: 0.573533730477317   7: 0.204660397940364   8: 0.079843912087925   1: 0.020308943525718   5: 0.020307565636532   9: 0.020284102794886   0: 0.020271962700707   3: 0.020263341775471   4: 0.020263170478975   2: 0.020262872582106 

training_9134     6: 0.648345411232424   1: 0.229662958418224   7: 0.041190854523442   0: 0.011555534358489   5: 0.011542822944858   9: 0.011542581247350   3: 0.011540304276484   8: 0.011540052844618   2: 0.011539752205396   4: 0.011539727948713 

training_9135     6: 0.798374405412945   9: 0.051663115085229   7: 0.018760254734817   0: 0.018752570097883   5: 0.018751483875218   8: 0.018747620164849   1: 0.018743963175583   4: 0.018737067107102   2: 0.018735664059016   3: 0.018733856287359 

training_9137     6: 0.413557694501177   1: 0.357958310443667   8: 0.028566980430202   9: 0.028563760056499   0: 0.028562323765883   5: 0.028558708031945   7: 0.028558373540111   2: 0.028558053035072   3: 0.028558040755869   4: 0.028557755439576 

training_9138     6: 0.693303510997517   1: 0.182451899082078   0: 0.040196764895592   5: 0.012020332145380   4: 0.012008318496390   7: 0.012006960568119   8: 0.012003168932248   2: 0.012003105012627   9: 0.012003064422297   3: 0.012002875447752 

training_9139     0: 0.393234434862209   6: 0.305311690998468   3: 0.199341126577672   7: 0.022936865588510   5: 0.013197953428892   2: 0.013197755178002   1: 0.013196044578520   8: 0.013195662832685   4: 0.013195021760362   9: 0.013193444194681 

training_9142     1: 0.450881522530478   6: 0.435774149609024   0: 0.024803200944963   7: 0.012708919057760   5: 0.012646029689216   4: 0.012639976225117   8: 0.012637510992228   9: 0.012636489199352   3: 0.012636241479986   2: 0.012635960271877 

training_9143     6: 0.711514974180762   3: 0.101853779462495   5: 0.023335149249704   8: 0.023330828583703   4: 0.023328907188248   9: 0.023328399236841   0: 0.023327534356137   1: 0.023327034354371   7: 0.023326923356507   2: 0.023326470031233 

training_9146     6: 0.613783396252465   9: 0.217358420543794   0: 0.052659468223570   1: 0.016609568719154   5: 0.016601150764863   4: 0.016598306155693   8: 0.016597480544024   3: 0.016597445503897   2: 0.016597412344751   7: 0.016597350947788 

training_9147     9: 0.507540955272959   5: 0.223541674737081   0: 0.132528080494986   8: 0.034703850055530   7: 0.016953441540097   1: 0.016952989825713   6: 0.016951844923690   4: 0.016943702240825   2: 0.016941902140133   3: 0.016941558768988 

training_9149     6: 0.851802590191346   1: 0.060973905987775   0: 0.011212656515128   8: 0.010864391340500   9: 0.010859749463352   3: 0.010858205671513   5: 0.010857979702103   4: 0.010857482485188   7: 0.010856638779138   2: 0.010856399863958 

training_915      6: 0.681216017647586   7: 0.165179410743376   0: 0.055177549787632   1: 0.014065403210791   8: 0.014062670268799   5: 0.014060397034174   9: 0.014060042927184   2: 0.014059542694203   3: 0.014059491681696   4: 0.014059474004562 

training_9152     7: 0.456446692211417   6: 0.320499658921540   5: 0.027907285422332   3: 0.027881407725374   4: 0.027879216677086   0: 0.027878543091010   1: 0.027878077167000   2: 0.027876862808364   8: 0.027876387766391   9: 0.027875868209487 

training_9153     6: 0.458356329993358   2: 0.306745506253225   5: 0.068765054091441   0: 0.064750640147937   1: 0.016902985428763   9: 0.016897843497529   7: 0.016896983852357   8: 0.016895127801746   4: 0.016894775676032   3: 0.016894753257614 

training_9155     6: 0.501873565658292   2: 0.289590721868247   0: 0.056161432366141   3: 0.050024398762613   4: 0.025739362829588   8: 0.024094331998156   1: 0.013132605353303   5: 0.013129208314375   9: 0.013128014570698   7: 0.013126358278587 

training_9156     6: 0.631212206208977   7: 0.242076410194375   0: 0.037948246805738   5: 0.012682458429513   1: 0.012681495650250   4: 0.012680260717440   9: 0.012679895356848   2: 0.012679843991827   8: 0.012679707725362   3: 0.012679474919671 

training_9158     5: 0.837671526933532   6: 0.038837300435142   0: 0.015438806320811   1: 0.015437727927810   8: 0.015436247383109   4: 0.015435975573576   9: 0.015435694628150   7: 0.015435663148004   3: 0.015435651724873   2: 0.015435405924992 

training_9159     9: 0.719141496519314   5: 0.031225935167992   4: 0.031217252185189   6: 0.031205213881033   1: 0.031205128790438   0: 0.031205064609817   3: 0.031202854564132   8: 0.031201568210216   2: 0.031197844119885   7: 0.031197641951983 

training_9160     5: 0.506741905715123   1: 0.206786625742233   0: 0.134414222567866   3: 0.038961658543505   6: 0.036257132904356   8: 0.015371748622153   9: 0.015370725716925   4: 0.015365982916219   7: 0.015365492754700   2: 0.015364504516919 

training_9161     5: 0.657492870721929   6: 0.210077542811729   0: 0.016557625240576   1: 0.016554877690591   8: 0.016553675657559   4: 0.016553090212190   9: 0.016552842264772   7: 0.016552648395853   2: 0.016552453968860   3: 0.016552373035940 

training_9162     6: 0.770712761758788   5: 0.025480926650799   4: 0.025478113062942   0: 0.025476675685109   1: 0.025476503071244   8: 0.025475344273839   9: 0.025475324105623   7: 0.025475163258341   2: 0.025474703417509   3: 0.025474484715807 

training_9163     6: 0.703635937577287   5: 0.089645463178428   0: 0.079667469960193   7: 0.044434008855114   1: 0.013779280574052   9: 0.013772289028780   2: 0.013766807043905   8: 0.013766423748385   4: 0.013766244673095   3: 0.013766075360762 

training_9164     6: 0.512748523177947   9: 0.283429741437879   2: 0.063055920269781   0: 0.020113346423472   5: 0.020110733974196   1: 0.020110520777554   8: 0.020108494369476   7: 0.020107792744520   4: 0.020107601848704   3: 0.020107324976472 

training_9165     6: 0.748177897553895   3: 0.082112058186085   9: 0.021214473858044   7: 0.021214197118116   5: 0.021214104916565   0: 0.021214093624579   1: 0.021213684802086   8: 0.021213457365307   2: 0.021213135775462   4: 0.021212896799862 

training_9166     6: 0.593149765471165   1: 0.287618221617654   0: 0.014904765347477   5: 0.014904743794280   9: 0.014904408857799   8: 0.014904294162557   7: 0.014903603660029   2: 0.014903454457180   3: 0.014903401604204   4: 0.014903341027655 

training_9170     6: 0.778725761914327   7: 0.058757685586707   0: 0.057311350072111   1: 0.042940854764338   4: 0.018840128091394   3: 0.008737602229149   9: 0.008674923487304   5: 0.008670895874336   8: 0.008670561894350   2: 0.008670236085985 

training_9171     6: 0.819562086116565   5: 0.020050798658367   1: 0.020050181785483   9: 0.020049770793375   7: 0.020048267221461   0: 0.020048077309135   8: 0.020047899164837   3: 0.020047815021134   4: 0.020047605991332   2: 0.020047497938310 

training_9172     1: 0.379218968655012   0: 0.181071702723738   6: 0.157041438894592   3: 0.104081322626688   8: 0.068372648009182   4: 0.048164273762440   5: 0.015514891056014   9: 0.015512792594084   2: 0.015511426032121   7: 0.015510535646128 

training_9175     9: 0.382675310370113   6: 0.340487550837456   1: 0.131929542275385   3: 0.039843580527198   5: 0.028683675203866   0: 0.025057892006283   4: 0.012835326825049   2: 0.012829801173361   8: 0.012828801771825   7: 0.012828519009464 

training_9177     8: 0.440628781980547   5: 0.241866905220586   0: 0.155822663678248   9: 0.023101404199797   1: 0.023098755302349   3: 0.023098520777798   4: 0.023097993692336   6: 0.023097862078601   7: 0.023093617452721   2: 0.023093495617017 

training_9178     6: 0.592801051509068   8: 0.270618215116247   7: 0.017075392998754   9: 0.017073532035705   5: 0.017073050535545   0: 0.017072614438344   1: 0.017071760880925   4: 0.017071738008621   2: 0.017071324440765   3: 0.017071320036026 

training_918      6: 0.384549085854190   2: 0.350567566175324   4: 0.116618858491664   9: 0.062665768956549   8: 0.014848309559081   5: 0.014369787426311   7: 0.014100302166160   0: 0.014094978571479   1: 0.014094199854050   3: 0.014091142945192 

training_9181     6: 0.635521727433945   1: 0.210867510551962   0: 0.035361581850935   5: 0.016910374796582   4: 0.016901329938636   8: 0.016890515062577   9: 0.016888463282770   3: 0.016886815351307   2: 0.016886300126246   7: 0.016885381605041 

training_9182     1: 0.360591648557496   6: 0.291386961304769   0: 0.261276265906356   4: 0.018825782256922   9: 0.011322510012209   5: 0.011321976697355   8: 0.011320472216128   3: 0.011318424601230   2: 0.011317995898545   7: 0.011317962548991 

training_9184     6: 0.777290014588409   1: 0.085004208124244   2: 0.045074559352112   5: 0.013234681797577   9: 0.013234575514577   0: 0.013234081562107   4: 0.013232914522575   8: 0.013231778690677   3: 0.013231777281130   7: 0.013231408566592 

training_9187     5: 0.670127415371199   0: 0.165771295837847   9: 0.020536336349835   8: 0.020523179564856   3: 0.020510541929092   1: 0.020508956753438   6: 0.020508932369731   4: 0.020504903038847   7: 0.020504564467408   2: 0.020503874317748 

training_9189     5: 0.517439765795600   8: 0.264243976651139   2: 0.059417495327807   3: 0.057376904443823   6: 0.016925012085487   1: 0.016921533668797   0: 0.016920600251524   4: 0.016919542013599   9: 0.016919200752372   7: 0.016915969009851 

training_9190     6: 0.496838329498245   7: 0.147147613307271   0: 0.139873071816149   2: 0.101418474729546   9: 0.028151238507063   1: 0.027495315657993   5: 0.014771086740258   3: 0.014769426271433   8: 0.014767934324175   4: 0.014767509147868 

training_9192     0: 0.573385258571733   6: 0.305558601368070   9: 0.015134479644405   5: 0.015134021092229   8: 0.015132089893354   1: 0.015132020859111   4: 0.015131995934407   3: 0.015131123507802   7: 0.015130244562715   2: 0.015130164566173 

training_9193     6: 0.547564771960461   3: 0.194301077563164   0: 0.126832247010175   7: 0.018769175695982   1: 0.018757836732360   2: 0.018757107851312   8: 0.018756599710583   5: 0.018755332858708   9: 0.018753059456342   4: 0.018752791160914 

training_9194     6: 0.769377299455363   0: 0.113386213091612   4: 0.014658434204472   5: 0.014656881804865   1: 0.014655508805832   8: 0.014653730123752   3: 0.014653286326493   7: 0.014653012391284   9: 0.014652833314093   2: 0.014652800482235 

training_9195     6: 0.718335071829868   5: 0.105952044990058   0: 0.021972865782291   1: 0.021963579074602   9: 0.021962874551823   4: 0.021962827551800   2: 0.021962806088145   7: 0.021962671605049   3: 0.021962642012172   8: 0.021962616514192 

training_9196     6: 0.556982328580748   9: 0.180058463863045   1: 0.069141457394749   2: 0.067828310892823   0: 0.047696267448675   5: 0.015660844339953   7: 0.015658277036269   3: 0.015658172466985   4: 0.015658151491893   8: 0.015657726484858 

training_9197     6: 0.652834502312013   8: 0.197611731667609   1: 0.018695555087161   5: 0.018694732261817   0: 0.018694643637814   9: 0.018694345278129   4: 0.018694250031961   3: 0.018693432692767   2: 0.018693419294318   7: 0.018693387736411 

training_92       8: 0.768588441764611   6: 0.025716662430973   9: 0.025714505512828   5: 0.025714276213302   4: 0.025712008189362   0: 0.025711755616913   7: 0.025711675212656   1: 0.025710619272451   2: 0.025710110396721   3: 0.025709945390182 

training_920      5: 0.572466754664560   3: 0.251442317287994   2: 0.055305360538725   1: 0.017326605780941   9: 0.017246040281593   8: 0.017244319986679   4: 0.017243793791953   0: 0.017242730952335   6: 0.017241809666457   7: 0.017240267048764 

training_9201     6: 0.522974507282909   8: 0.280574192383646   9: 0.072376916527230   0: 0.017733686354277   5: 0.017727539590378   4: 0.017723351579623   1: 0.017723239825541   7: 0.017722725074418   2: 0.017721945071687   3: 0.017721896310290 

training_9202     6: 0.568341771540827   8: 0.165513431248510   5: 0.128641887324807   2: 0.035714476538855   0: 0.028421295494792   7: 0.014698289081715   9: 0.014669487559639   1: 0.014667902143233   4: 0.014666974268977   3: 0.014664484798647 

training_9203     6: 0.749030359919158   7: 0.102562661747347   0: 0.061274211622787   1: 0.019869527971924   3: 0.011211933958077   9: 0.011211151908027   5: 0.011210726328195   2: 0.011209891971095   8: 0.011209882078248   4: 0.011209652495142 

training_9204     6: 0.474829239153927   2: 0.241389413195062   4: 0.090546140685794   8: 0.065341408802878   7: 0.038597422966779   1: 0.017868286768099   0: 0.017866465250768   5: 0.017855578135848   9: 0.017854358407729   3: 0.017851686633115 

training_9205     6: 0.363941600525777   1: 0.333479200604676   0: 0.179474996073295   7: 0.045629491075501   8: 0.013221546267361   4: 0.012859924457858   9: 0.012849121635130   3: 0.012848863818075   5: 0.012848362780714   2: 0.012846892761612 

training_9206     0: 0.532923302595627   6: 0.345321882806606   7: 0.025710000252826   1: 0.025390112020935   9: 0.011836410634269   5: 0.011770208411274   2: 0.011767137164997   4: 0.011765827248157   8: 0.011764718339960   3: 0.011750400525348 

training_9207     6: 0.873547309392229   5: 0.014050848306857   0: 0.014050811759714   1: 0.014050547917415   4: 0.014050224559077   7: 0.014050147985625   9: 0.014050116060972   8: 0.014050113398930   3: 0.014049941156690   2: 0.014049939462491 

training_9208     6: 0.686032019671619   8: 0.143602230899947   2: 0.031522680645353   5: 0.031519916033354   1: 0.027885915825719   0: 0.020340069841251   9: 0.018876482051305   4: 0.013673337251383   7: 0.013301800724036   3: 0.013245547056032 

training_921      6: 0.405060102107064   5: 0.224905918453944   8: 0.170216472530132   0: 0.054815722226023   9: 0.049378713935079   1: 0.034947224180066   7: 0.022174056737792   2: 0.012908820487168   3: 0.012797115374999   4: 0.012795853967733 

training_9210     5: 0.434285717022099   6: 0.297698364114539   7: 0.120603627799463   1: 0.034111328983472   8: 0.018893238513144   0: 0.018885538361270   3: 0.018880723293489   9: 0.018880675458078   4: 0.018880637919538   2: 0.018880148534909 

training_9213     6: 0.851925456123443   1: 0.060991144965946   0: 0.011207643620615   8: 0.010845082897287   9: 0.010840431895116   3: 0.010838896802006   5: 0.010838705725083   4: 0.010838207588593   7: 0.010837331748484   2: 0.010837098633426 

training_9214     6: 0.804293506747638   1: 0.047236974715693   7: 0.018560387011636   0: 0.018559415894423   8: 0.018559358381153   9: 0.018559140361534   5: 0.018558516951407   4: 0.018557833028321   2: 0.018557478302767   3: 0.018557388605429 

training_9216     6: 0.693311163742659   1: 0.182442374758667   0: 0.040198653994404   5: 0.012020321554780   4: 0.012008314905287   7: 0.012006957885836   8: 0.012003168911332   2: 0.012003104615021   9: 0.012003064405275   3: 0.012002875226740 

training_9217     9: 0.529797406842469   6: 0.305791154579438   8: 0.020553118791117   0: 0.020552333609814   1: 0.020551816106418   5: 0.020551540811588   7: 0.020550838430239   4: 0.020550742471184   3: 0.020550546513134   2: 0.020550501844599 

training_9218     9: 0.489957243272433   6: 0.354592955048578   1: 0.019433034554611   8: 0.019432871893706   0: 0.019431987275049   5: 0.019431895782449   4: 0.019430315744554   7: 0.019429958113203   2: 0.019429882418666   3: 0.019429855896752 

training_922      6: 0.439424863133202   5: 0.221982158493160   3: 0.181726261018421   0: 0.067422472972725   7: 0.023895313507306   1: 0.017802598338649   2: 0.011986941473729   4: 0.011923839033812   8: 0.011919354940206   9: 0.011916197088792 

training_9220     6: 0.648283391771797   1: 0.229719356230075   7: 0.041196848818859   0: 0.011555187182522   5: 0.011542811539509   9: 0.011542569593521   3: 0.011540301763216   8: 0.011540052915004   2: 0.011539752219462   4: 0.011539727966034 

training_9222     6: 0.593000858419016   1: 0.287767127388585   0: 0.014904764735311   5: 0.014904744453305   9: 0.014904409112499   8: 0.014904294858605   7: 0.014903603842716   2: 0.014903454496087   3: 0.014903401686015   4: 0.014903341007862 

training_9224     6: 0.778341918738240   0: 0.075222729757292   8: 0.048299567917006   1: 0.014020994897341   9: 0.014020454320658   3: 0.014019652127729   7: 0.014018940946534   5: 0.014018784500426   2: 0.014018549462772   4: 0.014018407332001 

training_9228     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_9229     5: 0.375884108326172   6: 0.276442035597293   3: 0.229135279197923   0: 0.016936341444046   1: 0.016935733864153   9: 0.016935648948818   8: 0.016933588722620   4: 0.016933558758254   2: 0.016932110841622   7: 0.016931594299099 

training_9230     1: 0.556862983897728   0: 0.168875011753820   5: 0.154695905281724   6: 0.017083726038693   9: 0.017080736157806   4: 0.017080597219784   2: 0.017080523422352   8: 0.017080476869903   7: 0.017080109648118   3: 0.017079929710072 

training_9231     5: 0.701682903534469   9: 0.141040435430141   4: 0.019665653484771   6: 0.019659101734151   0: 0.019658986367510   8: 0.019658678868346   1: 0.019658665474217   2: 0.019658540647690   3: 0.019658528295456   7: 0.019658506163247 

training_9232     0: 0.567147346186315   6: 0.168596115105126   9: 0.142573928791267   5: 0.017391189572720   4: 0.017386998413728   1: 0.017383856514392   8: 0.017381551767851   2: 0.017379899514201   3: 0.017379718957278   7: 0.017379395177122 

training_9234     6: 0.308520431465416   9: 0.179583985000624   7: 0.168420139205986   1: 0.163929009683249   2: 0.064548739789199   0: 0.038186778119106   4: 0.019244327061544   8: 0.019190644208193   5: 0.019188816004972   3: 0.019187129461712 

training_9235     5: 0.692245173772986   1: 0.162126669531114   4: 0.018206082315805   6: 0.018203547987676   0: 0.018203308184436   7: 0.018203159473731   8: 0.018203139010963   9: 0.018203081456044   2: 0.018202919924359   3: 0.018202918342886 

training_9237     5: 0.670292500557605   0: 0.094860901243553   7: 0.091451255910831   2: 0.020491795359778   4: 0.020486862237324   1: 0.020486127954757   6: 0.020483553454635   8: 0.020482655976646   9: 0.020482343584291   3: 0.020482003720580 

training_9238     5: 0.793866194781186   4: 0.022906949671355   3: 0.022903778602250   6: 0.022903532131096   0: 0.022903414058300   8: 0.022903406532049   1: 0.022903321442421   2: 0.022903274830618   9: 0.022903100253543   7: 0.022903027697183 

training_9239     5: 0.741497175509099   6: 0.028726360736502   1: 0.028724997533015   0: 0.028723263293013   8: 0.028722157964307   7: 0.028721616278314   2: 0.028721357891558   4: 0.028721295357394   3: 0.028720973307908   9: 0.028720802128891 

training_924      6: 0.817570342846753   1: 0.020275754671899   0: 0.020274595878823   5: 0.020273508907053   4: 0.020269795505458   9: 0.020268227721670   8: 0.020267613118484   7: 0.020267044716371   3: 0.020266627230839   2: 0.020266489402650 

training_9240     5: 0.693788120161668   2: 0.099570507381159   8: 0.071834347690236   6: 0.019260693777037   0: 0.019258508362265   4: 0.019258124186195   9: 0.019257597334000   7: 0.019257512156523   1: 0.019257333619636   3: 0.019257255331281 

training_9242     1: 0.572770152519134   5: 0.257327975481425   8: 0.043090016401717   6: 0.018121305803329   0: 0.018118577685622   4: 0.018115494952308   9: 0.018114947777166   7: 0.018114262333714   2: 0.018113767724126   3: 0.018113499321461 

training_9243     7: 0.550785957576712   6: 0.197852130991873   1: 0.031431218109188   0: 0.031426522085268   5: 0.031423939234452   4: 0.031417917408391   9: 0.031416839664253   2: 0.031416040396475   8: 0.031414874648270   3: 0.031414559885117 

training_9246     1: 0.519232419735005   7: 0.332095601842723   0: 0.031920168964133   4: 0.017137834882095   6: 0.016605726686523   5: 0.016605013459407   9: 0.016602711929568   8: 0.016600561354172   2: 0.016600193184332   3: 0.016599767962042 

training_925      6: 0.657115844320613   1: 0.133385334123100   0: 0.126147317053095   7: 0.024163543039603   9: 0.016110087848210   3: 0.008621787668690   8: 0.008617396237869   5: 0.008613070325457   2: 0.008612927687933   4: 0.008612691695430 

training_9250     5: 0.554747517497656   0: 0.253047176992991   6: 0.024030119128808   4: 0.024029081894206   9: 0.024024781874812   8: 0.024024674820501   1: 0.024024263570110   3: 0.024024165932271   2: 0.024024122456056   7: 0.024024095832589 

training_9252     0: 0.717132647532709   4: 0.076533256824892   6: 0.025806624053010   5: 0.025805469997044   1: 0.025800978710168   9: 0.025787332550960   2: 0.025785316584965   7: 0.025783171798609   3: 0.025782742512587   8: 0.025782459435057 

training_9253     6: 0.603970522738527   2: 0.150207504976432   7: 0.132150101683148   0: 0.024512861446379   4: 0.020972258710856   9: 0.013648356891311   5: 0.013635228569051   1: 0.013634658606695   8: 0.013634355820747   3: 0.013634150556853 

training_9255     5: 0.556842709020704   6: 0.257013735192098   3: 0.023268628805366   1: 0.023268442768017   4: 0.023268188504536   0: 0.023268069662622   8: 0.023267588365242   2: 0.023267577036074   9: 0.023267539005793   7: 0.023267521639546 

training_9258     1: 0.747245923425967   5: 0.028086266836861   6: 0.028084425226452   0: 0.028084398033483   4: 0.028084009243728   9: 0.028083515653840   2: 0.028083408067490   8: 0.028082802182969   7: 0.028082648343157   3: 0.028082602986054 

training_9259     6: 0.406299942059378   4: 0.218437165159683   5: 0.216596778479774   0: 0.022683620631191   8: 0.022669165734029   2: 0.022664630603812   1: 0.022664339345012   9: 0.022662028942381   3: 0.022661306345048   7: 0.022661022699693 

training_926      6: 0.508853872150701   0: 0.381630786764921   3: 0.023195068886133   8: 0.012334331477398   9: 0.012332648226031   1: 0.012331636506906   5: 0.012330894794550   7: 0.012330462558713   4: 0.012330225405454   2: 0.012330073229193 

training_9260     4: 0.721755729174775   5: 0.030921792774479   2: 0.030915983936468   6: 0.030915733507208   9: 0.030915705590352   3: 0.030915140266753   8: 0.030915124230156   1: 0.030915008341948   7: 0.030914896717606   0: 0.030914885460255 

training_9261     9: 0.805208276439907   6: 0.021649125064357   8: 0.021644855776137   5: 0.021643739371771   0: 0.021643349929601   1: 0.021642710769013   4: 0.021642405591323   7: 0.021642002401611   3: 0.021641770295928   2: 0.021641764360352 

training_9263     5: 0.828918782391771   4: 0.019011584289574   6: 0.019010793055477   1: 0.019009667121947   8: 0.019009497263300   0: 0.019009432608472   9: 0.019007777530177   7: 0.019007615584267   3: 0.019007565012767   2: 0.019007285142248 

training_9264     4: 0.723501992524820   1: 0.030726854018051   0: 0.030726748465101   6: 0.030725542096509   7: 0.030723209619416   5: 0.030720438179883   9: 0.030720413515668   2: 0.030718934578007   8: 0.030718147121391   3: 0.030717719881155 

training_9265     6: 0.801430344231110   5: 0.044457272198662   4: 0.019299714702485   9: 0.019268675662822   8: 0.019267608548561   0: 0.019255900308097   7: 0.019255474002578   2: 0.019255467004167   1: 0.019254814723638   3: 0.019254728617880 

training_9266     5: 0.719077805365288   3: 0.094147650077359   8: 0.023351390742794   6: 0.023347684470576   2: 0.023346903917382   0: 0.023346173515766   4: 0.023345808548456   1: 0.023345745271770   7: 0.023345429430285   9: 0.023345408660326 

training_9267     5: 0.795359887590177   4: 0.022741953673500   8: 0.022737561646287   6: 0.022737460885202   0: 0.022737371060111   9: 0.022737280062752   3: 0.022737172793553   7: 0.022737122329321   2: 0.022737110611997   1: 0.022737079347098 

training_9268     5: 0.482057911250831   4: 0.297186486326844   1: 0.064944967983561   2: 0.022315255669403   0: 0.022263508347710   6: 0.022260795332883   7: 0.022252254453937   8: 0.022243591780945   9: 0.022237736981193   3: 0.022237491872692 

training_9270     4: 0.760760302849039   5: 0.026590471227750   6: 0.026581771458381   1: 0.026581718917131   0: 0.026581705011300   3: 0.026580978691680   8: 0.026580885780493   7: 0.026580781433618   2: 0.026580753520671   9: 0.026580631109937 

training_9271     5: 0.792447549921654   6: 0.023068487377916   8: 0.023063930879002   0: 0.023061786118671   1: 0.023060685663242   3: 0.023059731575706   4: 0.023059628292863   7: 0.023059520691422   9: 0.023059505437736   2: 0.023059174041788 

training_9272     5: 0.789614221320108   8: 0.023376991413166   6: 0.023376636267392   3: 0.023376346691077   4: 0.023376289229719   0: 0.023376255369344   1: 0.023376026392075   9: 0.023375759545416   7: 0.023375752047485   2: 0.023375721724219 

training_9273     5: 0.751432974641713   6: 0.090353262064232   4: 0.019779134279784   1: 0.019777504025229   0: 0.019776868113559   9: 0.019776294374396   7: 0.019776035721049   3: 0.019776030739970   8: 0.019775996719279   2: 0.019775899320790 

training_9274     5: 0.792249985952889   4: 0.023088522056750   1: 0.023083264858431   8: 0.023082777710080   0: 0.023082706095651   6: 0.023082686857148   2: 0.023082626303892   3: 0.023082552417431   9: 0.023082462224592   7: 0.023082415523136 

training_9277     5: 0.419757187626186   6: 0.202724228553855   7: 0.177537200764275   1: 0.071017735425001   0: 0.035611503743262   3: 0.018672297344868   4: 0.018671201218385   8: 0.018669879432815   9: 0.018669601187673   2: 0.018669164703682 

training_9278     4: 0.785203032841032   5: 0.023873039729204   0: 0.023867197862255   1: 0.023866617384676   6: 0.023865481041261   9: 0.023865473938494   3: 0.023865128177163   8: 0.023864808406849   2: 0.023864653210661   7: 0.023864567408402 

training_9279     2: 0.349490895136587   6: 0.336784566937460   1: 0.213011904973410   5: 0.026685085594192   7: 0.014595892812245   0: 0.014558602052544   9: 0.011447955042012   3: 0.011153091317158   8: 0.011136355309701   4: 0.011135650824692 

training_9280     0: 0.344545624759985   1: 0.291461254046890   6: 0.236986803355416   5: 0.018153788403097   4: 0.018147588541123   8: 0.018144469454878   9: 0.018140373242190   3: 0.018140218993971   2: 0.018140161691713   7: 0.018139717510736 

training_9282     1: 0.607981179039288   0: 0.159990632835902   6: 0.029010257413587   7: 0.029004214108225   8: 0.029003895900655   9: 0.029002700292793   5: 0.029001865985531   4: 0.029001776358743   3: 0.029001747442914   2: 0.029001730622363 

training_9283     1: 0.412021057752804   6: 0.401735113422440   0: 0.051519719206857   2: 0.042148183602359   3: 0.029480355981323   4: 0.012628934842300   5: 0.012620921395204   9: 0.012615776098891   8: 0.012615322245025   7: 0.012614615452799 

training_9284     5: 0.511891475816775   0: 0.230758174319390   8: 0.086600009123814   6: 0.024394186989043   9: 0.024393815063815   1: 0.024393363201415   3: 0.024392405236447   2: 0.024392286697814   7: 0.024392237314840   4: 0.024392046236647 

training_9285     4: 0.600041478675984   6: 0.242995358449276   1: 0.019625732827838   5: 0.019623914464215   0: 0.019623279195001   2: 0.019618848575528   7: 0.019617939355118   9: 0.019617835902904   3: 0.019617832267801   8: 0.019617780286336 

training_9287     4: 0.749603805893132   5: 0.027827699335668   1: 0.027821699112330   8: 0.027821341294538   6: 0.027821065888346   0: 0.027821057259280   9: 0.027820921583753   2: 0.027820842156431   7: 0.027820785849292   3: 0.027820781627230 

training_9288     5: 0.711790537480189   2: 0.120738535579468   6: 0.020937817686267   1: 0.020936617404502   0: 0.020936016312878   8: 0.020933619412295   4: 0.020932227748084   7: 0.020931765365986   9: 0.020931561346470   3: 0.020931301663860 

training_929      6: 0.813833702279027   0: 0.020686251205527   9: 0.020685777903860   1: 0.020685391861771   7: 0.020685218485943   5: 0.020685037908875   8: 0.020684857868370   4: 0.020684657822296   3: 0.020684571126424   2: 0.020684533537908 

training_9290     6: 0.813208658240605   0: 0.045344873788745   7: 0.017735407013933   5: 0.017675639959446   1: 0.017673124019771   4: 0.017672677594470   3: 0.017672489013984   9: 0.017672409432474   8: 0.017672369649950   2: 0.017672351286623 

training_9293     6: 0.698351408464260   1: 0.116534464719349   2: 0.053450968982418   0: 0.052690512777512   9: 0.013187108734183   5: 0.013157645754511   7: 0.013157289649577   8: 0.013156953369589   4: 0.013156854640389   3: 0.013156792908212 

training_9294     6: 0.738662540975068   0: 0.140899778517476   1: 0.015057283786319   5: 0.015055201109486   7: 0.015054539454958   8: 0.015054439290340   9: 0.015054398213035   4: 0.015054205819999   2: 0.015053851087236   3: 0.015053761746083 

training_9295     6: 0.728331809232527   0: 0.170479984362641   1: 0.012650896386069   8: 0.012649937541668   9: 0.012648664275883   7: 0.012648163488923   5: 0.012647810270814   2: 0.012647612816296   3: 0.012647572783059   4: 0.012647548842119 

training_9296     5: 0.483077964389594   1: 0.286679355738736   0: 0.067720326118364   6: 0.058137645501272   9: 0.017468540010812   8: 0.017453613358830   7: 0.017366419373385   4: 0.017366062970079   3: 0.017365254275047   2: 0.017364818263881 

training_9299     9: 0.812571243296062   6: 0.020829207689300   8: 0.020826390979892   0: 0.020826301671175   5: 0.020826202218805   1: 0.020825244950822   7: 0.020824025109108   4: 0.020823926538492   2: 0.020823895417713   3: 0.020823562128630 

training_93       5: 0.397886280761681   4: 0.346849262313439   9: 0.104313409078570   1: 0.021565796836152   0: 0.021565318927522   6: 0.021564786449208   2: 0.021564190436568   8: 0.021563811058843   7: 0.021563655166606   3: 0.021563488971413 

training_930      6: 0.498472548071485   0: 0.206177939213339   2: 0.131391648380278   8: 0.049664323595133   1: 0.019050811094551   9: 0.019049499085013   5: 0.019049463812188   4: 0.019048287394436   7: 0.019047896232659   3: 0.019047583120918 

training_9301     5: 0.746244632295000   9: 0.111055744688255   4: 0.017838939804836   6: 0.017838889010302   8: 0.017837952087633   0: 0.017837307370862   1: 0.017837174875830   2: 0.017836936874695   7: 0.017836218345963   3: 0.017836204646623 

training_9302     0: 0.441669670614745   1: 0.401525607408249   5: 0.019604594467408   6: 0.019603765691342   4: 0.019601296029959   3: 0.019599480977439   9: 0.019599279080966   8: 0.019599147552743   2: 0.019598725749517   7: 0.019598432427632 

training_9304     6: 0.778626043074173   7: 0.024597839279901   0: 0.024597364386405   9: 0.024597255326018   1: 0.024597048935903   8: 0.024596942370769   2: 0.024596935193249   3: 0.024596889672222   5: 0.024596858398207   4: 0.024596823363153 

training_9305     6: 0.876593410488883   0: 0.013712256626564   1: 0.013712210523615   9: 0.013712054489194   5: 0.013711953806484   8: 0.013711740098215   7: 0.013711712288262   2: 0.013711604546019   4: 0.013711580060124   3: 0.013711477072639 

training_9306     5: 0.442393324750637   4: 0.350888406461747   3: 0.025841609461930   1: 0.025840294924211   0: 0.025839703457415   6: 0.025839460884837   2: 0.025839346063989   7: 0.025839307466498   8: 0.025839294696388   9: 0.025839251832347 

training_9308     6: 0.623640319925932   0: 0.151869489153718   9: 0.028062600990846   8: 0.028062324729328   1: 0.028062038708973   5: 0.028061386300285   7: 0.028060560475038   3: 0.028060473005244   2: 0.028060405545611   4: 0.028060401165025 

training_9311     5: 0.769269248513431   4: 0.025640423172603   8: 0.025636477771316   3: 0.025636368177566   9: 0.025636343346455   2: 0.025636294512578   6: 0.025636257596303   7: 0.025636245162709   0: 0.025636191004964   1: 0.025636150742075 

training_9312     4: 0.793714771831344   5: 0.022926987321040   0: 0.022921605503983   8: 0.022919934678032   3: 0.022919534233103   9: 0.022919470887673   2: 0.022919452680769   1: 0.022919417301072   7: 0.022919413744135   6: 0.022919411818850 

training_9313     5: 0.638547866640597   9: 0.163231385211437   1: 0.024778614182704   3: 0.024778173613199   4: 0.024777766695585   0: 0.024777310623524   8: 0.024777283546228   6: 0.024777244291086   2: 0.024777207327950   7: 0.024777147867690 

training_9314     6: 0.790286328613484   8: 0.076167823073044   5: 0.016694728686643   0: 0.016694205762355   1: 0.016693765099424   9: 0.016692776655923   3: 0.016692725324293   4: 0.016692601699131   7: 0.016692558739423   2: 0.016692486346278 

training_9315     6: 0.834878890565989   1: 0.046234331717353   0: 0.036156757915646   7: 0.011824930738384   8: 0.011818808439958   5: 0.011818271677988   9: 0.011817565210140   3: 0.011817073471417   4: 0.011816708162876   2: 0.011816662100248 

training_9316     5: 0.820657594155041   4: 0.019930403519048   8: 0.019926668047099   0: 0.019926537183070   3: 0.019926516523645   9: 0.019926515816069   6: 0.019926515300476   1: 0.019926430821908   2: 0.019926427143880   7: 0.019926391489765 

training_932      1: 0.679543539689380   9: 0.119582296373081   4: 0.038454064649451   6: 0.036363511119511   0: 0.033070145823393   7: 0.018638443119616   5: 0.018609005054671   8: 0.018581147701844   3: 0.018579477344107   2: 0.018578369124945 

training_9324     1: 0.706781343863627   2: 0.122086584384812   0: 0.021392475589461   5: 0.021392397359898   6: 0.021392366652899   4: 0.021391540024471   3: 0.021391077931189   8: 0.021390792738010   9: 0.021390755519727   7: 0.021390665935905 

training_9326     0: 0.707429245369476   1: 0.115267118369437   6: 0.022166725258621   5: 0.022166205733380   7: 0.022163730267228   9: 0.022162980020494   2: 0.022162572745854   8: 0.022160753757952   4: 0.022160570531844   3: 0.022160097945713 

training_9327     6: 0.768855469663864   0: 0.073511582568923   8: 0.046808060329805   1: 0.027120692865546   5: 0.024690873366141   4: 0.011848041031946   9: 0.011797842907989   7: 0.011789256784641   2: 0.011789105281057   3: 0.011789075200089 

training_9328     6: 0.401357106009274   5: 0.249614663184514   2: 0.197524397064493   8: 0.058421534626897   3: 0.025524121113328   9: 0.013521761100051   4: 0.013510727542775   0: 0.013509516357097   7: 0.013508582574970   1: 0.013507590426601 

training_9330     0: 0.735612069551269   6: 0.069734865703077   2: 0.050284945000422   3: 0.020856775870557   5: 0.020616432065284   4: 0.020587467490431   1: 0.020577577350149   9: 0.020577019946689   8: 0.020576586957845   7: 0.020576260064277 

training_9332     5: 0.611665967766255   0: 0.109216536324179   6: 0.065705942777982   1: 0.062674499337212   9: 0.054686929315013   8: 0.019228768415130   7: 0.019225533669061   4: 0.019199533681499   2: 0.019198400966585   3: 0.019197887747084 

training_9333     5: 0.740949874319113   0: 0.092716033043729   4: 0.020793643180383   6: 0.020793148607207   7: 0.020791955997524   8: 0.020791321837880   9: 0.020791150892602   1: 0.020790994796204   3: 0.020790961621400   2: 0.020790915703957 

training_9334     4: 0.762199615102170   8: 0.072287836578988   5: 0.020693643027814   0: 0.020689457004961   1: 0.020688717196647   6: 0.020688423076878   3: 0.020688120695309   9: 0.020688096176578   2: 0.020688079897610   7: 0.020688011243044 

training_9335     5: 0.648168823303716   9: 0.160754168574655   0: 0.023885719782455   4: 0.023885037923602   1: 0.023884841754084   3: 0.023884689824831   6: 0.023884599834032   2: 0.023884119188288   7: 0.023884111519959   8: 0.023883888294378 

training_9336     6: 0.692198902575296   5: 0.126917585059181   0: 0.110308649570867   1: 0.010530722453512   7: 0.010046070308561   9: 0.010000897220400   8: 0.009999452223548   4: 0.009999332937797   2: 0.009999207655696   3: 0.009999179995142 

training_9337     0: 0.638258188916331   1: 0.201612902435332   5: 0.020022046754077   4: 0.020017926489891   6: 0.020017664089795   9: 0.020014648080376   8: 0.020014487554037   3: 0.020014219352870   2: 0.020014074726306   7: 0.020013841600986 

training_9338     5: 0.435595570285009   1: 0.252592507922351   3: 0.156728622209171   6: 0.041756251327657   0: 0.018934878634938   4: 0.018879552921249   2: 0.018878510491768   8: 0.018878283647427   9: 0.018877988308230   7: 0.018877834252199 

training_9339     5: 0.785586005587952   2: 0.071945927669424   4: 0.017813939462740   1: 0.017808859961812   6: 0.017808112905308   0: 0.017808025994676   8: 0.017807615564800   9: 0.017807224632493   7: 0.017807165904138   3: 0.017807122316656 

training_934      9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_9343     0: 0.371950150602655   1: 0.335591651169246   3: 0.152768832543900   6: 0.019959405379151   5: 0.019956730176957   9: 0.019954868554438   2: 0.019954742011886   8: 0.019954665324966   7: 0.019954534143522   4: 0.019954420093279 

training_9345     6: 0.532666486152422   5: 0.307127965449057   0: 0.033071637381317   3: 0.018173117073113   1: 0.018167785381471   8: 0.018159190981401   9: 0.018158923737321   4: 0.018158544439902   2: 0.018158527155075   7: 0.018157822248920 

training_9346     2: 0.453934971205259   5: 0.331723605643575   4: 0.026799703768849   8: 0.026792656014116   9: 0.026791831543488   3: 0.026791652718622   7: 0.026791560856888   1: 0.026791365326071   0: 0.026791327431699   6: 0.026791325491432 

training_9348     6: 0.484814234405264   8: 0.320173767988169   0: 0.097684545793689   1: 0.013905005858545   5: 0.013904712520987   9: 0.013904651467047   4: 0.013903363416475   3: 0.013903343544158   7: 0.013903214411959   2: 0.013903160593707 

training_9349     6: 0.849115698653949   1: 0.016765888243541   0: 0.016765255004704   9: 0.016765028165516   5: 0.016764888910061   7: 0.016764848225644   2: 0.016764714849014   4: 0.016764593954752   8: 0.016764592228537   3: 0.016764491764282 

training_9352     6: 0.501274436486097   2: 0.185417220578899   1: 0.107518495188498   0: 0.063515046282023   5: 0.048312287185293   4: 0.018815786511164   8: 0.018794991897157   3: 0.018787829768118   9: 0.018784463775308   7: 0.018779442327443 

training_9354     5: 0.449097600974601   9: 0.154751059638959   0: 0.136965362865009   3: 0.119279296850434   6: 0.023322348716625   4: 0.023317659729522   2: 0.023317418145945   1: 0.023316677243079   8: 0.023316478330327   7: 0.023316097505499 

training_9356     6: 0.490966458026734   8: 0.279781143718416   7: 0.090275973201050   1: 0.019910422997491   0: 0.019845381489646   5: 0.019844525903471   3: 0.019844124004683   9: 0.019844018806713   4: 0.019843983156936   2: 0.019843968694862 

training_9357     2: 0.456122130081648   1: 0.299416154988254   0: 0.030562291272890   6: 0.030560378075208   5: 0.030556994736858   7: 0.030556609084117   9: 0.030556595203724   8: 0.030556540695069   4: 0.030556365665541   3: 0.030555940196692 

training_9361     8: 0.816934620461061   0: 0.054691392014655   6: 0.016049499570494   7: 0.016048313591691   1: 0.016046958248385   9: 0.016046821119775   2: 0.016046227171010   5: 0.016046034363818   4: 0.016045242268109   3: 0.016044891191001 

training_9362     6: 0.703873637958197   2: 0.120381711603788   0: 0.021984301161368   1: 0.021967038305401   9: 0.021966430631822   5: 0.021966218342590   7: 0.021965504720736   4: 0.021965397144583   8: 0.021965255691511   3: 0.021964504440005 

training_9363     2: 0.472781048007478   1: 0.319167558708599   9: 0.041887496975480   6: 0.039056820284524   8: 0.021200677755007   7: 0.021200594172799   5: 0.021181791106094   0: 0.021176863505313   4: 0.021173810137712   3: 0.021173339346994 

training_9364     5: 0.510471860328178   2: 0.323956542315623   4: 0.020698102480646   6: 0.020697827233647   0: 0.020696248882344   9: 0.020696182126729   1: 0.020696077246692   7: 0.020695946377508   8: 0.020695889406465   3: 0.020695323602167 

training_9365     1: 0.447362372893366   4: 0.239167512979325   5: 0.153181139798405   3: 0.022901429727015   6: 0.022900165207235   0: 0.022899476089950   9: 0.022898428816662   8: 0.022897067633225   7: 0.022896773887444   2: 0.022895632967372 

training_9366     5: 0.478803889280031   3: 0.320091235730717   4: 0.025143955457738   8: 0.025137558819481   2: 0.025137339803644   9: 0.025137319313591   7: 0.025137187310018   0: 0.025137182579731   6: 0.025137179230082   1: 0.025137152474966 

training_9369     5: 0.612432830946470   0: 0.197824111317382   6: 0.023720775008828   9: 0.023718399506461   8: 0.023718300015740   3: 0.023717672100959   1: 0.023717327729343   4: 0.023717067297345   7: 0.023716871067396   2: 0.023716645010078 

training_937      6: 0.796375487598129   0: 0.065600790393698   9: 0.041138901276352   7: 0.024854030596331   5: 0.012016610183212   4: 0.012006584921351   8: 0.012003799924662   1: 0.012002373373935   3: 0.012000745494704   2: 0.012000676237625 

training_9371     5: 0.585469665777594   3: 0.280717214938272   1: 0.016727739270619   6: 0.016727403921502   0: 0.016727071789125   2: 0.016726595457719   4: 0.016726160760912   9: 0.016726116338429   7: 0.016726033968969   8: 0.016725997776858 

training_9372     3: 0.438511575757555   5: 0.404013411401059   4: 0.019687123789479   8: 0.019684882077365   6: 0.019684601546019   9: 0.019684377936447   0: 0.019683814437182   1: 0.019683541797950   7: 0.019683402072987   2: 0.019683269183956 

training_9373     5: 0.401169058456016   3: 0.265191366853001   0: 0.191605746751459   8: 0.036981245078860   6: 0.017514314581286   1: 0.017510961522697   9: 0.017507930820103   4: 0.017506932089855   2: 0.017506465253123   7: 0.017505978593601 

training_9374     6: 0.590936799738879   0: 0.232943766415959   8: 0.054269748488899   5: 0.017410500719972   1: 0.017407762449145   9: 0.017407194583992   7: 0.017406422047212   4: 0.017405960056289   3: 0.017405935106980   2: 0.017405910392672 

training_9377     6: 0.601604527993354   5: 0.183123847767630   8: 0.026941673925980   0: 0.026909338730863   7: 0.026905431584686   1: 0.026904711353011   2: 0.026903109148502   9: 0.026902552073057   4: 0.026902546562378   3: 0.026902260860539 

training_9378     5: 0.822389788120429   4: 0.019736908060478   6: 0.019735282570938   0: 0.019734291356488   9: 0.019734034757715   1: 0.019734033260195   8: 0.019734030663308   7: 0.019733966910440   3: 0.019733854494680   2: 0.019733809805330 

training_938      6: 0.401249454723250   8: 0.227159907689400   5: 0.204762653711343   0: 0.062398590004132   1: 0.030469935547334   9: 0.014795898893114   3: 0.014792733707623   4: 0.014791639993066   7: 0.014789595503895   2: 0.014789590226842 

training_9381     5: 0.521417964124862   8: 0.319173692902805   6: 0.019959415360090   7: 0.019924553353099   1: 0.019923495516667   0: 0.019923192240312   9: 0.019922043577425   2: 0.019919872158805   3: 0.019918129817587   4: 0.019917640948348 

training_9382     1: 0.412004124890108   6: 0.401709823995318   0: 0.051561902975684   2: 0.042148182195737   3: 0.029480443919088   4: 0.012628887715564   5: 0.012620921095486   9: 0.012615775971136   8: 0.012615322316530   7: 0.012614614925348 

training_9383     5: 0.537077944187087   4: 0.231654441665963   6: 0.071318339330415   8: 0.045542776483168   3: 0.019194828871728   1: 0.019045669494357   0: 0.019044644182636   9: 0.019042069328196   7: 0.019039797680369   2: 0.019039488776080 

training_9385     5: 0.487226517962558   6: 0.311926601020708   3: 0.025106856170196   4: 0.025106314885186   0: 0.025105736200275   8: 0.025105714554739   2: 0.025105602676591   7: 0.025105597985007   1: 0.025105572459118   9: 0.025105486085622 

training_9388     5: 0.394981435095720   0: 0.368911663842001   1: 0.076033222168948   6: 0.057983657210238   8: 0.017020677561401   7: 0.017017219517739   9: 0.017013387804404   4: 0.017013116210409   2: 0.017013040269459   3: 0.017012580319681 

training_9389     4: 0.675610507251633   8: 0.109912375150452   5: 0.026815176921662   1: 0.026810067819547   0: 0.026809669815082   3: 0.026808565651748   6: 0.026808504321668   2: 0.026808451541951   9: 0.026808362890992   7: 0.026808318635264 

training_939      6: 0.498739471909178   8: 0.244215107818123   1: 0.063675994185909   5: 0.056425655660645   9: 0.046389349643243   0: 0.018124960926409   4: 0.018112736250870   2: 0.018106991059078   3: 0.018105664607283   7: 0.018104067939263 

training_9392     0: 0.753976112811872   5: 0.061196756943198   3: 0.052630268111875   1: 0.018895555265585   6: 0.018888393239727   4: 0.018885231498821   2: 0.018884119314492   7: 0.018882754474582   9: 0.018881256204686   8: 0.018879552135163 

training_9393     6: 0.700301315399282   7: 0.114374894093549   0: 0.047027142399385   8: 0.040912836734985   9: 0.016239198986271   5: 0.016231849969157   4: 0.016229203652748   1: 0.016228442696031   2: 0.016227605233802   3: 0.016227510834791 

training_9397     2: 0.405512774735317   1: 0.347157296970340   6: 0.030932153976116   5: 0.030920817146268   4: 0.030915442564884   0: 0.030913974612691   7: 0.030912494706704   9: 0.030912084611630   3: 0.030911853637456   8: 0.030911107038595 

training_9398     6: 0.589525570372656   0: 0.252107207735016   8: 0.043832350938541   1: 0.016363754239937   5: 0.016362533684657   7: 0.016362232213867   9: 0.016361739570026   2: 0.016361643267684   4: 0.016361512548749   3: 0.016361455428866 

training_9399     5: 0.759018184686701   2: 0.082156297039000   4: 0.019855769304583   6: 0.019854348402134   0: 0.019853184761153   8: 0.019852958911690   1: 0.019852674437936   9: 0.019852578106436   7: 0.019852053298985   3: 0.019851951051381 

training_94       8: 0.766597518285489   5: 0.025936763603610   6: 0.025935774912356   4: 0.025934412999081   9: 0.025934164248991   0: 0.025932944107892   7: 0.025932573479713   1: 0.025932315194004   2: 0.025931808081057   3: 0.025931725087808 

training_940      6: 0.468788180441141   9: 0.303434685582617   8: 0.096037775625460   1: 0.018828908194623   0: 0.018822299476582   7: 0.018819155487814   5: 0.018818613333826   4: 0.018817437278005   2: 0.018816606115627   3: 0.018816338464305 

training_9403     1: 0.561996118355096   6: 0.286516738403516   0: 0.050717884077842   5: 0.014405121118659   2: 0.014404789517649   4: 0.014394729247179   3: 0.014391886796856   9: 0.014391373267801   7: 0.014390745697383   8: 0.014390613518021 

training_9405     5: 0.540531959079834   2: 0.236022476416997   9: 0.086710773296082   4: 0.019534841780079   6: 0.019534802177304   0: 0.019533448194577   1: 0.019533323713631   7: 0.019532972015504   8: 0.019532912344786   3: 0.019532490981206 

training_9406     6: 0.695083732220840   0: 0.127481423937996   1: 0.040777967927421   2: 0.038666606500412   8: 0.036948913925013   7: 0.016784127433215   3: 0.011081732683721   5: 0.011067890581798   9: 0.011054346775897   4: 0.011053258013688 

training_9408     0: 0.532904128138651   6: 0.310481238235880   4: 0.048412196671210   9: 0.015464951672921   1: 0.015462724165748   5: 0.015457569767539   8: 0.015456398266874   3: 0.015454061454483   7: 0.015453444119984   2: 0.015453287506711 

training_941      0: 0.450132400763621   6: 0.403416241929155   4: 0.018310605566856   1: 0.018308231668479   2: 0.018306708556977   5: 0.018305604278539   9: 0.018305329271011   8: 0.018305047212557   3: 0.018305001396641   7: 0.018304829356163 

training_9410     2: 0.304558312356253   6: 0.287816137422324   1: 0.243068416475649   5: 0.023512106341729   0: 0.023511269193205   4: 0.023508630089543   9: 0.023506502482496   7: 0.023506277648655   8: 0.023506194826344   3: 0.023506153163801 

training_9412     0: 0.387093001006592   1: 0.349248182257057   5: 0.032959704479930   6: 0.032957724847799   2: 0.032957250566437   4: 0.032957110740185   9: 0.032956827582331   7: 0.032956800933405   8: 0.032956706017762   3: 0.032956691568502 

training_9413     0: 0.599699938216092   5: 0.236745687152024   1: 0.020449124544521   6: 0.020446664339776   2: 0.020443815944235   9: 0.020443762326044   8: 0.020443229076573   4: 0.020442938921502   3: 0.020442502798566   7: 0.020442336680664 

training_9414     1: 0.438864318035221   5: 0.220601954336765   3: 0.154715910883915   8: 0.066374841321584   6: 0.019910199920533   0: 0.019908377662467   9: 0.019907872690846   2: 0.019905664925842   4: 0.019905479187894   7: 0.019905381034932 

training_9415     1: 0.386990286827237   6: 0.369503800457215   0: 0.109607030915220   5: 0.031550948412169   7: 0.030329606880211   9: 0.014404017904541   4: 0.014403838613798   8: 0.014403814622084   3: 0.014403478029795   2: 0.014403177337729 

training_9417     5: 0.413240791954438   9: 0.296733604270781   6: 0.093520905992356   0: 0.028089530272405   1: 0.028075745029155   2: 0.028071807576323   4: 0.028068397960046   7: 0.028066752235488   3: 0.028066266912193   8: 0.028066197796814 

training_942      6: 0.506857124567560   0: 0.383627891883235   3: 0.023194730148302   8: 0.012334320511656   9: 0.012332637968618   1: 0.012331636387396   5: 0.012330896128841   7: 0.012330463279389   4: 0.012330225862509   2: 0.012330073262494 

training_9422     5: 0.682754651667466   9: 0.132620646789207   0: 0.023078667527977   3: 0.023078386438353   4: 0.023078285598699   1: 0.023078219418311   6: 0.023078051179070   2: 0.023077772267351   8: 0.023077675459154   7: 0.023077643654412 

training_9423     1: 0.464289509463809   0: 0.332458144905577   6: 0.038772159339957   5: 0.023498531155074   8: 0.023497795201299   9: 0.023497311553873   7: 0.023497303898538   4: 0.023496579163178   2: 0.023496501200398   3: 0.023496164118297 

training_9425     5: 0.784146568598404   4: 0.023989496986139   8: 0.023983373359575   6: 0.023983167041761   9: 0.023982995053065   3: 0.023982966629762   2: 0.023982899427607   0: 0.023982876577125   7: 0.023982842668647   1: 0.023982813657914 

training_9426     8: 0.305213339275951   1: 0.261600731174779   5: 0.249715041864444   0: 0.026214629025398   3: 0.026211414496471   2: 0.026209570548030   4: 0.026209296401954   6: 0.026208838109459   7: 0.026208569812276   9: 0.026208569291237 

training_9427     5: 0.822437850864282   4: 0.019732161594523   8: 0.019729098630867   0: 0.019728883604994   6: 0.019728857758298   1: 0.019728693749844   9: 0.019728657973856   3: 0.019728626492278   2: 0.019728597954990   7: 0.019728571376069 

training_9428     4: 0.747394825313720   5: 0.028071580617020   0: 0.028066836233799   8: 0.028066835712634   1: 0.028066814815966   9: 0.028066776032901   3: 0.028066640405025   2: 0.028066637879921   7: 0.028066548472813   6: 0.028066504516201 

training_9429     5: 0.685152151984365   8: 0.095854804788329   0: 0.078723951526909   6: 0.020040769952112   4: 0.020039479889521   9: 0.020037993804425   1: 0.020037865552528   3: 0.020037712062041   2: 0.020037680861025   7: 0.020037589578745 

training_943      9: 0.728903781770974   5: 0.081947624135966   6: 0.023647544777666   0: 0.023646100080500   1: 0.023644690257820   8: 0.023644328144113   4: 0.023643036723932   2: 0.023642199472392   7: 0.023640533812971   3: 0.023640160823668 

training_9431     2: 0.689457520916275   1: 0.134310741943459   6: 0.022039584932437   5: 0.022031603267567   0: 0.022031122312603   4: 0.022028110470788   7: 0.022025752804540   9: 0.022025339899890   3: 0.022025228371300   8: 0.022024995081141 

training_9432     4: 0.462678153731230   1: 0.253975717493181   5: 0.138930172505959   6: 0.020641216345999   0: 0.020634152065039   2: 0.020629000428421   8: 0.020628737602527   9: 0.020628222335175   7: 0.020627397931372   3: 0.020627229561097 

training_9433     6: 0.839954718719889   9: 0.017783451701755   0: 0.017783273842614   5: 0.017783168566477   7: 0.017782968768178   8: 0.017782791176245   1: 0.017782681986295   4: 0.017782449856855   2: 0.017782287622631   3: 0.017782207759060 

training_9434     9: 0.366576250189562   6: 0.266225709462562   5: 0.199718599503687   7: 0.047293043648471   2: 0.020043445511490   0: 0.020038370187128   1: 0.020027710812665   4: 0.020026064525563   8: 0.020025774420318   3: 0.020025031738554 

training_9435     1: 0.735327342126892   0: 0.029436085677760   6: 0.029417962673814   2: 0.029404815759259   5: 0.029403339531161   7: 0.029402408541924   9: 0.029402277468661   3: 0.029402111905593   4: 0.029401930589916   8: 0.029401725725020 

training_9436     6: 0.609098332808168   9: 0.167549662217219   0: 0.083915670639013   1: 0.051876912672898   8: 0.036267082165331   7: 0.014013410027066   5: 0.009320600230725   2: 0.009319952364800   4: 0.009319384244610   3: 0.009318992630170 

training_9437     6: 0.369179134197020   8: 0.213573594934511   5: 0.168539638055336   1: 0.115763898202427   0: 0.049399078317270   4: 0.028221735750983   2: 0.013831014344008   9: 0.013830760406650   3: 0.013830684246885   7: 0.013830461544911 

training_9438     5: 0.767936037506398   1: 0.025785194987985   0: 0.025785123767295   6: 0.025784949876100   4: 0.025784892215821   3: 0.025784883811714   2: 0.025784807640559   8: 0.025784747280715   7: 0.025784694401640   9: 0.025784668511773 

training_944      6: 0.395633869531636   7: 0.339430325244252   3: 0.107383501666795   0: 0.022508151168579   5: 0.022508075691593   9: 0.022507734983812   2: 0.022507245680231   1: 0.022507241539320   8: 0.022507130722213   4: 0.022506723771569 

training_9441     5: 0.790651459522097   4: 0.023264320556975   6: 0.023260892975794   1: 0.023260849609693   8: 0.023260816625072   9: 0.023260584878448   0: 0.023260535616216   3: 0.023260265006908   7: 0.023260138516673   2: 0.023260136692123 

training_9443     1: 0.694918847726905   0: 0.135742767779234   3: 0.039699825581908   6: 0.018524271829989   5: 0.018521533027259   8: 0.018520841080038   2: 0.018518435395894   4: 0.018518366605781   7: 0.018517594731102   9: 0.018517516241891 

training_9444     5: 0.593949726603059   0: 0.205659496718382   4: 0.025052459308021   1: 0.025050931966859   9: 0.025048508257187   8: 0.025048188637687   6: 0.025047734699688   3: 0.025047701914905   7: 0.025047675576910   2: 0.025047576317304 

training_9445     6: 0.724372041527058   1: 0.122984977885285   2: 0.060334667427984   3: 0.019946569478449   0: 0.012066516657946   5: 0.012060065494287   9: 0.012059893708701   7: 0.012059397997944   4: 0.012058015796044   8: 0.012057854026301 

training_945      6: 0.486162571462328   0: 0.214118424517914   2: 0.135321023512824   8: 0.050658818797076   1: 0.018958484850713   9: 0.018957184225130   5: 0.018956898968587   4: 0.018955831988003   7: 0.018955542582363   3: 0.018955219095062 

training_9450     6: 0.772542909728107   0: 0.103223666308557   8: 0.015603417434720   3: 0.015543855294319   1: 0.015517029423400   2: 0.015516760943831   5: 0.015513874269519   4: 0.015513040861379   7: 0.015513021124709   9: 0.015512424611458 

training_9453     0: 0.453436310339897   6: 0.337123866252932   5: 0.026184102134202   4: 0.026181597754919   1: 0.026180266565215   9: 0.026179167508352   7: 0.026178811473105   8: 0.026178810254328   2: 0.026178605930885   3: 0.026178461786165 

training_9454     1: 0.670527439364223   3: 0.177025628957606   5: 0.019060739060590   6: 0.019058500017853   0: 0.019056569991913   2: 0.019054564268519   4: 0.019054508180686   8: 0.019054094203124   9: 0.019054025723967   7: 0.019053930231517 

training_9463     4: 0.569602340378102   7: 0.190322897415281   5: 0.030015653681562   6: 0.030009424817790   9: 0.030008646048295   1: 0.030008541657634   0: 0.030008208128701   2: 0.030008195379819   8: 0.030008104054951   3: 0.030007988437863 

training_9465     6: 0.552174389900302   5: 0.234383084194575   2: 0.062628074535129   3: 0.061867352667586   0: 0.026392182833766   1: 0.012519420647642   8: 0.012510438242024   4: 0.012509105317480   9: 0.012508168702943   7: 0.012507782958552 

training_9469     6: 0.485357441846623   0: 0.299545759525877   1: 0.026892287538403   5: 0.026891273323147   4: 0.026887002859088   7: 0.026885503104724   2: 0.026885407288742   9: 0.026885327512281   8: 0.026885054811335   3: 0.026884942189781 

training_9470     6: 0.827209002255483   0: 0.052513100178274   5: 0.029548383952938   8: 0.013217343204854   3: 0.012979752847187   7: 0.012912543937876   1: 0.012908957197248   2: 0.012905314488461   9: 0.012903241108710   4: 0.012902360828970 

training_9472     1: 0.506807183360519   8: 0.157942544094720   0: 0.104478133394574   6: 0.097118433036565   2: 0.049161316368238   5: 0.016899654761852   4: 0.016898329548690   9: 0.016898326567733   7: 0.016898177989288   3: 0.016897900877820 

training_9473     7: 0.464859546104974   6: 0.326240338084715   0: 0.084857201549113   4: 0.017721274580817   8: 0.017721095775771   1: 0.017721016981925   2: 0.017720229234498   9: 0.017720145261182   5: 0.017719824896681   3: 0.017719327530323 

training_9475     4: 0.741274201912361   5: 0.028751516241820   6: 0.028748573234749   2: 0.028747769344309   9: 0.028747287093965   1: 0.028746279744507   7: 0.028746145997680   0: 0.028746122414669   3: 0.028746072042123   8: 0.028746031973818 

training_9477     5: 0.495874090166761   0: 0.304947618851059   8: 0.024905216013085   3: 0.024897119480498   4: 0.024896636396035   6: 0.024896019382927   2: 0.024895859896691   1: 0.024895849461018   7: 0.024895827609518   9: 0.024895762742406 

training_9478     4: 0.660398519728298   0: 0.124716652050159   2: 0.081544766993154   5: 0.019052494467982   6: 0.019050777908329   1: 0.019047811131502   9: 0.019047378272071   8: 0.019047288698094   7: 0.019047212253969   3: 0.019047098496440 

training_9479     6: 0.669316299786807   0: 0.162376796716869   3: 0.040075254880892   5: 0.030960702016053   8: 0.028581269338056   7: 0.026474378373397   1: 0.010568400281882   4: 0.010550574540735   9: 0.010548188082934   2: 0.010548135982375 

training_9484     0: 0.477707311019238   5: 0.364412284408209   9: 0.044813806124172   6: 0.016156114537223   1: 0.016152920931553   8: 0.016152685511616   4: 0.016151831391204   3: 0.016151398662764   2: 0.016150897704300   7: 0.016150749709720 

training_9486     4: 0.743440857914983   5: 0.065612044025286   7: 0.023871171001939   1: 0.023868755606052   6: 0.023868526597569   0: 0.023868190354433   8: 0.023867815538819   2: 0.023867693927809   3: 0.023867647082322   9: 0.023867297950788 

training_9487     6: 0.601690226528145   1: 0.186264805462404   0: 0.102691001524721   7: 0.015672592280503   5: 0.015620663661570   8: 0.015612324193068   4: 0.015612322052289   2: 0.015612167520671   9: 0.015611980893891   3: 0.015611915882738 

training_9488     2: 0.295712556407926   1: 0.283912463687655   5: 0.261828941937372   4: 0.062216958679674   7: 0.025282135293606   6: 0.014213542097270   0: 0.014210172816084   8: 0.014208814985804   9: 0.014208656341899   3: 0.014205757752711 

training_9489     6: 0.400292230350232   0: 0.375619390983711   5: 0.028015945744596   4: 0.028012662858531   1: 0.028011484692042   9: 0.028010253717482   7: 0.028009722702036   8: 0.028009670824238   2: 0.028009446582004   3: 0.028009191545130 

training_949      9: 0.598677425182952   2: 0.184721607106617   4: 0.027082604128978   5: 0.027080472269290   1: 0.027074199734322   8: 0.027073753485650   3: 0.027073709081496   0: 0.027072938424373   6: 0.027072330065528   7: 0.027070960520795 

training_9491     9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_9493     6: 0.754962824693502   0: 0.027234635088589   1: 0.027227137944724   9: 0.027226437171820   5: 0.027225384887403   7: 0.027225147283505   8: 0.027224817070125   4: 0.027224747949143   2: 0.027224658206371   3: 0.027224209704818 

training_9497     0: 0.457259150874193   5: 0.230592391604550   4: 0.138723535051203   1: 0.024776906957530   6: 0.024776802240250   2: 0.024774641869000   9: 0.024774400990929   8: 0.024774209387314   7: 0.024774154536568   3: 0.024773806488463 

training_9498     6: 0.595829500906352   0: 0.171319828581063   1: 0.114164307205119   5: 0.016956638932715   9: 0.016955507618836   2: 0.016955020277938   8: 0.016954918500114   7: 0.016954855806628   4: 0.016954780957915   3: 0.016954641213320 

training_9499     7: 0.394527271330352   6: 0.377002034065076   5: 0.028566885841806   1: 0.028564640679800   0: 0.028560735167059   4: 0.028557481052997   2: 0.028556314127301   3: 0.028555526679285   9: 0.028554726008958   8: 0.028554385047365 

training_95       8: 0.765475893272709   5: 0.026067474033478   4: 0.026063159219105   6: 0.026059254262525   9: 0.026056519428356   0: 0.026056013949380   1: 0.026055741998397   7: 0.026055712774429   2: 0.026055132380703   3: 0.026055098680919 

training_9502     5: 0.808975295446844   4: 0.021229826588000   8: 0.021225635819776   6: 0.021224434277387   0: 0.021224348759551   1: 0.021224203216766   7: 0.021224128211193   9: 0.021224126220582   2: 0.021224021448438   3: 0.021223980011463 

training_9503     5: 0.670165766913144   6: 0.137931677709537   2: 0.023989485898864   3: 0.023988090132904   4: 0.023987942935432   1: 0.023987589528672   0: 0.023987499414238   8: 0.023987403139607   7: 0.023987289678543   9: 0.023987254649059 

training_9505     6: 0.405016265139855   1: 0.370526818381963   8: 0.082247873370716   2: 0.044849764542568   5: 0.016235957128686   0: 0.016226114966262   4: 0.016224740757749   3: 0.016224497432070   9: 0.016224289066962   7: 0.016223679213169 

training_9509     6: 0.629827131941183   1: 0.234383686360324   3: 0.031124102894365   5: 0.027082627661313   0: 0.012945872363038   2: 0.012934959604504   9: 0.012927471579593   4: 0.012925221605735   8: 0.012924563997080   7: 0.012924361992865 

training_9510     0: 0.476215657338614   5: 0.208059868730907   8: 0.167788819342182   6: 0.021135947284629   1: 0.021134989908663   9: 0.021133447074160   7: 0.021133326904983   2: 0.021132845314781   4: 0.021132735471045   3: 0.021132362630036 

training_9511     4: 0.684819167207647   6: 0.035042081670626   8: 0.035024230270369   5: 0.035023298570720   1: 0.035019300193993   0: 0.035017849964715   7: 0.035014970989730   9: 0.035014681706275   3: 0.035012732013691   2: 0.035011687412233 

training_9515     6: 0.637517556971637   0: 0.245949600325704   1: 0.014567906272971   9: 0.014566731625739   8: 0.014566673178165   5: 0.014566488866241   7: 0.014566303846379   3: 0.014566278711419   2: 0.014566270200869   4: 0.014566190000876 

training_9519     5: 0.592254567697752   0: 0.110007046289300   4: 0.078032035765392   9: 0.046083070368902   8: 0.045399072030565   2: 0.041079149359799   7: 0.040741730600934   6: 0.015476408936043   1: 0.015464729789435   3: 0.015462189161877 

training_952      6: 0.741964839981338   1: 0.080869593781924   2: 0.070084175768782   0: 0.025800824176738   9: 0.013551914751984   5: 0.013548323053719   7: 0.013546340396941   4: 0.013544764228295   3: 0.013544649467425   8: 0.013544574392852 

training_9521     6: 0.648511060046898   7: 0.221073613377915   0: 0.052301473378683   8: 0.011168182036474   9: 0.011159779958168   1: 0.011158568037467   3: 0.011158031066460   5: 0.011157377495273   4: 0.011156216843174   2: 0.011155697759489 

training_9525     5: 0.732154062764943   1: 0.121705312669002   4: 0.018273162839402   6: 0.018268386912353   0: 0.018266868681380   7: 0.018266633890661   9: 0.018266565499632   8: 0.018266384995032   2: 0.018266318432788   3: 0.018266303314806 

training_9526     6: 0.405415381437041   7: 0.403743865868422   4: 0.048832886775233   8: 0.029938405102844   1: 0.019237321455334   5: 0.018572507212490   0: 0.018568371250810   2: 0.018564821264748   9: 0.018563417077832   3: 0.018563022555247 

training_9527     6: 0.753615958630913   1: 0.116860290706876   4: 0.016356405556688   9: 0.016179138754503   5: 0.016171415746120   3: 0.016164468650401   0: 0.016164157695412   2: 0.016162917106047   8: 0.016162728221753   7: 0.016162518931289 

training_953      9: 0.712307297126857   6: 0.129656667765728   8: 0.019758956042752   3: 0.019755448416954   5: 0.019754498605194   0: 0.019753950017205   1: 0.019753645069230   4: 0.019753392808452   2: 0.019753179101506   7: 0.019752965046122 

training_9530     5: 0.794122118591839   6: 0.022878489676309   0: 0.022876384353943   1: 0.022875383562031   3: 0.022875040828500   4: 0.022874853850156   7: 0.022874553469062   2: 0.022874429286499   8: 0.022874402551154   9: 0.022874343830508 

training_9531     5: 0.586795671932196   0: 0.168817454301662   3: 0.092298841971788   1: 0.021728410549368   6: 0.021727650092343   8: 0.021727172048224   4: 0.021726684819712   7: 0.021726077242043   2: 0.021726020866399   9: 0.021726016176265 

training_9532     6: 0.709901235510769   0: 0.105896962159807   1: 0.072489052536943   8: 0.040018983347142   2: 0.016695433799800   4: 0.011004362096617   7: 0.010999003353452   5: 0.010998524799681   3: 0.010998307310510   9: 0.010998135085278 

training_9534     0: 0.724691704516911   6: 0.030599002464983   1: 0.030594413630678   8: 0.030588941178639   9: 0.030588253348030   7: 0.030587979913095   5: 0.030587905328661   2: 0.030587340675355   3: 0.030587268891708   4: 0.030587190051940 

training_9535     6: 0.563104736772662   0: 0.327636490934640   1: 0.024453605468638   5: 0.012115545984971   7: 0.012115213325643   9: 0.012115067851278   4: 0.012114983126296   8: 0.012114874677579   2: 0.012114759583775   3: 0.012114722274517 

training_9538     5: 0.409493836938344   6: 0.407094608377271   0: 0.047805837088748   7: 0.019388057282907   8: 0.019372830383706   1: 0.019372793282865   4: 0.019368472342764   2: 0.019368016628140   9: 0.019367922945572   3: 0.019367624729683 

training_9539     1: 0.429967500366250   4: 0.267062895578185   5: 0.168605288635016   6: 0.019198406756290   0: 0.019197368025588   9: 0.019194692687434   8: 0.019194200394955   2: 0.019193488604912   7: 0.019193306429078   3: 0.019192852522293 

training_9543     6: 0.493555638968789   4: 0.347187396761390   1: 0.033658810169781   0: 0.024637516161069   5: 0.017637917547121   9: 0.016677161119632   7: 0.016661770901373   8: 0.016661583548660   2: 0.016661125402393   3: 0.016661079419791 

training_9544     1: 0.442532833301681   4: 0.229825433847441   0: 0.184216451671651   3: 0.042151896912500   8: 0.016888439074382   6: 0.016881720983419   5: 0.016879750811158   2: 0.016876204585064   7: 0.016873674128298   9: 0.016873594684406 

training_9547     5: 0.689725106471822   3: 0.122235239038880   2: 0.023509205971177   6: 0.023505963023393   9: 0.023505745563148   4: 0.023504550981446   1: 0.023503891895857   0: 0.023503877084682   7: 0.023503230206836   8: 0.023503189762760 

training_9549     6: 0.315876824711669   0: 0.265234221668728   4: 0.237862747353351   5: 0.100481405132703   1: 0.014193169706857   3: 0.013323544601200   8: 0.013259688283876   9: 0.013256878566040   2: 0.013256365378827   7: 0.013255154596748 

training_955      6: 0.767918801824000   1: 0.086810229326322   7: 0.067393771688284   4: 0.019809245003842   0: 0.009680317530545   5: 0.009679155532452   9: 0.009677658851083   8: 0.009677296359737   3: 0.009676787892348   2: 0.009676735991388 

training_9550     6: 0.577168017164925   0: 0.268489123807158   8: 0.042547088788465   5: 0.015973493073015   4: 0.015971638641180   1: 0.015970859829947   9: 0.015970099534338   2: 0.015970009399006   7: 0.015969930703170   3: 0.015969739058797 

training_9551     9: 0.318723450624390   5: 0.294443914021070   6: 0.245974567744642   4: 0.020123883612333   1: 0.020123180245478   3: 0.020122978419253   0: 0.020122371114367   8: 0.020121979915864   2: 0.020121867570051   7: 0.020121806732553 

training_9554     6: 0.774452824913021   1: 0.088655384262796   2: 0.032219069508199   8: 0.021816665117324   9: 0.020945072118942   0: 0.012384309765131   5: 0.012382191270139   7: 0.012381608945141   4: 0.012381469634838   3: 0.012381404464470 

training_9556     5: 0.816478129532559   4: 0.020393177126396   1: 0.020392284035490   6: 0.020391932585579   0: 0.020391469563851   8: 0.020391283317110   9: 0.020390541886660   7: 0.020390521991950   2: 0.020390372996456   3: 0.020390286963947 

training_9557     1: 0.413552628707269   5: 0.359604373959053   2: 0.049829837466051   6: 0.025290423461986   0: 0.025288557264095   7: 0.025287324499323   4: 0.025287057811670   9: 0.025286819076413   8: 0.025286636175130   3: 0.025286341579009 

training_9558     5: 0.653977159621140   7: 0.153124037608625   4: 0.024115614024123   0: 0.024112014407817   3: 0.024111948448735   6: 0.024111924442098   8: 0.024111902889099   1: 0.024111830722837   2: 0.024111796876644   9: 0.024111770958882 

training_9559     6: 0.801947296776949   0: 0.058011615476931   8: 0.046673831782234   1: 0.013343574189171   3: 0.013339915524786   5: 0.013337208602210   2: 0.013336947497751   7: 0.013336579362349   9: 0.013336525319072   4: 0.013336505468547 

training_9560     6: 0.574286204994031   4: 0.245836091079316   1: 0.066928535240577   0: 0.016150101760624   5: 0.016138103255924   7: 0.016133839694369   9: 0.016132273204409   8: 0.016131959300193   3: 0.016131569054796   2: 0.016131322415760 

training_9561     6: 0.469336307341027   1: 0.290052026225576   5: 0.100036662467301   9: 0.041041525210993   4: 0.016590038204046   0: 0.016589884692987   2: 0.016588692712259   3: 0.016588417837333   8: 0.016588269602087   7: 0.016588175706390 

training_9562     5: 0.635673700348369   9: 0.210134436755942   8: 0.019280138928228   4: 0.019276415898331   6: 0.019273971864893   0: 0.019273206809729   1: 0.019272648555807   2: 0.019271926688658   7: 0.019271872528624   3: 0.019271681621419 

training_9563     5: 0.448978673601443   9: 0.384935158953742   6: 0.020768938136234   8: 0.020767718467314   0: 0.020762736499101   1: 0.020760914599224   4: 0.020757057530976   2: 0.020756729566465   7: 0.020756324702061   3: 0.020755747943441 

training_9565     1: 0.621808549753377   0: 0.158948705642851   6: 0.027415668204804   8: 0.027404770087010   5: 0.027404546838348   4: 0.027403766730516   9: 0.027403671419283   7: 0.027403552646235   2: 0.027403412209464   3: 0.027403356468112 

training_9566     4: 0.787424349966425   5: 0.023624399133052   8: 0.023619272527222   0: 0.023618908202921   1: 0.023618881883698   9: 0.023618880677799   3: 0.023618854006387   6: 0.023618853248872   2: 0.023618804738638   7: 0.023618795614987 

training_9570     1: 0.758522445394552   6: 0.075180558123145   0: 0.020788012098916   5: 0.020787940053409   9: 0.020787230359014   4: 0.020787097779717   7: 0.020786749197346   2: 0.020786742515107   3: 0.020786694275101   8: 0.020786530203693 

training_9572     5: 0.783475675673524   1: 0.024062666192497   4: 0.024061934441750   3: 0.024057596730453   6: 0.024057521403618   0: 0.024057433427171   8: 0.024056885886046   9: 0.024056781136744   7: 0.024056776799873   2: 0.024056728308324 

training_9573     6: 0.552199902247202   9: 0.258692962237450   5: 0.023641405516478   1: 0.023639496982461   2: 0.023639025625797   4: 0.023639002975128   0: 0.023637716798103   8: 0.023637549655957   3: 0.023636635210936   7: 0.023636302750489 

training_9576     4: 0.724336883080016   5: 0.030642488321311   8: 0.030628437006777   9: 0.030627799281696   3: 0.030627628551506   2: 0.030627486592410   7: 0.030627432895989   6: 0.030627322411649   1: 0.030627263648450   0: 0.030627258210196 

training_9577     5: 0.772236815169339   4: 0.025307844640803   6: 0.025307674986736   1: 0.025307290005021   0: 0.025306964430733   3: 0.025306862097920   8: 0.025306720170526   9: 0.025306654363088   7: 0.025306644861069   2: 0.025306529274765 

training_9578     5: 0.769949813198810   4: 0.025562142369673   3: 0.025561358746012   0: 0.025561284188929   1: 0.025560936897951   2: 0.025560930791027   6: 0.025560917188462   7: 0.025560899499763   8: 0.025560865498950   9: 0.025560851620424 

training_958      9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_9580     5: 0.605894963201576   0: 0.190939114426338   4: 0.025396948244502   3: 0.025396234264771   2: 0.025395518572221   6: 0.025395495874401   1: 0.025395478517138   7: 0.025395450363550   8: 0.025395410049503   9: 0.025395386486001 

training_9582     6: 0.473309998248924   1: 0.410360803339533   0: 0.034883814082563   8: 0.027056064765309   9: 0.009081921054413   5: 0.009069807345254   3: 0.009063462247185   2: 0.009059044933487   4: 0.009057663306282   7: 0.009057420677050 

training_9583     6: 0.426295344279859   1: 0.414206614388114   9: 0.063205506775728   2: 0.020825156647397   0: 0.013794570393986   7: 0.012520388576792   5: 0.012289482406631   4: 0.012289087400993   8: 0.012287570366676   3: 0.012286278763824 

training_9585     6: 0.730616257360783   3: 0.130660651450056   8: 0.032441699493021   5: 0.015476951273281   7: 0.015222158950631   4: 0.015119753778923   0: 0.015116742655142   9: 0.015115505225423   1: 0.015115427451883   2: 0.015114852360857 

training_9587     5: 0.688398280153293   3: 0.110791421094478   7: 0.025112810946353   6: 0.025100456368710   4: 0.025099821034491   0: 0.025099648269006   2: 0.025099421005935   1: 0.025099410462161   9: 0.025099365504763   8: 0.025099365160810 

training_9588     5: 0.776770858125269   8: 0.024804516246455   3: 0.024804093287935   4: 0.024803226670192   6: 0.024803200107037   0: 0.024803059510373   1: 0.024802826302978   7: 0.024802792969276   2: 0.024802750456159   9: 0.024802676324327 

training_9590     6: 0.439118969062962   0: 0.168237174209708   2: 0.144861733191164   7: 0.137941120266919   5: 0.032588537862147   1: 0.024001348719898   8: 0.013370808221506   4: 0.013296694968554   9: 0.013292154710320   3: 0.013291458786823 

training_9592     6: 0.819043586228649   0: 0.056066177168227   2: 0.031222513539487   1: 0.013388690332392   5: 0.013382917998115   7: 0.013380317589312   9: 0.013379138958317   4: 0.013378976708740   8: 0.013378921851742   3: 0.013378759625018 

training_9597     3: 0.500364223839381   1: 0.272809239860902   0: 0.028356180219005   5: 0.028354900699003   6: 0.028354611894155   4: 0.028353351170854   2: 0.028353209238464   7: 0.028351554693918   9: 0.028351513657715   8: 0.028351214726604 

training_9598     5: 0.695595095282698   4: 0.033830923296280   0: 0.033822166328392   3: 0.033821772470101   8: 0.033821766169108   1: 0.033821733336022   6: 0.033821725256614   2: 0.033821713918876   7: 0.033821581787577   9: 0.033821522154333 

training_9599     5: 0.802572903423697   1: 0.021939413295482   6: 0.021937932727828   0: 0.021936955647954   7: 0.021935998017516   4: 0.021935753188095   9: 0.021935650718380   8: 0.021935218870411   2: 0.021935188803580   3: 0.021934985307056 

training_96       1: 0.642491843792374   7: 0.205523992483329   5: 0.019005719601261   4: 0.018998788919079   6: 0.018997962418200   8: 0.018997694399552   0: 0.018997129246521   9: 0.018996518589322   2: 0.018995452091449   3: 0.018994898458914 

training_960      0: 0.460950456756571   3: 0.223904217172804   6: 0.203809237060085   4: 0.015969696687215   8: 0.015913797622312   2: 0.015900963098629   5: 0.015896959520702   1: 0.015889148467454   7: 0.015882783254659   9: 0.015882740359569 

training_9600     6: 0.390645954453877   0: 0.276810862453194   5: 0.148514140176823   1: 0.026299277820853   4: 0.026293705918792   8: 0.026290629252302   9: 0.026289340593591   7: 0.026286594182348   2: 0.026284810162796   3: 0.026284684985424 

training_9603     6: 0.644618525762706   1: 0.226413195337452   0: 0.016126395501783   5: 0.016121379928496   9: 0.016120551457735   7: 0.016120192899826   4: 0.016120117497473   8: 0.016120071631783   2: 0.016119816892178   3: 0.016119753090567 

training_9604     6: 0.823355527908683   1: 0.075038074870619   2: 0.012702109069852   5: 0.012701536392729   0: 0.012701046542438   8: 0.012700644783043   9: 0.012700408097951   4: 0.012700261417721   7: 0.012700237602277   3: 0.012700153314686 

training_9605     5: 0.686312015710976   4: 0.075158165857199   3: 0.066381293420023   7: 0.056920403880911   1: 0.019205232829437   6: 0.019205213025436   8: 0.019204664341234   0: 0.019204466744550   9: 0.019204339571110   2: 0.019204204619124 

training_9606     5: 0.439880423684070   8: 0.375714692847465   6: 0.023055124845705   4: 0.023051445061262   0: 0.023051411644375   7: 0.023050089937090   1: 0.023049660710594   9: 0.023049554343047   2: 0.023048913446143   3: 0.023048683480247 

training_9607     0: 0.415754718072945   6: 0.226440860235540   3: 0.220997754219648   1: 0.031561812074293   5: 0.030371724699964   4: 0.028496263752119   7: 0.011810671622257   9: 0.011719909390855   8: 0.011423325874166   2: 0.011422960058214 

training_9608     3: 0.450563091998617   5: 0.217906495991836   0: 0.125259102720001   7: 0.082973419955385   6: 0.020573799723669   1: 0.020552545353613   9: 0.020544058870290   4: 0.020542807652166   8: 0.020542608648971   2: 0.020542069085453 

training_9610     4: 0.725390417531270   2: 0.081651179134011   5: 0.024125725654838   6: 0.024119934263966   9: 0.024119329133826   8: 0.024118790932492   0: 0.024118713278517   1: 0.024118696527474   7: 0.024118624334341   3: 0.024118589209265 

training_9611     4: 0.783560310576017   5: 0.024053871959396   6: 0.024049100721104   1: 0.024048614409300   0: 0.024048512254875   8: 0.024048239270569   9: 0.024047980449097   3: 0.024047839460135   2: 0.024047796705521   7: 0.024047734193986 

training_9612     5: 0.477743808730113   4: 0.327340666882817   3: 0.024366170180558   6: 0.024364397476745   0: 0.024364276724005   8: 0.024364263949698   1: 0.024364221069850   7: 0.024364185735354   2: 0.024364071721488   9: 0.024363937529372 

training_9613     5: 0.679765916625703   9: 0.123853702962749   8: 0.024553178976754   4: 0.024547411625840   3: 0.024547129055832   1: 0.024546649787267   6: 0.024546585998222   2: 0.024546491428714   0: 0.024546472825432   7: 0.024546460713487 

training_9614     2: 0.565507212289541   7: 0.203573794664871   5: 0.028873866493367   4: 0.028866439846299   9: 0.028864475623370   1: 0.028863367685584   6: 0.028863195208721   8: 0.028863013402053   0: 0.028862656913395   3: 0.028861977872798 

training_9615     6: 0.446054323612931   5: 0.287262042281981   4: 0.099319801332201   0: 0.050084180399574   1: 0.019552606182765   7: 0.019547199110728   9: 0.019546185607090   8: 0.019544893138434   3: 0.019544410742669   2: 0.019544357591629 

training_9617     6: 0.794092633478897   1: 0.075512028290849   5: 0.037309939545871   3: 0.016322000854232   0: 0.012833774846469   7: 0.012792922012874   8: 0.012788040233799   9: 0.012783072148676   4: 0.012782803682395   2: 0.012782784905939 

training_9618     1: 0.465652188192446   5: 0.311640362353949   0: 0.096306686153001   6: 0.018060290513419   2: 0.018057170049354   9: 0.018057101407828   4: 0.018056829777355   7: 0.018056729565219   8: 0.018056354514587   3: 0.018056287472843 

training_9619     4: 0.599068631201390   6: 0.177755042251302   7: 0.060761859881036   1: 0.023212932145944   0: 0.023203853573622   5: 0.023203098604059   9: 0.023199894276647   8: 0.023198355092534   3: 0.023198230850317   2: 0.023198102123149 

training_9625     5: 0.637054261366645   9: 0.201432167438810   4: 0.020192925050755   6: 0.020189974713253   3: 0.020188938162606   8: 0.020188684662451   7: 0.020188400780984   2: 0.020188288582194   0: 0.020188233372209   1: 0.020188125870092 

training_9626     5: 0.621924762459078   0: 0.157510598685274   6: 0.027572779065234   1: 0.027571440958721   9: 0.027570921186967   8: 0.027570190538012   4: 0.027570022738017   2: 0.027569860961273   7: 0.027569774565266   3: 0.027569648842159 

training_9628     6: 0.765439874496946   0: 0.095755258900461   1: 0.044784452271236   7: 0.013433659204462   5: 0.013432094525973   4: 0.013431886795280   8: 0.013430756491735   2: 0.013430749088305   9: 0.013430689173121   3: 0.013430579052482 

training_963      1: 0.611366432722419   2: 0.208655976888864   0: 0.049881323527046   5: 0.018595680189602   4: 0.018589638664348   6: 0.018587402642855   9: 0.018581769348825   3: 0.018580845592934   8: 0.018580653336039   7: 0.018580277087068 

training_9634     6: 0.618762419620426   7: 0.243645900092833   2: 0.017202879643525   9: 0.017202443110770   5: 0.017201097179996   4: 0.017199044838481   8: 0.017197341767626   0: 0.017196844834993   1: 0.017196433841438   3: 0.017195595069912 

training_9635     5: 0.568238629278642   6: 0.131003313135746   8: 0.117956187374660   1: 0.026118678317684   2: 0.026118283471724   0: 0.026116167185838   9: 0.026114508585494   7: 0.026112292923801   4: 0.026111168369162   3: 0.026110771357250 

training_9637     9: 0.337386417817786   5: 0.241718657759367   6: 0.179493673011027   1: 0.122267488497945   0: 0.057860543204054   8: 0.012262407775430   7: 0.012256290205277   4: 0.012252058829253   2: 0.012251283503296   3: 0.012251179396566 

training_9638     1: 0.390644127989409   0: 0.284568756687332   6: 0.168860175669441   2: 0.075572048527981   9: 0.020684838254613   3: 0.020663838683623   5: 0.009752072715710   4: 0.009751885298267   7: 0.009751442237494   8: 0.009750813936131 

training_9639     6: 0.454650273018656   2: 0.363163997216329   0: 0.081580682878518   4: 0.021721050851941   5: 0.013159165940502   3: 0.013149901293377   9: 0.013144852151097   1: 0.013143723868355   7: 0.013143441838574   8: 0.013142910942652 

training_9640     1: 0.479401485891492   5: 0.370784420003909   8: 0.034733806758217   6: 0.016445518709401   0: 0.016440995534175   7: 0.016440976638171   2: 0.016440792354805   9: 0.016437621902423   4: 0.016437520141214   3: 0.016436862066191 

training_9641     6: 0.334246471274344   5: 0.329245988370378   0: 0.240208529865188   1: 0.013760171509097   9: 0.013758913472531   4: 0.013756758191611   8: 0.013755962858876   7: 0.013755836159554   2: 0.013755735461296   3: 0.013755632837125 

training_9642     6: 0.383901491505060   5: 0.306713130698473   0: 0.173424472753514   1: 0.019426058364756   2: 0.019423738900657   4: 0.019422944416900   9: 0.019422855501148   7: 0.019421947020609   3: 0.019421902548484   8: 0.019421458290399 

training_9644     1: 0.749541128700116   5: 0.052050289334125   4: 0.024829176402703   6: 0.024817678118605   0: 0.024805138914778   2: 0.024795713265917   8: 0.024793104798340   9: 0.024789672063598   3: 0.024789276869154   7: 0.024788821532664 

training_9647     4: 0.615410653444452   6: 0.206927075296066   5: 0.022213548197576   0: 0.022207120709892   8: 0.022207012706393   1: 0.022207004597941   3: 0.022206960874257   2: 0.022206903181045   9: 0.022206883799249   7: 0.022206837193128 

training_9650     6: 0.505339631217254   1: 0.291424681265857   9: 0.106129507212213   2: 0.027989659165773   0: 0.011523140004207   4: 0.011522016452541   5: 0.011519586590598   8: 0.011518298055366   7: 0.011517421904608   3: 0.011516058131583 

training_9652     4: 0.712722274079058   5: 0.083945738793306   0: 0.025431803837377   3: 0.025423824823308   2: 0.025417296923623   8: 0.025412295851907   1: 0.025412096325184   6: 0.025411590716145   7: 0.025411575734689   9: 0.025411502915404 

training_9654     6: 0.814036115714707   0: 0.053177442018031   1: 0.016600345060558   8: 0.016598849629752   5: 0.016598322025068   7: 0.016598127179157   2: 0.016597819989674   9: 0.016597721280462   3: 0.016597683924959   4: 0.016597573177633 

training_9656     6: 0.841080332775895   1: 0.048566164935144   0: 0.035914632636032   5: 0.010637772753227   8: 0.010633805494930   9: 0.010633684579592   4: 0.010633676650496   3: 0.010633662352273   7: 0.010633223346997   2: 0.010633044475414 

training_9657     6: 0.761225785747497   0: 0.096722871943898   1: 0.046936951726870   7: 0.013589948444699   5: 0.013588399357416   4: 0.013588065738487   8: 0.013587069012947   2: 0.013587044340384   9: 0.013586991039077   3: 0.013586872648725 

training_9661     5: 0.517968893808827   8: 0.289064996735859   1: 0.024136033172885   6: 0.024128976401092   0: 0.024125271820692   2: 0.024115681390230   4: 0.024115422203331   9: 0.024115120653716   7: 0.024114974543387   3: 0.024114629269981 

training_9667     6: 0.618966150819979   8: 0.147877568991081   0: 0.130306560570564   1: 0.025478087514635   2: 0.018796348320685   7: 0.015508951603128   5: 0.011728733021937   3: 0.010627373538272   9: 0.010359438053630   4: 0.010350787566090 

training_9668     2: 0.357770922842772   0: 0.352994664975395   9: 0.158559843861101   5: 0.018859420507922   6: 0.018641498874955   1: 0.018638928783524   4: 0.018634027266797   3: 0.018633872622769   7: 0.018633444143636   8: 0.018633376121129 

training_9671     5: 0.766735216995937   3: 0.025918785653831   4: 0.025918695802320   6: 0.025918529986022   1: 0.025918383397387   0: 0.025918275430215   2: 0.025918038674159   9: 0.025918030993439   8: 0.025918030659081   7: 0.025918012407610 

training_9674     6: 0.758384797589264   0: 0.105201508203118   7: 0.051728587431883   8: 0.012152581780619   1: 0.012090103964719   3: 0.012089297844877   5: 0.012088779239973   9: 0.012088216509349   4: 0.012088200364431   2: 0.012087927071770 

training_9675     6: 0.814664811117201   5: 0.020598774935122   4: 0.020594710034629   8: 0.020593836076053   0: 0.020592673115896   9: 0.020592483243497   1: 0.020591167658990   7: 0.020590771526055   2: 0.020590427740717   3: 0.020590344551840 

training_9677     2: 0.761791340498541   1: 0.026477432928295   5: 0.026476776884094   6: 0.026472296350168   0: 0.026470640221510   4: 0.026464937516645   8: 0.026462100116111   9: 0.026462079396964   3: 0.026461557750766   7: 0.026460838336906 

training_9678     5: 0.441800811712457   1: 0.379831352546052   4: 0.022312202671077   8: 0.022294097474260   6: 0.022293972393139   0: 0.022293930805446   9: 0.022293521278847   3: 0.022293425915738   2: 0.022293380072806   7: 0.022293305130178 

training_968      5: 0.694423059588434   4: 0.134036556208796   6: 0.021443997313491   7: 0.021442832220177   9: 0.021442668564961   8: 0.021442328859222   0: 0.021442198874326   1: 0.021442154140166   3: 0.021442123020583   2: 0.021442081209844 

training_9680     6: 0.780435797219487   1: 0.050400154649103   7: 0.050399238124618   3: 0.032850001409798   5: 0.014319909465993   0: 0.014319785428616   8: 0.014318866825396   4: 0.014318783347919   9: 0.014318740148652   2: 0.014318723380417 

training_9681     6: 0.822535280707924   0: 0.063233039025711   5: 0.014281385041957   3: 0.014279184157467   9: 0.014279163798153   1: 0.014278919551194   8: 0.014278781396421   7: 0.014278214362684   4: 0.014278102451643   2: 0.014277929506847 

training_9682     5: 0.821962116440783   0: 0.019784358081270   1: 0.019783748622336   4: 0.019783409847682   8: 0.019781227494528   6: 0.019781226925406   3: 0.019781065844046   7: 0.019780975485761   2: 0.019780950255859   9: 0.019780921002330 

training_9686     6: 0.762682310602438   0: 0.026375279224873   1: 0.026368795344991   9: 0.026368027406751   7: 0.026367754344427   8: 0.026367720300782   2: 0.026367689350196   5: 0.026367524029341   3: 0.026367471837312   4: 0.026367427558890 

training_9689     6: 0.648440023442682   0: 0.244816548252237   1: 0.034041795081979   4: 0.010386321416956   5: 0.010386235311083   7: 0.010385971940705   8: 0.010385943116653   9: 0.010385870844388   2: 0.010385709997179   3: 0.010385580596138 

training_969      6: 0.548557221861071   1: 0.352415566988452   9: 0.012379264603913   0: 0.012379037045966   8: 0.012378586789143   5: 0.012378478001251   7: 0.012378154881204   3: 0.012378132562780   4: 0.012377812703784   2: 0.012377744562436 

training_9697     6: 0.553554942437659   0: 0.305285811333099   5: 0.017646952404455   1: 0.017646761374477   4: 0.017645157790390   9: 0.017644710276000   8: 0.017644407361519   7: 0.017644002451560   2: 0.017643836825620   3: 0.017643417745220 

training_9698     1: 0.466636225652569   6: 0.305848569601613   9: 0.028442142414754   0: 0.028441996573113   7: 0.028439077326419   5: 0.028438774254190   8: 0.028438679191271   3: 0.028438214626813   2: 0.028438190288409   4: 0.028438130070848 

training_9699     1: 0.391845048661020   6: 0.381580163035146   0: 0.028331690513515   5: 0.028320707674921   9: 0.028320617343099   7: 0.028320429111177   3: 0.028320394486602   8: 0.028320333163545   2: 0.028320319317064   4: 0.028320296693910 

training_97       5: 0.281804666716564   8: 0.199770983116852   6: 0.182203762847211   0: 0.175581900449558   7: 0.067409754580384   1: 0.032828800007128   9: 0.024326308102022   2: 0.012025006976549   3: 0.012024566424631   4: 0.012024250779101 

training_9700     6: 0.731618198677235   5: 0.103517237275611   7: 0.035765096447842   8: 0.018473165063333   9: 0.018442881962704   0: 0.018437855559967   1: 0.018436571586551   4: 0.018436537438992   2: 0.018436264697268   3: 0.018436191290497 

training_9701     6: 0.695060998078630   1: 0.154340718196638   0: 0.065915192058408   9: 0.019253842956281   7: 0.011087981222689   3: 0.010881814363733   5: 0.010875381310307   4: 0.010862562167017   8: 0.010861187004813   2: 0.010860322641484 

training_9704     6: 0.778995285635741   0: 0.111937809437557   1: 0.019463022948251   9: 0.012801119694293   7: 0.012800987356779   5: 0.012800546445346   3: 0.012800518334502   8: 0.012800291802372   4: 0.012800254761998   2: 0.012800163583160 

training_9705     6: 0.605772287706451   8: 0.171945493463148   2: 0.105545212982555   0: 0.016680307691113   5: 0.016677826090814   1: 0.016677226663354   9: 0.016676113097594   3: 0.016675871356244   7: 0.016674832127343   4: 0.016674828821382 

training_9706     0: 0.555298384678510   6: 0.322408487710749   7: 0.015834978033910   5: 0.015211460869153   4: 0.015209272708272   1: 0.015208372024035   2: 0.015208176330913   9: 0.015206989319422   8: 0.015206953455718   3: 0.015206924869319 

training_9707     0: 0.564511064657923   5: 0.251016775197643   6: 0.041688960053164   1: 0.020400056958034   4: 0.020398473036560   3: 0.020397359260166   9: 0.020397280013282   8: 0.020397113673725   7: 0.020396602932666   2: 0.020396314216837 

training_971      6: 0.578352419358734   2: 0.117167257505097   1: 0.116058857795920   5: 0.108075571272143   9: 0.013394861952202   0: 0.013391671653990   8: 0.013390411238001   4: 0.013389998549153   7: 0.013389501496692   3: 0.013389449178068 

training_9712     6: 0.694775715447545   1: 0.190113624614909   0: 0.014390851989952   5: 0.014389020228919   8: 0.014388696433558   9: 0.014388601020730   7: 0.014388459619593   4: 0.014388422812844   2: 0.014388316378374   3: 0.014388291453575 

training_9718     6: 0.655935018271449   1: 0.195868447540504   3: 0.042442836231369   5: 0.015124177377378   0: 0.015106119807498   4: 0.015105334436341   2: 0.015104720509523   8: 0.015104615602982   7: 0.015104546725921   9: 0.015104183497034 

training_972      9: 0.624795036158924   5: 0.165711604896201   6: 0.026192997041169   8: 0.026187197216778   7: 0.026186578147707   4: 0.026186200525639   0: 0.026186030756515   1: 0.026185768446118   2: 0.026184449320525   3: 0.026184137490425 

training_9720     6: 0.836777106270233   0: 0.047012090609273   1: 0.014539456454047   5: 0.014524963059680   9: 0.014524522582913   8: 0.014524514822558   3: 0.014524402612409   7: 0.014524398430047   2: 0.014524286120111   4: 0.014524259038730 

training_9723     0: 0.490338700081847   3: 0.289587462631838   5: 0.027522374468809   4: 0.027517205334017   6: 0.027509776896237   1: 0.027508286711228   9: 0.027506350014194   8: 0.027505375096130   2: 0.027502356353792   7: 0.027502112411909 

training_9727     6: 0.757544567308741   9: 0.026944576530598   8: 0.026941892778581   0: 0.026939871854826   1: 0.026939679935636   7: 0.026939101647908   4: 0.026937691783110   3: 0.026937653834343   5: 0.026937493221532   2: 0.026937471104727 

training_9728     6: 0.430062587326019   5: 0.369239228586799   3: 0.051896791141531   0: 0.021263776088128   1: 0.021261757445413   4: 0.021255741354715   9: 0.021255713167559   8: 0.021255157740566   7: 0.021254775741484   2: 0.021254471407786 

training_9729     6: 0.760686327526738   0: 0.091286401082528   5: 0.018506397048537   1: 0.018506352630793   7: 0.018503114618283   9: 0.018503048626992   8: 0.018502577739566   4: 0.018502248937238   3: 0.018501823891392   2: 0.018501707897932 

training_9730     6: 0.794202942424623   0: 0.094728639390703   3: 0.027307826039728   9: 0.011967840279107   8: 0.011966146875600   1: 0.011965917857137   5: 0.011965908579013   7: 0.011965039051347   4: 0.011964891257726   2: 0.011964848245016 

training_9731     9: 0.754791087087731   5: 0.027250784680759   6: 0.027250658153672   1: 0.027249372953116   0: 0.027248447744577   4: 0.027245460521746   7: 0.027243115281377   2: 0.027241928616960   8: 0.027240324992417   3: 0.027238819967646 

training_9733     6: 0.449914966138872   0: 0.182859023807449   9: 0.179934079593921   1: 0.126133752540258   7: 0.010203680635812   5: 0.010195032499316   4: 0.010191962935548   8: 0.010191282572285   2: 0.010189451161279   3: 0.010186768115260 

training_9734     6: 0.568019819819140   3: 0.218907444792087   5: 0.118954502063422   0: 0.013447642850716   1: 0.013447423097472   7: 0.013446061225337   2: 0.013445752431528   4: 0.013444709308955   9: 0.013444186256707   8: 0.013442458154636 

training_9735     6: 0.583150884407760   3: 0.199412454926675   9: 0.027185620513979   8: 0.027184303564959   0: 0.027179917045079   7: 0.027179910490371   1: 0.027177470147605   5: 0.027176646267838   2: 0.027176606761353   4: 0.027176185874380 

training_9736     6: 0.833712291841178   0: 0.035869875883254   4: 0.027110602211318   7: 0.025657504355058   1: 0.012955083150073   5: 0.012951865681911   8: 0.012936657709374   9: 0.012935689671644   3: 0.012935214806781   2: 0.012935214689409 

training_9737     6: 0.309566800912302   4: 0.270437846784840   9: 0.247805319465346   1: 0.024604435043988   0: 0.024599924461407   5: 0.024599759085871   7: 0.024597203905978   2: 0.024597087797605   8: 0.024596089508675   3: 0.024595533033989 

training_9738     6: 0.589564963593142   5: 0.190648425249710   2: 0.080411193142072   0: 0.045995048995084   9: 0.015577562121055   7: 0.015565845882608   1: 0.015560671681132   8: 0.015560198327166   3: 0.015558167894854   4: 0.015557923113177 

training_974      6: 0.650267954292232   9: 0.239589387136446   7: 0.013772220006203   0: 0.013768640816696   1: 0.013768444437393   5: 0.013768028305448   8: 0.013766784126799   4: 0.013766484475010   2: 0.013766127879892   3: 0.013765928523880 

training_9741     5: 0.445669469237158   3: 0.343097954364950   1: 0.079911885788969   9: 0.018763012253328   6: 0.018762328373838   8: 0.018762002715998   0: 0.018760466998201   4: 0.018759466653884   7: 0.018756838555558   2: 0.018756575058115 

training_9742     6: 0.391788679760363   0: 0.273888139120440   1: 0.221793760619221   4: 0.033235871830361   8: 0.020391489046388   5: 0.011790088251188   9: 0.011781932886587   3: 0.011776917259576   7: 0.011776658731057   2: 0.011776462494820 

training_9744     5: 0.446461990211448   1: 0.376840229712160   6: 0.022090742459308   4: 0.022088959498982   8: 0.022087682604338   0: 0.022086562290575   9: 0.022086342058149   7: 0.022086223914362   3: 0.022085689188165   2: 0.022085578062513 

training_9745     9: 0.694724118342056   6: 0.173001588008134   5: 0.016535573396798   0: 0.016535029090218   8: 0.016534760013294   1: 0.016534695760056   4: 0.016534173461402   2: 0.016533439932972   3: 0.016533327017805   7: 0.016533294977266 

training_9746     6: 0.773801489404828   0: 0.118281558461673   1: 0.013491059623512   5: 0.013490705903831   7: 0.013489625776662   9: 0.013489519015955   2: 0.013489468482736   8: 0.013489433635499   3: 0.013488588736839   4: 0.013488550958465 

training_9747     6: 0.606302951488048   5: 0.185302220855462   4: 0.026053644296054   0: 0.026052503771547   9: 0.026051759750567   8: 0.026050425425282   7: 0.026047435380937   1: 0.026046863480675   2: 0.026046184187147   3: 0.026046011364281 

training_9748     6: 0.661848499649261   5: 0.117940777629871   4: 0.027537129188023   9: 0.027529933250190   0: 0.027528695717210   8: 0.027526147897568   7: 0.027522953543020   1: 0.027522389858696   2: 0.027521875189331   3: 0.027521598076830 

training_9749     6: 0.824129604126761   0: 0.065032257565637   9: 0.017328173565001   1: 0.013363034781302   5: 0.013359422273460   8: 0.013358240703855   7: 0.013358041683228   4: 0.013357281432794   3: 0.013356986739633   2: 0.013356957128329 

training_9751     6: 0.746202323586248   7: 0.087322595644938   0: 0.058740769831216   1: 0.015394019698275   5: 0.015391540035203   9: 0.015391052222933   4: 0.015389914132337   8: 0.015389360622014   2: 0.015389332599078   3: 0.015389091627758 

training_9752     6: 0.694094108048497   0: 0.098116924606699   9: 0.096008682832400   1: 0.015972285013444   5: 0.015972211716301   8: 0.015969196422989   4: 0.015967543992957   7: 0.015966452490853   2: 0.015966338482799   3: 0.015966256393060 

training_9753     6: 0.770105867445928   7: 0.081408773315154   1: 0.018561811905755   8: 0.018561279620670   0: 0.018561060610317   9: 0.018560818266453   5: 0.018560528282450   2: 0.018559987446089   4: 0.018559955024245   3: 0.018559918082939 

training_9754     6: 0.644362753609596   0: 0.235025528674929   9: 0.029617636782018   5: 0.016376721700995   1: 0.014399906667347   4: 0.012049636559844   8: 0.012042896013826   2: 0.012042568197699   7: 0.012041265009570   3: 0.012041086784176 

training_9755     1: 0.344736833086141   6: 0.343121656395081   5: 0.177625265298623   0: 0.058208839859147   4: 0.028624358730765   2: 0.009536753462911   8: 0.009536703911406   9: 0.009536633625229   3: 0.009536577615045   7: 0.009536378015652 

training_9756     6: 0.765208197476003   8: 0.064470827615260   2: 0.021291372143519   9: 0.021291107776375   5: 0.021290291125221   7: 0.021289998227221   1: 0.021289692165385   4: 0.021289630679870   0: 0.021289618813388   3: 0.021289263977758 

training_976      5: 0.453993167793311   1: 0.240414532009764   9: 0.137017835761432   4: 0.024084781142512   6: 0.024082406276096   8: 0.024081686179439   2: 0.024081565282788   0: 0.024081392540310   3: 0.024081327208912   7: 0.024081305805436 

training_9760     6: 0.428756829667884   0: 0.410607593288012   3: 0.048203749383746   8: 0.029158074769284   4: 0.014019994833064   9: 0.013951361541342   7: 0.013854264478454   1: 0.013818697110214   5: 0.013816557986086   2: 0.013812876941914 

training_9761     6: 0.691136406061908   1: 0.138696732122929   0: 0.074037218875219   8: 0.020306439282768   4: 0.012667106641019   9: 0.012636208924912   3: 0.012635257976245   5: 0.012628992122857   7: 0.012628135627275   2: 0.012627502364868 

training_9763     6: 0.801161036819375   0: 0.084545794049952   4: 0.024122917637510   1: 0.020265336779404   8: 0.011668777787969   5: 0.011647798603408   9: 0.011647294398765   7: 0.011647065690079   3: 0.011647013686649   2: 0.011646964546891 

training_9764     6: 0.734758952725990   0: 0.105964918922495   1: 0.079819098072776   9: 0.024183680026703   5: 0.009214058490875   8: 0.009212172656700   7: 0.009212153431826   4: 0.009211718320855   3: 0.009211655961890   2: 0.009211591389890 

training_9767     9: 0.747961111266354   6: 0.028014539112807   5: 0.028012379052138   4: 0.028006172792601   8: 0.028004098709412   0: 0.028001680634759   1: 0.028001161885202   7: 0.028000860072200   3: 0.027999105395578   2: 0.027998891078949 

training_9768     9: 0.751395410662540   5: 0.027630108697388   6: 0.027626120186291   4: 0.027625039150183   8: 0.027623020729869   0: 0.027620841885381   7: 0.027620479122706   1: 0.027619751189949   3: 0.027619632855731   2: 0.027619595519960 

training_9769     6: 0.773235342690741   0: 0.135624311162917   7: 0.011399610389509   1: 0.011393893376293   2: 0.011391888825131   9: 0.011391747237148   5: 0.011391393822524   8: 0.011390774104061   4: 0.011390584880066   3: 0.011390453511611 

training_977      6: 0.615291107627856   1: 0.190784422670569   8: 0.064915820091555   0: 0.049431180964733   5: 0.013269095907636   4: 0.013264168596103   9: 0.013262876337583   3: 0.013260838363609   7: 0.013260635780401   2: 0.013259853659955 

training_9770     6: 0.807692380810317   9: 0.052969759332734   7: 0.039872774533295   0: 0.024015112280561   5: 0.012576055950146   8: 0.012575477005847   1: 0.012574770412047   4: 0.012574658172302   3: 0.012574602452730   2: 0.012574409050023 

training_9771     0: 0.622581136794911   6: 0.219638535838202   7: 0.052768367847324   4: 0.015044818520304   9: 0.015027522385671   5: 0.014989720785515   1: 0.014988963282706   3: 0.014987750724281   8: 0.014987279009741   2: 0.014985904811346 

training_9772     6: 0.633501092428164   5: 0.149606055881578   1: 0.027112785859096   9: 0.027112365302574   8: 0.027112030409770   4: 0.027111772508559   7: 0.027111377805849   0: 0.027111304696259   3: 0.027110652370949   2: 0.027110562737204 

training_9773     6: 0.765669277506906   5: 0.026047491498473   4: 0.026036069046144   8: 0.026035815159405   3: 0.026035574435263   9: 0.026035559803709   0: 0.026035525356943   1: 0.026035084834294   7: 0.026035079027542   2: 0.026034523331321 

training_9777     6: 0.694739249831317   1: 0.190150090256976   0: 0.014390851867340   5: 0.014389020239028   8: 0.014388696447391   9: 0.014388601056824   7: 0.014388459639530   4: 0.014388422825969   2: 0.014388316376635   3: 0.014388291458992 

training_9779     1: 0.410043302994466   5: 0.397200777871938   0: 0.058438916339933   6: 0.038571004028672   3: 0.015958828440444   7: 0.015958509025082   4: 0.015958014181319   8: 0.015957053799298   9: 0.015956999904882   2: 0.015956593413966 

training_978      1: 0.635466021472604   0: 0.118417386238453   5: 0.088617926976465   2: 0.057986548492124   6: 0.016596369820736   9: 0.016585560431422   4: 0.016583818315594   3: 0.016582428758036   7: 0.016581982831555   8: 0.016581956663011 

training_9781     9: 0.488165311145262   6: 0.335628328492905   8: 0.022030080137186   0: 0.022025945247986   5: 0.022025797184135   1: 0.022025573319334   7: 0.022024882038994   4: 0.022024879180778   3: 0.022024626807172   2: 0.022024576446249 

training_9782     6: 0.837269808001782   0: 0.045154898635815   8: 0.020508671576944   1: 0.013872906060904   9: 0.013870183804261   7: 0.013867872425630   5: 0.013865263167326   2: 0.013863690037027   4: 0.013863507895669   3: 0.013863198394642 

training_9783     6: 0.622249898205483   1: 0.122500241951698   7: 0.117730489292623   0: 0.044930216704419   5: 0.015433095153614   8: 0.015431777915902   9: 0.015431523782393   4: 0.015431363884249   2: 0.015430697160362   3: 0.015430695949257 

training_9784     6: 0.798048057223768   0: 0.116773742977914   9: 0.023261568959191   1: 0.013895619494559   7: 0.008005560295798   8: 0.008004577210770   2: 0.008002817799272   3: 0.008002786029326   5: 0.008002744118562   4: 0.008002525890841 

training_9787     6: 0.445497157985655   0: 0.384379995608242   5: 0.021279271450945   4: 0.021273801296592   8: 0.021266650210637   9: 0.021261351215133   7: 0.021261010911885   2: 0.021260535290964   3: 0.021260141217150   1: 0.021260084812797 

training_9792     6: 0.744327782513910   0: 0.105700884480693   1: 0.032013927787169   9: 0.028792163709853   4: 0.014867474630203   7: 0.014866789114954   5: 0.014864080512524   8: 0.014857338263612   3: 0.014855774024711   2: 0.014853784962371 

training_9793     6: 0.829352985251912   0: 0.067677489080428   3: 0.029324367177460   1: 0.013368079344747   9: 0.010289719191623   7: 0.010260240230588   5: 0.009954050052852   2: 0.009924897492579   8: 0.009924220627359   4: 0.009923951550452 

training_9795     6: 0.669108073474318   0: 0.228480544529613   9: 0.022001738791215   1: 0.011489188680275   8: 0.011487669093222   5: 0.011487618088047   4: 0.011486510812657   7: 0.011486351967630   2: 0.011486231760942   3: 0.011486072802082 

training_9797     6: 0.624858298718985   0: 0.272854594439675   1: 0.023176195238836   4: 0.011304822060919   7: 0.011302917160493   5: 0.011300915503791   8: 0.011300779379410   9: 0.011300649408799   2: 0.011300497423938   3: 0.011300330665153 

training_9799     6: 0.704439557241782   0: 0.173204420144737   8: 0.025228123379053   2: 0.013890636874326   1: 0.013873878510870   9: 0.013873806935270   5: 0.013873320146808   4: 0.013872401260003   7: 0.013872135196329   3: 0.013871720310821 

training_98       4: 0.687334704405168   2: 0.126843374554877   5: 0.023238193321253   7: 0.023228528190968   6: 0.023227351195841   0: 0.023226398065217   3: 0.023225756927788   8: 0.023225371132302   1: 0.023225196289256   9: 0.023225125917330 

training_9801     6: 0.655951204776396   1: 0.195859951636134   3: 0.042435133517700   5: 0.015124188210584   0: 0.015106120064203   4: 0.015105335168999   2: 0.015104720502802   8: 0.015104615610253   7: 0.015104546995431   9: 0.015104183517497 

training_9804     6: 0.490892632297759   4: 0.283434273884464   8: 0.118124438324364   1: 0.015366592506813   5: 0.015366586567061   0: 0.015364682752428   9: 0.015363416813555   7: 0.015363363312151   2: 0.015362094592518   3: 0.015361918948886 

training_9805     7: 0.750679268440947   6: 0.027714274450943   9: 0.027705105388378   5: 0.027703745616597   0: 0.027700401659627   8: 0.027700359031296   4: 0.027699847921359   1: 0.027699730825802   3: 0.027698847070692   2: 0.027698419594358 

training_9807     5: 0.813377323418109   4: 0.020740552019481   6: 0.020735454235326   0: 0.020735426792931   8: 0.020735402703752   9: 0.020735215487987   3: 0.020735193179892   2: 0.020735168879667   1: 0.020735154533119   7: 0.020735108749736 

training_9809     5: 0.566489190119128   1: 0.250597475033777   0: 0.022866305179116   4: 0.022865555431128   6: 0.022864693523632   3: 0.022864611099355   9: 0.022863450094805   2: 0.022863137247829   8: 0.022862866535522   7: 0.022862715735709 

training_981      4: 0.658195086683767   5: 0.037984560402026   6: 0.037979540380377   8: 0.037977754876652   2: 0.037977386160932   0: 0.037977306295344   7: 0.037977123094506   1: 0.037977120604717   9: 0.037977088716563   3: 0.037977032785116 

training_9810     5: 0.820622322325613   4: 0.019933709801492   6: 0.019930620051415   0: 0.019930620045740   8: 0.019930615708527   9: 0.019930546889524   3: 0.019930467449897   1: 0.019930388913257   2: 0.019930355672713   7: 0.019930353141822 

training_9812     6: 0.480959382849600   7: 0.326343935470227   0: 0.056777984948471   1: 0.019449503661689   9: 0.019423990233037   5: 0.019415798230449   4: 0.019407954743232   8: 0.019407951758606   3: 0.019407252952575   2: 0.019406245152114 

training_9814     0: 0.406649766128363   1: 0.371872075168787   8: 0.068170971758712   9: 0.022033351613358   5: 0.021898861868927   6: 0.021876102194223   4: 0.021875049164196   3: 0.021874953573260   2: 0.021874663802499   7: 0.021874204727677 

training_9815     5: 0.751271675098439   4: 0.027640936597422   0: 0.027637837273907   1: 0.027636352655837   6: 0.027636295469112   3: 0.027636149027838   8: 0.027635374071454   2: 0.027635336928145   7: 0.027635159209018   9: 0.027634883668829 

training_9816     6: 0.553241132698235   0: 0.305599624275536   5: 0.017646951670687   1: 0.017646757907717   4: 0.017645157726886   9: 0.017644711038778   8: 0.017644407399135   7: 0.017644002768083   2: 0.017643836750264   3: 0.017643417764678 

training_9818     5: 0.769846227090487   3: 0.060691747907058   7: 0.054609990730098   6: 0.016413367016252   4: 0.016408503779025   8: 0.016406966248056   0: 0.016406296091967   1: 0.016405767197983   9: 0.016405716290334   2: 0.016405417648741 

training_982      0: 0.406842428441815   6: 0.315184960843386   4: 0.124278487950847   1: 0.051640684270242   7: 0.031262589849647   9: 0.014158951766375   5: 0.014158845437620   2: 0.014157957621129   8: 0.014157638985960   3: 0.014157454832978 

training_9821     6: 0.773908539461924   9: 0.068597766919243   7: 0.048105388423441   0: 0.027793203320401   5: 0.013600600356092   8: 0.013599781109770   4: 0.013598795645952   1: 0.013598773210729   3: 0.013598697716857   2: 0.013598453835591 

training_9822     6: 0.739394250887442   0: 0.096675829330012   1: 0.035955481548729   8: 0.034879697755971   7: 0.015593120281964   5: 0.015501328657459   9: 0.015500944447317   2: 0.015500311178107   4: 0.015499870399934   3: 0.015499165513064 

training_9823     1: 0.413038958343210   8: 0.268891973844387   6: 0.121506256985448   7: 0.028083643090084   0: 0.028081611516679   5: 0.028081151303311   9: 0.028079527219635   4: 0.028079164779473   2: 0.028078861300549   3: 0.028078851617223 

training_9824     6: 0.764520710514182   5: 0.026190820324538   4: 0.026171171554889   8: 0.026168679485106   9: 0.026162787626766   0: 0.026158542059387   7: 0.026158344784902   1: 0.026157020374431   2: 0.026155996129930   3: 0.026155927145869 

training_9825     5: 0.784659413527147   4: 0.023929282415036   6: 0.023926901677348   9: 0.023926787817953   0: 0.023926506273549   1: 0.023926468267767   8: 0.023926449357685   2: 0.023926128879232   7: 0.023926036828199   3: 0.023926024956082 

training_9827     5: 0.705331502970559   1: 0.102879559280778   7: 0.023975645813345   3: 0.023973968495711   0: 0.023973913477696   4: 0.023973611102931   6: 0.023972995147948   2: 0.023972962690079   9: 0.023972922152308   8: 0.023972918868645 

training_9829     6: 0.734614408102442   0: 0.116626379492430   5: 0.018596668529556   8: 0.018595438311852   9: 0.018594957772068   7: 0.018594929534120   1: 0.018594525826411   4: 0.018594497508070   2: 0.018594241154858   3: 0.018593953768194 

training_983      0: 0.316052917673483   4: 0.285706836105336   1: 0.276379901371236   5: 0.033117011191310   6: 0.014840861922332   8: 0.014785566878632   7: 0.014782564546817   9: 0.014779950857151   2: 0.014777271965463   3: 0.014777117488241 

training_9833     1: 0.595421405589331   0: 0.142099807285439   6: 0.107372578916295   8: 0.062439313158378   3: 0.015448884664321   5: 0.015446319303098   4: 0.015443498360970   7: 0.015443018639929   9: 0.015442619112327   2: 0.015442554969911 

training_9834     6: 0.571274611910140   7: 0.290615875703462   5: 0.017282445602902   3: 0.017262866946563   1: 0.017261828918022   8: 0.017261435858850   4: 0.017260783984434   0: 0.017260632784481   9: 0.017260152812903   2: 0.017259365478243 

training_9836     6: 0.680182830032330   1: 0.127467257872650   5: 0.072883844075420   0: 0.017087335118448   8: 0.017070580462393   7: 0.017062533009273   9: 0.017061967329358   4: 0.017061830206818   3: 0.017060952677168   2: 0.017060869216140 

training_9837     5: 0.710681479401289   4: 0.032152497958060   6: 0.032148573274991   0: 0.032146448361128   2: 0.032145887708228   1: 0.032145760178919   9: 0.032145099294641   8: 0.032144892811039   3: 0.032144791877560   7: 0.032144569134147 

training_9839     5: 0.839433027708262   4: 0.017844262886604   6: 0.017841209355236   0: 0.017840715152141   1: 0.017840592069119   8: 0.017840491736893   9: 0.017840232916325   2: 0.017839853460685   7: 0.017839845954664   3: 0.017839768760071 

training_984      5: 0.446127102674549   6: 0.234694695978151   3: 0.125379097497030   2: 0.083103301670926   1: 0.018466889130631   0: 0.018451168844260   4: 0.018447922021125   9: 0.018443872721949   8: 0.018443319481475   7: 0.018442629979904 

training_9841     6: 0.757971250947723   5: 0.134467881496399   9: 0.023843984534731   0: 0.011977733749968   8: 0.011958240074048   1: 0.011957350990173   7: 0.011956125532628   4: 0.011955862749873   2: 0.011955808691321   3: 0.011955761233135 

training_9844     1: 0.596079761585317   9: 0.146479348759076   2: 0.081264375165814   8: 0.046429072911776   5: 0.021636631803985   6: 0.021625907717767   4: 0.021623567242952   0: 0.021622313458526   7: 0.021620942702556   3: 0.021618078652231 

training_9847     6: 0.681620567249515   1: 0.206053106970037   0: 0.014046416922422   5: 0.014040645515913   8: 0.014040554055628   4: 0.014039975836856   9: 0.014039826788741   3: 0.014039680355498   7: 0.014039615064551   2: 0.014039611240839 

training_9848     6: 0.801079062389932   0: 0.103148245436919   1: 0.037365629933145   9: 0.014459241392848   8: 0.007325892338199   5: 0.007325079424759   2: 0.007324397279271   3: 0.007324334635310   4: 0.007324126079026   7: 0.007323991090590 

training_9849     6: 0.761454702947156   0: 0.067712362281541   7: 0.048304219237408   1: 0.035939278455401   9: 0.014471343167074   2: 0.014432628017842   5: 0.014423888782248   3: 0.014422069024162   8: 0.014419827409578   4: 0.014419680677590 

training_985      6: 0.704463212598396   1: 0.032849751154105   0: 0.032839517514209   5: 0.032837084842199   4: 0.032835574803030   9: 0.032835327187521   8: 0.032835108974513   7: 0.032834918609583   2: 0.032834835914611   3: 0.032834668401833 

training_9850     6: 0.627504135433307   9: 0.224538309447396   1: 0.018499337830825   5: 0.018496647007618   0: 0.018496035635559   4: 0.018495135124537   2: 0.018493049529945   8: 0.018492597850072   3: 0.018492496598580   7: 0.018492255542161 

training_9851     6: 0.779434435739158   0: 0.024510135333603   1: 0.024508298946029   9: 0.024506877896291   5: 0.024506869010690   8: 0.024506802208780   7: 0.024506793450976   3: 0.024506631789195   2: 0.024506601451948   4: 0.024506554173330 

training_9852     6: 0.743623551074035   0: 0.028487803590350   1: 0.028487475754980   9: 0.028486955955755   8: 0.028486039625659   2: 0.028485793309424   3: 0.028485662977268   7: 0.028485582417896   5: 0.028485580976020   4: 0.028485554318611 

training_9853     6: 0.708438456025759   0: 0.170449035479498   8: 0.025055146447613   2: 0.013737286351336   1: 0.013721009023522   9: 0.013720951898619   5: 0.013720396621751   4: 0.013719553922548   7: 0.013719285089939   3: 0.013718879139415 

training_9855     8: 0.776548367901042   9: 0.056784628315073   6: 0.020836721713633   0: 0.020836521571758   5: 0.020833581299964   1: 0.020833284486385   2: 0.020831956703313   4: 0.020831900547573   7: 0.020831636233443   3: 0.020831401227815 

training_9857     6: 0.774604515246881   9: 0.025048498776078   8: 0.025046346900804   0: 0.025044288079047   7: 0.025043580991647   1: 0.025043212222806   3: 0.025042848908759   5: 0.025042408572376   2: 0.025042219932470   4: 0.025042080369130 

training_9858     5: 0.586914088027279   6: 0.243902421123253   1: 0.021161429707511   0: 0.021148318776443   4: 0.021146051799047   2: 0.021145729482368   3: 0.021145567647688   7: 0.021145542232408   9: 0.021145535721963   8: 0.021145315482040 

training_986      5: 0.659734789735233   6: 0.182045485639035   4: 0.019792398397391   8: 0.019775618253632   9: 0.019775569683538   0: 0.019775541072864   1: 0.019775279979874   7: 0.019775155080711   2: 0.019775136303855   3: 0.019775025853867 

training_9860     5: 0.591930328191524   8: 0.233322493619642   6: 0.021846054988431   4: 0.021845731531820   2: 0.021842956253999   0: 0.021842854640142   1: 0.021842804347512   9: 0.021842637802836   7: 0.021842273335462   3: 0.021841865288631 

training_9861     5: 0.593732698867231   6: 0.268141719601849   1: 0.031392122412221   0: 0.015249883785952   4: 0.015247962404595   9: 0.015247467077615   8: 0.015247424526499   7: 0.015247168194726   2: 0.015246823461450   3: 0.015246729667862 

training_9862     6: 0.748000334395226   1: 0.028006374518768   0: 0.028001592588367   8: 0.028001129062423   7: 0.027999748488796   9: 0.027999068855733   5: 0.027998240063018   2: 0.027997926977292   4: 0.027997873614099   3: 0.027997711436278 

training_9864     6: 0.778187206157342   0: 0.082332742881986   1: 0.045609267181382   2: 0.024208945309769   8: 0.011611414088412   5: 0.011610785742418   7: 0.011610409819175   4: 0.011609866469912   9: 0.011609854573043   3: 0.011609507776560 

training_9865     6: 0.832921001972164   8: 0.018570951659948   1: 0.018564154706180   0: 0.018564035282919   7: 0.018563896823377   9: 0.018563511940103   2: 0.018563157686839   5: 0.018563136169050   4: 0.018563112413796   3: 0.018563041345624 

training_9866     6: 0.715758434486444   9: 0.084132412104225   4: 0.066001866683445   7: 0.043630984742283   1: 0.021421972244739   5: 0.013837747468043   0: 0.013822256394007   2: 0.013800863157291   8: 0.013796875481057   3: 0.013796587238465 

training_9867     4: 0.650387799944225   0: 0.171046604333620   1: 0.046748139220688   6: 0.018836695779092   8: 0.018832338506389   5: 0.018830716876352   9: 0.018830448408646   2: 0.018830384491610   3: 0.018828901212102   7: 0.018827971227275 

training_9868     5: 0.542038092580832   4: 0.277562900822921   8: 0.022551542904516   6: 0.022550623058869   9: 0.022549940554339   0: 0.022549748578876   2: 0.022549528902200   1: 0.022549455782379   3: 0.022549254730481   7: 0.022548912084586 

training_9869     4: 0.394982626153030   6: 0.347265212203950   0: 0.133549321486098   2: 0.031204287900973   5: 0.015503772897981   1: 0.015501841840615   7: 0.015498395299330   9: 0.015498352752915   8: 0.015498276336799   3: 0.015497913128308 

training_9871     6: 0.824868688193017   1: 0.076086183022318   0: 0.012397204169069   7: 0.012380353856830   8: 0.012378651277763   9: 0.012378249876299   5: 0.012377922097617   4: 0.012377608453512   2: 0.012377587562004   3: 0.012377551491572 

training_9872     9: 0.346584171383220   6: 0.271013750146888   1: 0.257519291724093   2: 0.017847052274040   0: 0.017842646106532   5: 0.017841593135359   4: 0.017838960672642   3: 0.017837655416417   7: 0.017837499711975   8: 0.017837379428834 

training_9874     6: 0.405877554472428   5: 0.264425942115404   3: 0.221885463918092   0: 0.015405860654997   1: 0.015404655586527   4: 0.015400983963547   9: 0.015400168794844   2: 0.015399863965742   7: 0.015399777135075   8: 0.015399729393344 

training_9875     5: 0.819848239865242   6: 0.020017826803518   1: 0.020016982778143   3: 0.020016881992853   4: 0.020016810068793   2: 0.020016760031121   0: 0.020016751255460   7: 0.020016705837241   9: 0.020016550986932   8: 0.020016490380696 

training_9878     5: 0.621990363615698   1: 0.183423169393762   6: 0.024328089082370   3: 0.024323381821264   4: 0.024323148266468   0: 0.024322859728031   8: 0.024322385407083   7: 0.024322277176947   2: 0.024322228093194   9: 0.024322097415182 

training_988      6: 0.565888398832166   1: 0.325236615049048   5: 0.013616095111139   9: 0.013612343905091   4: 0.013611418127779   3: 0.013607958552615   8: 0.013607925054687   0: 0.013607366364355   2: 0.013607179364795   7: 0.013604699638326 

training_9880     9: 0.737800387917744   8: 0.086719767265507   6: 0.021951008536475   5: 0.021933832622068   0: 0.021933242703341   1: 0.021932791323552   4: 0.021932458623551   2: 0.021932357496412   7: 0.021932202577629   3: 0.021931950933722 

training_9884     5: 0.631743338443136   1: 0.119955478462678   6: 0.111046393828502   0: 0.019610137663941   9: 0.019608587328726   4: 0.019608361806349   7: 0.019606989121943   2: 0.019606947700328   8: 0.019606915761771   3: 0.019606849882626 

training_9891     1: 0.550480047306302   0: 0.135976921561906   6: 0.110005667367457   8: 0.098665117818716   3: 0.017486841756167   5: 0.017479909859365   7: 0.017476909184498   4: 0.017476453645525   9: 0.017476095340259   2: 0.017476036159805 

training_9892     0: 0.382420084496853   6: 0.276905174925852   9: 0.222904741309527   7: 0.032136307719188   1: 0.020546717387709   8: 0.013336311821948   5: 0.012940437133265   4: 0.012937382493990   2: 0.012936449015621   3: 0.012936393696046 

training_9893     0: 0.562090498789579   1: 0.257748720868312   7: 0.057743791574147   4: 0.017532449544573   9: 0.017512968935862   6: 0.017476126678568   5: 0.017475943689359   3: 0.017473249351369   8: 0.017473153585005   2: 0.017473096983227 

training_9894     5: 0.683255725543409   1: 0.162241352510358   4: 0.019316924233655   6: 0.019312715073811   0: 0.019312482918682   8: 0.019312376845910   9: 0.019312315371929   2: 0.019312077119646   3: 0.019312032314667   7: 0.019311998067933 

training_9896     4: 0.762803659404708   5: 0.026361076375865   1: 0.026355173306478   8: 0.026354473810256   3: 0.026354361708449   2: 0.026354293075631   7: 0.026354262605490   0: 0.026354248137617   6: 0.026354228950976   9: 0.026354222624530 

training_9897     6: 0.746278774256543   7: 0.087631556890439   0: 0.058355267405361   1: 0.015394118949869   5: 0.015391537916935   9: 0.015391046950435   4: 0.015389914704601   8: 0.015389360449412   2: 0.015389330916992   3: 0.015389091559413 

training_99       9: 0.100000000000000   8: 0.100000000000000   7: 0.100000000000000   6: 0.100000000000000   5: 0.100000000000000   4: 0.100000000000000   3: 0.100000000000000   2: 0.100000000000000   1: 0.100000000000000   0: 0.100000000000000 

training_9901     5: 0.788758401413388   1: 0.023472487429049   0: 0.023471933916132   9: 0.023471507604488   3: 0.023471316646148   6: 0.023471238286917   4: 0.023470960850112   8: 0.023470828124399   7: 0.023470738471780   2: 0.023470587257587 

training_9902     3: 0.424622179627934   5: 0.374958956593927   4: 0.025053165343293   0: 0.025052349609431   6: 0.025052326879061   8: 0.025052301840681   1: 0.025052255468451   7: 0.025052223687513   2: 0.025052196061142   9: 0.025052044888565 

training_9903     6: 0.752241052051668   0: 0.057815462243093   7: 0.054769147993856   9: 0.019312484554980   8: 0.019311368641300   5: 0.019311135985069   1: 0.019310304427031   4: 0.019309907097693   2: 0.019309578923472   3: 0.019309558081836 

training_9904     5: 0.693356222857577   1: 0.115077553969890   6: 0.023959073991913   0: 0.023945344352370   3: 0.023944583725651   4: 0.023943724183435   8: 0.023943454888791   7: 0.023943376820508   2: 0.023943376424278   9: 0.023943288785587 

training_9905     6: 0.754628909290507   0: 0.101038392924925   7: 0.043019984368064   1: 0.014494576412779   5: 0.014477929572980   4: 0.014471450170178   8: 0.014469434348684   9: 0.014468602477713   3: 0.014465363826894   2: 0.014465356607276 

training_9906     6: 0.509186876616666   5: 0.207318364325229   1: 0.104628572721065   2: 0.086996459788382   8: 0.015320864382045   7: 0.015311241349461   3: 0.015310896905632   0: 0.015309574096102   9: 0.015308753014721   4: 0.015308396800697 

training_9907     6: 0.622921042404258   9: 0.246412404313635   0: 0.039264365007695   8: 0.013183888505388   3: 0.013079919449256   1: 0.013033397386042   2: 0.013030228167108   5: 0.013027182408922   7: 0.013024182553541   4: 0.013023389804155 

training_9909     5: 0.725422502084926   8: 0.084826968131977   6: 0.023726140891929   9: 0.023720184977318   0: 0.023719845129947   1: 0.023718111600977   7: 0.023717601138277   4: 0.023717025623418   2: 0.023716000600651   3: 0.023715619820579 

training_991      6: 0.755618237382725   1: 0.112731590276217   5: 0.038160854674374   0: 0.013400063288973   9: 0.013362876088705   8: 0.013345666928463   3: 0.013345431128991   4: 0.013345185253454   7: 0.013345075598417   2: 0.013345019379681 

training_9912     6: 0.438649882016403   3: 0.435060079218376   2: 0.028976803885990   9: 0.013903168483718   7: 0.013902807392698   0: 0.013901782191435   1: 0.013901646829271   8: 0.013901476469240   5: 0.013901448537217   4: 0.013900904975653 

training_9913     1: 0.495308655050932   9: 0.361785829747570   7: 0.043255600359900   6: 0.014239210864828   0: 0.014237890307142   2: 0.014235118990480   5: 0.014234860680269   4: 0.014234645854608   8: 0.014234319377520   3: 0.014233868766753 

training_9914     5: 0.453552818258475   4: 0.348011790218999   7: 0.043257978502605   1: 0.040233604757242   8: 0.035517611869454   6: 0.015890629062051   0: 0.015886160501921   9: 0.015884370897314   3: 0.015882722622411   2: 0.015882313309526 

training_9915     9: 0.724518684253573   5: 0.149941081351251   1: 0.015695241820771   0: 0.015694774772056   2: 0.015693928440946   6: 0.015693043491330   3: 0.015691233971995   8: 0.015690855657194   4: 0.015690781794954   7: 0.015690374445929 

training_9918     4: 0.499465352081871   5: 0.310143497749027   1: 0.023809128139294   6: 0.023806001173749   0: 0.023799868730878   8: 0.023799319532474   9: 0.023797117740025   7: 0.023795065449423   2: 0.023792741997432   3: 0.023791907405826 

training_9919     6: 0.643700012828815   0: 0.153564441250499   7: 0.071322581598083   8: 0.018795650707145   1: 0.018769947410641   5: 0.018769819841796   9: 0.018769667266435   2: 0.018769500011856   4: 0.018769256536319   3: 0.018769122548411 

training_9920     1: 0.445379924228387   4: 0.296108503716646   5: 0.106802919801239   6: 0.021679899741818   2: 0.021678408640670   8: 0.021674949235408   0: 0.021670430173731   7: 0.021668411597651   3: 0.021668379450517   9: 0.021668173413933 

training_9923     6: 0.745810386895848   1: 0.096764973254771   0: 0.071189048897467   5: 0.012320168695659   8: 0.012319620276926   9: 0.012319254002112   7: 0.012319252439209   4: 0.012319190104768   2: 0.012319068341502   3: 0.012319037091738 

training_9925     1: 0.683280831850144   3: 0.092195237888665   0: 0.028091335572354   7: 0.028076870722386   6: 0.028072434983557   2: 0.028060709463381   5: 0.028058083069746   4: 0.028055945196622   8: 0.028054376886508   9: 0.028054174366638 

training_9926     6: 0.381786607590826   5: 0.321328245437473   3: 0.156646497141107   1: 0.020042214971648   0: 0.020037251379785   2: 0.020032290561901   4: 0.020032238459276   8: 0.020031902742527   9: 0.020031699572339   7: 0.020031052143117 

training_9927     5: 0.423841990982301   1: 0.318069178645309   0: 0.120223917849214   6: 0.036924719681941   9: 0.016825585910092   2: 0.016823410739701   7: 0.016822932610142   8: 0.016822890970287   4: 0.016822829975713   3: 0.016822542635301 

training_9928     1: 0.413744865806964   5: 0.189135225776579   9: 0.126736855643241   4: 0.094509361602502   2: 0.061231567895750   8: 0.060649994080324   6: 0.013502692820921   0: 0.013499305689467   7: 0.013495118695739   3: 0.013495011988515 

training_9929     4: 0.449794013450336   5: 0.374119612603307   0: 0.022017590240574   1: 0.022016899387965   6: 0.022015762855440   2: 0.022007811915480   9: 0.022007726729302   7: 0.022007183343620   8: 0.022006772674834   3: 0.022006626799142 

training_9930     4: 0.786811944058045   8: 0.023702294101917   5: 0.023691753218899   1: 0.023685869550891   0: 0.023685171654494   6: 0.023685044821501   3: 0.023684575033494   9: 0.023684522316431   2: 0.023684470402842   7: 0.023684354841487 

training_9933     6: 0.632093719365495   0: 0.156042018564614   8: 0.073339724970778   4: 0.041860866347126   1: 0.032627402657300   5: 0.012808845751799   7: 0.012807050549430   2: 0.012806960721733   9: 0.012806717357250   3: 0.012806693714476 

training_9934     1: 0.726206243978256   4: 0.030424436704913   6: 0.030423824135084   5: 0.030422051051864   0: 0.030421929009453   3: 0.030420346244375   2: 0.030420324650976   9: 0.030420316159731   8: 0.030420264809763   7: 0.030420263255585 

training_9936     5: 0.771123821001082   3: 0.025440484866618   4: 0.025429910429976   0: 0.025429488791011   8: 0.025429451685229   6: 0.025429419686174   1: 0.025429419533824   2: 0.025429386304382   7: 0.025429326145559   9: 0.025429291556143 

training_9937     5: 0.777377059911538   1: 0.063439718069306   4: 0.019901553371772   0: 0.019898638809165   6: 0.019897562698976   8: 0.019897441946545   9: 0.019897055417879   2: 0.019897012518644   3: 0.019896995216636   7: 0.019896962039538 

training_9939     5: 0.421951249176041   1: 0.331650258670328   6: 0.030804329381771   0: 0.030802849159779   8: 0.030802382640465   9: 0.030800533763364   4: 0.030800184673647   7: 0.030797232525847   3: 0.030795637687429   2: 0.030795342321329 

training_9940     6: 0.458925233756068   1: 0.316125619028522   5: 0.117693355985875   8: 0.036678175455578   0: 0.011765338937110   4: 0.011764219889542   7: 0.011762527961191   9: 0.011762059943156   2: 0.011761861707137   3: 0.011761607335821 

training_9941     6: 0.730815524020863   8: 0.092731919584744   5: 0.022057610313879   1: 0.022057342523290   0: 0.022056994703670   7: 0.022056452257618   4: 0.022056246440299   2: 0.022056231436347   9: 0.022055895662327   3: 0.022055783056963 

training_9942     6: 0.722267630459322   5: 0.030867342421514   1: 0.030866829843208   0: 0.030861020367817   4: 0.030857924883154   7: 0.030856959877107   2: 0.030856740937543   9: 0.030855528778874   8: 0.030855441420069   3: 0.030854581011391 

training_9943     8: 0.525126005179707   6: 0.286406629913248   0: 0.083922514093094   2: 0.014961557321620   1: 0.014931429411346   5: 0.014931123063447   9: 0.014930722132209   4: 0.014930124886053   7: 0.014930040912804   3: 0.014929853086472 

training_9946     6: 0.804305726314286   1: 0.098796688980502   8: 0.028554612821581   0: 0.009765241403693   5: 0.009763331737555   9: 0.009763306751446   7: 0.009762976179454   4: 0.009762799892059   3: 0.009762693254767   2: 0.009762622664656 

training_9947     1: 0.401334528858087   9: 0.387165807327155   6: 0.056452266632577   2: 0.047658146273576   7: 0.044994538520496   3: 0.020475183764092   0: 0.010481388052345   5: 0.010480365335542   4: 0.010479295742368   8: 0.010478479493762 

training_995      5: 0.488470842970787   0: 0.314962334339633   1: 0.067203942647933   6: 0.018482012583196   4: 0.018481612910695   7: 0.018480206895248   9: 0.018480122503052   2: 0.018480028303764   3: 0.018479461012342   8: 0.018479435833349 

training_9952     0: 0.412641730146957   6: 0.341440930696447   5: 0.131579813595045   4: 0.016336197327998   1: 0.016335123889434   9: 0.016333930252493   2: 0.016333377792295   8: 0.016333023556481   7: 0.016332997139762   3: 0.016332875603088 

training_9953     6: 0.785990864002168   1: 0.103569945369353   8: 0.013812592745728   0: 0.013807662787055   5: 0.013803604747619   9: 0.013803410291881   7: 0.013803341869382   2: 0.013802948766141   4: 0.013802864950858   3: 0.013802764469814 

training_9954     6: 0.362580178902591   3: 0.338661818313910   0: 0.144644021864946   5: 0.056737202171301   9: 0.022572641754420   1: 0.019213489424228   7: 0.013904171675695   2: 0.013899360223175   4: 0.013894147049184   8: 0.013892968620550 

training_9955     6: 0.631328952670860   0: 0.153752619016423   1: 0.026867939946967   2: 0.026864650521411   4: 0.026864340634606   5: 0.026864322875164   7: 0.026864300094046   9: 0.026864299273670   3: 0.026864290495542   8: 0.026864284471311 

training_9956     5: 0.571954512634607   6: 0.226799983441696   1: 0.057295636684537   9: 0.035419945439721   0: 0.018090058550453   8: 0.018088581478972   3: 0.018088465170578   7: 0.018087649329868   2: 0.018087602840380   4: 0.018087564429189 

training_9957     6: 0.775609289567819   0: 0.114687003483008   1: 0.013714479715412   5: 0.013713498028296   4: 0.013712819612077   8: 0.013712813539543   9: 0.013712660090863   7: 0.013712598967553   3: 0.013712420077958   2: 0.013712416917472 

training_9958     6: 0.785076225753785   8: 0.023881349350218   1: 0.023880962169881   7: 0.023880512198099   9: 0.023880476569161   0: 0.023880341648446   2: 0.023880068248656   5: 0.023880058010869   3: 0.023880008783668   4: 0.023879997267216 

training_9959     5: 0.708375240498657   6: 0.106154246352801   0: 0.043621839142868   2: 0.029863040912216   3: 0.027203737857065   8: 0.025680726159371   7: 0.014812476096317   1: 0.014783346209935   4: 0.014755058614074   9: 0.014750288156696 

training_9961     5: 0.817704675863683   4: 0.020257925043669   6: 0.020254905304311   0: 0.020254900275487   1: 0.020254807202070   8: 0.020254666656331   9: 0.020254553854744   3: 0.020254546371480   2: 0.020254543728276   7: 0.020254475699949 

training_9963     5: 0.830685994399801   4: 0.018816135246257   8: 0.018812320098867   6: 0.018812255503848   0: 0.018812249888323   7: 0.018812248842950   1: 0.018812247595468   9: 0.018812206029868   3: 0.018812199411927   2: 0.018812142982690 

training_9964     5: 0.385820051551583   4: 0.308471107465583   6: 0.114954805753878   0: 0.027252817002179   7: 0.027251555193908   9: 0.027250440137115   8: 0.027250262312150   1: 0.027249892153949   3: 0.027249593196658   2: 0.027249475232997 

training_9965     4: 0.583431343739763   0: 0.218260345752098   5: 0.024800067411617   3: 0.024788559996223   1: 0.024787557542592   7: 0.024787077553541   2: 0.024786920575541   6: 0.024786896782481   9: 0.024785836933832   8: 0.024785393712311 

training_9967     1: 0.412942019505181   6: 0.279587208354173   4: 0.174436964816819   7: 0.051107514107747   5: 0.013679311456183   0: 0.013651732414507   9: 0.013649092381650   8: 0.013648822982121   2: 0.013648819694969   3: 0.013648514286650 

training_9970     4: 0.758692153967087   5: 0.026817986335241   1: 0.026812057550921   8: 0.026811262065343   3: 0.026811185657646   2: 0.026811124508097   7: 0.026811089522457   0: 0.026811086471275   6: 0.026811046313865   9: 0.026811007608068 

training_9971     6: 0.705921444632182   5: 0.117593363126715   2: 0.042481419452321   0: 0.019151774324294   1: 0.019146419662619   4: 0.019142306909584   3: 0.019141557057425   7: 0.019140735220296   9: 0.019140573777610   8: 0.019140405836955 

training_9972     8: 0.715385299215199   5: 0.031630779467334   4: 0.031624789176747   6: 0.031624745663108   0: 0.031623627291613   9: 0.031622400526324   3: 0.031622214783119   1: 0.031622177419642   7: 0.031622100950584   2: 0.031621865506330 

training_9973     5: 0.741755306098513   1: 0.099057110118676   6: 0.019899943341352   4: 0.019899869159359   9: 0.019898413161540   0: 0.019898270745102   8: 0.019897910197609   3: 0.019897826617069   2: 0.019897684163192   7: 0.019897666397590 

training_9974     0: 0.545815214963078   6: 0.306347413723787   1: 0.018480812954952   5: 0.018480652060194   3: 0.018480113802552   9: 0.018479665788614   8: 0.018479108276793   2: 0.018479040133270   7: 0.018479033012546   4: 0.018478945284215 

training_9975     6: 0.754820039305601   0: 0.114860237312710   1: 0.064531482258873   2: 0.015826859042045   5: 0.008353674059954   3: 0.008323423607663   4: 0.008323137466244   8: 0.008321716996502   7: 0.008321135379441   9: 0.008318294570966 

training_9976     1: 0.510498251201606   5: 0.345736367356666   6: 0.038807167303544   3: 0.015036106418417   8: 0.014997490446463   9: 0.014986106441768   0: 0.014985905577672   4: 0.014984321472065   7: 0.014984175401010   2: 0.014984108380789 

training_9977     5: 0.350749816201123   6: 0.340893904565391   3: 0.164391642897977   1: 0.020574974141761   0: 0.020569087326218   2: 0.020564527053512   4: 0.020564482345176   8: 0.020564260079146   9: 0.020563966434853   7: 0.020563338954844 

training_9978     6: 0.426320683199228   0: 0.347244249647029   4: 0.087319381369112   1: 0.041507535792072   7: 0.025131139047215   5: 0.023953686503220   8: 0.015086155326672   2: 0.011452948315078   9: 0.011015896748197   3: 0.010968324052177 

training_998      5: 0.819605931554032   4: 0.020050546872397   1: 0.020044110931455   0: 0.020043603105343   6: 0.020043275514543   9: 0.020042905549759   2: 0.020042758973844   8: 0.020042578432541   3: 0.020042211622637   7: 0.020042077443450 

training_9981     5: 0.756431045809142   1: 0.063016211042869   9: 0.051948284271042   6: 0.018379365875750   0: 0.018375188596005   8: 0.018370964733652   4: 0.018370168012564   7: 0.018369731099425   2: 0.018369560944197   3: 0.018369479615354 

training_9982     6: 0.565770446900829   0: 0.238415328997719   8: 0.089296230639872   1: 0.015223937280709   5: 0.015217683863159   7: 0.015215471913156   4: 0.015215466902818   2: 0.015215211672481   3: 0.015215112763759   9: 0.015215109065498 

training_9984     6: 0.310815561594581   8: 0.292669917668917   3: 0.238699710528359   4: 0.069185251623322   1: 0.014775301894184   5: 0.014773933151053   9: 0.014772111297829   0: 0.014771607751320   2: 0.014768783965440   7: 0.014767820524995 

training_9985     1: 0.397318067648008   5: 0.374774242503265   4: 0.028494977650064   8: 0.028488587531695   9: 0.028487837964293   3: 0.028487444615166   2: 0.028487260355641   7: 0.028487248921258   0: 0.028487215278944   6: 0.028487117531666 

training_9988     8: 0.726693622744299   0: 0.129264642858203   2: 0.018037021489537   1: 0.018002814103084   6: 0.018002752437306   5: 0.018001923266749   7: 0.017999664452892   9: 0.017999431726434   4: 0.017999331342893   3: 0.017998795578603 

training_9989     6: 0.745511355628776   1: 0.119865006189071   5: 0.016829304951541   8: 0.016828592891397   0: 0.016828193277864   9: 0.016827653955183   7: 0.016827630807775   3: 0.016827459180319   2: 0.016827425411174   4: 0.016827377706899 

training_999      9: 0.613940154436277   6: 0.215255224653292   8: 0.021356165118682   5: 0.021351824186203   4: 0.021350089156176   0: 0.021350024966888   1: 0.021349523880217   7: 0.021349132941313   3: 0.021348992661634   2: 0.021348867999319 

training_9992     5: 0.610676041760701   1: 0.182673221722306   3: 0.025832073897655   4: 0.025831653534891   6: 0.025831259450362   0: 0.025831244629745   8: 0.025831234095778   2: 0.025831116748050   7: 0.025831101418770   9: 0.025831052741744 

training_9993     5: 0.769404058300381   4: 0.025628902278968   3: 0.025621491029824   6: 0.025620868155297   0: 0.025620857203178   8: 0.025620848782705   1: 0.025620759505293   2: 0.025620758677828   7: 0.025620746593435   9: 0.025620709473093 

training_9994     5: 0.546511925137599   2: 0.191189088130139   0: 0.090933757790734   4: 0.024491675320921   8: 0.024479177434062   6: 0.024478935804452   3: 0.024478912612268   7: 0.024478880537157   1: 0.024478867181182   9: 0.024478780051485 

training_9995     4: 0.767459750455840   5: 0.025843879195554   9: 0.025837763519152   1: 0.025837110978863   7: 0.025837107249353   0: 0.025837093048474   3: 0.025836918740555   8: 0.025836854905082   2: 0.025836817216481   6: 0.025836704690646 